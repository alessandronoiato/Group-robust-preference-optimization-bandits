2024-10-07 00:59:31,073 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log-hyperparam-search/2024_10_07_00_27_03/rdpo,0.1,0.1,0.04,2021
2024-10-07 00:59:31,074 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2021
2024-10-07 00:59:31,075 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-10-07 00:59:31,165 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.2351, l2 distance: 36.4442, acc: 0.90.
2024-10-07 00:59:31,166 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-10-07 00:59:31,167 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [ 9.05939251 17.1373287   9.50347978 12.39752865]
2024-10-07 00:59:31,392 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.8285, 7.1348, 3.2752
2024-10-07 00:59:31,627 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1314] - INFO: unique_group_ids: {0, 1, 2}
2024-10-07 00:59:32,952 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  0, train_loss:  12.1558, val_loss:  12.4221, grad_norm: 0.4595, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6570, 0.3053, 0.6502, param: [5.44226926 8.30150541 5.14464219 8.57609433], weights: [0.33244291 0.33228895 0.33526814], train_wt_loss:  36.4675, val_wt_loss: 37.2663, train_grp_loss: [11.80348267 13.07745009 10.73259334], val_grp_loss: [12.66535943 12.4547959  12.14545168], train_hist_grp_loss: [0.15100158 0.13942111 0.36256349], cur_train_grp_loss: [0.15100158 0.13942111 0.36256349], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6570, max_kl_dist_index: 0, max_train_grp_loss:  13.0775, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6654, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.3626, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:59:34,042 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  1, train_loss:  12.1558, val_loss:  12.4222, grad_norm: 0.0001, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6571, 0.3053, 0.6503, param: [5.44250639 8.30081738 5.14567423 8.57758398], weights: [0.3318616  0.33184317 0.33629524], train_wt_loss:  36.4675, val_wt_loss: 37.2667, train_grp_loss: [11.80377605 13.07729721 10.73224574], val_grp_loss: [12.66582692 12.45463285 12.14549056], train_hist_grp_loss: [0.24542944 0.24404071 0.57721535], cur_train_grp_loss: [0.09442786 0.1046196  0.21465187], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6571, max_kl_dist_index: 0, max_train_grp_loss:  13.0773, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6658, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2147, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:59:35,141 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  2, train_loss:  12.1558, val_loss:  12.4223, grad_norm: 0.0002, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6572, 0.3054, 0.6504, param: [5.44274249 8.30013157 5.14670805 8.57908248], weights: [0.33127979 0.33139641 0.33732381], train_wt_loss:  36.4675, val_wt_loss: 37.2670, train_grp_loss: [11.80406611 13.07714914 10.73189638], val_grp_loss: [12.66629166 12.45447526 12.14552816], train_hist_grp_loss: [0.33985965 0.34865909 0.79186027], cur_train_grp_loss: [0.09443021 0.10461838 0.21464491], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6572, max_kl_dist_index: 0, max_train_grp_loss:  13.0771, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6663, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2146, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:59:36,249 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  3, train_loss:  12.1558, val_loss:  12.4225, grad_norm: 0.0003, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6573, 0.3054, 0.6505, param: [5.44297755 8.29944797 5.14774366 8.58058983], weights: [0.33069747 0.33094869 0.33835384], train_wt_loss:  36.4675, val_wt_loss: 37.2674, train_grp_loss: [11.80435282 13.07700586 10.73154524], val_grp_loss: [12.66675366 12.45432313 12.14556447], train_hist_grp_loss: [0.43429218 0.45327628 1.0064982 ], cur_train_grp_loss: [0.09443253 0.10461719 0.21463793], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6573, max_kl_dist_index: 0, max_train_grp_loss:  13.0770, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6668, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2146, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:59:37,376 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  4, train_loss:  12.1558, val_loss:  12.4226, grad_norm: 0.0003, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6574, 0.3055, 0.6506, param: [5.44321156 8.29876659 5.14878106 8.58210606], weights: [0.33011466 0.3305     0.33938533], train_wt_loss:  36.4675, val_wt_loss: 37.2677, train_grp_loss: [11.80463621 13.07686739 10.73119234], val_grp_loss: [12.66721291 12.45417646 12.1455995 ], train_hist_grp_loss: [0.528727   0.55789233 1.2211291 ], cur_train_grp_loss: [0.09443482 0.10461605 0.2146309 ], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6574, max_kl_dist_index: 0, max_train_grp_loss:  13.0769, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6672, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2146, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:59:38,572 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  5, train_loss:  12.1558, val_loss:  12.4227, grad_norm: 0.0004, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6575, 0.3056, 0.6507, param: [5.44344453 8.2980874  5.14982026 8.58363117], weights: [0.32953136 0.33005036 0.34041828], train_wt_loss:  36.4675, val_wt_loss: 37.2681, train_grp_loss: [11.80491626 13.07673373 10.73083766], val_grp_loss: [12.66766941 12.45403526 12.14563325], train_hist_grp_loss: [0.62316409 0.66250727 1.43575295], cur_train_grp_loss: [0.09443709 0.10461494 0.21462385], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6575, max_kl_dist_index: 0, max_train_grp_loss:  13.0767, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6677, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2146, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:59:39,682 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  6, train_loss:  12.1558, val_loss:  12.4228, grad_norm: 0.0005, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6576, 0.3056, 0.6507, param: [5.44367644 8.29741042 5.15086128 8.58516519], weights: [0.32894757 0.32959977 0.34145266], train_wt_loss:  36.4675, val_wt_loss: 37.2684, train_grp_loss: [11.80519297 13.07660489 10.73048121], val_grp_loss: [12.66812317 12.45389954 12.14566572], train_hist_grp_loss: [0.71760342 0.76712114 1.6503697 ], cur_train_grp_loss: [0.09443933 0.10461387 0.21461675], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6576, max_kl_dist_index: 0, max_train_grp_loss:  13.0766, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6681, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2146, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:59:40,737 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  7, train_loss:  12.1558, val_loss:  12.4229, grad_norm: 0.0006, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6577, 0.3057, 0.6508, param: [5.4439073  8.29673563 5.1519041  8.58670813], weights: [0.3283633  0.32914823 0.34248847], train_wt_loss:  36.4675, val_wt_loss: 37.2688, train_grp_loss: [11.80546636 13.07648087 10.73012298], val_grp_loss: [12.66857419 12.45376931 12.1456969 ], train_hist_grp_loss: [0.81204496 0.87173397 1.86497933], cur_train_grp_loss: [0.09444154 0.10461284 0.21460962], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6577, max_kl_dist_index: 0, max_train_grp_loss:  13.0765, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6686, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2146, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:59:41,826 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  8, train_loss:  12.1558, val_loss:  12.4230, grad_norm: 0.0006, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6578, 0.3057, 0.6509, param: [5.44413711 8.29606302 5.15294875 8.58826001], weights: [0.32777855 0.32869574 0.34352571], train_wt_loss:  36.4675, val_wt_loss: 37.2691, train_grp_loss: [11.80573641 13.07636168 10.72976298], val_grp_loss: [12.66902247 12.45364457 12.14572681], train_hist_grp_loss: [0.90648869 0.97634582 2.07958179], cur_train_grp_loss: [0.09444373 0.10461185 0.21460246], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6578, max_kl_dist_index: 0, max_train_grp_loss:  13.0764, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6690, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2146, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:59:42,863 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  9, train_loss:  12.1558, val_loss:  12.4232, grad_norm: 0.0007, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6579, 0.3058, 0.6510, param: [5.44436586 8.2953926  5.15399522 8.58982083], weights: [0.32719333 0.32824231 0.34456436], train_wt_loss:  36.4675, val_wt_loss: 37.2695, train_grp_loss: [11.80600314 13.07624733 10.7294012 ], val_grp_loss: [12.66946801 12.45352533 12.14575545], train_hist_grp_loss: [1.00093458 1.08095671 2.29417704], cur_train_grp_loss: [0.09444589 0.10461089 0.21459526], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6579, max_kl_dist_index: 0, max_train_grp_loss:  13.0762, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6695, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2146, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:59:43,893 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  10, train_loss:  12.1558, val_loss:  12.4233, grad_norm: 0.0008, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6581, 0.3059, 0.6511, param: [5.44459355 8.29472436 5.15504353 8.59139063], weights: [0.32660763 0.32778795 0.34560442], train_wt_loss:  36.4675, val_wt_loss: 37.2698, train_grp_loss: [11.80626654 13.07613781 10.72903764], val_grp_loss: [12.66991081 12.4534116  12.14578281], train_hist_grp_loss: [1.09538261 1.18556669 2.50876507], cur_train_grp_loss: [0.09444803 0.10460998 0.21458802], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6581, max_kl_dist_index: 0, max_train_grp_loss:  13.0761, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6699, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2146, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:59:44,944 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  11, train_loss:  12.1558, val_loss:  12.4234, grad_norm: 0.0009, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6582, 0.3059, 0.6512, param: [5.44482017 8.29405829 5.15609368 8.5929694 ], weights: [0.32602146 0.32733265 0.34664588], train_wt_loss:  36.4675, val_wt_loss: 37.2702, train_grp_loss: [11.80652662 13.07603315 10.7286723 ], val_grp_loss: [12.67035087 12.45330338 12.1458089 ], train_hist_grp_loss: [1.18983274 1.2901758  2.72334582], cur_train_grp_loss: [0.09445013 0.1046091  0.21458075], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6582, max_kl_dist_index: 0, max_train_grp_loss:  13.0760, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6704, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2146, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:59:45,976 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  12, train_loss:  12.1558, val_loss:  12.4235, grad_norm: 0.0010, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6583, 0.3060, 0.6513, param: [5.44504573 8.29339439 5.15714567 8.59455718], weights: [0.32543484 0.32687643 0.34768873], train_wt_loss:  36.4675, val_wt_loss: 37.2706, train_grp_loss: [11.80678336 13.07593333 10.72830518], val_grp_loss: [12.6707882  12.45320067 12.14583372], train_hist_grp_loss: [1.28428495 1.39478406 2.93791927], cur_train_grp_loss: [0.09445221 0.10460827 0.21457345], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6583, max_kl_dist_index: 0, max_train_grp_loss:  13.0759, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6708, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2146, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:59:47,005 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  13, train_loss:  12.1559, val_loss:  12.4236, grad_norm: 0.0011, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6584, 0.3060, 0.6514, param: [5.44527022 8.29273265 5.15819951 8.59615397], weights: [0.32484775 0.32641929 0.34873296], train_wt_loss:  36.4676, val_wt_loss: 37.2709, train_grp_loss: [11.80703679 13.07583838 10.72793628], val_grp_loss: [12.67122279 12.4531035  12.14585727], train_hist_grp_loss: [1.37873922 1.49939153 3.15248537], cur_train_grp_loss: [0.09445427 0.10460747 0.2145661 ], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6584, max_kl_dist_index: 0, max_train_grp_loss:  13.0758, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6712, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2146, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:59:48,034 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  14, train_loss:  12.1559, val_loss:  12.4238, grad_norm: 0.0011, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6585, 0.3061, 0.6515, param: [5.44549364 8.29207306 5.15925521 8.59775979], weights: [0.32426021 0.32596123 0.34977856], train_wt_loss:  36.4676, val_wt_loss: 37.2713, train_grp_loss: [11.80728689 13.07574829 10.7275656 ], val_grp_loss: [12.67165465 12.45301186 12.14587955], train_hist_grp_loss: [1.47319552 1.60399823 3.3670441 ], cur_train_grp_loss: [0.09445629 0.10460671 0.21455873], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6585, max_kl_dist_index: 0, max_train_grp_loss:  13.0757, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6717, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2146, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:59:49,060 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  15, train_loss:  12.1559, val_loss:  12.4239, grad_norm: 0.0012, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6586, 0.3062, 0.6516, param: [5.44571598 8.29141563 5.16031278 8.59937466], weights: [0.32367223 0.32550225 0.35082552], train_wt_loss:  36.4676, val_wt_loss: 37.2717, train_grp_loss: [11.80753367 13.07566307 10.72719314], val_grp_loss: [12.67208378 12.45292575 12.14590057], train_hist_grp_loss: [1.56765381 1.70860422 3.58159541], cur_train_grp_loss: [0.0944583  0.10460599 0.21455131], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6586, max_kl_dist_index: 0, max_train_grp_loss:  13.0757, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6721, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2146, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:59:50,115 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  16, train_loss:  12.1559, val_loss:  12.4240, grad_norm: 0.0013, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6587, 0.3062, 0.6517, param: [5.44593725 8.29076034 5.16137221 8.60099858], weights: [0.32308379 0.32504236 0.35187384], train_wt_loss:  36.4676, val_wt_loss: 37.2720, train_grp_loss: [11.80777714 13.07558272 10.72681889], val_grp_loss: [12.67251018 12.45284519 12.14592032], train_hist_grp_loss: [1.66211408 1.81320953 3.79613927], cur_train_grp_loss: [0.09446027 0.1046053  0.21454386], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6587, max_kl_dist_index: 0, max_train_grp_loss:  13.0756, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6725, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2145, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:59:51,151 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  17, train_loss:  12.1559, val_loss:  12.4241, grad_norm: 0.0014, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6588, 0.3063, 0.6518, param: [5.44615744 8.2901072  5.16243352 8.60263159], weights: [0.32249492 0.32458157 0.35292351], train_wt_loss:  36.4676, val_wt_loss: 37.2724, train_grp_loss: [11.80801728 13.07550726 10.72644286], val_grp_loss: [12.67293385 12.45277019 12.14593881], train_hist_grp_loss: [1.7565763  1.91781419 4.01067565], cur_train_grp_loss: [0.09446222 0.10460466 0.21453638], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6588, max_kl_dist_index: 0, max_train_grp_loss:  13.0755, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6729, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2145, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:59:52,179 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  18, train_loss:  12.1559, val_loss:  12.4243, grad_norm: 0.0015, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6590, 0.3063, 0.6519, param: [5.44637654 8.28945618 5.16349671 8.60427368], weights: [0.3219056  0.32411988 0.35397451], train_wt_loss:  36.4676, val_wt_loss: 37.2728, train_grp_loss: [11.80825411 13.07543668 10.72606504], val_grp_loss: [12.6733548  12.45270074 12.14595605], train_hist_grp_loss: [1.85104044 2.02241825 4.22520451], cur_train_grp_loss: [0.09446414 0.10460406 0.21452886], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6590, max_kl_dist_index: 0, max_train_grp_loss:  13.0754, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6734, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2145, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:59:53,221 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  19, train_loss:  12.1559, val_loss:  12.4244, grad_norm: 0.0016, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6591, 0.3064, 0.6520, param: [5.44659456 8.2888073  5.16456179 8.60592489], weights: [0.32131586 0.3236573  0.35502684], train_wt_loss:  36.4677, val_wt_loss: 37.2731, train_grp_loss: [11.80848763 13.075371   10.72568544], val_grp_loss: [12.67377302 12.45263686 12.14597202], train_hist_grp_loss: [1.94550647 2.12702174 4.43972581], cur_train_grp_loss: [0.09446603 0.10460349 0.2145213 ], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6591, max_kl_dist_index: 0, max_train_grp_loss:  13.0754, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6738, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2145, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:59:54,333 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  20, train_loss:  12.1559, val_loss:  12.4245, grad_norm: 0.0017, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6592, 0.3065, 0.6522, param: [5.44681149 8.28816054 5.16562877 8.60758521], weights: [0.32072569 0.32319382 0.35608049], train_wt_loss:  36.4677, val_wt_loss: 37.2735, train_grp_loss: [11.80871783 13.07531022 10.72530405], val_grp_loss: [12.67418852 12.45257856 12.14598675], train_hist_grp_loss: [2.03997437 2.23162471 4.65423952], cur_train_grp_loss: [0.0944679  0.10460297 0.21451371], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6592, max_kl_dist_index: 0, max_train_grp_loss:  13.0753, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6742, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2145, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:59:55,368 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  21, train_loss:  12.1559, val_loss:  12.4246, grad_norm: 0.0017, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6593, 0.3065, 0.6523, param: [5.44702733 8.28751589 5.16669764 8.60925467], weights: [0.32013509 0.32272946 0.35713545], train_wt_loss:  36.4677, val_wt_loss: 37.2739, train_grp_loss: [11.80894472 13.07525435 10.72492087], val_grp_loss: [12.6746013  12.45252583 12.14600021], train_hist_grp_loss: [2.13444411 2.33622719 4.8687456 ], cur_train_grp_loss: [0.09446974 0.10460248 0.21450608], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6593, max_kl_dist_index: 0, max_train_grp_loss:  13.0753, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6746, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2145, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:59:56,443 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  22, train_loss:  12.1559, val_loss:  12.4248, grad_norm: 0.0018, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6594, 0.3066, 0.6524, param: [5.44724208 8.28687336 5.16776842 8.61093329], weights: [0.31954407 0.32226422 0.35819171], train_wt_loss:  36.4677, val_wt_loss: 37.2743, train_grp_loss: [11.80916831 13.07520338 10.72453591], val_grp_loss: [12.67501135 12.45247869 12.14601243], train_hist_grp_loss: [2.22891567 2.44082922 5.08324401], cur_train_grp_loss: [0.09447156 0.10460203 0.21449842], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6594, max_kl_dist_index: 0, max_train_grp_loss:  13.0752, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6750, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2145, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:59:57,493 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  23, train_loss:  12.1559, val_loss:  12.4249, grad_norm: 0.0019, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6595, 0.3067, 0.6525, param: [5.44745573 8.28623293 5.16884112 8.61262107], weights: [0.31895264 0.32179809 0.35924926], train_wt_loss:  36.4678, val_wt_loss: 37.2746, train_grp_loss: [11.80938859 13.07515733 10.72414916], val_grp_loss: [12.6754187  12.45243714 12.1460234 ], train_hist_grp_loss: [2.32338902 2.54543085 5.29773473], cur_train_grp_loss: [0.09447335 0.10460163 0.21449072], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6595, max_kl_dist_index: 0, max_train_grp_loss:  13.0752, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6754, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2145, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:59:58,521 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  24, train_loss:  12.1559, val_loss:  12.4250, grad_norm: 0.0020, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6597, 0.3067, 0.6526, param: [5.44766827 8.28559461 5.16991573 8.61431804], weights: [0.3183608 0.3213311 0.3603081], train_wt_loss:  36.4678, val_wt_loss: 37.2750, train_grp_loss: [11.80960556 13.07511621 10.72376062], val_grp_loss: [12.67582332 12.4524012  12.14603312], train_hist_grp_loss: [2.41786413 2.65003211 5.51221772], cur_train_grp_loss: [0.09447511 0.10460126 0.21448298], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6597, max_kl_dist_index: 0, max_train_grp_loss:  13.0751, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6758, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2145, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:59:59,544 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  25, train_loss:  12.1559, val_loss:  12.4251, grad_norm: 0.0021, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6598, 0.3068, 0.6527, param: [5.44787972 8.28495837 5.17099226 8.61602421], weights: [0.31776856 0.32086324 0.3613682 ], train_wt_loss:  36.4678, val_wt_loss: 37.2754, train_grp_loss: [11.80981923 13.07508001 10.72337029], val_grp_loss: [12.67622523 12.45237086 12.1460416 ], train_hist_grp_loss: [2.51234097 2.75463304 5.72669293], cur_train_grp_loss: [0.09447684 0.10460093 0.21447521], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6598, max_kl_dist_index: 0, max_train_grp_loss:  13.0751, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6762, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2145, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:00:00,582 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  26, train_loss:  12.1559, val_loss:  12.4253, grad_norm: 0.0022, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6599, 0.3069, 0.6528, param: [5.44809006 8.28432423 5.17207073 8.61773959], weights: [0.31717591 0.32039452 0.36242957], train_wt_loss:  36.4678, val_wt_loss: 37.2758, train_grp_loss: [11.8100296  13.07504875 10.72297817], val_grp_loss: [12.67662443 12.45234613 12.14604883], train_hist_grp_loss: [2.60681952 2.85923368 5.94116033], cur_train_grp_loss: [0.09447855 0.10460064 0.21446741], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6599, max_kl_dist_index: 0, max_train_grp_loss:  13.0750, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6766, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2145, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:00:01,646 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  27, train_loss:  12.1560, val_loss:  12.4254, grad_norm: 0.0023, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6600, 0.3069, 0.6529, param: [5.44829929 8.28369216 5.17315113 8.61946419], weights: [0.31658287 0.31992494 0.3634922 ], train_wt_loss:  36.4679, val_wt_loss: 37.2762, train_grp_loss: [11.81023667 13.07502243 10.72258426], val_grp_loss: [12.67702092 12.45232702 12.14605483], train_hist_grp_loss: [2.70129976 2.96383407 6.1556199 ], cur_train_grp_loss: [0.09448024 0.10460039 0.21445956], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6600, max_kl_dist_index: 0, max_train_grp_loss:  13.0750, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6770, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2145, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:00:02,662 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  28, train_loss:  12.1560, val_loss:  12.4255, grad_norm: 0.0024, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6601, 0.3070, 0.6530, param: [5.44850741 8.28306217 5.17423347 8.62119804], weights: [0.31598943 0.3194545  0.36455607], train_wt_loss:  36.4679, val_wt_loss: 37.2765, train_grp_loss: [11.81044044 13.07500105 10.72218856], val_grp_loss: [12.67741471 12.45231354 12.14605958], train_hist_grp_loss: [2.79578165 3.06843425 6.37007158], cur_train_grp_loss: [0.09448189 0.10460018 0.21445169], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6601, max_kl_dist_index: 0, max_train_grp_loss:  13.0750, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6774, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2145, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:00:03,682 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  29, train_loss:  12.1560, val_loss:  12.4256, grad_norm: 0.0025, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6603, 0.3071, 0.6531, param: [5.44871441 8.28243425 5.17531776 8.62294115], weights: [0.31539561 0.31898322 0.36562117], train_wt_loss:  36.4679, val_wt_loss: 37.2769, train_grp_loss: [11.81064092 13.07498463 10.72179107], val_grp_loss: [12.67780578 12.45230569 12.14606311], train_hist_grp_loss: [2.89026518 3.17303426 6.58451535], cur_train_grp_loss: [0.09448352 0.10460001 0.21444377], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6603, max_kl_dist_index: 0, max_train_grp_loss:  13.0750, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6778, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2144, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:00:04,731 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  30, train_loss:  12.1560, val_loss:  12.4258, grad_norm: 0.0026, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6604, 0.3071, 0.6532, param: [5.4489203  8.2818084  5.17640401 8.62469353], weights: [0.3148014 0.3185111 0.3666875], train_wt_loss:  36.4680, val_wt_loss: 37.2773, train_grp_loss: [11.81083811 13.07497316 10.72139179], val_grp_loss: [12.67819416 12.45230348 12.1460654 ], train_hist_grp_loss: [2.9847503  3.27763413 6.79895117], cur_train_grp_loss: [0.09448513 0.10459988 0.21443582], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6604, max_kl_dist_index: 0, max_train_grp_loss:  13.0750, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6782, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2144, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:00:05,802 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  31, train_loss:  12.1560, val_loss:  12.4259, grad_norm: 0.0027, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6605, 0.3072, 0.6534, param: [5.44912506 8.2811846  5.17749221 8.6264552 ], weights: [0.31420682 0.31803813 0.36775505], train_wt_loss:  36.4680, val_wt_loss: 37.2777, train_grp_loss: [11.81103201 13.07496666 10.72099072], val_grp_loss: [12.67857983 12.45230692 12.14606646], train_hist_grp_loss: [3.07923701 3.38223392 7.01337901], cur_train_grp_loss: [0.0944867  0.10459979 0.21442784], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6605, max_kl_dist_index: 0, max_train_grp_loss:  13.0750, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6786, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2144, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:00:06,826 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  32, train_loss:  12.1560, val_loss:  12.4260, grad_norm: 0.0028, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6606, 0.3073, 0.6535, param: [5.4493287  8.28056285 5.17858238 8.62822616], weights: [0.31361186 0.31756434 0.36882381], train_wt_loss:  36.4680, val_wt_loss: 37.2781, train_grp_loss: [11.81122263 13.07496513 10.72058786], val_grp_loss: [12.6789628  12.45231601 12.14606629], train_hist_grp_loss: [3.17372527 3.48683365 7.22779883], cur_train_grp_loss: [0.09448826 0.10459973 0.21441981], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6606, max_kl_dist_index: 0, max_train_grp_loss:  13.0750, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6790, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2144, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:00:07,848 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  33, train_loss:  12.1560, val_loss:  12.4262, grad_norm: 0.0029, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6608, 0.3073, 0.6536, param: [5.44953122 8.27994315 5.17967452 8.63000645], weights: [0.31301653 0.31708971 0.36989376], train_wt_loss:  36.4681, val_wt_loss: 37.2785, train_grp_loss: [11.81140995 13.07496857 10.72018321], val_grp_loss: [12.67934308 12.45233076 12.14606489], train_hist_grp_loss: [3.26821505 3.59143337 7.44221058], cur_train_grp_loss: [0.09448978 0.10459972 0.21441176], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6608, max_kl_dist_index: 0, max_train_grp_loss:  13.0750, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6793, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2144, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:00:08,884 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  34, train_loss:  12.1560, val_loss:  12.4263, grad_norm: 0.0030, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6609, 0.3074, 0.6537, param: [5.4497326  8.27932549 5.18076864 8.63179606], weights: [0.31242084 0.31661426 0.3709649 ], train_wt_loss:  36.4681, val_wt_loss: 37.2789, train_grp_loss: [11.811594   13.07497699 10.71977676], val_grp_loss: [12.67972066 12.45235118 12.14606228], train_hist_grp_loss: [3.36270633 3.69603312 7.65661425], cur_train_grp_loss: [0.09449128 0.10459975 0.21440366], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6609, max_kl_dist_index: 0, max_train_grp_loss:  13.0750, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6797, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2144, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:00:09,924 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  35, train_loss:  12.1560, val_loss:  12.4264, grad_norm: 0.0031, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6610, 0.3075, 0.6538, param: [5.44993285 8.27870986 5.18186474 8.63359503], weights: [0.31182479 0.316138   0.37203721], train_wt_loss:  36.4681, val_wt_loss: 37.2793, train_grp_loss: [11.81177477 13.0749904  10.71936853], val_grp_loss: [12.68009555 12.45237727 12.14605844], train_hist_grp_loss: [3.45719908 3.80063294 7.87100978], cur_train_grp_loss: [0.09449275 0.10459982 0.21439554], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6610, max_kl_dist_index: 0, max_train_grp_loss:  13.0750, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6801, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2144, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:00:10,973 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  36, train_loss:  12.1561, val_loss:  12.4266, grad_norm: 0.0032, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6611, 0.3075, 0.6539, param: [5.45013197 8.27809625 5.18296282 8.63540335], weights: [0.31122839 0.31566092 0.3731107 ], train_wt_loss:  36.4682, val_wt_loss: 37.2797, train_grp_loss: [11.81195226 13.07500881 10.7189585 ], val_grp_loss: [12.68046774 12.45240905 12.14605339], train_hist_grp_loss: [3.55169328 3.90523286 8.08539715], cur_train_grp_loss: [0.0944942  0.10459992 0.21438737], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6611, max_kl_dist_index: 0, max_train_grp_loss:  13.0750, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6805, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2144, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:00:12,038 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  37, train_loss:  12.1561, val_loss:  12.4267, grad_norm: 0.0033, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6613, 0.3076, 0.6540, param: [5.45032994 8.27748467 5.1840629  8.63722104], weights: [0.31063163 0.31518303 0.37418534], train_wt_loss:  36.4682, val_wt_loss: 37.2801, train_grp_loss: [11.81212648 13.07503221 10.71854668], val_grp_loss: [12.68083726 12.4524465  12.14604712], train_hist_grp_loss: [3.64618889 4.00983293 8.29977632], cur_train_grp_loss: [0.09449562 0.10460007 0.21437917], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6613, max_kl_dist_index: 0, max_train_grp_loss:  13.0750, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6808, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2144, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:00:13,116 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  38, train_loss:  12.1561, val_loss:  12.4268, grad_norm: 0.0034, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6614, 0.3077, 0.6542, param: [5.45052678 8.27687509 5.18516498 8.63904812], weights: [0.31003453 0.31470433 0.37526113], train_wt_loss:  36.4683, val_wt_loss: 37.2805, train_grp_loss: [11.81229742 13.07506061 10.71813307], val_grp_loss: [12.68120408 12.45248965 12.14603964], train_hist_grp_loss: [3.74068591 4.11443319 8.51414726], cur_train_grp_loss: [0.09449701 0.10460026 0.21437093], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6614, max_kl_dist_index: 0, max_train_grp_loss:  13.0751, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6812, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2144, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:00:14,168 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  39, train_loss:  12.1561, val_loss:  12.4270, grad_norm: 0.0035, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6615, 0.3077, 0.6543, param: [5.45072246 8.27626752 5.18626907 8.64088461], weights: [0.30943709 0.31422484 0.37633806], train_wt_loss:  36.4683, val_wt_loss: 37.2809, train_grp_loss: [11.8124651  13.07509402 10.71771767], val_grp_loss: [12.68156822 12.4525385  12.14603096], train_hist_grp_loss: [3.83518429 4.21903367 8.72850992], cur_train_grp_loss: [0.09449838 0.10460048 0.21436266], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6615, max_kl_dist_index: 0, max_train_grp_loss:  13.0751, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6816, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2144, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:00:15,212 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  40, train_loss:  12.1561, val_loss:  12.4271, grad_norm: 0.0036, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6616, 0.3078, 0.6544, param: [5.450917   8.27566196 5.18737516 8.64273051], weights: [0.30883932 0.31374456 0.37741612], train_wt_loss:  36.4684, val_wt_loss: 37.2813, train_grp_loss: [11.81262951 13.07513245 10.71730048], val_grp_loss: [12.68192969 12.45259306 12.14602106], train_hist_grp_loss: [3.92968401 4.32363443 8.94286427], cur_train_grp_loss: [0.09449972 0.10460075 0.21435435], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6616, max_kl_dist_index: 0, max_train_grp_loss:  13.0751, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6819, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2144, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:00:16,269 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  41, train_loss:  12.1561, val_loss:  12.4272, grad_norm: 0.0037, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6618, 0.3079, 0.6545, param: [5.45111039 8.27505838 5.18848327 8.64458584], weights: [0.30824121 0.31326349 0.3784953 ], train_wt_loss:  36.4684, val_wt_loss: 37.2817, train_grp_loss: [11.81279066 13.0751759  10.7168815 ], val_grp_loss: [12.68228847 12.45265333 12.14600996], train_hist_grp_loss: [4.02418504 4.42823549 9.15721028], cur_train_grp_loss: [0.09450104 0.10460106 0.21434601], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6618, max_kl_dist_index: 0, max_train_grp_loss:  13.0752, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6823, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2143, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:00:17,321 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  42, train_loss:  12.1561, val_loss:  12.4274, grad_norm: 0.0038, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6619, 0.3079, 0.6546, param: [5.45130262 8.27445679 5.1895934  8.64645061], weights: [0.30764278 0.31278164 0.37957558], train_wt_loss:  36.4684, val_wt_loss: 37.2821, train_grp_loss: [11.81294855 13.07522438 10.71646072], val_grp_loss: [12.68264458 12.45271932 12.14599767], train_hist_grp_loss: [4.11868737 4.53283689 9.37154791], cur_train_grp_loss: [0.09450233 0.10460141 0.21433763], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6619, max_kl_dist_index: 0, max_train_grp_loss:  13.0752, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6826, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2143, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:00:18,395 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  43, train_loss:  12.1562, val_loss:  12.4275, grad_norm: 0.0039, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6620, 0.3080, 0.6548, param: [5.4514937  8.27385718 5.19070556 8.64832485], weights: [0.30704403 0.312299   0.38065696], train_wt_loss:  36.4685, val_wt_loss: 37.2825, train_grp_loss: [11.81310319 13.07527789 10.71603816], val_grp_loss: [12.68299802 12.45279103 12.14598417], train_hist_grp_loss: [4.21319096 4.63743869 9.58587712], cur_train_grp_loss: [0.09450359 0.1046018  0.21432921], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6620, max_kl_dist_index: 0, max_train_grp_loss:  13.0753, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6830, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2143, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:00:19,427 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  44, train_loss:  12.1562, val_loss:  12.4277, grad_norm: 0.0040, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6622, 0.3081, 0.6549, param: [5.45168361 8.27325954 5.19181975 8.65020855], weights: [0.30644497 0.3118156  0.38173943], train_wt_loss:  36.4685, val_wt_loss: 37.2830, train_grp_loss: [11.81325457 13.07533643 10.71561381], val_grp_loss: [12.68334879 12.45286848 12.14596948], train_hist_grp_loss: [4.30769578 4.74204091 9.80019789], cur_train_grp_loss: [0.09450483 0.10460222 0.21432076], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6622, max_kl_dist_index: 0, max_train_grp_loss:  13.0753, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6833, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2143, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:00:20,460 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  45, train_loss:  12.1562, val_loss:  12.4278, grad_norm: 0.0041, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6623, 0.3082, 0.6550, param: [5.45187236 8.27266387 5.19293598 8.65210175], weights: [0.30584559 0.31133143 0.38282298], train_wt_loss:  36.4686, val_wt_loss: 37.2834, train_grp_loss: [11.8134027  13.07540002 10.71518766], val_grp_loss: [12.68369689 12.45295167 12.1459536 ], train_hist_grp_loss: [ 4.40220182  4.8466436  10.01451016], cur_train_grp_loss: [0.09450604 0.10460269 0.21431228], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6623, max_kl_dist_index: 0, max_train_grp_loss:  13.0754, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6837, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2143, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:00:21,497 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  46, train_loss:  12.1562, val_loss:  12.4279, grad_norm: 0.0042, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6624, 0.3082, 0.6551, param: [5.45205994 8.27207016 5.19405425 8.65400444], weights: [0.30524591 0.3108465  0.3839076 ], train_wt_loss:  36.4687, val_wt_loss: 37.2838, train_grp_loss: [11.81354758 13.07546866 10.71475973], val_grp_loss: [12.68404232 12.4530406  12.14593653], train_hist_grp_loss: [ 4.49670904  4.9512468  10.22881392], cur_train_grp_loss: [0.09450722 0.1046032  0.21430375], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6624, max_kl_dist_index: 0, max_train_grp_loss:  13.0755, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6840, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2143, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:00:22,540 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  47, train_loss:  12.1562, val_loss:  12.4281, grad_norm: 0.0043, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6626, 0.3083, 0.6553, param: [5.45224635 8.2714784  5.19517457 8.65591664], weights: [0.30464592 0.31036081 0.38499327], train_wt_loss:  36.4687, val_wt_loss: 37.2842, train_grp_loss: [11.81368923 13.07554235 10.71433001], val_grp_loss: [12.68438509 12.45313528 12.14591828], train_hist_grp_loss: [ 4.59121742  5.05585055 10.44310911], cur_train_grp_loss: [0.09450838 0.10460375 0.21429519], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6626, max_kl_dist_index: 0, max_train_grp_loss:  13.0755, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6844, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2143, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:00:23,583 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  48, train_loss:  12.1563, val_loss:  12.4282, grad_norm: 0.0044, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6627, 0.3084, 0.6554, param: [5.45243159 8.27088858 5.19629695 8.65783837], weights: [0.30404564 0.30987437 0.38607999], train_wt_loss:  36.4688, val_wt_loss: 37.2846, train_grp_loss: [11.81382763 13.07562111 10.7138985 ], val_grp_loss: [12.68472521 12.45323573 12.14589884], train_hist_grp_loss: [ 4.68572693  5.16045489 10.65739571], cur_train_grp_loss: [0.09450951 0.10460434 0.2142866 ], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6627, max_kl_dist_index: 0, max_train_grp_loss:  13.0756, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6847, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2143, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:00:24,657 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  49, train_loss:  12.1563, val_loss:  12.4284, grad_norm: 0.0045, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6628, 0.3084, 0.6555, param: [5.45261565 8.2703007  5.19742138 8.65976965], weights: [0.30344507 0.30938718 0.38716775], train_wt_loss:  36.4688, val_wt_loss: 37.2851, train_grp_loss: [11.81396279 13.07570493 10.71346521], val_grp_loss: [12.68506267 12.45334194 12.14587823], train_hist_grp_loss: [ 4.78023756  5.26505986 10.87167368], cur_train_grp_loss: [0.09451062 0.10460497 0.21427797], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6628, max_kl_dist_index: 0, max_train_grp_loss:  13.0757, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6851, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2143, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:00:25,700 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  50, train_loss:  12.1563, val_loss:  12.4285, grad_norm: 0.0046, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6630, 0.3085, 0.6556, param: [5.45279852 8.26971475 5.19854788 8.66171047], weights: [0.30284422 0.30889925 0.38825653], train_wt_loss:  36.4689, val_wt_loss: 37.2855, train_grp_loss: [11.81409472 13.07579382 10.71303012], val_grp_loss: [12.68539748 12.45345392 12.14585644], train_hist_grp_loss: [ 4.87474926  5.3696655  11.08594299], cur_train_grp_loss: [0.0945117  0.10460564 0.2142693 ], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6630, max_kl_dist_index: 0, max_train_grp_loss:  13.0758, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6854, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2143, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:00:26,731 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  51, train_loss:  12.1563, val_loss:  12.4286, grad_norm: 0.0048, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6631, 0.3086, 0.6558, param: [5.45298022 8.26913073 5.19967644 8.66366086], weights: [0.30224308 0.30841059 0.38934633], train_wt_loss:  36.4689, val_wt_loss: 37.2859, train_grp_loss: [11.81422343 13.07588779 10.71259325], val_grp_loss: [12.68572963 12.45357167 12.14583348], train_hist_grp_loss: [ 4.96926202  5.47427185 11.30020359], cur_train_grp_loss: [0.09451276 0.10460635 0.2142606 ], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6631, max_kl_dist_index: 0, max_train_grp_loss:  13.0759, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6857, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2143, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:00:27,760 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  52, train_loss:  12.1563, val_loss:  12.4288, grad_norm: 0.0049, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6632, 0.3087, 0.6559, param: [5.45316072 8.26854862 5.20080709 8.66562084], weights: [0.30164167 0.3079212  0.39043713], train_wt_loss:  36.4690, val_wt_loss: 37.2863, train_grp_loss: [11.8143489  13.07598684 10.7121546 ], val_grp_loss: [12.68605914 12.45369522 12.14580934], train_hist_grp_loss: [ 5.0637758   5.57887895 11.51445545], cur_train_grp_loss: [0.09451379 0.1046071  0.21425187], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6632, max_kl_dist_index: 0, max_train_grp_loss:  13.0760, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6861, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2143, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:00:28,801 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  53, train_loss:  12.1564, val_loss:  12.4289, grad_norm: 0.0050, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6634, 0.3087, 0.6560, param: [5.45334004 8.26796842 5.20193981 8.6675904 ], weights: [0.30103998 0.30743108 0.39152893], train_wt_loss:  36.4691, val_wt_loss: 37.2868, train_grp_loss: [11.81447116 13.07609098 10.71171416], val_grp_loss: [12.68638601 12.45382455 12.14578405], train_hist_grp_loss: [ 5.15829059  5.68348685 11.72869855], cur_train_grp_loss: [0.09451479 0.10460789 0.21424309], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6634, max_kl_dist_index: 0, max_train_grp_loss:  13.0761, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6864, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2142, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:00:29,870 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  54, train_loss:  12.1564, val_loss:  12.4291, grad_norm: 0.0051, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6635, 0.3088, 0.6562, param: [5.45351816 8.26739012 5.20307462 8.66956958], weights: [0.30043804 0.30694025 0.39262171], train_wt_loss:  36.4691, val_wt_loss: 37.2872, train_grp_loss: [11.8145902  13.07620021 10.71127193], val_grp_loss: [12.68671023 12.45395968 12.14575759], train_hist_grp_loss: [ 5.25280636  5.78809557 11.94293283], cur_train_grp_loss: [0.09451577 0.10460873 0.21423428], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6635, max_kl_dist_index: 0, max_train_grp_loss:  13.0762, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6867, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2142, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:00:30,909 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  55, train_loss:  12.1564, val_loss:  12.4292, grad_norm: 0.0052, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6636, 0.3089, 0.6563, param: [5.45369509 8.26681372 5.20421152 8.67155837], weights: [0.29983583 0.3064487  0.39371547], train_wt_loss:  36.4692, val_wt_loss: 37.2876, train_grp_loss: [11.81470602 13.07631455 10.71082793], val_grp_loss: [12.68703182 12.45410062 12.14572997], train_hist_grp_loss: [ 5.34732309  5.89270518 12.15715827], cur_train_grp_loss: [0.09451672 0.1046096  0.21422544], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6636, max_kl_dist_index: 0, max_train_grp_loss:  13.0763, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6870, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2142, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:00:32,004 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  56, train_loss:  12.1564, val_loss:  12.4294, grad_norm: 0.0053, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6638, 0.3090, 0.6564, param: [5.45387081 8.2662392  5.20535051 8.6735568 ], weights: [0.29923337 0.30595644 0.39481019], train_wt_loss:  36.4693, val_wt_loss: 37.2881, train_grp_loss: [11.81481863 13.07643399 10.71038214], val_grp_loss: [12.68735077 12.45424736 12.1457012 ], train_hist_grp_loss: [ 5.44184073  5.99731569 12.37137483], cur_train_grp_loss: [0.09451765 0.10461052 0.21421656], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6638, max_kl_dist_index: 0, max_train_grp_loss:  13.0764, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6874, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2142, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:00:33,052 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  57, train_loss:  12.1564, val_loss:  12.4295, grad_norm: 0.0054, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6639, 0.3090, 0.6566, param: [5.45404533 8.26566656 5.2064916  8.67556487], weights: [0.29863065 0.30546349 0.39590586], train_wt_loss:  36.4693, val_wt_loss: 37.2885, train_grp_loss: [11.81492804 13.07655853 10.70993456], val_grp_loss: [12.68766709 12.45439993 12.14567128], train_hist_grp_loss: [ 5.53635928  6.10192716 12.58558247], cur_train_grp_loss: [0.09451855 0.10461147 0.21420764], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6639, max_kl_dist_index: 0, max_train_grp_loss:  13.0766, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6877, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2142, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:00:34,101 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  58, train_loss:  12.1565, val_loss:  12.4297, grad_norm: 0.0056, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6641, 0.3091, 0.6567, param: [5.45421864 8.2650958  5.2076348  8.6775826 ], weights: [0.29802769 0.30496983 0.39700248], train_wt_loss:  36.4694, val_wt_loss: 37.2890, train_grp_loss: [11.81503424 13.0766882  10.70948521], val_grp_loss: [12.68798079 12.45455831 12.1456402 ], train_hist_grp_loss: [ 5.63087871  6.20653963 12.79978116], cur_train_grp_loss: [0.09451942 0.10461247 0.21419869], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6641, max_kl_dist_index: 0, max_train_grp_loss:  13.0767, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6880, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2142, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:00:35,149 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  59, train_loss:  12.1565, val_loss:  12.4298, grad_norm: 0.0057, live_grad: 0.0000, reward_err: 0.0105, 0.0142, 0.0002, KL_dist: 0.6642, 0.3092, 0.6568, param: [5.45439074 8.26452689 5.20878012 8.67961   ], weights: [0.2974245  0.30447548 0.39810002], train_wt_loss:  36.4695, val_wt_loss: 37.2894, train_grp_loss: [11.81513725 13.07682298 10.70903408], val_grp_loss: [12.68829185 12.45472253 12.14560799], train_hist_grp_loss: [ 5.72539898  6.31115314 13.01397086], cur_train_grp_loss: [0.09452027 0.10461351 0.2141897 ], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6642, max_kl_dist_index: 0, max_train_grp_loss:  13.0768, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6883, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2142, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:00:36,188 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  60, train_loss:  12.1565, val_loss:  12.4299, grad_norm: 0.0058, live_grad: 0.0000, reward_err: 0.0105, 0.0142, 0.0002, KL_dist: 0.6643, 0.3093, 0.6570, param: [5.45456163 8.26395985 5.20992754 8.68164708], weights: [0.29682107 0.30398045 0.39919848], train_wt_loss:  36.4695, val_wt_loss: 37.2898, train_grp_loss: [11.81523706 13.07696289 10.70858117], val_grp_loss: [12.6886003  12.45489258 12.14557463], train_hist_grp_loss: [ 5.81992008  6.41576772 13.22815155], cur_train_grp_loss: [0.0945211  0.10461458 0.21418068], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6643, max_kl_dist_index: 0, max_train_grp_loss:  13.0770, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6886, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2142, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:00:37,223 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  61, train_loss:  12.1565, val_loss:  12.4301, grad_norm: 0.0059, live_grad: 0.0000, reward_err: 0.0105, 0.0142, 0.0002, KL_dist: 0.6645, 0.3093, 0.6571, param: [5.4547313  8.26339465 5.21107709 8.68369386], weights: [0.29621741 0.30348474 0.40029786], train_wt_loss:  36.4696, val_wt_loss: 37.2903, train_grp_loss: [11.81533368 13.07710794 10.70812648], val_grp_loss: [12.68890613 12.45506847 12.14554014], train_hist_grp_loss: [ 5.91444198  6.52038343 13.44232317], cur_train_grp_loss: [0.0945219  0.1046157  0.21417162], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6645, max_kl_dist_index: 0, max_train_grp_loss:  13.0771, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6889, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2142, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:00:38,275 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  62, train_loss:  12.1566, val_loss:  12.4302, grad_norm: 0.0060, live_grad: 0.0000, reward_err: 0.0105, 0.0139, 0.0002, KL_dist: 0.6646, 0.3094, 0.6572, param: [5.45489975 8.2628313  5.21222876 8.68575035], weights: [0.29561352 0.30298835 0.40139813], train_wt_loss:  36.4697, val_wt_loss: 37.2907, train_grp_loss: [11.81542711 13.07725812 10.70767002], val_grp_loss: [12.68920935 12.45525021 12.14550451], train_hist_grp_loss: [ 6.00896464  6.62500029 13.6564857 ], cur_train_grp_loss: [0.09452267 0.10461686 0.21416253], max_reward_err:  0.0139, max_reward_err_index: 1, max_kl_dist:  0.6646, max_kl_dist_index: 0, max_train_grp_loss:  13.0773, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6892, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2142, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:00:39,318 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  63, train_loss:  12.1566, val_loss:  12.4304, grad_norm: 0.0062, live_grad: 0.0000, reward_err: 0.0105, 0.0139, 0.0002, KL_dist: 0.6648, 0.3095, 0.6574, param: [5.45506697 8.26226978 5.21338256 8.68781656], weights: [0.29500942 0.30249129 0.40249929], train_wt_loss:  36.4698, val_wt_loss: 37.2912, train_grp_loss: [11.81551737 13.07741344 10.70721178], val_grp_loss: [12.68950995 12.45543781 12.14546776], train_hist_grp_loss: [ 6.10348806  6.72961835 13.8706391 ], cur_train_grp_loss: [0.09452342 0.10461806 0.2141534 ], max_reward_err:  0.0139, max_reward_err_index: 1, max_kl_dist:  0.6648, max_kl_dist_index: 0, max_train_grp_loss:  13.0774, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6895, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2142, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:00:40,367 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  64, train_loss:  12.1566, val_loss:  12.4305, grad_norm: 0.0063, live_grad: 0.0000, reward_err: 0.0105, 0.0139, 0.0002, KL_dist: 0.6649, 0.3096, 0.6575, param: [5.45523297 8.26171008 5.2145385  8.6898925 ], weights: [0.2944051  0.30199357 0.40360132], train_wt_loss:  36.4698, val_wt_loss: 37.2916, train_grp_loss: [11.81560445 13.07757391 10.70675176], val_grp_loss: [12.68980795 12.45563127 12.14542987], train_hist_grp_loss: [ 6.1980122   6.83423766 14.08478334], cur_train_grp_loss: [0.09452414 0.10461931 0.21414424], max_reward_err:  0.0139, max_reward_err_index: 1, max_kl_dist:  0.6649, max_kl_dist_index: 0, max_train_grp_loss:  13.0776, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6898, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2141, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:00:41,440 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  65, train_loss:  12.1566, val_loss:  12.4307, grad_norm: 0.0064, live_grad: 0.0000, reward_err: 0.0105, 0.0139, 0.0002, KL_dist: 0.6650, 0.3097, 0.6576, param: [5.45539773 8.2611522  5.21569658 8.69197819], weights: [0.29380058 0.3014952  0.40470422], train_wt_loss:  36.4699, val_wt_loss: 37.2921, train_grp_loss: [11.81568835 13.07773954 10.70628998], val_grp_loss: [12.69010334 12.45583059 12.14539087], train_hist_grp_loss: [ 6.29253704  6.93885825 14.29891837], cur_train_grp_loss: [0.09452484 0.10462059 0.21413504], max_reward_err:  0.0139, max_reward_err_index: 1, max_kl_dist:  0.6650, max_kl_dist_index: 0, max_train_grp_loss:  13.0777, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6901, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2141, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:00:42,476 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  66, train_loss:  12.1567, val_loss:  12.4309, grad_norm: 0.0065, live_grad: 0.0000, reward_err: 0.0105, 0.0139, 0.0002, KL_dist: 0.6652, 0.3097, 0.6578, param: [5.45556126 8.26059614 5.2168568  8.69407364], weights: [0.29319585 0.30099617 0.40580798], train_wt_loss:  36.4700, val_wt_loss: 37.2926, train_grp_loss: [11.81576909 13.07791032 10.70582642], val_grp_loss: [12.69039613 12.45603579 12.14535075], train_hist_grp_loss: [ 6.38706254  7.04348017 14.51304417], cur_train_grp_loss: [0.09452551 0.10462192 0.2141258 ], max_reward_err:  0.0139, max_reward_err_index: 1, max_kl_dist:  0.6652, max_kl_dist_index: 0, max_train_grp_loss:  13.0779, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6904, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2141, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:00:43,539 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  67, train_loss:  12.1567, val_loss:  12.4310, grad_norm: 0.0066, live_grad: 0.0000, reward_err: 0.0105, 0.0139, 0.0002, KL_dist: 0.6653, 0.3098, 0.6579, param: [5.45572355 8.26004187 5.21801917 8.69617885], weights: [0.29259093 0.30049649 0.40691258], train_wt_loss:  36.4701, val_wt_loss: 37.2930, train_grp_loss: [11.81584666 13.07808627 10.70536109], val_grp_loss: [12.69068633 12.45624687 12.14530952], train_hist_grp_loss: [ 6.4815887   7.14810345 14.7271607 ], cur_train_grp_loss: [0.09452615 0.10462328 0.21411653], max_reward_err:  0.0139, max_reward_err_index: 1, max_kl_dist:  0.6653, max_kl_dist_index: 0, max_train_grp_loss:  13.0781, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6907, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2141, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:00:44,601 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  68, train_loss:  12.1567, val_loss:  12.4312, grad_norm: 0.0068, live_grad: 0.0000, reward_err: 0.0105, 0.0139, 0.0002, KL_dist: 0.6655, 0.3099, 0.6581, param: [5.4558846  8.2594894  5.2191837  8.69829385], weights: [0.29198581 0.29999618 0.40801801], train_wt_loss:  36.4702, val_wt_loss: 37.2935, train_grp_loss: [11.81592108 13.07826739 10.704894  ], val_grp_loss: [12.69097393 12.45646383 12.14526717], train_hist_grp_loss: [ 6.57611547  7.25272814 14.94126792], cur_train_grp_loss: [0.09452677 0.10462469 0.21410722], max_reward_err:  0.0139, max_reward_err_index: 1, max_kl_dist:  0.6655, max_kl_dist_index: 0, max_train_grp_loss:  13.0783, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6910, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2141, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:00:45,627 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  69, train_loss:  12.1568, val_loss:  12.4313, grad_norm: 0.0069, live_grad: 0.0000, reward_err: 0.0105, 0.0139, 0.0002, KL_dist: 0.6656, 0.3100, 0.6582, param: [5.45604441 8.25893871 5.22035038 8.70041864], weights: [0.29138051 0.29949522 0.40912426], train_wt_loss:  36.4703, val_wt_loss: 37.2939, train_grp_loss: [11.81599234 13.07845368 10.70442513], val_grp_loss: [12.69125894 12.45668668 12.14522372], train_hist_grp_loss: [ 6.67064284  7.35735428 15.1553658 ], cur_train_grp_loss: [0.09452737 0.10462614 0.21409788], max_reward_err:  0.0139, max_reward_err_index: 1, max_kl_dist:  0.6656, max_kl_dist_index: 0, max_train_grp_loss:  13.0785, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6913, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2141, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:00:46,676 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  70, train_loss:  12.1568, val_loss:  12.4315, grad_norm: 0.0070, live_grad: 0.0000, reward_err: 0.0105, 0.0139, 0.0002, KL_dist: 0.6658, 0.3101, 0.6583, param: [5.45620296 8.2583898  5.22151923 8.70255324], weights: [0.29077503 0.29899364 0.41023133], train_wt_loss:  36.4704, val_wt_loss: 37.2944, train_grp_loss: [11.81606045 13.07864515 10.7039545 ], val_grp_loss: [12.69154137 12.45691544 12.14517917], train_hist_grp_loss: [ 6.76517078  7.46198191 15.3694543 ], cur_train_grp_loss: [0.09452794 0.10462763 0.2140885 ], max_reward_err:  0.0139, max_reward_err_index: 1, max_kl_dist:  0.6658, max_kl_dist_index: 0, max_train_grp_loss:  13.0786, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6915, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2141, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:00:47,725 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  71, train_loss:  12.1568, val_loss:  12.4316, grad_norm: 0.0072, live_grad: 0.0000, reward_err: 0.0105, 0.0139, 0.0002, KL_dist: 0.6659, 0.3101, 0.6585, param: [5.45636027 8.25784266 5.22269025 8.70469765], weights: [0.29016937 0.29849144 0.41133919], train_wt_loss:  36.4705, val_wt_loss: 37.2949, train_grp_loss: [11.81612542 13.0788418  10.70348211], val_grp_loss: [12.69182122 12.4571501  12.14513353], train_hist_grp_loss: [ 6.85969926  7.56661107 15.58353339], cur_train_grp_loss: [0.09452848 0.10462916 0.21407909], max_reward_err:  0.0139, max_reward_err_index: 1, max_kl_dist:  0.6659, max_kl_dist_index: 0, max_train_grp_loss:  13.0788, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6918, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2141, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:00:48,760 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  72, train_loss:  12.1568, val_loss:  12.4318, grad_norm: 0.0073, live_grad: 0.0000, reward_err: 0.0105, 0.0139, 0.0002, KL_dist: 0.6661, 0.3102, 0.6586, param: [5.45651632 8.25729728 5.22386344 8.70685189], weights: [0.28956354 0.29798862 0.41244784], train_wt_loss:  36.4705, val_wt_loss: 37.2954, train_grp_loss: [11.81618725 13.07904365 10.70300796], val_grp_loss: [12.69209849 12.45739066 12.14508678], train_hist_grp_loss: [ 6.95422826  7.67124181 15.79760304], cur_train_grp_loss: [0.094529   0.10463073 0.21406964], max_reward_err:  0.0139, max_reward_err_index: 1, max_kl_dist:  0.6661, max_kl_dist_index: 0, max_train_grp_loss:  13.0790, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6921, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2141, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:00:49,785 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  73, train_loss:  12.1569, val_loss:  12.4319, grad_norm: 0.0074, live_grad: 0.0000, reward_err: 0.0105, 0.0139, 0.0002, KL_dist: 0.6662, 0.3103, 0.6588, param: [5.4566711  8.25675365 5.2250388  8.70901598], weights: [0.28895755 0.29748519 0.41355727], train_wt_loss:  36.4706, val_wt_loss: 37.2958, train_grp_loss: [11.81624594 13.07925069 10.70253204], val_grp_loss: [12.69237319 12.45763715 12.14503895], train_hist_grp_loss: [ 7.04875776  7.77587416 16.01166319], cur_train_grp_loss: [0.0945295  0.10463235 0.21406016], max_reward_err:  0.0139, max_reward_err_index: 1, max_kl_dist:  0.6662, max_kl_dist_index: 0, max_train_grp_loss:  13.0793, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6924, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2141, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:00:50,842 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  74, train_loss:  12.1569, val_loss:  12.4321, grad_norm: 0.0075, live_grad: 0.0000, reward_err: 0.0105, 0.0139, 0.0002, KL_dist: 0.6664, 0.3104, 0.6589, param: [5.45682463 8.25621177 5.22621635 8.71118991], weights: [0.28835139 0.29698115 0.41466746], train_wt_loss:  36.4707, val_wt_loss: 37.2963, train_grp_loss: [11.81630151 13.07946293 10.70205437], val_grp_loss: [12.69264531 12.45788956 12.14499004], train_hist_grp_loss: [ 7.14328773  7.88050816 16.22571384], cur_train_grp_loss: [0.09452997 0.10463401 0.21405064], max_reward_err:  0.0139, max_reward_err_index: 1, max_kl_dist:  0.6664, max_kl_dist_index: 0, max_train_grp_loss:  13.0795, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6926, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2141, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:00:51,900 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  75, train_loss:  12.1569, val_loss:  12.4323, grad_norm: 0.0077, live_grad: 0.0000, reward_err: 0.0105, 0.0139, 0.0002, KL_dist: 0.6665, 0.3105, 0.6591, param: [5.45697689 8.25567162 5.22739608 8.7133737 ], weights: [0.28774508 0.29647651 0.4157784 ], train_wt_loss:  36.4708, val_wt_loss: 37.2968, train_grp_loss: [11.81635395 13.07968038 10.70157493], val_grp_loss: [12.69291487 12.45814789 12.14494005], train_hist_grp_loss: [ 7.23781814  7.98514386 16.43975492], cur_train_grp_loss: [0.09453041 0.1046357  0.21404109], max_reward_err:  0.0139, max_reward_err_index: 1, max_kl_dist:  0.6665, max_kl_dist_index: 0, max_train_grp_loss:  13.0797, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6929, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2140, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:00:52,937 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  76, train_loss:  12.1570, val_loss:  12.4324, grad_norm: 0.0078, live_grad: 0.0000, reward_err: 0.0105, 0.0139, 0.0002, KL_dist: 0.6667, 0.3105, 0.6592, param: [5.45712788 8.2551332  5.228578   8.71556737], weights: [0.28713863 0.29597128 0.41689009], train_wt_loss:  36.4709, val_wt_loss: 37.2973, train_grp_loss: [11.81640327 13.07990303 10.70109375], val_grp_loss: [12.69318187 12.45841216 12.14488897], train_hist_grp_loss: [ 7.33234897  8.08978131 16.65378642], cur_train_grp_loss: [0.09453083 0.10463744 0.2140315 ], max_reward_err:  0.0139, max_reward_err_index: 1, max_kl_dist:  0.6667, max_kl_dist_index: 0, max_train_grp_loss:  13.0799, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6932, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2140, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:00:54,003 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  77, train_loss:  12.1570, val_loss:  12.4326, grad_norm: 0.0079, live_grad: 0.0000, reward_err: 0.0105, 0.0139, 0.0002, KL_dist: 0.6668, 0.3106, 0.6594, param: [5.45727759 8.2545965  5.22976212 8.71777093], weights: [0.28653203 0.29546546 0.41800251], train_wt_loss:  36.4710, val_wt_loss: 37.2977, train_grp_loss: [11.81644949 13.08013091 10.70061081], val_grp_loss: [12.69344632 12.45868237 12.14483683], train_hist_grp_loss: [ 7.4268802   8.19442053 16.8678083 ], cur_train_grp_loss: [0.09453123 0.10463922 0.21402187], max_reward_err:  0.0139, max_reward_err_index: 1, max_kl_dist:  0.6668, max_kl_dist_index: 0, max_train_grp_loss:  13.0801, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6934, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2140, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:00:55,048 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  78, train_loss:  12.1570, val_loss:  12.4327, grad_norm: 0.0081, live_grad: 0.0000, reward_err: 0.0105, 0.0139, 0.0002, KL_dist: 0.6670, 0.3107, 0.6595, param: [5.45742603 8.25406151 5.23094844 8.71998438], weights: [0.28592529 0.29495905 0.41911565], train_wt_loss:  36.4711, val_wt_loss: 37.2982, train_grp_loss: [11.81649259 13.080364   10.70012611], val_grp_loss: [12.69370821 12.45895853 12.14478362], train_hist_grp_loss: [ 7.52141179  8.29906158 17.08182051], cur_train_grp_loss: [0.0945316  0.10464105 0.21401222], max_reward_err:  0.0139, max_reward_err_index: 1, max_kl_dist:  0.6670, max_kl_dist_index: 0, max_train_grp_loss:  13.0804, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6937, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2140, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:00:56,086 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  79, train_loss:  12.1571, val_loss:  12.4329, grad_norm: 0.0082, live_grad: 0.0000, reward_err: 0.0105, 0.0139, 0.0002, KL_dist: 0.6671, 0.3108, 0.6597, param: [5.45757318 8.25352823 5.23213696 8.72220774], weights: [0.28531842 0.29445207 0.4202295 ], train_wt_loss:  36.4712, val_wt_loss: 37.2987, train_grp_loss: [11.81653259 13.08060232 10.69963967], val_grp_loss: [12.69396755 12.45924064 12.14472935], train_hist_grp_loss: [ 7.61594374  8.40370449 17.29582303], cur_train_grp_loss: [0.09453194 0.10464291 0.21400252], max_reward_err:  0.0139, max_reward_err_index: 1, max_kl_dist:  0.6671, max_kl_dist_index: 0, max_train_grp_loss:  13.0806, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6940, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2140, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:00:57,128 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  80, train_loss:  12.1571, val_loss:  12.4331, grad_norm: 0.0083, live_grad: 0.0000, reward_err: 0.0105, 0.0139, 0.0002, KL_dist: 0.6673, 0.3109, 0.6598, param: [5.45771906 8.25299663 5.23332768 8.72444101], weights: [0.28471143 0.29394452 0.42134405], train_wt_loss:  36.4713, val_wt_loss: 37.2992, train_grp_loss: [11.81656949 13.08084587 10.69915148], val_grp_loss: [12.69422434 12.45952871 12.14467402], train_hist_grp_loss: [ 7.710476    8.50834931 17.50981583], cur_train_grp_loss: [0.09453226 0.10464482 0.21399279], max_reward_err:  0.0139, max_reward_err_index: 1, max_kl_dist:  0.6673, max_kl_dist_index: 0, max_train_grp_loss:  13.0808, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6942, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2140, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:00:58,162 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  81, train_loss:  12.1572, val_loss:  12.4332, grad_norm: 0.0085, live_grad: 0.0000, reward_err: 0.0105, 0.0139, 0.0002, KL_dist: 0.6674, 0.3110, 0.6600, param: [5.45786364 8.25246672 5.23452062 8.72668422], weights: [0.28410431 0.29343641 0.42245928], train_wt_loss:  36.4715, val_wt_loss: 37.2997, train_grp_loss: [11.8166033  13.08109465 10.69866154], val_grp_loss: [12.6944786  12.45982274 12.14461764], train_hist_grp_loss: [ 7.80500855  8.61299608 17.72379886], cur_train_grp_loss: [0.09453256 0.10464677 0.21398303], max_reward_err:  0.0139, max_reward_err_index: 1, max_kl_dist:  0.6674, max_kl_dist_index: 0, max_train_grp_loss:  13.0811, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6945, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2140, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:00:59,194 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  82, train_loss:  12.1572, val_loss:  12.4334, grad_norm: 0.0086, live_grad: 0.0000, reward_err: 0.0105, 0.0139, 0.0002, KL_dist: 0.6676, 0.3110, 0.6601, param: [5.45800693 8.25193848 5.23571578 8.72893736], weights: [0.28349708 0.29292774 0.42357519], train_wt_loss:  36.4716, val_wt_loss: 37.3002, train_grp_loss: [11.81663403 13.08134868 10.69816987], val_grp_loss: [12.69473032 12.46012274 12.14456021], train_hist_grp_loss: [ 7.89954138  8.71764483 17.93777209], cur_train_grp_loss: [0.09453283 0.10464876 0.21397323], max_reward_err:  0.0139, max_reward_err_index: 1, max_kl_dist:  0.6676, max_kl_dist_index: 0, max_train_grp_loss:  13.0813, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6947, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2140, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:01:00,228 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  83, train_loss:  12.1572, val_loss:  12.4336, grad_norm: 0.0087, live_grad: 0.0000, reward_err: 0.0105, 0.0139, 0.0002, KL_dist: 0.6678, 0.3111, 0.6603, param: [5.45814893 8.25141191 5.23691315 8.73120045], weights: [0.28288973 0.29241851 0.42469176], train_wt_loss:  36.4717, val_wt_loss: 37.3007, train_grp_loss: [11.81666168 13.08160795 10.69767644], val_grp_loss: [12.69497951 12.46042872 12.14450174], train_hist_grp_loss: [ 7.99407445  8.82229562 18.15173549], cur_train_grp_loss: [0.09453307 0.10465079 0.2139634 ], max_reward_err:  0.0139, max_reward_err_index: 1, max_kl_dist:  0.6678, max_kl_dist_index: 0, max_train_grp_loss:  13.0816, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6950, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2140, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:01:01,278 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  84, train_loss:  12.1573, val_loss:  12.4337, grad_norm: 0.0089, live_grad: 0.0000, reward_err: 0.0105, 0.0139, 0.0002, KL_dist: 0.6679, 0.3112, 0.6604, param: [5.45828963 8.250887   5.23811275 8.73347351], weights: [0.28228229 0.29190874 0.42580898], train_wt_loss:  36.4718, val_wt_loss: 37.3012, train_grp_loss: [11.81668625 13.08187247 10.69718128], val_grp_loss: [12.69522617 12.46074068 12.14444222], train_hist_grp_loss: [ 8.08860774  8.92694849 18.36568901], cur_train_grp_loss: [0.09453329 0.10465286 0.21395353], max_reward_err:  0.0139, max_reward_err_index: 1, max_kl_dist:  0.6679, max_kl_dist_index: 0, max_train_grp_loss:  13.0819, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6952, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2140, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:01:02,296 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  85, train_loss:  12.1573, val_loss:  12.4339, grad_norm: 0.0090, live_grad: 0.0000, reward_err: 0.0105, 0.0139, 0.0002, KL_dist: 0.6681, 0.3113, 0.6606, param: [5.45842902 8.25036374 5.23931457 8.73575653], weights: [0.28167474 0.29139842 0.42692684], train_wt_loss:  36.4719, val_wt_loss: 37.3017, train_grp_loss: [11.81670775 13.08214224 10.69668439], val_grp_loss: [12.69547031 12.46105863 12.14438167], train_hist_grp_loss: [ 8.18314123  9.03160347 18.57963264], cur_train_grp_loss: [0.09453349 0.10465498 0.21394363], max_reward_err:  0.0139, max_reward_err_index: 1, max_kl_dist:  0.6681, max_kl_dist_index: 0, max_train_grp_loss:  13.0821, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6955, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2139, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:01:03,340 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  86, train_loss:  12.1573, val_loss:  12.4341, grad_norm: 0.0092, live_grad: 0.0000, reward_err: 0.0105, 0.0139, 0.0002, KL_dist: 0.6682, 0.3114, 0.6607, param: [5.45856711 8.24984211 5.24051863 8.73804954], weights: [0.2810671  0.29088758 0.42804532], train_wt_loss:  36.4720, val_wt_loss: 37.3022, train_grp_loss: [11.81672619 13.08241728 10.69618576], val_grp_loss: [12.69571193 12.46138257 12.14432009], train_hist_grp_loss: [ 8.2776749   9.1362606  18.79356633], cur_train_grp_loss: [0.09453366 0.10465714 0.21393369], max_reward_err:  0.0139, max_reward_err_index: 1, max_kl_dist:  0.6682, max_kl_dist_index: 0, max_train_grp_loss:  13.0824, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6957, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2139, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:01:04,420 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  87, train_loss:  12.1574, val_loss:  12.4342, grad_norm: 0.0093, live_grad: 0.0000, reward_err: 0.0105, 0.0139, 0.0002, KL_dist: 0.6684, 0.3115, 0.6609, param: [5.45870389 8.24932212 5.24172493 8.74035253], weights: [0.28045937 0.2903762  0.42916443], train_wt_loss:  36.4721, val_wt_loss: 37.3027, train_grp_loss: [11.81674158 13.08269758 10.69568539], val_grp_loss: [12.69595104 12.46171251 12.14425749], train_hist_grp_loss: [ 8.37220871  9.24091994 19.00749004], cur_train_grp_loss: [0.09453381 0.10465934 0.21392372], max_reward_err:  0.0139, max_reward_err_index: 1, max_kl_dist:  0.6684, max_kl_dist_index: 0, max_train_grp_loss:  13.0827, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6960, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2139, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:01:05,471 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  88, train_loss:  12.1574, val_loss:  12.4344, grad_norm: 0.0094, live_grad: 0.0000, reward_err: 0.0105, 0.0139, 0.0002, KL_dist: 0.6685, 0.3116, 0.6610, param: [5.45883936 8.24880374 5.24293346 8.74266553], weights: [0.27985156 0.2898643  0.43028414], train_wt_loss:  36.4723, val_wt_loss: 37.3032, train_grp_loss: [11.81675391 13.08298315 10.6951833 ], val_grp_loss: [12.69618764 12.46204846 12.14419387], train_hist_grp_loss: [ 8.46674264  9.34558152 19.22140375], cur_train_grp_loss: [0.09453393 0.10466158 0.21391371], max_reward_err:  0.0139, max_reward_err_index: 1, max_kl_dist:  0.6685, max_kl_dist_index: 0, max_train_grp_loss:  13.0830, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6962, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2139, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:01:06,500 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  89, train_loss:  12.1575, val_loss:  12.4346, grad_norm: 0.0096, live_grad: 0.0000, reward_err: 0.0105, 0.0139, 0.0002, KL_dist: 0.6687, 0.3116, 0.6612, param: [5.45897351 8.24828698 5.24414424 8.74498853], weights: [0.27924368 0.28935188 0.43140444], train_wt_loss:  36.4724, val_wt_loss: 37.3037, train_grp_loss: [11.8167632  13.08327399 10.69467948], val_grp_loss: [12.69642173 12.46239041 12.14412923], train_hist_grp_loss: [ 8.56127667  9.45024539 19.43530742], cur_train_grp_loss: [0.09453403 0.10466387 0.21390367], max_reward_err:  0.0139, max_reward_err_index: 1, max_kl_dist:  0.6687, max_kl_dist_index: 0, max_train_grp_loss:  13.0833, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6964, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2139, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:01:07,540 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  90, train_loss:  12.1575, val_loss:  12.4347, grad_norm: 0.0097, live_grad: 0.0000, reward_err: 0.0105, 0.0143, 0.0002, KL_dist: 0.6689, 0.3117, 0.6613, param: [5.45910633 8.24777182 5.24535726 8.74732156], weights: [0.27863572 0.28883896 0.43252532], train_wt_loss:  36.4725, val_wt_loss: 37.3042, train_grp_loss: [11.81676945 13.08357011 10.69417393], val_grp_loss: [12.69665333 12.46273838 12.14406358], train_hist_grp_loss: [ 8.65581077  9.55491158 19.64920101], cur_train_grp_loss: [0.09453411 0.10466619 0.21389359], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6689, max_kl_dist_index: 0, max_train_grp_loss:  13.0836, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6967, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2139, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:01:08,612 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  91, train_loss:  12.1575, val_loss:  12.4349, grad_norm: 0.0099, live_grad: 0.0000, reward_err: 0.0105, 0.0143, 0.0002, KL_dist: 0.6690, 0.3118, 0.6615, param: [5.45923784 8.24725826 5.24657253 8.74966462], weights: [0.2780277  0.28832553 0.43364678], train_wt_loss:  36.4726, val_wt_loss: 37.3048, train_grp_loss: [11.81677268 13.08387152 10.69366666], val_grp_loss: [12.69688243 12.46309237 12.14399693], train_hist_grp_loss: [ 8.75034493  9.65958014 19.86308449], cur_train_grp_loss: [0.09453416 0.10466856 0.21388348], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6690, max_kl_dist_index: 0, max_train_grp_loss:  13.0839, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6969, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2139, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:01:09,663 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  92, train_loss:  12.1576, val_loss:  12.4351, grad_norm: 0.0100, live_grad: 0.0000, reward_err: 0.0105, 0.0143, 0.0002, KL_dist: 0.6692, 0.3119, 0.6617, param: [5.45936801 8.24674628 5.24779006 8.75201771], weights: [0.27741961 0.2878116  0.43476879], train_wt_loss:  36.4728, val_wt_loss: 37.3053, train_grp_loss: [11.81677287 13.08417821 10.69315767], val_grp_loss: [12.69710904 12.46345239 12.14392928], train_hist_grp_loss: [ 8.84487911  9.76425111 20.07695782], cur_train_grp_loss: [0.09453418 0.10467097 0.21387333], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6692, max_kl_dist_index: 0, max_train_grp_loss:  13.0842, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6971, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2139, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:01:10,693 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  93, train_loss:  12.1576, val_loss:  12.4353, grad_norm: 0.0102, live_grad: 0.0000, reward_err: 0.0105, 0.0143, 0.0002, KL_dist: 0.6693, 0.3120, 0.6618, param: [5.45949685 8.24623587 5.24900985 8.75438086], weights: [0.27681148 0.28729718 0.43589134], train_wt_loss:  36.4729, val_wt_loss: 37.3058, train_grp_loss: [11.81677005 13.08449019 10.69264697], val_grp_loss: [12.69733317 12.46381844 12.14386063], train_hist_grp_loss: [ 8.93941329  9.86892454 20.29082097], cur_train_grp_loss: [0.09453418 0.10467343 0.21386315], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6693, max_kl_dist_index: 0, max_train_grp_loss:  13.0845, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6973, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2139, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:01:11,792 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  94, train_loss:  12.1577, val_loss:  12.4354, grad_norm: 0.0103, live_grad: 0.0000, reward_err: 0.0105, 0.0143, 0.0002, KL_dist: 0.6695, 0.3121, 0.6620, param: [5.45962436 8.24572703 5.2502319  8.75675406], weights: [0.27620329 0.28678227 0.43701444], train_wt_loss:  36.4730, val_wt_loss: 37.3063, train_grp_loss: [11.81676421 13.08480748 10.69213455], val_grp_loss: [12.69755482 12.46419053 12.143791  ], train_hist_grp_loss: [ 9.03394746  9.97360046 20.50467391], cur_train_grp_loss: [0.09453416 0.10467592 0.21385294], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6695, max_kl_dist_index: 0, max_train_grp_loss:  13.0848, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6976, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2139, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:01:12,847 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  95, train_loss:  12.1577, val_loss:  12.4356, grad_norm: 0.0105, live_grad: 0.0000, reward_err: 0.0105, 0.0143, 0.0002, KL_dist: 0.6697, 0.3122, 0.6621, param: [5.45975053 8.24521974 5.25145622 8.75913734], weights: [0.27559507 0.28626688 0.43813805], train_wt_loss:  36.4732, val_wt_loss: 37.3069, train_grp_loss: [11.81675537 13.08513006 10.69162041], val_grp_loss: [12.69777399 12.46456867 12.14372037], train_hist_grp_loss: [ 9.12848157 10.07827892 20.7185166 ], cur_train_grp_loss: [0.09453411 0.10467846 0.21384269], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6697, max_kl_dist_index: 0, max_train_grp_loss:  13.0851, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6978, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2138, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:01:13,894 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  96, train_loss:  12.1578, val_loss:  12.4358, grad_norm: 0.0106, live_grad: 0.0000, reward_err: 0.0105, 0.0143, 0.0002, KL_dist: 0.6698, 0.3123, 0.6623, param: [5.45987535 8.244714   5.25268281 8.76153069], weights: [0.2749868  0.28575102 0.43926217], train_wt_loss:  36.4733, val_wt_loss: 37.3074, train_grp_loss: [11.81674353 13.08545795 10.69110457], val_grp_loss: [12.6979907  12.46495285 12.14364878], train_hist_grp_loss: [ 9.22301561 10.18295996 20.93234901], cur_train_grp_loss: [0.09453404 0.10468104 0.21383241], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6698, max_kl_dist_index: 0, max_train_grp_loss:  13.0855, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6980, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2138, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:01:14,924 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  97, train_loss:  12.1578, val_loss:  12.4360, grad_norm: 0.0108, live_grad: 0.0000, reward_err: 0.0105, 0.0143, 0.0002, KL_dist: 0.6700, 0.3124, 0.6625, param: [5.45999883 8.2442098  5.25391166 8.76393412], weights: [0.27437851 0.28523469 0.4403868 ], train_wt_loss:  36.4734, val_wt_loss: 37.3079, train_grp_loss: [11.81672869 13.08579115 10.69058703], val_grp_loss: [12.69820494 12.46534309 12.1435762 ], train_hist_grp_loss: [ 9.31754956 10.28764362 21.1461711 ], cur_train_grp_loss: [0.09453395 0.10468366 0.21382209], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6700, max_kl_dist_index: 0, max_train_grp_loss:  13.0858, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6982, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2138, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:01:15,966 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  98, train_loss:  12.1579, val_loss:  12.4361, grad_norm: 0.0109, live_grad: 0.0000, reward_err: 0.0105, 0.0143, 0.0002, KL_dist: 0.6702, 0.3124, 0.6626, param: [5.46012095 8.24370712 5.2551428  8.76634765], weights: [0.27377019 0.2847179  0.44151191], train_wt_loss:  36.4736, val_wt_loss: 37.3084, train_grp_loss: [11.81671088 13.08612967 10.69006778], val_grp_loss: [12.69841672 12.46573938 12.14350266], train_hist_grp_loss: [ 9.41208339 10.39232995 21.35998284], cur_train_grp_loss: [0.09453383 0.10468633 0.21381174], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6702, max_kl_dist_index: 0, max_train_grp_loss:  13.0861, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6984, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2138, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:01:16,979 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  99, train_loss:  12.1579, val_loss:  12.4363, grad_norm: 0.0111, live_grad: 0.0000, reward_err: 0.0105, 0.0143, 0.0002, KL_dist: 0.6703, 0.3125, 0.6628, param: [5.46024172 8.24320596 5.25637621 8.76877129], weights: [0.27316184 0.28420066 0.4426375 ], train_wt_loss:  36.4737, val_wt_loss: 37.3090, train_grp_loss: [11.81669008 13.0864735  10.68954683], val_grp_loss: [12.69862604 12.46614174 12.14342816], train_hist_grp_loss: [ 9.50661708 10.49701899 21.5737842 ], cur_train_grp_loss: [0.09453369 0.10468904 0.21380136], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6703, max_kl_dist_index: 0, max_train_grp_loss:  13.0865, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6986, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2138, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:01:17,998 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  100, train_loss:  12.1580, val_loss:  12.4365, grad_norm: 0.0112, live_grad: 0.0000, reward_err: 0.0105, 0.0143, 0.0002, KL_dist: 0.6705, 0.3126, 0.6630, param: [5.46036114 8.24270631 5.25761191 8.77120503], weights: [0.27255349 0.28368296 0.44376355], train_wt_loss:  36.4739, val_wt_loss: 37.3095, train_grp_loss: [11.81666631 13.08682266 10.68902418], val_grp_loss: [12.69883292 12.46655018 12.14335269], train_hist_grp_loss: [ 9.6011506  10.60171078 21.78757513], cur_train_grp_loss: [0.09453352 0.10469179 0.21379094], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6705, max_kl_dist_index: 0, max_train_grp_loss:  13.0868, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6988, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2138, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:01:19,055 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  101, train_loss:  12.1580, val_loss:  12.4367, grad_norm: 0.0114, live_grad: 0.0000, reward_err: 0.0102, 0.0143, 0.0001, KL_dist: 0.6707, 0.3127, 0.6631, param: [5.46047919 8.24220815 5.25884989 8.7736489 ], weights: [0.27194513 0.28316483 0.44489005], train_wt_loss:  36.4740, val_wt_loss: 37.3101, train_grp_loss: [11.81663957 13.08717715 10.68849984], val_grp_loss: [12.69903735 12.46696468 12.14327628], train_hist_grp_loss: [ 9.69568393 10.70640536 22.00135562], cur_train_grp_loss: [0.09453333 0.10469458 0.21378048], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6707, max_kl_dist_index: 0, max_train_grp_loss:  13.0872, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6990, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2138, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:01:20,102 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  102, train_loss:  12.1581, val_loss:  12.4369, grad_norm: 0.0115, live_grad: 0.0000, reward_err: 0.0102, 0.0143, 0.0001, KL_dist: 0.6708, 0.3128, 0.6633, param: [5.46059587 8.24171148 5.26009017 8.7761029 ], weights: [0.27133676 0.28264625 0.44601699], train_wt_loss:  36.4742, val_wt_loss: 37.3106, train_grp_loss: [11.81660988 13.08753697 10.6879738 ], val_grp_loss: [12.69923934 12.46738527 12.14319892], train_hist_grp_loss: [ 9.79021704 10.81110278 22.21512561], cur_train_grp_loss: [0.09453312 0.10469742 0.21377   ], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6708, max_kl_dist_index: 0, max_train_grp_loss:  13.0875, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6992, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2138, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:01:21,180 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  103, train_loss:  12.1581, val_loss:  12.4371, grad_norm: 0.0117, live_grad: 0.0000, reward_err: 0.0102, 0.0143, 0.0001, KL_dist: 0.6710, 0.3129, 0.6635, param: [5.46071119 8.24121628 5.26133273 8.77856703], weights: [0.27072839 0.28212725 0.44714436], train_wt_loss:  36.4743, val_wt_loss: 37.3112, train_grp_loss: [11.81657724 13.08790213 10.68744608], val_grp_loss: [12.69943891 12.46781194 12.14312062], train_hist_grp_loss: [ 9.88474992 10.91580307 22.42888509], cur_train_grp_loss: [0.09453288 0.1047003  0.21375948], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6710, max_kl_dist_index: 0, max_train_grp_loss:  13.0879, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6994, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2138, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:01:22,231 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  104, train_loss:  12.1582, val_loss:  12.4372, grad_norm: 0.0118, live_grad: 0.0000, reward_err: 0.0102, 0.0143, 0.0001, KL_dist: 0.6712, 0.3130, 0.6636, param: [5.46082513 8.24072256 5.26257759 8.78104131], weights: [0.27012004 0.28160782 0.44827214], train_wt_loss:  36.4745, val_wt_loss: 37.3117, train_grp_loss: [11.81654165 13.08827262 10.68691668], val_grp_loss: [12.69963604 12.46824471 12.14304138], train_hist_grp_loss: [ 9.97928254 11.02050629 22.64263401], cur_train_grp_loss: [0.09453262 0.10470322 0.21374892], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6712, max_kl_dist_index: 0, max_train_grp_loss:  13.0883, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6996, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2137, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:01:23,276 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  105, train_loss:  12.1582, val_loss:  12.4374, grad_norm: 0.0120, live_grad: 0.0000, reward_err: 0.0102, 0.0143, 0.0001, KL_dist: 0.6713, 0.3131, 0.6638, param: [5.4609377  8.24023029 5.26382475 8.78352575], weights: [0.2695117  0.28108797 0.44940033], train_wt_loss:  36.4746, val_wt_loss: 37.3123, train_grp_loss: [11.81650313 13.08864847 10.68638559], val_grp_loss: [12.69983075 12.46868357 12.14296122], train_hist_grp_loss: [10.07381487 11.12521247 22.85637235], cur_train_grp_loss: [0.09453233 0.10470618 0.21373833], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6713, max_kl_dist_index: 0, max_train_grp_loss:  13.0886, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6998, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2137, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:01:24,299 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  106, train_loss:  12.1583, val_loss:  12.4376, grad_norm: 0.0122, live_grad: 0.0000, reward_err: 0.0102, 0.0143, 0.0001, KL_dist: 0.6715, 0.3132, 0.6640, param: [5.46104888 8.23973946 5.26507422 8.78602035], weights: [0.26890338 0.28056772 0.45052891], train_wt_loss:  36.4748, val_wt_loss: 37.3128, train_grp_loss: [11.81646168 13.08902966 10.68585283], val_grp_loss: [12.70002304 12.46912853 12.14288013], train_hist_grp_loss: [10.1683469  11.22992166 23.07010006], cur_train_grp_loss: [0.09453203 0.10470919 0.21372771], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6715, max_kl_dist_index: 0, max_train_grp_loss:  13.0890, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7000, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2137, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:01:25,365 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  107, train_loss:  12.1583, val_loss:  12.4378, grad_norm: 0.0123, live_grad: 0.0000, reward_err: 0.0102, 0.0143, 0.0001, KL_dist: 0.6717, 0.3133, 0.6641, param: [5.46115868 8.23925008 5.26632598 8.78852511], weights: [0.26829508 0.28004705 0.45165787], train_wt_loss:  36.4750, val_wt_loss: 37.3134, train_grp_loss: [11.8164173  13.0894162  10.68531839], val_grp_loss: [12.70021293 12.4695796  12.14279812], train_hist_grp_loss: [10.26287859 11.3346339  23.28381711], cur_train_grp_loss: [0.09453169 0.10471224 0.21371706], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6717, max_kl_dist_index: 0, max_train_grp_loss:  13.0894, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7002, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2137, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:01:26,391 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  108, train_loss:  12.1584, val_loss:  12.4380, grad_norm: 0.0125, live_grad: 0.0000, reward_err: 0.0102, 0.0143, 0.0001, KL_dist: 0.6719, 0.3134, 0.6643, param: [5.46126709 8.23876212 5.26758006 8.79104006], weights: [0.26768682 0.27952599 0.45278719], train_wt_loss:  36.4751, val_wt_loss: 37.3139, train_grp_loss: [11.81637002 13.08980811 10.68478228], val_grp_loss: [12.70040041 12.47003678 12.1427152 ], train_hist_grp_loss: [10.35740993 11.43934923 23.49752348], cur_train_grp_loss: [0.09453134 0.10471533 0.21370637], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6719, max_kl_dist_index: 0, max_train_grp_loss:  13.0898, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7004, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2137, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:01:27,440 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  109, train_loss:  12.1584, val_loss:  12.4382, grad_norm: 0.0126, live_grad: 0.0000, reward_err: 0.0102, 0.0143, 0.0001, KL_dist: 0.6720, 0.3135, 0.6645, param: [5.46137411 8.23827557 5.26883645 8.79356519], weights: [0.26707859 0.27900453 0.45391688], train_wt_loss:  36.4753, val_wt_loss: 37.3145, train_grp_loss: [11.81631983 13.09020537 10.6842445 ], val_grp_loss: [12.70058549 12.47050008 12.14263138], train_hist_grp_loss: [10.45194089 11.54406769 23.71121913], cur_train_grp_loss: [0.09453096 0.10471846 0.21369565], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6720, max_kl_dist_index: 0, max_train_grp_loss:  13.0902, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7006, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2137, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:01:28,470 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  110, train_loss:  12.1585, val_loss:  12.4384, grad_norm: 0.0128, live_grad: 0.0000, reward_err: 0.0102, 0.0143, 0.0001, KL_dist: 0.6722, 0.3136, 0.6647, param: [5.46147973 8.23779043 5.27009515 8.79610051], weights: [0.26647041 0.27848269 0.4550469 ], train_wt_loss:  36.4754, val_wt_loss: 37.3151, train_grp_loss: [11.81626673 13.090608   10.68370506], val_grp_loss: [12.70076817 12.4709695  12.14254665], train_hist_grp_loss: [10.54647145 11.64878933 23.92490402], cur_train_grp_loss: [0.09453056 0.10472164 0.21368489], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6722, max_kl_dist_index: 0, max_train_grp_loss:  13.0906, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7008, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2137, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:01:29,532 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  111, train_loss:  12.1585, val_loss:  12.4385, grad_norm: 0.0130, live_grad: 0.0000, reward_err: 0.0102, 0.0143, 0.0001, KL_dist: 0.6724, 0.3137, 0.6648, param: [5.46158396 8.23730668 5.27135616 8.79864604], weights: [0.26586227 0.27796047 0.45617726], train_wt_loss:  36.4756, val_wt_loss: 37.3156, train_grp_loss: [11.81621075 13.091016   10.68316396], val_grp_loss: [12.70094847 12.47144504 12.14246103], train_hist_grp_loss: [10.64100158 11.7535142  24.13857812], cur_train_grp_loss: [0.09453013 0.10472486 0.2136741 ], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6724, max_kl_dist_index: 0, max_train_grp_loss:  13.0910, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7009, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2137, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:01:30,575 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  112, train_loss:  12.1586, val_loss:  12.4387, grad_norm: 0.0131, live_grad: 0.0000, reward_err: 0.0102, 0.0143, 0.0001, KL_dist: 0.6725, 0.3137, 0.6650, param: [5.46168677 8.23682432 5.2726195  8.80120177], weights: [0.26525419 0.27743787 0.45730794], train_wt_loss:  36.4758, val_wt_loss: 37.3162, train_grp_loss: [11.81615189 13.09142937 10.6826212 ], val_grp_loss: [12.70112638 12.47192672 12.14237452], train_hist_grp_loss: [10.73553127 11.85824233 24.3522414 ], cur_train_grp_loss: [0.09452969 0.10472813 0.21366328], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6725, max_kl_dist_index: 0, max_train_grp_loss:  13.0914, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7011, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2137, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:01:31,639 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  113, train_loss:  12.1587, val_loss:  12.4389, grad_norm: 0.0133, live_grad: 0.0000, reward_err: 0.0102, 0.0143, 0.0001, KL_dist: 0.6727, 0.3138, 0.6652, param: [5.46178819 8.23634334 5.27388515 8.80376771], weights: [0.26464617 0.27691491 0.45843892], train_wt_loss:  36.4760, val_wt_loss: 37.3168, train_grp_loss: [11.81609015 13.09184812 10.68207678], val_grp_loss: [12.70130192 12.47241453 12.14228713], train_hist_grp_loss: [10.83006049 11.96297376 24.56589382], cur_train_grp_loss: [0.09452922 0.10473143 0.21365242], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6727, max_kl_dist_index: 0, max_train_grp_loss:  13.0918, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7013, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2137, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:01:32,690 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  114, train_loss:  12.1587, val_loss:  12.4391, grad_norm: 0.0135, live_grad: 0.0000, reward_err: 0.0102, 0.0143, 0.0001, KL_dist: 0.6729, 0.3139, 0.6653, param: [5.46188819 8.23586371 5.27515314 8.80634388], weights: [0.26403822 0.27639158 0.4595702 ], train_wt_loss:  36.4761, val_wt_loss: 37.3174, train_grp_loss: [11.81602554 13.09227225 10.68153072], val_grp_loss: [12.70147509 12.47290848 12.14219886], train_hist_grp_loss: [10.92458921 12.06770855 24.77953536], cur_train_grp_loss: [0.09452872 0.10473478 0.21364154], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6729, max_kl_dist_index: 0, max_train_grp_loss:  13.0923, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7015, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2136, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:01:33,773 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  115, train_loss:  12.1588, val_loss:  12.4393, grad_norm: 0.0136, live_grad: 0.0000, reward_err: 0.0102, 0.0143, 0.0001, KL_dist: 0.6731, 0.3140, 0.6655, param: [5.46198677 8.23538544 5.27642345 8.80893028], weights: [0.26343034 0.2758679  0.46070176], train_wt_loss:  36.4763, val_wt_loss: 37.3180, train_grp_loss: [11.81595807 13.09270176 10.68098301], val_grp_loss: [12.70164589 12.47340857 12.14210972], train_hist_grp_loss: [11.01911741 12.17244672 24.99316597], cur_train_grp_loss: [0.0945282  0.10473818 0.21363061], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6731, max_kl_dist_index: 0, max_train_grp_loss:  13.0927, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7016, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2136, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:01:34,814 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  116, train_loss:  12.1588, val_loss:  12.4395, grad_norm: 0.0138, live_grad: 0.0000, reward_err: 0.0102, 0.0143, 0.0001, KL_dist: 0.6733, 0.3141, 0.6657, param: [5.46208394 8.23490851 5.27769609 8.81152691], weights: [0.26282253 0.27534387 0.4618336 ], train_wt_loss:  36.4765, val_wt_loss: 37.3185, train_grp_loss: [11.81588776 13.09313666 10.68043366], val_grp_loss: [12.70181433 12.47391482 12.14201971], train_hist_grp_loss: [11.11364508 12.27718834 25.20678563], cur_train_grp_loss: [0.09452766 0.10474161 0.21361966], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6733, max_kl_dist_index: 0, max_train_grp_loss:  13.0931, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7018, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2136, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:01:35,850 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  117, train_loss:  12.1589, val_loss:  12.4397, grad_norm: 0.0140, live_grad: 0.0000, reward_err: 0.0102, 0.0143, 0.0001, KL_dist: 0.6734, 0.3142, 0.6659, param: [5.46217968 8.2344329  5.27897106 8.81413378], weights: [0.26221481 0.2748195  0.46296569], train_wt_loss:  36.4767, val_wt_loss: 37.3191, train_grp_loss: [11.8158146  13.09357696 10.67988267], val_grp_loss: [12.70198042 12.47442722 12.14192885], train_hist_grp_loss: [11.20817218 12.38193343 25.42039431], cur_train_grp_loss: [0.0945271  0.10474509 0.21360867], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6734, max_kl_dist_index: 0, max_train_grp_loss:  13.0936, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7020, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2136, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:01:36,891 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  118, train_loss:  12.1590, val_loss:  12.4399, grad_norm: 0.0141, live_grad: 0.0000, reward_err: 0.0102, 0.0143, 0.0001, KL_dist: 0.6736, 0.3143, 0.6661, param: [5.462274   8.23395862 5.28024836 8.8167509 ], weights: [0.26160718 0.27429479 0.46409803], train_wt_loss:  36.4769, val_wt_loss: 37.3197, train_grp_loss: [11.8157386  13.09402265 10.67933005], val_grp_loss: [12.70214417 12.47494578 12.14183714], train_hist_grp_loss: [11.30269869 12.48668205 25.63399196], cur_train_grp_loss: [0.09452652 0.10474862 0.21359765], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6736, max_kl_dist_index: 0, max_train_grp_loss:  13.0940, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7021, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2136, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:01:37,946 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  119, train_loss:  12.1590, val_loss:  12.4401, grad_norm: 0.0143, live_grad: 0.0000, reward_err: 0.0102, 0.0143, 0.0001, KL_dist: 0.6738, 0.3144, 0.6662, param: [5.46236689 8.23348565 5.28152801 8.81937828], weights: [0.26099964 0.27376975 0.4652306 ], train_wt_loss:  36.4771, val_wt_loss: 37.3203, train_grp_loss: [11.81565978 13.09447373 10.67877579], val_grp_loss: [12.70230557 12.4754705  12.14174458], train_hist_grp_loss: [11.3972246  12.59143423 25.84757856], cur_train_grp_loss: [0.09452591 0.10475218 0.2135866 ], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6738, max_kl_dist_index: 0, max_train_grp_loss:  13.0945, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7023, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2136, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:01:38,992 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  120, train_loss:  12.1591, val_loss:  12.4403, grad_norm: 0.0145, live_grad: 0.0000, reward_err: 0.0102, 0.0143, 0.0001, KL_dist: 0.6740, 0.3145, 0.6664, param: [5.46245834 8.23301397 5.28280999 8.82201592], weights: [0.26039221 0.27324439 0.4663634 ], train_wt_loss:  36.4772, val_wt_loss: 37.3209, train_grp_loss: [11.81557814 13.09493023 10.67821992], val_grp_loss: [12.70246464 12.47600139 12.14165118], train_hist_grp_loss: [11.49174988 12.69619002 26.06115408], cur_train_grp_loss: [0.09452528 0.10475579 0.21357552], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6740, max_kl_dist_index: 0, max_train_grp_loss:  13.0949, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7025, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2136, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:01:40,023 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  121, train_loss:  12.1591, val_loss:  12.4405, grad_norm: 0.0147, live_grad: 0.0000, reward_err: 0.0102, 0.0143, 0.0001, KL_dist: 0.6741, 0.3146, 0.6666, param: [5.46254835 8.23254359 5.28409431 8.82466382], weights: [0.25978488 0.27271871 0.46749641], train_wt_loss:  36.4774, val_wt_loss: 37.3215, train_grp_loss: [11.81549369 13.09539213 10.67766241], val_grp_loss: [12.70262138 12.47653846 12.14155695], train_hist_grp_loss: [11.58627451 12.80094946 26.27471847], cur_train_grp_loss: [0.09452463 0.10475944 0.2135644 ], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6741, max_kl_dist_index: 0, max_train_grp_loss:  13.0954, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7026, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2136, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:01:41,098 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  122, train_loss:  12.1592, val_loss:  12.4407, grad_norm: 0.0148, live_grad: 0.0000, reward_err: 0.0102, 0.0143, 0.0001, KL_dist: 0.6743, 0.3147, 0.6668, param: [5.46263693 8.23207447 5.28538098 8.827322  ], weights: [0.25917766 0.27219272 0.46862961], train_wt_loss:  36.4776, val_wt_loss: 37.3221, train_grp_loss: [11.81540644 13.09585943 10.6771033 ], val_grp_loss: [12.7027758  12.4770817  12.14146189], train_hist_grp_loss: [11.68079846 12.9057126  26.48827172], cur_train_grp_loss: [0.09452395 0.10476314 0.21355325], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6743, max_kl_dist_index: 0, max_train_grp_loss:  13.0959, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7028, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2136, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:01:42,160 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  123, train_loss:  12.1593, val_loss:  12.4409, grad_norm: 0.0150, live_grad: 0.0000, reward_err: 0.0102, 0.0143, 0.0001, KL_dist: 0.6745, 0.3148, 0.6670, param: [5.46272405 8.23160662 5.28667    8.82999046], weights: [0.25857057 0.27166643 0.469763  ], train_wt_loss:  36.4778, val_wt_loss: 37.3227, train_grp_loss: [11.8153164  13.09633216 10.67654256], val_grp_loss: [12.70292791 12.47763112 12.14136601], train_hist_grp_loss: [11.77532171 13.01047947 26.70181379], cur_train_grp_loss: [0.09452325 0.10476688 0.21354207], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6745, max_kl_dist_index: 0, max_train_grp_loss:  13.0963, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7029, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2135, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:01:43,192 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  124, train_loss:  12.1593, val_loss:  12.4411, grad_norm: 0.0152, live_grad: 0.0000, reward_err: 0.0102, 0.0143, 0.0001, KL_dist: 0.6747, 0.3149, 0.6671, param: [5.46280973 8.23114003 5.28796136 8.8326692 ], weights: [0.25796359 0.27113984 0.47089657], train_wt_loss:  36.4780, val_wt_loss: 37.3233, train_grp_loss: [11.81522358 13.09681029 10.67598022], val_grp_loss: [12.7030777  12.47818672 12.14126932], train_hist_grp_loss: [11.86984424 13.11525013 26.91534464], cur_train_grp_loss: [0.09452253 0.10477066 0.21353085], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6747, max_kl_dist_index: 0, max_train_grp_loss:  13.0968, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7031, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2135, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:01:44,237 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  125, train_loss:  12.1594, val_loss:  12.4413, grad_norm: 0.0154, live_grad: 0.0000, reward_err: 0.0102, 0.0143, 0.0001, KL_dist: 0.6749, 0.3150, 0.6673, param: [5.46289395 8.23067467 5.28925507 8.83535823], weights: [0.25735675 0.27061295 0.4720303 ], train_wt_loss:  36.4782, val_wt_loss: 37.3239, train_grp_loss: [11.81512798 13.09729385 10.67541627], val_grp_loss: [12.7032252  12.47874852 12.14117182], train_hist_grp_loss: [11.96436603 13.22002461 27.12886424], cur_train_grp_loss: [0.09452179 0.10477448 0.2135196 ], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6749, max_kl_dist_index: 0, max_train_grp_loss:  13.0973, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7032, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2135, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:01:45,270 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  126, train_loss:  12.1595, val_loss:  12.4415, grad_norm: 0.0155, live_grad: 0.0000, reward_err: 0.0102, 0.0143, 0.0001, KL_dist: 0.6751, 0.3151, 0.6675, param: [5.46297672 8.23021055 5.29055114 8.83805756], weights: [0.25675004 0.27008579 0.47316417], train_wt_loss:  36.4784, val_wt_loss: 37.3245, train_grp_loss: [11.81502961 13.09778283 10.67485073], val_grp_loss: [12.7033704  12.47931651 12.14107353], train_hist_grp_loss: [12.05888705 13.32480296 27.34237257], cur_train_grp_loss: [0.09452102 0.10477835 0.21350833], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6751, max_kl_dist_index: 0, max_train_grp_loss:  13.0978, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7034, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2135, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:01:46,308 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  127, train_loss:  12.1595, val_loss:  12.4417, grad_norm: 0.0157, live_grad: 0.0000, reward_err: 0.0102, 0.0143, 0.0001, KL_dist: 0.6752, 0.3152, 0.6677, param: [5.46305803 8.22974764 5.29184956 8.84076719], weights: [0.25614347 0.26955834 0.47429819], train_wt_loss:  36.4786, val_wt_loss: 37.3252, train_grp_loss: [11.81492849 13.09827724 10.67428358], val_grp_loss: [12.7035133  12.4798907  12.14097443], train_hist_grp_loss: [12.15340729 13.42958522 27.55586958], cur_train_grp_loss: [0.09452024 0.10478226 0.21349701], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6752, max_kl_dist_index: 0, max_train_grp_loss:  13.0983, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7035, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2135, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:01:47,388 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  128, train_loss:  12.1596, val_loss:  12.4419, grad_norm: 0.0159, live_grad: 0.0000, reward_err: 0.0102, 0.0143, 0.0001, KL_dist: 0.6754, 0.3153, 0.6679, param: [5.46313787 8.22928594 5.29315033 8.84348713], weights: [0.25553705 0.26903062 0.47543233], train_wt_loss:  36.4789, val_wt_loss: 37.3258, train_grp_loss: [11.81482462 13.09877708 10.67371485], val_grp_loss: [12.70365393 12.48047109 12.14087455], train_hist_grp_loss: [12.24792672 13.53437144 27.76935526], cur_train_grp_loss: [0.09451943 0.10478622 0.21348567], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6754, max_kl_dist_index: 0, max_train_grp_loss:  13.0988, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7037, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2135, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:01:48,440 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  129, train_loss:  12.1597, val_loss:  12.4421, grad_norm: 0.0161, live_grad: 0.0000, reward_err: 0.0102, 0.0143, 0.0001, KL_dist: 0.6756, 0.3154, 0.6681, param: [5.46321624 8.22882544 5.29445346 8.84621737], weights: [0.25493078 0.26850263 0.47656658], train_wt_loss:  36.4791, val_wt_loss: 37.3264, train_grp_loss: [11.814718   13.09928235 10.67314452], val_grp_loss: [12.70379228 12.48105769 12.14077389], train_hist_grp_loss: [12.34244531 13.63916166 27.98282955], cur_train_grp_loss: [0.0945186  0.10479022 0.2134743 ], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6756, max_kl_dist_index: 0, max_train_grp_loss:  13.0993, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7038, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2135, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:01:49,491 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  130, train_loss:  12.1598, val_loss:  12.4423, grad_norm: 0.0163, live_grad: 0.0000, reward_err: 0.0102, 0.0143, 0.0001, KL_dist: 0.6758, 0.3155, 0.6683, param: [5.46329314 8.22836612 5.29575896 8.84895794], weights: [0.25432468 0.26797439 0.47770093], train_wt_loss:  36.4793, val_wt_loss: 37.3270, train_grp_loss: [11.81460867 13.09979306 10.67257262], val_grp_loss: [12.70392836 12.48165049 12.14067246], train_hist_grp_loss: [12.43696306 13.74395592 28.19629244], cur_train_grp_loss: [0.09451774 0.10479426 0.21346289], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6758, max_kl_dist_index: 0, max_train_grp_loss:  13.0998, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7039, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2135, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:01:50,548 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  131, train_loss:  12.1598, val_loss:  12.4426, grad_norm: 0.0164, live_grad: 0.0000, reward_err: 0.0102, 0.0143, 0.0001, KL_dist: 0.6760, 0.3156, 0.6685, param: [5.46336856 8.22790798 5.29706681 8.85170882], weights: [0.25371873 0.26744589 0.47883538], train_wt_loss:  36.4795, val_wt_loss: 37.3277, train_grp_loss: [11.8144966  13.10030921 10.67199914], val_grp_loss: [12.70406218 12.48224951 12.14057026], train_hist_grp_loss: [12.53147993 13.84875426 28.4097439 ], cur_train_grp_loss: [0.09451687 0.10479834 0.21345145], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6760, max_kl_dist_index: 0, max_train_grp_loss:  13.1003, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7041, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2135, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:01:51,625 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  132, train_loss:  12.1599, val_loss:  12.4428, grad_norm: 0.0166, live_grad: 0.0000, reward_err: 0.0102, 0.0143, 0.0001, KL_dist: 0.6762, 0.3157, 0.6686, param: [5.46344251 8.22745099 5.29837703 8.85447003], weights: [0.25311296 0.26691715 0.4799699 ], train_wt_loss:  36.4797, val_wt_loss: 37.3283, train_grp_loss: [11.81438183 13.10083079 10.67142408], val_grp_loss: [12.70419374 12.48285475 12.1404673 ], train_hist_grp_loss: [12.6259959  13.95355674 28.62318388], cur_train_grp_loss: [0.09451597 0.10480247 0.21343998], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6762, max_kl_dist_index: 0, max_train_grp_loss:  13.1008, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7042, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2134, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:01:52,676 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  133, train_loss:  12.1600, val_loss:  12.4430, grad_norm: 0.0168, live_grad: 0.0000, reward_err: 0.0102, 0.0143, 0.0001, KL_dist: 0.6764, 0.3158, 0.6688, param: [5.46351497 8.22699516 5.29968961 8.85724157], weights: [0.25250736 0.26638816 0.48110448], train_wt_loss:  36.4800, val_wt_loss: 37.3289, train_grp_loss: [11.81426436 13.10135783 10.67084745], val_grp_loss: [12.70432306 12.48346621 12.14036359], train_hist_grp_loss: [12.72051095 14.05836338 28.83661236], cur_train_grp_loss: [0.09451505 0.10480665 0.21342848], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6764, max_kl_dist_index: 0, max_train_grp_loss:  13.1014, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7043, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2134, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:01:53,705 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  134, train_loss:  12.1601, val_loss:  12.4432, grad_norm: 0.0170, live_grad: 0.0000, reward_err: 0.0102, 0.0143, 0.0001, KL_dist: 0.6766, 0.3159, 0.6690, param: [5.46358594 8.22654046 5.30100455 8.86002344], weights: [0.25190195 0.26585894 0.48223911], train_wt_loss:  36.4802, val_wt_loss: 37.3296, train_grp_loss: [11.81414419 13.10189031 10.67026927], val_grp_loss: [12.70445013 12.4840839  12.14025913], train_hist_grp_loss: [12.81502507 14.16317425 29.05002931], cur_train_grp_loss: [0.09451411 0.10481086 0.21341695], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6766, max_kl_dist_index: 0, max_train_grp_loss:  13.1019, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7045, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2134, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:01:54,748 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  135, train_loss:  12.1601, val_loss:  12.4434, grad_norm: 0.0172, live_grad: 0.0000, reward_err: 0.0102, 0.0143, 0.0001, KL_dist: 0.6767, 0.3160, 0.6692, param: [5.46365542 8.22608689 5.30232187 8.86281566], weights: [0.25129672 0.26532949 0.48337379], train_wt_loss:  36.4804, val_wt_loss: 37.3302, train_grp_loss: [11.81402134 13.10242824 10.66968952], val_grp_loss: [12.70457496 12.48470782 12.14015393], train_hist_grp_loss: [12.90953822 14.26798937 29.26343469], cur_train_grp_loss: [0.09451315 0.10481512 0.21340539], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6767, max_kl_dist_index: 0, max_train_grp_loss:  13.1024, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7046, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2134, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:01:55,769 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  136, train_loss:  12.1602, val_loss:  12.4436, grad_norm: 0.0174, live_grad: 0.0000, reward_err: 0.0102, 0.0143, 0.0001, KL_dist: 0.6769, 0.3161, 0.6694, param: [5.4637234  8.22563443 5.30364155 8.86561821], weights: [0.25069168 0.26479983 0.48450849], train_wt_loss:  36.4806, val_wt_loss: 37.3309, train_grp_loss: [11.81389582 13.10297162 10.66910822], val_grp_loss: [12.70469757 12.48533797 12.140048  ], train_hist_grp_loss: [13.00405039 14.37280879 29.47682848], cur_train_grp_loss: [0.09451217 0.10481943 0.21339379], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6769, max_kl_dist_index: 0, max_train_grp_loss:  13.1030, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7047, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2134, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:01:56,823 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  137, train_loss:  12.1603, val_loss:  12.4438, grad_norm: 0.0176, live_grad: 0.0000, reward_err: 0.0102, 0.0143, 0.0001, KL_dist: 0.6771, 0.3163, 0.6696, param: [5.46378989 8.22518307 5.30496361 8.86843111], weights: [0.25008685 0.26426994 0.48564321], train_wt_loss:  36.4809, val_wt_loss: 37.3315, train_grp_loss: [11.81376763 13.10352046 10.66852536], val_grp_loss: [12.70481796 12.48597435 12.13994135], train_hist_grp_loss: [13.09856156 14.47763257 29.69021065], cur_train_grp_loss: [0.09451117 0.10482377 0.21338216], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6771, max_kl_dist_index: 0, max_train_grp_loss:  13.1035, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7048, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2134, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:01:57,870 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  138, train_loss:  12.1604, val_loss:  12.4441, grad_norm: 0.0177, live_grad: 0.0000, reward_err: 0.0102, 0.0143, 0.0001, KL_dist: 0.6773, 0.3164, 0.6698, param: [5.46385487 8.2247328  5.30628803 8.87125437], weights: [0.24948222 0.26373985 0.48677793], train_wt_loss:  36.4811, val_wt_loss: 37.3322, train_grp_loss: [11.81363679 13.10407476 10.66794097], val_grp_loss: [12.70493613 12.48661698 12.13983397], train_hist_grp_loss: [13.1930717  14.58246073 29.90358116], cur_train_grp_loss: [0.09451014 0.10482816 0.21337051], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6773, max_kl_dist_index: 0, max_train_grp_loss:  13.1041, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7049, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2134, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:01:58,919 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  139, train_loss:  12.1604, val_loss:  12.4443, grad_norm: 0.0179, live_grad: 0.0000, reward_err: 0.0102, 0.0143, 0.0001, KL_dist: 0.6775, 0.3165, 0.6700, param: [5.46391835 8.22428361 5.30761483 8.87408797], weights: [0.2488778  0.26320956 0.48791264], train_wt_loss:  36.4813, val_wt_loss: 37.3328, train_grp_loss: [11.8135033  13.10463453 10.66735504], val_grp_loss: [12.70505209 12.48726585 12.13972589], train_hist_grp_loss: [13.28758079 14.68729333 30.11693998], cur_train_grp_loss: [0.09450909 0.1048326  0.21335882], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6775, max_kl_dist_index: 0, max_train_grp_loss:  13.1046, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7051, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2134, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:02:00,003 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  140, train_loss:  12.1605, val_loss:  12.4445, grad_norm: 0.0181, live_grad: 0.0000, reward_err: 0.0102, 0.0143, 0.0001, KL_dist: 0.6777, 0.3166, 0.6702, param: [5.46398031 8.22383548 5.308944   8.87693194], weights: [0.2482736  0.26267907 0.48904733], train_wt_loss:  36.4816, val_wt_loss: 37.3335, train_grp_loss: [11.81336718 13.10519975 10.66676757], val_grp_loss: [12.70516586 12.48792097 12.1396171 ], train_hist_grp_loss: [13.38208882 14.7921304  30.33028708], cur_train_grp_loss: [0.09450803 0.10483708 0.2133471 ], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6777, max_kl_dist_index: 0, max_train_grp_loss:  13.1052, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7052, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2133, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:02:01,031 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  141, train_loss:  12.1606, val_loss:  12.4447, grad_norm: 0.0183, live_grad: 0.0000, reward_err: 0.0102, 0.0143, 0.0001, KL_dist: 0.6779, 0.3167, 0.6704, param: [5.46404076 8.2233884  5.31027555 8.87978626], weights: [0.24766962 0.26214839 0.49018199], train_wt_loss:  36.4818, val_wt_loss: 37.3341, train_grp_loss: [11.81322844 13.10577044 10.66617857], val_grp_loss: [12.70527743 12.48858234 12.13950762], train_hist_grp_loss: [13.47659576 14.896972   30.54362243], cur_train_grp_loss: [0.09450694 0.1048416  0.21333535], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6779, max_kl_dist_index: 0, max_train_grp_loss:  13.1058, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7053, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2133, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:02:02,099 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  142, train_loss:  12.1607, val_loss:  12.4449, grad_norm: 0.0185, live_grad: 0.0000, reward_err: 0.0102, 0.0143, 0.0001, KL_dist: 0.6781, 0.3168, 0.6706, param: [5.46409969 8.22294237 5.31160947 8.88265095], weights: [0.24706587 0.26161753 0.49131661], train_wt_loss:  36.4821, val_wt_loss: 37.3348, train_grp_loss: [11.81308708 13.10634661 10.66558805], val_grp_loss: [12.70538682 12.48924996 12.13939744], train_hist_grp_loss: [13.57110159 15.00181817 30.756946  ], cur_train_grp_loss: [0.09450583 0.10484616 0.21332357], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6781, max_kl_dist_index: 0, max_train_grp_loss:  13.1063, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7054, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2133, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:02:03,137 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  143, train_loss:  12.1608, val_loss:  12.4452, grad_norm: 0.0187, live_grad: 0.0000, reward_err: 0.0102, 0.0143, 0.0001, KL_dist: 0.6783, 0.3169, 0.6708, param: [5.4641571  8.22249736 5.31294577 8.885526  ], weights: [0.24646235 0.26108649 0.49245116], train_wt_loss:  36.4823, val_wt_loss: 37.3355, train_grp_loss: [11.81294312 13.10692824 10.66499601], val_grp_loss: [12.70549403 12.48992384 12.13928659], train_hist_grp_loss: [13.66560628 15.10666894 30.97025776], cur_train_grp_loss: [0.0945047  0.10485077 0.21331176], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6783, max_kl_dist_index: 0, max_train_grp_loss:  13.1069, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7055, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2133, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:02:04,179 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  144, train_loss:  12.1609, val_loss:  12.4454, grad_norm: 0.0189, live_grad: 0.0000, reward_err: 0.0102, 0.0143, 0.0001, KL_dist: 0.6785, 0.3170, 0.6710, param: [5.46421299 8.22205337 5.31428445 8.88841143], weights: [0.24585907 0.26055528 0.49358565], train_wt_loss:  36.4826, val_wt_loss: 37.3362, train_grp_loss: [11.81279656 13.10751535 10.66440246], val_grp_loss: [12.70559907 12.49060399 12.13917506], train_hist_grp_loss: [13.76010983 15.21152436 31.18355768], cur_train_grp_loss: [0.09450354 0.10485543 0.21329992], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6785, max_kl_dist_index: 0, max_train_grp_loss:  13.1075, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7056, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2133, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:02:05,203 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  145, train_loss:  12.1609, val_loss:  12.4456, grad_norm: 0.0191, live_grad: 0.0000, reward_err: 0.0102, 0.0143, 0.0001, KL_dist: 0.6787, 0.3171, 0.6712, param: [5.46426734 8.22161038 5.31562551 8.89130723], weights: [0.24525604 0.26002391 0.49472005], train_wt_loss:  36.4828, val_wt_loss: 37.3368, train_grp_loss: [11.81264742 13.10810793 10.6638074 ], val_grp_loss: [12.70570195 12.49129039 12.13906286], train_hist_grp_loss: [13.8546122  15.31638449 31.39684573], cur_train_grp_loss: [0.09450237 0.10486012 0.21328805], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6787, max_kl_dist_index: 0, max_train_grp_loss:  13.1081, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7057, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2133, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:02:06,232 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  146, train_loss:  12.1610, val_loss:  12.4458, grad_norm: 0.0193, live_grad: 0.0000, reward_err: 0.0102, 0.0143, 0.0001, KL_dist: 0.6789, 0.3172, 0.6714, param: [5.46432016 8.22116839 5.31696895 8.8942134 ], weights: [0.24465325 0.25949238 0.49585436], train_wt_loss:  36.4831, val_wt_loss: 37.3375, train_grp_loss: [11.8124957  13.10870599 10.66321084], val_grp_loss: [12.70580267 12.49198306 12.13895   ], train_hist_grp_loss: [13.94911338 15.42124935 31.61012188], cur_train_grp_loss: [0.09450118 0.10486486 0.21327615], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6789, max_kl_dist_index: 0, max_train_grp_loss:  13.1087, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7058, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2133, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:02:07,277 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  147, train_loss:  12.1611, val_loss:  12.4461, grad_norm: 0.0195, live_grad: 0.0000, reward_err: 0.0102, 0.0143, 0.0001, KL_dist: 0.6791, 0.3173, 0.6716, param: [5.46437145 8.22072737 5.31831476 8.89712995], weights: [0.24405073 0.25896071 0.49698857], train_wt_loss:  36.4834, val_wt_loss: 37.3382, train_grp_loss: [11.81234142 13.10930953 10.66261278], val_grp_loss: [12.70590124 12.49268201 12.13883649], train_hist_grp_loss: [14.04361334 15.526119   31.82338609], cur_train_grp_loss: [0.09449997 0.10486965 0.21326422], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6791, max_kl_dist_index: 0, max_train_grp_loss:  13.1093, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7059, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2133, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:02:08,317 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  148, train_loss:  12.1612, val_loss:  12.4463, grad_norm: 0.0197, live_grad: 0.0000, reward_err: 0.0102, 0.0143, 0.0001, KL_dist: 0.6793, 0.3174, 0.6718, param: [5.46442119 8.22028731 5.31966296 8.90005689], weights: [0.24344847 0.25842888 0.49812265], train_wt_loss:  36.4836, val_wt_loss: 37.3389, train_grp_loss: [11.81218459 13.10991856 10.66201323], val_grp_loss: [12.70599767 12.49338722 12.13872234], train_hist_grp_loss: [14.13811208 15.63099348 32.03663835], cur_train_grp_loss: [0.09449873 0.10487448 0.21325226], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6793, max_kl_dist_index: 0, max_train_grp_loss:  13.1099, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7060, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2133, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:02:09,365 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  149, train_loss:  12.1613, val_loss:  12.4465, grad_norm: 0.0199, live_grad: 0.0000, reward_err: 0.0102, 0.0143, 0.0001, KL_dist: 0.6795, 0.3175, 0.6720, param: [5.46446939 8.21984821 5.32101354 8.9029942 ], weights: [0.24284647 0.25789692 0.49925661], train_wt_loss:  36.4839, val_wt_loss: 37.3396, train_grp_loss: [11.81202521 13.11053307 10.6614122 ], val_grp_loss: [12.70609197 12.49409872 12.13860755], train_hist_grp_loss: [14.23260955 15.73587282 32.24987861], cur_train_grp_loss: [0.09449748 0.10487935 0.21324026], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6795, max_kl_dist_index: 0, max_train_grp_loss:  13.1105, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7061, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2132, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:02:10,424 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  150, train_loss:  12.1614, val_loss:  12.4468, grad_norm: 0.0201, live_grad: 0.0000, reward_err: 0.0102, 0.0143, 0.0001, KL_dist: 0.6797, 0.3176, 0.6722, param: [5.46451604 8.21941005 5.3223665  8.9059419 ], weights: [0.24224475 0.25736483 0.50039042], train_wt_loss:  36.4842, val_wt_loss: 37.3403, train_grp_loss: [11.81186331 13.11115307 10.66080968], val_grp_loss: [12.70618414 12.49481649 12.13849213], train_hist_grp_loss: [14.32710575 15.84075709 32.46310686], cur_train_grp_loss: [0.0944962  0.10488426 0.21322824], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6797, max_kl_dist_index: 0, max_train_grp_loss:  13.1112, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7062, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2132, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:02:11,487 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  151, train_loss:  12.1615, val_loss:  12.4470, grad_norm: 0.0203, live_grad: 0.0000, reward_err: 0.0102, 0.0143, 0.0001, KL_dist: 0.6799, 0.3177, 0.6724, param: [5.46456113 8.21897281 5.32372185 8.90889998], weights: [0.24164331 0.25683261 0.50152408], train_wt_loss:  36.4844, val_wt_loss: 37.3410, train_grp_loss: [11.81169888 13.11177855 10.66020569], val_grp_loss: [12.70627419 12.49554054 12.13837608], train_hist_grp_loss: [14.42160066 15.94564631 32.67632305], cur_train_grp_loss: [0.09449491 0.10488922 0.21321619], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6799, max_kl_dist_index: 0, max_train_grp_loss:  13.1118, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7063, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2132, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:02:12,526 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  152, train_loss:  12.1616, val_loss:  12.4472, grad_norm: 0.0205, live_grad: 0.0000, reward_err: 0.0102, 0.0143, 0.0001, KL_dist: 0.6801, 0.3179, 0.6726, param: [5.46460468 8.21853649 5.32507958 8.91186846], weights: [0.24104216 0.25630027 0.50265757], train_wt_loss:  36.4847, val_wt_loss: 37.3417, train_grp_loss: [11.81153194 13.11240953 10.65960023], val_grp_loss: [12.70636214 12.49627088 12.13825943], train_hist_grp_loss: [14.51609425 16.05054054 32.88952717], cur_train_grp_loss: [0.09449359 0.10489423 0.21320411], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6801, max_kl_dist_index: 0, max_train_grp_loss:  13.1124, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7064, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2132, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:02:13,578 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  153, train_loss:  12.1617, val_loss:  12.4475, grad_norm: 0.0207, live_grad: 0.0000, reward_err: 0.0102, 0.0143, 0.0001, KL_dist: 0.6803, 0.3180, 0.6728, param: [5.46464666 8.21810107 5.32643969 8.91484732], weights: [0.24044129 0.25576782 0.50379088], train_wt_loss:  36.4850, val_wt_loss: 37.3424, train_grp_loss: [11.8113625  13.113046   10.65899331], val_grp_loss: [12.70644798 12.4970075  12.13814216], train_hist_grp_loss: [14.61058651 16.15543982 33.10271917], cur_train_grp_loss: [0.09449226 0.10489928 0.213192  ], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6803, max_kl_dist_index: 0, max_train_grp_loss:  13.1130, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7064, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2132, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:02:14,647 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  154, train_loss:  12.1618, val_loss:  12.4477, grad_norm: 0.0209, live_grad: 0.0000, reward_err: 0.0102, 0.0143, 0.0001, KL_dist: 0.6805, 0.3181, 0.6730, param: [5.46468708 8.21766654 5.32780218 8.91783657], weights: [0.23984073 0.25523527 0.504924  ], train_wt_loss:  36.4853, val_wt_loss: 37.3431, train_grp_loss: [11.81119057 13.11368796 10.65838494], val_grp_loss: [12.70653173 12.49775042 12.1380243 ], train_hist_grp_loss: [14.70507741 16.26034419 33.31589904], cur_train_grp_loss: [0.0944909  0.10490437 0.21317987], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6805, max_kl_dist_index: 0, max_train_grp_loss:  13.1137, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7065, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2132, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:02:15,682 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  155, train_loss:  12.1619, val_loss:  12.4479, grad_norm: 0.0211, live_grad: 0.0000, reward_err: 0.0102, 0.0143, 0.0001, KL_dist: 0.6807, 0.3182, 0.6732, param: [5.46472593 8.21723288 5.32916706 8.92083622], weights: [0.23924046 0.25470261 0.50605692], train_wt_loss:  36.4856, val_wt_loss: 37.3438, train_grp_loss: [11.81101617 13.11433542 10.65777511], val_grp_loss: [12.70661339 12.49849963 12.13790584], train_hist_grp_loss: [14.79956693 16.36525369 33.52906674], cur_train_grp_loss: [0.09448952 0.1049095  0.2131677 ], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6807, max_kl_dist_index: 0, max_train_grp_loss:  13.1143, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7066, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2132, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:02:16,734 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  156, train_loss:  12.1620, val_loss:  12.4482, grad_norm: 0.0213, live_grad: 0.0000, reward_err: 0.0102, 0.0143, 0.0001, KL_dist: 0.6809, 0.3183, 0.6734, param: [5.46476321 8.21680009 5.33053432 8.92384626], weights: [0.23864051 0.25416986 0.50718963], train_wt_loss:  36.4859, val_wt_loss: 37.3445, train_grp_loss: [11.8108393  13.11498838 10.65716383], val_grp_loss: [12.70669297 12.49925513 12.13778681], train_hist_grp_loss: [14.89405506 16.47016837 33.74222224], cur_train_grp_loss: [0.09448813 0.10491468 0.2131555 ], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6809, max_kl_dist_index: 0, max_train_grp_loss:  13.1150, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7067, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2132, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:02:17,765 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  157, train_loss:  12.1621, val_loss:  12.4484, grad_norm: 0.0216, live_grad: 0.0000, reward_err: 0.0102, 0.0143, 0.0001, KL_dist: 0.6811, 0.3184, 0.6736, param: [5.46479891 8.21636814 5.33190397 8.92686669], weights: [0.23804087 0.25363703 0.50832211], train_wt_loss:  36.4862, val_wt_loss: 37.3452, train_grp_loss: [11.81065997 13.11564684 10.65655112], val_grp_loss: [12.70677049 12.50001693 12.13766719], train_hist_grp_loss: [14.98854178 16.57508828 33.95536551], cur_train_grp_loss: [0.09448671 0.10491991 0.21314328], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6811, max_kl_dist_index: 0, max_train_grp_loss:  13.1156, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7068, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2131, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:02:18,834 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  158, train_loss:  12.1622, val_loss:  12.4487, grad_norm: 0.0218, live_grad: 0.0000, reward_err: 0.0102, 0.0143, 0.0001, KL_dist: 0.6813, 0.3185, 0.6738, param: [5.46483304 8.21593703 5.333276   8.92989751], weights: [0.23744154 0.25310411 0.50945434], train_wt_loss:  36.4865, val_wt_loss: 37.3460, train_grp_loss: [11.8104782  13.1163108  10.65593698], val_grp_loss: [12.70684594 12.50078503 12.13754701], train_hist_grp_loss: [15.08302706 16.68001345 34.16849654], cur_train_grp_loss: [0.09448528 0.10492517 0.21313102], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6813, max_kl_dist_index: 0, max_train_grp_loss:  13.1163, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7068, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2131, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:02:19,860 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  159, train_loss:  12.1623, val_loss:  12.4489, grad_norm: 0.0220, live_grad: 0.0000, reward_err: 0.0104, 0.0143, 0.0002, KL_dist: 0.6815, 0.3186, 0.6741, param: [5.46486559 8.21550674 5.33465042 8.93293874], weights: [0.23684255 0.25257112 0.51058633], train_wt_loss:  36.4868, val_wt_loss: 37.3467, train_grp_loss: [11.81029399 13.11698026 10.6553214 ], val_grp_loss: [12.70691933 12.50155944 12.13742627], train_hist_grp_loss: [15.17751088 16.78494394 34.38161528], cur_train_grp_loss: [0.09448383 0.10493049 0.21311874], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6815, max_kl_dist_index: 0, max_train_grp_loss:  13.1170, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7069, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2131, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:02:20,903 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  160, train_loss:  12.1624, val_loss:  12.4491, grad_norm: 0.0222, live_grad: 0.0000, reward_err: 0.0104, 0.0143, 0.0002, KL_dist: 0.6817, 0.3188, 0.6743, param: [5.46489655 8.21507726 5.33602722 8.93599036], weights: [0.23624388 0.25203806 0.51171806], train_wt_loss:  36.4871, val_wt_loss: 37.3474, train_grp_loss: [11.81010736 13.11765522 10.65470441], val_grp_loss: [12.70699068 12.50234014 12.13730498], train_hist_grp_loss: [15.27199323 16.88987978 34.5947217 ], cur_train_grp_loss: [0.09448235 0.10493584 0.21310643], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6817, max_kl_dist_index: 0, max_train_grp_loss:  13.1177, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7070, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2131, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:02:21,944 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  161, train_loss:  12.1625, val_loss:  12.4494, grad_norm: 0.0224, live_grad: 0.0000, reward_err: 0.0104, 0.0143, 0.0002, KL_dist: 0.6819, 0.3189, 0.6745, param: [5.46492592 8.21464857 5.3374064  8.93905237], weights: [0.23564555 0.25150494 0.51284951], train_wt_loss:  36.4874, val_wt_loss: 37.3481, train_grp_loss: [11.80991833 13.11833569 10.654086  ], val_grp_loss: [12.70705999 12.50312716 12.13718314], train_hist_grp_loss: [15.36647409 16.99482102 34.80781579], cur_train_grp_loss: [0.09448086 0.10494124 0.21309409], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6819, max_kl_dist_index: 0, max_train_grp_loss:  13.1183, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7071, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2131, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:02:22,985 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  162, train_loss:  12.1626, val_loss:  12.4496, grad_norm: 0.0226, live_grad: 0.0000, reward_err: 0.0104, 0.0143, 0.0002, KL_dist: 0.6821, 0.3190, 0.6747, param: [5.46495369 8.21422067 5.33878796 8.94212478], weights: [0.23504756 0.25097177 0.51398067], train_wt_loss:  36.4877, val_wt_loss: 37.3489, train_grp_loss: [11.80972689 13.11902167 10.65346618], val_grp_loss: [12.70712727 12.50392048 12.13706076], train_hist_grp_loss: [15.46095344 17.09976771 35.02089751], cur_train_grp_loss: [0.09447935 0.10494669 0.21308172], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6821, max_kl_dist_index: 0, max_train_grp_loss:  13.1190, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7071, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2131, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:02:24,035 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  163, train_loss:  12.1627, val_loss:  12.4499, grad_norm: 0.0228, live_grad: 0.0000, reward_err: 0.0104, 0.0143, 0.0002, KL_dist: 0.6823, 0.3191, 0.6749, param: [5.46497987 8.21379354 5.34017191 8.94520759], weights: [0.23444992 0.25043855 0.51511153], train_wt_loss:  36.4880, val_wt_loss: 37.3496, train_grp_loss: [11.80953306 13.11971315 10.65284497], val_grp_loss: [12.70719253 12.50472012 12.13693786], train_hist_grp_loss: [15.55543125 17.20471988 35.23396684], cur_train_grp_loss: [0.09447782 0.10495217 0.21306932], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6823, max_kl_dist_index: 0, max_train_grp_loss:  13.1197, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7072, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2131, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:02:25,052 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  164, train_loss:  12.1628, val_loss:  12.4501, grad_norm: 0.0230, live_grad: 0.0000, reward_err: 0.0104, 0.0143, 0.0002, KL_dist: 0.6825, 0.3192, 0.6751, param: [5.46500445 8.21336716 5.34155825 8.94830079], weights: [0.23385264 0.24990528 0.51624208], train_wt_loss:  36.4883, val_wt_loss: 37.3504, train_grp_loss: [11.80933686 13.12041015 10.65222235], val_grp_loss: [12.70725577 12.50552607 12.13681444], train_hist_grp_loss: [15.64990752 17.30967759 35.44702374], cur_train_grp_loss: [0.09447626 0.10495771 0.2130569 ], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6825, max_kl_dist_index: 0, max_train_grp_loss:  13.1204, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7073, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2131, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:02:26,123 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  165, train_loss:  12.1629, val_loss:  12.4504, grad_norm: 0.0233, live_grad: 0.0000, reward_err: 0.0104, 0.0143, 0.0002, KL_dist: 0.6827, 0.3193, 0.6753, param: [5.46502743 8.21294152 5.34294696 8.95140439], weights: [0.23325571 0.24937198 0.51737231], train_wt_loss:  36.4886, val_wt_loss: 37.3511, train_grp_loss: [11.80913829 13.12111265 10.65159835], val_grp_loss: [12.70731701 12.50633833 12.13669051], train_hist_grp_loss: [15.74438221 17.41464087 35.66006818], cur_train_grp_loss: [0.09447469 0.10496328 0.21304445], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6827, max_kl_dist_index: 0, max_train_grp_loss:  13.1211, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7073, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2130, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:02:27,156 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  166, train_loss:  12.1630, val_loss:  12.4506, grad_norm: 0.0235, live_grad: 0.0000, reward_err: 0.0104, 0.0143, 0.0002, KL_dist: 0.6830, 0.3194, 0.6756, param: [5.4650488  8.21251661 5.34433806 8.95451839], weights: [0.23265915 0.24883864 0.51850221], train_wt_loss:  36.4889, val_wt_loss: 37.3519, train_grp_loss: [11.80893737 13.12182067 10.65097296], val_grp_loss: [12.70737626 12.50715691 12.13656608], train_hist_grp_loss: [15.83885532 17.51960977 35.87310015], cur_train_grp_loss: [0.09447311 0.1049689  0.21303197], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6830, max_kl_dist_index: 0, max_train_grp_loss:  13.1218, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7074, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2130, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:02:28,179 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  167, train_loss:  12.1631, val_loss:  12.4509, grad_norm: 0.0237, live_grad: 0.0000, reward_err: 0.0104, 0.0143, 0.0002, KL_dist: 0.6832, 0.3195, 0.6758, param: [5.46506856 8.21209241 5.34573153 8.95764278], weights: [0.23206295 0.24830529 0.51963176], train_wt_loss:  36.4893, val_wt_loss: 37.3526, train_grp_loss: [11.80873411 13.12253419 10.6503462 ], val_grp_loss: [12.70743351 12.50798181 12.13644115], train_hist_grp_loss: [15.93332682 17.62458434 36.08611961], cur_train_grp_loss: [0.0944715  0.10497457 0.21301946], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6832, max_kl_dist_index: 0, max_train_grp_loss:  13.1225, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7074, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2130, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:02:29,243 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  168, train_loss:  12.1632, val_loss:  12.4511, grad_norm: 0.0239, live_grad: 0.0000, reward_err: 0.0104, 0.0143, 0.0002, KL_dist: 0.6834, 0.3197, 0.6760, param: [5.4650867  8.21166891 5.34712739 8.96077756], weights: [0.23146714 0.24777192 0.52076095], train_wt_loss:  36.4896, val_wt_loss: 37.3534, train_grp_loss: [11.80852852 13.12325323 10.64971807], val_grp_loss: [12.70748878 12.50881303 12.13631573], train_hist_grp_loss: [16.02779669 17.72956461 36.29912653], cur_train_grp_loss: [0.09446987 0.10498027 0.21300692], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6834, max_kl_dist_index: 0, max_train_grp_loss:  13.1233, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7075, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2130, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:02:30,279 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  169, train_loss:  12.1633, val_loss:  12.4514, grad_norm: 0.0241, live_grad: 0.0000, reward_err: 0.0104, 0.0143, 0.0002, KL_dist: 0.6836, 0.3198, 0.6762, param: [5.46510323 8.2112461  5.34852563 8.96392274], weights: [0.2308717  0.24723853 0.52188977], train_wt_loss:  36.4899, val_wt_loss: 37.3542, train_grp_loss: [11.80832062 13.12397778 10.64908857], val_grp_loss: [12.70754209 12.50965057 12.13618983], train_hist_grp_loss: [16.12226492 17.83455064 36.51212089], cur_train_grp_loss: [0.09446823 0.10498603 0.21299436], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6836, max_kl_dist_index: 0, max_train_grp_loss:  13.1240, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7075, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2130, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:02:31,354 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  170, train_loss:  12.1634, val_loss:  12.4516, grad_norm: 0.0244, live_grad: 0.0000, reward_err: 0.0104, 0.0143, 0.0002, KL_dist: 0.6838, 0.3199, 0.6764, param: [5.46511813 8.21082397 5.34992624 8.96707831], weights: [0.23027665 0.24670514 0.52301821], train_wt_loss:  36.4903, val_wt_loss: 37.3549, train_grp_loss: [11.80811041 13.12470785 10.64845772], val_grp_loss: [12.70759342 12.51049444 12.13606347], train_hist_grp_loss: [16.21673148 17.93954246 36.72510266], cur_train_grp_loss: [0.09446656 0.10499182 0.21298177], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6838, max_kl_dist_index: 0, max_train_grp_loss:  13.1247, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7076, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2130, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:02:32,409 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  171, train_loss:  12.1635, val_loss:  12.4519, grad_norm: 0.0246, live_grad: 0.0000, reward_err: 0.0104, 0.0143, 0.0002, KL_dist: 0.6840, 0.3200, 0.6766, param: [5.46513141 8.21040249 5.35132924 8.97024427], weights: [0.229682   0.24617175 0.52414625], train_wt_loss:  36.4906, val_wt_loss: 37.3557, train_grp_loss: [11.8078979  13.12544344 10.64782552], val_grp_loss: [12.70764281 12.51134463 12.13593664], train_hist_grp_loss: [16.31119637 18.04454012 36.93807182], cur_train_grp_loss: [0.09446488 0.10499766 0.21296915], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6840, max_kl_dist_index: 0, max_train_grp_loss:  13.1254, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7076, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2130, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:02:33,456 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  172, train_loss:  12.1636, val_loss:  12.4522, grad_norm: 0.0248, live_grad: 0.0000, reward_err: 0.0104, 0.0143, 0.0002, KL_dist: 0.6842, 0.3201, 0.6769, param: [5.46514306 8.20998165 5.35273461 8.97342062], weights: [0.22908774 0.24563837 0.52527389], train_wt_loss:  36.4909, val_wt_loss: 37.3565, train_grp_loss: [11.80768311 13.12618454 10.64719197], val_grp_loss: [12.70769025 12.51220114 12.13580935], train_hist_grp_loss: [16.40565955 18.14954367 37.15102833], cur_train_grp_loss: [0.09446318 0.10500355 0.21295651], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6842, max_kl_dist_index: 0, max_train_grp_loss:  13.1262, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7077, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2130, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:02:34,510 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  173, train_loss:  12.1638, val_loss:  12.4524, grad_norm: 0.0250, live_grad: 0.0000, reward_err: 0.0104, 0.0143, 0.0002, KL_dist: 0.6844, 0.3202, 0.6771, param: [5.46515307 8.20956144 5.35414235 8.97660736], weights: [0.22849388 0.24510501 0.52640111], train_wt_loss:  36.4913, val_wt_loss: 37.3572, train_grp_loss: [11.80746606 13.12693115 10.64655709], val_grp_loss: [12.70773575 12.51306399 12.13568163], train_hist_grp_loss: [16.50012102 18.25455314 37.36397217], cur_train_grp_loss: [0.09446146 0.10500948 0.21294384], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6844, max_kl_dist_index: 0, max_train_grp_loss:  13.1269, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7077, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2129, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:02:35,541 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  174, train_loss:  12.1639, val_loss:  12.4527, grad_norm: 0.0253, live_grad: 0.0000, reward_err: 0.0104, 0.0143, 0.0002, KL_dist: 0.6847, 0.3204, 0.6773, param: [5.46516145 8.20914185 5.35555248 8.97980448], weights: [0.22790044 0.24457166 0.5275279 ], train_wt_loss:  36.4916, val_wt_loss: 37.3580, train_grp_loss: [11.80724675 13.12768328 10.64592088], val_grp_loss: [12.70777932 12.51393317 12.13555346], train_hist_grp_loss: [16.59458074 18.35956859 37.57690331], cur_train_grp_loss: [0.09445973 0.10501545 0.21293114], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6847, max_kl_dist_index: 0, max_train_grp_loss:  13.1277, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7078, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2129, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:02:36,578 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  175, train_loss:  12.1640, val_loss:  12.4529, grad_norm: 0.0255, live_grad: 0.0000, reward_err: 0.0104, 0.0143, 0.0002, KL_dist: 0.6849, 0.3205, 0.6775, param: [5.46516819 8.20872287 5.35696497 8.98301198], weights: [0.2273074  0.24403834 0.52865425], train_wt_loss:  36.4920, val_wt_loss: 37.3588, train_grp_loss: [11.80702519 13.12844093 10.64528335], val_grp_loss: [12.70782098 12.51480867 12.13542487], train_hist_grp_loss: [16.68903872 18.46459006 37.78982173], cur_train_grp_loss: [0.09445797 0.10502147 0.21291842], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6849, max_kl_dist_index: 0, max_train_grp_loss:  13.1284, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7078, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2129, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:02:37,635 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  176, train_loss:  12.1641, val_loss:  12.4532, grad_norm: 0.0257, live_grad: 0.0000, reward_err: 0.0104, 0.0143, 0.0002, KL_dist: 0.6851, 0.3206, 0.6777, param: [5.46517329 8.20830447 5.35837984 8.98622987], weights: [0.22671479 0.24350506 0.52978015], train_wt_loss:  36.4923, val_wt_loss: 37.3596, train_grp_loss: [11.8068014 13.1292041 10.6446445], val_grp_loss: [12.70786072 12.51569051 12.13529586], train_hist_grp_loss: [16.78349492 18.56961759 38.0027274 ], cur_train_grp_loss: [0.0944562  0.10502753 0.21290567], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6851, max_kl_dist_index: 0, max_train_grp_loss:  13.1292, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7079, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2129, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:02:38,666 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  177, train_loss:  12.1642, val_loss:  12.4535, grad_norm: 0.0260, live_grad: 0.0000, reward_err: 0.0104, 0.0143, 0.0002, KL_dist: 0.6853, 0.3207, 0.6780, param: [5.46517674 8.20788664 5.35979708 8.98945814], weights: [0.22612261 0.24297181 0.53090558], train_wt_loss:  36.4927, val_wt_loss: 37.3604, train_grp_loss: [11.80657539 13.12997279 10.64400434], val_grp_loss: [12.70789856 12.51657868 12.13516644], train_hist_grp_loss: [16.87794933 18.67465122 38.21562029], cur_train_grp_loss: [0.09445441 0.10503363 0.21289289], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6853, max_kl_dist_index: 0, max_train_grp_loss:  13.1300, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7079, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2129, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:02:39,717 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  178, train_loss:  12.1643, val_loss:  12.4537, grad_norm: 0.0262, live_grad: 0.0000, reward_err: 0.0104, 0.0143, 0.0002, KL_dist: 0.6855, 0.3208, 0.6782, param: [5.46517854 8.20746937 5.36121669 8.99269678], weights: [0.22553085 0.24243861 0.53203054], train_wt_loss:  36.4930, val_wt_loss: 37.3612, train_grp_loss: [11.80634718 13.13074699 10.64336288], val_grp_loss: [12.70793451 12.51747319 12.13503661], train_hist_grp_loss: [16.97240193 18.779691   38.42850037], cur_train_grp_loss: [0.0944526  0.10503978 0.21288009], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6855, max_kl_dist_index: 0, max_train_grp_loss:  13.1307, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7079, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2129, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:02:40,760 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  179, train_loss:  12.1645, val_loss:  12.4540, grad_norm: 0.0264, live_grad: 0.0000, reward_err: 0.0104, 0.0143, 0.0002, KL_dist: 0.6857, 0.3210, 0.6784, param: [5.46517869 8.20705265 5.36263866 8.9959458 ], weights: [0.22493953 0.24190546 0.53315501], train_wt_loss:  36.4934, val_wt_loss: 37.3620, train_grp_loss: [11.80611676 13.13152671 10.64272013], val_grp_loss: [12.70796857 12.51837403 12.13490639], train_hist_grp_loss: [17.06685271 18.88473698 38.64136763], cur_train_grp_loss: [0.09445078 0.10504598 0.21286726], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6857, max_kl_dist_index: 0, max_train_grp_loss:  13.1315, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7080, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2129, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:02:41,835 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  180, train_loss:  12.1646, val_loss:  12.4543, grad_norm: 0.0267, live_grad: 0.0000, reward_err: 0.0104, 0.0143, 0.0002, KL_dist: 0.6860, 0.3211, 0.6787, param: [5.46517718 8.20663646 5.36406301 8.99920518], weights: [0.22434865 0.24137237 0.53427898], train_wt_loss:  36.4938, val_wt_loss: 37.3628, train_grp_loss: [11.80588417 13.13231195 10.64207609], val_grp_loss: [12.70800076 12.5192812  12.13477578], train_hist_grp_loss: [17.16130165 18.98978919 38.85422203], cur_train_grp_loss: [0.09444893 0.10505221 0.2128544 ], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6860, max_kl_dist_index: 0, max_train_grp_loss:  13.1323, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7080, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2129, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:02:42,866 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  181, train_loss:  12.1647, val_loss:  12.4545, grad_norm: 0.0269, live_grad: 0.0000, reward_err: 0.0104, 0.0143, 0.0002, KL_dist: 0.6862, 0.3212, 0.6789, param: [5.46517401 8.20622078 5.36548972 9.00247494], weights: [0.22375822 0.24083934 0.53540244], train_wt_loss:  36.4942, val_wt_loss: 37.3636, train_grp_loss: [11.80564941 13.13310271 10.64143076], val_grp_loss: [12.70803108 12.52019471 12.1346448 ], train_hist_grp_loss: [17.25574872 19.09484769 39.06706355], cur_train_grp_loss: [0.09444707 0.1050585  0.21284152], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6862, max_kl_dist_index: 0, max_train_grp_loss:  13.1331, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7080, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2128, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:02:43,898 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  182, train_loss:  12.1648, val_loss:  12.4548, grad_norm: 0.0271, live_grad: 0.0000, reward_err: 0.0104, 0.0143, 0.0002, KL_dist: 0.6864, 0.3213, 0.6791, param: [5.46516917 8.20580561 5.36691879 9.00575506], weights: [0.22316824 0.24030638 0.53652538], train_wt_loss:  36.4945, val_wt_loss: 37.3644, train_grp_loss: [11.80541249 13.13389899 10.64078417], val_grp_loss: [12.70805954 12.52111456 12.13451345], train_hist_grp_loss: [17.35019391 19.19991251 39.27989217], cur_train_grp_loss: [0.0944452  0.10506482 0.21282862], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6864, max_kl_dist_index: 0, max_train_grp_loss:  13.1339, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7081, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2128, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:02:44,941 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  183, train_loss:  12.1650, val_loss:  12.4551, grad_norm: 0.0274, live_grad: 0.0000, reward_err: 0.0104, 0.0143, 0.0002, KL_dist: 0.6866, 0.3214, 0.6793, param: [5.46516267 8.20539092 5.36835022 9.00904555], weights: [0.22257872 0.23977349 0.53764778], train_wt_loss:  36.4949, val_wt_loss: 37.3653, train_grp_loss: [11.80517343 13.13470079 10.64013631], val_grp_loss: [12.70808616 12.52204075 12.13438174], train_hist_grp_loss: [17.44463721 19.3049837  39.49270785], cur_train_grp_loss: [0.0944433  0.10507119 0.21281568], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6866, max_kl_dist_index: 0, max_train_grp_loss:  13.1347, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7081, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2128, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:02:46,006 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  184, train_loss:  12.1651, val_loss:  12.4554, grad_norm: 0.0276, live_grad: 0.0000, reward_err: 0.0104, 0.0143, 0.0002, KL_dist: 0.6868, 0.3216, 0.6796, param: [5.4651545  8.2049767  5.36978402 9.01234639], weights: [0.22198966 0.23924069 0.53876964], train_wt_loss:  36.4953, val_wt_loss: 37.3661, train_grp_loss: [11.80493224 13.1355081  10.63948719], val_grp_loss: [12.70811094 12.52297328 12.13424968], train_hist_grp_loss: [17.5390786  19.41006131 39.70551058], cur_train_grp_loss: [0.09444139 0.10507761 0.21280273], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6868, max_kl_dist_index: 0, max_train_grp_loss:  13.1355, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7081, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2128, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:02:47,054 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  185, train_loss:  12.1652, val_loss:  12.4556, grad_norm: 0.0278, live_grad: 0.0000, reward_err: 0.0104, 0.0143, 0.0002, KL_dist: 0.6871, 0.3217, 0.6798, param: [5.46514465 8.20456295 5.37122017 9.01565759], weights: [0.22140107 0.23870798 0.53989094], train_wt_loss:  36.4957, val_wt_loss: 37.3669, train_grp_loss: [11.80468893 13.13632094 10.63883683], val_grp_loss: [12.70813388 12.52391214 12.13411728], train_hist_grp_loss: [17.63351806 19.51514537 39.91830032], cur_train_grp_loss: [0.09443946 0.10508406 0.21278974], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6871, max_kl_dist_index: 0, max_train_grp_loss:  13.1363, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7081, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2128, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:02:48,110 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  186, train_loss:  12.1654, val_loss:  12.4559, grad_norm: 0.0281, live_grad: 0.0000, reward_err: 0.0104, 0.0143, 0.0002, KL_dist: 0.6873, 0.3218, 0.6800, param: [5.46513313 8.20414963 5.37265868 9.01897914], weights: [0.22081296 0.23817536 0.54101168], train_wt_loss:  36.4961, val_wt_loss: 37.3678, train_grp_loss: [11.80444352 13.13713929 10.63818521], val_grp_loss: [12.70815501 12.52485735 12.13398455], train_hist_grp_loss: [17.72795557 19.62023594 40.13107706], cur_train_grp_loss: [0.09443751 0.10509057 0.21277674], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6873, max_kl_dist_index: 0, max_train_grp_loss:  13.1371, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7082, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2128, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:02:49,158 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  187, train_loss:  12.1655, val_loss:  12.4562, grad_norm: 0.0283, live_grad: 0.0000, reward_err: 0.0104, 0.0143, 0.0002, KL_dist: 0.6875, 0.3219, 0.6803, param: [5.46511992 8.20373674 5.37409954 9.02231103], weights: [0.22022532 0.23764285 0.54213183], train_wt_loss:  36.4965, val_wt_loss: 37.3686, train_grp_loss: [11.80419601 13.13796315 10.63753237], val_grp_loss: [12.70817433 12.5258089  12.13385149], train_hist_grp_loss: [17.82239112 19.72533305 40.34384076], cur_train_grp_loss: [0.09443555 0.10509711 0.2127637 ], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6875, max_kl_dist_index: 0, max_train_grp_loss:  13.1380, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7082, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2128, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:02:50,222 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  188, train_loss:  12.1656, val_loss:  12.4565, grad_norm: 0.0286, live_grad: 0.0000, reward_err: 0.0104, 0.0143, 0.0002, KL_dist: 0.6877, 0.3221, 0.6805, param: [5.46510504 8.20332427 5.37554275 9.02565327], weights: [0.21963817 0.23711043 0.54325139], train_wt_loss:  36.4969, val_wt_loss: 37.3694, train_grp_loss: [11.80394643 13.13879254 10.63687829], val_grp_loss: [12.70819184 12.52676678 12.13371811], train_hist_grp_loss: [17.91682469 19.83043676 40.55659141], cur_train_grp_loss: [0.09443357 0.10510371 0.21275065], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6877, max_kl_dist_index: 0, max_train_grp_loss:  13.1388, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7082, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2128, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:02:51,259 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  189, train_loss:  12.1658, val_loss:  12.4568, grad_norm: 0.0288, live_grad: 0.0000, reward_err: 0.0104, 0.0143, 0.0002, KL_dist: 0.6880, 0.3222, 0.6807, param: [5.46508846 8.20291219 5.37698831 9.02900585], weights: [0.21905151 0.23657814 0.54437035], train_wt_loss:  36.4973, val_wt_loss: 37.3703, train_grp_loss: [11.80369478 13.13962744 10.63622299], val_grp_loss: [12.70820756 12.52773101 12.13358443], train_hist_grp_loss: [18.01125626 19.9355471  40.76932898], cur_train_grp_loss: [0.09443157 0.10511034 0.21273757], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6880, max_kl_dist_index: 0, max_train_grp_loss:  13.1396, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7082, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2127, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:02:52,315 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  190, train_loss:  12.1659, val_loss:  12.4570, grad_norm: 0.0291, live_grad: 0.0000, reward_err: 0.0104, 0.0143, 0.0002, KL_dist: 0.6882, 0.3223, 0.6810, param: [5.46507019 8.20250049 5.37843622 9.03236876], weights: [0.21846534 0.23604596 0.5454887 ], train_wt_loss:  36.4977, val_wt_loss: 37.3711, train_grp_loss: [11.80344108 13.14046785 10.63556648], val_grp_loss: [12.70822149 12.52870157 12.13345046], train_hist_grp_loss: [18.10568582 20.04066412 40.98205344], cur_train_grp_loss: [0.09442956 0.10511702 0.21272446], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6882, max_kl_dist_index: 0, max_train_grp_loss:  13.1405, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7082, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2127, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:02:53,368 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  191, train_loss:  12.1660, val_loss:  12.4573, grad_norm: 0.0293, live_grad: 0.0000, reward_err: 0.0104, 0.0143, 0.0002, KL_dist: 0.6884, 0.3224, 0.6812, param: [5.46505024 8.20208917 5.37988648 9.035742  ], weights: [0.21787968 0.2355139  0.54660642], train_wt_loss:  36.4981, val_wt_loss: 37.3720, train_grp_loss: [11.80318534 13.14131378 10.63490877], val_grp_loss: [12.70823366 12.52967848 12.13331619], train_hist_grp_loss: [18.20011335 20.14578786 41.19476477], cur_train_grp_loss: [0.09442753 0.10512374 0.21271133], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6884, max_kl_dist_index: 0, max_train_grp_loss:  13.1413, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7082, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2127, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:02:54,398 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  192, train_loss:  12.1662, val_loss:  12.4576, grad_norm: 0.0296, live_grad: 0.0000, reward_err: 0.0104, 0.0143, 0.0002, KL_dist: 0.6886, 0.3225, 0.6814, param: [5.46502858 8.2016782  5.38133908 9.03912557], weights: [0.21729451 0.23498198 0.54772351], train_wt_loss:  36.4985, val_wt_loss: 37.3728, train_grp_loss: [11.80292757 13.14216523 10.63424985], val_grp_loss: [12.70824405 12.53066173 12.13318165], train_hist_grp_loss: [18.29453883 20.25091837 41.40746294], cur_train_grp_loss: [0.09442548 0.10513051 0.21269818], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6886, max_kl_dist_index: 0, max_train_grp_loss:  13.1422, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7082, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2127, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:02:55,426 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  193, train_loss:  12.1663, val_loss:  12.4579, grad_norm: 0.0298, live_grad: 0.0000, reward_err: 0.0104, 0.0143, 0.0002, KL_dist: 0.6889, 0.3227, 0.6817, param: [5.46500522 8.20126756 5.38279401 9.04251945], weights: [0.21670986 0.23445019 0.54883994], train_wt_loss:  36.4989, val_wt_loss: 37.3737, train_grp_loss: [11.80266779 13.14302218 10.63358975], val_grp_loss: [12.7082527  12.53165132 12.13304683], train_hist_grp_loss: [18.38896225 20.35605569 41.62014794], cur_train_grp_loss: [0.09442342 0.10513732 0.212685  ], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6889, max_kl_dist_index: 0, max_train_grp_loss:  13.1430, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7083, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2127, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:02:56,472 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  194, train_loss:  12.1664, val_loss:  12.4582, grad_norm: 0.0301, live_grad: 0.0000, reward_err: 0.0102, 0.0143, 0.0001, KL_dist: 0.6891, 0.3228, 0.6819, param: [5.46498016 8.20085725 5.38425129 9.04592365], weights: [0.21612573 0.23391855 0.54995572], train_wt_loss:  36.4993, val_wt_loss: 37.3746, train_grp_loss: [11.80240602 13.14388465 10.63292846], val_grp_loss: [12.70825959 12.53264724 12.13291175], train_hist_grp_loss: [18.48338359 20.46119987 41.83281973], cur_train_grp_loss: [0.09442134 0.10514418 0.2126718 ], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6891, max_kl_dist_index: 0, max_train_grp_loss:  13.1439, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7083, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2127, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:02:57,532 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  195, train_loss:  12.1666, val_loss:  12.4585, grad_norm: 0.0303, live_grad: 0.0000, reward_err: 0.0102, 0.0143, 0.0001, KL_dist: 0.6893, 0.3229, 0.6821, param: [5.46495339 8.20044724 5.3857109  9.04933816], weights: [0.21554212 0.23338705 0.55107083], train_wt_loss:  36.4998, val_wt_loss: 37.3754, train_grp_loss: [11.80214226 13.14475263 10.632266  ], val_grp_loss: [12.70826475 12.53364951 12.13277642], train_hist_grp_loss: [18.57780284 20.56635095 42.0454783 ], cur_train_grp_loss: [0.09441925 0.10515108 0.21265857], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6893, max_kl_dist_index: 0, max_train_grp_loss:  13.1448, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7083, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2127, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:02:58,577 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  196, train_loss:  12.1667, val_loss:  12.4588, grad_norm: 0.0306, live_grad: 0.0000, reward_err: 0.0102, 0.0143, 0.0001, KL_dist: 0.6895, 0.3230, 0.6824, param: [5.46492492 8.20003753 5.38717284 9.05276297], weights: [0.21495903 0.23285571 0.55218526], train_wt_loss:  36.5002, val_wt_loss: 37.3763, train_grp_loss: [11.80187653 13.14562612 10.63160238], val_grp_loss: [12.70826819 12.53465812 12.13264085], train_hist_grp_loss: [18.67221998 20.67150897 42.25812362], cur_train_grp_loss: [0.09441714 0.10515802 0.21264532], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6895, max_kl_dist_index: 0, max_train_grp_loss:  13.1456, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7083, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2126, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:02:59,640 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  197, train_loss:  12.1669, val_loss:  12.4591, grad_norm: 0.0308, live_grad: 0.0000, reward_err: 0.0102, 0.0143, 0.0001, KL_dist: 0.6898, 0.3232, 0.6826, param: [5.46489473 8.1996281  5.38863711 9.05619808], weights: [0.21437647 0.23232454 0.55329899], train_wt_loss:  36.5006, val_wt_loss: 37.3772, train_grp_loss: [11.80160884 13.14650512 10.63093759], val_grp_loss: [12.7082699  12.53567307 12.13250504], train_hist_grp_loss: [18.76663499 20.77667398 42.47075567], cur_train_grp_loss: [0.09441501 0.10516501 0.21263205], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6898, max_kl_dist_index: 0, max_train_grp_loss:  13.1465, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7083, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2126, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:03:00,677 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  198, train_loss:  12.1670, val_loss:  12.4594, grad_norm: 0.0311, live_grad: 0.0000, reward_err: 0.0102, 0.0143, 0.0001, KL_dist: 0.6900, 0.3233, 0.6829, param: [5.46486282 8.19921892 5.39010371 9.05964348], weights: [0.21379446 0.23179352 0.55441202], train_wt_loss:  36.5010, val_wt_loss: 37.3781, train_grp_loss: [11.8013392  13.14738963 10.63027166], val_grp_loss: [12.70826991 12.53669435 12.13236901], train_hist_grp_loss: [18.86104786 20.88184602 42.68337442], cur_train_grp_loss: [0.09441287 0.10517204 0.21261875], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6900, max_kl_dist_index: 0, max_train_grp_loss:  13.1474, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7083, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2126, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:03:01,765 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  199, train_loss:  12.1672, val_loss:  12.4597, grad_norm: 0.0313, live_grad: 0.0000, reward_err: 0.0102, 0.0143, 0.0001, KL_dist: 0.6902, 0.3234, 0.6831, param: [5.4648292  8.19881    5.39157263 9.06309917], weights: [0.21321298 0.23126269 0.55552434], train_wt_loss:  36.5015, val_wt_loss: 37.3790, train_grp_loss: [11.80106764 13.14827964 10.62960458], val_grp_loss: [12.70826822 12.53772198 12.13223277], train_hist_grp_loss: [18.95545857 20.98702514 42.89597986], cur_train_grp_loss: [0.09441071 0.10517912 0.21260543], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6902, max_kl_dist_index: 0, max_train_grp_loss:  13.1483, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7083, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2126, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:03:02,721 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1654] - INFO: Iteration:  199, train_loss:  12.1672, val_loss:  12.4597, grad_norm: 0.0313,  live_grad: 0.0000, reward_err: 0.0102, 0.0143, 0.0001, KL_dist: 0.6902, 0.3234, 0.6831, param: [5.4648292  8.19881    5.39157263 9.06309917], weights: [0.21321298 0.23126269 0.55552434], train_wt_loss:  36.5015, val_wt_loss: 37.3790, train_grp_loss: [11.80106764 13.14827964 10.62960458], val_grp_loss: [12.70826822 12.53772198 12.13223277], train_hist_grp_loss: [18.95545857 20.98702514 42.89597986], cur_train_grp_loss: [0.09441071 0.10517912 0.21260543], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6902, max_kl_dist_index: 0, max_train_grp_loss:  13.1483, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7083, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2126, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:03:02,955 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:388] - INFO: Policy parameter learned solely on the preference data rdpo: [5.4648292  8.19881    5.39157263 9.06309917].
2024-10-07 01:03:03,317 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Uniform reward: 3.8318, 3.8318, 3.1647
2024-10-07 01:03:03,318 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Optimal reward: 3.8678, 7.2446, 3.2763
2024-10-07 01:03:03,318 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Policy reward: 3.8283, 7.1412, 3.2758
2024-10-07 01:03:03,319 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:402] - INFO: Reward Error: 0.0102, 0.0143, 0.0001
2024-10-07 01:03:04,035 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:417] - INFO: Optimal reward: 3.8678, 7.2446, 3.2763
Known param reward: [[3.867779541015625, 6.77779443359375, 3.255072021484375], [3.441058349609375, 7.24455908203125, 3.05710986328125], [3.841189453125, 7.1339345703125, 3.27631982421875]], Known param reward error: [[0.0, 0.06442968345654335, 0.0064852651372159075], [0.11032717529039895, 0.0, 0.06690737556116683], [0.006874768225192712, 0.015270013049259644, 0.0]].
