2024-10-07 00:30:43,215 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log-hyperparam-search/2024_10_07_00_27_03/rdpo,0.1,0.1,0.01,2022
2024-10-07 00:30:43,217 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2022
2024-10-07 00:30:43,218 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-10-07 00:30:43,308 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.3214, l2 distance: 25.6155, acc: 0.89.
2024-10-07 00:30:43,309 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-10-07 00:30:43,310 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [ 4.91492317 13.51244723  6.71533233  9.49961375]
2024-10-07 00:30:43,525 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.8530, 6.9304, 3.3326
2024-10-07 00:30:43,757 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1314] - INFO: unique_group_ids: {0, 1, 2}
2024-10-07 00:30:45,027 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  0, train_loss:  13.4334, val_loss:  12.2618, grad_norm: 0.5704, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6505, 0.3478, 0.6807, param: [4.15112139 9.52389454 4.95553387 8.8558309 ], weights: [0.33300418 0.3330439  0.33395192], train_wt_loss:  40.3003, val_wt_loss: 36.7855, train_grp_loss: [11.73586405 15.89578613 11.15365364], val_grp_loss: [10.62097178 14.91008014 11.27026442], train_hist_grp_loss: [0.17243466 0.18436246 0.45663202], cur_train_grp_loss: [0.17243466 0.18436246 0.45663202], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6807, max_kl_dist_index: 2, max_train_grp_loss:  15.8958, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9101, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.4566, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:30:46,090 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  1, train_loss:  13.4334, val_loss:  12.2618, grad_norm: 0.0000, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6505, 0.3478, 0.6807, param: [4.15114364 9.52360181 4.95569255 8.85591503], weights: [0.33281382 0.33294866 0.33423752], train_wt_loss:  40.3003, val_wt_loss: 36.7854, train_grp_loss: [11.73604179 15.89559431 11.15371113], val_grp_loss: [10.62110705 14.90982261 11.27033487], train_hist_grp_loss: [0.26707873 0.30758561 0.6939438 ], cur_train_grp_loss: [0.09464406 0.12322315 0.23731178], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6807, max_kl_dist_index: 2, max_train_grp_loss:  15.8956, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9098, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2373, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:30:47,196 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  2, train_loss:  13.4334, val_loss:  12.2618, grad_norm: 0.0000, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6505, 0.3478, 0.6806, param: [4.15116566 9.52330958 4.95585107 8.85599968], weights: [0.33262344 0.33285331 0.33452325], train_wt_loss:  40.3003, val_wt_loss: 36.7854, train_grp_loss: [11.73621903 15.89540308 11.1537684 ], val_grp_loss: [10.62124187 14.90956595 11.27040515], train_hist_grp_loss: [0.36172422 0.43080727 0.93125681], cur_train_grp_loss: [0.0946455  0.12322166 0.237313  ], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6806, max_kl_dist_index: 2, max_train_grp_loss:  15.8954, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9096, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2373, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:30:48,290 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  3, train_loss:  13.4334, val_loss:  12.2618, grad_norm: 0.0000, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6505, 0.3478, 0.6806, param: [4.15118745 9.52301784 4.95600942 8.85608485], weights: [0.33243305 0.33275785 0.33480909], train_wt_loss:  40.3003, val_wt_loss: 36.7853, train_grp_loss: [11.73639576 15.89521243 11.15382545], val_grp_loss: [10.62137624 14.90931016 11.27047527], train_hist_grp_loss: [0.45637115 0.55402745 1.16857103], cur_train_grp_loss: [0.09464693 0.12322018 0.23731422], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6806, max_kl_dist_index: 2, max_train_grp_loss:  15.8952, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9093, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2373, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:30:49,457 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  4, train_loss:  13.4334, val_loss:  12.2618, grad_norm: 0.0000, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6505, 0.3478, 0.6806, param: [4.15120901 9.5227266  4.95616761 8.85617056], weights: [0.33224265 0.33266229 0.33509506], train_wt_loss:  40.3003, val_wt_loss: 36.7853, train_grp_loss: [11.736572   15.89502237 11.15388229], val_grp_loss: [10.62151017 14.90905525 11.27054523], train_hist_grp_loss: [0.55101951 0.67724615 1.40588646], cur_train_grp_loss: [0.09464835 0.1232187  0.23731544], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6806, max_kl_dist_index: 2, max_train_grp_loss:  15.8950, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9091, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2373, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:30:50,501 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  5, train_loss:  13.4334, val_loss:  12.2617, grad_norm: 0.0000, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6505, 0.3478, 0.6806, param: [4.15123033 9.52243586 4.95632562 8.85625678], weights: [0.33205223 0.33256663 0.33538114], train_wt_loss:  40.3003, val_wt_loss: 36.7852, train_grp_loss: [11.73674772 15.8948329  11.15393891], val_grp_loss: [10.62164365 14.90880122 11.27061502], train_hist_grp_loss: [0.64566928 0.80046338 1.64320311], cur_train_grp_loss: [0.09464977 0.12321723 0.23731664], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6806, max_kl_dist_index: 2, max_train_grp_loss:  15.8948, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9088, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2373, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:30:51,571 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  6, train_loss:  13.4334, val_loss:  12.2617, grad_norm: 0.0001, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6505, 0.3477, 0.6806, param: [4.15125143 9.52214562 4.95648347 8.85634354], weights: [0.3318618  0.33247086 0.33566734], train_wt_loss:  40.3003, val_wt_loss: 36.7852, train_grp_loss: [11.73692295 15.89464401 11.15399532], val_grp_loss: [10.62177668 14.90854806 11.27068464], train_hist_grp_loss: [0.74032047 0.92367914 1.88052096], cur_train_grp_loss: [0.09465119 0.12321576 0.23731785], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6806, max_kl_dist_index: 2, max_train_grp_loss:  15.8946, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9085, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2373, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:30:52,589 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  7, train_loss:  13.4334, val_loss:  12.2617, grad_norm: 0.0001, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6505, 0.3477, 0.6806, param: [4.15127229 9.52185587 4.95664115 8.85643082], weights: [0.33167135 0.33237498 0.33595367], train_wt_loss:  40.3003, val_wt_loss: 36.7851, train_grp_loss: [11.73709767 15.89445571 11.15405152], val_grp_loss: [10.62190927 14.90829578 11.27075411], train_hist_grp_loss: [0.83497308 1.04689343 2.11784001], cur_train_grp_loss: [0.0946526  0.12321429 0.23731905], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6806, max_kl_dist_index: 2, max_train_grp_loss:  15.8945, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9083, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2373, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:30:53,629 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  8, train_loss:  13.4334, val_loss:  12.2617, grad_norm: 0.0001, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6505, 0.3477, 0.6806, param: [4.15129292 9.52156663 4.95679866 8.85651863], weights: [0.3314809  0.332279   0.33624011], train_wt_loss:  40.3003, val_wt_loss: 36.7851, train_grp_loss: [11.73727188 15.894268   11.1541075 ], val_grp_loss: [10.62204141 14.90804438 11.2708234 ], train_hist_grp_loss: [0.92962709 1.17010627 2.35516025], cur_train_grp_loss: [0.09465401 0.12321283 0.23732025], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6806, max_kl_dist_index: 2, max_train_grp_loss:  15.8943, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9080, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2373, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:30:54,642 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  9, train_loss:  13.4334, val_loss:  12.2617, grad_norm: 0.0001, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6505, 0.3477, 0.6806, param: [4.15131332 9.52127788 4.95695601 8.85660697], weights: [0.33129042 0.33218291 0.33652667], train_wt_loss:  40.3003, val_wt_loss: 36.7850, train_grp_loss: [11.73744559 15.89408088 11.15416326], val_grp_loss: [10.6221731  14.90779385 11.27089254], train_hist_grp_loss: [1.02428251 1.29331765 2.59248169], cur_train_grp_loss: [0.09465542 0.12321138 0.23732144], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6806, max_kl_dist_index: 2, max_train_grp_loss:  15.8941, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9078, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2373, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:30:55,660 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  10, train_loss:  13.4334, val_loss:  12.2617, grad_norm: 0.0001, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6505, 0.3477, 0.6806, param: [4.15133349 9.52098963 4.95711318 8.85669583], weights: [0.33109994 0.33208672 0.33681334], train_wt_loss:  40.3003, val_wt_loss: 36.7850, train_grp_loss: [11.73761879 15.89389435 11.15421881], val_grp_loss: [10.62230435 14.90754421 11.2709615 ], train_hist_grp_loss: [1.11893933 1.41652758 2.82980431], cur_train_grp_loss: [0.09465682 0.12320993 0.23732262], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6806, max_kl_dist_index: 2, max_train_grp_loss:  15.8939, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9075, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2373, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:30:56,703 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  11, train_loss:  13.4334, val_loss:  12.2616, grad_norm: 0.0001, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6505, 0.3477, 0.6806, param: [4.15135343 9.52070188 4.95727019 8.85678522], weights: [0.33090944 0.33199042 0.33710014], train_wt_loss:  40.3003, val_wt_loss: 36.7849, train_grp_loss: [11.73779149 15.8937084  11.15427414], val_grp_loss: [10.62243515 14.90729544 11.27103031], train_hist_grp_loss: [1.21359754 1.53973606 3.06712811], cur_train_grp_loss: [0.09465822 0.12320848 0.2373238 ], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6806, max_kl_dist_index: 2, max_train_grp_loss:  15.8937, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9073, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2373, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:30:57,701 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  12, train_loss:  13.4334, val_loss:  12.2616, grad_norm: 0.0001, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6505, 0.3477, 0.6805, param: [4.15137314 9.52041463 4.95742703 8.85687514], weights: [0.33071892 0.33189402 0.33738706], train_wt_loss:  40.3003, val_wt_loss: 36.7849, train_grp_loss: [11.73796368 15.89352305 11.15432926], val_grp_loss: [10.6225655  14.90704755 11.27109895], train_hist_grp_loss: [1.30825715 1.6629431  3.3044531 ], cur_train_grp_loss: [0.09465961 0.12320704 0.23732498], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6805, max_kl_dist_index: 2, max_train_grp_loss:  15.8935, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9070, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2373, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:30:58,723 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  13, train_loss:  13.4334, val_loss:  12.2616, grad_norm: 0.0002, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6505, 0.3477, 0.6805, param: [4.15139261 9.52012788 4.9575837  8.85696559], weights: [0.3305284  0.33179751 0.33767409], train_wt_loss:  40.3003, val_wt_loss: 36.7848, train_grp_loss: [11.73813537 15.89333828 11.15438416], val_grp_loss: [10.62269541 14.90680053 11.27116742], train_hist_grp_loss: [1.40291815 1.78614871 3.54177925], cur_train_grp_loss: [0.094661   0.12320561 0.23732615], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6805, max_kl_dist_index: 2, max_train_grp_loss:  15.8933, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9068, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2373, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:30:59,771 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  14, train_loss:  13.4334, val_loss:  12.2616, grad_norm: 0.0002, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6505, 0.3477, 0.6805, param: [4.15141185 9.51984162 4.9577402  8.85705657], weights: [0.33033786 0.3317009  0.33796124], train_wt_loss:  40.3003, val_wt_loss: 36.7848, train_grp_loss: [11.73830655 15.8931541  11.15443884], val_grp_loss: [10.62282486 14.9065544  11.27123573], train_hist_grp_loss: [1.49758053 1.90935288 3.77910657], cur_train_grp_loss: [0.09466238 0.12320417 0.23732732], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6805, max_kl_dist_index: 2, max_train_grp_loss:  15.8932, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9066, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2373, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:31:00,789 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  15, train_loss:  13.4334, val_loss:  12.2616, grad_norm: 0.0002, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6505, 0.3477, 0.6805, param: [4.15143086 9.51955587 4.95789654 8.85714808], weights: [0.33014731 0.33160419 0.33824851], train_wt_loss:  40.3003, val_wt_loss: 36.7847, train_grp_loss: [11.73847722 15.89297051 11.15449331], val_grp_loss: [10.62295387 14.90630915 11.27130387], train_hist_grp_loss: [1.59224429 2.03255562 4.01643506], cur_train_grp_loss: [0.09466376 0.12320274 0.23732849], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6805, max_kl_dist_index: 2, max_train_grp_loss:  15.8930, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9063, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2373, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:31:01,817 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  16, train_loss:  13.4334, val_loss:  12.2616, grad_norm: 0.0002, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6505, 0.3477, 0.6805, param: [4.15144964 9.51927062 4.9580527  8.85724011], weights: [0.32995674 0.33150737 0.33853589], train_wt_loss:  40.3003, val_wt_loss: 36.7847, train_grp_loss: [11.73864739 15.8927875  11.15454756], val_grp_loss: [10.62308243 14.90606477 11.27137184], train_hist_grp_loss: [1.68690943 2.15575695 4.2537647 ], cur_train_grp_loss: [0.09466514 0.12320132 0.23732964], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6805, max_kl_dist_index: 2, max_train_grp_loss:  15.8928, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9061, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2373, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:31:02,850 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  17, train_loss:  13.4334, val_loss:  12.2615, grad_norm: 0.0002, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6505, 0.3477, 0.6805, param: [4.15146819 9.51898586 4.9582087  8.85733268], weights: [0.32976616 0.33141044 0.33882339], train_wt_loss:  40.3003, val_wt_loss: 36.7846, train_grp_loss: [11.73881705 15.89260509 11.1546016 ], val_grp_loss: [10.62321054 14.90582127 11.27143965], train_hist_grp_loss: [1.78157594 2.27895685 4.4910955 ], cur_train_grp_loss: [0.09466651 0.1231999  0.2373308 ], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6805, max_kl_dist_index: 2, max_train_grp_loss:  15.8926, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9058, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2373, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:31:03,898 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  18, train_loss:  13.4334, val_loss:  12.2615, grad_norm: 0.0002, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6504, 0.3477, 0.6805, param: [4.1514865  9.51870161 4.95836452 8.85742577], weights: [0.32957557 0.33131342 0.33911101], train_wt_loss:  40.3003, val_wt_loss: 36.7846, train_grp_loss: [11.7389862  15.89242327 11.15465541], val_grp_loss: [10.6233382  14.90557866 11.2715073 ], train_hist_grp_loss: [1.87624382 2.40215534 4.72842745], cur_train_grp_loss: [0.09466788 0.12319849 0.23733195], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6805, max_kl_dist_index: 2, max_train_grp_loss:  15.8924, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9056, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2373, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:31:04,918 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  19, train_loss:  13.4334, val_loss:  12.2615, grad_norm: 0.0002, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6504, 0.3476, 0.6805, param: [4.15150458 9.51841785 4.95852018 8.8575194 ], weights: [0.32938497 0.33121628 0.33939875], train_wt_loss:  40.3003, val_wt_loss: 36.7845, train_grp_loss: [11.73915484 15.89224203 11.15470901], val_grp_loss: [10.62346541 14.90533692 11.27157478], train_hist_grp_loss: [1.97091307 2.52535242 4.96576055], cur_train_grp_loss: [0.09466924 0.12319708 0.23733309], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6805, max_kl_dist_index: 2, max_train_grp_loss:  15.8922, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9053, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2373, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:31:05,998 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  20, train_loss:  13.4334, val_loss:  12.2615, grad_norm: 0.0003, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6504, 0.3476, 0.6805, param: [4.15152243 9.51813459 4.95867567 8.85761355], weights: [0.32919435 0.33111904 0.3396866 ], train_wt_loss:  40.3003, val_wt_loss: 36.7845, train_grp_loss: [11.73932298 15.89206139 11.1547624 ], val_grp_loss: [10.62359217 14.90509607 11.27164209], train_hist_grp_loss: [2.06558367 2.64854809 5.20309478], cur_train_grp_loss: [0.0946706  0.12319567 0.23733423], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6805, max_kl_dist_index: 2, max_train_grp_loss:  15.8921, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9051, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2373, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:31:07,040 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  21, train_loss:  13.4334, val_loss:  12.2615, grad_norm: 0.0003, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6504, 0.3476, 0.6805, param: [4.15154005 9.51785184 4.95883099 8.85770824], weights: [0.32900373 0.3310217  0.33997457], train_wt_loss:  40.3003, val_wt_loss: 36.7845, train_grp_loss: [11.7394906  15.89188134 11.15481557], val_grp_loss: [10.62371848 14.9048561  11.27170924], train_hist_grp_loss: [2.16025563 2.77174237 5.44043015], cur_train_grp_loss: [0.09467196 0.12319427 0.23733537], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6805, max_kl_dist_index: 2, max_train_grp_loss:  15.8919, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9049, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2373, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:31:08,042 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  22, train_loss:  13.4334, val_loss:  12.2615, grad_norm: 0.0003, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6504, 0.3476, 0.6805, param: [4.15155743 9.51756958 4.95898614 8.85780346], weights: [0.32881309 0.33092426 0.34026266], train_wt_loss:  40.3003, val_wt_loss: 36.7844, train_grp_loss: [11.73965772 15.89170187 11.15486851], val_grp_loss: [10.62384434 14.904617   11.27177621], train_hist_grp_loss: [2.25492894 2.89493524 5.67776665], cur_train_grp_loss: [0.09467331 0.12319288 0.2373365 ], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6805, max_kl_dist_index: 2, max_train_grp_loss:  15.8917, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9046, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2373, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:31:09,064 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  23, train_loss:  13.4334, val_loss:  12.2615, grad_norm: 0.0003, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6504, 0.3476, 0.6805, param: [4.15157459 9.51728783 4.95914112 8.8578992 ], weights: [0.32862243 0.33082671 0.34055086], train_wt_loss:  40.3003, val_wt_loss: 36.7844, train_grp_loss: [11.73982433 15.891523   11.15492125], val_grp_loss: [10.62396976 14.90437879 11.27184303], train_hist_grp_loss: [2.3496036  3.01812673 5.91510428], cur_train_grp_loss: [0.09467466 0.12319149 0.23733763], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6805, max_kl_dist_index: 2, max_train_grp_loss:  15.8915, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9044, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2373, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:31:10,080 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  24, train_loss:  13.4334, val_loss:  12.2614, grad_norm: 0.0003, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6504, 0.3476, 0.6804, param: [4.15159151 9.51700657 4.95929593 8.85799548], weights: [0.32843177 0.33072906 0.34083918], train_wt_loss:  40.3003, val_wt_loss: 36.7843, train_grp_loss: [11.73999043 15.89134472 11.15497376], val_grp_loss: [10.62409472 14.90414147 11.27190967], train_hist_grp_loss: [2.4442796  3.14131683 6.15244303], cur_train_grp_loss: [0.094676   0.1231901  0.23733875], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6804, max_kl_dist_index: 2, max_train_grp_loss:  15.8913, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9041, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2373, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:31:11,094 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  25, train_loss:  13.4334, val_loss:  12.2614, grad_norm: 0.0003, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6504, 0.3476, 0.6804, param: [4.1516082  9.51672582 4.95945057 8.85809229], weights: [0.32824109 0.3306313  0.34112761], train_wt_loss:  40.3003, val_wt_loss: 36.7843, train_grp_loss: [11.74015602 15.89116703 11.15502606], val_grp_loss: [10.62421923 14.90390502 11.27197615], train_hist_grp_loss: [2.53895694 3.26450555 6.3897829 ], cur_train_grp_loss: [0.09467734 0.12318872 0.23733987], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6804, max_kl_dist_index: 2, max_train_grp_loss:  15.8912, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9039, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2373, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:31:12,128 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  26, train_loss:  13.4334, val_loss:  12.2614, grad_norm: 0.0003, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6504, 0.3476, 0.6804, param: [4.15162465 9.51644556 4.95960504 8.85818964], weights: [0.3280504  0.33053344 0.34141616], train_wt_loss:  40.3003, val_wt_loss: 36.7842, train_grp_loss: [11.7403211  15.89098992 11.15507814], val_grp_loss: [10.62434329 14.90366945 11.27204247], train_hist_grp_loss: [2.63363562 3.38769289 6.62712388], cur_train_grp_loss: [0.09467868 0.12318734 0.23734098], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6804, max_kl_dist_index: 2, max_train_grp_loss:  15.8910, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9037, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2373, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:31:13,134 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  27, train_loss:  13.4334, val_loss:  12.2614, grad_norm: 0.0004, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6504, 0.3476, 0.6804, param: [4.15164087 9.51616581 4.95975935 8.85828751], weights: [0.3278597  0.33043548 0.34170482], train_wt_loss:  40.3003, val_wt_loss: 36.7842, train_grp_loss: [11.74048567 15.89081341 11.15513   ], val_grp_loss: [10.6244669  14.90343477 11.27210861], train_hist_grp_loss: [2.72831563 3.51087886 6.86446596], cur_train_grp_loss: [0.09468001 0.12318597 0.23734209], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6804, max_kl_dist_index: 2, max_train_grp_loss:  15.8908, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9034, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2373, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:31:14,183 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  28, train_loss:  13.4334, val_loss:  12.2614, grad_norm: 0.0004, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6504, 0.3476, 0.6804, param: [4.15165687 9.51588656 4.95991348 8.85838592], weights: [0.32766899 0.33033741 0.3419936 ], train_wt_loss:  40.3003, val_wt_loss: 36.7841, train_grp_loss: [11.74064973 15.8906375  11.15518164], val_grp_loss: [10.62459006 14.90320097 11.27217459], train_hist_grp_loss: [2.82299697 3.63406346 7.10180916], cur_train_grp_loss: [0.09468134 0.1231846  0.23734319], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6804, max_kl_dist_index: 2, max_train_grp_loss:  15.8906, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9032, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2373, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:31:15,222 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  29, train_loss:  13.4334, val_loss:  12.2614, grad_norm: 0.0004, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6504, 0.3476, 0.6804, param: [4.15167262 9.51560781 4.96006744 8.85848486], weights: [0.32747826 0.33023924 0.3422825 ], train_wt_loss:  40.3003, val_wt_loss: 36.7841, train_grp_loss: [11.74081329 15.89046217 11.15523307], val_grp_loss: [10.62471276 14.90296806 11.2722404 ], train_hist_grp_loss: [2.91767963 3.7572467  7.33915345], cur_train_grp_loss: [0.09468266 0.12318324 0.23734429], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6804, max_kl_dist_index: 2, max_train_grp_loss:  15.8905, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9030, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2373, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:31:16,247 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  30, train_loss:  13.4334, val_loss:  12.2614, grad_norm: 0.0004, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6504, 0.3476, 0.6804, param: [4.15168815 9.51532956 4.96022123 8.85858433], weights: [0.32728753 0.33014096 0.34257151], train_wt_loss:  40.3003, val_wt_loss: 36.7841, train_grp_loss: [11.74097633 15.89028743 11.15528427], val_grp_loss: [10.62483502 14.90273603 11.27230605], train_hist_grp_loss: [3.0123636  3.88042857 7.57649883], cur_train_grp_loss: [0.09468398 0.12318188 0.23734538], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6804, max_kl_dist_index: 2, max_train_grp_loss:  15.8903, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9027, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2373, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:31:17,291 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  31, train_loss:  13.4334, val_loss:  12.2613, grad_norm: 0.0004, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6504, 0.3476, 0.6804, param: [4.15170344 9.51505181 4.96037485 8.85868434], weights: [0.32709678 0.33004258 0.34286064], train_wt_loss:  40.3003, val_wt_loss: 36.7840, train_grp_loss: [11.74113886 15.89011329 11.15533526], val_grp_loss: [10.62495682 14.90250488 11.27237152], train_hist_grp_loss: [3.1070489 4.0036091 7.8138453], cur_train_grp_loss: [0.09468529 0.12318052 0.23734647], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6804, max_kl_dist_index: 2, max_train_grp_loss:  15.8901, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9025, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2373, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:31:18,314 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  32, train_loss:  13.4334, val_loss:  12.2613, grad_norm: 0.0004, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6504, 0.3476, 0.6804, param: [4.1517185  9.51477456 4.9605283  8.85878488], weights: [0.32690602 0.3299441  0.34314987], train_wt_loss:  40.3003, val_wt_loss: 36.7840, train_grp_loss: [11.74130087 15.88993973 11.15538603], val_grp_loss: [10.62507817 14.90227461 11.27243683], train_hist_grp_loss: [3.2017355  4.12678827 8.05119286], cur_train_grp_loss: [0.0946866  0.12317917 0.23734756], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6804, max_kl_dist_index: 2, max_train_grp_loss:  15.8899, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9023, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2373, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:31:19,323 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  33, train_loss:  13.4334, val_loss:  12.2613, grad_norm: 0.0004, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6504, 0.3476, 0.6804, param: [4.15173333 9.51449782 4.96068158 8.85888596], weights: [0.32671525 0.32984552 0.34343923], train_wt_loss:  40.3003, val_wt_loss: 36.7839, train_grp_loss: [11.74146238 15.88976677 11.15543658], val_grp_loss: [10.62519907 14.90204523 11.27250197], train_hist_grp_loss: [3.29642341 4.2499661  8.2885415 ], cur_train_grp_loss: [0.09468791 0.12317783 0.23734864], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6804, max_kl_dist_index: 2, max_train_grp_loss:  15.8898, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9020, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2373, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:31:20,363 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  34, train_loss:  13.4334, val_loss:  12.2613, grad_norm: 0.0005, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6504, 0.3475, 0.6804, param: [4.15174792 9.51422157 4.96083469 8.85898756], weights: [0.32652447 0.32974683 0.3437287 ], train_wt_loss:  40.3003, val_wt_loss: 36.7839, train_grp_loss: [11.74162337 15.8895944  11.15548691], val_grp_loss: [10.62531952 14.90181674 11.27256695], train_hist_grp_loss: [3.39111262 4.37314258 8.52589122], cur_train_grp_loss: [0.09468921 0.12317649 0.23734971], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6804, max_kl_dist_index: 2, max_train_grp_loss:  15.8896, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9018, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2373, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:31:21,411 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  35, train_loss:  13.4334, val_loss:  12.2613, grad_norm: 0.0005, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6504, 0.3475, 0.6804, param: [4.15176228 9.51394583 4.96098763 8.85908971], weights: [0.32633368 0.32964804 0.34401828], train_wt_loss:  40.3003, val_wt_loss: 36.7839, train_grp_loss: [11.74178386 15.88942263 11.15553702], val_grp_loss: [10.62543951 14.90158913 11.27263175], train_hist_grp_loss: [3.48580313 4.49631773 8.763242  ], cur_train_grp_loss: [0.09469051 0.12317515 0.23735079], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6804, max_kl_dist_index: 2, max_train_grp_loss:  15.8894, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9016, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:31:22,424 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  36, train_loss:  13.4334, val_loss:  12.2613, grad_norm: 0.0005, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6504, 0.3475, 0.6804, param: [4.15177641 9.51367059 4.9611404  8.85919238], weights: [0.32614287 0.32954915 0.34430798], train_wt_loss:  40.3003, val_wt_loss: 36.7838, train_grp_loss: [11.74194383 15.88925144 11.15558692], val_grp_loss: [10.62555905 14.9013624  11.27269639], train_hist_grp_loss: [3.58049494 4.61949155 9.00059385], cur_train_grp_loss: [0.09469181 0.12317382 0.23735185], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6804, max_kl_dist_index: 2, max_train_grp_loss:  15.8893, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9014, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:31:23,472 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  37, train_loss:  13.4334, val_loss:  12.2613, grad_norm: 0.0005, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6504, 0.3475, 0.6803, param: [4.1517903  9.51339585 4.96129299 8.8592956 ], weights: [0.32595206 0.32945016 0.34459779], train_wt_loss:  40.3003, val_wt_loss: 36.7838, train_grp_loss: [11.74210329 15.88908085 11.15563659], val_grp_loss: [10.62567813 14.90113656 11.27276086], train_hist_grp_loss: [3.67518804 4.74266405 9.23794677], cur_train_grp_loss: [0.0946931  0.12317249 0.23735291], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6803, max_kl_dist_index: 2, max_train_grp_loss:  15.8891, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9011, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:31:24,495 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  38, train_loss:  13.4334, val_loss:  12.2612, grad_norm: 0.0005, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6504, 0.3475, 0.6803, param: [4.15180397 9.51312161 4.96144542 8.85939934], weights: [0.32576123 0.32935106 0.34488771], train_wt_loss:  40.3003, val_wt_loss: 36.7837, train_grp_loss: [11.74226223 15.88891085 11.15568604], val_grp_loss: [10.62579677 14.90091161 11.27282516], train_hist_grp_loss: [3.76988242 4.86583521 9.47530074], cur_train_grp_loss: [0.09469438 0.12317117 0.23735397], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6803, max_kl_dist_index: 2, max_train_grp_loss:  15.8889, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9009, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:31:25,503 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  39, train_loss:  13.4334, val_loss:  12.2612, grad_norm: 0.0005, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6504, 0.3475, 0.6803, param: [4.15181739 9.51284788 4.96159767 8.85950363], weights: [0.3255704  0.32925186 0.34517775], train_wt_loss:  40.3003, val_wt_loss: 36.7837, train_grp_loss: [11.74242067 15.88874145 11.15573528], val_grp_loss: [10.62591495 14.90068754 11.27288929], train_hist_grp_loss: [3.86457808 4.98900507 9.71265576], cur_train_grp_loss: [0.09469566 0.12316985 0.23735502], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6803, max_kl_dist_index: 2, max_train_grp_loss:  15.8887, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9007, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:31:26,550 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  40, train_loss:  13.4334, val_loss:  12.2612, grad_norm: 0.0005, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6504, 0.3475, 0.6803, param: [4.15183059 9.51257465 4.96174976 8.85960844], weights: [0.32537955 0.32915255 0.3454679 ], train_wt_loss:  40.3003, val_wt_loss: 36.7836, train_grp_loss: [11.74257858 15.88857264 11.15578429], val_grp_loss: [10.62603267 14.90046436 11.27295326], train_hist_grp_loss: [3.95927502 5.1121736  9.95001183], cur_train_grp_loss: [0.09469694 0.12316854 0.23735607], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6803, max_kl_dist_index: 2, max_train_grp_loss:  15.8886, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9005, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:31:27,570 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  41, train_loss:  13.4334, val_loss:  12.2612, grad_norm: 0.0006, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6504, 0.3475, 0.6803, param: [4.15184355 9.51230192 4.96190167 8.8597138 ], weights: [0.32518869 0.32905315 0.34575816], train_wt_loss:  40.3003, val_wt_loss: 36.7836, train_grp_loss: [11.74273599 15.88840442 11.15583309], val_grp_loss: [10.62614995 14.90024207 11.27301705], train_hist_grp_loss: [ 4.05397324  5.23534083 10.18736894], cur_train_grp_loss: [0.09469821 0.12316723 0.23735711], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6803, max_kl_dist_index: 2, max_train_grp_loss:  15.8884, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9002, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:31:28,601 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  42, train_loss:  13.4334, val_loss:  12.2612, grad_norm: 0.0006, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6504, 0.3475, 0.6803, param: [4.15185628 9.51202969 4.96205341 8.85981969], weights: [0.32499783 0.32895364 0.34604853], train_wt_loss:  40.3003, val_wt_loss: 36.7836, train_grp_loss: [11.74289288 15.88823679 11.15588166], val_grp_loss: [10.62626676 14.90002066 11.27308068], train_hist_grp_loss: [ 4.14867272  5.35850676 10.42472709], cur_train_grp_loss: [0.09469948 0.12316593 0.23735815], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6803, max_kl_dist_index: 2, max_train_grp_loss:  15.8882, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9000, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:31:29,618 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  43, train_loss:  13.4334, val_loss:  12.2612, grad_norm: 0.0006, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6504, 0.3475, 0.6803, param: [4.15186877 9.51175796 4.96220498 8.85992611], weights: [0.32480695 0.32885403 0.34633902], train_wt_loss:  40.3003, val_wt_loss: 36.7835, train_grp_loss: [11.74304926 15.88806976 11.15593002], val_grp_loss: [10.62638313 14.89980014 11.27314414], train_hist_grp_loss: [ 4.24337347  5.48167139 10.66208628], cur_train_grp_loss: [0.09470075 0.12316463 0.23735918], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6803, max_kl_dist_index: 2, max_train_grp_loss:  15.8881, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8998, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:31:30,647 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  44, train_loss:  13.4334, val_loss:  12.2612, grad_norm: 0.0006, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6504, 0.3475, 0.6803, param: [4.15188104 9.51148674 4.96235638 8.86003308], weights: [0.32461606 0.32875432 0.34662962], train_wt_loss:  40.3003, val_wt_loss: 36.7835, train_grp_loss: [11.74320512 15.88790332 11.15597815], val_grp_loss: [10.62649903 14.89958051 11.27320742], train_hist_grp_loss: [ 4.33807548  5.60483472 10.89944649], cur_train_grp_loss: [0.09470201 0.12316333 0.23736021], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6803, max_kl_dist_index: 2, max_train_grp_loss:  15.8879, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8996, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:31:31,678 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  45, train_loss:  13.4334, val_loss:  12.2611, grad_norm: 0.0006, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6504, 0.3475, 0.6803, param: [4.15189306 9.51121602 4.9625076  8.86014058], weights: [0.32442516 0.3286545  0.34692033], train_wt_loss:  40.3003, val_wt_loss: 36.7834, train_grp_loss: [11.74336047 15.88773748 11.15602607], val_grp_loss: [10.62661449 14.89936176 11.27327054], train_hist_grp_loss: [ 4.43277875  5.72799676 11.13680773], cur_train_grp_loss: [0.09470327 0.12316204 0.23736124], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6803, max_kl_dist_index: 2, max_train_grp_loss:  15.8877, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8994, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:31:32,699 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  46, train_loss:  13.4334, val_loss:  12.2611, grad_norm: 0.0006, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6504, 0.3475, 0.6803, param: [4.15190486 9.51094581 4.96265866 8.86024862], weights: [0.32423425 0.32855459 0.34721116], train_wt_loss:  40.3003, val_wt_loss: 36.7834, train_grp_loss: [11.74351531 15.88757223 11.15607376], val_grp_loss: [10.62672949 14.8991439  11.27333349], train_hist_grp_loss: [ 4.52748327  5.85115751 11.37416998], cur_train_grp_loss: [0.09470452 0.12316076 0.23736226], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6803, max_kl_dist_index: 2, max_train_grp_loss:  15.8876, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8991, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:31:33,734 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  47, train_loss:  13.4334, val_loss:  12.2611, grad_norm: 0.0006, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6504, 0.3475, 0.6803, param: [4.15191642 9.5106761  4.96280954 8.86035719], weights: [0.32404333 0.32845457 0.3475021 ], train_wt_loss:  40.3003, val_wt_loss: 36.7834, train_grp_loss: [11.74366963 15.88740757 11.15612123], val_grp_loss: [10.62684403 14.89892694 11.27339627], train_hist_grp_loss: [ 4.62218903  5.97431699 11.61153325], cur_train_grp_loss: [0.09470577 0.12315947 0.23736327], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6803, max_kl_dist_index: 2, max_train_grp_loss:  15.8874, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8989, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:31:34,773 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  48, train_loss:  13.4334, val_loss:  12.2611, grad_norm: 0.0007, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6504, 0.3475, 0.6803, param: [4.15192774 9.51040689 4.96296025 8.8604663 ], weights: [0.32385241 0.32835445 0.34779314], train_wt_loss:  40.3003, val_wt_loss: 36.7833, train_grp_loss: [11.74382343 15.88724351 11.15616849], val_grp_loss: [10.62695812 14.89871086 11.27345889], train_hist_grp_loss: [ 4.71689605  6.09747519 11.84889754], cur_train_grp_loss: [0.09470701 0.1231582  0.23736428], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6803, max_kl_dist_index: 2, max_train_grp_loss:  15.8872, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8987, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:31:35,798 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  49, train_loss:  13.4334, val_loss:  12.2611, grad_norm: 0.0007, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6504, 0.3474, 0.6803, param: [4.15193884 9.51013818 4.96311078 8.86057595], weights: [0.32366147 0.32825423 0.3480843 ], train_wt_loss:  40.3003, val_wt_loss: 36.7833, train_grp_loss: [11.74397672 15.88708004 11.15621552], val_grp_loss: [10.62707175 14.89849566 11.27352133], train_hist_grp_loss: [ 4.8116043   6.22063211 12.08626282], cur_train_grp_loss: [0.09470825 0.12315693 0.23736529], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6803, max_kl_dist_index: 2, max_train_grp_loss:  15.8871, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8985, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:31:36,842 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  50, train_loss:  13.4334, val_loss:  12.2611, grad_norm: 0.0007, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6504, 0.3474, 0.6803, param: [4.1519497  9.50986998 4.96326115 8.86068614], weights: [0.32347052 0.32815391 0.34837557], train_wt_loss:  40.3003, val_wt_loss: 36.7833, train_grp_loss: [11.74412949 15.88691717 11.15626233], val_grp_loss: [10.62718493 14.89828136 11.2735836 ], train_hist_grp_loss: [ 4.90631379  6.34378777 12.32362911], cur_train_grp_loss: [0.09470949 0.12315566 0.23736629], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6803, max_kl_dist_index: 2, max_train_grp_loss:  15.8869, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8983, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:31:37,852 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  51, train_loss:  13.4334, val_loss:  12.2611, grad_norm: 0.0007, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6504, 0.3474, 0.6802, param: [4.15196032 9.50960228 4.96341134 8.86079687], weights: [0.32327956 0.32805348 0.34866696], train_wt_loss:  40.3003, val_wt_loss: 36.7832, train_grp_loss: [11.74428175 15.88675489 11.15630892], val_grp_loss: [10.62729765 14.89806795 11.2736457 ], train_hist_grp_loss: [ 5.00102451  6.46694217 12.56099639], cur_train_grp_loss: [0.09471072 0.1231544  0.23736728], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6802, max_kl_dist_index: 2, max_train_grp_loss:  15.8868, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8981, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:31:38,859 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  52, train_loss:  13.4334, val_loss:  12.2611, grad_norm: 0.0007, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6504, 0.3474, 0.6802, param: [4.15197071 9.50933508 4.96356136 8.86090814], weights: [0.3230886  0.32795295 0.34895845], train_wt_loss:  40.3003, val_wt_loss: 36.7832, train_grp_loss: [11.74443349 15.88659321 11.15635528], val_grp_loss: [10.62740991 14.89785543 11.27370763], train_hist_grp_loss: [ 5.09573646  6.59009531 12.79836467], cur_train_grp_loss: [0.09471195 0.12315314 0.23736827], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6802, max_kl_dist_index: 2, max_train_grp_loss:  15.8866, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8979, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:31:39,881 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  53, train_loss:  13.4334, val_loss:  12.2610, grad_norm: 0.0007, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6504, 0.3474, 0.6802, param: [4.15198087 9.50906839 4.96371121 8.86101994], weights: [0.32289762 0.32785233 0.34925005], train_wt_loss:  40.3003, val_wt_loss: 36.7831, train_grp_loss: [11.74458472 15.88643212 11.15640143], val_grp_loss: [10.62752172 14.89764379 11.2737694 ], train_hist_grp_loss: [ 5.19044964  6.71324719 13.03573393], cur_train_grp_loss: [0.09471317 0.12315189 0.23736926], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6802, max_kl_dist_index: 2, max_train_grp_loss:  15.8864, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8976, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:31:40,919 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  54, train_loss:  13.4334, val_loss:  12.2610, grad_norm: 0.0007, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6504, 0.3474, 0.6802, param: [4.15199079 9.5088022  4.96386089 8.86113229], weights: [0.32270663 0.3277516  0.34954177], train_wt_loss:  40.3003, val_wt_loss: 36.7831, train_grp_loss: [11.74473542 15.88627163 11.15644736], val_grp_loss: [10.62763307 14.89743305 11.27383099], train_hist_grp_loss: [ 5.28516403  6.83639783 13.27310417], cur_train_grp_loss: [0.09471439 0.12315064 0.23737024], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6802, max_kl_dist_index: 2, max_train_grp_loss:  15.8863, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8974, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:31:41,975 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  55, train_loss:  13.4334, val_loss:  12.2610, grad_norm: 0.0008, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6504, 0.3474, 0.6802, param: [4.15200048 9.50853652 4.96401039 8.86124517], weights: [0.32251564 0.32765077 0.34983359], train_wt_loss:  40.3003, val_wt_loss: 36.7831, train_grp_loss: [11.74488562 15.88611174 11.15649306], val_grp_loss: [10.62774396 14.8972232  11.27389241], train_hist_grp_loss: [ 5.37987964  6.95954722 13.51047539], cur_train_grp_loss: [0.09471561 0.12314939 0.23737122], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6802, max_kl_dist_index: 2, max_train_grp_loss:  15.8861, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8972, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:31:43,009 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  56, train_loss:  13.4334, val_loss:  12.2610, grad_norm: 0.0008, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6504, 0.3474, 0.6802, param: [4.15200994 9.50827134 4.96415972 8.86135859], weights: [0.32232464 0.32754984 0.35012553], train_wt_loss:  40.3003, val_wt_loss: 36.7830, train_grp_loss: [11.74503529 15.88595244 11.15653854], val_grp_loss: [10.6278544  14.89701424 11.27395366], train_hist_grp_loss: [ 5.47459646  7.08269538 13.74784759], cur_train_grp_loss: [0.09471682 0.12314815 0.23737219], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6802, max_kl_dist_index: 2, max_train_grp_loss:  15.8860, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8970, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:31:44,065 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  57, train_loss:  13.4334, val_loss:  12.2610, grad_norm: 0.0008, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6504, 0.3474, 0.6802, param: [4.15201916 9.50800666 4.96430887 8.86147256], weights: [0.32213362 0.3274488  0.35041757], train_wt_loss:  40.3003, val_wt_loss: 36.7830, train_grp_loss: [11.74518445 15.88579373 11.1565838 ], val_grp_loss: [10.62796437 14.89680617 11.27401474], train_hist_grp_loss: [ 5.56931448  7.20584229 13.98522075], cur_train_grp_loss: [0.09471803 0.12314692 0.23737316], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6802, max_kl_dist_index: 2, max_train_grp_loss:  15.8858, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8968, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:31:45,118 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  58, train_loss:  13.4334, val_loss:  12.2610, grad_norm: 0.0008, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6504, 0.3474, 0.6802, param: [4.15202815 9.50774249 4.96445786 8.86158706], weights: [0.3219426  0.32734767 0.35070973], train_wt_loss:  40.3003, val_wt_loss: 36.7830, train_grp_loss: [11.74533308 15.88563563 11.15662884], val_grp_loss: [10.6280739  14.89659899 11.27407565], train_hist_grp_loss: [ 5.66403371  7.32898798 14.22259487], cur_train_grp_loss: [0.09471923 0.12314569 0.23737412], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6802, max_kl_dist_index: 2, max_train_grp_loss:  15.8856, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8966, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:31:46,154 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  59, train_loss:  13.4334, val_loss:  12.2610, grad_norm: 0.0008, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6504, 0.3474, 0.6802, param: [4.1520369  9.50747883 4.96460667 8.8617021 ], weights: [0.32175157 0.32724644 0.35100199], train_wt_loss:  40.3003, val_wt_loss: 36.7829, train_grp_loss: [11.7454812  15.88547811 11.15667365], val_grp_loss: [10.62818296 14.8963927  11.27413639], train_hist_grp_loss: [ 5.75875414  7.45213244 14.45996995], cur_train_grp_loss: [0.09472043 0.12314446 0.23737508], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6802, max_kl_dist_index: 2, max_train_grp_loss:  15.8855, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8964, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:31:47,187 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  60, train_loss:  13.4334, val_loss:  12.2610, grad_norm: 0.0008, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6504, 0.3474, 0.6802, param: [4.15204542 9.50721566 4.9647553  8.86181769], weights: [0.32156053 0.3271451  0.35129436], train_wt_loss:  40.3003, val_wt_loss: 36.7829, train_grp_loss: [11.74562881 15.8853212  11.15671824], val_grp_loss: [10.62829156 14.89618731 11.27419696], train_hist_grp_loss: [ 5.85347576  7.57527569 14.69734599], cur_train_grp_loss: [0.09472162 0.12314324 0.23737604], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6802, max_kl_dist_index: 2, max_train_grp_loss:  15.8853, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8962, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:31:48,224 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  61, train_loss:  13.4334, val_loss:  12.2610, grad_norm: 0.0008, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6504, 0.3474, 0.6802, param: [4.1520537  9.50695301 4.96490377 8.86193381], weights: [0.32136949 0.32704367 0.35158685], train_wt_loss:  40.3003, val_wt_loss: 36.7829, train_grp_loss: [11.74577589 15.88516488 11.15676262], val_grp_loss: [10.62839971 14.8959828  11.27425736], train_hist_grp_loss: [ 5.94819858  7.69841771 14.93472297], cur_train_grp_loss: [0.09472281 0.12314202 0.23737698], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6802, max_kl_dist_index: 2, max_train_grp_loss:  15.8852, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8960, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:31:49,232 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  62, train_loss:  13.4334, val_loss:  12.2609, grad_norm: 0.0009, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6504, 0.3474, 0.6802, param: [4.15206175 9.50669085 4.96505206 8.86205048], weights: [0.32117843 0.32694213 0.35187944], train_wt_loss:  40.3003, val_wt_loss: 36.7828, train_grp_loss: [11.74592245 15.88500916 11.15680676], val_grp_loss: [10.6285074  14.89577919 11.27431758], train_hist_grp_loss: [ 6.04292257  7.82155852 15.1721009 ], cur_train_grp_loss: [0.094724   0.12314081 0.23737793], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6802, max_kl_dist_index: 2, max_train_grp_loss:  15.8850, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8958, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:31:50,274 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  63, train_loss:  13.4334, val_loss:  12.2609, grad_norm: 0.0009, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6504, 0.3474, 0.6802, param: [4.15206956 9.5064292  4.96520017 8.86216769], weights: [0.32098737 0.3268405  0.35217214], train_wt_loss:  40.3003, val_wt_loss: 36.7828, train_grp_loss: [11.7460685  15.88485403 11.15685069], val_grp_loss: [10.62861463 14.89557647 11.27437764], train_hist_grp_loss: [ 6.13764776  7.94469813 15.40947977], cur_train_grp_loss: [0.09472518 0.12313961 0.23737887], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6802, max_kl_dist_index: 2, max_train_grp_loss:  15.8849, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8956, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:31:51,323 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  64, train_loss:  13.4334, val_loss:  12.2609, grad_norm: 0.0009, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6504, 0.3474, 0.6802, param: [4.15207714 9.50616806 4.96534812 8.86228544], weights: [0.32079629 0.32673876 0.35246495], train_wt_loss:  40.3003, val_wt_loss: 36.7828, train_grp_loss: [11.74621403 15.8846995  11.15689439], val_grp_loss: [10.6287214  14.89537465 11.27443752], train_hist_grp_loss: [ 6.23237411  8.06783653 15.64685957], cur_train_grp_loss: [0.09472636 0.1231384  0.2373798 ], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6802, max_kl_dist_index: 2, max_train_grp_loss:  15.8847, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8954, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:31:52,356 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  65, train_loss:  13.4334, val_loss:  12.2609, grad_norm: 0.0009, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6504, 0.3474, 0.6802, param: [4.15208449 9.50590742 4.96549588 8.86240373], weights: [0.32060521 0.32663692 0.35275787], train_wt_loss:  40.3003, val_wt_loss: 36.7827, train_grp_loss: [11.74635903 15.88454557 11.15693787], val_grp_loss: [10.62882772 14.89517372 11.27449724], train_hist_grp_loss: [ 6.32710165  8.19097374 15.8842403 ], cur_train_grp_loss: [0.09472753 0.12313721 0.23738073], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6802, max_kl_dist_index: 2, max_train_grp_loss:  15.8845, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8952, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:31:53,369 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  66, train_loss:  13.4334, val_loss:  12.2609, grad_norm: 0.0009, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6504, 0.3473, 0.6802, param: [4.1520916  9.50564729 4.96564348 8.86252256], weights: [0.32041412 0.32653498 0.35305089], train_wt_loss:  40.3003, val_wt_loss: 36.7827, train_grp_loss: [11.74650352 15.88439224 11.15698113], val_grp_loss: [10.62893357 14.89497368 11.27455678], train_hist_grp_loss: [ 6.42183035  8.31410975 16.12162196], cur_train_grp_loss: [0.0947287  0.12313601 0.23738166], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6802, max_kl_dist_index: 2, max_train_grp_loss:  15.8844, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8950, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:31:54,386 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  67, train_loss:  13.4334, val_loss:  12.2609, grad_norm: 0.0009, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6504, 0.3473, 0.6801, param: [4.15209847 9.50538766 4.9657909  8.86264194], weights: [0.32022303 0.32643295 0.35334403], train_wt_loss:  40.3003, val_wt_loss: 36.7827, train_grp_loss: [11.74664749 15.8842395  11.15702416], val_grp_loss: [10.62903896 14.89477454 11.27461615], train_hist_grp_loss: [ 6.51656022  8.43724457 16.35900453], cur_train_grp_loss: [0.09472987 0.12313482 0.23738258], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6801, max_kl_dist_index: 2, max_train_grp_loss:  15.8842, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8948, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:31:55,402 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  68, train_loss:  13.4334, val_loss:  12.2609, grad_norm: 0.0009, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6503, 0.3473, 0.6801, param: [4.15210512 9.50512854 4.96593815 8.86276186], weights: [0.32003192 0.32633081 0.35363727], train_wt_loss:  40.3003, val_wt_loss: 36.7826, train_grp_loss: [11.74679094 15.88408737 11.15706697], val_grp_loss: [10.6291439  14.89457629 11.27467535], train_hist_grp_loss: [ 6.61129124  8.56037821 16.59638803], cur_train_grp_loss: [0.09473103 0.12313364 0.23738349], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6801, max_kl_dist_index: 2, max_train_grp_loss:  15.8841, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8946, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:31:56,434 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  69, train_loss:  13.4334, val_loss:  12.2609, grad_norm: 0.0010, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6503, 0.3473, 0.6801, param: [4.15211152 9.50486992 4.96608522 8.86288232], weights: [0.31984081 0.32622857 0.35393062], train_wt_loss:  40.3003, val_wt_loss: 36.7826, train_grp_loss: [11.74693387 15.88393582 11.15710956], val_grp_loss: [10.62924837 14.89437893 11.27473437], train_hist_grp_loss: [ 6.70602343  8.68351067 16.83377243], cur_train_grp_loss: [0.09473218 0.12313246 0.2373844 ], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6801, max_kl_dist_index: 2, max_train_grp_loss:  15.8839, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8944, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:31:57,446 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  70, train_loss:  13.4334, val_loss:  12.2609, grad_norm: 0.0010, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6503, 0.3473, 0.6801, param: [4.15211769 9.50461181 4.96623211 8.86300333], weights: [0.31964969 0.32612624 0.35422407], train_wt_loss:  40.3003, val_wt_loss: 36.7826, train_grp_loss: [11.74707627 15.88378488 11.15715192], val_grp_loss: [10.62935239 14.89418247 11.27479323], train_hist_grp_loss: [ 6.80075677  8.80664196 17.07115774], cur_train_grp_loss: [0.09473334 0.12313129 0.23738531], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6801, max_kl_dist_index: 2, max_train_grp_loss:  15.8838, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8942, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:31:58,467 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  71, train_loss:  13.4334, val_loss:  12.2608, grad_norm: 0.0010, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6503, 0.3473, 0.6801, param: [4.15212363 9.50435421 4.96637884 8.86312487], weights: [0.31945856 0.3260238  0.35451764], train_wt_loss:  40.3003, val_wt_loss: 36.7825, train_grp_loss: [11.74721816 15.88363454 11.15719406], val_grp_loss: [10.62945594 14.8939869  11.27485191], train_hist_grp_loss: [ 6.89549125  8.92977207 17.30854395], cur_train_grp_loss: [0.09473449 0.12313012 0.23738621], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6801, max_kl_dist_index: 2, max_train_grp_loss:  15.8836, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8940, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:31:59,481 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  72, train_loss:  13.4334, val_loss:  12.2608, grad_norm: 0.0010, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6503, 0.3473, 0.6801, param: [4.15212933 9.50409711 4.96652539 8.86324697], weights: [0.31926743 0.32592126 0.35481131], train_wt_loss:  40.3003, val_wt_loss: 36.7825, train_grp_loss: [11.74735952 15.88348479 11.15723598], val_grp_loss: [10.62955904 14.89379223 11.27491042], train_hist_grp_loss: [ 6.99022688  9.05290102 17.54593106], cur_train_grp_loss: [0.09473563 0.12312895 0.23738711], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6801, max_kl_dist_index: 2, max_train_grp_loss:  15.8835, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8938, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:32:00,524 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  73, train_loss:  13.4334, val_loss:  12.2608, grad_norm: 0.0010, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6503, 0.3473, 0.6801, param: [4.1521348  9.50384051 4.96667176 8.8633696 ], weights: [0.31907629 0.32581863 0.35510509], train_wt_loss:  40.3003, val_wt_loss: 36.7825, train_grp_loss: [11.74750037 15.88333564 11.15727767], val_grp_loss: [10.62966167 14.89359846 11.27496876], train_hist_grp_loss: [ 7.08496365  9.17602881 17.78331906], cur_train_grp_loss: [0.09473677 0.12312779 0.237388  ], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6801, max_kl_dist_index: 2, max_train_grp_loss:  15.8833, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8936, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:32:01,527 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  74, train_loss:  13.4334, val_loss:  12.2608, grad_norm: 0.0010, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6503, 0.3473, 0.6801, param: [4.15214003 9.50358442 4.96681796 8.86349278], weights: [0.31888514 0.32571589 0.35539897], train_wt_loss:  40.3003, val_wt_loss: 36.7824, train_grp_loss: [11.74764069 15.88318709 11.15731913], val_grp_loss: [10.62976384 14.89340558 11.27502692], train_hist_grp_loss: [ 7.17970156  9.29915545 18.02070795], cur_train_grp_loss: [0.09473791 0.12312663 0.23738889], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6801, max_kl_dist_index: 2, max_train_grp_loss:  15.8832, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8934, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:32:02,522 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  75, train_loss:  13.4334, val_loss:  12.2608, grad_norm: 0.0010, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6503, 0.3473, 0.6801, param: [4.15214502 9.50332884 4.96696398 8.86361651], weights: [0.31869398 0.32561306 0.35569296], train_wt_loss:  40.3003, val_wt_loss: 36.7824, train_grp_loss: [11.74778049 15.88303914 11.15736038], val_grp_loss: [10.62986556 14.89321359 11.27508492], train_hist_grp_loss: [ 7.2744406   9.42228093 18.25809771], cur_train_grp_loss: [0.09473904 0.12312548 0.23738977], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6801, max_kl_dist_index: 2, max_train_grp_loss:  15.8830, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8932, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:32:03,583 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  76, train_loss:  13.4334, val_loss:  12.2608, grad_norm: 0.0011, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6503, 0.3473, 0.6801, param: [4.15214978 9.50307377 4.96710983 8.86374077], weights: [0.31850282 0.32551012 0.35598706], train_wt_loss:  40.3003, val_wt_loss: 36.7824, train_grp_loss: [11.74791977 15.88289179 11.1574014 ], val_grp_loss: [10.62996681 14.89302251 11.27514274], train_hist_grp_loss: [ 7.36918076  9.54540526 18.49548836], cur_train_grp_loss: [0.09474017 0.12312433 0.23739065], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6801, max_kl_dist_index: 2, max_train_grp_loss:  15.8829, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8930, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:32:04,629 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  77, train_loss:  13.4334, val_loss:  12.2608, grad_norm: 0.0011, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6503, 0.3473, 0.6801, param: [4.15215431 9.5028192  4.9672555  8.86386559], weights: [0.31831164 0.32540709 0.35628127], train_wt_loss:  40.3003, val_wt_loss: 36.7823, train_grp_loss: [11.74805852 15.88274504 11.15744219], val_grp_loss: [10.6300676  14.89283232 11.27520039], train_hist_grp_loss: [ 7.46392205  9.66852845 18.73287988], cur_train_grp_loss: [0.09474129 0.12312319 0.23739152], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6801, max_kl_dist_index: 2, max_train_grp_loss:  15.8827, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8928, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:32:05,641 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  78, train_loss:  13.4334, val_loss:  12.2608, grad_norm: 0.0011, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6503, 0.3473, 0.6801, param: [4.1521586  9.50256513 4.967401   8.86399095], weights: [0.31812047 0.32530396 0.35657558], train_wt_loss:  40.3003, val_wt_loss: 36.7823, train_grp_loss: [11.74819676 15.88259889 11.15748276], val_grp_loss: [10.63016793 14.89264302 11.27525786], train_hist_grp_loss: [ 7.55866446  9.79165051 18.97027227], cur_train_grp_loss: [0.09474241 0.12312205 0.23739239], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6801, max_kl_dist_index: 2, max_train_grp_loss:  15.8826, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8926, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:32:06,681 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  79, train_loss:  13.4334, val_loss:  12.2608, grad_norm: 0.0011, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6503, 0.3473, 0.6801, param: [4.15216265 9.50231158 4.96754633 8.86411685], weights: [0.31792928 0.32520073 0.35686999], train_wt_loss:  40.3003, val_wt_loss: 36.7823, train_grp_loss: [11.74833447 15.88245333 11.15752311], val_grp_loss: [10.63026779 14.89245463 11.27531516], train_hist_grp_loss: [ 7.65340798  9.91477143 19.20766552], cur_train_grp_loss: [0.09474352 0.12312092 0.23739325], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6801, max_kl_dist_index: 2, max_train_grp_loss:  15.8825, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8925, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:32:07,692 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  80, train_loss:  13.4334, val_loss:  12.2607, grad_norm: 0.0011, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6503, 0.3473, 0.6801, param: [4.15216647 9.50205852 4.96769147 8.8642433 ], weights: [0.31773809 0.3250974  0.35716451], train_wt_loss:  40.3003, val_wt_loss: 36.7822, train_grp_loss: [11.74847166 15.88230838 11.15756323], val_grp_loss: [10.6303672  14.89226713 11.27537229], train_hist_grp_loss: [ 7.74815261 10.03789122 19.44505963], cur_train_grp_loss: [0.09474463 0.12311979 0.23739411], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6801, max_kl_dist_index: 2, max_train_grp_loss:  15.8823, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8923, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:32:08,770 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  81, train_loss:  13.4334, val_loss:  12.2607, grad_norm: 0.0011, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6503, 0.3473, 0.6801, param: [4.15217005 9.50180598 4.96783645 8.86437029], weights: [0.31754689 0.32499397 0.35745914], train_wt_loss:  40.3003, val_wt_loss: 36.7822, train_grp_loss: [11.74860832 15.88216403 11.15760313], val_grp_loss: [10.63046614 14.89208052 11.27542925], train_hist_grp_loss: [ 7.84289835 10.16100989 19.68245459], cur_train_grp_loss: [0.09474574 0.12311867 0.23739496], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6801, max_kl_dist_index: 2, max_train_grp_loss:  15.8822, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8921, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:32:09,759 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  82, train_loss:  13.4334, val_loss:  12.2607, grad_norm: 0.0011, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6503, 0.3473, 0.6801, param: [4.1521734  9.50155394 4.96798124 8.86449783], weights: [0.31735569 0.32489044 0.35775387], train_wt_loss:  40.3003, val_wt_loss: 36.7822, train_grp_loss: [11.74874446 15.88202027 11.1576428 ], val_grp_loss: [10.63056462 14.89189482 11.27548603], train_hist_grp_loss: [ 7.93764519 10.28412744 19.9198504 ], cur_train_grp_loss: [0.09474684 0.12311755 0.23739581], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6801, max_kl_dist_index: 2, max_train_grp_loss:  15.8820, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8919, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:32:10,786 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  83, train_loss:  13.4334, val_loss:  12.2607, grad_norm: 0.0012, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6503, 0.3473, 0.6801, param: [4.15217651 9.50130241 4.96812586 8.86462592], weights: [0.31716448 0.32478681 0.35804871], train_wt_loss:  40.3003, val_wt_loss: 36.7822, train_grp_loss: [11.74888008 15.88187712 11.15768224], val_grp_loss: [10.63066264 14.89171001 11.27554264], train_hist_grp_loss: [ 8.03239313 10.40724388 20.15724705], cur_train_grp_loss: [0.09474794 0.12311644 0.23739666], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6801, max_kl_dist_index: 2, max_train_grp_loss:  15.8819, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8917, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:32:11,809 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  84, train_loss:  13.4334, val_loss:  12.2607, grad_norm: 0.0012, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6503, 0.3473, 0.6801, param: [4.15217939 9.50105139 4.96827031 8.86475455], weights: [0.31697326 0.32468309 0.35834365], train_wt_loss:  40.3003, val_wt_loss: 36.7821, train_grp_loss: [11.74901517 15.88173456 11.15772147], val_grp_loss: [10.6307602  14.89152611 11.27559908], train_hist_grp_loss: [ 8.12714217 10.53035921 20.39464455], cur_train_grp_loss: [0.09474903 0.12311533 0.23739749], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6801, max_kl_dist_index: 2, max_train_grp_loss:  15.8817, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8915, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:32:12,817 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  85, train_loss:  13.4334, val_loss:  12.2607, grad_norm: 0.0012, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6503, 0.3473, 0.6801, param: [4.15218203 9.50080087 4.96841457 8.86488373], weights: [0.31678204 0.32457926 0.3586387 ], train_wt_loss:  40.3003, val_wt_loss: 36.7821, train_grp_loss: [11.74914974 15.88159261 11.15776046], val_grp_loss: [10.63085729 14.8913431  11.27565534], train_hist_grp_loss: [ 8.22189229 10.65347343 20.63204288], cur_train_grp_loss: [0.09475012 0.12311422 0.23739833], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6801, max_kl_dist_index: 2, max_train_grp_loss:  15.8816, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8913, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:32:13,887 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  86, train_loss:  13.4334, val_loss:  12.2607, grad_norm: 0.0012, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6503, 0.3472, 0.6801, param: [4.15218444 9.50055086 4.96855867 8.86501346], weights: [0.31659081 0.32447534 0.35893385], train_wt_loss:  40.3003, val_wt_loss: 36.7821, train_grp_loss: [11.74928379 15.88145126 11.15779923], val_grp_loss: [10.63095392 14.89116099 11.27571143], train_hist_grp_loss: [ 8.3166435  10.77658655 20.86944204], cur_train_grp_loss: [0.09475121 0.12311312 0.23739916], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6801, max_kl_dist_index: 2, max_train_grp_loss:  15.8815, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8912, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:32:14,915 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  87, train_loss:  13.4335, val_loss:  12.2607, grad_norm: 0.0012, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6503, 0.3472, 0.6801, param: [4.15218661 9.50030136 4.96870258 8.86514373], weights: [0.31639957 0.32437132 0.3592291 ], train_wt_loss:  40.3004, val_wt_loss: 36.7820, train_grp_loss: [11.74941731 15.8813105  11.15783778], val_grp_loss: [10.63105009 14.89097978 11.27576735], train_hist_grp_loss: [ 8.41139578 10.89969857 21.10684202], cur_train_grp_loss: [0.09475229 0.12311203 0.23739998], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6801, max_kl_dist_index: 2, max_train_grp_loss:  15.8813, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8910, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:32:15,941 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  88, train_loss:  13.4335, val_loss:  12.2607, grad_norm: 0.0012, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6503, 0.3472, 0.6800, param: [4.15218854 9.50005237 4.96884632 8.86527456], weights: [0.31620833 0.32426721 0.35952446], train_wt_loss:  40.3004, val_wt_loss: 36.7820, train_grp_loss: [11.7495503  15.88117035 11.1578761 ], val_grp_loss: [10.63114579 14.89079946 11.27582309], train_hist_grp_loss: [ 8.50614915 11.02280951 21.34424282], cur_train_grp_loss: [0.09475337 0.12311093 0.2374008 ], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6800, max_kl_dist_index: 2, max_train_grp_loss:  15.8812, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8908, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:32:16,970 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  89, train_loss:  13.4335, val_loss:  12.2607, grad_norm: 0.0012, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6503, 0.3472, 0.6800, param: [4.15219024 9.49980388 4.96898989 8.86540592], weights: [0.31601709 0.32416299 0.35981992], train_wt_loss:  40.3004, val_wt_loss: 36.7820, train_grp_loss: [11.74968277 15.8810308  11.15791419], val_grp_loss: [10.63124103 14.89062005 11.27587866], train_hist_grp_loss: [ 8.60090359 11.14591936 21.58164444], cur_train_grp_loss: [0.09475444 0.12310985 0.23740162], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6800, max_kl_dist_index: 2, max_train_grp_loss:  15.8810, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8906, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:32:18,002 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  90, train_loss:  13.4335, val_loss:  12.2607, grad_norm: 0.0013, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6503, 0.3472, 0.6800, param: [4.1521917  9.4995559  4.96913327 8.86553784], weights: [0.31582583 0.32405868 0.36011549], train_wt_loss:  40.3004, val_wt_loss: 36.7820, train_grp_loss: [11.74981472 15.88089185 11.15795206], val_grp_loss: [10.63133581 14.89044154 11.27593405], train_hist_grp_loss: [ 8.69565909 11.26902812 21.81904687], cur_train_grp_loss: [0.09475551 0.12310877 0.23740243], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6800, max_kl_dist_index: 2, max_train_grp_loss:  15.8809, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8904, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:32:19,020 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  91, train_loss:  13.4335, val_loss:  12.2606, grad_norm: 0.0013, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6503, 0.3472, 0.6800, param: [4.15219292 9.49930842 4.96927648 8.8656703 ], weights: [0.31563458 0.32395426 0.36041116], train_wt_loss:  40.3004, val_wt_loss: 36.7819, train_grp_loss: [11.74994614 15.8807535  11.1579897 ], val_grp_loss: [10.63143012 14.89026393 11.27598927], train_hist_grp_loss: [ 8.79041566 11.39213581 22.05645011], cur_train_grp_loss: [0.09475657 0.12310769 0.23740324], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6800, max_kl_dist_index: 2, max_train_grp_loss:  15.8808, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8903, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:32:20,083 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  92, train_loss:  13.4335, val_loss:  12.2606, grad_norm: 0.0013, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6503, 0.3472, 0.6800, param: [4.15219391 9.49906146 4.96941951 8.86580332], weights: [0.31544331 0.32384975 0.36070693], train_wt_loss:  40.3004, val_wt_loss: 36.7819, train_grp_loss: [11.75007704 15.88061575 11.15802711], val_grp_loss: [10.63152397 14.89008722 11.27604432], train_hist_grp_loss: [ 8.88517329 11.51524243 22.29385414], cur_train_grp_loss: [0.09475763 0.12310662 0.23740404], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6800, max_kl_dist_index: 2, max_train_grp_loss:  15.8806, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8901, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:32:21,107 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  93, train_loss:  13.4335, val_loss:  12.2606, grad_norm: 0.0013, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6503, 0.3472, 0.6800, param: [4.15219466 9.498815   4.96956237 8.86593688], weights: [0.31525205 0.32374515 0.36100281], train_wt_loss:  40.3004, val_wt_loss: 36.7819, train_grp_loss: [11.7502074  15.88047861 11.1580643 ], val_grp_loss: [10.63161735 14.88991141 11.27609919], train_hist_grp_loss: [ 8.97993198 11.63834798 22.53125898], cur_train_grp_loss: [0.09475869 0.12310555 0.23740483], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6800, max_kl_dist_index: 2, max_train_grp_loss:  15.8805, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8899, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:32:22,126 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  94, train_loss:  13.4335, val_loss:  12.2606, grad_norm: 0.0013, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6503, 0.3472, 0.6800, param: [4.15219518 9.49856905 4.96970505 8.86607099], weights: [0.31506077 0.32364044 0.36129879], train_wt_loss:  40.3004, val_wt_loss: 36.7819, train_grp_loss: [11.75033725 15.88034206 11.15810127], val_grp_loss: [10.63171027 14.8897365  11.27615389], train_hist_grp_loss: [ 9.07469172 11.76145246 22.7686646 ], cur_train_grp_loss: [0.09475974 0.12310449 0.23740562], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6800, max_kl_dist_index: 2, max_train_grp_loss:  15.8803, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8897, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:32:23,146 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  95, train_loss:  13.4335, val_loss:  12.2606, grad_norm: 0.0013, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6503, 0.3472, 0.6800, param: [4.15219546 9.49832361 4.96984755 8.86620565], weights: [0.31486949 0.32353564 0.36159487], train_wt_loss:  40.3004, val_wt_loss: 36.7818, train_grp_loss: [11.75046656 15.88020612 11.158138  ], val_grp_loss: [10.63180272 14.88956249 11.27620841], train_hist_grp_loss: [ 9.1694525  11.88455589 23.00607101], cur_train_grp_loss: [0.09476078 0.12310343 0.23740641], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6800, max_kl_dist_index: 2, max_train_grp_loss:  15.8802, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8896, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:32:24,190 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  96, train_loss:  13.4335, val_loss:  12.2606, grad_norm: 0.0013, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6503, 0.3472, 0.6800, param: [4.15219551 9.49807868 4.96998988 8.86634085], weights: [0.31467821 0.32343074 0.36189105], train_wt_loss:  40.3004, val_wt_loss: 36.7818, train_grp_loss: [11.75059535 15.88007078 11.15817451], val_grp_loss: [10.63189471 14.88938938 11.27626276], train_hist_grp_loss: [ 9.26421433 12.00765826 23.2434782 ], cur_train_grp_loss: [0.09476183 0.12310237 0.23740719], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6800, max_kl_dist_index: 2, max_train_grp_loss:  15.8801, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8894, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:32:25,206 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  97, train_loss:  13.4335, val_loss:  12.2606, grad_norm: 0.0014, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6503, 0.3472, 0.6800, param: [4.15219531 9.49783425 4.97013202 8.86647661], weights: [0.31448692 0.32332574 0.36218733], train_wt_loss:  40.3004, val_wt_loss: 36.7818, train_grp_loss: [11.75072361 15.87993604 11.1582108 ], val_grp_loss: [10.63198624 14.88921718 11.27631693], train_hist_grp_loss: [ 9.35897719 12.13075958 23.48088617], cur_train_grp_loss: [0.09476287 0.12310132 0.23740797], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6800, max_kl_dist_index: 2, max_train_grp_loss:  15.8799, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8892, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:32:26,257 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  98, train_loss:  13.4335, val_loss:  12.2606, grad_norm: 0.0014, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6503, 0.3472, 0.6800, param: [4.15219488 9.49759033 4.97027399 8.86661292], weights: [0.31429563 0.32322065 0.36248372], train_wt_loss:  40.3004, val_wt_loss: 36.7818, train_grp_loss: [11.75085135 15.87980191 11.15824685], val_grp_loss: [10.6320773  14.88904588 11.27637093], train_hist_grp_loss: [ 9.45374109 12.25385986 23.71829491], cur_train_grp_loss: [0.0947639  0.12310028 0.23740874], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6800, max_kl_dist_index: 2, max_train_grp_loss:  15.8798, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8890, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:32:27,275 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  99, train_loss:  13.4335, val_loss:  12.2606, grad_norm: 0.0014, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6503, 0.3472, 0.6800, param: [4.15219422 9.49734692 4.97041579 8.86674977], weights: [0.31410433 0.32311546 0.36278021], train_wt_loss:  40.3004, val_wt_loss: 36.7817, train_grp_loss: [11.75097856 15.87966838 11.15828268], val_grp_loss: [10.63216789 14.88887547 11.27642476], train_hist_grp_loss: [ 9.54850603 12.3769591  23.95570442], cur_train_grp_loss: [0.09476493 0.12309924 0.23740951], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6800, max_kl_dist_index: 2, max_train_grp_loss:  15.8797, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8889, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:32:28,328 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  100, train_loss:  13.4335, val_loss:  12.2606, grad_norm: 0.0014, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6503, 0.3472, 0.6800, param: [4.15219332 9.49710402 4.9705574  8.86688718], weights: [0.31391303 0.32301017 0.3630768 ], train_wt_loss:  40.3004, val_wt_loss: 36.7817, train_grp_loss: [11.75110524 15.87953545 11.15831829], val_grp_loss: [10.63225802 14.88870598 11.2764784 ], train_hist_grp_loss: [ 9.64327198 12.50005731 24.19311469], cur_train_grp_loss: [0.09476596 0.1230982  0.23741027], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6800, max_kl_dist_index: 2, max_train_grp_loss:  15.8795, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8887, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:32:29,341 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  101, train_loss:  13.4335, val_loss:  12.2606, grad_norm: 0.0014, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6503, 0.3472, 0.6800, param: [4.15219218 9.49686163 4.97069884 8.86702513], weights: [0.31372172 0.32290479 0.36337349], train_wt_loss:  40.3004, val_wt_loss: 36.7817, train_grp_loss: [11.75123139 15.87940312 11.15835366], val_grp_loss: [10.63234769 14.88853738 11.27653188], train_hist_grp_loss: [ 9.73803896 12.62315448 24.43052571], cur_train_grp_loss: [0.09476698 0.12309717 0.23741103], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6800, max_kl_dist_index: 2, max_train_grp_loss:  15.8794, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8885, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:32:30,359 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  102, train_loss:  13.4335, val_loss:  12.2606, grad_norm: 0.0014, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6503, 0.3472, 0.6800, param: [4.1521908  9.49661974 4.9708401  8.86716364], weights: [0.31353041 0.32279931 0.36367029], train_wt_loss:  40.3004, val_wt_loss: 36.7817, train_grp_loss: [11.75135702 15.87927139 11.15838881], val_grp_loss: [10.63243688 14.88836969 11.27658518], train_hist_grp_loss: [ 9.83280695 12.74625063 24.66793749], cur_train_grp_loss: [0.094768   0.12309615 0.23741178], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6800, max_kl_dist_index: 2, max_train_grp_loss:  15.8793, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8884, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:32:31,378 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  103, train_loss:  13.4335, val_loss:  12.2605, grad_norm: 0.0014, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6503, 0.3472, 0.6800, param: [4.15218919 9.49637837 4.97098118 8.8673027 ], weights: [0.31333909 0.32269373 0.36396718], train_wt_loss:  40.3004, val_wt_loss: 36.7816, train_grp_loss: [11.75148212 15.87914027 11.15842373], val_grp_loss: [10.63252561 14.8882029  11.2766383 ], train_hist_grp_loss: [ 9.92757596 12.86934576 24.90535002], cur_train_grp_loss: [0.09476901 0.12309513 0.23741253], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6800, max_kl_dist_index: 2, max_train_grp_loss:  15.8791, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8882, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:32:32,415 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  104, train_loss:  13.4335, val_loss:  12.2605, grad_norm: 0.0015, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6503, 0.3472, 0.6800, param: [4.15218734 9.4961375  4.97112208 8.86744231], weights: [0.31314777 0.32258805 0.36426418], train_wt_loss:  40.3004, val_wt_loss: 36.7816, train_grp_loss: [11.75160669 15.87900975 11.15845842], val_grp_loss: [10.63261388 14.88803702 11.27669125], train_hist_grp_loss: [10.02234598 12.99243987 25.14276329], cur_train_grp_loss: [0.09477002 0.12309411 0.23741327], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6800, max_kl_dist_index: 2, max_train_grp_loss:  15.8790, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8880, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:32:33,421 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  105, train_loss:  13.4335, val_loss:  12.2605, grad_norm: 0.0015, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6503, 0.3472, 0.6800, param: [4.15218526 9.49589714 4.9712628  8.86758247], weights: [0.31295645 0.32248228 0.36456127], train_wt_loss:  40.3004, val_wt_loss: 36.7816, train_grp_loss: [11.75173073 15.87887984 11.15849289], val_grp_loss: [10.63270168 14.88787203 11.27674402], train_hist_grp_loss: [10.117117   13.11553297 25.3801773 ], cur_train_grp_loss: [0.09477102 0.1230931  0.23741401], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6800, max_kl_dist_index: 2, max_train_grp_loss:  15.8789, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8879, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:32:34,471 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  106, train_loss:  13.4335, val_loss:  12.2605, grad_norm: 0.0015, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6503, 0.3472, 0.6800, param: [4.15218294 9.49565729 4.97140335 8.86772318], weights: [0.31276512 0.32237641 0.36485847], train_wt_loss:  40.3004, val_wt_loss: 36.7816, train_grp_loss: [11.75185424 15.87875053 11.15852713], val_grp_loss: [10.63278901 14.88770796 11.27679662], train_hist_grp_loss: [10.21188902 13.23862506 25.61759204], cur_train_grp_loss: [0.09477202 0.12309209 0.23741474], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6800, max_kl_dist_index: 2, max_train_grp_loss:  15.8788, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8877, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:32:35,517 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  107, train_loss:  13.4335, val_loss:  12.2605, grad_norm: 0.0015, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6503, 0.3472, 0.6800, param: [4.15218038 9.49541795 4.97154372 8.86786444], weights: [0.31257379 0.32227045 0.36515576], train_wt_loss:  40.3004, val_wt_loss: 36.7815, train_grp_loss: [11.75197722 15.87862182 11.15856114], val_grp_loss: [10.63287588 14.88754478 11.27684904], train_hist_grp_loss: [10.30666204 13.36171615 25.85500752], cur_train_grp_loss: [0.09477302 0.12309109 0.23741547], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6800, max_kl_dist_index: 2, max_train_grp_loss:  15.8786, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8875, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:32:36,566 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  108, train_loss:  13.4335, val_loss:  12.2605, grad_norm: 0.0015, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6503, 0.3472, 0.6800, param: [4.15217758 9.49517912 4.97168391 8.86800625], weights: [0.31238245 0.32216439 0.36545316], train_wt_loss:  40.3004, val_wt_loss: 36.7815, train_grp_loss: [11.75209967 15.87849371 11.15859492], val_grp_loss: [10.63296227 14.88738252 11.27690129], train_hist_grp_loss: [10.40143605 13.48480624 26.09242371], cur_train_grp_loss: [0.09477401 0.12309009 0.23741619], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6800, max_kl_dist_index: 2, max_train_grp_loss:  15.8785, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8874, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:32:37,629 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  109, train_loss:  13.4335, val_loss:  12.2605, grad_norm: 0.0015, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6504, 0.3471, 0.6800, param: [4.15217455 9.49494079 4.97182392 8.86814862], weights: [0.31219111 0.32205823 0.36575066], train_wt_loss:  40.3004, val_wt_loss: 36.7815, train_grp_loss: [11.7522216  15.87836621 11.15862848], val_grp_loss: [10.63304821 14.88722115 11.27695336], train_hist_grp_loss: [10.49621105 13.60789534 26.32984062], cur_train_grp_loss: [0.094775   0.1230891  0.23741691], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6800, max_kl_dist_index: 2, max_train_grp_loss:  15.8784, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8872, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:32:38,625 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  110, train_loss:  13.4335, val_loss:  12.2605, grad_norm: 0.0015, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6504, 0.3471, 0.6800, param: [4.15217128 9.49470298 4.97196375 8.86829153], weights: [0.31199977 0.32195198 0.36604825], train_wt_loss:  40.3004, val_wt_loss: 36.7815, train_grp_loss: [11.75234299 15.87823932 11.1586618 ], val_grp_loss: [10.63313367 14.88706069 11.27700525], train_hist_grp_loss: [10.59098703 13.73098345 26.56725825], cur_train_grp_loss: [0.09477598 0.12308811 0.23741763], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6800, max_kl_dist_index: 2, max_train_grp_loss:  15.8782, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8871, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:32:39,671 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  111, train_loss:  13.4335, val_loss:  12.2605, grad_norm: 0.0015, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6504, 0.3471, 0.6800, param: [4.15216777 9.49446567 4.9721034  8.868435  ], weights: [0.31180842 0.32184563 0.36634594], train_wt_loss:  40.3004, val_wt_loss: 36.7814, train_grp_loss: [11.75246386 15.87811303 11.1586949 ], val_grp_loss: [10.63321867 14.88690114 11.27705697], train_hist_grp_loss: [10.68576399 13.85407057 26.80467659], cur_train_grp_loss: [0.09477696 0.12308713 0.23741834], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6800, max_kl_dist_index: 2, max_train_grp_loss:  15.8781, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8869, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:32:40,699 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  112, train_loss:  13.4335, val_loss:  12.2605, grad_norm: 0.0016, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6504, 0.3471, 0.6800, param: [4.15216403 9.49422888 4.97224287 8.86857903], weights: [0.31161707 0.32173919 0.36664374], train_wt_loss:  40.3004, val_wt_loss: 36.7814, train_grp_loss: [11.75258419 15.87798734 11.15872777], val_grp_loss: [10.63330319 14.88674249 11.27710851], train_hist_grp_loss: [10.78054192 13.97715672 27.04209563], cur_train_grp_loss: [0.09477793 0.12308615 0.23741904], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6800, max_kl_dist_index: 2, max_train_grp_loss:  15.8780, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8867, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:32:41,716 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  113, train_loss:  13.4335, val_loss:  12.2605, grad_norm: 0.0016, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6504, 0.3471, 0.6800, param: [4.15216005 9.49399259 4.97238217 8.8687236 ], weights: [0.31142572 0.32163265 0.36694163], train_wt_loss:  40.3004, val_wt_loss: 36.7814, train_grp_loss: [11.752704   15.87786226 11.15876042], val_grp_loss: [10.63338726 14.88658475 11.27715987], train_hist_grp_loss: [10.87532083 14.1002419  27.27951537], cur_train_grp_loss: [0.0947789  0.12308517 0.23741974], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6800, max_kl_dist_index: 2, max_train_grp_loss:  15.8779, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8866, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:32:42,738 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  114, train_loss:  13.4335, val_loss:  12.2605, grad_norm: 0.0016, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6504, 0.3471, 0.6800, param: [4.15215583 9.49375681 4.97252128 8.86886873], weights: [0.31123436 0.32152602 0.36723962], train_wt_loss:  40.3004, val_wt_loss: 36.7814, train_grp_loss: [11.75282327 15.87773778 11.15879283], val_grp_loss: [10.63347085 14.88642792 11.27721106], train_hist_grp_loss: [10.9701007 14.2233261 27.5169358], cur_train_grp_loss: [0.09477987 0.1230842  0.23742043], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6800, max_kl_dist_index: 2, max_train_grp_loss:  15.8777, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8864, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:32:43,819 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  115, train_loss:  13.4335, val_loss:  12.2605, grad_norm: 0.0016, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6504, 0.3471, 0.6800, param: [4.15215137 9.49352154 4.97266022 8.86901441], weights: [0.311043   0.32141929 0.36753771], train_wt_loss:  40.3004, val_wt_loss: 36.7814, train_grp_loss: [11.75294201 15.87761391 11.15882502], val_grp_loss: [10.63355397 14.88627199 11.27726208], train_hist_grp_loss: [11.06488153 14.34640934 27.75435693], cur_train_grp_loss: [0.09478083 0.12308324 0.23742112], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6800, max_kl_dist_index: 2, max_train_grp_loss:  15.8776, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8863, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:32:44,817 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  116, train_loss:  13.4335, val_loss:  12.2604, grad_norm: 0.0016, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6504, 0.3471, 0.6800, param: [4.15214668 9.49328679 4.97279898 8.86916064], weights: [0.31085164 0.32131246 0.3678359 ], train_wt_loss:  40.3004, val_wt_loss: 36.7813, train_grp_loss: [11.75306023 15.87749064 11.15885697], val_grp_loss: [10.63363663 14.88611696 11.27731291], train_hist_grp_loss: [11.15966332 14.46949162 27.99177873], cur_train_grp_loss: [0.09478179 0.12308228 0.23742181], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6800, max_kl_dist_index: 2, max_train_grp_loss:  15.8775, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8861, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:32:45,833 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  117, train_loss:  13.4335, val_loss:  12.2604, grad_norm: 0.0016, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6504, 0.3471, 0.6800, param: [4.15214175 9.49305254 4.97293755 8.86930743], weights: [0.31066028 0.32120554 0.36813419], train_wt_loss:  40.3004, val_wt_loss: 36.7813, train_grp_loss: [11.75317791 15.87736798 11.1588887 ], val_grp_loss: [10.63371882 14.88596285 11.27736357], train_hist_grp_loss: [11.25444607 14.59257294 28.22920122], cur_train_grp_loss: [0.09478274 0.12308132 0.23742249], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6800, max_kl_dist_index: 2, max_train_grp_loss:  15.8774, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8860, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:32:46,868 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  118, train_loss:  13.4335, val_loss:  12.2604, grad_norm: 0.0016, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6504, 0.3471, 0.6800, param: [4.15213658 9.4928188  4.97307595 8.86945477], weights: [0.31046891 0.32109852 0.36843257], train_wt_loss:  40.3004, val_wt_loss: 36.7813, train_grp_loss: [11.75329506 15.87724592 11.1589202 ], val_grp_loss: [10.63380054 14.88580964 11.27741406], train_hist_grp_loss: [11.34922976 14.71565331 28.46662439], cur_train_grp_loss: [0.09478369 0.12308037 0.23742316], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6800, max_kl_dist_index: 2, max_train_grp_loss:  15.8772, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8858, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:32:47,907 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  119, train_loss:  13.4335, val_loss:  12.2604, grad_norm: 0.0017, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6504, 0.3471, 0.6799, param: [4.15213117 9.49258557 4.97321417 8.86960267], weights: [0.31027754 0.32099141 0.36873105], train_wt_loss:  40.3004, val_wt_loss: 36.7813, train_grp_loss: [11.75341168 15.87712447 11.15895147], val_grp_loss: [10.63388179 14.88565734 11.27746436], train_hist_grp_loss: [11.4440144  14.83873274 28.70404822], cur_train_grp_loss: [0.09478464 0.12307943 0.23742383], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6799, max_kl_dist_index: 2, max_train_grp_loss:  15.8771, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8857, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:32:48,952 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  120, train_loss:  13.4335, val_loss:  12.2604, grad_norm: 0.0017, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6504, 0.3471, 0.6799, param: [4.15212553 9.49235285 4.9733522  8.86975112], weights: [0.31008617 0.3208842  0.36902963], train_wt_loss:  40.3004, val_wt_loss: 36.7813, train_grp_loss: [11.75352776 15.87700362 11.15898251], val_grp_loss: [10.63396257 14.88550594 11.27751449], train_hist_grp_loss: [11.53879997 14.96181122 28.94147272], cur_train_grp_loss: [0.09478558 0.12307848 0.2374245 ], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6799, max_kl_dist_index: 2, max_train_grp_loss:  15.8770, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8855, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:32:49,983 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  121, train_loss:  13.4335, val_loss:  12.2604, grad_norm: 0.0017, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6504, 0.3471, 0.6799, param: [4.15211965 9.49212064 4.97349006 8.86990012], weights: [0.30989479 0.3207769  0.36932831], train_wt_loss:  40.3004, val_wt_loss: 36.7812, train_grp_loss: [11.75364332 15.87688338 11.15901332], val_grp_loss: [10.63404289 14.88535546 11.27756445], train_hist_grp_loss: [11.63358649 15.08488877 29.17889788], cur_train_grp_loss: [0.09478651 0.12307755 0.23742516], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6799, max_kl_dist_index: 2, max_train_grp_loss:  15.8769, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8854, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:32:51,006 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  122, train_loss:  13.4335, val_loss:  12.2604, grad_norm: 0.0017, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6504, 0.3471, 0.6799, param: [4.15211353 9.49188894 4.97362774 8.87004968], weights: [0.30970341 0.32066951 0.36962708], train_wt_loss:  40.3004, val_wt_loss: 36.7812, train_grp_loss: [11.75375834 15.87676374 11.1590439 ], val_grp_loss: [10.63412273 14.88520588 11.27761422], train_hist_grp_loss: [11.72837393 15.20796538 29.4163237 ], cur_train_grp_loss: [0.09478745 0.12307662 0.23742582], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6799, max_kl_dist_index: 2, max_train_grp_loss:  15.8768, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8852, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:32:52,014 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  123, train_loss:  13.4335, val_loss:  12.2604, grad_norm: 0.0017, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6504, 0.3471, 0.6799, param: [4.15210717 9.49165775 4.97376523 8.87019979], weights: [0.30951203 0.32056202 0.36992595], train_wt_loss:  40.3004, val_wt_loss: 36.7812, train_grp_loss: [11.75387283 15.87664472 11.15907426], val_grp_loss: [10.6342021  14.88505721 11.27766382], train_hist_grp_loss: [11.82316231 15.33104107 29.65375016], cur_train_grp_loss: [0.09478837 0.12307569 0.23742647], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6799, max_kl_dist_index: 2, max_train_grp_loss:  15.8766, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8851, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:32:53,011 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  124, train_loss:  13.4335, val_loss:  12.2604, grad_norm: 0.0017, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6504, 0.3471, 0.6799, param: [4.15210058 9.49142707 4.97390255 8.87035046], weights: [0.30932065 0.32045443 0.37022492], train_wt_loss:  40.3004, val_wt_loss: 36.7812, train_grp_loss: [11.75398679 15.87652629 11.15910438], val_grp_loss: [10.63428101 14.88490945 11.27771324], train_hist_grp_loss: [11.91795161 15.45411584 29.89117727], cur_train_grp_loss: [0.0947893  0.12307477 0.23742711], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6799, max_kl_dist_index: 2, max_train_grp_loss:  15.8765, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8849, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:32:54,054 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  125, train_loss:  13.4335, val_loss:  12.2604, grad_norm: 0.0017, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6504, 0.3471, 0.6799, param: [4.15209375 9.4911969  4.97403969 8.87050169], weights: [0.30912927 0.32034675 0.37052398], train_wt_loss:  40.3004, val_wt_loss: 36.7812, train_grp_loss: [11.75410021 15.87640848 11.15913427], val_grp_loss: [10.63435944 14.8847626  11.27776249], train_hist_grp_loss: [12.01274182 15.57718968 30.12860503], cur_train_grp_loss: [0.09479022 0.12307385 0.23742775], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6799, max_kl_dist_index: 2, max_train_grp_loss:  15.8764, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8848, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:32:55,083 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  126, train_loss:  13.4335, val_loss:  12.2604, grad_norm: 0.0018, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6504, 0.3471, 0.6799, param: [4.15208668 9.49096724 4.97417664 8.87065347], weights: [0.30893788 0.32023898 0.37082314], train_wt_loss:  40.3004, val_wt_loss: 36.7812, train_grp_loss: [11.75421311 15.87629127 11.15916394], val_grp_loss: [10.63443741 14.88461665 11.27781155], train_hist_grp_loss: [12.10753295 15.70026262 30.36603341], cur_train_grp_loss: [0.09479113 0.12307293 0.23742839], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6799, max_kl_dist_index: 2, max_train_grp_loss:  15.8763, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8846, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:32:56,108 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  127, train_loss:  13.4335, val_loss:  12.2604, grad_norm: 0.0018, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6504, 0.3471, 0.6799, param: [4.15207937 9.49073809 4.97431342 8.8708058 ], weights: [0.3087465  0.32013111 0.37112239], train_wt_loss:  40.3004, val_wt_loss: 36.7811, train_grp_loss: [11.75432547 15.87617466 11.15919337], val_grp_loss: [10.6345149  14.88447162 11.27786044], train_hist_grp_loss: [12.20232499 15.82333464 30.60346243], cur_train_grp_loss: [0.09479204 0.12307203 0.23742902], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6799, max_kl_dist_index: 2, max_train_grp_loss:  15.8762, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8845, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:32:57,148 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  128, train_loss:  13.4335, val_loss:  12.2604, grad_norm: 0.0018, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6504, 0.3471, 0.6799, param: [4.15207182 9.49050945 4.97445001 8.87095869], weights: [0.30855511 0.32002315 0.37142174], train_wt_loss:  40.3005, val_wt_loss: 36.7811, train_grp_loss: [11.75443729 15.87605867 11.15922258], val_grp_loss: [10.63459193 14.8843275  11.27790915], train_hist_grp_loss: [12.29711794 15.94640576 30.84089208], cur_train_grp_loss: [0.09479295 0.12307112 0.23742965], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6799, max_kl_dist_index: 2, max_train_grp_loss:  15.8761, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8843, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:32:58,174 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  129, train_loss:  13.4335, val_loss:  12.2604, grad_norm: 0.0018, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6504, 0.3471, 0.6799, param: [4.15206404 9.49028132 4.97458642 8.87111214], weights: [0.30836372 0.31991509 0.37172119], train_wt_loss:  40.3005, val_wt_loss: 36.7811, train_grp_loss: [11.75454858 15.87594328 11.15925155], val_grp_loss: [10.63466848 14.88418428 11.27795769], train_hist_grp_loss: [12.39191179 16.06947599 31.07832235], cur_train_grp_loss: [0.09479385 0.12307022 0.23743027], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6799, max_kl_dist_index: 2, max_train_grp_loss:  15.8759, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8842, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:32:59,198 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  130, train_loss:  13.4335, val_loss:  12.2604, grad_norm: 0.0018, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6504, 0.3471, 0.6799, param: [4.15205602 9.49005371 4.97472265 8.87126614], weights: [0.30817232 0.31980694 0.37202073], train_wt_loss:  40.3005, val_wt_loss: 36.7811, train_grp_loss: [11.75465934 15.8758285  11.1592803 ], val_grp_loss: [10.63474456 14.88404198 11.27800604], train_hist_grp_loss: [12.48670654 16.19254531 31.31575323], cur_train_grp_loss: [0.09479475 0.12306933 0.23743088], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6799, max_kl_dist_index: 2, max_train_grp_loss:  15.8758, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8840, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:33:00,187 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  131, train_loss:  13.4335, val_loss:  12.2604, grad_norm: 0.0018, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6504, 0.3471, 0.6799, param: [4.15204776 9.4898266  4.9748587  8.8714207 ], weights: [0.30798093 0.3196987  0.37232037], train_wt_loss:  40.3005, val_wt_loss: 36.7811, train_grp_loss: [11.75476957 15.87571432 11.15930881], val_grp_loss: [10.63482018 14.88390058 11.27805422], train_hist_grp_loss: [12.58150218 16.31561375 31.55318473], cur_train_grp_loss: [0.09479564 0.12306844 0.2374315 ], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6799, max_kl_dist_index: 2, max_train_grp_loss:  15.8757, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8839, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:33:01,195 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  132, train_loss:  13.4335, val_loss:  12.2603, grad_norm: 0.0018, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6504, 0.3471, 0.6799, param: [4.15203926 9.4896     4.97499457 8.87157581], weights: [0.30778954 0.31959036 0.3726201 ], train_wt_loss:  40.3005, val_wt_loss: 36.7810, train_grp_loss: [11.75487926 15.87560075 11.1593371 ], val_grp_loss: [10.63489532 14.8837601  11.27810222], train_hist_grp_loss: [12.6762987  16.43868131 31.79061683], cur_train_grp_loss: [0.09479653 0.12306755 0.2374321 ], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6799, max_kl_dist_index: 2, max_train_grp_loss:  15.8756, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8838, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:33:02,201 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  133, train_loss:  13.4335, val_loss:  12.2603, grad_norm: 0.0018, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6504, 0.3471, 0.6799, param: [4.15203052 9.48937392 4.97513026 8.87173148], weights: [0.30759814 0.31948193 0.37291993], train_wt_loss:  40.3005, val_wt_loss: 36.7810, train_grp_loss: [11.75498841 15.87548779 11.15936515], val_grp_loss: [10.63496999 14.88362053 11.27815005], train_hist_grp_loss: [12.77109612 16.56174798 32.02804954], cur_train_grp_loss: [0.09479741 0.12306667 0.2374327 ], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6799, max_kl_dist_index: 2, max_train_grp_loss:  15.8755, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8836, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:33:03,209 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  134, train_loss:  13.4335, val_loss:  12.2603, grad_norm: 0.0019, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6504, 0.3471, 0.6799, param: [4.15202155 9.48914834 4.97526577 8.87188771], weights: [0.30740674 0.3193734  0.37321985], train_wt_loss:  40.3005, val_wt_loss: 36.7810, train_grp_loss: [11.75509703 15.87537544 11.15939297], val_grp_loss: [10.63504419 14.88348186 11.27819769], train_hist_grp_loss: [12.86589441 16.68481377 32.26548284], cur_train_grp_loss: [0.09479829 0.1230658  0.2374333 ], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6799, max_kl_dist_index: 2, max_train_grp_loss:  15.8754, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8835, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:33:04,287 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  135, train_loss:  13.4335, val_loss:  12.2603, grad_norm: 0.0019, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6504, 0.3471, 0.6799, param: [4.15201234 9.48892328 4.97540109 8.8720445 ], weights: [0.30721535 0.31926479 0.37351987], train_wt_loss:  40.3005, val_wt_loss: 36.7810, train_grp_loss: [11.75520512 15.87526369 11.15942057], val_grp_loss: [10.63511792 14.88334411 11.27824516], train_hist_grp_loss: [12.96069358 16.8078787  32.50291673], cur_train_grp_loss: [0.09479917 0.12306493 0.23743389], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6799, max_kl_dist_index: 2, max_train_grp_loss:  15.8753, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8833, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:33:05,308 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  136, train_loss:  13.4335, val_loss:  12.2603, grad_norm: 0.0019, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6504, 0.3471, 0.6799, param: [4.15200288 9.48869872 4.97553623 8.87220184], weights: [0.30702395 0.31915608 0.37381998], train_wt_loss:  40.3005, val_wt_loss: 36.7810, train_grp_loss: [11.75531267 15.87515256 11.15944793], val_grp_loss: [10.63519117 14.88320727 11.27829245], train_hist_grp_loss: [13.05549362 16.93094276 32.74035121], cur_train_grp_loss: [0.09480004 0.12306406 0.23743448], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6799, max_kl_dist_index: 2, max_train_grp_loss:  15.8752, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8832, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:33:06,309 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  137, train_loss:  13.4335, val_loss:  12.2603, grad_norm: 0.0019, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6504, 0.3471, 0.6799, param: [4.15199319 9.48847468 4.97567119 8.87235974], weights: [0.30683255 0.31904727 0.37412018], train_wt_loss:  40.3005, val_wt_loss: 36.7810, train_grp_loss: [11.75541969 15.87504203 11.15947506], val_grp_loss: [10.63526396 14.88307135 11.27833956], train_hist_grp_loss: [13.15029453 17.05400596 32.97778627], cur_train_grp_loss: [0.09480091 0.1230632  0.23743506], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6799, max_kl_dist_index: 2, max_train_grp_loss:  15.8750, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8831, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:33:07,329 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  138, train_loss:  13.4335, val_loss:  12.2603, grad_norm: 0.0019, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6504, 0.3471, 0.6799, param: [4.15198327 9.48825115 4.97580597 8.8725182 ], weights: [0.30664115 0.31893837 0.37442048], train_wt_loss:  40.3005, val_wt_loss: 36.7810, train_grp_loss: [11.75552617 15.87493211 11.15950196], val_grp_loss: [10.63533627 14.88293633 11.27838649], train_hist_grp_loss: [13.2450963  17.1770683  33.21522191], cur_train_grp_loss: [0.09480177 0.12306234 0.23743564], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6799, max_kl_dist_index: 2, max_train_grp_loss:  15.8749, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8829, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:33:08,353 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  139, train_loss:  13.4335, val_loss:  12.2603, grad_norm: 0.0019, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6504, 0.3471, 0.6799, param: [4.1519731  9.48802813 4.97594057 8.87267722], weights: [0.30644975 0.31882938 0.37472087], train_wt_loss:  40.3005, val_wt_loss: 36.7809, train_grp_loss: [11.75563212 15.87482279 11.15952863], val_grp_loss: [10.63540811 14.88280223 11.27843324], train_hist_grp_loss: [13.33989893 17.30012979 33.45265812], cur_train_grp_loss: [0.09480263 0.12306149 0.23743621], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6799, max_kl_dist_index: 2, max_train_grp_loss:  15.8748, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8828, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:33:09,360 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  140, train_loss:  13.4335, val_loss:  12.2603, grad_norm: 0.0019, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6504, 0.3471, 0.6799, param: [4.15196269 9.48780562 4.97607498 8.87283679], weights: [0.30625835 0.3187203  0.37502135], train_wt_loss:  40.3005, val_wt_loss: 36.7809, train_grp_loss: [11.75573753 15.87471409 11.15955507], val_grp_loss: [10.63547948 14.88266904 11.27847982], train_hist_grp_loss: [13.43470242 17.42319043 33.6900949 ], cur_train_grp_loss: [0.09480348 0.12306064 0.23743678], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6799, max_kl_dist_index: 2, max_train_grp_loss:  15.8747, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8827, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:33:10,407 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  141, train_loss:  13.4335, val_loss:  12.2603, grad_norm: 0.0020, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6504, 0.3470, 0.6799, param: [4.15195205 9.48758362 4.97620921 8.87299692], weights: [0.30606695 0.31861112 0.37532193], train_wt_loss:  40.3005, val_wt_loss: 36.7809, train_grp_loss: [11.7558424  15.87460599 11.15958128], val_grp_loss: [10.63555038 14.88253676 11.27852621], train_hist_grp_loss: [13.52950675 17.54625023 33.92753224], cur_train_grp_loss: [0.09480433 0.1230598  0.23743734], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6799, max_kl_dist_index: 2, max_train_grp_loss:  15.8746, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8825, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:33:11,443 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  142, train_loss:  13.4335, val_loss:  12.2603, grad_norm: 0.0020, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6504, 0.3470, 0.6799, param: [4.15194117 9.48736213 4.97634326 8.87315761], weights: [0.30587555 0.31850185 0.3756226 ], train_wt_loss:  40.3005, val_wt_loss: 36.7809, train_grp_loss: [11.75594674 15.87449851 11.15960725], val_grp_loss: [10.6356208  14.88240539 11.27857243], train_hist_grp_loss: [13.62431193 17.66930919 34.16497014], cur_train_grp_loss: [0.09480518 0.12305896 0.2374379 ], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6799, max_kl_dist_index: 2, max_train_grp_loss:  15.8745, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8824, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:33:12,465 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  143, train_loss:  13.4335, val_loss:  12.2603, grad_norm: 0.0020, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6504, 0.3470, 0.6799, param: [4.15193004 9.48714116 4.97647713 8.87331886], weights: [0.30568415 0.31839249 0.37592336], train_wt_loss:  40.3005, val_wt_loss: 36.7809, train_grp_loss: [11.75605054 15.87439163 11.159633  ], val_grp_loss: [10.63569076 14.88227494 11.27861847], train_hist_grp_loss: [13.71911796 17.79236732 34.4024086 ], cur_train_grp_loss: [0.09480602 0.12305813 0.23743845], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6799, max_kl_dist_index: 2, max_train_grp_loss:  15.8744, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8823, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:33:13,535 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  144, train_loss:  13.4335, val_loss:  12.2603, grad_norm: 0.0020, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6504, 0.3470, 0.6799, param: [4.15191868 9.48692069 4.97661081 8.87348067], weights: [0.30549275 0.31828304 0.37622421], train_wt_loss:  40.3005, val_wt_loss: 36.7809, train_grp_loss: [11.75615381 15.87428536 11.15965851], val_grp_loss: [10.63576024 14.8821454  11.27866433], train_hist_grp_loss: [13.81392481 17.91542462 34.6398476 ], cur_train_grp_loss: [0.09480686 0.1230573  0.237439  ], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6799, max_kl_dist_index: 2, max_train_grp_loss:  15.8743, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8821, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:33:14,557 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  145, train_loss:  13.4335, val_loss:  12.2603, grad_norm: 0.0020, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6504, 0.3470, 0.6799, param: [4.15190708 9.48670074 4.97674432 8.87364304], weights: [0.30530135 0.31817349 0.37652516], train_wt_loss:  40.3005, val_wt_loss: 36.7809, train_grp_loss: [11.75625653 15.8741797  11.15968379], val_grp_loss: [10.63582924 14.88201678 11.27871001], train_hist_grp_loss: [13.90873251 18.03848109 34.87728714], cur_train_grp_loss: [0.09480769 0.12305648 0.23743954], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6799, max_kl_dist_index: 2, max_train_grp_loss:  15.8742, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8820, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:33:15,583 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  146, train_loss:  13.4335, val_loss:  12.2603, grad_norm: 0.0020, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6504, 0.3470, 0.6799, param: [4.15189525 9.4864813  4.97687763 8.87380597], weights: [0.30510995 0.31806385 0.3768262 ], train_wt_loss:  40.3005, val_wt_loss: 36.7808, train_grp_loss: [11.75635873 15.87407465 11.15970885], val_grp_loss: [10.63589777 14.88188906 11.27875551], train_hist_grp_loss: [14.00354103 18.16153675 35.11472722], cur_train_grp_loss: [0.09480852 0.12305566 0.23744008], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6799, max_kl_dist_index: 2, max_train_grp_loss:  15.8741, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8819, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:33:16,625 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  147, train_loss:  13.4335, val_loss:  12.2603, grad_norm: 0.0020, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6504, 0.3470, 0.6799, param: [4.15188317 9.48626237 4.97701077 8.87396945], weights: [0.30491855 0.31795412 0.37712733], train_wt_loss:  40.3005, val_wt_loss: 36.7808, train_grp_loss: [11.75646038 15.87397021 11.15973366], val_grp_loss: [10.63596583 14.88176227 11.27880084], train_hist_grp_loss: [14.09835037 18.28459159 35.35216783], cur_train_grp_loss: [0.09480934 0.12305484 0.23744061], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6799, max_kl_dist_index: 2, max_train_grp_loss:  15.8740, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8818, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:33:17,659 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  148, train_loss:  13.4335, val_loss:  12.2603, grad_norm: 0.0020, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6504, 0.3470, 0.6799, param: [4.15187085 9.48604395 4.97714372 8.8741335 ], weights: [0.30472715 0.3178443  0.37742855], train_wt_loss:  40.3005, val_wt_loss: 36.7808, train_grp_loss: [11.7565615  15.87386638 11.15975825], val_grp_loss: [10.63603342 14.88163638 11.27884598], train_hist_grp_loss: [14.19316054 18.40764563 35.58960898], cur_train_grp_loss: [0.09481016 0.12305403 0.23744114], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6799, max_kl_dist_index: 2, max_train_grp_loss:  15.8739, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8816, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:33:18,705 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  149, train_loss:  13.4335, val_loss:  12.2603, grad_norm: 0.0021, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6504, 0.3470, 0.6799, param: [4.1518583  9.48582604 4.97727649 8.8742981 ], weights: [0.30453575 0.31773439 0.37772986], train_wt_loss:  40.3005, val_wt_loss: 36.7808, train_grp_loss: [11.75666208 15.87376316 11.15978261], val_grp_loss: [10.63610053 14.88151141 11.27889094], train_hist_grp_loss: [14.28797152 18.53069885 35.82705064], cur_train_grp_loss: [0.09481098 0.12305323 0.23744166], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6799, max_kl_dist_index: 2, max_train_grp_loss:  15.8738, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8815, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:33:19,738 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  150, train_loss:  13.4335, val_loss:  12.2603, grad_norm: 0.0021, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6504, 0.3470, 0.6799, param: [4.1518455  9.48560864 4.97740908 8.87446327], weights: [0.30434436 0.31762438 0.37803126], train_wt_loss:  40.3005, val_wt_loss: 36.7808, train_grp_loss: [11.75676212 15.87366054 11.15980673], val_grp_loss: [10.63616717 14.88138736 11.27893573], train_hist_grp_loss: [14.38278331 18.65375128 36.06449282], cur_train_grp_loss: [0.09481179 0.12305243 0.23744218], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6799, max_kl_dist_index: 2, max_train_grp_loss:  15.8737, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8814, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:33:20,758 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  151, train_loss:  13.4335, val_loss:  12.2603, grad_norm: 0.0021, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6504, 0.3470, 0.6799, param: [4.15183247 9.48539176 4.97754148 8.87462899], weights: [0.30415296 0.31751428 0.37833276], train_wt_loss:  40.3005, val_wt_loss: 36.7808, train_grp_loss: [11.75686162 15.87355854 11.15983062], val_grp_loss: [10.63623334 14.88126422 11.27898033], train_hist_grp_loss: [14.4775959  18.77680291 36.30193552], cur_train_grp_loss: [0.0948126  0.12305163 0.2374427 ], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6799, max_kl_dist_index: 2, max_train_grp_loss:  15.8736, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8813, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:33:21,780 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  152, train_loss:  13.4335, val_loss:  12.2603, grad_norm: 0.0021, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6504, 0.3470, 0.6799, param: [4.1518192  9.48517539 4.9776737  8.87479528], weights: [0.30396156 0.31740409 0.37863434], train_wt_loss:  40.3005, val_wt_loss: 36.7808, train_grp_loss: [11.75696059 15.87345715 11.15985428], val_grp_loss: [10.63629903 14.881142   11.27902476], train_hist_grp_loss: [14.5724093  18.89985375 36.53937872], cur_train_grp_loss: [0.0948134  0.12305084 0.2374432 ], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6799, max_kl_dist_index: 2, max_train_grp_loss:  15.8735, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8811, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:33:22,779 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  153, train_loss:  13.4335, val_loss:  12.2603, grad_norm: 0.0021, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6504, 0.3470, 0.6799, param: [4.15180569 9.48495953 4.97780573 8.87496212], weights: [0.30377017 0.31729381 0.37893602], train_wt_loss:  40.3005, val_wt_loss: 36.7808, train_grp_loss: [11.75705902 15.87335637 11.15987771], val_grp_loss: [10.63636425 14.88102069 11.27906901], train_hist_grp_loss: [14.6672235  19.02290381 36.77682243], cur_train_grp_loss: [0.0948142  0.12305006 0.23744371], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6799, max_kl_dist_index: 2, max_train_grp_loss:  15.8734, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8810, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:33:23,815 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  154, train_loss:  13.4335, val_loss:  12.2602, grad_norm: 0.0021, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6504, 0.3470, 0.6799, param: [4.15179193 9.48474418 4.97793758 8.87512953], weights: [0.30357877 0.31718344 0.37923779], train_wt_loss:  40.3005, val_wt_loss: 36.7807, train_grp_loss: [11.75715691 15.8732562  11.15990091], val_grp_loss: [10.63642899 14.8809003  11.27911307], train_hist_grp_loss: [14.7620385  19.14595308 37.01426664], cur_train_grp_loss: [0.09481499 0.12304927 0.23744421], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6799, max_kl_dist_index: 2, max_train_grp_loss:  15.8733, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8809, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:33:24,839 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  155, train_loss:  13.4335, val_loss:  12.2602, grad_norm: 0.0021, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6504, 0.3470, 0.6799, param: [4.15177794 9.48452934 4.97806925 8.8752975 ], weights: [0.30338738 0.31707298 0.37953964], train_wt_loss:  40.3005, val_wt_loss: 36.7807, train_grp_loss: [11.75725426 15.87315664 11.15992387], val_grp_loss: [10.63649326 14.88078082 11.27915696], train_hist_grp_loss: [14.85685428 19.26900158 37.25171134], cur_train_grp_loss: [0.09481578 0.1230485  0.2374447 ], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6799, max_kl_dist_index: 2, max_train_grp_loss:  15.8732, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8808, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:33:25,871 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  156, train_loss:  13.4335, val_loss:  12.2602, grad_norm: 0.0021, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6504, 0.3470, 0.6799, param: [4.15176371 9.48431502 4.97820073 8.87546602], weights: [0.30319599 0.31696242 0.37984159], train_wt_loss:  40.3005, val_wt_loss: 36.7807, train_grp_loss: [11.75735107 15.87305769 11.1599466 ], val_grp_loss: [10.63655706 14.88066226 11.27920067], train_hist_grp_loss: [14.95167084 19.39204931 37.48915653], cur_train_grp_loss: [0.09481657 0.12304773 0.23744519], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6799, max_kl_dist_index: 2, max_train_grp_loss:  15.8731, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8807, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:33:26,878 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  157, train_loss:  13.4335, val_loss:  12.2602, grad_norm: 0.0022, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6504, 0.3470, 0.6799, param: [4.15174924 9.4841012  4.97833203 8.87563511], weights: [0.3030046  0.31685177 0.38014362], train_wt_loss:  40.3005, val_wt_loss: 36.7807, train_grp_loss: [11.75744735 15.87295935 11.1599691 ], val_grp_loss: [10.63662038 14.88054461 11.2792442 ], train_hist_grp_loss: [15.04648819 19.51509627 37.7266022 ], cur_train_grp_loss: [0.09481735 0.12304696 0.23744567], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6799, max_kl_dist_index: 2, max_train_grp_loss:  15.8730, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8805, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:33:27,898 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  158, train_loss:  13.4335, val_loss:  12.2602, grad_norm: 0.0022, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6505, 0.3470, 0.6799, param: [4.15173454 9.4838879  4.97846314 8.87580476], weights: [0.30281322 0.31674104 0.38044575], train_wt_loss:  40.3005, val_wt_loss: 36.7807, train_grp_loss: [11.75754308 15.87286162 11.15999136], val_grp_loss: [10.63668322 14.88042789 11.27928754], train_hist_grp_loss: [15.14130631 19.63814246 37.96404835], cur_train_grp_loss: [0.09481812 0.1230462  0.23744615], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6799, max_kl_dist_index: 2, max_train_grp_loss:  15.8729, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8804, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:33:28,925 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  159, train_loss:  13.4335, val_loss:  12.2602, grad_norm: 0.0022, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6505, 0.3470, 0.6799, param: [4.15171959 9.48367511 4.97859407 8.87597498], weights: [0.30262183 0.31663021 0.38074796], train_wt_loss:  40.3005, val_wt_loss: 36.7807, train_grp_loss: [11.75763828 15.8727645  11.1600134 ], val_grp_loss: [10.63674559 14.88031207 11.27933071], train_hist_grp_loss: [15.23612521 19.7611879  38.20149498], cur_train_grp_loss: [0.0948189  0.12304544 0.23744662], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6799, max_kl_dist_index: 2, max_train_grp_loss:  15.8728, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8803, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:33:29,958 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  160, train_loss:  13.4335, val_loss:  12.2602, grad_norm: 0.0022, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6505, 0.3470, 0.6799, param: [4.1517044  9.48346284 4.97872482 8.87614575], weights: [0.30243045 0.31651929 0.38105026], train_wt_loss:  40.3005, val_wt_loss: 36.7807, train_grp_loss: [11.75773293 15.872668   11.1600352 ], val_grp_loss: [10.63680749 14.88019718 11.2793737 ], train_hist_grp_loss: [15.33094487 19.88423259 38.43894207], cur_train_grp_loss: [0.09481966 0.12304469 0.23744709], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6799, max_kl_dist_index: 2, max_train_grp_loss:  15.8727, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8802, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:33:30,977 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  161, train_loss:  13.4335, val_loss:  12.2602, grad_norm: 0.0022, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6505, 0.3470, 0.6799, param: [4.15168897 9.48325107 4.97885538 8.87631708], weights: [0.30223906 0.31640828 0.38135265], train_wt_loss:  40.3006, val_wt_loss: 36.7807, train_grp_loss: [11.75782705 15.8725721  11.16005676], val_grp_loss: [10.63686891 14.8800832  11.27941651], train_hist_grp_loss: [15.4257653  20.00727653 38.67638963], cur_train_grp_loss: [0.09482043 0.12304394 0.23744756], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6799, max_kl_dist_index: 2, max_train_grp_loss:  15.8726, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8801, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:33:31,989 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  162, train_loss:  13.4335, val_loss:  12.2602, grad_norm: 0.0022, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6505, 0.3470, 0.6799, param: [4.15167331 9.48303982 4.97898575 8.87648898], weights: [0.30204768 0.31629718 0.38165513], train_wt_loss:  40.3006, val_wt_loss: 36.7807, train_grp_loss: [11.75792063 15.87247682 11.1600781 ], val_grp_loss: [10.63692985 14.87997014 11.27945913], train_hist_grp_loss: [15.52058649 20.13031972 38.91383764], cur_train_grp_loss: [0.09482119 0.12304319 0.23744802], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6799, max_kl_dist_index: 2, max_train_grp_loss:  15.8725, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8800, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:33:33,026 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  163, train_loss:  13.4335, val_loss:  12.2602, grad_norm: 0.0022, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6505, 0.3470, 0.6799, param: [4.1516574  9.48282908 4.97911594 8.87666144], weights: [0.30185631 0.31618599 0.3819577 ], train_wt_loss:  40.3006, val_wt_loss: 36.7807, train_grp_loss: [11.75801366 15.87238215 11.1600992 ], val_grp_loss: [10.63699032 14.879858   11.27950158], train_hist_grp_loss: [15.61540843 20.25336218 39.15128611], cur_train_grp_loss: [0.09482194 0.12304246 0.23744847], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6799, max_kl_dist_index: 2, max_train_grp_loss:  15.8724, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8799, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:33:34,075 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  164, train_loss:  13.4335, val_loss:  12.2602, grad_norm: 0.0023, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6505, 0.3470, 0.6799, param: [4.15164125 9.48261885 4.97924595 8.87683446], weights: [0.30166493 0.31607471 0.38226036], train_wt_loss:  40.3006, val_wt_loss: 36.7807, train_grp_loss: [11.75810616 15.87228809 11.16012007], val_grp_loss: [10.63705032 14.87974678 11.27954384], train_hist_grp_loss: [15.71023112 20.3764039  39.38873503], cur_train_grp_loss: [0.09482269 0.12304172 0.23744892], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6799, max_kl_dist_index: 2, max_train_grp_loss:  15.8723, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8797, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:33:35,117 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  165, train_loss:  13.4335, val_loss:  12.2602, grad_norm: 0.0023, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6505, 0.3470, 0.6799, param: [4.15162487 9.48240914 4.97937577 8.87700805], weights: [0.30147356 0.31596334 0.3825631 ], train_wt_loss:  40.3006, val_wt_loss: 36.7806, train_grp_loss: [11.75819812 15.87219464 11.1601407 ], val_grp_loss: [10.63710984 14.87963647 11.27958593], train_hist_grp_loss: [15.80505455 20.49944489 39.6261844 ], cur_train_grp_loss: [0.09482344 0.12304099 0.23744936], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6799, max_kl_dist_index: 2, max_train_grp_loss:  15.8722, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8796, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:33:36,128 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  166, train_loss:  13.4335, val_loss:  12.2602, grad_norm: 0.0023, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6505, 0.3470, 0.6799, param: [4.15160824 9.48219993 4.9795054  8.87718219], weights: [0.30128219 0.31585188 0.38286593], train_wt_loss:  40.3006, val_wt_loss: 36.7806, train_grp_loss: [11.75828953 15.8721018  11.1601611 ], val_grp_loss: [10.63716888 14.87952709 11.27962784], train_hist_grp_loss: [15.89987873 20.62248516 39.8636342 ], cur_train_grp_loss: [0.09482418 0.12304027 0.2374498 ], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6799, max_kl_dist_index: 2, max_train_grp_loss:  15.8721, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8795, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:33:37,155 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  167, train_loss:  13.4335, val_loss:  12.2602, grad_norm: 0.0023, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6505, 0.3470, 0.6799, param: [4.15159137 9.48199124 4.97963485 8.8773569 ], weights: [0.30109082 0.31574033 0.38316885], train_wt_loss:  40.3006, val_wt_loss: 36.7806, train_grp_loss: [11.75838041 15.87200958 11.16018127], val_grp_loss: [10.63722744 14.87941862 11.27966956], train_hist_grp_loss: [15.99470365 20.74552471 40.10108443], cur_train_grp_loss: [0.09482492 0.12303955 0.23745024], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6799, max_kl_dist_index: 2, max_train_grp_loss:  15.8720, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8794, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2375, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:33:38,172 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  168, train_loss:  13.4335, val_loss:  12.2602, grad_norm: 0.0023, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6505, 0.3470, 0.6799, param: [4.15157427 9.48178306 4.97976412 8.87753217], weights: [0.30089945 0.31562869 0.38347185], train_wt_loss:  40.3006, val_wt_loss: 36.7806, train_grp_loss: [11.75847074 15.87191797 11.16020121], val_grp_loss: [10.63728553 14.87931107 11.2797111 ], train_hist_grp_loss: [16.0895293  20.86856354 40.3385351 ], cur_train_grp_loss: [0.09482565 0.12303883 0.23745067], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6799, max_kl_dist_index: 2, max_train_grp_loss:  15.8719, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8793, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2375, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:33:39,215 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  169, train_loss:  13.4335, val_loss:  12.2602, grad_norm: 0.0023, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6505, 0.3470, 0.6799, param: [4.15155692 9.4815754  4.9798932  8.87770801], weights: [0.30070809 0.31551697 0.38377494], train_wt_loss:  40.3006, val_wt_loss: 36.7806, train_grp_loss: [11.75856053 15.87182697 11.16022091], val_grp_loss: [10.63734315 14.87920444 11.27975247], train_hist_grp_loss: [16.18435567 20.99160167 40.57598619], cur_train_grp_loss: [0.09482638 0.12303812 0.23745109], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6799, max_kl_dist_index: 2, max_train_grp_loss:  15.8718, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8792, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2375, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:33:40,242 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  170, train_loss:  13.4335, val_loss:  12.2602, grad_norm: 0.0023, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6505, 0.3470, 0.6799, param: [4.15153933 9.48136824 4.98002209 8.87788441], weights: [0.30051673 0.31540515 0.38407812], train_wt_loss:  40.3006, val_wt_loss: 36.7806, train_grp_loss: [11.75864978 15.87173658 11.16024038], val_grp_loss: [10.63740029 14.87909873 11.27979365], train_hist_grp_loss: [16.27918278 21.11463908 40.8134377 ], cur_train_grp_loss: [0.0948271  0.12303742 0.23745151], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6799, max_kl_dist_index: 2, max_train_grp_loss:  15.8717, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8791, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2375, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:33:41,271 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  171, train_loss:  13.4335, val_loss:  12.2602, grad_norm: 0.0023, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6505, 0.3470, 0.6799, param: [4.15152151 9.4811616  4.98015079 8.87806137], weights: [0.30032537 0.31529324 0.38438139], train_wt_loss:  40.3006, val_wt_loss: 36.7806, train_grp_loss: [11.75873849 15.87164681 11.16025961], val_grp_loss: [10.63745695 14.87899393 11.27983465], train_hist_grp_loss: [16.3740106  21.2376758  41.05088962], cur_train_grp_loss: [0.09482782 0.12303672 0.23745192], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6799, max_kl_dist_index: 2, max_train_grp_loss:  15.8716, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8790, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2375, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:33:42,297 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  172, train_loss:  13.4335, val_loss:  12.2602, grad_norm: 0.0024, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6505, 0.3470, 0.6799, param: [4.15150344 9.48095548 4.98027932 8.8782389 ], weights: [0.30013402 0.31518124 0.38468474], train_wt_loss:  40.3006, val_wt_loss: 36.7806, train_grp_loss: [11.75882666 15.87155765 11.16027861], val_grp_loss: [10.63751313 14.87889006 11.27987547], train_hist_grp_loss: [16.46883913 21.36071182 41.28834195], cur_train_grp_loss: [0.09482854 0.12303602 0.23745233], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6799, max_kl_dist_index: 2, max_train_grp_loss:  15.8716, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8789, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2375, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:33:43,340 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  173, train_loss:  13.4335, val_loss:  12.2602, grad_norm: 0.0024, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6505, 0.3470, 0.6799, param: [4.15148513 9.48074986 4.98040765 8.87841699], weights: [0.29994267 0.31506915 0.38498818], train_wt_loss:  40.3006, val_wt_loss: 36.7806, train_grp_loss: [11.75891429 15.8714691  11.16029738], val_grp_loss: [10.63756884 14.87878711 11.27991611], train_hist_grp_loss: [16.56366838 21.48374715 41.52579469], cur_train_grp_loss: [0.09482925 0.12303533 0.23745274], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6799, max_kl_dist_index: 2, max_train_grp_loss:  15.8715, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8788, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2375, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:33:44,406 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  174, train_loss:  13.4335, val_loss:  12.2602, grad_norm: 0.0024, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6505, 0.3470, 0.6799, param: [4.15146659 9.48054476 4.9805358  8.87859564], weights: [0.29975132 0.31495698 0.3852917 ], train_wt_loss:  40.3006, val_wt_loss: 36.7806, train_grp_loss: [11.75900138 15.87138116 11.16031591], val_grp_loss: [10.63762407 14.87868508 11.27995657], train_hist_grp_loss: [16.65849833 21.6067818  41.76324782], cur_train_grp_loss: [0.09482995 0.12303464 0.23745314], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6799, max_kl_dist_index: 2, max_train_grp_loss:  15.8714, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8787, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2375, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:33:45,447 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  175, train_loss:  13.4335, val_loss:  12.2602, grad_norm: 0.0024, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6505, 0.3470, 0.6799, param: [4.1514478  9.48034017 4.98066376 8.87877486], weights: [0.29955998 0.31484471 0.38559531], train_wt_loss:  40.3006, val_wt_loss: 36.7806, train_grp_loss: [11.75908792 15.87129384 11.16033421], val_grp_loss: [10.63767882 14.87858397 11.27999685], train_hist_grp_loss: [16.75332899 21.72981576 42.00070135], cur_train_grp_loss: [0.09483066 0.12303396 0.23745353], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6799, max_kl_dist_index: 2, max_train_grp_loss:  15.8713, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8786, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2375, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:33:46,473 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  176, train_loss:  13.4335, val_loss:  12.2602, grad_norm: 0.0024, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6505, 0.3470, 0.6799, param: [4.15142877 9.48013609 4.98079154 8.87895464], weights: [0.29936864 0.31473236 0.385899  ], train_wt_loss:  40.3006, val_wt_loss: 36.7806, train_grp_loss: [11.75917392 15.87120713 11.16035227], val_grp_loss: [10.6377331  14.87848377 11.28003694], train_hist_grp_loss: [16.84816034 21.85284905 42.23815527], cur_train_grp_loss: [0.09483135 0.12303329 0.23745392], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6799, max_kl_dist_index: 2, max_train_grp_loss:  15.8712, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8785, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2375, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:33:47,515 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  177, train_loss:  13.4335, val_loss:  12.2602, grad_norm: 0.0024, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6505, 0.3470, 0.6799, param: [4.1514095  9.47993253 4.98091912 8.87913499], weights: [0.29917731 0.31461991 0.38620278], train_wt_loss:  40.3006, val_wt_loss: 36.7806, train_grp_loss: [11.75925938 15.87112104 11.16037011], val_grp_loss: [10.6377869  14.8783845  11.28007686], train_hist_grp_loss: [16.94299239 21.97588166 42.47560958], cur_train_grp_loss: [0.09483205 0.12303261 0.2374543 ], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6799, max_kl_dist_index: 2, max_train_grp_loss:  15.8711, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8784, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2375, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:33:48,558 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  178, train_loss:  13.4335, val_loss:  12.2602, grad_norm: 0.0024, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6505, 0.3470, 0.6799, param: [4.15138999 9.47972948 4.98104653 8.8793159 ], weights: [0.29898597 0.31450738 0.38650664], train_wt_loss:  40.3006, val_wt_loss: 36.7806, train_grp_loss: [11.75934429 15.87103556 11.1603877 ], val_grp_loss: [10.63784022 14.87828615 11.28011659], train_hist_grp_loss: [17.03782513 22.09891361 42.71306426], cur_train_grp_loss: [0.09483274 0.12303195 0.23745468], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6799, max_kl_dist_index: 2, max_train_grp_loss:  15.8710, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8783, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2375, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:33:49,608 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  179, train_loss:  13.4335, val_loss:  12.2602, grad_norm: 0.0024, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6505, 0.3470, 0.6799, param: [4.15137025 9.47952694 4.98117374 8.87949737], weights: [0.29879465 0.31439476 0.38681059], train_wt_loss:  40.3006, val_wt_loss: 36.7806, train_grp_loss: [11.75942867 15.87095069 11.16040506], val_grp_loss: [10.63789306 14.87818873 11.28015614], train_hist_grp_loss: [17.13265855 22.22194489 42.95051932], cur_train_grp_loss: [0.09483342 0.12303128 0.23745506], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6799, max_kl_dist_index: 2, max_train_grp_loss:  15.8710, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8782, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2375, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:33:50,625 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  180, train_loss:  13.4335, val_loss:  12.2602, grad_norm: 0.0025, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6505, 0.3470, 0.6799, param: [4.15135026 9.47932491 4.98130077 8.87967941], weights: [0.29860332 0.31428205 0.38711462], train_wt_loss:  40.3006, val_wt_loss: 36.7806, train_grp_loss: [11.7595125  15.87086644 11.16042219], val_grp_loss: [10.63794543 14.87809222 11.28019551], train_hist_grp_loss: [17.22749265 22.34497552 43.18797475], cur_train_grp_loss: [0.0948341  0.12303063 0.23745543], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6799, max_kl_dist_index: 2, max_train_grp_loss:  15.8709, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8781, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2375, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:33:51,642 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  181, train_loss:  13.4335, val_loss:  12.2602, grad_norm: 0.0025, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6505, 0.3470, 0.6799, param: [4.15133003 9.4791234  4.98142761 8.87986202], weights: [0.298412   0.31416926 0.38741874], train_wt_loss:  40.3006, val_wt_loss: 36.7806, train_grp_loss: [11.75959578 15.8707828  11.16043909], val_grp_loss: [10.63799732 14.87799663 11.2802347 ], train_hist_grp_loss: [17.32232743 22.46800549 43.42543054], cur_train_grp_loss: [0.09483478 0.12302997 0.23745579], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6799, max_kl_dist_index: 2, max_train_grp_loss:  15.8708, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8780, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2375, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:33:52,643 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  182, train_loss:  13.4335, val_loss:  12.2602, grad_norm: 0.0025, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6505, 0.3470, 0.6799, param: [4.15130956 9.4789224  4.98155427 8.88004519], weights: [0.29822069 0.31405637 0.38772294], train_wt_loss:  40.3006, val_wt_loss: 36.7805, train_grp_loss: [11.75967853 15.87069977 11.16045575], val_grp_loss: [10.63804873 14.87790197 11.28027371], train_hist_grp_loss: [17.41716288 22.59103481 43.66288669], cur_train_grp_loss: [0.09483545 0.12302932 0.23745615], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6799, max_kl_dist_index: 2, max_train_grp_loss:  15.8707, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8779, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2375, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:33:53,712 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  183, train_loss:  13.4335, val_loss:  12.2602, grad_norm: 0.0025, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6505, 0.3470, 0.6799, param: [4.15128884 9.47872191 4.98168073 8.88022893], weights: [0.29802938 0.3139434  0.38802723], train_wt_loss:  40.3006, val_wt_loss: 36.7805, train_grp_loss: [11.75976073 15.87061736 11.16047217], val_grp_loss: [10.63809966 14.87780823 11.28031253], train_hist_grp_loss: [17.511999   22.71406349 43.90034319], cur_train_grp_loss: [0.09483612 0.12302868 0.23745651], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6799, max_kl_dist_index: 2, max_train_grp_loss:  15.8706, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8778, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2375, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:33:54,751 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  184, train_loss:  13.4335, val_loss:  12.2602, grad_norm: 0.0025, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6505, 0.3470, 0.6799, param: [4.15126789 9.47852194 4.98180701 8.88041323], weights: [0.29783807 0.31383034 0.38833159], train_wt_loss:  40.3006, val_wt_loss: 36.7805, train_grp_loss: [11.75984239 15.87053556 11.16048836], val_grp_loss: [10.63815011 14.87771541 11.28035118], train_hist_grp_loss: [17.60683578 22.83709153 44.13780005], cur_train_grp_loss: [0.09483678 0.12302804 0.23745685], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6799, max_kl_dist_index: 2, max_train_grp_loss:  15.8705, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8777, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2375, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:33:55,778 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  185, train_loss:  13.4335, val_loss:  12.2602, grad_norm: 0.0025, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6506, 0.3470, 0.6799, param: [4.1512467  9.47832248 4.9819331  8.88059809], weights: [0.29764677 0.31371719 0.38863604], train_wt_loss:  40.3006, val_wt_loss: 36.7805, train_grp_loss: [11.7599235  15.87045438 11.16050432], val_grp_loss: [10.63820009 14.87762351 11.28038964], train_hist_grp_loss: [17.70167322 22.96011894 44.37525725], cur_train_grp_loss: [0.09483744 0.12302741 0.2374572 ], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6799, max_kl_dist_index: 2, max_train_grp_loss:  15.8705, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8776, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2375, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:33:56,809 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  186, train_loss:  13.4335, val_loss:  12.2602, grad_norm: 0.0025, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6506, 0.3470, 0.6800, param: [4.15122526 9.47812353 4.98205901 8.88078353], weights: [0.29745547 0.31360395 0.38894058], train_wt_loss:  40.3006, val_wt_loss: 36.7805, train_grp_loss: [11.76000407 15.87037381 11.16052004], val_grp_loss: [10.63824959 14.87753254 11.28042792], train_hist_grp_loss: [17.79651131 23.08314572 44.61271479], cur_train_grp_loss: [0.09483809 0.12302678 0.23745754], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6800, max_kl_dist_index: 2, max_train_grp_loss:  15.8704, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8775, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2375, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:33:57,849 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  187, train_loss:  13.4335, val_loss:  12.2602, grad_norm: 0.0025, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6506, 0.3470, 0.6800, param: [4.15120359 9.4779251  4.98218472 8.88096953], weights: [0.29726418 0.31349063 0.38924519], train_wt_loss:  40.3006, val_wt_loss: 36.7805, train_grp_loss: [11.76008409 15.87029386 11.16053552], val_grp_loss: [10.63829861 14.87744249 11.28046602], train_hist_grp_loss: [17.89135005 23.20617187 44.85017266], cur_train_grp_loss: [0.09483874 0.12302615 0.23745787], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6800, max_kl_dist_index: 2, max_train_grp_loss:  15.8703, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8774, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2375, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:33:58,906 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  188, train_loss:  13.4335, val_loss:  12.2602, grad_norm: 0.0026, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6506, 0.3470, 0.6800, param: [4.15118167 9.47772717 4.98231025 8.88115609], weights: [0.29707289 0.31337721 0.38954989], train_wt_loss:  40.3006, val_wt_loss: 36.7805, train_grp_loss: [11.76016357 15.87021452 11.16055077], val_grp_loss: [10.63834715 14.87735336 11.28050393], train_hist_grp_loss: [17.98618944 23.32919741 45.08763086], cur_train_grp_loss: [0.09483939 0.12302553 0.2374582 ], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6800, max_kl_dist_index: 2, max_train_grp_loss:  15.8702, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8774, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2375, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:33:59,932 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  189, train_loss:  13.4335, val_loss:  12.2602, grad_norm: 0.0026, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6506, 0.3470, 0.6800, param: [4.15115952 9.47752977 4.98243559 8.88134322], weights: [0.29688161 0.31326371 0.38985468], train_wt_loss:  40.3006, val_wt_loss: 36.7805, train_grp_loss: [11.76024251 15.87013579 11.16056579], val_grp_loss: [10.63839521 14.87726516 11.28054167], train_hist_grp_loss: [18.08102947 23.45222233 45.32508939], cur_train_grp_loss: [0.09484003 0.12302492 0.23745853], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6800, max_kl_dist_index: 2, max_train_grp_loss:  15.8701, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8773, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2375, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:34:00,957 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  190, train_loss:  13.4335, val_loss:  12.2602, grad_norm: 0.0026, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6506, 0.3470, 0.6800, param: [4.15113712 9.47733287 4.98256074 8.88153092], weights: [0.29669033 0.31315013 0.39015954], train_wt_loss:  40.3006, val_wt_loss: 36.7805, train_grp_loss: [11.7603209  15.87005768 11.16058057], val_grp_loss: [10.63844279 14.87717787 11.28057922], train_hist_grp_loss: [18.17587013 23.57524663 45.56254823], cur_train_grp_loss: [0.09484067 0.12302431 0.23745885], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6800, max_kl_dist_index: 2, max_train_grp_loss:  15.8701, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8772, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2375, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:34:01,988 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  191, train_loss:  13.4335, val_loss:  12.2602, grad_norm: 0.0026, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6506, 0.3470, 0.6800, param: [4.15111448 9.47713649 4.98268571 8.88171918], weights: [0.29649906 0.31303645 0.39046448], train_wt_loss:  40.3006, val_wt_loss: 36.7805, train_grp_loss: [11.76039875 15.86998019 11.16059511], val_grp_loss: [10.63848989 14.87709152 11.28061659], train_hist_grp_loss: [18.27071143 23.69827034 45.8000074 ], cur_train_grp_loss: [0.0948413  0.1230237  0.23745916], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6800, max_kl_dist_index: 2, max_train_grp_loss:  15.8700, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8771, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2375, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:34:03,010 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  192, train_loss:  13.4336, val_loss:  12.2602, grad_norm: 0.0026, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6506, 0.3470, 0.6800, param: [4.1510916  9.47694062 4.98281048 8.88190801], weights: [0.2963078  0.31292269 0.39076951], train_wt_loss:  40.3007, val_wt_loss: 36.7805, train_grp_loss: [11.76047605 15.86990331 11.16060942], val_grp_loss: [10.63853652 14.87700608 11.28065378], train_hist_grp_loss: [18.36555336 23.82129344 46.03746687], cur_train_grp_loss: [0.09484193 0.1230231  0.23745947], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6800, max_kl_dist_index: 2, max_train_grp_loss:  15.8699, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8770, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2375, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:34:04,045 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  193, train_loss:  13.4336, val_loss:  12.2602, grad_norm: 0.0026, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6506, 0.3470, 0.6800, param: [4.15106848 9.47674527 4.98293507 8.88209741], weights: [0.29611654 0.31280884 0.39107462], train_wt_loss:  40.3007, val_wt_loss: 36.7805, train_grp_loss: [11.76055281 15.86982705 11.1606235 ], val_grp_loss: [10.63858266 14.87692157 11.28069078], train_hist_grp_loss: [18.46039591 23.94431595 46.27492664], cur_train_grp_loss: [0.09484255 0.12302251 0.23745977], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6800, max_kl_dist_index: 2, max_train_grp_loss:  15.8698, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8769, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2375, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:34:05,027 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  194, train_loss:  13.4336, val_loss:  12.2602, grad_norm: 0.0026, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6506, 0.3470, 0.6800, param: [4.15104512 9.47655042 4.98305947 8.88228738], weights: [0.29592528 0.31269491 0.39137981], train_wt_loss:  40.3007, val_wt_loss: 36.7805, train_grp_loss: [11.76062902 15.8697514  11.16063734], val_grp_loss: [10.63862833 14.87683799 11.2807276 ], train_hist_grp_loss: [18.55523907 24.06733786 46.51238672], cur_train_grp_loss: [0.09484317 0.12302192 0.23746007], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6800, max_kl_dist_index: 2, max_train_grp_loss:  15.8698, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8768, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2375, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:34:06,042 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  195, train_loss:  13.4336, val_loss:  12.2602, grad_norm: 0.0026, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6506, 0.3470, 0.6800, param: [4.15102152 9.4763561  4.98318368 8.88247791], weights: [0.29573403 0.31258089 0.39168508], train_wt_loss:  40.3007, val_wt_loss: 36.7805, train_grp_loss: [11.76070469 15.86967637 11.16065094], val_grp_loss: [10.63867351 14.87675533 11.28076424], train_hist_grp_loss: [18.65008286 24.19035919 46.74984708], cur_train_grp_loss: [0.09484378 0.12302133 0.23746037], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6800, max_kl_dist_index: 2, max_train_grp_loss:  15.8697, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8768, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2375, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:34:07,057 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  196, train_loss:  13.4336, val_loss:  12.2602, grad_norm: 0.0027, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6506, 0.3470, 0.6800, param: [4.15099767 9.47616228 4.9833077  8.88266901], weights: [0.29554279 0.31246678 0.39199043], train_wt_loss:  40.3007, val_wt_loss: 36.7805, train_grp_loss: [11.76077981 15.86960196 11.16066431], val_grp_loss: [10.63871822 14.87667359 11.2808007 ], train_hist_grp_loss: [18.74492725 24.31337994 46.98730774], cur_train_grp_loss: [0.09484439 0.12302075 0.23746066], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6800, max_kl_dist_index: 2, max_train_grp_loss:  15.8696, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8767, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2375, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:34:08,101 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  197, train_loss:  13.4336, val_loss:  12.2602, grad_norm: 0.0027, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6506, 0.3470, 0.6800, param: [4.15097358 9.47596898 4.98343153 8.88286067], weights: [0.29535155 0.31235258 0.39229586], train_wt_loss:  40.3007, val_wt_loss: 36.7805, train_grp_loss: [11.76085439 15.86952816 11.16067745], val_grp_loss: [10.63876245 14.87659278 11.28083698], train_hist_grp_loss: [18.83977225 24.43640011 47.22476869], cur_train_grp_loss: [0.094845   0.12302017 0.23746094], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6800, max_kl_dist_index: 2, max_train_grp_loss:  15.8695, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8766, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2375, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:34:09,127 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  198, train_loss:  13.4336, val_loss:  12.2602, grad_norm: 0.0027, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6506, 0.3470, 0.6800, param: [4.15094926 9.47577619 4.98355517 8.88305291], weights: [0.29516032 0.3122383  0.39260138], train_wt_loss:  40.3007, val_wt_loss: 36.7805, train_grp_loss: [11.76092842 15.86945497 11.16069034], val_grp_loss: [10.63880619 14.8765129  11.28087307], train_hist_grp_loss: [18.93461785 24.5594197  47.46222991], cur_train_grp_loss: [0.0948456  0.1230196  0.23746122], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6800, max_kl_dist_index: 2, max_train_grp_loss:  15.8695, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8765, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2375, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:34:10,169 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  199, train_loss:  13.4336, val_loss:  12.2602, grad_norm: 0.0027, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6506, 0.3470, 0.6800, param: [4.15092469 9.47558391 4.98367863 8.88324571], weights: [0.2949691  0.31212394 0.39290697], train_wt_loss:  40.3007, val_wt_loss: 36.7805, train_grp_loss: [11.7610019  15.86938241 11.16070301], val_grp_loss: [10.63884946 14.87643394 11.28090898], train_hist_grp_loss: [19.02946404 24.68243874 47.6996914 ], cur_train_grp_loss: [0.0948462  0.12301903 0.2374615 ], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6800, max_kl_dist_index: 2, max_train_grp_loss:  15.8694, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8764, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2375, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:34:11,110 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1654] - INFO: Iteration:  199, train_loss:  13.4336, val_loss:  12.2602, grad_norm: 0.0027,  live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6506, 0.3470, 0.6800, param: [4.15092469 9.47558391 4.98367863 8.88324571], weights: [0.2949691  0.31212394 0.39290697], train_wt_loss:  40.3007, val_wt_loss: 36.7805, train_grp_loss: [11.7610019  15.86938241 11.16070301], val_grp_loss: [10.63884946 14.87643394 11.28090898], train_hist_grp_loss: [19.02946404 24.68243874 47.6996914 ], cur_train_grp_loss: [0.0948462  0.12301903 0.2374615 ], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6800, max_kl_dist_index: 2, max_train_grp_loss:  15.8694, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8764, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2375, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:34:11,340 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:388] - INFO: Policy parameter learned solely on the preference data rdpo: [4.15092469 9.47558391 4.98367863 8.88324571].
2024-10-07 00:34:11,691 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Uniform reward: 3.8269, 3.8269, 3.1987
2024-10-07 00:34:11,692 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Optimal reward: 3.8681, 7.1581, 3.3364
2024-10-07 00:34:11,692 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Policy reward: 3.8540, 6.9363, 3.3325
2024-10-07 00:34:11,693 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:402] - INFO: Reward Error: 0.0036, 0.0310, 0.0012
2024-10-07 00:34:12,395 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:417] - INFO: Optimal reward: 3.8681, 7.1581, 3.3364
Known param reward: [[3.8680634765625, 6.699916015625, 3.30809521484375], [3.46072314453125, 7.1581357421875, 3.12821826171875], [3.83464501953125, 7.0068994140625, 3.336449462890625]], Known param reward error: [[0.0, 0.06401383587376193, 0.00849832984501714], [0.10530859550248342, 0.0, 0.06241101610796404], [0.008639583407495802, 0.02112789329121925, 0.0]].
