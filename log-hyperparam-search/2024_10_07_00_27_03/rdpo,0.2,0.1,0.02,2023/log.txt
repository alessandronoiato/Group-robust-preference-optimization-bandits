2024-10-07 01:28:18,185 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log-hyperparam-search/2024_10_07_00_27_03/rdpo,0.2,0.1,0.02,2023
2024-10-07 01:28:18,187 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2023
2024-10-07 01:28:18,187 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-10-07 01:28:18,279 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.2729, l2 distance: 29.4548, acc: 0.92.
2024-10-07 01:28:18,280 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-10-07 01:28:18,281 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [ 6.99981245 12.85202501  8.22225193 12.39503134]
2024-10-07 01:28:18,498 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.8503, 7.1054, 3.3198
2024-10-07 01:28:18,730 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1314] - INFO: unique_group_ids: {0, 1, 2}
2024-10-07 01:28:19,976 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  0, train_loss:  12.6261, val_loss:  12.2165, grad_norm: 0.4066, live_grad: 0.0000, reward_err: 0.0095, 0.0189, 0.0009, KL_dist: 0.6768, 0.3238, 0.6776, param: [ 4.90005407  6.97920771  5.67480389 10.23346092], weights: [0.33281521 0.33288885 0.33429594], train_wt_loss:  37.8784, val_wt_loss: 36.6494, train_grp_loss: [11.44713637 13.75145527 13.00564157], val_grp_loss: [12.59526077 12.82743756 11.2249144 ], train_hist_grp_loss: [0.1342519  0.14531453 0.3562142 ], cur_train_grp_loss: [0.1342519  0.14531453 0.3562142 ], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6776, max_kl_dist_index: 2, max_train_grp_loss:  13.7515, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8274, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.3562, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:28:21,015 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  1, train_loss:  12.6261, val_loss:  12.2166, grad_norm: 0.0000, live_grad: 0.0000, reward_err: 0.0095, 0.0189, 0.0009, KL_dist: 0.6768, 0.3238, 0.6776, param: [ 4.89995395  6.97832755  5.6753924  10.2332857 ], weights: [0.33238268 0.33263915 0.33497817], train_wt_loss:  37.8784, val_wt_loss: 36.6497, train_grp_loss: [11.44770236 13.75080868 13.00570789], val_grp_loss: [12.59582705 12.82680713 11.22519291], train_hist_grp_loss: [0.2223068  0.26087298 0.61122678], cur_train_grp_loss: [0.0880549  0.11555845 0.25501258], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6776, max_kl_dist_index: 2, max_train_grp_loss:  13.7508, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8268, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:28:22,058 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  2, train_loss:  12.6261, val_loss:  12.2166, grad_norm: 0.0001, live_grad: 0.0000, reward_err: 0.0095, 0.0189, 0.0009, KL_dist: 0.6768, 0.3238, 0.6775, param: [ 4.89985236  6.97744867  5.67598039 10.23311494], weights: [0.33195003 0.33238889 0.33566107], train_wt_loss:  37.8784, val_wt_loss: 36.6499, train_grp_loss: [11.4482657  13.75016559 13.00577343], val_grp_loss: [12.59639091 12.82618088 11.22547028], train_hist_grp_loss: [0.31036604 0.37642599 0.86624066], cur_train_grp_loss: [0.08805925 0.11555301 0.25501388], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6775, max_kl_dist_index: 2, max_train_grp_loss:  13.7502, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8262, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:28:23,137 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  3, train_loss:  12.6261, val_loss:  12.2167, grad_norm: 0.0001, live_grad: 0.0000, reward_err: 0.0095, 0.0189, 0.0009, KL_dist: 0.6767, 0.3238, 0.6775, param: [ 4.8997493   6.97657106  5.67656788 10.23294867], weights: [0.33151726 0.33213807 0.33634466], train_wt_loss:  37.8784, val_wt_loss: 36.6501, train_grp_loss: [11.44882638 13.74952599 13.00583821], val_grp_loss: [12.59695235 12.82555882 11.22574653], train_hist_grp_loss: [0.39842963 0.4919736  1.12125582], cur_train_grp_loss: [0.08806358 0.11554761 0.25501517], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6775, max_kl_dist_index: 2, max_train_grp_loss:  13.7495, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8256, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:28:24,251 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  4, train_loss:  12.6261, val_loss:  12.2168, grad_norm: 0.0001, live_grad: 0.0000, reward_err: 0.0095, 0.0189, 0.0009, KL_dist: 0.6767, 0.3238, 0.6775, param: [ 4.89964476  6.97569472  5.67715485 10.23278688], weights: [0.33108438 0.3318867  0.33702893], train_wt_loss:  37.8784, val_wt_loss: 36.6503, train_grp_loss: [11.4493844  13.74888988 13.00590221], val_grp_loss: [12.59751137 12.82494095 11.22602163], train_hist_grp_loss: [0.48649752 0.60751584 1.37627226], cur_train_grp_loss: [0.0880679  0.11554224 0.25501644], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6775, max_kl_dist_index: 2, max_train_grp_loss:  13.7489, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8249, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:28:25,335 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  5, train_loss:  12.6261, val_loss:  12.2168, grad_norm: 0.0002, live_grad: 0.0000, reward_err: 0.0095, 0.0189, 0.0009, KL_dist: 0.6767, 0.3238, 0.6774, param: [ 4.89953874  6.97481966  5.67774131 10.23262958], weights: [0.33065138 0.33163476 0.33771386], train_wt_loss:  37.8784, val_wt_loss: 36.6505, train_grp_loss: [11.44993975 13.74825727 13.00596543], val_grp_loss: [12.59806796 12.82432728 11.2262956 ], train_hist_grp_loss: [0.57456971 0.72305273 1.63128995], cur_train_grp_loss: [0.08807219 0.11553689 0.25501769], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6774, max_kl_dist_index: 2, max_train_grp_loss:  13.7483, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8243, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:28:26,415 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  6, train_loss:  12.6261, val_loss:  12.2169, grad_norm: 0.0002, live_grad: 0.0000, reward_err: 0.0095, 0.0189, 0.0009, KL_dist: 0.6767, 0.3237, 0.6774, param: [ 4.89943124  6.97394587  5.67832726 10.23247678], weights: [0.33021826 0.33138227 0.33839948], train_wt_loss:  37.8784, val_wt_loss: 36.6507, train_grp_loss: [11.45049243 13.74762816 13.00602788], val_grp_loss: [12.59862212 12.82371781 11.22656842], train_hist_grp_loss: [0.66264617 0.8385843  1.88630888], cur_train_grp_loss: [0.08807646 0.11553157 0.25501893], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6774, max_kl_dist_index: 2, max_train_grp_loss:  13.7476, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8237, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:28:27,479 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  7, train_loss:  12.6261, val_loss:  12.2170, grad_norm: 0.0002, live_grad: 0.0000, reward_err: 0.0095, 0.0189, 0.0009, KL_dist: 0.6767, 0.3237, 0.6773, param: [ 4.89932226  6.97307336  5.6789127  10.2323285 ], weights: [0.32978503 0.33112922 0.33908576], train_wt_loss:  37.8784, val_wt_loss: 36.6509, train_grp_loss: [11.45104244 13.74700256 13.00608955], val_grp_loss: [12.59917384 12.82311254 11.2268401 ], train_hist_grp_loss: [0.75072688 0.95411059 2.14132903], cur_train_grp_loss: [0.08808071 0.11552629 0.25502015], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6773, max_kl_dist_index: 2, max_train_grp_loss:  13.7470, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8231, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:28:28,535 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  8, train_loss:  12.6261, val_loss:  12.2171, grad_norm: 0.0003, live_grad: 0.0000, reward_err: 0.0095, 0.0189, 0.0009, KL_dist: 0.6766, 0.3237, 0.6773, param: [ 4.89921179  6.97220212  5.67949762 10.23218472], weights: [0.32935168 0.33087561 0.33977271], train_wt_loss:  37.8784, val_wt_loss: 36.6512, train_grp_loss: [11.45158978 13.74638046 13.00615044], val_grp_loss: [12.59972312 12.82251149 11.22711063], train_hist_grp_loss: [0.83881182 1.06963162 2.3963504 ], cur_train_grp_loss: [0.08808494 0.11552103 0.25502136], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6773, max_kl_dist_index: 2, max_train_grp_loss:  13.7464, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8225, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:28:29,536 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  9, train_loss:  12.6261, val_loss:  12.2171, grad_norm: 0.0003, live_grad: 0.0000, reward_err: 0.0095, 0.0189, 0.0009, KL_dist: 0.6766, 0.3237, 0.6773, param: [ 4.89909984  6.97133215  5.68008202 10.23204548], weights: [0.32891822 0.33062146 0.34046032], train_wt_loss:  37.8784, val_wt_loss: 36.6514, train_grp_loss: [11.45213443 13.74576188 13.00621055], val_grp_loss: [12.60026996 12.82191465 11.22738001], train_hist_grp_loss: [0.92690097 1.18514742 2.65137295], cur_train_grp_loss: [0.08808915 0.1155158  0.25502256], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6773, max_kl_dist_index: 2, max_train_grp_loss:  13.7458, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8219, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:28:30,553 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  10, train_loss:  12.6261, val_loss:  12.2172, grad_norm: 0.0004, live_grad: 0.0000, reward_err: 0.0095, 0.0189, 0.0009, KL_dist: 0.6766, 0.3237, 0.6772, param: [ 4.8989864   6.97046346  5.68066591 10.23191076], weights: [0.32848465 0.33036675 0.3411486 ], train_wt_loss:  37.8784, val_wt_loss: 36.6516, train_grp_loss: [11.45267639 13.74514681 13.00626987], val_grp_loss: [12.60081435 12.82132203 11.22764824], train_hist_grp_loss: [1.01499432 1.30065802 2.90639669], cur_train_grp_loss: [0.08809334 0.1155106  0.25502374], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6772, max_kl_dist_index: 2, max_train_grp_loss:  13.7451, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8213, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:28:31,575 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  11, train_loss:  12.6261, val_loss:  12.2173, grad_norm: 0.0004, live_grad: 0.0000, reward_err: 0.0095, 0.0189, 0.0009, KL_dist: 0.6766, 0.3237, 0.6772, param: [ 4.89887147  6.96959604  5.68124928 10.23178058], weights: [0.32805097 0.33011149 0.34183754], train_wt_loss:  37.8784, val_wt_loss: 36.6518, train_grp_loss: [11.45321567 13.74453526 13.00632841], val_grp_loss: [12.60135629 12.82073363 11.22791531], train_hist_grp_loss: [1.10309183 1.41616346 3.16142159], cur_train_grp_loss: [0.08809751 0.11550544 0.2550249 ], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6772, max_kl_dist_index: 2, max_train_grp_loss:  13.7445, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8207, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:28:32,607 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  12, train_loss:  12.6261, val_loss:  12.2173, grad_norm: 0.0005, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6766, 0.3237, 0.6771, param: [ 4.89875505  6.96872988  5.68183214 10.23165495], weights: [0.32761719 0.32985568 0.34252714], train_wt_loss:  37.8784, val_wt_loss: 36.6520, train_grp_loss: [11.45375225 13.74392723 13.00638616], val_grp_loss: [12.60189577 12.82014947 11.22818123], train_hist_grp_loss: [1.19119349 1.53166376 3.41644764], cur_train_grp_loss: [0.08810166 0.1155003  0.25502605], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6771, max_kl_dist_index: 2, max_train_grp_loss:  13.7439, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8201, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:28:33,653 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  13, train_loss:  12.6261, val_loss:  12.2174, grad_norm: 0.0005, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6766, 0.3237, 0.6771, param: [ 4.89863714  6.96786501  5.68241447 10.23153387], weights: [0.32718329 0.32959932 0.34321739], train_wt_loss:  37.8784, val_wt_loss: 36.6523, train_grp_loss: [11.45428613 13.74332273 13.00644312], val_grp_loss: [12.60243279 12.81956954 11.22844599], train_hist_grp_loss: [1.27929927 1.64715894 3.67147482], cur_train_grp_loss: [0.08810579 0.11549519 0.25502718], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6771, max_kl_dist_index: 2, max_train_grp_loss:  13.7433, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8196, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:28:34,683 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  14, train_loss:  12.6261, val_loss:  12.2175, grad_norm: 0.0005, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6765, 0.3237, 0.6771, param: [ 4.89851773  6.9670014   5.68299629 10.23141735], weights: [0.32674929 0.32934241 0.3439083 ], train_wt_loss:  37.8784, val_wt_loss: 36.6525, train_grp_loss: [11.45481731 13.74272176 13.0064993 ], val_grp_loss: [12.60296735 12.81899385 11.22870959], train_hist_grp_loss: [1.36740917 1.76264905 3.92650311], cur_train_grp_loss: [0.08810989 0.11549011 0.2550283 ], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6771, max_kl_dist_index: 2, max_train_grp_loss:  13.7427, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8190, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:28:35,703 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  15, train_loss:  12.6261, val_loss:  12.2176, grad_norm: 0.0006, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6765, 0.3237, 0.6770, param: [ 4.89839683  6.96613906  5.68357759 10.2313054 ], weights: [0.32631518 0.32908496 0.34459986], train_wt_loss:  37.8784, val_wt_loss: 36.6527, train_grp_loss: [11.45534578 13.74212432 13.00655468], val_grp_loss: [12.60349945 12.81842241 11.22897203], train_hist_grp_loss: [1.45552315 1.87813411 4.18153251], cur_train_grp_loss: [0.08811398 0.11548506 0.2550294 ], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6770, max_kl_dist_index: 2, max_train_grp_loss:  13.7421, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8184, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:28:36,782 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  16, train_loss:  12.6261, val_loss:  12.2176, grad_norm: 0.0006, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6765, 0.3236, 0.6770, param: [ 4.89827443  6.965278    5.68415837 10.23119802], weights: [0.32588097 0.32882696 0.34529207], train_wt_loss:  37.8784, val_wt_loss: 36.6529, train_grp_loss: [11.45587154 13.74153042 13.00660926], val_grp_loss: [12.60402907 12.81785521 11.2292333 ], train_hist_grp_loss: [1.54364119 1.99361414 4.43656299], cur_train_grp_loss: [0.08811804 0.11548004 0.25503048], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6770, max_kl_dist_index: 2, max_train_grp_loss:  13.7415, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8179, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:28:37,801 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  17, train_loss:  12.6261, val_loss:  12.2177, grad_norm: 0.0007, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6765, 0.3236, 0.6770, param: [ 4.89815053  6.9644182   5.68473863 10.23109523], weights: [0.32544666 0.32856842 0.34598492], train_wt_loss:  37.8784, val_wt_loss: 36.6531, train_grp_loss: [11.45639459 13.74094005 13.00666306], val_grp_loss: [12.60455621 12.81729227 11.2294934 ], train_hist_grp_loss: [1.63176328 2.10908919 4.69159455], cur_train_grp_loss: [0.08812209 0.11547505 0.25503155], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6770, max_kl_dist_index: 2, max_train_grp_loss:  13.7409, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8173, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:28:38,849 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  18, train_loss:  12.6261, val_loss:  12.2178, grad_norm: 0.0007, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6765, 0.3236, 0.6769, param: [ 4.89802513  6.96355968  5.68531837 10.23099703], weights: [0.32501224 0.32830933 0.34667842], train_wt_loss:  37.8784, val_wt_loss: 36.6534, train_grp_loss: [11.45691491 13.74035324 13.00671605], val_grp_loss: [12.60508087 12.81673359 11.22975233], train_hist_grp_loss: [1.71988939 2.22455927 4.94662716], cur_train_grp_loss: [0.08812611 0.11547008 0.25503261], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6769, max_kl_dist_index: 2, max_train_grp_loss:  13.7404, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8167, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:28:39,870 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  19, train_loss:  12.6261, val_loss:  12.2179, grad_norm: 0.0007, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6765, 0.3236, 0.6769, param: [ 4.89789823  6.96270242  5.68589758 10.23090343], weights: [0.32457773 0.32804971 0.34737256], train_wt_loss:  37.8784, val_wt_loss: 36.6536, train_grp_loss: [11.45743251 13.73976997 13.00676825], val_grp_loss: [12.60560306 12.81617918 11.23001008], train_hist_grp_loss: [1.80801951 2.34002443 5.20166081], cur_train_grp_loss: [0.08813011 0.11546515 0.25503365], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6769, max_kl_dist_index: 2, max_train_grp_loss:  13.7398, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8162, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:28:40,927 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  20, train_loss:  12.6261, val_loss:  12.2179, grad_norm: 0.0008, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6764, 0.3236, 0.6769, param: [ 4.89776982  6.96184644  5.68647628 10.23081443], weights: [0.32414312 0.32778954 0.34806734], train_wt_loss:  37.8784, val_wt_loss: 36.6538, train_grp_loss: [11.45794739 13.73919025 13.00681965], val_grp_loss: [12.60612275 12.81562903 11.23026666], train_hist_grp_loss: [1.8961536  2.45548468 5.45669548], cur_train_grp_loss: [0.0881341  0.11546025 0.25503467], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6769, max_kl_dist_index: 2, max_train_grp_loss:  13.7392, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8156, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:28:41,987 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  21, train_loss:  12.6262, val_loss:  12.2180, grad_norm: 0.0008, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6764, 0.3236, 0.6768, param: [ 4.89763991  6.96099172  5.68705445 10.23073005], weights: [0.32370841 0.32752883 0.34876276], train_wt_loss:  37.8785, val_wt_loss: 36.6540, train_grp_loss: [11.45845953 13.73861408 13.00687024], val_grp_loss: [12.60663995 12.81508316 11.23052207], train_hist_grp_loss: [1.98429166 2.57094006 5.71173116], cur_train_grp_loss: [0.08813806 0.11545538 0.25503568], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6768, max_kl_dist_index: 2, max_train_grp_loss:  13.7386, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8151, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:28:43,016 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  22, train_loss:  12.6262, val_loss:  12.2181, grad_norm: 0.0009, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6764, 0.3236, 0.6768, param: [ 4.89750849  6.96013827  5.68763209 10.23065029], weights: [0.3232736  0.32726759 0.34945881], train_wt_loss:  37.8785, val_wt_loss: 36.6543, train_grp_loss: [11.45896893 13.73804147 13.00692004], val_grp_loss: [12.60715466 12.81454156 11.23077629], train_hist_grp_loss: [2.07243365 2.6863906  5.96676783], cur_train_grp_loss: [0.088142   0.11545054 0.25503667], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6768, max_kl_dist_index: 2, max_train_grp_loss:  13.7380, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8145, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:28:44,031 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  23, train_loss:  12.6262, val_loss:  12.2182, grad_norm: 0.0009, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6764, 0.3236, 0.6768, param: [ 4.89737555  6.95928609  5.68820921 10.23057516], weights: [0.3228387  0.32700581 0.35015549], train_wt_loss:  37.8785, val_wt_loss: 36.6545, train_grp_loss: [11.4594756  13.73747243 13.00696902], val_grp_loss: [12.60766687 12.81400425 11.23102933], train_hist_grp_loss: [2.16057957 2.80183632 6.22180548], cur_train_grp_loss: [0.08814591 0.11544573 0.25503765], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6768, max_kl_dist_index: 2, max_train_grp_loss:  13.7375, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8140, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:28:45,073 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  24, train_loss:  12.6262, val_loss:  12.2182, grad_norm: 0.0010, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6764, 0.3236, 0.6767, param: [ 4.89724111  6.95843518  5.68878581 10.23050466], weights: [0.3224037  0.32674349 0.35085281], train_wt_loss:  37.8785, val_wt_loss: 36.6547, train_grp_loss: [11.45997952 13.73690695 13.00701721], val_grp_loss: [12.60817657 12.81347123 11.23128118], train_hist_grp_loss: [2.24872938 2.91727727 6.47684408], cur_train_grp_loss: [0.08814981 0.11544094 0.25503861], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6767, max_kl_dist_index: 2, max_train_grp_loss:  13.7369, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8135, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:28:46,092 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  25, train_loss:  12.6262, val_loss:  12.2183, grad_norm: 0.0010, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6764, 0.3236, 0.6767, param: [ 4.89710515  6.95758553  5.68936188 10.2304388 ], weights: [0.32196861 0.32648064 0.35155075], train_wt_loss:  37.8785, val_wt_loss: 36.6549, train_grp_loss: [11.46048069 13.73634504 13.00706458], val_grp_loss: [12.60868377 12.8129425  11.23153185], train_hist_grp_loss: [2.33688307 3.03271346 6.73188364], cur_train_grp_loss: [0.08815369 0.11543619 0.25503955], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6767, max_kl_dist_index: 2, max_train_grp_loss:  13.7363, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8129, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:28:47,107 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  26, train_loss:  12.6262, val_loss:  12.2184, grad_norm: 0.0010, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6763, 0.3236, 0.6767, param: [ 4.89696768  6.95673715  5.68993742 10.2303776 ], weights: [0.32153343 0.32621726 0.35224931], train_wt_loss:  37.8785, val_wt_loss: 36.6552, train_grp_loss: [11.46097911 13.7357867  13.00711114], val_grp_loss: [12.60918845 12.81241808 11.23178133], train_hist_grp_loss: [2.42504061 3.14814493 6.98692412], cur_train_grp_loss: [0.08815754 0.11543147 0.25504048], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6767, max_kl_dist_index: 2, max_train_grp_loss:  13.7358, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8124, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:28:48,173 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  27, train_loss:  12.6262, val_loss:  12.2185, grad_norm: 0.0011, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6763, 0.3236, 0.6766, param: [ 4.89682868  6.95589004  5.69051244 10.23032106], weights: [0.32109816 0.32595335 0.35294849], train_wt_loss:  37.8785, val_wt_loss: 36.6554, train_grp_loss: [11.46147477 13.73523194 13.0071569 ], val_grp_loss: [12.60969062 12.81189795 11.23202962], train_hist_grp_loss: [2.51320199 3.26357171 7.24196551], cur_train_grp_loss: [0.08816138 0.11542678 0.25504139], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6766, max_kl_dist_index: 2, max_train_grp_loss:  13.7352, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8119, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:28:49,223 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  28, train_loss:  12.6262, val_loss:  12.2185, grad_norm: 0.0011, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6763, 0.3235, 0.6766, param: [ 4.89668817  6.95504419  5.69108693 10.23026918], weights: [0.3206628 0.3256889 0.3536483], train_wt_loss:  37.8785, val_wt_loss: 36.6556, train_grp_loss: [11.46196767 13.73468075 13.00720184], val_grp_loss: [12.61019027 12.81138214 11.23227671], train_hist_grp_loss: [2.60136718 3.37899383 7.49700781], cur_train_grp_loss: [0.08816519 0.11542212 0.25504229], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6766, max_kl_dist_index: 2, max_train_grp_loss:  13.7347, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8114, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:28:50,229 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  29, train_loss:  12.6262, val_loss:  12.2186, grad_norm: 0.0012, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6763, 0.3235, 0.6766, param: [ 4.89654614  6.95419961  5.69166089 10.23022198], weights: [0.32022735 0.32542393 0.35434872], train_wt_loss:  37.8785, val_wt_loss: 36.6559, train_grp_loss: [11.46245781 13.73413316 13.00724596], val_grp_loss: [12.6106874  12.81087064 11.2325226 ], train_hist_grp_loss: [2.68953616 3.49441131 7.75205098], cur_train_grp_loss: [0.08816898 0.11541749 0.25504317], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6766, max_kl_dist_index: 2, max_train_grp_loss:  13.7341, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8109, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:28:51,250 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  30, train_loss:  12.6262, val_loss:  12.2187, grad_norm: 0.0012, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6763, 0.3235, 0.6765, param: [ 4.89640259  6.95335629  5.69223432 10.23017946], weights: [0.31979182 0.32515842 0.35504976], train_wt_loss:  37.8785, val_wt_loss: 36.6561, train_grp_loss: [11.46294517 13.73358914 13.00728927], val_grp_loss: [12.611182   12.81036345 11.2327673 ], train_hist_grp_loss: [2.77770892 3.6098242  8.00709502], cur_train_grp_loss: [0.08817275 0.11541288 0.25504404], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6765, max_kl_dist_index: 2, max_train_grp_loss:  13.7336, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8104, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:28:52,249 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  31, train_loss:  12.6262, val_loss:  12.2188, grad_norm: 0.0013, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6763, 0.3235, 0.6765, param: [ 4.89625751  6.95251424  5.69280721 10.23014162], weights: [0.3193562 0.3248924 0.3557514], train_wt_loss:  37.8785, val_wt_loss: 36.6563, train_grp_loss: [11.46342976 13.73304872 13.00733177], val_grp_loss: [12.61167407 12.8098606  11.2330108 ], train_hist_grp_loss: [2.86588542 3.72523251 8.26213991], cur_train_grp_loss: [0.0881765  0.11540831 0.25504489], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6765, max_kl_dist_index: 2, max_train_grp_loss:  13.7330, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8099, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:28:53,261 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  32, train_loss:  12.6262, val_loss:  12.2189, grad_norm: 0.0013, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6763, 0.3235, 0.6765, param: [ 4.89611091  6.95167345  5.69337958 10.23010849], weights: [0.3189205  0.32462584 0.35645366], train_wt_loss:  37.8785, val_wt_loss: 36.6566, train_grp_loss: [11.46391158 13.7325119  13.00737344], val_grp_loss: [12.61216361 12.80936207 11.23325309], train_hist_grp_loss: [2.95406565 3.84063628 8.51718563], cur_train_grp_loss: [0.08818023 0.11540377 0.25504572], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6765, max_kl_dist_index: 2, max_train_grp_loss:  13.7325, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8094, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:28:54,287 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  33, train_loss:  12.6262, val_loss:  12.2189, grad_norm: 0.0013, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6762, 0.3235, 0.6764, param: [ 4.89596278  6.95083393  5.69395142 10.23008005], weights: [0.31848471 0.32435876 0.35715652], train_wt_loss:  37.8785, val_wt_loss: 36.6568, train_grp_loss: [11.46439061 13.73197867 13.00741429], val_grp_loss: [12.6126506  12.80886788 11.23349417], train_hist_grp_loss: [3.04224958 3.95603554 8.77223217], cur_train_grp_loss: [0.08818394 0.11539926 0.25504654], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6764, max_kl_dist_index: 2, max_train_grp_loss:  13.7320, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8089, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:28:55,333 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  34, train_loss:  12.6262, val_loss:  12.2190, grad_norm: 0.0014, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6762, 0.3235, 0.6764, param: [ 4.89581312  6.94999567  5.69452272 10.23005633], weights: [0.31804885 0.32409116 0.35785999], train_wt_loss:  37.8786, val_wt_loss: 36.6570, train_grp_loss: [11.46486686 13.73144905 13.00745432], val_grp_loss: [12.61313505 12.80837802 11.23373405], train_hist_grp_loss: [3.1304372  4.07143032 9.0272795 ], cur_train_grp_loss: [0.08818762 0.11539478 0.25504734], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6764, max_kl_dist_index: 2, max_train_grp_loss:  13.7314, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8084, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:28:56,367 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  35, train_loss:  12.6262, val_loss:  12.2191, grad_norm: 0.0014, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6762, 0.3235, 0.6764, param: [ 4.89566192  6.94915867  5.69509349 10.23003733], weights: [0.3176129  0.32382304 0.35856406], train_wt_loss:  37.8786, val_wt_loss: 36.6573, train_grp_loss: [11.46534031 13.73092303 13.00749353], val_grp_loss: [12.61361696 12.80789251 11.23397272], train_hist_grp_loss: [3.21862849 4.18682065 9.28232763], cur_train_grp_loss: [0.08819128 0.11539033 0.25504812], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6764, max_kl_dist_index: 2, max_train_grp_loss:  13.7309, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8079, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:28:57,372 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  36, train_loss:  12.6262, val_loss:  12.2192, grad_norm: 0.0015, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6762, 0.3235, 0.6764, param: [ 4.8955092   6.94832293  5.69566372 10.23002306], weights: [0.31717688 0.3235544  0.35926873], train_wt_loss:  37.8786, val_wt_loss: 36.6575, train_grp_loss: [11.46581097 13.73040062 13.00753191], val_grp_loss: [12.61409632 12.80741135 11.23421018], train_hist_grp_loss: [3.30682341 4.30220655 9.53737652], cur_train_grp_loss: [0.08819493 0.11538591 0.25504889], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6764, max_kl_dist_index: 2, max_train_grp_loss:  13.7304, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8074, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:28:58,400 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  37, train_loss:  12.6262, val_loss:  12.2192, grad_norm: 0.0015, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6762, 0.3235, 0.6763, param: [ 4.89535494  6.94748845  5.69623342 10.23001352], weights: [0.31674077 0.32328524 0.35997399], train_wt_loss:  37.8786, val_wt_loss: 36.6577, train_grp_loss: [11.46627884 13.72988182 13.00756946], val_grp_loss: [12.61457312 12.80693455 11.23444642], train_hist_grp_loss: [3.39502196 4.41758807 9.79242617], cur_train_grp_loss: [0.08819855 0.11538152 0.25504965], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6763, max_kl_dist_index: 2, max_train_grp_loss:  13.7299, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8069, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:28:59,417 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  38, train_loss:  12.6262, val_loss:  12.2193, grad_norm: 0.0016, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6762, 0.3235, 0.6763, param: [ 4.89519914  6.94665524  5.69680259 10.23000872], weights: [0.3163046  0.32301556 0.36067985], train_wt_loss:  37.8786, val_wt_loss: 36.6580, train_grp_loss: [11.4667439  13.72936664 13.00760619], val_grp_loss: [12.61504736 12.8064621  11.23468144], train_hist_grp_loss: [ 3.4832241   4.53296523 10.04747655], cur_train_grp_loss: [0.08820214 0.11537716 0.25505038], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6763, max_kl_dist_index: 2, max_train_grp_loss:  13.7294, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8065, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:29:00,440 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  39, train_loss:  12.6262, val_loss:  12.2194, grad_norm: 0.0016, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6762, 0.3235, 0.6763, param: [ 4.8950418   6.94582328  5.69737121 10.23000867], weights: [0.31586834 0.32274536 0.36138629], train_wt_loss:  37.8786, val_wt_loss: 36.6582, train_grp_loss: [11.46720615 13.72885509 13.00764208], val_grp_loss: [12.61551904 12.80599402 11.23491525], train_hist_grp_loss: [ 3.57142982  4.64833806 10.30252765], cur_train_grp_loss: [0.08820572 0.11537283 0.2550511 ], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6763, max_kl_dist_index: 2, max_train_grp_loss:  13.7289, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8060, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:29:01,456 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  40, train_loss:  12.6262, val_loss:  12.2195, grad_norm: 0.0016, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6762, 0.3235, 0.6762, param: [ 4.89488293  6.94499259  5.6979393  10.23001338], weights: [0.31543202 0.32247465 0.36209333], train_wt_loss:  37.8786, val_wt_loss: 36.6584, train_grp_loss: [11.46766559 13.72834715 13.00767715], val_grp_loss: [12.61598816 12.80553031 11.23514783], train_hist_grp_loss: [ 3.6596391   4.76370659 10.55757946], cur_train_grp_loss: [0.08820928 0.11536853 0.25505181], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6762, max_kl_dist_index: 2, max_train_grp_loss:  13.7283, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8055, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:29:02,470 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  41, train_loss:  12.6262, val_loss:  12.2196, grad_norm: 0.0017, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6762, 0.3235, 0.6762, param: [ 4.89472251  6.94416315  5.69850685 10.23002286], weights: [0.31499562 0.32220343 0.36280095], train_wt_loss:  37.8786, val_wt_loss: 36.6587, train_grp_loss: [11.46812222 13.72784285 13.00771138], val_grp_loss: [12.6164547  12.80507098 11.23537919], train_hist_grp_loss: [ 3.74785192  4.87907085 10.81263195], cur_train_grp_loss: [0.08821281 0.11536426 0.25505249], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6762, max_kl_dist_index: 2, max_train_grp_loss:  13.7278, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8051, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:29:03,500 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  42, train_loss:  12.6262, val_loss:  12.2196, grad_norm: 0.0017, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6761, 0.3235, 0.6762, param: [ 4.89456054  6.94333497  5.69907386 10.2300371 ], weights: [0.31455915 0.32193169 0.36350915], train_wt_loss:  37.8786, val_wt_loss: 36.6589, train_grp_loss: [11.46857603 13.72734217 13.00774477], val_grp_loss: [12.61691867 12.80461602 11.23560933], train_hist_grp_loss: [ 3.83606824  4.99443087 11.06768511], cur_train_grp_loss: [0.08821632 0.11536002 0.25505316], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6762, max_kl_dist_index: 2, max_train_grp_loss:  13.7273, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8046, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:29:04,512 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  43, train_loss:  12.6262, val_loss:  12.2197, grad_norm: 0.0018, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6761, 0.3235, 0.6762, param: [ 4.89439703  6.94250805  5.69964034 10.23005613], weights: [0.31412261 0.32165945 0.36421794], train_wt_loss:  37.8786, val_wt_loss: 36.6591, train_grp_loss: [11.46902702 13.72684513 13.00777733], val_grp_loss: [12.61738006 12.80416545 11.23583823], train_hist_grp_loss: [ 3.92428806  5.10978669 11.32273893], cur_train_grp_loss: [0.08821982 0.11535582 0.25505382], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6762, max_kl_dist_index: 2, max_train_grp_loss:  13.7268, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8042, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:29:05,524 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  44, train_loss:  12.6262, val_loss:  12.2198, grad_norm: 0.0018, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6761, 0.3234, 0.6761, param: [ 4.89423198  6.94168239  5.70020627 10.23007994], weights: [0.31368601 0.32138669 0.3649273 ], train_wt_loss:  37.8787, val_wt_loss: 36.6594, train_grp_loss: [11.46947517 13.72635174 13.00780905], val_grp_loss: [12.61783887 12.80371927 11.23606591], train_hist_grp_loss: [ 4.01251134  5.22513833 11.57779339], cur_train_grp_loss: [0.08822328 0.11535164 0.25505446], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6761, max_kl_dist_index: 2, max_train_grp_loss:  13.7264, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8037, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:29:06,566 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  45, train_loss:  12.6262, val_loss:  12.2199, grad_norm: 0.0019, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6761, 0.3234, 0.6761, param: [ 4.89406537  6.94085798  5.70077166 10.23010856], weights: [0.31324934 0.32111343 0.36563723], train_wt_loss:  37.8787, val_wt_loss: 36.6596, train_grp_loss: [11.4699205  13.72586198 13.00783993], val_grp_loss: [12.61829509 12.80327749 11.23629235], train_hist_grp_loss: [ 4.10073807  5.34048582 11.83284847], cur_train_grp_loss: [0.08822673 0.11534749 0.25505508], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6761, max_kl_dist_index: 2, max_train_grp_loss:  13.7259, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8033, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:29:07,591 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  46, train_loss:  12.6262, val_loss:  12.2200, grad_norm: 0.0019, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6761, 0.3234, 0.6761, param: [ 4.89389721  6.94003483  5.70133651 10.23014197], weights: [0.3128126  0.32083966 0.36634774], train_wt_loss:  37.8787, val_wt_loss: 36.6599, train_grp_loss: [11.47036299 13.72537587 13.00786997], val_grp_loss: [12.61874873 12.80284011 11.23651756], train_hist_grp_loss: [ 4.18896823  5.4558292  12.08790415], cur_train_grp_loss: [0.08823016 0.11534338 0.25505568], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6761, max_kl_dist_index: 0, max_train_grp_loss:  13.7254, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8028, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:29:08,625 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  47, train_loss:  12.6262, val_loss:  12.2200, grad_norm: 0.0019, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6761, 0.3234, 0.6761, param: [ 4.8937275   6.93921293  5.70190081 10.23018019], weights: [0.31237579 0.32056539 0.36705882], train_wt_loss:  37.8787, val_wt_loss: 36.6601, train_grp_loss: [11.47080264 13.72489342 13.00789916], val_grp_loss: [12.61919977 12.80240714 11.23674153], train_hist_grp_loss: [ 4.27720179  5.5711685  12.34296043], cur_train_grp_loss: [0.08823356 0.11533929 0.25505627], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6761, max_kl_dist_index: 0, max_train_grp_loss:  13.7249, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8024, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:29:09,644 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  48, train_loss:  12.6262, val_loss:  12.2201, grad_norm: 0.0020, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6761, 0.3234, 0.6760, param: [ 4.89355624  6.93839229  5.70246457 10.23022324], weights: [0.31193893 0.32029061 0.36777046], train_wt_loss:  37.8787, val_wt_loss: 36.6603, train_grp_loss: [11.47123945 13.72441462 13.00792752], val_grp_loss: [12.61964821 12.80197857 11.23696427], train_hist_grp_loss: [ 4.36543873  5.68650373 12.59801727], cur_train_grp_loss: [0.08823694 0.11533524 0.25505685], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6761, max_kl_dist_index: 0, max_train_grp_loss:  13.7244, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8020, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:29:10,676 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  49, train_loss:  12.6262, val_loss:  12.2202, grad_norm: 0.0020, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6761, 0.3234, 0.6760, param: [ 4.89338341  6.9375729   5.70302779 10.2302711 ], weights: [0.311502   0.32001533 0.36848267], train_wt_loss:  37.8787, val_wt_loss: 36.6606, train_grp_loss: [11.47167341 13.72393947 13.00795502], val_grp_loss: [12.62009405 12.80155443 11.23718576], train_hist_grp_loss: [ 4.45367904  5.80183495 12.85307468], cur_train_grp_loss: [0.0882403  0.11533122 0.2550574 ], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6761, max_kl_dist_index: 0, max_train_grp_loss:  13.7239, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8016, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:29:11,685 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  50, train_loss:  12.6262, val_loss:  12.2203, grad_norm: 0.0021, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6761, 0.3234, 0.6760, param: [ 4.89320903  6.93675477  5.70359045 10.23032381], weights: [0.31106502 0.31973954 0.36919544], train_wt_loss:  37.8787, val_wt_loss: 36.6608, train_grp_loss: [11.47210452 13.72346799 13.00798168], val_grp_loss: [12.62053729 12.80113471 11.23740601], train_hist_grp_loss: [ 4.54192268  5.91716217 13.10813262], cur_train_grp_loss: [0.08824364 0.11532722 0.25505794], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6761, max_kl_dist_index: 0, max_train_grp_loss:  13.7235, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8011, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:29:12,720 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  51, train_loss:  12.6262, val_loss:  12.2204, grad_norm: 0.0021, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6761, 0.3234, 0.6760, param: [ 4.89303309  6.93593789  5.70415258 10.23038135], weights: [0.31062797 0.31946326 0.36990877], train_wt_loss:  37.8787, val_wt_loss: 36.6611, train_grp_loss: [11.47253278 13.72300018 13.00800749], val_grp_loss: [12.62097792 12.80071941 11.23762501], train_hist_grp_loss: [ 4.63016964  6.03248543 13.36319108], cur_train_grp_loss: [0.08824696 0.11532326 0.25505846], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6761, max_kl_dist_index: 0, max_train_grp_loss:  13.7230, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8007, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:29:13,740 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  52, train_loss:  12.6263, val_loss:  12.2204, grad_norm: 0.0022, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6760, 0.3234, 0.6759, param: [ 4.89285559  6.93512226  5.70471415 10.23044374], weights: [0.31019087 0.31918648 0.37062265], train_wt_loss:  37.8788, val_wt_loss: 36.6613, train_grp_loss: [11.47295817 13.72253604 13.00803245], val_grp_loss: [12.62141593 12.80030855 11.23784276], train_hist_grp_loss: [ 4.71841989  6.14780476 13.61825005], cur_train_grp_loss: [0.08825025 0.11531933 0.25505897], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6760, max_kl_dist_index: 0, max_train_grp_loss:  13.7225, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8003, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:29:14,772 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  53, train_loss:  12.6263, val_loss:  12.2205, grad_norm: 0.0022, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6760, 0.3234, 0.6759, param: [ 4.89267652  6.93430788  5.70527518 10.23051099], weights: [0.30975371 0.31890921 0.37133708], train_wt_loss:  37.8788, val_wt_loss: 36.6616, train_grp_loss: [11.4733807  13.72207557 13.00805655], val_grp_loss: [12.62185133 12.79990212 11.23805927], train_hist_grp_loss: [ 4.80667341  6.26312019 13.87330951], cur_train_grp_loss: [0.08825352 0.11531543 0.25505946], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6760, max_kl_dist_index: 0, max_train_grp_loss:  13.7221, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7999, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:29:15,790 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  54, train_loss:  12.6263, val_loss:  12.2206, grad_norm: 0.0022, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6760, 0.3234, 0.6759, param: [ 4.89249588  6.93349475  5.70583566 10.23058311], weights: [0.3093165  0.31863143 0.37205207], train_wt_loss:  37.8788, val_wt_loss: 36.6618, train_grp_loss: [11.47380036 13.72161878 13.00807981], val_grp_loss: [12.6222841  12.79950014 11.23827452], train_hist_grp_loss: [ 4.89493019  6.37843175 14.12836944], cur_train_grp_loss: [0.08825677 0.11531156 0.25505993], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6760, max_kl_dist_index: 0, max_train_grp_loss:  13.7216, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7995, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:29:16,838 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  55, train_loss:  12.6263, val_loss:  12.2207, grad_norm: 0.0023, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6760, 0.3234, 0.6759, param: [ 4.89231368  6.93268287  5.70639559 10.23066009], weights: [0.30887923 0.31835317 0.3727676 ], train_wt_loss:  37.8788, val_wt_loss: 36.6620, train_grp_loss: [11.47421715 13.72116567 13.0081022 ], val_grp_loss: [12.62271426 12.79910261 11.23848852], train_hist_grp_loss: [ 4.98319019  6.49373947 14.38342983], cur_train_grp_loss: [0.08826    0.11530772 0.25506039], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6760, max_kl_dist_index: 0, max_train_grp_loss:  13.7212, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7991, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:29:17,877 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  56, train_loss:  12.6263, val_loss:  12.2208, grad_norm: 0.0023, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6760, 0.3234, 0.6759, param: [ 4.89212991  6.93187224  5.70695496 10.23074196], weights: [0.30844192 0.31807441 0.37348367], train_wt_loss:  37.8788, val_wt_loss: 36.6623, train_grp_loss: [11.47463106 13.72071624 13.00812374], val_grp_loss: [12.62314178 12.79870953 11.23870126], train_hist_grp_loss: [ 5.0714534   6.60904338 14.63849066], cur_train_grp_loss: [0.08826321 0.11530391 0.25506083], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6760, max_kl_dist_index: 0, max_train_grp_loss:  13.7207, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7987, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:29:19,000 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  57, train_loss:  12.6263, val_loss:  12.2208, grad_norm: 0.0024, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6760, 0.3234, 0.6758, param: [ 4.89194457  6.93106286  5.70751379 10.23082871], weights: [0.30800455 0.31779516 0.37420029], train_wt_loss:  37.8788, val_wt_loss: 36.6625, train_grp_loss: [11.47504209 13.72027051 13.00814443], val_grp_loss: [12.62356667 12.79832091 11.23891274], train_hist_grp_loss: [ 5.15971979  6.72434352 14.89355191], cur_train_grp_loss: [0.08826639 0.11530014 0.25506125], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6760, max_kl_dist_index: 0, max_train_grp_loss:  13.7203, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7983, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:29:20,034 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  58, train_loss:  12.6263, val_loss:  12.2209, grad_norm: 0.0024, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6760, 0.3234, 0.6758, param: [ 4.89175765  6.93025472  5.70807206 10.23092035], weights: [0.30756713 0.31751542 0.37491745], train_wt_loss:  37.8788, val_wt_loss: 36.6628, train_grp_loss: [11.47545024 13.71982847 13.00816425], val_grp_loss: [12.62398892 12.79793675 11.23912296], train_hist_grp_loss: [ 5.24798935  6.83963991 15.14861357], cur_train_grp_loss: [0.08826955 0.11529639 0.25506166], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6760, max_kl_dist_index: 0, max_train_grp_loss:  13.7198, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7979, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:29:21,094 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  59, train_loss:  12.6263, val_loss:  12.2210, grad_norm: 0.0025, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6760, 0.3234, 0.6758, param: [ 4.89156916  6.92944783  5.70862978 10.2310169 ], weights: [0.30712967 0.31723519 0.37563514], train_wt_loss:  37.8789, val_wt_loss: 36.6630, train_grp_loss: [11.4758555  13.71939013 13.00818321], val_grp_loss: [12.62440854 12.79755707 11.23933192], train_hist_grp_loss: [ 5.33626204  6.95493259 15.40367561], cur_train_grp_loss: [0.08827269 0.11529268 0.25506204], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6760, max_kl_dist_index: 0, max_train_grp_loss:  13.7194, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7976, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:29:22,170 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  60, train_loss:  12.6263, val_loss:  12.2211, grad_norm: 0.0025, live_grad: 0.0000, reward_err: 0.0098, 0.0186, 0.0009, KL_dist: 0.6760, 0.3234, 0.6758, param: [ 4.89137909  6.92864219  5.70918694 10.23111836], weights: [0.30669216 0.31695448 0.37635336], train_wt_loss:  37.8789, val_wt_loss: 36.6633, train_grp_loss: [11.47625787 13.71895549 13.00820131], val_grp_loss: [12.62482551 12.79718186 11.23953962], train_hist_grp_loss: [ 5.42453785  7.07022158 15.65873803], cur_train_grp_loss: [0.08827581 0.11528899 0.25506242], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6760, max_kl_dist_index: 0, max_train_grp_loss:  13.7190, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7972, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:29:23,206 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  61, train_loss:  12.6263, val_loss:  12.2212, grad_norm: 0.0025, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6760, 0.3234, 0.6757, param: [ 4.89118744  6.92783779  5.70974355 10.23122474], weights: [0.3062546  0.31667328 0.37707212], train_wt_loss:  37.8789, val_wt_loss: 36.6635, train_grp_loss: [11.47665734 13.71852455 13.00821854], val_grp_loss: [12.62523983 12.79681113 11.23974605], train_hist_grp_loss: [ 5.51281676  7.18550692 15.9138008 ], cur_train_grp_loss: [0.08827891 0.11528534 0.25506277], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6760, max_kl_dist_index: 0, max_train_grp_loss:  13.7185, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7968, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:29:24,239 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  62, train_loss:  12.6263, val_loss:  12.2213, grad_norm: 0.0026, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6760, 0.3234, 0.6757, param: [ 4.89099421  6.92703463  5.7102996  10.23133604], weights: [0.305817  0.3163916 0.3777914], train_wt_loss:  37.8789, val_wt_loss: 36.6638, train_grp_loss: [11.47705392 13.71809732 13.00823491], val_grp_loss: [12.6256515  12.79644488 11.23995121], train_hist_grp_loss: [ 5.60109874  7.30078864 16.1688639 ], cur_train_grp_loss: [0.08828198 0.11528172 0.25506311], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6760, max_kl_dist_index: 0, max_train_grp_loss:  13.7181, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7964, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:29:25,270 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  63, train_loss:  12.6263, val_loss:  12.2213, grad_norm: 0.0026, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6760, 0.3234, 0.6757, param: [ 4.8907994   6.92623272  5.7108551  10.23145228], weights: [0.30537936 0.31610943 0.37851121], train_wt_loss:  37.8789, val_wt_loss: 36.6640, train_grp_loss: [11.47744758 13.71767381 13.00825041], val_grp_loss: [12.62606052 12.79608313 11.2401551 ], train_hist_grp_loss: [ 5.68938377  7.41606677 16.42392733], cur_train_grp_loss: [0.08828503 0.11527813 0.25506343], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6760, max_kl_dist_index: 0, max_train_grp_loss:  13.7177, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7961, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:29:26,303 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  64, train_loss:  12.6263, val_loss:  12.2214, grad_norm: 0.0027, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6760, 0.3234, 0.6757, param: [ 4.89060301  6.92543205  5.71141003 10.23157346], weights: [0.30494168 0.31582679 0.37923153], train_wt_loss:  37.8789, val_wt_loss: 36.6643, train_grp_loss: [11.47783834 13.71725401 13.00826504], val_grp_loss: [12.62646687 12.79572587 11.24035771], train_hist_grp_loss: [ 5.77767183  7.53134134 16.67899107], cur_train_grp_loss: [0.08828806 0.11527457 0.25506373], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6760, max_kl_dist_index: 0, max_train_grp_loss:  13.7173, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7957, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:29:27,329 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  65, train_loss:  12.6263, val_loss:  12.2215, grad_norm: 0.0027, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6759, 0.3234, 0.6757, param: [ 4.89040503  6.92463262  5.71196441 10.23169958], weights: [0.30450396 0.31554366 0.37995238], train_wt_loss:  37.8790, val_wt_loss: 36.6645, train_grp_loss: [11.47822619 13.71683794 13.0082788 ], val_grp_loss: [12.62687057 12.79537312 11.24055905], train_hist_grp_loss: [ 5.86596289  7.64661238 16.93405509], cur_train_grp_loss: [0.08829106 0.11527104 0.25506402], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6759, max_kl_dist_index: 0, max_train_grp_loss:  13.7168, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7954, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:29:28,381 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  66, train_loss:  12.6263, val_loss:  12.2216, grad_norm: 0.0028, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6759, 0.3234, 0.6756, param: [ 4.89020546  6.92383444  5.71251823 10.23183066], weights: [0.3040662  0.31526006 0.38067374], train_wt_loss:  37.8790, val_wt_loss: 36.6648, train_grp_loss: [11.47861112 13.71642558 13.00829168], val_grp_loss: [12.62727159 12.79502487 11.24075911], train_hist_grp_loss: [ 5.95425694  7.76187993 17.18911938], cur_train_grp_loss: [0.08829405 0.11526755 0.25506429], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6759, max_kl_dist_index: 0, max_train_grp_loss:  13.7164, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7950, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:29:29,424 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  67, train_loss:  12.6263, val_loss:  12.2217, grad_norm: 0.0028, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6759, 0.3234, 0.6756, param: [ 4.8900043   6.92303749  5.71307149 10.23196671], weights: [0.3036284  0.31497598 0.38139561], train_wt_loss:  37.8790, val_wt_loss: 36.6650, train_grp_loss: [11.47899313 13.71601696 13.0083037 ], val_grp_loss: [12.62766995 12.79468114 11.2409579 ], train_hist_grp_loss: [ 6.04255395  7.87714401 17.44418392], cur_train_grp_loss: [0.08829701 0.11526408 0.25506454], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6759, max_kl_dist_index: 0, max_train_grp_loss:  13.7160, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7947, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:29:30,464 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  68, train_loss:  12.6263, val_loss:  12.2218, grad_norm: 0.0029, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6759, 0.3234, 0.6756, param: [ 4.88980154  6.92224178  5.71362418 10.23210773], weights: [0.30319057 0.31469143 0.382118  ], train_wt_loss:  37.8790, val_wt_loss: 36.6653, train_grp_loss: [11.47937221 13.71561207 13.00831484], val_grp_loss: [12.62806563 12.79434193 11.2411554 ], train_hist_grp_loss: [ 6.1308539   7.99240465 17.6992487 ], cur_train_grp_loss: [0.08829995 0.11526065 0.25506478], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6759, max_kl_dist_index: 0, max_train_grp_loss:  13.7156, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7943, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:29:31,499 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  69, train_loss:  12.6263, val_loss:  12.2218, grad_norm: 0.0029, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6759, 0.3234, 0.6756, param: [ 4.8895972   6.92144731  5.71417631 10.23225372], weights: [0.30275271 0.3144064  0.38284089], train_wt_loss:  37.8790, val_wt_loss: 36.6655, train_grp_loss: [11.47974837 13.71521092 13.0083251 ], val_grp_loss: [12.62845863 12.79400723 11.24135162], train_hist_grp_loss: [ 6.21915676  8.1076619  17.9543137 ], cur_train_grp_loss: [0.08830286 0.11525724 0.255065  ], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6759, max_kl_dist_index: 0, max_train_grp_loss:  13.7152, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7940, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:29:32,531 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  70, train_loss:  12.6263, val_loss:  12.2219, grad_norm: 0.0029, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6759, 0.3234, 0.6756, param: [ 4.88939126  6.92065407  5.71472788 10.23240471], weights: [0.30231481 0.31412091 0.38356428], train_wt_loss:  37.8790, val_wt_loss: 36.6658, train_grp_loss: [11.4801216  13.71481351 13.00833448], val_grp_loss: [12.62884895 12.79367707 11.24154655], train_hist_grp_loss: [ 6.30746252  8.22291577 18.20937889], cur_train_grp_loss: [0.08830576 0.11525387 0.2550652 ], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6759, max_kl_dist_index: 0, max_train_grp_loss:  13.7148, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7937, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:29:33,545 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  71, train_loss:  12.6264, val_loss:  12.2220, grad_norm: 0.0030, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6759, 0.3234, 0.6756, param: [ 4.88918372  6.91986207  5.71527888 10.23256068], weights: [0.30187689 0.31383494 0.38428818], train_wt_loss:  37.8791, val_wt_loss: 36.6660, train_grp_loss: [11.48049189 13.71441985 13.00834299], val_grp_loss: [12.62923658 12.79335145 11.2417402 ], train_hist_grp_loss: [ 6.39577114  8.3381663  18.46444428], cur_train_grp_loss: [0.08830863 0.11525053 0.25506538], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6759, max_kl_dist_index: 0, max_train_grp_loss:  13.7144, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7934, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:29:34,607 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  72, train_loss:  12.6264, val_loss:  12.2221, grad_norm: 0.0030, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6759, 0.3234, 0.6755, param: [ 4.88897458  6.91907131  5.71582932 10.23272166], weights: [0.30143893 0.3135485  0.38501257], train_wt_loss:  37.8791, val_wt_loss: 36.6663, train_grp_loss: [11.48085924 13.71402993 13.00835061], val_grp_loss: [12.62962153 12.79303036 11.24193255], train_hist_grp_loss: [ 6.48408262  8.45341353 18.71950982], cur_train_grp_loss: [0.08831148 0.11524723 0.25506555], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6759, max_kl_dist_index: 0, max_train_grp_loss:  13.7140, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7930, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:29:35,640 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  73, train_loss:  12.6264, val_loss:  12.2222, grad_norm: 0.0031, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6759, 0.3234, 0.6755, param: [ 4.88876384  6.91828178  5.71637919 10.23288765], weights: [0.30100095 0.3132616  0.38573746], train_wt_loss:  37.8791, val_wt_loss: 36.6666, train_grp_loss: [11.48122364 13.71364376 13.00835735], val_grp_loss: [12.63000378 12.79271382 11.24212362], train_hist_grp_loss: [ 6.57239692  8.56865748 18.97457552], cur_train_grp_loss: [0.0883143  0.11524395 0.2550657 ], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6759, max_kl_dist_index: 0, max_train_grp_loss:  13.7136, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7927, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:29:36,651 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  74, train_loss:  12.6264, val_loss:  12.2223, grad_norm: 0.0031, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6759, 0.3234, 0.6755, param: [ 4.8885515   6.91749348  5.71692849 10.23305866], weights: [0.30056293 0.31297423 0.38646284], train_wt_loss:  37.8791, val_wt_loss: 36.6668, train_grp_loss: [11.4815851  13.71326136 13.00836321], val_grp_loss: [12.63038333 12.79240183 11.24231339], train_hist_grp_loss: [ 6.66071403  8.68389818 19.22964135], cur_train_grp_loss: [0.0883171  0.1152407  0.25506583], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6759, max_kl_dist_index: 0, max_train_grp_loss:  13.7133, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7924, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:29:37,648 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  75, train_loss:  12.6264, val_loss:  12.2224, grad_norm: 0.0032, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6759, 0.3234, 0.6755, param: [ 4.88833755  6.91670642  5.71747722 10.2332347 ], weights: [0.3001249  0.31268639 0.38718871], train_wt_loss:  37.8791, val_wt_loss: 36.6671, train_grp_loss: [11.4819436  13.71288271 13.00836818], val_grp_loss: [12.63076018 12.79209439 11.24250187], train_hist_grp_loss: [ 6.74903391  8.79913567 19.4847073 ], cur_train_grp_loss: [0.08831989 0.11523749 0.25506595], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6759, max_kl_dist_index: 0, max_train_grp_loss:  13.7129, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7921, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:29:38,693 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  76, train_loss:  12.6264, val_loss:  12.2224, grad_norm: 0.0032, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6759, 0.3234, 0.6755, param: [ 4.888122    6.91592058  5.71802539 10.23341576], weights: [0.29968684 0.3123981  0.38791506], train_wt_loss:  37.8791, val_wt_loss: 36.6673, train_grp_loss: [11.48229915 13.71250783 13.00837227], val_grp_loss: [12.63113433 12.79179152 11.24268904], train_hist_grp_loss: [ 6.83735655  8.91436998 19.73977334], cur_train_grp_loss: [0.08832264 0.11523431 0.25506604], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6759, max_kl_dist_index: 0, max_train_grp_loss:  13.7125, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7918, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:29:39,743 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  77, train_loss:  12.6264, val_loss:  12.2225, grad_norm: 0.0033, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6759, 0.3234, 0.6755, param: [ 4.88790484  6.91513598  5.71857298 10.23360187], weights: [0.29924876 0.31210934 0.3886419 ], train_wt_loss:  37.8792, val_wt_loss: 36.6676, train_grp_loss: [11.48265174 13.71213672 13.00837546], val_grp_loss: [12.63150577 12.79149322 11.24287492], train_hist_grp_loss: [ 6.92568193  9.02960114 19.99483946], cur_train_grp_loss: [0.08832538 0.11523116 0.25506612], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6759, max_kl_dist_index: 0, max_train_grp_loss:  13.7121, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7915, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:29:40,768 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  78, train_loss:  12.6264, val_loss:  12.2226, grad_norm: 0.0033, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6759, 0.3234, 0.6754, param: [ 4.88768606  6.9143526   5.71912    10.23379303], weights: [0.29881066 0.31182013 0.38936922], train_wt_loss:  37.8792, val_wt_loss: 36.6678, train_grp_loss: [11.48300137 13.71176938 13.00837777], val_grp_loss: [12.6318745  12.79119949 11.2430595 ], train_hist_grp_loss: [ 7.01401002  9.14482918 20.24990565], cur_train_grp_loss: [0.08832809 0.11522804 0.25506619], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6759, max_kl_dist_index: 0, max_train_grp_loss:  13.7118, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7912, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:29:41,841 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  79, train_loss:  12.6264, val_loss:  12.2227, grad_norm: 0.0033, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6759, 0.3234, 0.6754, param: [ 4.88746568  6.91357046  5.71966645 10.23398924], weights: [0.29837254 0.31153045 0.39009701], train_wt_loss:  37.8792, val_wt_loss: 36.6681, train_grp_loss: [11.48334802 13.71140582 13.00837918], val_grp_loss: [12.6322405  12.79091034 11.24324278], train_hist_grp_loss: [ 7.1023408   9.26005413 20.50497188], cur_train_grp_loss: [0.08833078 0.11522495 0.25506623], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6759, max_kl_dist_index: 0, max_train_grp_loss:  13.7114, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7909, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:29:42,872 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  80, train_loss:  12.6264, val_loss:  12.2228, grad_norm: 0.0034, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6759, 0.3234, 0.6754, param: [ 4.88724368  6.91278954  5.72021232 10.23419051], weights: [0.2979344  0.31124032 0.39082528], train_wt_loss:  37.8792, val_wt_loss: 36.6684, train_grp_loss: [11.48369171 13.71104604 13.0083797 ], val_grp_loss: [12.63260379 12.79062577 11.24342475], train_hist_grp_loss: [ 7.19067425  9.37527603 20.76003814], cur_train_grp_loss: [0.08833345 0.1152219  0.25506626], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6759, max_kl_dist_index: 0, max_train_grp_loss:  13.7110, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7906, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:29:43,898 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  81, train_loss:  12.6264, val_loss:  12.2229, grad_norm: 0.0034, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6759, 0.3234, 0.6754, param: [ 4.88702006  6.91200984  5.72075762 10.23439686], weights: [0.29749624 0.31094974 0.39155402], train_wt_loss:  37.8792, val_wt_loss: 36.6686, train_grp_loss: [11.48403242 13.71069004 13.00837933], val_grp_loss: [12.63296436 12.79034579 11.24360541], train_hist_grp_loss: [ 7.27901034  9.4904949  21.01510441], cur_train_grp_loss: [0.08833609 0.11521887 0.25506627], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6759, max_kl_dist_index: 0, max_train_grp_loss:  13.7107, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7903, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:29:44,932 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  82, train_loss:  12.6264, val_loss:  12.2230, grad_norm: 0.0035, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6759, 0.3234, 0.6754, param: [ 4.88679483  6.91123137  5.72130234 10.23460829], weights: [0.29705807 0.3106587  0.39228322], train_wt_loss:  37.8793, val_wt_loss: 36.6689, train_grp_loss: [11.48437015 13.71033784 13.00837806], val_grp_loss: [12.6333222  12.79007041 11.24378476], train_hist_grp_loss: [ 7.36734905  9.60571079 21.27017067], cur_train_grp_loss: [0.08833871 0.11521588 0.25506626], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6759, max_kl_dist_index: 0, max_train_grp_loss:  13.7103, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7901, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:29:45,960 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  83, train_loss:  12.6264, val_loss:  12.2230, grad_norm: 0.0035, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6759, 0.3234, 0.6754, param: [ 4.88656797  6.91045413  5.72184649 10.2348248 ], weights: [0.29661989 0.31036721 0.39301289], train_wt_loss:  37.8793, val_wt_loss: 36.6691, train_grp_loss: [11.4847049  13.70998942 13.00837589], val_grp_loss: [12.63367731 12.78979963 11.2439628 ], train_hist_grp_loss: [ 7.45569036  9.72092371 21.52523691], cur_train_grp_loss: [0.08834131 0.11521292 0.25506624], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6759, max_kl_dist_index: 0, max_train_grp_loss:  13.7100, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7898, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:29:46,998 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  84, train_loss:  12.6264, val_loss:  12.2231, grad_norm: 0.0036, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6759, 0.3234, 0.6754, param: [ 4.8863395   6.9096781   5.72239006 10.23504641], weights: [0.2961817  0.31007528 0.39374303], train_wt_loss:  37.8793, val_wt_loss: 36.6694, train_grp_loss: [11.48503666 13.70964481 13.00837282], val_grp_loss: [12.63402968 12.78953345 11.24413953], train_hist_grp_loss: [ 7.54403424  9.83613371 21.7803031 ], cur_train_grp_loss: [0.08834388 0.11521    0.25506619], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6759, max_kl_dist_index: 0, max_train_grp_loss:  13.7096, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7895, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:29:48,007 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  85, train_loss:  12.6264, val_loss:  12.2232, grad_norm: 0.0036, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6759, 0.3234, 0.6754, param: [ 4.8861094   6.9089033   5.72293305 10.23527312], weights: [0.29574349 0.30978289 0.39447362], train_wt_loss:  37.8793, val_wt_loss: 36.6697, train_grp_loss: [11.48536543 13.709304   13.00836886], val_grp_loss: [12.63437931 12.78927189 11.24431495], train_hist_grp_loss: [ 7.63238068  9.9513408  22.03536923], cur_train_grp_loss: [0.08834644 0.1152071  0.25506613], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6759, max_kl_dist_index: 0, max_train_grp_loss:  13.7093, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7893, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:29:49,048 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  86, train_loss:  12.6264, val_loss:  12.2233, grad_norm: 0.0037, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6759, 0.3234, 0.6753, param: [ 4.88587767  6.90812972  5.72347546 10.23550494], weights: [0.29530528 0.30949006 0.39520467], train_wt_loss:  37.8793, val_wt_loss: 36.6699, train_grp_loss: [11.4856912  13.70896699 13.00836399], val_grp_loss: [12.6347262  12.78901494 11.24448905], train_hist_grp_loss: [ 7.72072964 10.06654504 22.29043529], cur_train_grp_loss: [0.08834896 0.11520424 0.25506606], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6759, max_kl_dist_index: 0, max_train_grp_loss:  13.7090, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7890, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:29:50,064 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  87, train_loss:  12.6265, val_loss:  12.2234, grad_norm: 0.0037, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6759, 0.3234, 0.6753, param: [ 4.88564432  6.90735736  5.72401729 10.23574187], weights: [0.29486706 0.30919678 0.39593616], train_wt_loss:  37.8794, val_wt_loss: 36.6702, train_grp_loss: [11.48601398 13.70863379 13.00835822], val_grp_loss: [12.63507035 12.78876262 11.24466183], train_hist_grp_loss: [ 7.80908111 10.18174644 22.54550125], cur_train_grp_loss: [0.08835147 0.1152014  0.25506596], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6759, max_kl_dist_index: 0, max_train_grp_loss:  13.7086, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7888, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:29:51,093 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  88, train_loss:  12.6265, val_loss:  12.2235, grad_norm: 0.0038, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6759, 0.3234, 0.6753, param: [ 4.88540933  6.90658621  5.72455853 10.23598394], weights: [0.29442883 0.30890306 0.39666811], train_wt_loss:  37.8794, val_wt_loss: 36.6705, train_grp_loss: [11.48633375 13.70830441 13.00835154], val_grp_loss: [12.63541175 12.78851493 11.24483328], train_hist_grp_loss: [ 7.89743507 10.29694505 22.8005671 ], cur_train_grp_loss: [0.08835395 0.1151986  0.25506585], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6759, max_kl_dist_index: 0, max_train_grp_loss:  13.7083, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7885, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:29:52,151 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  89, train_loss:  12.6265, val_loss:  12.2236, grad_norm: 0.0038, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6759, 0.3234, 0.6753, param: [ 4.88517272  6.90581629  5.7250992  10.23623113], weights: [0.2939906  0.3086089  0.39740051], train_wt_loss:  37.8794, val_wt_loss: 36.6707, train_grp_loss: [11.48665052 13.70797884 13.00834396], val_grp_loss: [12.63575039 12.78827187 11.24500342], train_hist_grp_loss: [ 7.98579148 10.41214088 23.05563281], cur_train_grp_loss: [0.08835641 0.11519584 0.25506572], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6759, max_kl_dist_index: 0, max_train_grp_loss:  13.7080, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7883, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:29:53,189 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  90, train_loss:  12.6265, val_loss:  12.2237, grad_norm: 0.0038, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6759, 0.3234, 0.6753, param: [ 4.88493447  6.90504757  5.72563927 10.23648347], weights: [0.29355236 0.30831429 0.39813334], train_wt_loss:  37.8794, val_wt_loss: 36.6710, train_grp_loss: [11.48696427 13.7076571  13.00833547], val_grp_loss: [12.63608627 12.78803345 11.24517223], train_hist_grp_loss: [ 8.07415033 10.52733398 23.31069838], cur_train_grp_loss: [0.08835885 0.1151931  0.25506557], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6759, max_kl_dist_index: 0, max_train_grp_loss:  13.7077, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7880, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:29:54,230 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  91, train_loss:  12.6265, val_loss:  12.2238, grad_norm: 0.0039, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6759, 0.3234, 0.6753, param: [ 4.88469459  6.90428008  5.72617877 10.23674095], weights: [0.29311412 0.30801925 0.39886662], train_wt_loss:  37.8794, val_wt_loss: 36.6713, train_grp_loss: [11.48727502 13.70733918 13.00832607], val_grp_loss: [12.6364194  12.78779968 11.24533972], train_hist_grp_loss: [ 8.1625116  10.64252438 23.56576378], cur_train_grp_loss: [0.08836126 0.1151904  0.2550654 ], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6759, max_kl_dist_index: 0, max_train_grp_loss:  13.7073, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7878, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:29:55,274 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  92, train_loss:  12.6265, val_loss:  12.2238, grad_norm: 0.0039, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6759, 0.3234, 0.6753, param: [ 4.88445307  6.90351379  5.72671767 10.2370036 ], weights: [0.29267589 0.30772378 0.39960034], train_wt_loss:  37.8795, val_wt_loss: 36.6715, train_grp_loss: [11.48758274 13.7070251  13.00831576], val_grp_loss: [12.63674976 12.78757055 11.24550588], train_hist_grp_loss: [ 8.25087525 10.7577121  23.820829  ], cur_train_grp_loss: [0.08836365 0.11518772 0.25506522], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6759, max_kl_dist_index: 0, max_train_grp_loss:  13.7070, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7876, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:29:56,292 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  93, train_loss:  12.6265, val_loss:  12.2239, grad_norm: 0.0040, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6759, 0.3234, 0.6753, param: [ 4.88420991  6.90274872  5.72725599 10.2372714 ], weights: [0.29223765 0.30742786 0.40033448], train_wt_loss:  37.8795, val_wt_loss: 36.6718, train_grp_loss: [11.48788744 13.70671484 13.00830454], val_grp_loss: [12.63707735 12.78734609 11.24567071], train_hist_grp_loss: [ 8.33924127 10.87289719 24.07589402], cur_train_grp_loss: [0.08836602 0.11518508 0.25506501], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6759, max_kl_dist_index: 0, max_train_grp_loss:  13.7067, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7873, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:29:57,316 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  94, train_loss:  12.6265, val_loss:  12.2240, grad_norm: 0.0040, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6759, 0.3234, 0.6753, param: [ 4.88396511  6.90198486  5.72779373 10.23754438], weights: [0.29179942 0.30713152 0.40106906], train_wt_loss:  37.8795, val_wt_loss: 36.6721, train_grp_loss: [11.48818912 13.70640843 13.0082924 ], val_grp_loss: [12.63740217 12.78712629 11.2458342 ], train_hist_grp_loss: [ 8.42760964 10.98807966 24.33095881], cur_train_grp_loss: [0.08836836 0.11518248 0.25506479], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6759, max_kl_dist_index: 0, max_train_grp_loss:  13.7064, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7871, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:29:58,327 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  95, train_loss:  12.6265, val_loss:  12.2241, grad_norm: 0.0041, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6759, 0.3234, 0.6753, param: [ 4.88371867  6.90122221  5.72833087 10.23782253], weights: [0.29136119 0.30683474 0.40180407], train_wt_loss:  37.8795, val_wt_loss: 36.6723, train_grp_loss: [11.48848776 13.70610586 13.00827935], val_grp_loss: [12.63772421 12.78691115 11.24599637], train_hist_grp_loss: [ 8.51598032 11.10325957 24.58602337], cur_train_grp_loss: [0.08837069 0.1151799  0.25506456], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6759, max_kl_dist_index: 0, max_train_grp_loss:  13.7061, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7869, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:29:59,352 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  96, train_loss:  12.6265, val_loss:  12.2242, grad_norm: 0.0041, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6759, 0.3234, 0.6752, param: [ 4.88347059  6.90046076  5.72886742 10.23810587], weights: [0.29092297 0.30653753 0.4025395 ], train_wt_loss:  37.8795, val_wt_loss: 36.6726, train_grp_loss: [11.48878338 13.70580714 13.00826539], val_grp_loss: [12.63804348 12.78670069 11.2461572 ], train_hist_grp_loss: [ 8.6043533  11.21843693 24.84108767], cur_train_grp_loss: [0.08837298 0.11517736 0.2550643 ], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6759, max_kl_dist_index: 0, max_train_grp_loss:  13.7058, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7867, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:30:00,410 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  97, train_loss:  12.6265, val_loss:  12.2243, grad_norm: 0.0042, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6759, 0.3234, 0.6752, param: [ 4.88322085  6.89970052  5.72940338 10.23839441], weights: [0.29048476 0.3062399  0.40327535], train_wt_loss:  37.8796, val_wt_loss: 36.6729, train_grp_loss: [11.48907596 13.70551227 13.0082505 ], val_grp_loss: [12.63835996 12.78649491 11.24631669], train_hist_grp_loss: [ 8.69272856 11.33361178 25.0961517 ], cur_train_grp_loss: [0.08837526 0.11517485 0.25506403], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6759, max_kl_dist_index: 0, max_train_grp_loss:  13.7055, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7865, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:30:01,431 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  98, train_loss:  12.6265, val_loss:  12.2244, grad_norm: 0.0042, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6759, 0.3234, 0.6752, param: [ 4.88296947  6.89894149  5.72993874 10.23868815], weights: [0.29004655 0.30594183 0.40401161], train_wt_loss:  37.8796, val_wt_loss: 36.6731, train_grp_loss: [11.48936549 13.70522125 13.0082347 ], val_grp_loss: [12.63867365 12.78629382 11.24647484], train_hist_grp_loss: [ 8.78110607 11.44878415 25.35121543], cur_train_grp_loss: [0.08837751 0.11517237 0.25506374], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6759, max_kl_dist_index: 0, max_train_grp_loss:  13.7052, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7863, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:30:02,513 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  99, train_loss:  12.6265, val_loss:  12.2245, grad_norm: 0.0043, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6759, 0.3234, 0.6752, param: [ 4.88271644  6.89818367  5.73047351 10.2389871 ], weights: [0.28960836 0.30564335 0.4047483 ], train_wt_loss:  37.8796, val_wt_loss: 36.6734, train_grp_loss: [11.48965198 13.7049341  13.00821798], val_grp_loss: [12.63898456 12.78609742 11.24663165], train_hist_grp_loss: [ 8.8694858  11.56395407 25.60627886], cur_train_grp_loss: [0.08837973 0.11516993 0.25506343], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6759, max_kl_dist_index: 0, max_train_grp_loss:  13.7049, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7861, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:30:03,605 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  100, train_loss:  12.6265, val_loss:  12.2246, grad_norm: 0.0043, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6759, 0.3234, 0.6752, param: [ 4.88246175  6.89742704  5.73100769 10.23929127], weights: [0.28917018 0.30534444 0.40548539], train_wt_loss:  37.8796, val_wt_loss: 36.6737, train_grp_loss: [11.48993543 13.7046508  13.00820033], val_grp_loss: [12.63929267 12.78590571 11.24678712], train_hist_grp_loss: [ 8.95786774 11.67912159 25.86134195], cur_train_grp_loss: [0.08838194 0.11516751 0.2550631 ], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6759, max_kl_dist_index: 0, max_train_grp_loss:  13.7047, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7859, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:30:04,618 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  101, train_loss:  12.6266, val_loss:  12.2246, grad_norm: 0.0043, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6759, 0.3234, 0.6752, param: [ 4.88220542  6.89667162  5.73154127 10.23960066], weights: [0.28873201 0.3050451  0.40622289], train_wt_loss:  37.8797, val_wt_loss: 36.6739, train_grp_loss: [11.49021582 13.70437138 13.00818176], val_grp_loss: [12.63959798 12.7857187  11.24694125], train_hist_grp_loss: [ 9.04625186 11.79428672 26.1164047 ], cur_train_grp_loss: [0.08838412 0.11516513 0.25506275], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6759, max_kl_dist_index: 0, max_train_grp_loss:  13.7044, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7857, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:30:05,643 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  102, train_loss:  12.6266, val_loss:  12.2247, grad_norm: 0.0044, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6759, 0.3234, 0.6752, param: [ 4.88194742  6.8959174   5.73207425 10.23991528], weights: [0.28829385 0.30474535 0.4069608 ], train_wt_loss:  37.8797, val_wt_loss: 36.6742, train_grp_loss: [11.49049315 13.70409583 13.00816227], val_grp_loss: [12.6399005  12.78553641 11.24709403], train_hist_grp_loss: [ 9.13463813 11.90944951 26.37146709], cur_train_grp_loss: [0.08838628 0.11516278 0.25506239], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6759, max_kl_dist_index: 0, max_train_grp_loss:  13.7041, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7855, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:30:06,693 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  103, train_loss:  12.6266, val_loss:  12.2248, grad_norm: 0.0044, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6759, 0.3234, 0.6752, param: [ 4.88168777  6.89516437  5.73260663 10.24023515], weights: [0.28785572 0.30444518 0.40769911], train_wt_loss:  37.8797, val_wt_loss: 36.6745, train_grp_loss: [11.49076743 13.70382415 13.00814185], val_grp_loss: [12.6402002  12.78535883 11.24724546], train_hist_grp_loss: [ 9.22302654 12.02460998 26.6265291 ], cur_train_grp_loss: [0.08838841 0.11516047 0.25506201], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6759, max_kl_dist_index: 0, max_train_grp_loss:  13.7038, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7854, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:30:07,708 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  104, train_loss:  12.6266, val_loss:  12.2249, grad_norm: 0.0045, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6759, 0.3234, 0.6752, param: [ 4.88142646  6.89441255  5.73313842 10.24056026], weights: [0.2874176  0.30414459 0.40843781], train_wt_loss:  37.8797, val_wt_loss: 36.6748, train_grp_loss: [11.49103864 13.70355636 13.0081205 ], val_grp_loss: [12.6404971  12.78518596 11.24739555], train_hist_grp_loss: [ 9.31141706 12.13976816 26.8815907 ], cur_train_grp_loss: [0.08839052 0.11515819 0.2550616 ], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6759, max_kl_dist_index: 0, max_train_grp_loss:  13.7036, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7852, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:30:08,736 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  105, train_loss:  12.6266, val_loss:  12.2250, grad_norm: 0.0045, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6759, 0.3234, 0.6752, param: [ 4.88116348  6.89366192  5.7336696  10.24089063], weights: [0.2869795  0.30384359 0.40917691], train_wt_loss:  37.8797, val_wt_loss: 36.6750, train_grp_loss: [11.49130679 13.70329245 13.00809823], val_grp_loss: [12.64079119 12.78501783 11.24754428], train_hist_grp_loss: [ 9.39980967 12.2549241  27.13665189], cur_train_grp_loss: [0.0883926  0.11515594 0.25506119], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6759, max_kl_dist_index: 0, max_train_grp_loss:  13.7033, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7850, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:30:09,754 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  106, train_loss:  12.6266, val_loss:  12.2251, grad_norm: 0.0046, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6759, 0.3234, 0.6752, param: [ 4.88089884  6.89291248  5.73420018 10.24122626], weights: [0.28654142 0.30354217 0.40991641], train_wt_loss:  37.8798, val_wt_loss: 36.6753, train_grp_loss: [11.49157186 13.70303243 13.00807502], val_grp_loss: [12.64108247 12.78485442 11.24769166], train_hist_grp_loss: [ 9.48820433 12.37007782 27.39171264], cur_train_grp_loss: [0.08839467 0.11515372 0.25506075], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6759, max_kl_dist_index: 0, max_train_grp_loss:  13.7030, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7849, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:30:10,785 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  107, train_loss:  12.6266, val_loss:  12.2252, grad_norm: 0.0046, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6759, 0.3234, 0.6752, param: [ 4.88063254  6.89216424  5.73473016 10.24156717], weights: [0.28610336 0.30324035 0.41065629], train_wt_loss:  37.8798, val_wt_loss: 36.6756, train_grp_loss: [11.49183386 13.7027763  13.00805088], val_grp_loss: [12.64137092 12.78469575 11.24783768], train_hist_grp_loss: [ 9.57660104 12.48522935 27.64677293], cur_train_grp_loss: [0.08839671 0.11515153 0.25506029], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6759, max_kl_dist_index: 0, max_train_grp_loss:  13.7028, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7847, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:30:11,820 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  108, train_loss:  12.6266, val_loss:  12.2253, grad_norm: 0.0047, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6759, 0.3234, 0.6752, param: [ 4.88036457  6.89141719  5.73525953 10.24191335], weights: [0.28566533 0.30293811 0.41139656], train_wt_loss:  37.8798, val_wt_loss: 36.6759, train_grp_loss: [11.49209278 13.70252408 13.00802581], val_grp_loss: [12.64165655 12.78454183 11.24798235], train_hist_grp_loss: [ 9.66499976 12.60037873 27.90183275], cur_train_grp_loss: [0.08839872 0.11514938 0.25505982], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6759, max_kl_dist_index: 0, max_train_grp_loss:  13.7025, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7845, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:30:12,826 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  109, train_loss:  12.6266, val_loss:  12.2254, grad_norm: 0.0047, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6759, 0.3234, 0.6752, param: [ 4.88009493  6.89067134  5.7357883  10.24226482], weights: [0.28522732 0.30263547 0.41213721], train_wt_loss:  37.8798, val_wt_loss: 36.6761, train_grp_loss: [11.49234862 13.70227575 13.00799981], val_grp_loss: [12.64193936 12.78439265 11.24812567], train_hist_grp_loss: [ 9.75340048 12.71552599 28.15689208], cur_train_grp_loss: [0.08840071 0.11514726 0.25505933], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6759, max_kl_dist_index: 0, max_train_grp_loss:  13.7023, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7844, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:30:13,841 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  110, train_loss:  12.6266, val_loss:  12.2255, grad_norm: 0.0048, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6759, 0.3234, 0.6752, param: [ 4.87982361  6.88992667  5.73631646 10.24262158], weights: [0.28478935 0.30233242 0.41287824], train_wt_loss:  37.8799, val_wt_loss: 36.6764, train_grp_loss: [11.49260138 13.70203133 13.00797287], val_grp_loss: [12.64221933 12.78424823 11.24826762], train_hist_grp_loss: [ 9.84180316 12.83067116 28.4119509 ], cur_train_grp_loss: [0.08840268 0.11514517 0.25505882], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6759, max_kl_dist_index: 0, max_train_grp_loss:  13.7020, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7842, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:30:14,891 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  111, train_loss:  12.6266, val_loss:  12.2256, grad_norm: 0.0048, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6759, 0.3234, 0.6752, param: [ 4.87955063  6.88918318  5.73684401 10.24298365], weights: [0.2843514  0.30202896 0.41361964], train_wt_loss:  37.8799, val_wt_loss: 36.6767, train_grp_loss: [11.49285104 13.70179082 13.00794499], val_grp_loss: [12.64249647 12.78410856 11.24840821], train_hist_grp_loss: [ 9.93020778 12.94581428 28.6670092 ], cur_train_grp_loss: [0.08840463 0.11514312 0.25505829], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6759, max_kl_dist_index: 0, max_train_grp_loss:  13.7018, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7841, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:30:15,899 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  112, train_loss:  12.6266, val_loss:  12.2257, grad_norm: 0.0049, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6759, 0.3234, 0.6752, param: [ 4.87927597  6.88844089  5.73737096 10.24335103], weights: [0.28391348 0.3017251  0.41436142], train_wt_loss:  37.8799, val_wt_loss: 36.6770, train_grp_loss: [11.49309762 13.70155422 13.00791617], val_grp_loss: [12.64277078 12.78397367 11.24854744], train_hist_grp_loss: [10.01861433 13.06095538 28.92206694], cur_train_grp_loss: [0.08840655 0.1151411  0.25505774], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6759, max_kl_dist_index: 0, max_train_grp_loss:  13.7016, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7840, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:30:16,913 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  113, train_loss:  12.6266, val_loss:  12.2257, grad_norm: 0.0049, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6759, 0.3234, 0.6752, param: [ 4.87899963  6.88769978  5.73789729 10.24372372], weights: [0.28347559 0.30142085 0.41510356], train_wt_loss:  37.8799, val_wt_loss: 36.6772, train_grp_loss: [11.49334109 13.70132155 13.00788642], val_grp_loss: [12.64304224 12.78384354 11.2486853 ], train_hist_grp_loss: [10.10702277 13.1760945  29.17712412], cur_train_grp_loss: [0.08840844 0.11513911 0.25505718], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6759, max_kl_dist_index: 0, max_train_grp_loss:  13.7013, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7838, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:30:17,961 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  114, train_loss:  12.6267, val_loss:  12.2258, grad_norm: 0.0049, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6760, 0.3234, 0.6752, param: [ 4.87872161  6.88695985  5.73842301 10.24410174], weights: [0.28303774 0.30111619 0.41584608], train_wt_loss:  37.8800, val_wt_loss: 36.6775, train_grp_loss: [11.49358147 13.70109279 13.00785572], val_grp_loss: [12.64331087 12.7837182  11.2488218 ], train_hist_grp_loss: [10.19543309 13.29123165 29.43218072], cur_train_grp_loss: [0.08841032 0.11513716 0.2550566 ], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6760, max_kl_dist_index: 0, max_train_grp_loss:  13.7011, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7837, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:30:19,030 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  115, train_loss:  12.6267, val_loss:  12.2259, grad_norm: 0.0050, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6760, 0.3235, 0.6752, param: [ 4.87844191  6.8862211   5.73894812 10.24448509], weights: [0.28259992 0.30081113 0.41658895], train_wt_loss:  37.8800, val_wt_loss: 36.6778, train_grp_loss: [11.49381874 13.70086797 13.00782408], val_grp_loss: [12.64357664 12.78359763 11.24895693], train_hist_grp_loss: [10.28384526 13.40636688 29.68723671], cur_train_grp_loss: [0.08841217 0.11513523 0.25505599], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6760, max_kl_dist_index: 0, max_train_grp_loss:  13.7009, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7836, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:30:20,066 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  116, train_loss:  12.6267, val_loss:  12.2260, grad_norm: 0.0050, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6760, 0.3235, 0.6752, param: [ 4.87816053  6.88548353  5.73947262 10.24487378], weights: [0.28216213 0.30050568 0.41733218], train_wt_loss:  37.8800, val_wt_loss: 36.6781, train_grp_loss: [11.49405291 13.70064708 13.0077915 ], val_grp_loss: [12.64383956 12.78348186 11.2490907 ], train_hist_grp_loss: [10.37225925 13.52150023 29.94229209], cur_train_grp_loss: [0.08841399 0.11513334 0.25505537], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6760, max_kl_dist_index: 0, max_train_grp_loss:  13.7006, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7835, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:30:21,082 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  117, train_loss:  12.6267, val_loss:  12.2261, grad_norm: 0.0051, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6760, 0.3235, 0.6751, param: [ 4.87787746  6.88474714  5.7399965  10.24526781], weights: [0.28172439 0.30019984 0.41807577], train_wt_loss:  37.8800, val_wt_loss: 36.6784, train_grp_loss: [11.49428396 13.70043012 13.00775797], val_grp_loss: [12.64409963 12.78337088 11.24922309], train_hist_grp_loss: [10.46067504 13.63663172 30.19734682], cur_train_grp_loss: [0.08841579 0.11513149 0.25505474], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6760, max_kl_dist_index: 0, max_train_grp_loss:  13.7004, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7834, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:30:22,128 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  118, train_loss:  12.6267, val_loss:  12.2262, grad_norm: 0.0051, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6760, 0.3235, 0.6751, param: [ 4.87759271  6.88401193  5.74051976 10.24566721], weights: [0.28128668 0.2998936  0.41881971], train_wt_loss:  37.8801, val_wt_loss: 36.6786, train_grp_loss: [11.4945119  13.7002171  13.00772349], val_grp_loss: [12.64435684 12.7832647  11.24935411], train_hist_grp_loss: [10.54909261 13.75176138 30.4524009 ], cur_train_grp_loss: [0.08841757 0.11512966 0.25505408], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6760, max_kl_dist_index: 0, max_train_grp_loss:  13.7002, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7833, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:30:23,159 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  119, train_loss:  12.6267, val_loss:  12.2263, grad_norm: 0.0052, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6760, 0.3235, 0.6751, param: [ 4.87730627  6.8832779   5.7410424  10.24607197], weights: [0.28084902 0.29958698 0.419564  ], train_wt_loss:  37.8801, val_wt_loss: 36.6789, train_grp_loss: [11.49473672 13.70000803 13.00768807], val_grp_loss: [12.64461119 12.78316333 11.24948375], train_hist_grp_loss: [10.63751193 13.86688926 30.7074543 ], cur_train_grp_loss: [0.08841932 0.11512787 0.2550534 ], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6760, max_kl_dist_index: 0, max_train_grp_loss:  13.7000, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7832, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:30:24,183 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  120, train_loss:  12.6267, val_loss:  12.2264, grad_norm: 0.0052, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6760, 0.3235, 0.6751, param: [ 4.87701814  6.88254503  5.74156443 10.24648209], weights: [0.2804114  0.29927996 0.42030864], train_wt_loss:  37.8801, val_wt_loss: 36.6792, train_grp_loss: [11.49495842 13.69980291 13.0076517 ], val_grp_loss: [12.64486268 12.78306677 11.24961202], train_hist_grp_loss: [10.72593298 13.98201537 30.96250701], cur_train_grp_loss: [0.08842105 0.11512612 0.25505271], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6760, max_kl_dist_index: 0, max_train_grp_loss:  13.6998, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7831, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:30:25,192 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  121, train_loss:  12.6267, val_loss:  12.2265, grad_norm: 0.0053, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6760, 0.3235, 0.6751, param: [ 4.87672831  6.88181334  5.74208584 10.2468976 ], weights: [0.27997382 0.29897256 0.42105362], train_wt_loss:  37.8801, val_wt_loss: 36.6795, train_grp_loss: [11.495177   13.69960174 13.00761437], val_grp_loss: [12.6451113  12.78297503 11.24973891], train_hist_grp_loss: [10.81435574 14.09713977 31.217559  ], cur_train_grp_loss: [0.08842276 0.11512439 0.25505199], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6760, max_kl_dist_index: 0, max_train_grp_loss:  13.6996, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7830, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:30:26,213 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  122, train_loss:  12.6267, val_loss:  12.2266, grad_norm: 0.0053, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6760, 0.3235, 0.6751, param: [ 4.87643679  6.88108282  5.74260662 10.24731849], weights: [0.27953629 0.29866477 0.42179893], train_wt_loss:  37.8802, val_wt_loss: 36.6798, train_grp_loss: [11.49539244 13.69940453 13.0075761 ], val_grp_loss: [12.64535704 12.78288811 11.24986443], train_hist_grp_loss: [10.90278018 14.21226247 31.47261026], cur_train_grp_loss: [0.08842444 0.1151227  0.25505126], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6760, max_kl_dist_index: 0, max_train_grp_loss:  13.6994, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7829, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:30:27,232 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  123, train_loss:  12.6267, val_loss:  12.2267, grad_norm: 0.0054, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6760, 0.3235, 0.6752, param: [ 4.87614357  6.88035347  5.74312679 10.24774478], weights: [0.27909881 0.2983566  0.42254459], train_wt_loss:  37.8802, val_wt_loss: 36.6801, train_grp_loss: [11.49560475 13.69921128 13.00753687], val_grp_loss: [12.64559991 12.78280603 11.24998856], train_hist_grp_loss: [10.99120627 14.32738352 31.72766078], cur_train_grp_loss: [0.0884261  0.11512105 0.25505051], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6760, max_kl_dist_index: 0, max_train_grp_loss:  13.6992, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7828, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:30:28,306 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  124, train_loss:  12.6267, val_loss:  12.2268, grad_norm: 0.0054, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6760, 0.3235, 0.6752, param: [ 4.87584866  6.87962528  5.74364633 10.24817646], weights: [0.27866138 0.29804805 0.42329057], train_wt_loss:  37.8802, val_wt_loss: 36.6803, train_grp_loss: [11.49581393 13.69902199 13.00749669], val_grp_loss: [12.6458399  12.78272878 11.25011131], train_hist_grp_loss: [11.079634   14.44250294 31.98271052], cur_train_grp_loss: [0.08842773 0.11511942 0.25504974], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6760, max_kl_dist_index: 0, max_train_grp_loss:  13.6990, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7827, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:30:29,344 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  125, train_loss:  12.6267, val_loss:  12.2269, grad_norm: 0.0055, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6760, 0.3235, 0.6752, param: [ 4.87555204  6.87889826  5.74416524 10.24861356], weights: [0.27822399 0.29773912 0.42403689], train_wt_loss:  37.8802, val_wt_loss: 36.6806, train_grp_loss: [11.49601997 13.69883668 13.00745555], val_grp_loss: [12.64607701 12.78265637 11.25023268], train_hist_grp_loss: [11.16806334 14.55762077 32.23775947], cur_train_grp_loss: [0.08842934 0.11511783 0.25504895], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6760, max_kl_dist_index: 0, max_train_grp_loss:  13.6988, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7827, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:30:30,381 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  126, train_loss:  12.6268, val_loss:  12.2270, grad_norm: 0.0055, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6760, 0.3235, 0.6752, param: [ 4.87525373  6.87817241  5.74468353 10.24905607], weights: [0.27778666 0.29742981 0.42478352], train_wt_loss:  37.8803, val_wt_loss: 36.6809, train_grp_loss: [11.49622286 13.69865535 13.00741345], val_grp_loss: [12.64631123 12.78258882 11.25035267], train_hist_grp_loss: [11.25649426 14.67273705 32.49280762], cur_train_grp_loss: [0.08843092 0.11511627 0.25504815], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6760, max_kl_dist_index: 0, max_train_grp_loss:  13.6987, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7826, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:30:31,425 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  127, train_loss:  12.6268, val_loss:  12.2271, grad_norm: 0.0056, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6760, 0.3235, 0.6752, param: [ 4.8749537   6.87744771  5.74520119 10.249504  ], weights: [0.27734939 0.29712013 0.42553049], train_wt_loss:  37.8803, val_wt_loss: 36.6812, train_grp_loss: [11.49642261 13.69847799 13.0073704 ], val_grp_loss: [12.64654257 12.78252611 11.25047126], train_hist_grp_loss: [11.34492675 14.7878518  32.74785494], cur_train_grp_loss: [0.08843248 0.11511475 0.25504732], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6760, max_kl_dist_index: 0, max_train_grp_loss:  13.6985, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7825, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:30:32,437 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  128, train_loss:  12.6268, val_loss:  12.2272, grad_norm: 0.0056, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6761, 0.3235, 0.6752, param: [ 4.87465197  6.87672418  5.74571822 10.24995737], weights: [0.27691216 0.29681007 0.42627777], train_wt_loss:  37.8803, val_wt_loss: 36.6815, train_grp_loss: [11.49661921 13.69830462 13.00732638], val_grp_loss: [12.64677101 12.78246827 11.25058848], train_hist_grp_loss: [11.43336077 14.90296506 33.00290142], cur_train_grp_loss: [0.08843402 0.11511326 0.25504648], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6761, max_kl_dist_index: 0, max_train_grp_loss:  13.6983, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7825, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:30:33,482 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  129, train_loss:  12.6268, val_loss:  12.2273, grad_norm: 0.0056, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6761, 0.3235, 0.6752, param: [ 4.87434854  6.8760018   5.74623462 10.25041618], weights: [0.276475   0.29649964 0.42702536], train_wt_loss:  37.8804, val_wt_loss: 36.6818, train_grp_loss: [11.49681265 13.69813523 13.00728141], val_grp_loss: [12.64699656 12.78241529 11.2507043 ], train_hist_grp_loss: [11.5217963  15.01807686 33.25794704], cur_train_grp_loss: [0.08843553 0.1151118  0.25504562], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6761, max_kl_dist_index: 0, max_train_grp_loss:  13.6981, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7824, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:30:34,531 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  130, train_loss:  12.6268, val_loss:  12.2274, grad_norm: 0.0057, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6761, 0.3236, 0.6752, param: [ 4.87404339  6.87528058  5.74675039 10.25088043], weights: [0.27603789 0.29618884 0.42777327], train_wt_loss:  37.8804, val_wt_loss: 36.6821, train_grp_loss: [11.49700294 13.69796984 13.00723547], val_grp_loss: [12.64721921 12.78236718 11.25081873], train_hist_grp_loss: [11.61023332 15.13318724 33.51299177], cur_train_grp_loss: [0.08843702 0.11511038 0.25504473], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6761, max_kl_dist_index: 0, max_train_grp_loss:  13.6980, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7824, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:30:35,540 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  131, train_loss:  12.6268, val_loss:  12.2275, grad_norm: 0.0057, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6761, 0.3236, 0.6752, param: [ 4.87373653  6.87456052  5.74726553 10.25135014], weights: [0.27560084 0.29587767 0.42852149], train_wt_loss:  37.8804, val_wt_loss: 36.6824, train_grp_loss: [11.49719007 13.69780844 13.00718857], val_grp_loss: [12.64743895 12.78232395 11.25093177], train_hist_grp_loss: [11.6986718  15.24829623 33.7680356 ], cur_train_grp_loss: [0.08843848 0.11510899 0.25504383], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6761, max_kl_dist_index: 0, max_train_grp_loss:  13.6978, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7823, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:30:36,591 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  132, train_loss:  12.6268, val_loss:  12.2276, grad_norm: 0.0058, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6761, 0.3236, 0.6752, param: [ 4.87342796  6.87384161  5.74778003 10.25182531], weights: [0.27516386 0.29556613 0.42927001], train_wt_loss:  37.8804, val_wt_loss: 36.6827, train_grp_loss: [11.49737403 13.69765105 13.00714071], val_grp_loss: [12.64765579 12.7822856  11.25104341], train_hist_grp_loss: [11.78711173 15.36340387 34.02307852], cur_train_grp_loss: [0.08843992 0.11510763 0.25504291], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6761, max_kl_dist_index: 0, max_train_grp_loss:  13.6977, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7823, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:30:37,590 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  133, train_loss:  12.6268, val_loss:  12.2276, grad_norm: 0.0058, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6761, 0.3236, 0.6752, param: [ 4.87311767  6.87312385  5.7482939  10.25230595], weights: [0.27472694 0.29525423 0.43001883], train_wt_loss:  37.8805, val_wt_loss: 36.6829, train_grp_loss: [11.49755483 13.69749766 13.00709187], val_grp_loss: [12.64786972 12.78225215 11.25115367], train_hist_grp_loss: [11.87555306 15.47851018 34.27812049], cur_train_grp_loss: [0.08844134 0.11510631 0.25504197], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6761, max_kl_dist_index: 0, max_train_grp_loss:  13.6975, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7823, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:30:38,622 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  134, train_loss:  12.6268, val_loss:  12.2277, grad_norm: 0.0059, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6761, 0.3236, 0.6752, param: [ 4.87280567  6.87240724  5.74880713 10.25279207], weights: [0.27429008 0.29494197 0.43076795], train_wt_loss:  37.8805, val_wt_loss: 36.6832, train_grp_loss: [11.49773245 13.69734828 13.00704208], val_grp_loss: [12.64808074 12.78222359 11.25126252], train_hist_grp_loss: [11.96399579 15.5936152  34.53316151], cur_train_grp_loss: [0.08844273 0.11510502 0.25504102], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6761, max_kl_dist_index: 0, max_train_grp_loss:  13.6973, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7822, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:30:39,676 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  135, train_loss:  12.6268, val_loss:  12.2278, grad_norm: 0.0059, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6761, 0.3236, 0.6752, param: [ 4.87249194  6.87169177  5.74931972 10.25328367], weights: [0.27385329 0.29462934 0.43151737], train_wt_loss:  37.8805, val_wt_loss: 36.6835, train_grp_loss: [11.4979069  13.69720292 13.00699131], val_grp_loss: [12.64828884 12.78219993 11.25136998], train_hist_grp_loss: [12.05243989 15.70871897 34.78820155], cur_train_grp_loss: [0.0884441  0.11510377 0.25504004], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6761, max_kl_dist_index: 0, max_train_grp_loss:  13.6972, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7822, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:30:40,695 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  136, train_loss:  12.6268, val_loss:  12.2279, grad_norm: 0.0060, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6761, 0.3236, 0.6752, param: [ 4.87217649  6.87097745  5.74983168 10.25378076], weights: [0.27341657 0.29431636 0.43226707], train_wt_loss:  37.8805, val_wt_loss: 36.6838, train_grp_loss: [11.49807818 13.69706158 13.00693957], val_grp_loss: [12.64849403 12.78218118 11.25147604], train_hist_grp_loss: [12.14088533 15.82382151 35.04324059], cur_train_grp_loss: [0.08844544 0.11510255 0.25503905], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6761, max_kl_dist_index: 0, max_train_grp_loss:  13.6971, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7822, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:30:41,715 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  137, train_loss:  12.6269, val_loss:  12.2280, grad_norm: 0.0060, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6761, 0.3236, 0.6752, param: [ 4.87185932  6.87026428  5.75034299 10.25428335], weights: [0.27297991 0.29400302 0.43301707], train_wt_loss:  37.8806, val_wt_loss: 36.6841, train_grp_loss: [11.49824627 13.69692426 13.00688686], val_grp_loss: [12.64869629 12.78216734 11.2515807 ], train_hist_grp_loss: [12.22933208 15.93892287 35.29827862], cur_train_grp_loss: [0.08844676 0.11510136 0.25503803], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6761, max_kl_dist_index: 0, max_train_grp_loss:  13.6969, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7822, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:30:42,732 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  138, train_loss:  12.6269, val_loss:  12.2281, grad_norm: 0.0061, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6762, 0.3236, 0.6752, param: [ 4.87154043  6.86955225  5.75085366 10.25479145], weights: [0.27254333 0.29368932 0.43376735], train_wt_loss:  37.8806, val_wt_loss: 36.6844, train_grp_loss: [11.49841118 13.69679096 13.00683318], val_grp_loss: [12.64889562 12.78215842 11.25168395], train_hist_grp_loss: [12.31778013 16.05402307 35.55331562], cur_train_grp_loss: [0.08844805 0.1151002  0.255037  ], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6762, max_kl_dist_index: 0, max_train_grp_loss:  13.6968, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7822, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:30:43,756 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  139, train_loss:  12.6269, val_loss:  12.2282, grad_norm: 0.0061, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6762, 0.3236, 0.6752, param: [ 4.8712198   6.86884136  5.75136369 10.25530507], weights: [0.27210682 0.29337527 0.43451791], train_wt_loss:  37.8806, val_wt_loss: 36.6847, train_grp_loss: [11.4985729  13.6966617  13.00677852], val_grp_loss: [12.64909203 12.78215443 11.25178581], train_hist_grp_loss: [12.40622945 16.16912216 35.80835157], cur_train_grp_loss: [0.08844932 0.11509908 0.25503594], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6762, max_kl_dist_index: 0, max_train_grp_loss:  13.6967, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7822, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:30:44,776 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  140, train_loss:  12.6269, val_loss:  12.2283, grad_norm: 0.0062, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6762, 0.3236, 0.6752, param: [ 4.87089745  6.86813161  5.75187307 10.25582421], weights: [0.27167039 0.29306087 0.43526875], train_wt_loss:  37.8807, val_wt_loss: 36.6850, train_grp_loss: [11.49873143 13.69653648 13.0067229 ], val_grp_loss: [12.6492855  12.78215537 11.25188626], train_hist_grp_loss: [12.49468001 16.28422016 36.06338644], cur_train_grp_loss: [0.08845056 0.115098   0.25503487], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6762, max_kl_dist_index: 0, max_train_grp_loss:  13.6965, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7822, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:30:45,812 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  141, train_loss:  12.6269, val_loss:  12.2284, grad_norm: 0.0062, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6762, 0.3236, 0.6752, param: [ 4.87057336  6.86742299  5.75238181 10.25634888], weights: [0.27123403 0.29274611 0.43601986], train_wt_loss:  37.8807, val_wt_loss: 36.6853, train_grp_loss: [11.49888676 13.69641529 13.00666629], val_grp_loss: [12.64947604 12.78216124 11.2519853 ], train_hist_grp_loss: [12.58313179 16.3993171  36.31842022], cur_train_grp_loss: [0.08845178 0.11509695 0.25503378], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6762, max_kl_dist_index: 0, max_train_grp_loss:  13.6964, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7822, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:30:46,823 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  142, train_loss:  12.6269, val_loss:  12.2285, grad_norm: 0.0063, live_grad: 0.0000, reward_err: 0.0103, 0.0186, 0.0011, KL_dist: 0.6762, 0.3237, 0.6752, param: [ 4.87024754  6.86671551  5.7528899  10.25687908], weights: [0.27079775 0.29243101 0.43677124], train_wt_loss:  37.8807, val_wt_loss: 36.6856, train_grp_loss: [11.4990389  13.69629816 13.00660871], val_grp_loss: [12.64966364 12.78217206 11.25208294], train_hist_grp_loss: [12.67158476 16.51441303 36.57345289], cur_train_grp_loss: [0.08845298 0.11509593 0.25503267], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6762, max_kl_dist_index: 0, max_train_grp_loss:  13.6963, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7822, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:30:47,849 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  143, train_loss:  12.6269, val_loss:  12.2286, grad_norm: 0.0063, live_grad: 0.0000, reward_err: 0.0103, 0.0186, 0.0011, KL_dist: 0.6762, 0.3237, 0.6752, param: [ 4.86991999  6.86600915  5.75339734 10.25741483], weights: [0.27036154 0.29211557 0.43752289], train_wt_loss:  37.8807, val_wt_loss: 36.6859, train_grp_loss: [11.49918783 13.69618507 13.00655014], val_grp_loss: [12.64984829 12.78218783 11.25217916], train_hist_grp_loss: [12.76003891 16.62950797 36.82848444], cur_train_grp_loss: [0.08845415 0.11509494 0.25503154], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6762, max_kl_dist_index: 0, max_train_grp_loss:  13.6962, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7822, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:30:48,881 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  144, train_loss:  12.6269, val_loss:  12.2287, grad_norm: 0.0064, live_grad: 0.0000, reward_err: 0.0103, 0.0186, 0.0011, KL_dist: 0.6762, 0.3237, 0.6753, param: [ 4.8695907   6.86530393  5.75390413 10.25795614], weights: [0.26992542 0.29179977 0.4382748 ], train_wt_loss:  37.8808, val_wt_loss: 36.6862, train_grp_loss: [11.49933356 13.69607604 13.0064906 ], val_grp_loss: [12.65003001 12.78220856 11.25227398], train_hist_grp_loss: [12.8484942  16.74460196 37.08351483], cur_train_grp_loss: [0.08845529 0.11509399 0.25503039], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6762, max_kl_dist_index: 0, max_train_grp_loss:  13.6961, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7822, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:30:49,890 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  145, train_loss:  12.6269, val_loss:  12.2288, grad_norm: 0.0064, live_grad: 0.0000, reward_err: 0.0103, 0.0186, 0.0011, KL_dist: 0.6762, 0.3237, 0.6753, param: [ 4.86925967  6.86459984  5.75441027 10.258503  ], weights: [0.26948938 0.29148364 0.43902698], train_wt_loss:  37.8808, val_wt_loss: 36.6865, train_grp_loss: [11.49947609 13.69597106 13.00643008], val_grp_loss: [12.65020877 12.78223425 11.25236739], train_hist_grp_loss: [12.93695061 16.85969504 37.33854406], cur_train_grp_loss: [0.08845641 0.11509308 0.25502923], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6762, max_kl_dist_index: 0, max_train_grp_loss:  13.6960, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7822, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:30:50,893 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  146, train_loss:  12.6269, val_loss:  12.2289, grad_norm: 0.0065, live_grad: 0.0000, reward_err: 0.0103, 0.0186, 0.0011, KL_dist: 0.6763, 0.3237, 0.6753, param: [ 4.8689269   6.86389688  5.75491576 10.25905543], weights: [0.26905343 0.29116717 0.43977941], train_wt_loss:  37.8808, val_wt_loss: 36.6868, train_grp_loss: [11.4996154  13.69587015 13.00636858], val_grp_loss: [12.65038458 12.7822649  11.25245939], train_hist_grp_loss: [13.02540812 16.97478723 37.5935721 ], cur_train_grp_loss: [0.08845751 0.11509219 0.25502804], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6763, max_kl_dist_index: 0, max_train_grp_loss:  13.6959, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7823, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:30:51,932 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  147, train_loss:  12.6270, val_loss:  12.2290, grad_norm: 0.0065, live_grad: 0.0000, reward_err: 0.0103, 0.0186, 0.0011, KL_dist: 0.6763, 0.3237, 0.6753, param: [ 4.86859238  6.86319504  5.7554206  10.25961344], weights: [0.26861756 0.29085035 0.44053209], train_wt_loss:  37.8809, val_wt_loss: 36.6871, train_grp_loss: [11.4997515  13.69577331 13.00630609], val_grp_loss: [12.65055743 12.78230053 11.25254997], train_hist_grp_loss: [13.1138667  17.08987858 37.84859894], cur_train_grp_loss: [0.08845858 0.11509135 0.25502683], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6763, max_kl_dist_index: 0, max_train_grp_loss:  13.6958, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7823, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:30:52,954 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  148, train_loss:  12.6270, val_loss:  12.2291, grad_norm: 0.0065, live_grad: 0.0000, reward_err: 0.0103, 0.0186, 0.0011, KL_dist: 0.6763, 0.3237, 0.6753, param: [ 4.86825613  6.86249432  5.75592477 10.26017703], weights: [0.26818177 0.2905332  0.44128502], train_wt_loss:  37.8809, val_wt_loss: 36.6874, train_grp_loss: [11.49988438 13.69568053 13.00624261], val_grp_loss: [12.65072733 12.78234114 11.25263914], train_hist_grp_loss: [13.20232633 17.20496911 38.10362455], cur_train_grp_loss: [0.08845963 0.11509053 0.25502561], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6763, max_kl_dist_index: 0, max_train_grp_loss:  13.6957, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7823, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:30:53,993 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  149, train_loss:  12.6270, val_loss:  12.2292, grad_norm: 0.0066, live_grad: 0.0000, reward_err: 0.0103, 0.0186, 0.0011, KL_dist: 0.6763, 0.3237, 0.6753, param: [ 4.86791812  6.86179472  5.7564283  10.26074621], weights: [0.26774608 0.29021572 0.4420382 ], train_wt_loss:  37.8809, val_wt_loss: 36.6877, train_grp_loss: [11.50001404 13.69559184 13.00617816], val_grp_loss: [12.65089427 12.78238673 11.25272689], train_hist_grp_loss: [13.29078698 17.32005886 38.35864891], cur_train_grp_loss: [0.08846065 0.11508975 0.25502436], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6763, max_kl_dist_index: 0, max_train_grp_loss:  13.6956, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7824, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:30:55,025 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  150, train_loss:  12.6270, val_loss:  12.2293, grad_norm: 0.0066, live_grad: 0.0000, reward_err: 0.0103, 0.0186, 0.0011, KL_dist: 0.6763, 0.3237, 0.6753, param: [ 4.86757836  6.86109624  5.75693116 10.26132098], weights: [0.26731048 0.2898979  0.44279162], train_wt_loss:  37.8810, val_wt_loss: 36.6880, train_grp_loss: [11.50014047 13.69550723 13.00611271], val_grp_loss: [12.65105824 12.78243732 11.25281323], train_hist_grp_loss: [13.37924862 17.43514787 38.61367201], cur_train_grp_loss: [0.08846165 0.11508901 0.2550231 ], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6763, max_kl_dist_index: 0, max_train_grp_loss:  13.6955, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7824, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:30:56,050 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  151, train_loss:  12.6270, val_loss:  12.2294, grad_norm: 0.0067, live_grad: 0.0000, reward_err: 0.0103, 0.0186, 0.0011, KL_dist: 0.6763, 0.3237, 0.6753, param: [ 4.86723686  6.86039887  5.75743336 10.26190136], weights: [0.26687496 0.28957975 0.44354528], train_wt_loss:  37.8810, val_wt_loss: 36.6883, train_grp_loss: [11.50026368 13.6954267  13.00604628], val_grp_loss: [12.65121924 12.7824929  11.25289814], train_hist_grp_loss: [13.46771124 17.55023617 38.86869383], cur_train_grp_loss: [0.08846262 0.1150883  0.25502182], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6763, max_kl_dist_index: 0, max_train_grp_loss:  13.6954, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7825, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:30:57,065 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  152, train_loss:  12.6270, val_loss:  12.2295, grad_norm: 0.0067, live_grad: 0.0000, reward_err: 0.0103, 0.0186, 0.0011, KL_dist: 0.6763, 0.3238, 0.6753, param: [ 4.8668936   6.85970262  5.75793491 10.26248736], weights: [0.26643955 0.28926128 0.44429918], train_wt_loss:  37.8810, val_wt_loss: 36.6886, train_grp_loss: [11.50038366 13.69535026 13.00597885], val_grp_loss: [12.65137727 12.78255349 11.25298164], train_hist_grp_loss: [13.55617481 17.66532378 39.12371434], cur_train_grp_loss: [0.08846357 0.11508762 0.25502052], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6763, max_kl_dist_index: 0, max_train_grp_loss:  13.6954, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7826, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:30:58,110 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  153, train_loss:  12.6270, val_loss:  12.2296, grad_norm: 0.0068, live_grad: 0.0000, reward_err: 0.0103, 0.0186, 0.0011, KL_dist: 0.6764, 0.3238, 0.6754, param: [ 4.86654859  6.85900748  5.75843579 10.26307897], weights: [0.26600422 0.28894247 0.44505331], train_wt_loss:  37.8810, val_wt_loss: 36.6889, train_grp_loss: [11.5005004  13.69527792 13.00591044], val_grp_loss: [12.65153233 12.78261909 11.25306372], train_hist_grp_loss: [13.6446393  17.78041076 39.37873354], cur_train_grp_loss: [0.08846449 0.11508698 0.25501919], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6764, max_kl_dist_index: 0, max_train_grp_loss:  13.6953, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7826, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:30:59,181 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  154, train_loss:  12.6270, val_loss:  12.2297, grad_norm: 0.0068, live_grad: 0.0000, reward_err: 0.0103, 0.0186, 0.0011, KL_dist: 0.6764, 0.3238, 0.6754, param: [ 4.86620182  6.85831345  5.75893601 10.26367622], weights: [0.265569   0.28862334 0.44580766], train_wt_loss:  37.8811, val_wt_loss: 36.6892, train_grp_loss: [11.50061391 13.69520967 13.00584103], val_grp_loss: [12.65168441 12.7826897  11.25314437], train_hist_grp_loss: [13.73310469 17.89549713 39.63375139], cur_train_grp_loss: [0.08846539 0.11508637 0.25501785], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6764, max_kl_dist_index: 0, max_train_grp_loss:  13.6952, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7827, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:31:00,204 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  155, train_loss:  12.6270, val_loss:  12.2298, grad_norm: 0.0069, live_grad: 0.0000, reward_err: 0.0103, 0.0186, 0.0011, KL_dist: 0.6764, 0.3238, 0.6754, param: [ 4.86585329  6.85762053  5.75943556 10.26427909], weights: [0.26513387 0.28830389 0.44656224], train_wt_loss:  37.8811, val_wt_loss: 36.6895, train_grp_loss: [11.50072417 13.69514553 13.00577064], val_grp_loss: [12.65183351 12.78276534 11.2532236 ], train_hist_grp_loss: [13.82157095 18.01058293 39.88876788], cur_train_grp_loss: [0.08846626 0.1150858  0.25501649], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6764, max_kl_dist_index: 0, max_train_grp_loss:  13.6951, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7828, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:31:01,230 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  156, train_loss:  12.6270, val_loss:  12.2299, grad_norm: 0.0069, live_grad: 0.0000, reward_err: 0.0103, 0.0186, 0.0011, KL_dist: 0.6764, 0.3238, 0.6754, param: [ 4.865503    6.85692871  5.75993444 10.26488761], weights: [0.26469884 0.28798412 0.44731705], train_wt_loss:  37.8811, val_wt_loss: 36.6898, train_grp_loss: [11.50083119 13.6950855  13.00569924], val_grp_loss: [12.65197963 12.78284601 11.25330141], train_hist_grp_loss: [13.91003806 18.12566818 40.14378299], cur_train_grp_loss: [0.08846711 0.11508526 0.25501511], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6764, max_kl_dist_index: 0, max_train_grp_loss:  13.6951, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7828, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:31:02,255 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  157, train_loss:  12.6271, val_loss:  12.2300, grad_norm: 0.0070, live_grad: 0.0000, reward_err: 0.0103, 0.0186, 0.0011, KL_dist: 0.6764, 0.3238, 0.6754, param: [ 4.86515095  6.856238    5.76043266 10.26550178], weights: [0.26426391 0.28766402 0.44807207], train_wt_loss:  37.8812, val_wt_loss: 36.6901, train_grp_loss: [11.50093497 13.69502958 13.00562686], val_grp_loss: [12.65212276 12.78293171 11.2533778 ], train_hist_grp_loss: [13.99850599 18.24075294 40.3987967 ], cur_train_grp_loss: [0.08846793 0.11508475 0.25501371], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6764, max_kl_dist_index: 0, max_train_grp_loss:  13.6950, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7829, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:31:03,269 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  158, train_loss:  12.6271, val_loss:  12.2301, grad_norm: 0.0070, live_grad: 0.0000, reward_err: 0.0103, 0.0186, 0.0011, KL_dist: 0.6764, 0.3238, 0.6754, param: [ 4.86479713  6.85554839  5.76093021 10.26612161], weights: [0.26382909 0.28734361 0.4488273 ], train_wt_loss:  37.8812, val_wt_loss: 36.6904, train_grp_loss: [11.5010355  13.69497778 13.00555347], val_grp_loss: [12.6522629  12.78302245 11.25345275], train_hist_grp_loss: [14.08697472 18.35583722 40.65380899], cur_train_grp_loss: [0.08846873 0.11508428 0.25501229], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6764, max_kl_dist_index: 0, max_train_grp_loss:  13.6950, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7830, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:31:04,290 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  159, train_loss:  12.6271, val_loss:  12.2302, grad_norm: 0.0071, live_grad: 0.0000, reward_err: 0.0103, 0.0186, 0.0011, KL_dist: 0.6765, 0.3238, 0.6754, param: [ 4.86444155  6.85485987  5.76142708 10.2667471 ], weights: [0.26339437 0.28702288 0.44958275], train_wt_loss:  37.8812, val_wt_loss: 36.6907, train_grp_loss: [11.50113277 13.6949301  13.00547909], val_grp_loss: [12.65240005 12.78311823 11.25352628], train_hist_grp_loss: [14.17544422 18.47092106 40.90881985], cur_train_grp_loss: [0.0884695  0.11508385 0.25501085], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6765, max_kl_dist_index: 0, max_train_grp_loss:  13.6949, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7831, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:31:05,319 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  160, train_loss:  12.6271, val_loss:  12.2303, grad_norm: 0.0071, live_grad: 0.0000, reward_err: 0.0103, 0.0186, 0.0011, KL_dist: 0.6765, 0.3239, 0.6754, param: [ 4.8640842   6.85417246  5.76192329 10.26737826], weights: [0.26295976 0.28670184 0.4503384 ], train_wt_loss:  37.8813, val_wt_loss: 36.6910, train_grp_loss: [11.50122679 13.69488654 13.00540371], val_grp_loss: [12.6525342  12.78321907 11.25359838], train_hist_grp_loss: [14.26391447 18.58600451 41.16382924], cur_train_grp_loss: [0.08847025 0.11508345 0.25500939], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6765, max_kl_dist_index: 0, max_train_grp_loss:  13.6949, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7832, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:31:06,353 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  161, train_loss:  12.6271, val_loss:  12.2304, grad_norm: 0.0072, live_grad: 0.0000, reward_err: 0.0103, 0.0186, 0.0011, KL_dist: 0.6765, 0.3239, 0.6755, param: [ 4.86372508  6.85348613  5.76241882 10.2680151 ], weights: [0.26252525 0.28638049 0.45109426], train_wt_loss:  37.8813, val_wt_loss: 36.6913, train_grp_loss: [11.50131755 13.69484712 13.00532733], val_grp_loss: [12.65266535 12.78332497 11.25366906], train_hist_grp_loss: [14.35238545 18.70108759 41.41883716], cur_train_grp_loss: [0.08847098 0.11508308 0.25500792], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6765, max_kl_dist_index: 0, max_train_grp_loss:  13.6948, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7833, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:31:07,380 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  162, train_loss:  12.6271, val_loss:  12.2305, grad_norm: 0.0072, live_grad: 0.0000, reward_err: 0.0103, 0.0186, 0.0011, KL_dist: 0.6765, 0.3239, 0.6755, param: [ 4.86336418  6.8528009   5.76291368 10.26865763], weights: [0.26209086 0.28605883 0.45185031], train_wt_loss:  37.8813, val_wt_loss: 36.6916, train_grp_loss: [11.50140505 13.69481183 13.00524995], val_grp_loss: [12.65279351 12.78343594 11.2537383 ], train_hist_grp_loss: [14.44085712 18.81617034 41.67384357], cur_train_grp_loss: [0.08847167 0.11508275 0.25500642], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6765, max_kl_dist_index: 0, max_train_grp_loss:  13.6948, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7834, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:31:08,428 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  163, train_loss:  12.6271, val_loss:  12.2306, grad_norm: 0.0073, live_grad: 0.0000, reward_err: 0.0103, 0.0186, 0.0011, KL_dist: 0.6765, 0.3239, 0.6755, param: [ 4.86300152  6.85211676  5.76340786 10.26930585], weights: [0.26165657 0.28573686 0.45260656], train_wt_loss:  37.8814, val_wt_loss: 36.6919, train_grp_loss: [11.50148928 13.69478068 13.00517157], val_grp_loss: [12.65291865 12.78355197 11.25380611], train_hist_grp_loss: [14.52932947 18.93125279 41.92884847], cur_train_grp_loss: [0.08847235 0.11508245 0.2550049 ], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6765, max_kl_dist_index: 0, max_train_grp_loss:  13.6948, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7836, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:31:09,512 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  164, train_loss:  12.6271, val_loss:  12.2307, grad_norm: 0.0073, live_grad: 0.0000, reward_err: 0.0103, 0.0186, 0.0011, KL_dist: 0.6765, 0.3239, 0.6755, param: [ 4.86263707  6.8514337   5.76390136 10.26995978], weights: [0.2612224  0.28541459 0.45336301], train_wt_loss:  37.8814, val_wt_loss: 36.6922, train_grp_loss: [11.50157024 13.69475367 13.00509218], val_grp_loss: [12.65304079 12.78367309 11.25387248], train_hist_grp_loss: [14.61780246 19.04633498 42.18385184], cur_train_grp_loss: [0.08847299 0.11508219 0.25500336], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6765, max_kl_dist_index: 0, max_train_grp_loss:  13.6948, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7837, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:31:10,557 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  165, train_loss:  12.6271, val_loss:  12.2309, grad_norm: 0.0074, live_grad: 0.0000, reward_err: 0.0103, 0.0186, 0.0011, KL_dist: 0.6766, 0.3239, 0.6755, param: [ 4.86227085  6.85075173  5.76439418 10.27061941], weights: [0.26078835 0.28509201 0.45411964], train_wt_loss:  37.8814, val_wt_loss: 36.6926, train_grp_loss: [11.50164793 13.69473081 13.00501179], val_grp_loss: [12.65315992 12.78379928 11.25393743], train_hist_grp_loss: [14.70627608 19.16141695 42.43885365], cur_train_grp_loss: [0.08847362 0.11508196 0.25500181], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6766, max_kl_dist_index: 0, max_train_grp_loss:  13.6947, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7838, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:31:11,620 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  166, train_loss:  12.6272, val_loss:  12.2310, grad_norm: 0.0074, live_grad: 0.0000, reward_err: 0.0103, 0.0186, 0.0011, KL_dist: 0.6766, 0.3239, 0.6755, param: [ 4.86190285  6.85007085  5.76488632 10.27128476], weights: [0.26035441 0.28476913 0.45487647], train_wt_loss:  37.8815, val_wt_loss: 36.6929, train_grp_loss: [11.50172235 13.69471211 13.0049304 ], val_grp_loss: [12.65327603 12.78393057 11.25400093], train_hist_grp_loss: [14.7947503  19.27649872 42.69385388], cur_train_grp_loss: [0.08847421 0.11508177 0.25500023], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6766, max_kl_dist_index: 0, max_train_grp_loss:  13.6947, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7839, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:31:12,696 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  167, train_loss:  12.6272, val_loss:  12.2311, grad_norm: 0.0075, live_grad: 0.0000, reward_err: 0.0103, 0.0186, 0.0011, KL_dist: 0.6766, 0.3239, 0.6756, param: [ 4.86153307  6.84939104  5.76537778 10.27195583], weights: [0.25992058 0.28444595 0.45563347], train_wt_loss:  37.8815, val_wt_loss: 36.6932, train_grp_loss: [11.50179349 13.69469756 13.004848  ], val_grp_loss: [12.65338913 12.78406695 11.25406301], train_hist_grp_loss: [14.88322508 19.39158033 42.94885251], cur_train_grp_loss: [0.08847479 0.11508161 0.25499864], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6766, max_kl_dist_index: 0, max_train_grp_loss:  13.6947, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7841, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:31:13,762 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  168, train_loss:  12.6272, val_loss:  12.2312, grad_norm: 0.0075, live_grad: 0.0000, reward_err: 0.0103, 0.0186, 0.0011, KL_dist: 0.6766, 0.3240, 0.6756, param: [ 4.8611615   6.84871231  5.76586855 10.27263264], weights: [0.25948688 0.28412247 0.45639065], train_wt_loss:  37.8815, val_wt_loss: 36.6935, train_grp_loss: [11.50186136 13.69468718 13.00476459], val_grp_loss: [12.6534992  12.78420844 11.25412364], train_hist_grp_loss: [14.97170042 19.50666182 43.20384953], cur_train_grp_loss: [0.08847533 0.11508149 0.25499702], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6766, max_kl_dist_index: 0, max_train_grp_loss:  13.6947, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7842, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:31:14,830 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  169, train_loss:  12.6272, val_loss:  12.2313, grad_norm: 0.0076, live_grad: 0.0000, reward_err: 0.0105, 0.0186, 0.0012, KL_dist: 0.6766, 0.3240, 0.6756, param: [ 4.86078815  6.84803466  5.76635864 10.27331518], weights: [0.2590533  0.2837987  0.45714801], train_wt_loss:  37.8816, val_wt_loss: 36.6938, train_grp_loss: [11.50192593 13.69468096 13.00468017], val_grp_loss: [12.65360626 12.78435503 11.25418284], train_hist_grp_loss: [15.06017627 19.62174323 43.45884492], cur_train_grp_loss: [0.08847586 0.1150814  0.25499538], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6766, max_kl_dist_index: 0, max_train_grp_loss:  13.6947, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7844, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:31:15,891 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  170, train_loss:  12.6272, val_loss:  12.2314, grad_norm: 0.0076, live_grad: 0.0000, reward_err: 0.0105, 0.0186, 0.0012, KL_dist: 0.6767, 0.3240, 0.6756, param: [ 4.86041301  6.84735807  5.76684804 10.27400347], weights: [0.25861984 0.28347463 0.45790553], train_wt_loss:  37.8816, val_wt_loss: 36.6941, train_grp_loss: [11.50198722 13.69467892 13.00459475], val_grp_loss: [12.65371028 12.78450674 11.2542406 ], train_hist_grp_loss: [15.14865263 19.73682458 43.71383865], cur_train_grp_loss: [0.08847635 0.11508135 0.25499373], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6767, max_kl_dist_index: 0, max_train_grp_loss:  13.6947, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7845, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:31:16,909 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  171, train_loss:  12.6272, val_loss:  12.2315, grad_norm: 0.0077, live_grad: 0.0000, reward_err: 0.0107, 0.0186, 0.0013, KL_dist: 0.6767, 0.3240, 0.6756, param: [ 4.86003608  6.84668256  5.76733676 10.27469751], weights: [0.2581865  0.28315027 0.45866323], train_wt_loss:  37.8816, val_wt_loss: 36.6944, train_grp_loss: [11.50204523 13.69468105 13.00450831], val_grp_loss: [12.65381128 12.78466356 11.25429692], train_hist_grp_loss: [15.23712945 19.85190592 43.9688307 ], cur_train_grp_loss: [0.08847682 0.11508134 0.25499205], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6767, max_kl_dist_index: 0, max_train_grp_loss:  13.6947, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7847, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:31:17,929 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  172, train_loss:  12.6272, val_loss:  12.2316, grad_norm: 0.0077, live_grad: 0.0000, reward_err: 0.0107, 0.0186, 0.0013, KL_dist: 0.6767, 0.3240, 0.6757, param: [ 4.85965735  6.84600812  5.76782478 10.27539731], weights: [0.25775329 0.28282562 0.45942109], train_wt_loss:  37.8817, val_wt_loss: 36.6947, train_grp_loss: [11.50209994 13.69468736 13.00442086], val_grp_loss: [12.65390925 12.78482552 11.2543518 ], train_hist_grp_loss: [15.32560672 19.96698727 44.22382106], cur_train_grp_loss: [0.08847727 0.11508135 0.25499036], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6767, max_kl_dist_index: 0, max_train_grp_loss:  13.6947, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7848, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:31:18,988 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  173, train_loss:  12.6272, val_loss:  12.2317, grad_norm: 0.0078, live_grad: 0.0000, reward_err: 0.0107, 0.0186, 0.0013, KL_dist: 0.6767, 0.3240, 0.6757, param: [ 4.85927684  6.84533475  5.76831211 10.27610288], weights: [0.25732021 0.28250068 0.46017911], train_wt_loss:  37.8817, val_wt_loss: 36.6951, train_grp_loss: [11.50215135 13.69469786 13.0043324 ], val_grp_loss: [12.65400418 12.78499261 11.25440524], train_hist_grp_loss: [15.41408442 20.08206868 44.4788097 ], cur_train_grp_loss: [0.08847769 0.11508141 0.25498864], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6767, max_kl_dist_index: 0, max_train_grp_loss:  13.6947, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7850, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:31:20,016 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  174, train_loss:  12.6272, val_loss:  12.2318, grad_norm: 0.0078, live_grad: 0.0000, reward_err: 0.0107, 0.0186, 0.0013, KL_dist: 0.6767, 0.3240, 0.6757, param: [ 4.85889453  6.84466243  5.76879875 10.27681423], weights: [0.25688726 0.28217546 0.46093728], train_wt_loss:  37.8817, val_wt_loss: 36.6954, train_grp_loss: [11.50219947 13.69471254 13.00424292], val_grp_loss: [12.65409608 12.78516483 11.25445724], train_hist_grp_loss: [15.5025625  20.19715017 44.73379661], cur_train_grp_loss: [0.08847809 0.11508149 0.25498691], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6767, max_kl_dist_index: 0, max_train_grp_loss:  13.6947, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7852, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:31:21,022 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  175, train_loss:  12.6273, val_loss:  12.2319, grad_norm: 0.0079, live_grad: 0.0000, reward_err: 0.0107, 0.0186, 0.0013, KL_dist: 0.6768, 0.3241, 0.6757, param: [ 4.85851042  6.84399118  5.7692847  10.27753135], weights: [0.25645444 0.28184995 0.46169561], train_wt_loss:  37.8818, val_wt_loss: 36.6957, train_grp_loss: [11.50224429 13.69473142 13.00415243], val_grp_loss: [12.65418493 12.7853422  11.25450779], train_hist_grp_loss: [15.59104096 20.31223179 44.98878177], cur_train_grp_loss: [0.08847846 0.11508162 0.25498516], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6768, max_kl_dist_index: 0, max_train_grp_loss:  13.6947, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7853, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:31:22,023 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  176, train_loss:  12.6273, val_loss:  12.2320, grad_norm: 0.0079, live_grad: 0.0000, reward_err: 0.0107, 0.0186, 0.0013, KL_dist: 0.6768, 0.3241, 0.6757, param: [ 4.85812451  6.84332099  5.76976995 10.27825427], weights: [0.25602175 0.28152416 0.46245409], train_wt_loss:  37.8818, val_wt_loss: 36.6960, train_grp_loss: [11.5022858  13.6947545  13.00406092], val_grp_loss: [12.65427074 12.78552473 11.2545569 ], train_hist_grp_loss: [15.67951976 20.42731357 45.24376515], cur_train_grp_loss: [0.0884788  0.11508178 0.25498338], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6768, max_kl_dist_index: 0, max_train_grp_loss:  13.6948, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7855, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:31:23,038 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  177, train_loss:  12.6273, val_loss:  12.2321, grad_norm: 0.0080, live_grad: 0.0000, reward_err: 0.0105, 0.0186, 0.0013, KL_dist: 0.6768, 0.3241, 0.6758, param: [ 4.8577368   6.84265185  5.7702545  10.27898298], weights: [0.25558919 0.28119809 0.46321272], train_wt_loss:  37.8818, val_wt_loss: 36.6963, train_grp_loss: [11.50232401 13.69478178 13.0039684 ], val_grp_loss: [12.65435351 12.78571241 11.25460457], train_hist_grp_loss: [15.76799888 20.54239554 45.49874673], cur_train_grp_loss: [0.08847912 0.11508197 0.25498159], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6768, max_kl_dist_index: 0, max_train_grp_loss:  13.6948, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7857, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:31:24,053 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  178, train_loss:  12.6273, val_loss:  12.2322, grad_norm: 0.0080, live_grad: 0.0000, reward_err: 0.0105, 0.0186, 0.0013, KL_dist: 0.6768, 0.3241, 0.6758, param: [ 4.85734729  6.84198376  5.77073835 10.2797175 ], weights: [0.25515677 0.28087174 0.46397149], train_wt_loss:  37.8819, val_wt_loss: 36.6967, train_grp_loss: [11.5023589  13.69481327 13.00387486], val_grp_loss: [12.65443322 12.78590525 11.25465079], train_hist_grp_loss: [15.8564783  20.65747774 45.75372651], cur_train_grp_loss: [0.08847942 0.1150822  0.25497977], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6768, max_kl_dist_index: 0, max_train_grp_loss:  13.6948, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7859, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:31:25,083 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  179, train_loss:  12.6273, val_loss:  12.2323, grad_norm: 0.0081, live_grad: 0.0000, reward_err: 0.0105, 0.0186, 0.0013, KL_dist: 0.6768, 0.3241, 0.6758, param: [ 4.85695598  6.84131673  5.77122151 10.28045782], weights: [0.25472449 0.28054512 0.4647304 ], train_wt_loss:  37.8819, val_wt_loss: 36.6970, train_grp_loss: [11.50239049 13.69484897 13.0037803 ], val_grp_loss: [12.65450989 12.78610327 11.25469556], train_hist_grp_loss: [15.94495798 20.7725602  46.00870445], cur_train_grp_loss: [0.08847968 0.11508246 0.25497794], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6768, max_kl_dist_index: 0, max_train_grp_loss:  13.6948, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7861, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:31:26,090 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  180, train_loss:  12.6273, val_loss:  12.2324, grad_norm: 0.0081, live_grad: 0.0000, reward_err: 0.0105, 0.0186, 0.0013, KL_dist: 0.6769, 0.3241, 0.6758, param: [ 4.85656285  6.84065074  5.77170396 10.28120397], weights: [0.25429234 0.28021822 0.46548944], train_wt_loss:  37.8819, val_wt_loss: 36.6973, train_grp_loss: [11.50241876 13.69488889 13.00368471], val_grp_loss: [12.6545835  12.78630646 11.25473889], train_hist_grp_loss: [16.03343791 20.88764297 46.26368053], cur_train_grp_loss: [0.08847993 0.11508276 0.25497608], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6769, max_kl_dist_index: 0, max_train_grp_loss:  13.6949, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7863, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:31:27,102 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  181, train_loss:  12.6273, val_loss:  12.2325, grad_norm: 0.0082, live_grad: 0.0000, reward_err: 0.0105, 0.0186, 0.0013, KL_dist: 0.6769, 0.3242, 0.6758, param: [ 4.85616792  6.8399858   5.7721857  10.28195594], weights: [0.25386034 0.27989105 0.46624861], train_wt_loss:  37.8820, val_wt_loss: 36.6976, train_grp_loss: [11.50244371 13.69493303 13.00358811], val_grp_loss: [12.65465405 12.78651483 11.25478076], train_hist_grp_loss: [16.12191805 21.00272607 46.51865474], cur_train_grp_loss: [0.08848014 0.1150831  0.25497421], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6769, max_kl_dist_index: 0, max_train_grp_loss:  13.6949, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7865, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:31:28,117 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  182, train_loss:  12.6273, val_loss:  12.2326, grad_norm: 0.0082, live_grad: 0.0000, reward_err: 0.0105, 0.0186, 0.0013, KL_dist: 0.6769, 0.3242, 0.6759, param: [ 4.85577117  6.8393219   5.77266675 10.28271375], weights: [0.25342847 0.27956361 0.46700791], train_wt_loss:  37.8820, val_wt_loss: 36.6979, train_grp_loss: [11.50246534 13.6949814  13.00349049], val_grp_loss: [12.65472154 12.78672839 11.25482119], train_hist_grp_loss: [16.21039839 21.11780954 46.77362706], cur_train_grp_loss: [0.08848034 0.11508347 0.25497232], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6769, max_kl_dist_index: 0, max_train_grp_loss:  13.6950, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7867, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:31:29,134 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  183, train_loss:  12.6273, val_loss:  12.2328, grad_norm: 0.0083, live_grad: 0.0000, reward_err: 0.0105, 0.0186, 0.0013, KL_dist: 0.6769, 0.3242, 0.6759, param: [ 4.85537262  6.83865904  5.77314708 10.28347739], weights: [0.25299676 0.2792359  0.46776734], train_wt_loss:  37.8820, val_wt_loss: 36.6983, train_grp_loss: [11.50248365 13.695034   13.00339184], val_grp_loss: [12.65478597 12.78694715 11.25486017], train_hist_grp_loss: [16.29887889 21.23289341 47.02859746], cur_train_grp_loss: [0.0884805  0.11508388 0.2549704 ], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6769, max_kl_dist_index: 0, max_train_grp_loss:  13.6950, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7869, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:31:30,149 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  184, train_loss:  12.6274, val_loss:  12.2329, grad_norm: 0.0083, live_grad: 0.0000, reward_err: 0.0105, 0.0186, 0.0013, KL_dist: 0.6770, 0.3242, 0.6759, param: [ 4.85497225  6.83799722  5.77362671 10.28424688], weights: [0.25256518 0.27890793 0.46852689], train_wt_loss:  37.8821, val_wt_loss: 36.6986, train_grp_loss: [11.50249863 13.69509083 13.00329217], val_grp_loss: [12.65484734 12.78717111 11.2548977 ], train_hist_grp_loss: [16.38735954 21.34797773 47.28356593], cur_train_grp_loss: [0.08848064 0.11508432 0.25496847], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6770, max_kl_dist_index: 0, max_train_grp_loss:  13.6951, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7872, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:31:31,145 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  185, train_loss:  12.6274, val_loss:  12.2330, grad_norm: 0.0084, live_grad: 0.0000, reward_err: 0.0105, 0.0186, 0.0013, KL_dist: 0.6770, 0.3242, 0.6759, param: [ 4.85457006  6.83733643  5.77410563 10.28502223], weights: [0.25213376 0.27857969 0.46928655], train_wt_loss:  37.8821, val_wt_loss: 36.6989, train_grp_loss: [11.50251028 13.6951519  13.00319147], val_grp_loss: [12.65490563 12.78740027 11.25493378], train_hist_grp_loss: [16.4758403  21.46306253 47.53853244], cur_train_grp_loss: [0.08848076 0.1150848  0.25496651], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6770, max_kl_dist_index: 0, max_train_grp_loss:  13.6952, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7874, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:31:32,149 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  186, train_loss:  12.6274, val_loss:  12.2331, grad_norm: 0.0084, live_grad: 0.0000, reward_err: 0.0105, 0.0186, 0.0013, KL_dist: 0.6770, 0.3242, 0.6760, param: [ 4.85416605  6.83667668  5.77458383 10.28580343], weights: [0.25170248 0.27825119 0.47004633], train_wt_loss:  37.8822, val_wt_loss: 36.6992, train_grp_loss: [11.5025186  13.69521722 13.00308975], val_grp_loss: [12.65496086 12.78763465 11.2549684 ], train_hist_grp_loss: [16.56432114 21.57814784 47.79349698], cur_train_grp_loss: [0.08848085 0.11508531 0.25496454], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6770, max_kl_dist_index: 0, max_train_grp_loss:  13.6952, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7876, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:31:33,151 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  187, train_loss:  12.6274, val_loss:  12.2332, grad_norm: 0.0085, live_grad: 0.0000, reward_err: 0.0105, 0.0186, 0.0013, KL_dist: 0.6770, 0.3243, 0.6760, param: [ 4.85376022  6.83601795  5.77506133 10.28659051], weights: [0.25127135 0.27792243 0.47080622], train_wt_loss:  37.8822, val_wt_loss: 36.6996, train_grp_loss: [11.50252359 13.69528679 13.002987  ], val_grp_loss: [12.65501301 12.78787425 11.25500158], train_hist_grp_loss: [16.65280206 21.6932337  48.04845952], cur_train_grp_loss: [0.08848091 0.11508586 0.25496254], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6770, max_kl_dist_index: 0, max_train_grp_loss:  13.6953, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7879, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:31:34,158 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  188, train_loss:  12.6274, val_loss:  12.2333, grad_norm: 0.0085, live_grad: 0.0000, reward_err: 0.0105, 0.0186, 0.0013, KL_dist: 0.6770, 0.3243, 0.6760, param: [ 4.85335257  6.83536025  5.77553811 10.28738346], weights: [0.25084037 0.27759342 0.47156621], train_wt_loss:  37.8822, val_wt_loss: 36.6999, train_grp_loss: [11.50252524 13.69536061 13.00288322], val_grp_loss: [12.65506208 12.78811908 11.2550333 ], train_hist_grp_loss: [16.74128301 21.80832014 48.30342005], cur_train_grp_loss: [0.08848095 0.11508644 0.25496053], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6770, max_kl_dist_index: 0, max_train_grp_loss:  13.6954, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7881, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:31:35,175 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  189, train_loss:  12.6274, val_loss:  12.2334, grad_norm: 0.0086, live_grad: 0.0000, reward_err: 0.0105, 0.0186, 0.0013, KL_dist: 0.6771, 0.3243, 0.6760, param: [ 4.8529431   6.83470358  5.77601417 10.2881823 ], weights: [0.25040955 0.27726414 0.4723263 ], train_wt_loss:  37.8823, val_wt_loss: 36.7002, train_grp_loss: [11.50252355 13.69543869 13.00277842], val_grp_loss: [12.65510808 12.78836913 11.25506356], train_hist_grp_loss: [16.82976397 21.92340721 48.55837855], cur_train_grp_loss: [0.08848096 0.11508706 0.25495849], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6771, max_kl_dist_index: 0, max_train_grp_loss:  13.6954, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7884, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:31:36,280 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  190, train_loss:  12.6274, val_loss:  12.2335, grad_norm: 0.0086, live_grad: 0.0000, reward_err: 0.0105, 0.0186, 0.0013, KL_dist: 0.6771, 0.3243, 0.6761, param: [ 4.8525318   6.83404793  5.77648952 10.28898702], weights: [0.24997888 0.27693462 0.4730865 ], train_wt_loss:  37.8823, val_wt_loss: 36.7005, train_grp_loss: [11.50251851 13.69552103 13.00267258], val_grp_loss: [12.65515099 12.78862443 11.25509238], train_hist_grp_loss: [16.91824492 22.03849493 48.81333498], cur_train_grp_loss: [0.08848095 0.11508772 0.25495644], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6771, max_kl_dist_index: 0, max_train_grp_loss:  13.6955, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7886, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:31:37,271 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  191, train_loss:  12.6274, val_loss:  12.2336, grad_norm: 0.0087, live_grad: 0.0000, reward_err: 0.0105, 0.0186, 0.0013, KL_dist: 0.6771, 0.3243, 0.6761, param: [ 4.85211867  6.83339329  5.77696415 10.28979764], weights: [0.24954837 0.27660484 0.47384679], train_wt_loss:  37.8823, val_wt_loss: 36.7009, train_grp_loss: [11.50251013 13.69560764 13.00256571], val_grp_loss: [12.65519082 12.78888497 11.25511973], train_hist_grp_loss: [17.00672583 22.15358334 49.06828935], cur_train_grp_loss: [0.08848091 0.11508841 0.25495436], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6771, max_kl_dist_index: 0, max_train_grp_loss:  13.6956, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7889, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:31:38,282 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  192, train_loss:  12.6275, val_loss:  12.2337, grad_norm: 0.0087, live_grad: 0.0000, reward_err: 0.0105, 0.0186, 0.0013, KL_dist: 0.6771, 0.3243, 0.6761, param: [ 4.85170371  6.83273967  5.77743805 10.29061417], weights: [0.24911802 0.27627481 0.47460717], train_wt_loss:  37.8824, val_wt_loss: 36.7012, train_grp_loss: [11.50249841 13.69569852 13.00245781], val_grp_loss: [12.65522756 12.78915076 11.25514563], train_hist_grp_loss: [17.09520668 22.26867248 49.32324162], cur_train_grp_loss: [0.08848085 0.11508914 0.25495227], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6771, max_kl_dist_index: 0, max_train_grp_loss:  13.6957, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7892, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:31:39,320 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  193, train_loss:  12.6275, val_loss:  12.2338, grad_norm: 0.0088, live_grad: 0.0000, reward_err: 0.0105, 0.0186, 0.0013, KL_dist: 0.6772, 0.3244, 0.6761, param: [ 4.85128692  6.83208707  5.77791124 10.29143661], weights: [0.24868782 0.27594454 0.47536764], train_wt_loss:  37.8824, val_wt_loss: 36.7015, train_grp_loss: [11.50248333 13.69579368 13.00234888], val_grp_loss: [12.65526121 12.78942181 11.25517008], train_hist_grp_loss: [17.18368744 22.38376238 49.57819177], cur_train_grp_loss: [0.08848076 0.1150899  0.25495015], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6772, max_kl_dist_index: 0, max_train_grp_loss:  13.6958, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7894, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:31:40,327 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  194, train_loss:  12.6275, val_loss:  12.2340, grad_norm: 0.0088, live_grad: 0.0000, reward_err: 0.0105, 0.0186, 0.0013, KL_dist: 0.6772, 0.3244, 0.6762, param: [ 4.8508683   6.83143547  5.7783837  10.29226497], weights: [0.24825779 0.27561402 0.47612819], train_wt_loss:  37.8825, val_wt_loss: 36.7019, train_grp_loss: [11.5024649  13.69589312 13.00223891], val_grp_loss: [12.65529177 12.78969812 11.25519307], train_hist_grp_loss: [17.27216808 22.49885308 49.83313979], cur_train_grp_loss: [0.08848064 0.1150907  0.25494802], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6772, max_kl_dist_index: 0, max_train_grp_loss:  13.6959, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7897, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2549, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:31:41,328 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  195, train_loss:  12.6275, val_loss:  12.2341, grad_norm: 0.0089, live_grad: 0.0000, reward_err: 0.0105, 0.0186, 0.0013, KL_dist: 0.6772, 0.3244, 0.6762, param: [ 4.85044784  6.83078488  5.77885543 10.29309925], weights: [0.24782792 0.27528325 0.47688882], train_wt_loss:  37.8825, val_wt_loss: 36.7022, train_grp_loss: [11.50244312 13.69599684 13.00212791], val_grp_loss: [12.65531924 12.78997971 11.2552146 ], train_hist_grp_loss: [17.36064858 22.61394462 50.08808565], cur_train_grp_loss: [0.0884805  0.11509154 0.25494586], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6772, max_kl_dist_index: 0, max_train_grp_loss:  13.6960, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7900, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2549, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:31:42,320 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  196, train_loss:  12.6275, val_loss:  12.2342, grad_norm: 0.0089, live_grad: 0.0000, reward_err: 0.0105, 0.0186, 0.0013, KL_dist: 0.6772, 0.3244, 0.6762, param: [ 4.85002554  6.83013529  5.77932644 10.29393946], weights: [0.24739822 0.27495224 0.47764954], train_wt_loss:  37.8825, val_wt_loss: 36.7025, train_grp_loss: [11.50241798 13.69610486 13.00201588], val_grp_loss: [12.6553436  12.79026657 11.25523467], train_hist_grp_loss: [17.44912891 22.72903703 50.34302933], cur_train_grp_loss: [0.08848033 0.11509241 0.25494368], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6772, max_kl_dist_index: 0, max_train_grp_loss:  13.6961, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7903, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2549, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:31:43,325 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  197, train_loss:  12.6275, val_loss:  12.2343, grad_norm: 0.0090, live_grad: 0.0000, reward_err: 0.0105, 0.0186, 0.0013, KL_dist: 0.6773, 0.3244, 0.6762, param: [ 4.8496014   6.82948671  5.77979672 10.29478562], weights: [0.24696868 0.274621   0.47841032], train_wt_loss:  37.8826, val_wt_loss: 36.7028, train_grp_loss: [11.50238947 13.69621717 13.00190281], val_grp_loss: [12.65536487 12.79055871 11.25525328], train_hist_grp_loss: [17.53760905 22.84413035 50.59797082], cur_train_grp_loss: [0.08848014 0.11509332 0.25494149], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6773, max_kl_dist_index: 0, max_train_grp_loss:  13.6962, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7906, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2549, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:31:44,338 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  198, train_loss:  12.6275, val_loss:  12.2344, grad_norm: 0.0090, live_grad: 0.0000, reward_err: 0.0105, 0.0186, 0.0013, KL_dist: 0.6773, 0.3244, 0.6763, param: [ 4.84917542  6.82883912  5.78026627 10.29563772], weights: [0.24653931 0.27428952 0.47917117], train_wt_loss:  37.8826, val_wt_loss: 36.7032, train_grp_loss: [11.50235761 13.69633379 13.0017887 ], val_grp_loss: [12.65538303 12.79085614 11.25527044], train_hist_grp_loss: [17.62608897 22.95922461 50.85291009], cur_train_grp_loss: [0.08847992 0.11509426 0.25493927], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6773, max_kl_dist_index: 0, max_train_grp_loss:  13.6963, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7909, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2549, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:31:45,337 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  199, train_loss:  12.6276, val_loss:  12.2345, grad_norm: 0.0091, live_grad: 0.0000, reward_err: 0.0105, 0.0186, 0.0013, KL_dist: 0.6773, 0.3245, 0.6763, param: [ 4.8487476   6.82819253  5.78073509 10.29649577], weights: [0.24611011 0.2739578  0.47993209], train_wt_loss:  37.8827, val_wt_loss: 36.7035, train_grp_loss: [11.50232238 13.6964547  13.00167355], val_grp_loss: [12.65539809 12.79115886 11.25528613], train_hist_grp_loss: [17.71456864 23.07431986 51.10784713], cur_train_grp_loss: [0.08847967 0.11509524 0.25493703], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6773, max_kl_dist_index: 0, max_train_grp_loss:  13.6965, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7912, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2549, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:31:46,259 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1654] - INFO: Iteration:  199, train_loss:  12.6276, val_loss:  12.2345, grad_norm: 0.0091,  live_grad: 0.0000, reward_err: 0.0105, 0.0186, 0.0013, KL_dist: 0.6773, 0.3245, 0.6763, param: [ 4.8487476   6.82819253  5.78073509 10.29649577], weights: [0.24611011 0.2739578  0.47993209], train_wt_loss:  37.8827, val_wt_loss: 36.7035, train_grp_loss: [11.50232238 13.6964547  13.00167355], val_grp_loss: [12.65539809 12.79115886 11.25528613], train_hist_grp_loss: [17.71456864 23.07431986 51.10784713], cur_train_grp_loss: [0.08847967 0.11509524 0.25493703], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6773, max_kl_dist_index: 0, max_train_grp_loss:  13.6965, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7912, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2549, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:31:46,485 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:388] - INFO: Policy parameter learned solely on the preference data rdpo: [ 4.8487476   6.82819253  5.78073509 10.29649577].
2024-10-07 01:31:46,840 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Uniform reward: 3.8511, 3.8511, 3.1970
2024-10-07 01:31:46,840 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Optimal reward: 3.8856, 7.2460, 3.3201
2024-10-07 01:31:46,841 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Policy reward: 3.8446, 7.1116, 3.3156
2024-10-07 01:31:46,841 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:402] - INFO: Reward Error: 0.0105, 0.0186, 0.0013
2024-10-07 01:31:47,532 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:417] - INFO: Optimal reward: 3.8856, 7.2460, 3.3201
Known param reward: [[3.885563232421875, 6.83889453125, 3.291370361328125], [3.493690185546875, 7.24602734375, 3.1155205078125], [3.850873046875, 7.10487548828125, 3.320061279296875]], Known param reward error: [[0.0, 0.05618703783269167, 0.008641683256769945], [0.10085360176489651, 0.0, 0.06160752898142066], [0.008927968346368324, 0.019479895503085456, 0.0]].
