2024-10-07 01:10:21,322 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log-hyperparam-search/2024_10_07_00_27_03/rdpo,0.2,0.1,0.01,2021
2024-10-07 01:10:21,324 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2021
2024-10-07 01:10:21,324 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-10-07 01:10:21,415 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.2351, l2 distance: 36.4442, acc: 0.90.
2024-10-07 01:10:21,416 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-10-07 01:10:21,417 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [ 9.05939251 17.1373287   9.50347978 12.39752865]
2024-10-07 01:10:21,634 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.8285, 7.1348, 3.2752
2024-10-07 01:10:21,867 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1314] - INFO: unique_group_ids: {0, 1, 2}
2024-10-07 01:10:23,079 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  0, train_loss:  12.1558, val_loss:  12.4221, grad_norm: 0.4595, live_grad: 0.0000, reward_err: 0.0104, 0.0142, 0.0002, KL_dist: 0.6567, 0.3051, 0.6499, param: [5.44259977 8.3001452  5.14403995 8.57240352], weights: [0.33311103 0.33307246 0.33381651], train_wt_loss:  36.4675, val_wt_loss: 37.2662, train_grp_loss: [11.80518823 13.07539799 10.73345362], val_grp_loss: [12.66677114 12.45251341 12.1461785 ], train_hist_grp_loss: [0.15100158 0.13942111 0.36256349], cur_train_grp_loss: [0.15100158 0.13942111 0.36256349], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6567, max_kl_dist_index: 0, max_train_grp_loss:  13.0754, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6668, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.3626, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:10:24,154 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  1, train_loss:  12.1558, val_loss:  12.4221, grad_norm: 0.0000, live_grad: 0.0000, reward_err: 0.0104, 0.0142, 0.0002, KL_dist: 0.6568, 0.3051, 0.6499, param: [5.4426591  8.29997348 5.14429669 8.57277289], weights: [0.33296605 0.33296132 0.33407263], train_wt_loss:  36.4675, val_wt_loss: 37.2663, train_grp_loss: [11.80526187 13.07535895 10.73336732], val_grp_loss: [12.66688807 12.45247172 12.14618837], train_hist_grp_loss: [0.24544308 0.24402429 0.57723256], cur_train_grp_loss: [0.09444151 0.10460318 0.21466907], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6568, max_kl_dist_index: 0, max_train_grp_loss:  13.0754, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6669, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2147, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:10:25,248 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  2, train_loss:  12.1558, val_loss:  12.4221, grad_norm: 0.0000, live_grad: 0.0000, reward_err: 0.0104, 0.0142, 0.0002, KL_dist: 0.6568, 0.3052, 0.6499, param: [5.44271836 8.29980191 5.14455354 8.57314282], weights: [0.33282103 0.33285013 0.33432884], train_wt_loss:  36.4675, val_wt_loss: 37.2664, train_grp_loss: [11.80533531 13.07532022 10.73328091], val_grp_loss: [12.66700482 12.45243037 12.14619816], train_hist_grp_loss: [0.33988518 0.34862716 0.79189991], cur_train_grp_loss: [0.09444209 0.10460287 0.21466735], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6568, max_kl_dist_index: 0, max_train_grp_loss:  13.0753, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6670, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2147, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:10:26,345 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  3, train_loss:  12.1558, val_loss:  12.4222, grad_norm: 0.0001, live_grad: 0.0000, reward_err: 0.0104, 0.0142, 0.0002, KL_dist: 0.6568, 0.3052, 0.6499, param: [5.44277756 8.29963047 5.1448105  8.57351329], weights: [0.33267599 0.33273887 0.33458514], train_wt_loss:  36.4675, val_wt_loss: 37.2665, train_grp_loss: [11.80540854 13.07528178 10.73319439], val_grp_loss: [12.66712141 12.45238937 12.14620786], train_hist_grp_loss: [0.43432786 0.45322973 1.00656552], cur_train_grp_loss: [0.09444268 0.10460256 0.21466562], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6568, max_kl_dist_index: 0, max_train_grp_loss:  13.0753, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6671, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2147, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:10:27,475 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  4, train_loss:  12.1558, val_loss:  12.4222, grad_norm: 0.0001, live_grad: 0.0000, reward_err: 0.0104, 0.0142, 0.0002, KL_dist: 0.6568, 0.3052, 0.6500, param: [5.4428367  8.29945917 5.14506757 8.57388432], weights: [0.33253091 0.33262756 0.33484154], train_wt_loss:  36.4675, val_wt_loss: 37.2665, train_grp_loss: [11.80548156 13.07524364 10.73310776], val_grp_loss: [12.66723782 12.4523487  12.14621749], train_hist_grp_loss: [0.52877113 0.55783198 1.22122941], cur_train_grp_loss: [0.09444327 0.10460225 0.21466389], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6568, max_kl_dist_index: 0, max_train_grp_loss:  13.0752, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6672, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2147, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:10:28,622 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  5, train_loss:  12.1558, val_loss:  12.4222, grad_norm: 0.0001, live_grad: 0.0000, reward_err: 0.0104, 0.0142, 0.0002, KL_dist: 0.6569, 0.3052, 0.6500, param: [5.44289577 8.29928801 5.14532476 8.57425589], weights: [0.3323858  0.33251618 0.33509802], train_wt_loss:  36.4675, val_wt_loss: 37.2666, train_grp_loss: [11.80555438 13.0752058  10.73302102], val_grp_loss: [12.66735406 12.45230837 12.14622704], train_hist_grp_loss: [0.62321498 0.66243393 1.43589157], cur_train_grp_loss: [0.09444385 0.10460195 0.21466216], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6569, max_kl_dist_index: 0, max_train_grp_loss:  13.0752, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6674, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2147, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:10:29,723 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  6, train_loss:  12.1558, val_loss:  12.4222, grad_norm: 0.0001, live_grad: 0.0000, reward_err: 0.0104, 0.0142, 0.0002, KL_dist: 0.6569, 0.3052, 0.6500, param: [5.44295477 8.29911699 5.14558205 8.57462802], weights: [0.33224065 0.33240474 0.3353546 ], train_wt_loss:  36.4675, val_wt_loss: 37.2667, train_grp_loss: [11.80562698 13.07516825 10.73293417], val_grp_loss: [12.66747013 12.45226838 12.1462365 ], train_hist_grp_loss: [0.71765942 0.76703557 1.65055199], cur_train_grp_loss: [0.09444444 0.10460165 0.21466042], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6569, max_kl_dist_index: 0, max_train_grp_loss:  13.0752, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6675, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2147, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:10:30,808 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  7, train_loss:  12.1558, val_loss:  12.4223, grad_norm: 0.0001, live_grad: 0.0000, reward_err: 0.0104, 0.0142, 0.0002, KL_dist: 0.6569, 0.3052, 0.6500, param: [5.44301371 8.2989461  5.14583946 8.5750007 ], weights: [0.33209548 0.33229324 0.33561128], train_wt_loss:  36.4675, val_wt_loss: 37.2668, train_grp_loss: [11.80569938 13.07513101 10.73284721], val_grp_loss: [12.66758603 12.45222873 12.14624589], train_hist_grp_loss: [0.81210443 0.87163692 1.86521067], cur_train_grp_loss: [0.09444502 0.10460135 0.21465868], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6569, max_kl_dist_index: 0, max_train_grp_loss:  13.0751, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6676, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2147, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:10:31,855 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  8, train_loss:  12.1558, val_loss:  12.4223, grad_norm: 0.0002, live_grad: 0.0000, reward_err: 0.0104, 0.0142, 0.0002, KL_dist: 0.6569, 0.3052, 0.6501, param: [5.44307259 8.29877536 5.14609698 8.57537393], weights: [0.33195027 0.33218168 0.33586804], train_wt_loss:  36.4675, val_wt_loss: 37.2669, train_grp_loss: [11.80577157 13.07509406 10.73276014], val_grp_loss: [12.66770176 12.45218941 12.1462552 ], train_hist_grp_loss: [0.90655003 0.97623797 2.07986762], cur_train_grp_loss: [0.0944456  0.10460105 0.21465694], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6569, max_kl_dist_index: 0, max_train_grp_loss:  13.0751, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6677, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2147, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:10:32,907 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  9, train_loss:  12.1558, val_loss:  12.4223, grad_norm: 0.0002, live_grad: 0.0000, reward_err: 0.0104, 0.0142, 0.0002, KL_dist: 0.6570, 0.3053, 0.6501, param: [5.4431314  8.29860475 5.14635461 8.57574771], weights: [0.33180504 0.33207006 0.3361249 ], train_wt_loss:  36.4675, val_wt_loss: 37.2670, train_grp_loss: [11.80584355 13.07505741 10.73267295], val_grp_loss: [12.66781732 12.45215044 12.14626442], train_hist_grp_loss: [1.0009962  1.08083872 2.29452282], cur_train_grp_loss: [0.09444617 0.10460075 0.2146552 ], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6570, max_kl_dist_index: 0, max_train_grp_loss:  13.0751, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6678, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2147, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:10:33,914 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  10, train_loss:  12.1558, val_loss:  12.4224, grad_norm: 0.0002, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6570, 0.3053, 0.6501, param: [5.44319015 8.29843428 5.14661235 8.57612204], weights: [0.33165977 0.33195838 0.33638185], train_wt_loss:  36.4675, val_wt_loss: 37.2671, train_grp_loss: [11.80591532 13.07502106 10.73258566], val_grp_loss: [12.6679327  12.45211181 12.14627357], train_hist_grp_loss: [1.09544295 1.18543918 2.50917628], cur_train_grp_loss: [0.09444675 0.10460046 0.21465346], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6570, max_kl_dist_index: 0, max_train_grp_loss:  13.0750, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6679, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2147, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:10:34,966 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  11, train_loss:  12.1558, val_loss:  12.4224, grad_norm: 0.0002, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6570, 0.3053, 0.6501, param: [5.44324883 8.29826395 5.1468702  8.57649692], weights: [0.33151447 0.33184664 0.33663889], train_wt_loss:  36.4675, val_wt_loss: 37.2671, train_grp_loss: [11.80598689 13.07498501 10.73249826], val_grp_loss: [12.66804791 12.45207352 12.14628263], train_hist_grp_loss: [1.18989027 1.29003935 2.72382799], cur_train_grp_loss: [0.09444732 0.10460017 0.21465171], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6570, max_kl_dist_index: 0, max_train_grp_loss:  13.0750, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6680, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2147, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:10:35,964 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  12, train_loss:  12.1558, val_loss:  12.4224, grad_norm: 0.0002, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6570, 0.3053, 0.6502, param: [5.44330745 8.29809376 5.14712817 8.57687236], weights: [0.33136913 0.33173484 0.33689603], train_wt_loss:  36.4675, val_wt_loss: 37.2672, train_grp_loss: [11.80605824 13.07494926 10.73241074], val_grp_loss: [12.66816296 12.45203557 12.14629161], train_hist_grp_loss: [1.28433817 1.39463923 2.93847796], cur_train_grp_loss: [0.0944479  0.10459988 0.21464997], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6570, max_kl_dist_index: 0, max_train_grp_loss:  13.0749, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6682, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2146, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:10:36,982 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  13, train_loss:  12.1558, val_loss:  12.4224, grad_norm: 0.0003, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6571, 0.3053, 0.6502, param: [5.443366   8.29792371 5.14738624 8.57724835], weights: [0.33122377 0.33162298 0.33715325], train_wt_loss:  36.4675, val_wt_loss: 37.2673, train_grp_loss: [11.80612939 13.07491381 10.73232312], val_grp_loss: [12.66827783 12.45199796 12.14630052], train_hist_grp_loss: [1.37878663 1.49923882 3.15312617], cur_train_grp_loss: [0.09444847 0.10459959 0.21464821], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6571, max_kl_dist_index: 0, max_train_grp_loss:  13.0749, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6683, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2146, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:10:37,984 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  14, train_loss:  12.1558, val_loss:  12.4225, grad_norm: 0.0003, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6571, 0.3053, 0.6502, param: [5.44342449 8.29775379 5.14764443 8.5776249 ], weights: [0.33107838 0.33151105 0.33741057], train_wt_loss:  36.4675, val_wt_loss: 37.2674, train_grp_loss: [11.80620033 13.07487866 10.73223538], val_grp_loss: [12.66839253 12.45196069 12.14630934], train_hist_grp_loss: [1.47323567 1.60383813 3.36777263], cur_train_grp_loss: [0.09444904 0.10459931 0.21464646], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6571, max_kl_dist_index: 0, max_train_grp_loss:  13.0749, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6684, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2146, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:10:39,028 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  15, train_loss:  12.1558, val_loss:  12.4225, grad_norm: 0.0003, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6571, 0.3053, 0.6502, param: [5.44348291 8.29758401 5.14790273 8.57800199], weights: [0.33093295 0.33139907 0.33766798], train_wt_loss:  36.4675, val_wt_loss: 37.2675, train_grp_loss: [11.80627107 13.07484381 10.73214754], val_grp_loss: [12.66850705 12.45192376 12.14631809], train_hist_grp_loss: [1.56768527 1.70843716 3.58241734], cur_train_grp_loss: [0.0944496  0.10459903 0.21464471], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6571, max_kl_dist_index: 0, max_train_grp_loss:  13.0748, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6685, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2146, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:10:40,081 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  16, train_loss:  12.1558, val_loss:  12.4225, grad_norm: 0.0003, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6571, 0.3054, 0.6502, param: [5.44354126 8.29741437 5.14816114 8.57837964], weights: [0.33078749 0.33128703 0.33792548], train_wt_loss:  36.4675, val_wt_loss: 37.2676, train_grp_loss: [11.80634159 13.07480925 10.73205958], val_grp_loss: [12.66862141 12.45188717 12.14632675], train_hist_grp_loss: [1.66213544 1.81303591 3.79706029], cur_train_grp_loss: [0.09445017 0.10459875 0.21464295], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6571, max_kl_dist_index: 0, max_train_grp_loss:  13.0748, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6686, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2146, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:10:41,104 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  17, train_loss:  12.1558, val_loss:  12.4226, grad_norm: 0.0003, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6572, 0.3054, 0.6503, param: [5.44359956 8.29724486 5.14841967 8.57875785], weights: [0.330642   0.33117493 0.33818307], train_wt_loss:  36.4675, val_wt_loss: 37.2677, train_grp_loss: [11.80641191 13.074775   10.73197151], val_grp_loss: [12.6687356  12.45185092 12.14633533], train_hist_grp_loss: [1.75658617 1.91763439 4.01170148], cur_train_grp_loss: [0.09445073 0.10459847 0.21464119], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6572, max_kl_dist_index: 0, max_train_grp_loss:  13.0748, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6687, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2146, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:10:42,132 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  18, train_loss:  12.1558, val_loss:  12.4226, grad_norm: 0.0003, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6572, 0.3054, 0.6503, param: [5.44365778 8.2970755  5.14867831 8.57913661], weights: [0.33049648 0.33106276 0.33844075], train_wt_loss:  36.4675, val_wt_loss: 37.2677, train_grp_loss: [11.80648202 13.07474104 10.73188333], val_grp_loss: [12.66884961 12.45181501 12.14634384], train_hist_grp_loss: [1.85103747 2.02223259 4.22634091], cur_train_grp_loss: [0.0944513  0.1045982  0.21463943], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6572, max_kl_dist_index: 0, max_train_grp_loss:  13.0747, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6688, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2146, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:10:43,147 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  19, train_loss:  12.1558, val_loss:  12.4226, grad_norm: 0.0004, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6572, 0.3054, 0.6503, param: [5.44371595 8.29690627 5.14893705 8.57951592], weights: [0.33035093 0.33095054 0.33869853], train_wt_loss:  36.4675, val_wt_loss: 37.2678, train_grp_loss: [11.80655192 13.07470739 10.73179504], val_grp_loss: [12.66896345 12.45177944 12.14635226], train_hist_grp_loss: [1.94548932 2.12683052 4.44097858], cur_train_grp_loss: [0.09445186 0.10459793 0.21463767], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6572, max_kl_dist_index: 0, max_train_grp_loss:  13.0747, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6690, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2146, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:10:44,220 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  20, train_loss:  12.1558, val_loss:  12.4226, grad_norm: 0.0004, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6573, 0.3054, 0.6503, param: [5.44377404 8.29673718 5.14919592 8.57989579], weights: [0.33020535 0.33083826 0.33895639], train_wt_loss:  36.4675, val_wt_loss: 37.2679, train_grp_loss: [11.80662161 13.07467403 10.73170664], val_grp_loss: [12.66907713 12.45174422 12.1463606 ], train_hist_grp_loss: [2.03994174 2.23142818 4.65561448], cur_train_grp_loss: [0.09445242 0.10459766 0.2146359 ], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6573, max_kl_dist_index: 0, max_train_grp_loss:  13.0747, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6691, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2146, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:10:45,249 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  21, train_loss:  12.1558, val_loss:  12.4227, grad_norm: 0.0004, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6573, 0.3054, 0.6504, param: [5.44383208 8.29656822 5.14945489 8.58027621], weights: [0.33005974 0.33072591 0.33921435], train_wt_loss:  36.4675, val_wt_loss: 37.2680, train_grp_loss: [11.80669109 13.07464098 10.73161813], val_grp_loss: [12.66919063 12.45170933 12.14636886], train_hist_grp_loss: [2.13439471 2.33602557 4.87024861], cur_train_grp_loss: [0.09445297 0.10459739 0.21463413], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6573, max_kl_dist_index: 0, max_train_grp_loss:  13.0746, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6692, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2146, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:10:46,317 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  22, train_loss:  12.1558, val_loss:  12.4227, grad_norm: 0.0004, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6573, 0.3054, 0.6504, param: [5.44389004 8.29639941 5.14971398 8.58065718], weights: [0.3299141  0.33061351 0.33947239], train_wt_loss:  36.4675, val_wt_loss: 37.2681, train_grp_loss: [11.80676037 13.07460822 10.73152951], val_grp_loss: [12.66930396 12.45167479 12.14637705], train_hist_grp_loss: [2.22884824 2.4406227  5.08488098], cur_train_grp_loss: [0.09445353 0.10459713 0.21463236], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6573, max_kl_dist_index: 0, max_train_grp_loss:  13.0746, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6693, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2146, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:10:47,353 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  23, train_loss:  12.1558, val_loss:  12.4227, grad_norm: 0.0004, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6573, 0.3055, 0.6504, param: [5.44394794 8.29623073 5.14997318 8.58103872], weights: [0.32976842 0.33050105 0.33973053], train_wt_loss:  36.4675, val_wt_loss: 37.2682, train_grp_loss: [11.80682944 13.07457577 10.73144078], val_grp_loss: [12.66941712 12.45164059 12.14638515], train_hist_grp_loss: [2.32330232 2.54521956 5.29951157], cur_train_grp_loss: [0.09445408 0.10459687 0.21463059], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6573, max_kl_dist_index: 0, max_train_grp_loss:  13.0746, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6694, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2146, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:10:48,372 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  24, train_loss:  12.1558, val_loss:  12.4228, grad_norm: 0.0005, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6574, 0.3055, 0.6504, param: [5.44400578 8.29606219 5.15023249 8.5814208 ], weights: [0.32962272 0.33038853 0.33998876], train_wt_loss:  36.4675, val_wt_loss: 37.2683, train_grp_loss: [11.8068983  13.07454362 10.73135193], val_grp_loss: [12.6695301  12.45160672 12.14639317], train_hist_grp_loss: [2.41775696 2.64981617 5.51414038], cur_train_grp_loss: [0.09445464 0.10459661 0.21462882], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6574, max_kl_dist_index: 0, max_train_grp_loss:  13.0745, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6695, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2146, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:10:49,414 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  25, train_loss:  12.1558, val_loss:  12.4228, grad_norm: 0.0005, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6574, 0.3055, 0.6505, param: [5.44406355 8.29589378 5.15049192 8.58180345], weights: [0.32947698 0.33027594 0.34024708], train_wt_loss:  36.4675, val_wt_loss: 37.2684, train_grp_loss: [11.80696695 13.07451176 10.73126298], val_grp_loss: [12.66964292 12.4515732  12.14640111], train_hist_grp_loss: [2.51221214 2.75441252 5.72876742], cur_train_grp_loss: [0.09445519 0.10459635 0.21462704], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6574, max_kl_dist_index: 0, max_train_grp_loss:  13.0745, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6696, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2146, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:10:50,433 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  26, train_loss:  12.1558, val_loss:  12.4228, grad_norm: 0.0005, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6574, 0.3055, 0.6505, param: [5.44412126 8.29572551 5.15075146 8.58218664], weights: [0.32933122 0.3301633  0.34050548], train_wt_loss:  36.4675, val_wt_loss: 37.2684, train_grp_loss: [11.8070354  13.07448021 10.73117391], val_grp_loss: [12.66975556 12.45154003 12.14640898], train_hist_grp_loss: [2.60666788 2.85900861 5.94339268], cur_train_grp_loss: [0.09445574 0.10459609 0.21462526], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6574, max_kl_dist_index: 0, max_train_grp_loss:  13.0745, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6698, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2146, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:10:51,509 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  27, train_loss:  12.1558, val_loss:  12.4228, grad_norm: 0.0005, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6574, 0.3055, 0.6505, param: [5.4441789  8.29555738 5.15101111 8.5825704 ], weights: [0.32918542 0.3300506  0.34076398], train_wt_loss:  36.4675, val_wt_loss: 37.2685, train_grp_loss: [11.80710363 13.07444895 10.73108474], val_grp_loss: [12.66986804 12.45150719 12.14641676], train_hist_grp_loss: [2.70112416 2.96360445 6.15801616], cur_train_grp_loss: [0.09445628 0.10459584 0.21462348], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6574, max_kl_dist_index: 0, max_train_grp_loss:  13.0744, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6699, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2146, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:10:52,526 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  28, train_loss:  12.1558, val_loss:  12.4229, grad_norm: 0.0005, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6575, 0.3055, 0.6505, param: [5.44423647 8.29538939 5.15127088 8.58295471], weights: [0.32903959 0.32993784 0.34102257], train_wt_loss:  36.4675, val_wt_loss: 37.2686, train_grp_loss: [11.80717166 13.074418   10.73099545], val_grp_loss: [12.66998034 12.4514747  12.14642446], train_hist_grp_loss: [2.79558099 3.06820004 6.37263785], cur_train_grp_loss: [0.09445683 0.10459559 0.21462169], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6575, max_kl_dist_index: 0, max_train_grp_loss:  13.0744, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6700, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2146, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:10:53,564 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  29, train_loss:  12.1558, val_loss:  12.4229, grad_norm: 0.0006, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6575, 0.3056, 0.6505, param: [5.44429398 8.29522153 5.15153076 8.58333958], weights: [0.32889374 0.32982502 0.34128124], train_wt_loss:  36.4675, val_wt_loss: 37.2687, train_grp_loss: [11.80723948 13.07438735 10.73090605], val_grp_loss: [12.67009247 12.45144254 12.14643208], train_hist_grp_loss: [2.89003837 3.17279539 6.58725776], cur_train_grp_loss: [0.09445737 0.10459534 0.21461991], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6575, max_kl_dist_index: 0, max_train_grp_loss:  13.0744, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6701, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2146, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:10:54,575 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  30, train_loss:  12.1558, val_loss:  12.4229, grad_norm: 0.0006, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6575, 0.3056, 0.6506, param: [5.44435142 8.29505381 5.15179075 8.58372501], weights: [0.32874785 0.32971214 0.34154001], train_wt_loss:  36.4675, val_wt_loss: 37.2688, train_grp_loss: [11.8073071  13.074357   10.73081654], val_grp_loss: [12.67020444 12.45141073 12.14643963], train_hist_grp_loss: [2.98449628 3.27739049 6.80187588], cur_train_grp_loss: [0.09445792 0.1045951  0.21461812], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6575, max_kl_dist_index: 0, max_train_grp_loss:  13.0744, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6702, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2146, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:10:55,593 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  31, train_loss:  12.1558, val_loss:  12.4230, grad_norm: 0.0006, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6575, 0.3056, 0.6506, param: [5.4444088  8.29488622 5.15205086 8.58411099], weights: [0.32860193 0.3295992  0.34179887], train_wt_loss:  36.4675, val_wt_loss: 37.2689, train_grp_loss: [11.8073745  13.07432695 10.73072692], val_grp_loss: [12.67031623 12.45137926 12.14644709], train_hist_grp_loss: [3.07895474 3.38198534 7.01649221], cur_train_grp_loss: [0.09445846 0.10459486 0.21461633], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6575, max_kl_dist_index: 0, max_train_grp_loss:  13.0743, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6703, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2146, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:10:56,617 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  32, train_loss:  12.1558, val_loss:  12.4230, grad_norm: 0.0006, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6576, 0.3056, 0.6506, param: [5.44446611 8.29471877 5.15231108 8.58449753], weights: [0.32845598 0.32948621 0.34205781], train_wt_loss:  36.4675, val_wt_loss: 37.2690, train_grp_loss: [11.8074417  13.0742972  10.73063719], val_grp_loss: [12.67042784 12.45134814 12.14645447], train_hist_grp_loss: [3.17341373 3.48657996 7.23110675], cur_train_grp_loss: [0.094459   0.10459462 0.21461454], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6576, max_kl_dist_index: 0, max_train_grp_loss:  13.0743, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6704, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2146, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:10:57,671 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  33, train_loss:  12.1558, val_loss:  12.4230, grad_norm: 0.0006, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6576, 0.3056, 0.6506, param: [5.44452336 8.29455146 5.15257142 8.58488463], weights: [0.32831    0.32937315 0.34231685], train_wt_loss:  36.4675, val_wt_loss: 37.2691, train_grp_loss: [11.80750869 13.07426775 10.73054735], val_grp_loss: [12.67053929 12.45131735 12.14646178], train_hist_grp_loss: [3.26787327 3.59117434 7.4457195 ], cur_train_grp_loss: [0.09445953 0.10459438 0.21461274], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6576, max_kl_dist_index: 0, max_train_grp_loss:  13.0743, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6705, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2146, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:10:58,702 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  34, train_loss:  12.1558, val_loss:  12.4231, grad_norm: 0.0007, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6576, 0.3056, 0.6507, param: [5.44458054 8.29438428 5.15283186 8.58527228], weights: [0.328164   0.32926004 0.34257597], train_wt_loss:  36.4675, val_wt_loss: 37.2692, train_grp_loss: [11.80757547 13.0742386  10.7304574 ], val_grp_loss: [12.67065057 12.45128691 12.146469  ], train_hist_grp_loss: [3.36233334 3.69576848 7.66033044], cur_train_grp_loss: [0.09446007 0.10459414 0.21461095], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6576, max_kl_dist_index: 0, max_train_grp_loss:  13.0742, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6707, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2146, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:10:59,718 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  35, train_loss:  12.1558, val_loss:  12.4231, grad_norm: 0.0007, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6577, 0.3056, 0.6507, param: [5.44463765 8.29421724 5.15309243 8.5856605 ], weights: [0.32801796 0.32914686 0.34283518], train_wt_loss:  36.4675, val_wt_loss: 37.2692, train_grp_loss: [11.80764205 13.07420975 10.73036733], val_grp_loss: [12.67076168 12.45125681 12.14647615], train_hist_grp_loss: [3.45679394 3.80036239 7.87493959], cur_train_grp_loss: [0.0944606  0.10459391 0.21460915], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6577, max_kl_dist_index: 0, max_train_grp_loss:  13.0742, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6708, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2146, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:11:00,747 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  36, train_loss:  12.1558, val_loss:  12.4231, grad_norm: 0.0007, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6577, 0.3057, 0.6507, param: [5.4446947  8.29405034 5.1533531  8.58604927], weights: [0.32787189 0.32903363 0.34309448], train_wt_loss:  36.4675, val_wt_loss: 37.2693, train_grp_loss: [11.80770842 13.07418121 10.73027716], val_grp_loss: [12.67087261 12.45122705 12.14648321], train_hist_grp_loss: [3.55125508 3.90495606 8.08954694], cur_train_grp_loss: [0.09446114 0.10459368 0.21460735], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6577, max_kl_dist_index: 0, max_train_grp_loss:  13.0742, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6709, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2146, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:11:01,793 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  37, train_loss:  12.1558, val_loss:  12.4231, grad_norm: 0.0007, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6577, 0.3057, 0.6507, param: [5.44475169 8.29388357 5.15361389 8.5864386 ], weights: [0.32772579 0.32892034 0.34335387], train_wt_loss:  36.4675, val_wt_loss: 37.2694, train_grp_loss: [11.80777457 13.07415296 10.73018687], val_grp_loss: [12.67098338 12.45119764 12.14649019], train_hist_grp_loss: [3.64571674 4.00954951 8.30415248], cur_train_grp_loss: [0.09446167 0.10459345 0.21460554], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6577, max_kl_dist_index: 0, max_train_grp_loss:  13.0742, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6710, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2146, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:11:02,845 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  38, train_loss:  12.1558, val_loss:  12.4232, grad_norm: 0.0007, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6577, 0.3057, 0.6508, param: [5.4448086  8.29371694 5.1538748  8.58682849], weights: [0.32757966 0.32880699 0.34361335], train_wt_loss:  36.4675, val_wt_loss: 37.2695, train_grp_loss: [11.80784053 13.07412502 10.73009648], val_grp_loss: [12.67109397 12.45116857 12.1464971 ], train_hist_grp_loss: [3.74017894 4.11414274 8.51875622], cur_train_grp_loss: [0.0944622  0.10459322 0.21460374], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6577, max_kl_dist_index: 0, max_train_grp_loss:  13.0741, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6711, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2146, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:11:03,887 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  39, train_loss:  12.1558, val_loss:  12.4232, grad_norm: 0.0008, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6578, 0.3057, 0.6508, param: [5.44486546 8.29355044 5.15413582 8.58721894], weights: [0.32743351 0.32869358 0.34387292], train_wt_loss:  36.4675, val_wt_loss: 37.2696, train_grp_loss: [11.80790627 13.07409738 10.73000597], val_grp_loss: [12.67120439 12.45113984 12.14650392], train_hist_grp_loss: [3.83464167 4.21873574 8.73335815], cur_train_grp_loss: [0.09446272 0.104593   0.21460193], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6578, max_kl_dist_index: 0, max_train_grp_loss:  13.0741, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6712, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2146, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:11:04,902 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  40, train_loss:  12.1558, val_loss:  12.4232, grad_norm: 0.0008, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6578, 0.3057, 0.6508, param: [5.44492224 8.29338408 5.15439695 8.58760995], weights: [0.32728732 0.32858011 0.34413257], train_wt_loss:  36.4675, val_wt_loss: 37.2697, train_grp_loss: [11.80797181 13.07407004 10.72991535], val_grp_loss: [12.67131465 12.45111146 12.14651067], train_hist_grp_loss: [3.92910492 4.32332852 8.94795827], cur_train_grp_loss: [0.09446325 0.10459278 0.21460012], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6578, max_kl_dist_index: 0, max_train_grp_loss:  13.0741, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6713, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2146, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:11:05,919 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  41, train_loss:  12.1558, val_loss:  12.4233, grad_norm: 0.0008, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6578, 0.3057, 0.6508, param: [5.44497896 8.29321786 5.1546582  8.58800152], weights: [0.3271411  0.32846658 0.34439232], train_wt_loss:  36.4675, val_wt_loss: 37.2698, train_grp_loss: [11.80803714 13.074043   10.72982462], val_grp_loss: [12.67142473 12.45108341 12.14651734], train_hist_grp_loss: [4.02356869 4.42792108 9.16255657], cur_train_grp_loss: [0.09446377 0.10459256 0.21459831], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6578, max_kl_dist_index: 0, max_train_grp_loss:  13.0740, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6714, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2146, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:11:06,945 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  42, train_loss:  12.1558, val_loss:  12.4233, grad_norm: 0.0008, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6578, 0.3057, 0.6509, param: [5.44503561 8.29305177 5.15491957 8.58839364], weights: [0.32699486 0.328353   0.34465215], train_wt_loss:  36.4675, val_wt_loss: 37.2699, train_grp_loss: [11.80810226 13.07401627 10.72973378], val_grp_loss: [12.67153464 12.45105572 12.14652392], train_hist_grp_loss: [4.11803299 4.53251342 9.37715307], cur_train_grp_loss: [0.0944643  0.10459234 0.21459649], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6578, max_kl_dist_index: 0, max_train_grp_loss:  13.0740, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6715, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2146, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:11:07,965 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  43, train_loss:  12.1558, val_loss:  12.4233, grad_norm: 0.0009, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6579, 0.3058, 0.6509, param: [5.4450922  8.29288582 5.15518105 8.58878633], weights: [0.32684858 0.32823935 0.34491207], train_wt_loss:  36.4675, val_wt_loss: 37.2699, train_grp_loss: [11.80816717 13.07398983 10.72964282], val_grp_loss: [12.67164438 12.45102836 12.14653043], train_hist_grp_loss: [4.21249781 4.63710555 9.59174774], cur_train_grp_loss: [0.09446482 0.10459213 0.21459468], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6579, max_kl_dist_index: 0, max_train_grp_loss:  13.0740, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6716, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2146, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:11:08,977 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  44, train_loss:  12.1558, val_loss:  12.4233, grad_norm: 0.0009, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6579, 0.3058, 0.6509, param: [5.44514872 8.29272    5.15544264 8.58917958], weights: [0.32670227 0.32812565 0.34517207], train_wt_loss:  36.4675, val_wt_loss: 37.2700, train_grp_loss: [11.80823188 13.0739637  10.72955176], val_grp_loss: [12.67175395 12.45100135 12.14653686], train_hist_grp_loss: [4.30696314 4.74169747 9.8063406 ], cur_train_grp_loss: [0.09446534 0.10459192 0.21459286], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6579, max_kl_dist_index: 0, max_train_grp_loss:  13.0740, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6718, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2146, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:11:10,001 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  45, train_loss:  12.1558, val_loss:  12.4234, grad_norm: 0.0009, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6579, 0.3058, 0.6509, param: [5.44520518 8.29255432 5.15570435 8.58957339], weights: [0.32655594 0.32801189 0.34543217], train_wt_loss:  36.4675, val_wt_loss: 37.2701, train_grp_loss: [11.80829637 13.07393787 10.72946058], val_grp_loss: [12.67186335 12.45097468 12.14654321], train_hist_grp_loss: [ 4.401429    4.84628918 10.02093163], cur_train_grp_loss: [0.09446586 0.10459171 0.21459104], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6579, max_kl_dist_index: 0, max_train_grp_loss:  13.0739, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6719, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2146, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:11:11,008 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  46, train_loss:  12.1558, val_loss:  12.4234, grad_norm: 0.0009, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6580, 0.3058, 0.6510, param: [5.44526157 8.29238877 5.15596617 8.58996776], weights: [0.32640958 0.32789808 0.34569235], train_wt_loss:  36.4675, val_wt_loss: 37.2702, train_grp_loss: [11.80836067 13.07391234 10.7293693 ], val_grp_loss: [12.67197257 12.45094836 12.14654947], train_hist_grp_loss: [ 4.49589537  4.95088068 10.23552085], cur_train_grp_loss: [0.09446637 0.1045915  0.21458921], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6580, max_kl_dist_index: 0, max_train_grp_loss:  13.0739, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6720, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2146, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:11:12,085 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  47, train_loss:  12.1558, val_loss:  12.4234, grad_norm: 0.0009, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6580, 0.3058, 0.6510, param: [5.44531789 8.29222336 5.15622811 8.59036269], weights: [0.32626318 0.3277842  0.34595262], train_wt_loss:  36.4675, val_wt_loss: 37.2703, train_grp_loss: [11.80842475 13.07388712 10.7292779 ], val_grp_loss: [12.67208163 12.45092238 12.14655566], train_hist_grp_loss: [ 4.59036225  5.05547198 10.45010823], cur_train_grp_loss: [0.09446689 0.1045913  0.21458739], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6580, max_kl_dist_index: 0, max_train_grp_loss:  13.0739, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6721, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2146, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:11:13,106 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  48, train_loss:  12.1558, val_loss:  12.4235, grad_norm: 0.0010, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6580, 0.3058, 0.6510, param: [5.44537414 8.29205808 5.15649016 8.59075819], weights: [0.32611676 0.32767026 0.34621297], train_wt_loss:  36.4675, val_wt_loss: 37.2704, train_grp_loss: [11.80848863 13.0738622  10.72918639], val_grp_loss: [12.67219052 12.45089674 12.14656177], train_hist_grp_loss: [ 4.68482965  5.16006308 10.66469379], cur_train_grp_loss: [0.0944674  0.1045911  0.21458556], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6580, max_kl_dist_index: 0, max_train_grp_loss:  13.0739, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6722, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2146, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:11:14,143 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  49, train_loss:  12.1558, val_loss:  12.4235, grad_norm: 0.0010, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6580, 0.3058, 0.6510, param: [5.44543033 8.29189294 5.15675233 8.59115424], weights: [0.32597031 0.32755627 0.34647342], train_wt_loss:  36.4675, val_wt_loss: 37.2705, train_grp_loss: [11.80855229 13.07383758 10.72909477], val_grp_loss: [12.67229923 12.45087145 12.1465678 ], train_hist_grp_loss: [ 4.77929756  5.26465398 10.87927752], cur_train_grp_loss: [0.09446791 0.1045909  0.21458373], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6580, max_kl_dist_index: 0, max_train_grp_loss:  13.0738, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6723, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2146, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:11:15,184 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  50, train_loss:  12.1558, val_loss:  12.4235, grad_norm: 0.0010, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6581, 0.3059, 0.6511, param: [5.44548646 8.29172793 5.15701462 8.59155086], weights: [0.32582383 0.32744222 0.34673395], train_wt_loss:  36.4675, val_wt_loss: 37.2706, train_grp_loss: [11.80861576 13.07381326 10.72900304], val_grp_loss: [12.67240778 12.4508465  12.14657375], train_hist_grp_loss: [ 4.87376598  5.36924468 11.09385941], cur_train_grp_loss: [0.09446842 0.1045907  0.2145819 ], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6581, max_kl_dist_index: 0, max_train_grp_loss:  13.0738, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6724, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2146, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:11:16,211 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  51, train_loss:  12.1558, val_loss:  12.4236, grad_norm: 0.0010, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6581, 0.3059, 0.6511, param: [5.44554251 8.29156306 5.15727702 8.59194804], weights: [0.32567732 0.32732811 0.34699457], train_wt_loss:  36.4675, val_wt_loss: 37.2707, train_grp_loss: [11.80867901 13.07378924 10.7289112 ], val_grp_loss: [12.67251615 12.45082189 12.14657963], train_hist_grp_loss: [ 4.96823491  5.47383518 11.30843947], cur_train_grp_loss: [0.09446893 0.10459051 0.21458006], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6581, max_kl_dist_index: 0, max_train_grp_loss:  13.0738, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6725, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2146, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:11:17,230 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  52, train_loss:  12.1558, val_loss:  12.4236, grad_norm: 0.0010, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6581, 0.3059, 0.6511, param: [5.4455985  8.29139832 5.15753954 8.59234578], weights: [0.32553078 0.32721395 0.34725527], train_wt_loss:  36.4675, val_wt_loss: 37.2708, train_grp_loss: [11.80874206 13.07376553 10.72881924], val_grp_loss: [12.67262436 12.45079763 12.14658542], train_hist_grp_loss: [ 5.06270434  5.5784255  11.5230177 ], cur_train_grp_loss: [0.09446943 0.10459031 0.21457822], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6581, max_kl_dist_index: 0, max_train_grp_loss:  13.0738, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6726, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2146, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:11:18,238 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  53, train_loss:  12.1558, val_loss:  12.4236, grad_norm: 0.0011, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6581, 0.3059, 0.6511, param: [5.44565443 8.29123372 5.15780217 8.59274408], weights: [0.32538421 0.32709973 0.34751606], train_wt_loss:  36.4675, val_wt_loss: 37.2708, train_grp_loss: [11.80880489 13.07374212 10.72872718], val_grp_loss: [12.67273239 12.45077372 12.14659113], train_hist_grp_loss: [ 5.15717427  5.68301562 11.73759408], cur_train_grp_loss: [0.09446994 0.10459012 0.21457638], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6581, max_kl_dist_index: 0, max_train_grp_loss:  13.0737, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6727, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2146, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:11:19,259 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  54, train_loss:  12.1559, val_loss:  12.4236, grad_norm: 0.0011, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6582, 0.3059, 0.6512, param: [5.44571029 8.29106925 5.15806492 8.59314295], weights: [0.32523762 0.32698544 0.34777694], train_wt_loss:  36.4676, val_wt_loss: 37.2709, train_grp_loss: [11.80886753 13.07371902 10.728635  ], val_grp_loss: [12.67284026 12.45075015 12.14659677], train_hist_grp_loss: [ 5.25164471  5.78760556 11.95216863], cur_train_grp_loss: [0.09447044 0.10458994 0.21457454], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6582, max_kl_dist_index: 0, max_train_grp_loss:  13.0737, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6728, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2146, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:11:20,293 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  55, train_loss:  12.1559, val_loss:  12.4237, grad_norm: 0.0011, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6582, 0.3059, 0.6512, param: [5.44576608 8.29090492 5.15832778 8.59354238], weights: [0.32509099 0.32687111 0.3480379 ], train_wt_loss:  36.4676, val_wt_loss: 37.2710, train_grp_loss: [11.80892995 13.07369621 10.72854271], val_grp_loss: [12.67294795 12.45072692 12.14660232], train_hist_grp_loss: [ 5.34611565  5.89219531 12.16674133], cur_train_grp_loss: [0.09447094 0.10458975 0.2145727 ], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6582, max_kl_dist_index: 0, max_train_grp_loss:  13.0737, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6729, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2146, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:11:21,321 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  56, train_loss:  12.1559, val_loss:  12.4237, grad_norm: 0.0011, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6582, 0.3060, 0.6512, param: [5.4458218  8.29074072 5.15859076 8.59394237], weights: [0.32494434 0.32675671 0.34829895], train_wt_loss:  36.4676, val_wt_loss: 37.2711, train_grp_loss: [11.80899217 13.07367371 10.72845031], val_grp_loss: [12.67305547 12.45070404 12.1466078 ], train_hist_grp_loss: [ 5.44058709  5.99678488 12.38131218], cur_train_grp_loss: [0.09447144 0.10458957 0.21457085], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6582, max_kl_dist_index: 0, max_train_grp_loss:  13.0737, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6731, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2146, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:11:22,392 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  57, train_loss:  12.1559, val_loss:  12.4237, grad_norm: 0.0011, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6583, 0.3060, 0.6512, param: [5.44587746 8.29057665 5.15885386 8.59434293], weights: [0.32479766 0.32664226 0.34856008], train_wt_loss:  36.4676, val_wt_loss: 37.2712, train_grp_loss: [11.80905418 13.07365151 10.7283578 ], val_grp_loss: [12.67316282 12.4506815  12.14661319], train_hist_grp_loss: [ 5.53505903  6.10137427 12.59588119], cur_train_grp_loss: [0.09447194 0.10458939 0.21456901], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6583, max_kl_dist_index: 0, max_train_grp_loss:  13.0737, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6732, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2146, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:11:23,445 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  58, train_loss:  12.1559, val_loss:  12.4238, grad_norm: 0.0012, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6583, 0.3060, 0.6513, param: [5.44593305 8.29041272 5.15911707 8.59474405], weights: [0.32465095 0.32652775 0.34882131], train_wt_loss:  36.4676, val_wt_loss: 37.2713, train_grp_loss: [11.80911598 13.07362962 10.72826518], val_grp_loss: [12.67327    12.45065931 12.14661851], train_hist_grp_loss: [ 5.62953146  6.20596348 12.81044834], cur_train_grp_loss: [0.09447243 0.10458921 0.21456716], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6583, max_kl_dist_index: 0, max_train_grp_loss:  13.0736, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6733, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2146, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:11:24,483 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  59, train_loss:  12.1559, val_loss:  12.4238, grad_norm: 0.0012, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6583, 0.3060, 0.6513, param: [5.44598857 8.29024893 5.1593804  8.59514573], weights: [0.32450421 0.32641318 0.34908261], train_wt_loss:  36.4676, val_wt_loss: 37.2714, train_grp_loss: [11.80917758 13.07360803 10.72817245], val_grp_loss: [12.67337702 12.45063747 12.14662375], train_hist_grp_loss: [ 5.72400439  6.31055252 13.02501365], cur_train_grp_loss: [0.09447293 0.10458904 0.2145653 ], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6583, max_kl_dist_index: 0, max_train_grp_loss:  13.0736, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6734, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2146, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:11:25,540 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  60, train_loss:  12.1559, val_loss:  12.4238, grad_norm: 0.0012, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6583, 0.3060, 0.6513, param: [5.44604403 8.29008527 5.15964384 8.59554798], weights: [0.32435744 0.32629855 0.349344  ], train_wt_loss:  36.4676, val_wt_loss: 37.2715, train_grp_loss: [11.80923896 13.07358674 10.7280796 ], val_grp_loss: [12.67348386 12.45061596 12.14662891], train_hist_grp_loss: [ 5.81847781  6.41514138 13.23957709], cur_train_grp_loss: [0.09447342 0.10458886 0.21456345], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6583, max_kl_dist_index: 0, max_train_grp_loss:  13.0736, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6735, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2146, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:11:26,534 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  61, train_loss:  12.1559, val_loss:  12.4239, grad_norm: 0.0012, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6584, 0.3060, 0.6513, param: [5.44609942 8.28992174 5.1599074  8.5959508 ], weights: [0.32421065 0.32618387 0.34960548], train_wt_loss:  36.4676, val_wt_loss: 37.2716, train_grp_loss: [11.80930014 13.07356576 10.72798665], val_grp_loss: [12.67359053 12.45059481 12.14663399], train_hist_grp_loss: [ 5.91295172  6.51973008 13.45413869], cur_train_grp_loss: [0.09447391 0.10458869 0.21456159], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6584, max_kl_dist_index: 0, max_train_grp_loss:  13.0736, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6736, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2146, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:11:27,556 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  62, train_loss:  12.1559, val_loss:  12.4239, grad_norm: 0.0012, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6584, 0.3060, 0.6514, param: [5.44615474 8.28975834 5.16017108 8.59635418], weights: [0.32406383 0.32606913 0.34986705], train_wt_loss:  36.4676, val_wt_loss: 37.2717, train_grp_loss: [11.80936112 13.07354508 10.72789358], val_grp_loss: [12.67369703 12.450574   12.14663899], train_hist_grp_loss: [ 6.00742613  6.6243186  13.66869842], cur_train_grp_loss: [0.0944744  0.10458853 0.21455973], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6584, max_kl_dist_index: 0, max_train_grp_loss:  13.0735, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6737, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2146, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:11:28,608 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  63, train_loss:  12.1559, val_loss:  12.4239, grad_norm: 0.0013, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6584, 0.3061, 0.6514, param: [5.44621    8.28959508 5.16043488 8.59675812], weights: [0.32391697 0.32595433 0.35012869], train_wt_loss:  36.4676, val_wt_loss: 37.2718, train_grp_loss: [11.80942188 13.0735247  10.7278004 ], val_grp_loss: [12.67380336 12.45055353 12.14664391], train_hist_grp_loss: [ 6.10190101  6.72890696 13.88325629], cur_train_grp_loss: [0.09447489 0.10458836 0.21455787], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6584, max_kl_dist_index: 0, max_train_grp_loss:  13.0735, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6738, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2146, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:11:29,631 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  64, train_loss:  12.1559, val_loss:  12.4239, grad_norm: 0.0013, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6585, 0.3061, 0.6514, param: [5.44626519 8.28943196 5.16069879 8.59716263], weights: [0.32377009 0.32583948 0.35039043], train_wt_loss:  36.4676, val_wt_loss: 37.2718, train_grp_loss: [11.80948244 13.07350463 10.72770711], val_grp_loss: [12.67390952 12.45053341 12.14664875], train_hist_grp_loss: [ 6.19637639  6.83349516 14.0978123 ], cur_train_grp_loss: [0.09447538 0.1045882  0.21455601], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6585, max_kl_dist_index: 0, max_train_grp_loss:  13.0735, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6739, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2146, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:11:30,634 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  65, train_loss:  12.1559, val_loss:  12.4240, grad_norm: 0.0013, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6585, 0.3061, 0.6514, param: [5.44632031 8.28926896 5.16096282 8.5975677 ], weights: [0.32362319 0.32572457 0.35065224], train_wt_loss:  36.4676, val_wt_loss: 37.2719, train_grp_loss: [11.8095428  13.07348486 10.72761371], val_grp_loss: [12.67401551 12.45051364 12.14665352], train_hist_grp_loss: [ 6.29085225  6.9380832  14.31236644], cur_train_grp_loss: [0.09447586 0.10458804 0.21455414], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6585, max_kl_dist_index: 0, max_train_grp_loss:  13.0735, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6740, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2146, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:11:31,678 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  66, train_loss:  12.1559, val_loss:  12.4240, grad_norm: 0.0013, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6585, 0.3061, 0.6515, param: [5.44637536 8.2891061  5.16122697 8.59797334], weights: [0.32347625 0.3256096  0.35091415], train_wt_loss:  36.4676, val_wt_loss: 37.2720, train_grp_loss: [11.80960294 13.0734654  10.72752019], val_grp_loss: [12.67412133 12.45049421 12.1466582 ], train_hist_grp_loss: [ 6.38532859  7.04267108 14.52691872], cur_train_grp_loss: [0.09447634 0.10458788 0.21455227], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6585, max_kl_dist_index: 0, max_train_grp_loss:  13.0735, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6741, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2146, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:11:32,691 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  67, train_loss:  12.1559, val_loss:  12.4240, grad_norm: 0.0014, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6585, 0.3061, 0.6515, param: [5.44643035 8.28894338 5.16149123 8.59837955], weights: [0.32332929 0.32549458 0.35117613], train_wt_loss:  36.4676, val_wt_loss: 37.2721, train_grp_loss: [11.80966288 13.07344624 10.72742657], val_grp_loss: [12.67422698 12.45047513 12.14666281], train_hist_grp_loss: [ 6.47980541  7.1472588  14.74146912], cur_train_grp_loss: [0.09447682 0.10458772 0.2145504 ], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6585, max_kl_dist_index: 0, max_train_grp_loss:  13.0734, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6742, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2146, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:11:33,729 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  68, train_loss:  12.1559, val_loss:  12.4241, grad_norm: 0.0014, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6586, 0.3061, 0.6515, param: [5.44648527 8.28878079 5.16175561 8.59878632], weights: [0.3231823  0.3253795  0.35143821], train_wt_loss:  36.4676, val_wt_loss: 37.2722, train_grp_loss: [11.80972261 13.07342738 10.72733283], val_grp_loss: [12.67433246 12.45045639 12.14666734], train_hist_grp_loss: [ 6.57428272  7.25184637 14.95601765], cur_train_grp_loss: [0.0944773  0.10458757 0.21454853], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6586, max_kl_dist_index: 0, max_train_grp_loss:  13.0734, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6743, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2145, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:11:34,750 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  69, train_loss:  12.1559, val_loss:  12.4241, grad_norm: 0.0014, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6586, 0.3062, 0.6515, param: [5.44654013 8.28861833 5.16202011 8.59919366], weights: [0.32303528 0.32526436 0.35170036], train_wt_loss:  36.4676, val_wt_loss: 37.2723, train_grp_loss: [11.80978214 13.07340883 10.72723898], val_grp_loss: [12.67443776 12.450438   12.14667179], train_hist_grp_loss: [ 6.6687605   7.35643379 15.17056431], cur_train_grp_loss: [0.09447778 0.10458742 0.21454666], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6586, max_kl_dist_index: 0, max_train_grp_loss:  13.0734, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6744, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2145, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:11:35,774 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  70, train_loss:  12.1559, val_loss:  12.4241, grad_norm: 0.0014, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6586, 0.3062, 0.6516, param: [5.44659491 8.288456   5.16228472 8.59960157], weights: [0.32288823 0.32514917 0.3519626 ], train_wt_loss:  36.4676, val_wt_loss: 37.2724, train_grp_loss: [11.80984145 13.07339059 10.72714502], val_grp_loss: [12.6745429  12.45041996 12.14667616], train_hist_grp_loss: [ 6.76323876  7.46102106 15.38510909], cur_train_grp_loss: [0.09447826 0.10458727 0.21454478], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6586, max_kl_dist_index: 0, max_train_grp_loss:  13.0734, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6745, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2145, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:11:36,816 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  71, train_loss:  12.1559, val_loss:  12.4242, grad_norm: 0.0014, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6587, 0.3062, 0.6516, param: [5.44664963 8.28829381 5.16254945 8.60001004], weights: [0.32274116 0.32503392 0.35222493], train_wt_loss:  36.4676, val_wt_loss: 37.2725, train_grp_loss: [11.80990056 13.07337264 10.72705095], val_grp_loss: [12.67464787 12.45040226 12.14668045], train_hist_grp_loss: [ 6.85771749  7.56560818 15.59965199], cur_train_grp_loss: [0.09447873 0.10458712 0.2145429 ], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6587, max_kl_dist_index: 0, max_train_grp_loss:  13.0734, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6746, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2145, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:11:37,812 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  72, train_loss:  12.1559, val_loss:  12.4242, grad_norm: 0.0015, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6587, 0.3062, 0.6516, param: [5.44670428 8.28813175 5.16281431 8.60041908], weights: [0.32259405 0.32491861 0.35248734], train_wt_loss:  36.4676, val_wt_loss: 37.2726, train_grp_loss: [11.80995947 13.07335501 10.72695677], val_grp_loss: [12.67475267 12.45038491 12.14668466], train_hist_grp_loss: [ 6.95219669  7.67019517 15.81419301], cur_train_grp_loss: [0.0944792  0.10458698 0.21454102], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6587, max_kl_dist_index: 0, max_train_grp_loss:  13.0734, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6748, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2145, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:11:38,812 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  73, train_loss:  12.1559, val_loss:  12.4242, grad_norm: 0.0015, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6587, 0.3062, 0.6516, param: [5.44675887 8.28796982 5.16307927 8.60082869], weights: [0.32244692 0.32480325 0.35274983], train_wt_loss:  36.4676, val_wt_loss: 37.2727, train_grp_loss: [11.81001816 13.07333767 10.72686247], val_grp_loss: [12.6748573  12.4503679  12.14668879], train_hist_grp_loss: [ 7.04667637  7.77478201 16.02873214], cur_train_grp_loss: [0.09447968 0.10458684 0.21453914], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6587, max_kl_dist_index: 0, max_train_grp_loss:  13.0733, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6749, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2145, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:11:39,832 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  74, train_loss:  12.1559, val_loss:  12.4243, grad_norm: 0.0015, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6587, 0.3062, 0.6517, param: [5.44681338 8.28780803 5.16334436 8.60123886], weights: [0.32229977 0.32468783 0.3530124 ], train_wt_loss:  36.4676, val_wt_loss: 37.2728, train_grp_loss: [11.81007665 13.07332064 10.72676807], val_grp_loss: [12.67496176 12.45035124 12.14669285], train_hist_grp_loss: [ 7.14115651  7.87936871 16.24326939], cur_train_grp_loss: [0.09448015 0.1045867  0.21453725], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6587, max_kl_dist_index: 0, max_train_grp_loss:  13.0733, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6750, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2145, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:11:40,853 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  75, train_loss:  12.1559, val_loss:  12.4243, grad_norm: 0.0015, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6588, 0.3062, 0.6517, param: [5.44686783 8.28764637 5.16360956 8.6016496 ], weights: [0.32215258 0.32457235 0.35327506], train_wt_loss:  36.4676, val_wt_loss: 37.2729, train_grp_loss: [11.81013494 13.07330392 10.72667355], val_grp_loss: [12.67506605 12.45033493 12.14669683], train_hist_grp_loss: [ 7.23563713  7.98395527 16.45780475], cur_train_grp_loss: [0.09448061 0.10458657 0.21453536], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6588, max_kl_dist_index: 0, max_train_grp_loss:  13.0733, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6751, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2145, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:11:41,882 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  76, train_loss:  12.1559, val_loss:  12.4243, grad_norm: 0.0016, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6588, 0.3063, 0.6517, param: [5.44692221 8.28748484 5.16387488 8.60206092], weights: [0.32200537 0.32445682 0.35353781], train_wt_loss:  36.4676, val_wt_loss: 37.2729, train_grp_loss: [11.81019301 13.0732875  10.72657892], val_grp_loss: [12.67517017 12.45031897 12.14670073], train_hist_grp_loss: [ 7.33011821  8.0885417  16.67233822], cur_train_grp_loss: [0.09448108 0.10458643 0.21453347], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6588, max_kl_dist_index: 0, max_train_grp_loss:  13.0733, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6752, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2145, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:11:42,887 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  77, train_loss:  12.1559, val_loss:  12.4243, grad_norm: 0.0016, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6588, 0.3063, 0.6517, param: [5.44697653 8.28732345 5.16414032 8.6024728 ], weights: [0.32185813 0.32434123 0.35380063], train_wt_loss:  36.4676, val_wt_loss: 37.2730, train_grp_loss: [11.81025088 13.07327139 10.72648418], val_grp_loss: [12.67527411 12.45030335 12.14670454], train_hist_grp_loss: [ 7.42459975  8.193128   16.8868698 ], cur_train_grp_loss: [0.09448154 0.1045863  0.21453158], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6588, max_kl_dist_index: 0, max_train_grp_loss:  13.0733, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6753, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2145, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:11:43,934 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  78, train_loss:  12.1559, val_loss:  12.4244, grad_norm: 0.0016, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6589, 0.3063, 0.6518, param: [5.44703077 8.28716218 5.16440588 8.60288524], weights: [0.32171087 0.32422559 0.35406354], train_wt_loss:  36.4676, val_wt_loss: 37.2731, train_grp_loss: [11.81030854 13.07325558 10.72638933], val_grp_loss: [12.67537789 12.45028808 12.14670829], train_hist_grp_loss: [ 7.51908176  8.29771417 17.10139949], cur_train_grp_loss: [0.09448201 0.10458617 0.21452968], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6589, max_kl_dist_index: 0, max_train_grp_loss:  13.0733, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6754, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2145, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:11:44,977 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  79, train_loss:  12.1559, val_loss:  12.4244, grad_norm: 0.0016, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6589, 0.3063, 0.6518, param: [5.44708495 8.28700105 5.16467156 8.60329826], weights: [0.32156357 0.32410989 0.35432653], train_wt_loss:  36.4677, val_wt_loss: 37.2732, train_grp_loss: [11.810366   13.07324008 10.72629436], val_grp_loss: [12.6754815  12.45027316 12.14671195], train_hist_grp_loss: [ 7.61356423  8.40230022 17.31592727], cur_train_grp_loss: [0.09448247 0.10458604 0.21452779], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6589, max_kl_dist_index: 0, max_train_grp_loss:  13.0732, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6755, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2145, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:11:45,989 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  80, train_loss:  12.1559, val_loss:  12.4244, grad_norm: 0.0016, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6589, 0.3063, 0.6518, param: [5.44713906 8.28684005 5.16493735 8.60371185], weights: [0.32141626 0.32399414 0.35458961], train_wt_loss:  36.4677, val_wt_loss: 37.2733, train_grp_loss: [11.81042325 13.07322488 10.72619929], val_grp_loss: [12.67558494 12.45025858 12.14671553], train_hist_grp_loss: [ 7.70804715  8.50688614 17.53045316], cur_train_grp_loss: [0.09448293 0.10458592 0.21452589], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6589, max_kl_dist_index: 0, max_train_grp_loss:  13.0732, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6756, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2145, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:11:47,009 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  81, train_loss:  12.1559, val_loss:  12.4245, grad_norm: 0.0017, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6589, 0.3063, 0.6519, param: [5.44719311 8.28667919 5.16520327 8.604126  ], weights: [0.32126891 0.32387833 0.35485277], train_wt_loss:  36.4677, val_wt_loss: 37.2734, train_grp_loss: [11.81048029 13.07320999 10.7261041 ], val_grp_loss: [12.67568821 12.45024435 12.14671904], train_hist_grp_loss: [ 7.80253054  8.61147194 17.74497715], cur_train_grp_loss: [0.09448339 0.1045858  0.21452399], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6589, max_kl_dist_index: 0, max_train_grp_loss:  13.0732, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6757, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2145, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:11:48,018 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  82, train_loss:  12.1559, val_loss:  12.4245, grad_norm: 0.0017, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6590, 0.3064, 0.6519, param: [5.44724708 8.28651845 5.1654693  8.60454073], weights: [0.32112153 0.32376246 0.35511601], train_wt_loss:  36.4677, val_wt_loss: 37.2735, train_grp_loss: [11.81053713 13.0731954  10.7260088 ], val_grp_loss: [12.67579131 12.45023047 12.14672247], train_hist_grp_loss: [ 7.89701438  8.71605762 17.95949923], cur_train_grp_loss: [0.09448384 0.10458568 0.21452208], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6590, max_kl_dist_index: 0, max_train_grp_loss:  13.0732, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6758, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2145, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:11:49,040 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  83, train_loss:  12.1559, val_loss:  12.4245, grad_norm: 0.0017, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6590, 0.3064, 0.6519, param: [5.44730099 8.28635785 5.16573545 8.60495602], weights: [0.32097413 0.32364654 0.35537933], train_wt_loss:  36.4677, val_wt_loss: 37.2736, train_grp_loss: [11.81059376 13.07318112 10.72591339], val_grp_loss: [12.67589424 12.45021694 12.14672582], train_hist_grp_loss: [ 7.99149868  8.82064318 18.1740194 ], cur_train_grp_loss: [0.0944843  0.10458556 0.21452018], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6590, max_kl_dist_index: 0, max_train_grp_loss:  13.0732, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6759, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2145, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:11:50,092 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  84, train_loss:  12.1559, val_loss:  12.4246, grad_norm: 0.0017, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6590, 0.3064, 0.6519, param: [5.44735483 8.28619738 5.16600172 8.60537189], weights: [0.32082671 0.32353056 0.35564273], train_wt_loss:  36.4677, val_wt_loss: 37.2737, train_grp_loss: [11.81065018 13.07316714 10.72581787], val_grp_loss: [12.675997   12.45020375 12.14672909], train_hist_grp_loss: [ 8.08598343  8.92522863 18.38853767], cur_train_grp_loss: [0.09448475 0.10458545 0.21451827], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6590, max_kl_dist_index: 0, max_train_grp_loss:  13.0732, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6760, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2145, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:11:51,126 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  85, train_loss:  12.1559, val_loss:  12.4246, grad_norm: 0.0018, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6591, 0.3064, 0.6520, param: [5.4474086  8.28603705 5.16626811 8.60578833], weights: [0.32067925 0.32341453 0.35590622], train_wt_loss:  36.4677, val_wt_loss: 37.2738, train_grp_loss: [11.8107064  13.07315347 10.72572224], val_grp_loss: [12.67609959 12.45019091 12.14673228], train_hist_grp_loss: [ 8.18046863  9.02981397 18.60305403], cur_train_grp_loss: [0.0944852  0.10458534 0.21451636], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6591, max_kl_dist_index: 0, max_train_grp_loss:  13.0732, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6761, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2145, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:11:52,158 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  86, train_loss:  12.1559, val_loss:  12.4246, grad_norm: 0.0018, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6591, 0.3064, 0.6520, param: [5.44746231 8.28587684 5.16653461 8.60620533], weights: [0.32053177 0.32329844 0.35616979], train_wt_loss:  36.4677, val_wt_loss: 37.2739, train_grp_loss: [11.81076241 13.07314011 10.72562649], val_grp_loss: [12.67620201 12.45017842 12.14673539], train_hist_grp_loss: [ 8.27495428  9.1343992  18.81756847], cur_train_grp_loss: [0.09448565 0.10458523 0.21451444], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6591, max_kl_dist_index: 0, max_train_grp_loss:  13.0731, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6762, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2145, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:11:53,184 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  87, train_loss:  12.1559, val_loss:  12.4247, grad_norm: 0.0018, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6591, 0.3064, 0.6520, param: [5.44751594 8.28571677 5.16680124 8.60662291], weights: [0.32038427 0.3231823  0.35643344], train_wt_loss:  36.4677, val_wt_loss: 37.2740, train_grp_loss: [11.81081821 13.07312705 10.72553063], val_grp_loss: [12.67630426 12.45016628 12.14673843], train_hist_grp_loss: [ 8.36944038  9.23898432 19.032081  ], cur_train_grp_loss: [0.0944861  0.10458512 0.21451253], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6591, max_kl_dist_index: 0, max_train_grp_loss:  13.0731, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6763, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2145, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:11:54,200 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  88, train_loss:  12.1559, val_loss:  12.4247, grad_norm: 0.0018, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6591, 0.3065, 0.6520, param: [5.44756951 8.28555682 5.16706798 8.60704106], weights: [0.32023673 0.3230661  0.35669717], train_wt_loss:  36.4677, val_wt_loss: 37.2741, train_grp_loss: [11.81087381 13.0731143  10.72543466], val_grp_loss: [12.67640634 12.45015449 12.14674139], train_hist_grp_loss: [ 8.46392693  9.34356933 19.24659162], cur_train_grp_loss: [0.09448655 0.10458502 0.21451061], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6591, max_kl_dist_index: 0, max_train_grp_loss:  13.0731, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6764, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2145, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:11:55,191 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  89, train_loss:  12.1559, val_loss:  12.4247, grad_norm: 0.0018, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6592, 0.3065, 0.6521, param: [5.44762301 8.28539701 5.16733485 8.60745978], weights: [0.32008917 0.32294984 0.35696098], train_wt_loss:  36.4677, val_wt_loss: 37.2742, train_grp_loss: [11.8109292  13.07310185 10.72533858], val_grp_loss: [12.67650826 12.45014304 12.14674427], train_hist_grp_loss: [ 8.55841392  9.44815425 19.46110031], cur_train_grp_loss: [0.09448699 0.10458491 0.21450869], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6592, max_kl_dist_index: 0, max_train_grp_loss:  13.0731, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6765, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2145, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:11:56,235 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  90, train_loss:  12.1559, val_loss:  12.4247, grad_norm: 0.0019, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6592, 0.3065, 0.6521, param: [5.44767644 8.28523733 5.16760183 8.60787907], weights: [0.31994159 0.32283353 0.35722488], train_wt_loss:  36.4677, val_wt_loss: 37.2742, train_grp_loss: [11.81098438 13.07308971 10.72524239], val_grp_loss: [12.67661    12.45013194 12.14674707], train_hist_grp_loss: [ 8.65290135  9.55273906 19.67560708], cur_train_grp_loss: [0.09448743 0.10458481 0.21450677], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6592, max_kl_dist_index: 0, max_train_grp_loss:  13.0731, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6766, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2145, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:11:57,258 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  91, train_loss:  12.1559, val_loss:  12.4248, grad_norm: 0.0019, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6592, 0.3065, 0.6521, param: [5.4477298  8.28507779 5.16786893 8.60829893], weights: [0.31979397 0.32271717 0.35748886], train_wt_loss:  36.4677, val_wt_loss: 37.2743, train_grp_loss: [11.81103936 13.07307788 10.72514609], val_grp_loss: [12.67671157 12.45012119 12.14674979], train_hist_grp_loss: [ 8.74738923  9.65732378 19.89011193], cur_train_grp_loss: [0.09448788 0.10458472 0.21450485], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6592, max_kl_dist_index: 0, max_train_grp_loss:  13.0731, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6767, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2145, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:11:58,287 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  92, train_loss:  12.1559, val_loss:  12.4248, grad_norm: 0.0019, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6593, 0.3065, 0.6521, param: [5.4477831  8.28491837 5.16813616 8.60871937], weights: [0.31964634 0.32260075 0.35775291], train_wt_loss:  36.4677, val_wt_loss: 37.2744, train_grp_loss: [11.81109413 13.07306635 10.72504967], val_grp_loss: [12.67681298 12.45011079 12.14675244], train_hist_grp_loss: [ 8.84187754  9.7619084  20.10461485], cur_train_grp_loss: [0.09448831 0.10458462 0.21450292], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6593, max_kl_dist_index: 0, max_train_grp_loss:  13.0731, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6768, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2145, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:11:59,291 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  93, train_loss:  12.1559, val_loss:  12.4248, grad_norm: 0.0019, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6593, 0.3065, 0.6522, param: [5.44783632 8.28475908 5.1684035  8.60914037], weights: [0.31949867 0.32248428 0.35801705], train_wt_loss:  36.4677, val_wt_loss: 37.2745, train_grp_loss: [11.81114869 13.07305513 10.72495314], val_grp_loss: [12.67691421 12.45010074 12.146755  ], train_hist_grp_loss: [ 8.93636629  9.86649293 20.31911584], cur_train_grp_loss: [0.09448875 0.10458453 0.21450099], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6593, max_kl_dist_index: 0, max_train_grp_loss:  13.0731, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6769, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2145, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:12:00,315 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  94, train_loss:  12.1559, val_loss:  12.4249, grad_norm: 0.0020, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6593, 0.3065, 0.6522, param: [5.44788948 8.28459993 5.16867096 8.60956195], weights: [0.31935098 0.32236775 0.35828127], train_wt_loss:  36.4677, val_wt_loss: 37.2746, train_grp_loss: [11.81120305 13.07304422 10.7248565 ], val_grp_loss: [12.67701527 12.45009104 12.14675749], train_hist_grp_loss: [ 9.03085548  9.97107737 20.53361491], cur_train_grp_loss: [0.09448919 0.10458444 0.21449906], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6593, max_kl_dist_index: 0, max_train_grp_loss:  13.0730, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6770, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2145, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:12:01,373 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  95, train_loss:  12.1559, val_loss:  12.4249, grad_norm: 0.0020, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6594, 0.3066, 0.6522, param: [5.44794257 8.28444091 5.16893854 8.60998411], weights: [0.31920326 0.32225117 0.35854557], train_wt_loss:  36.4677, val_wt_loss: 37.2747, train_grp_loss: [11.8112572  13.07303361 10.72475975], val_grp_loss: [12.67711617 12.45008168 12.1467599 ], train_hist_grp_loss: [ 9.12534511 10.07566173 20.74811204], cur_train_grp_loss: [0.09448962 0.10458435 0.21449713], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6594, max_kl_dist_index: 0, max_train_grp_loss:  13.0730, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6771, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2145, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:12:02,403 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  96, train_loss:  12.1559, val_loss:  12.4249, grad_norm: 0.0020, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6594, 0.3066, 0.6523, param: [5.44799559 8.28428201 5.16920624 8.61040683], weights: [0.31905552 0.32213453 0.35880995], train_wt_loss:  36.4677, val_wt_loss: 37.2748, train_grp_loss: [11.81131115 13.07302331 10.72466289], val_grp_loss: [12.67721689 12.45007268 12.14676224], train_hist_grp_loss: [ 9.21983516 10.180246   20.96260723], cur_train_grp_loss: [0.09449006 0.10458427 0.2144952 ], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6594, max_kl_dist_index: 0, max_train_grp_loss:  13.0730, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6772, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2145, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:12:03,424 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  97, train_loss:  12.1559, val_loss:  12.4250, grad_norm: 0.0020, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6594, 0.3066, 0.6523, param: [5.44804855 8.28412325 5.16947407 8.61083013], weights: [0.31890775 0.32201784 0.35907441], train_wt_loss:  36.4678, val_wt_loss: 37.2749, train_grp_loss: [11.81136489 13.07301332 10.72456591], val_grp_loss: [12.67731745 12.45006402 12.14676449], train_hist_grp_loss: [ 9.31432565 10.28483018 21.17710049], cur_train_grp_loss: [0.09449049 0.10458419 0.21449326], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6594, max_kl_dist_index: 0, max_train_grp_loss:  13.0730, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6773, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2145, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:12:04,463 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  98, train_loss:  12.1559, val_loss:  12.4250, grad_norm: 0.0020, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6594, 0.3066, 0.6523, param: [5.44810143 8.28396462 5.16974201 8.611254  ], weights: [0.31875996 0.32190109 0.35933895], train_wt_loss:  36.4678, val_wt_loss: 37.2750, train_grp_loss: [11.81141842 13.07300363 10.72446883], val_grp_loss: [12.67741784 12.45005571 12.14676667], train_hist_grp_loss: [ 9.40881657 10.38941429 21.39159181], cur_train_grp_loss: [0.09449092 0.10458411 0.21449132], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6594, max_kl_dist_index: 0, max_train_grp_loss:  13.0730, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6774, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2145, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:12:05,509 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  99, train_loss:  12.1559, val_loss:  12.4250, grad_norm: 0.0021, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6595, 0.3066, 0.6523, param: [5.44815425 8.28380612 5.17001007 8.61167845], weights: [0.31861214 0.32178429 0.35960357], train_wt_loss:  36.4678, val_wt_loss: 37.2751, train_grp_loss: [11.81147175 13.07299425 10.72437163], val_grp_loss: [12.67751806 12.45004776 12.14676877], train_hist_grp_loss: [ 9.50330792 10.49399832 21.60608118], cur_train_grp_loss: [0.09449135 0.10458403 0.21448938], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6595, max_kl_dist_index: 0, max_train_grp_loss:  13.0730, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6775, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2145, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:12:06,580 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  100, train_loss:  12.1559, val_loss:  12.4251, grad_norm: 0.0021, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6595, 0.3066, 0.6524, param: [5.44820699 8.28364775 5.17027825 8.61210347], weights: [0.3184643  0.32166743 0.35986827], train_wt_loss:  36.4678, val_wt_loss: 37.2752, train_grp_loss: [11.81152487 13.07298518 10.72427432], val_grp_loss: [12.6776181  12.45004015 12.14677079], train_hist_grp_loss: [ 9.59779969 10.59858227 21.82056862], cur_train_grp_loss: [0.09449177 0.10458395 0.21448743], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6595, max_kl_dist_index: 0, max_train_grp_loss:  13.0730, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6776, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2145, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:12:07,595 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  101, train_loss:  12.1559, val_loss:  12.4251, grad_norm: 0.0021, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6595, 0.3067, 0.6524, param: [5.44825967 8.28348951 5.17054655 8.61252906], weights: [0.31831642 0.32155052 0.36013305], train_wt_loss:  36.4678, val_wt_loss: 37.2753, train_grp_loss: [11.81157779 13.07297641 10.7241769 ], val_grp_loss: [12.67771798 12.45003289 12.14677274], train_hist_grp_loss: [ 9.69229189 10.70316615 22.0350541 ], cur_train_grp_loss: [0.0944922  0.10458388 0.21448549], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6595, max_kl_dist_index: 0, max_train_grp_loss:  13.0730, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6777, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2145, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:12:08,625 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  102, train_loss:  12.1559, val_loss:  12.4251, grad_norm: 0.0021, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6596, 0.3067, 0.6524, param: [5.44831228 8.2833314  5.17081497 8.61295523], weights: [0.31816853 0.32143356 0.36039791], train_wt_loss:  36.4678, val_wt_loss: 37.2754, train_grp_loss: [11.81163049 13.07296796 10.72407936], val_grp_loss: [12.67781769 12.45002598 12.1467746 ], train_hist_grp_loss: [ 9.78678452 10.80774997 22.24953764], cur_train_grp_loss: [0.09449262 0.10458381 0.21448354], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6596, max_kl_dist_index: 0, max_train_grp_loss:  13.0730, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6778, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2145, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:12:09,692 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  103, train_loss:  12.1559, val_loss:  12.4252, grad_norm: 0.0022, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6596, 0.3067, 0.6524, param: [5.44836482 8.28317342 5.17108352 8.61338197], weights: [0.31802061 0.32131654 0.36066285], train_wt_loss:  36.4678, val_wt_loss: 37.2755, train_grp_loss: [11.811683   13.07295981 10.72398172], val_grp_loss: [12.67791723 12.45001942 12.14677639], train_hist_grp_loss: [ 9.88127756 10.91233371 22.46401923], cur_train_grp_loss: [0.09449304 0.10458374 0.21448159], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6596, max_kl_dist_index: 0, max_train_grp_loss:  13.0730, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6779, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2145, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:12:10,733 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  104, train_loss:  12.1559, val_loss:  12.4252, grad_norm: 0.0022, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6596, 0.3067, 0.6525, param: [5.4484173  8.28301558 5.17135218 8.61380929], weights: [0.31787266 0.32119947 0.36092787], train_wt_loss:  36.4678, val_wt_loss: 37.2756, train_grp_loss: [11.8117353  13.07295196 10.72388396], val_grp_loss: [12.67801661 12.45001321 12.1467781 ], train_hist_grp_loss: [ 9.97577102 11.01691739 22.67849886], cur_train_grp_loss: [0.09449346 0.10458368 0.21447963], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6596, max_kl_dist_index: 0, max_train_grp_loss:  13.0730, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6780, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2145, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:12:11,768 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  105, train_loss:  12.1559, val_loss:  12.4252, grad_norm: 0.0022, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6596, 0.3067, 0.6525, param: [5.4484697  8.28285786 5.17162097 8.61423718], weights: [0.31772469 0.32108234 0.36119297], train_wt_loss:  36.4678, val_wt_loss: 37.2757, train_grp_loss: [11.81178739 13.07294443 10.72378609], val_grp_loss: [12.67811581 12.45000735 12.14677974], train_hist_grp_loss: [10.07026491 11.121501   22.89297654], cur_train_grp_loss: [0.09449388 0.10458362 0.21447768], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6596, max_kl_dist_index: 0, max_train_grp_loss:  13.0729, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6781, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2145, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:12:12,797 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  106, train_loss:  12.1559, val_loss:  12.4253, grad_norm: 0.0022, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6597, 0.3067, 0.6525, param: [5.44852203 8.28270027 5.17188987 8.61466565], weights: [0.31757669 0.32096516 0.36145815], train_wt_loss:  36.4678, val_wt_loss: 37.2758, train_grp_loss: [11.81183927 13.0729372  10.72368811], val_grp_loss: [12.67821484 12.45000184 12.14678129], train_hist_grp_loss: [10.1647592  11.22608456 23.10745226], cur_train_grp_loss: [0.0944943  0.10458356 0.21447572], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6597, max_kl_dist_index: 0, max_train_grp_loss:  13.0729, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6782, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2145, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:12:13,835 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  107, train_loss:  12.1559, val_loss:  12.4253, grad_norm: 0.0023, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6597, 0.3068, 0.6526, param: [5.4485743  8.28254281 5.1721589  8.61509469], weights: [0.31742867 0.32084793 0.3617234 ], train_wt_loss:  36.4678, val_wt_loss: 37.2759, train_grp_loss: [11.81189095 13.07293028 10.72359002], val_grp_loss: [12.67831371 12.44999668 12.14678277], train_hist_grp_loss: [10.25925392 11.33066806 23.32192603], cur_train_grp_loss: [0.09449471 0.1045835  0.21447376], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6597, max_kl_dist_index: 0, max_train_grp_loss:  13.0729, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6783, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2145, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:12:14,851 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  108, train_loss:  12.1559, val_loss:  12.4253, grad_norm: 0.0023, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6597, 0.3068, 0.6526, param: [5.4486265  8.28238548 5.17242804 8.61552431], weights: [0.31728062 0.32073064 0.36198874], train_wt_loss:  36.4678, val_wt_loss: 37.2759, train_grp_loss: [11.81194242 13.07292367 10.72349181], val_grp_loss: [12.6784124  12.44999187 12.14678417], train_hist_grp_loss: [10.35374905 11.4352515  23.53639783], cur_train_grp_loss: [0.09449513 0.10458344 0.2144718 ], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6597, max_kl_dist_index: 0, max_train_grp_loss:  13.0729, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6784, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2145, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:12:15,845 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  109, train_loss:  12.1559, val_loss:  12.4253, grad_norm: 0.0023, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6598, 0.3068, 0.6526, param: [5.44867862 8.28222828 5.17269731 8.6159545 ], weights: [0.31713255 0.3206133  0.36225415], train_wt_loss:  36.4678, val_wt_loss: 37.2760, train_grp_loss: [11.81199369 13.07291737 10.72339349], val_grp_loss: [12.67851093 12.44998741 12.1467855 ], train_hist_grp_loss: [10.44824459 11.53983489 23.75086766], cur_train_grp_loss: [0.09449554 0.10458339 0.21446984], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6598, max_kl_dist_index: 0, max_train_grp_loss:  13.0729, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6785, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2145, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:12:16,880 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  110, train_loss:  12.1559, val_loss:  12.4254, grad_norm: 0.0023, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6598, 0.3068, 0.6526, param: [5.44873068 8.28207122 5.1729667  8.61638527], weights: [0.31698445 0.3204959  0.36251965], train_wt_loss:  36.4678, val_wt_loss: 37.2761, train_grp_loss: [11.81204475 13.07291137 10.72329507], val_grp_loss: [12.67860928 12.4499833  12.14678674], train_hist_grp_loss: [10.54274054 11.64441823 23.96533553], cur_train_grp_loss: [0.09449595 0.10458334 0.21446787], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6598, max_kl_dist_index: 0, max_train_grp_loss:  13.0729, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6786, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2145, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:12:17,923 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  111, train_loss:  12.1559, val_loss:  12.4254, grad_norm: 0.0023, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6598, 0.3068, 0.6527, param: [5.44878267 8.28191428 5.17323621 8.61681662], weights: [0.31683633 0.32037846 0.36278522], train_wt_loss:  36.4678, val_wt_loss: 37.2762, train_grp_loss: [11.81209561 13.07290568 10.72319653], val_grp_loss: [12.67870747 12.44997954 12.14678791], train_hist_grp_loss: [10.63723689 11.74900152 24.17980143], cur_train_grp_loss: [0.09449636 0.10458329 0.2144659 ], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6598, max_kl_dist_index: 0, max_train_grp_loss:  13.0729, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6787, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2145, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:12:18,951 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  112, train_loss:  12.1560, val_loss:  12.4254, grad_norm: 0.0024, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6599, 0.3068, 0.6527, param: [5.44883459 8.28175747 5.17350584 8.61724855], weights: [0.31668818 0.32026095 0.36305087], train_wt_loss:  36.4679, val_wt_loss: 37.2763, train_grp_loss: [11.81214626 13.0729003  10.72309787], val_grp_loss: [12.67880549 12.44997613 12.146789  ], train_hist_grp_loss: [10.73173366 11.85358476 24.39426536], cur_train_grp_loss: [0.09449676 0.10458325 0.21446393], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6599, max_kl_dist_index: 0, max_train_grp_loss:  13.0729, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6788, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2145, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:12:19,984 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  113, train_loss:  12.1560, val_loss:  12.4255, grad_norm: 0.0024, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6599, 0.3069, 0.6527, param: [5.44888644 8.28160078 5.1737756  8.61768105], weights: [0.31654001 0.3201434  0.36331659], train_wt_loss:  36.4679, val_wt_loss: 37.2764, train_grp_loss: [11.81219671 13.07289523 10.72299911], val_grp_loss: [12.67890334 12.44997308 12.14679002], train_hist_grp_loss: [10.82623083 11.95816797 24.60872732], cur_train_grp_loss: [0.09449717 0.1045832  0.21446196], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6599, max_kl_dist_index: 0, max_train_grp_loss:  13.0729, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6789, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2145, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:12:21,015 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  114, train_loss:  12.1560, val_loss:  12.4255, grad_norm: 0.0024, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6599, 0.3069, 0.6527, param: [5.44893822 8.28144423 5.17404547 8.61811413], weights: [0.31639181 0.32002579 0.3635824 ], train_wt_loss:  36.4679, val_wt_loss: 37.2765, train_grp_loss: [11.81224695 13.07289047 10.72290023], val_grp_loss: [12.67900102 12.44997037 12.14679096], train_hist_grp_loss: [10.9207284  12.06275113 24.8231873 ], cur_train_grp_loss: [0.09449757 0.10458316 0.21445998], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6599, max_kl_dist_index: 0, max_train_grp_loss:  13.0729, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6790, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2145, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:12:22,087 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  115, train_loss:  12.1560, val_loss:  12.4255, grad_norm: 0.0024, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6600, 0.3069, 0.6528, param: [5.44898994 8.28128781 5.17431547 8.61854778], weights: [0.31624359 0.31990813 0.36384828], train_wt_loss:  36.4679, val_wt_loss: 37.2766, train_grp_loss: [11.81229698 13.07288602 10.72280124], val_grp_loss: [12.67909854 12.44996802 12.14679182], train_hist_grp_loss: [11.01522638 12.16733425 25.03764531], cur_train_grp_loss: [0.09449798 0.10458312 0.214458  ], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6600, max_kl_dist_index: 0, max_train_grp_loss:  13.0729, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6791, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2145, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:12:23,123 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  116, train_loss:  12.1560, val_loss:  12.4256, grad_norm: 0.0025, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6600, 0.3069, 0.6528, param: [5.44904158 8.28113152 5.17458559 8.61898202], weights: [0.31609535 0.31979041 0.36411424], train_wt_loss:  36.4679, val_wt_loss: 37.2767, train_grp_loss: [11.81234681 13.07288187 10.72270214], val_grp_loss: [12.67919588 12.44996601 12.1467926 ], train_hist_grp_loss: [11.10972475 12.27191734 25.25210133], cur_train_grp_loss: [0.09449838 0.10458309 0.21445602], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6600, max_kl_dist_index: 0, max_train_grp_loss:  13.0729, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6792, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2145, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:12:24,136 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  117, train_loss:  12.1560, val_loss:  12.4256, grad_norm: 0.0025, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6600, 0.3069, 0.6528, param: [5.44909315 8.28097535 5.17485583 8.61941683], weights: [0.31594708 0.31967265 0.36438028], train_wt_loss:  36.4679, val_wt_loss: 37.2768, train_grp_loss: [11.81239643 13.07287803 10.72260293], val_grp_loss: [12.67929306 12.44996436 12.1467933 ], train_hist_grp_loss: [11.20422353 12.3765004  25.46655538], cur_train_grp_loss: [0.09449877 0.10458305 0.21445404], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6600, max_kl_dist_index: 0, max_train_grp_loss:  13.0729, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6793, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2145, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:12:25,151 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  118, train_loss:  12.1560, val_loss:  12.4256, grad_norm: 0.0025, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6600, 0.3069, 0.6529, param: [5.44914466 8.28081932 5.17512619 8.61985222], weights: [0.31579878 0.31955482 0.36464639], train_wt_loss:  36.4679, val_wt_loss: 37.2769, train_grp_loss: [11.81244585 13.07287451 10.72250361], val_grp_loss: [12.67939006 12.44996306 12.14679393], train_hist_grp_loss: [11.2987227  12.48108342 25.68100743], cur_train_grp_loss: [0.09449917 0.10458302 0.21445206], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6600, max_kl_dist_index: 0, max_train_grp_loss:  13.0729, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6794, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2145, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:12:26,156 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  119, train_loss:  12.1560, val_loss:  12.4257, grad_norm: 0.0025, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6601, 0.3070, 0.6529, param: [5.44919609 8.28066341 5.17539667 8.62028818], weights: [0.31565046 0.31943695 0.36491258], train_wt_loss:  36.4679, val_wt_loss: 37.2770, train_grp_loss: [11.81249506 13.07287129 10.72240417], val_grp_loss: [12.6794869  12.44996211 12.14679448], train_hist_grp_loss: [11.39322227 12.58566642 25.89545751], cur_train_grp_loss: [0.09449957 0.104583   0.21445007], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6601, max_kl_dist_index: 0, max_train_grp_loss:  13.0729, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6795, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2145, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:12:27,231 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  120, train_loss:  12.1560, val_loss:  12.4257, grad_norm: 0.0026, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6601, 0.3070, 0.6529, param: [5.44924746 8.28050763 5.17566728 8.62072473], weights: [0.31550212 0.31931902 0.36517885], train_wt_loss:  36.4679, val_wt_loss: 37.2771, train_grp_loss: [11.81254406 13.07286838 10.72230462], val_grp_loss: [12.67958357 12.44996151 12.14679496], train_hist_grp_loss: [11.48772223 12.69024939 26.10990559], cur_train_grp_loss: [0.09449996 0.10458297 0.21444808], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6601, max_kl_dist_index: 0, max_train_grp_loss:  13.0729, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6796, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2144, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:12:28,229 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  121, train_loss:  12.1560, val_loss:  12.4257, grad_norm: 0.0026, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6601, 0.3070, 0.6529, param: [5.44929875 8.28035198 5.17593801 8.62116185], weights: [0.31535376 0.31920105 0.3654452 ], train_wt_loss:  36.4679, val_wt_loss: 37.2772, train_grp_loss: [11.81259287 13.07286578 10.72220497], val_grp_loss: [12.67968007 12.44996126 12.14679535], train_hist_grp_loss: [11.58222258 12.79483233 26.32435168], cur_train_grp_loss: [0.09450035 0.10458295 0.21444609], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6601, max_kl_dist_index: 0, max_train_grp_loss:  13.0729, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6797, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2144, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:12:29,249 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  122, train_loss:  12.1560, val_loss:  12.4258, grad_norm: 0.0026, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6602, 0.3070, 0.6530, param: [5.44934998 8.28019646 5.17620886 8.62159956], weights: [0.31520537 0.31908301 0.36571162], train_wt_loss:  36.4679, val_wt_loss: 37.2773, train_grp_loss: [11.81264146 13.07286348 10.72210519], val_grp_loss: [12.6797764  12.44996136 12.14679567], train_hist_grp_loss: [11.67672332 12.89941526 26.53879578], cur_train_grp_loss: [0.09450074 0.10458293 0.2144441 ], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6602, max_kl_dist_index: 0, max_train_grp_loss:  13.0729, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6798, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2144, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:12:30,261 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  123, train_loss:  12.1560, val_loss:  12.4258, grad_norm: 0.0026, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6602, 0.3070, 0.6530, param: [5.44940114 8.28004107 5.17647983 8.62203784], weights: [0.31505695 0.31896493 0.36597812], train_wt_loss:  36.4679, val_wt_loss: 37.2774, train_grp_loss: [11.81268985 13.0728615  10.72200531], val_grp_loss: [12.67987257 12.44996182 12.14679592], train_hist_grp_loss: [11.77122445 13.00399817 26.75323789], cur_train_grp_loss: [0.09450113 0.10458291 0.2144421 ], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6602, max_kl_dist_index: 0, max_train_grp_loss:  13.0729, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6799, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2144, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:12:31,315 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  124, train_loss:  12.1560, val_loss:  12.4258, grad_norm: 0.0027, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6602, 0.3070, 0.6530, param: [5.44945222 8.2798858  5.17675092 8.6224767 ], weights: [0.31490851 0.31884679 0.3662447 ], train_wt_loss:  36.4679, val_wt_loss: 37.2775, train_grp_loss: [11.81273804 13.07285983 10.72190531], val_grp_loss: [12.67996856 12.44996263 12.14679608], train_hist_grp_loss: [11.86572597 13.10858106 26.96767799], cur_train_grp_loss: [0.09450152 0.10458289 0.21444011], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6602, max_kl_dist_index: 0, max_train_grp_loss:  13.0729, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6800, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2144, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:12:32,334 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  125, train_loss:  12.1560, val_loss:  12.4259, grad_norm: 0.0027, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6603, 0.3071, 0.6531, param: [5.44950324 8.27973067 5.17702214 8.62291615], weights: [0.31476005 0.3187286  0.36651135], train_wt_loss:  36.4680, val_wt_loss: 37.2776, train_grp_loss: [11.81278602 13.07285847 10.72180521], val_grp_loss: [12.68006439 12.44996379 12.14679617], train_hist_grp_loss: [11.96022788 13.21316394 27.1821161 ], cur_train_grp_loss: [0.0945019  0.10458288 0.21443811], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6603, max_kl_dist_index: 0, max_train_grp_loss:  13.0729, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6801, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2144, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:12:33,365 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  126, train_loss:  12.1560, val_loss:  12.4259, grad_norm: 0.0027, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6603, 0.3071, 0.6531, param: [5.44955419 8.27957566 5.17729348 8.62335617], weights: [0.31461156 0.31861036 0.36677808], train_wt_loss:  36.4680, val_wt_loss: 37.2777, train_grp_loss: [11.81283379 13.07285741 10.72170499], val_grp_loss: [12.68016005 12.4499653  12.14679619], train_hist_grp_loss: [12.05473017 13.31774681 27.3965522 ], cur_train_grp_loss: [0.09450229 0.10458287 0.2144361 ], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6603, max_kl_dist_index: 0, max_train_grp_loss:  13.0729, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6802, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2144, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:12:34,400 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  127, train_loss:  12.1560, val_loss:  12.4259, grad_norm: 0.0027, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6603, 0.3071, 0.6531, param: [5.44960506 8.27942078 5.17756495 8.62379677], weights: [0.31446305 0.31849207 0.36704488], train_wt_loss:  36.4680, val_wt_loss: 37.2778, train_grp_loss: [11.81288136 13.07285667 10.72160466], val_grp_loss: [12.68025554 12.44996716 12.14679612], train_hist_grp_loss: [12.14923284 13.42232966 27.6109863 ], cur_train_grp_loss: [0.09450267 0.10458286 0.2144341 ], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6603, max_kl_dist_index: 0, max_train_grp_loss:  13.0729, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6803, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2144, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:12:35,397 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  128, train_loss:  12.1560, val_loss:  12.4260, grad_norm: 0.0028, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6603, 0.3071, 0.6531, param: [5.44965587 8.27926603 5.17783653 8.62423795], weights: [0.31431452 0.31837372 0.36731176], train_wt_loss:  36.4680, val_wt_loss: 37.2779, train_grp_loss: [11.81292872 13.07285623 10.72150421], val_grp_loss: [12.68035086 12.44996938 12.14679598], train_hist_grp_loss: [12.24373589 13.52691252 27.8254184 ], cur_train_grp_loss: [0.09450305 0.10458285 0.21443209], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6603, max_kl_dist_index: 0, max_train_grp_loss:  13.0729, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6804, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2144, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:12:36,426 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  129, train_loss:  12.1560, val_loss:  12.4260, grad_norm: 0.0028, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6604, 0.3071, 0.6532, param: [5.44970661 8.2791114  5.17810824 8.62467972], weights: [0.31416596 0.31825532 0.36757872], train_wt_loss:  36.4680, val_wt_loss: 37.2780, train_grp_loss: [11.81297588 13.07285611 10.72140366], val_grp_loss: [12.68044601 12.44997195 12.14679576], train_hist_grp_loss: [12.33823932 13.63149537 28.03984848], cur_train_grp_loss: [0.09450343 0.10458285 0.21443008], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6604, max_kl_dist_index: 0, max_train_grp_loss:  13.0729, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6804, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2144, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:12:37,427 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  130, train_loss:  12.1560, val_loss:  12.4260, grad_norm: 0.0028, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6604, 0.3071, 0.6532, param: [5.44975727 8.27895691 5.17838007 8.62512206], weights: [0.31401738 0.31813687 0.36784575], train_wt_loss:  36.4680, val_wt_loss: 37.2781, train_grp_loss: [11.81302284 13.07285629 10.72130299], val_grp_loss: [12.680541   12.44997487 12.14679547], train_hist_grp_loss: [12.43274312 13.73607822 28.25427655], cur_train_grp_loss: [0.09450381 0.10458285 0.21442807], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6604, max_kl_dist_index: 0, max_train_grp_loss:  13.0729, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6805, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2144, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:12:38,456 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  131, train_loss:  12.1560, val_loss:  12.4261, grad_norm: 0.0028, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6604, 0.3072, 0.6532, param: [5.44980787 8.27880254 5.17865203 8.62556499], weights: [0.31386878 0.31801837 0.36811285], train_wt_loss:  36.4680, val_wt_loss: 37.2782, train_grp_loss: [11.81306958 13.07285679 10.72120221], val_grp_loss: [12.68063581 12.44997814 12.1467951 ], train_hist_grp_loss: [12.52724731 13.84066107 28.46870261], cur_train_grp_loss: [0.09450418 0.10458285 0.21442606], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6604, max_kl_dist_index: 0, max_train_grp_loss:  13.0729, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6806, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2144, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:12:39,449 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  132, train_loss:  12.1560, val_loss:  12.4261, grad_norm: 0.0028, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6605, 0.3072, 0.6532, param: [5.4498584  8.2786483  5.1789241  8.62600849], weights: [0.31372015 0.31789981 0.36838003], train_wt_loss:  36.4680, val_wt_loss: 37.2783, train_grp_loss: [11.81311613 13.07285759 10.72110132], val_grp_loss: [12.68073046 12.44998177 12.14679465], train_hist_grp_loss: [12.62175186 13.94524392 28.68312666], cur_train_grp_loss: [0.09450456 0.10458285 0.21442404], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6605, max_kl_dist_index: 0, max_train_grp_loss:  13.0729, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6807, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2144, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:12:40,501 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  133, train_loss:  12.1560, val_loss:  12.4261, grad_norm: 0.0029, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6605, 0.3072, 0.6533, param: [5.44990885 8.27849418 5.17919631 8.62645258], weights: [0.3135715  0.31778121 0.36864729], train_wt_loss:  36.4680, val_wt_loss: 37.2784, train_grp_loss: [11.81316247 13.07285871 10.72100032], val_grp_loss: [12.68082494 12.44998575 12.14679413], train_hist_grp_loss: [12.71625679 14.04982678 28.89754868], cur_train_grp_loss: [0.09450493 0.10458286 0.21442203], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6605, max_kl_dist_index: 0, max_train_grp_loss:  13.0729, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6808, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2144, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:12:41,545 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  134, train_loss:  12.1560, val_loss:  12.4262, grad_norm: 0.0029, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6605, 0.3072, 0.6533, param: [5.44995924 8.2783402  5.17946863 8.62689725], weights: [0.31342283 0.31766255 0.36891462], train_wt_loss:  36.4680, val_wt_loss: 37.2785, train_grp_loss: [11.8132086  13.07286013 10.7208992 ], val_grp_loss: [12.68091925 12.44999008 12.14679352], train_hist_grp_loss: [12.81076209 14.15440965 29.11196869], cur_train_grp_loss: [0.0945053  0.10458287 0.21442001], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6605, max_kl_dist_index: 0, max_train_grp_loss:  13.0729, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6809, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2144, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:12:42,582 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  135, train_loss:  12.1560, val_loss:  12.4262, grad_norm: 0.0029, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6606, 0.3072, 0.6533, param: [5.45000956 8.27818634 5.17974108 8.6273425 ], weights: [0.31327413 0.31754384 0.36918203], train_wt_loss:  36.4680, val_wt_loss: 37.2786, train_grp_loss: [11.81325453 13.07286187 10.72079798], val_grp_loss: [12.6810134  12.44999477 12.14679285], train_hist_grp_loss: [12.90526776 14.25899253 29.32638667], cur_train_grp_loss: [0.09450567 0.10458288 0.21441798], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6606, max_kl_dist_index: 0, max_train_grp_loss:  13.0729, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6810, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2144, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:12:43,618 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  136, train_loss:  12.1560, val_loss:  12.4262, grad_norm: 0.0029, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6606, 0.3072, 0.6534, param: [5.4500598  8.2780326  5.18001365 8.62778834], weights: [0.31312541 0.31742508 0.36944951], train_wt_loss:  36.4681, val_wt_loss: 37.2787, train_grp_loss: [11.81330026 13.07286391 10.72069664], val_grp_loss: [12.68110737 12.44999981 12.14679209], train_hist_grp_loss: [12.9997738  14.36357543 29.54080263], cur_train_grp_loss: [0.09450604 0.10458289 0.21441596], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6606, max_kl_dist_index: 0, max_train_grp_loss:  13.0729, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6811, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2144, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:12:44,668 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  137, train_loss:  12.1560, val_loss:  12.4263, grad_norm: 0.0030, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6606, 0.3073, 0.6534, param: [5.45010998 8.277879   5.18028635 8.62823475], weights: [0.31297667 0.31730626 0.36971706], train_wt_loss:  36.4681, val_wt_loss: 37.2788, train_grp_loss: [11.81334577 13.07286627 10.72059519], val_grp_loss: [12.68120118 12.4500052  12.14679126], train_hist_grp_loss: [13.0942802  14.46815834 29.75521657], cur_train_grp_loss: [0.0945064  0.10458291 0.21441393], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6606, max_kl_dist_index: 0, max_train_grp_loss:  13.0729, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6812, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2144, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:12:45,704 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  138, train_loss:  12.1560, val_loss:  12.4263, grad_norm: 0.0030, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6607, 0.3073, 0.6534, param: [5.45016008 8.27772552 5.18055916 8.62868175], weights: [0.31282791 0.3171874  0.36998469], train_wt_loss:  36.4681, val_wt_loss: 37.2789, train_grp_loss: [11.81339109 13.07286893 10.72049362], val_grp_loss: [12.68129482 12.45001094 12.14679036], train_hist_grp_loss: [13.18878696 14.57274127 29.96962847], cur_train_grp_loss: [0.09450677 0.10458293 0.2144119 ], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6607, max_kl_dist_index: 0, max_train_grp_loss:  13.0729, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6813, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2144, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:12:46,730 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  139, train_loss:  12.1560, val_loss:  12.4263, grad_norm: 0.0030, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6607, 0.3073, 0.6535, param: [5.45021012 8.27757217 5.18083211 8.62912933], weights: [0.31267912 0.31706848 0.3702524 ], train_wt_loss:  36.4681, val_wt_loss: 37.2790, train_grp_loss: [11.8134362  13.07287191 10.72039195], val_grp_loss: [12.68138829 12.45001704 12.14678938], train_hist_grp_loss: [13.28329409 14.67732422 30.18403834], cur_train_grp_loss: [0.09450713 0.10458295 0.21440987], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6607, max_kl_dist_index: 0, max_train_grp_loss:  13.0729, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6814, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2144, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:12:47,767 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  140, train_loss:  12.1560, val_loss:  12.4264, grad_norm: 0.0030, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6607, 0.3073, 0.6535, param: [5.45026008 8.27741894 5.18110517 8.6295775 ], weights: [0.31253031 0.31694952 0.37052018], train_wt_loss:  36.4681, val_wt_loss: 37.2791, train_grp_loss: [11.81348111 13.0728752  10.72029016], val_grp_loss: [12.6814816  12.45002349 12.14678832], train_hist_grp_loss: [13.37780158 14.7819072  30.39844618], cur_train_grp_loss: [0.09450749 0.10458298 0.21440784], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6607, max_kl_dist_index: 0, max_train_grp_loss:  13.0729, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6815, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2144, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:12:48,779 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  141, train_loss:  12.1560, val_loss:  12.4264, grad_norm: 0.0031, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6607, 0.3073, 0.6535, param: [5.45030998 8.27726585 5.18137836 8.63002625], weights: [0.31238148 0.3168305  0.37078803], train_wt_loss:  36.4681, val_wt_loss: 37.2792, train_grp_loss: [11.81352581 13.0728788  10.72018827], val_grp_loss: [12.68157473 12.4500303  12.14678718], train_hist_grp_loss: [13.47230943 14.8864902  30.61285199], cur_train_grp_loss: [0.09450785 0.104583   0.2144058 ], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6607, max_kl_dist_index: 0, max_train_grp_loss:  13.0729, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6816, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2144, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:12:49,811 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  142, train_loss:  12.1560, val_loss:  12.4264, grad_norm: 0.0031, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6608, 0.3073, 0.6535, param: [5.4503598  8.27711287 5.18165168 8.63047558], weights: [0.31223262 0.31671143 0.37105595], train_wt_loss:  36.4681, val_wt_loss: 37.2793, train_grp_loss: [11.8135703  13.07288271 10.72008625], val_grp_loss: [12.6816677  12.45003746 12.14678597], train_hist_grp_loss: [13.56681764 14.99107323 30.82725575], cur_train_grp_loss: [0.09450821 0.10458303 0.21440377], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6608, max_kl_dist_index: 0, max_train_grp_loss:  13.0729, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6817, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2144, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:12:50,839 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  143, train_loss:  12.1560, val_loss:  12.4265, grad_norm: 0.0031, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6608, 0.3074, 0.6536, param: [5.45040955 8.27696003 5.18192512 8.63092549], weights: [0.31208374 0.31659231 0.37132395], train_wt_loss:  36.4681, val_wt_loss: 37.2794, train_grp_loss: [11.81361459 13.07288693 10.71998413], val_grp_loss: [12.6817605  12.45004497 12.14678468], train_hist_grp_loss: [13.6613262  15.09565629 31.04165748], cur_train_grp_loss: [0.09450856 0.10458306 0.21440173], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6608, max_kl_dist_index: 0, max_train_grp_loss:  13.0729, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6818, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2144, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:12:51,882 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  144, train_loss:  12.1560, val_loss:  12.4265, grad_norm: 0.0031, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6608, 0.3074, 0.6536, param: [5.45045923 8.27680731 5.18219868 8.63137599], weights: [0.31193484 0.31647314 0.37159202], train_wt_loss:  36.4681, val_wt_loss: 37.2795, train_grp_loss: [11.81365868 13.07289146 10.7198819 ], val_grp_loss: [12.68185313 12.45005284 12.14678332], train_hist_grp_loss: [13.75583512 15.20023938 31.25605716], cur_train_grp_loss: [0.09450892 0.1045831  0.21439968], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6608, max_kl_dist_index: 0, max_train_grp_loss:  13.0729, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6819, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2144, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:12:52,920 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  145, train_loss:  12.1560, val_loss:  12.4265, grad_norm: 0.0032, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6609, 0.3074, 0.6536, param: [5.45050884 8.27665472 5.18247237 8.63182708], weights: [0.31178592 0.31635391 0.37186017], train_wt_loss:  36.4681, val_wt_loss: 37.2796, train_grp_loss: [11.81370256 13.07289631 10.71977955], val_grp_loss: [12.68194559 12.45006106 12.14678188], train_hist_grp_loss: [13.85034439 15.30482252 31.4704548 ], cur_train_grp_loss: [0.09450927 0.10458313 0.21439764], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6609, max_kl_dist_index: 0, max_train_grp_loss:  13.0729, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6819, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2144, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:12:53,932 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  146, train_loss:  12.1560, val_loss:  12.4266, grad_norm: 0.0032, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6609, 0.3074, 0.6537, param: [5.45055838 8.27650225 5.18274618 8.63227874], weights: [0.31163697 0.31623464 0.37212839], train_wt_loss:  36.4681, val_wt_loss: 37.2797, train_grp_loss: [11.81374624 13.07290146 10.71967709], val_grp_loss: [12.68203789 12.45006964 12.14678037], train_hist_grp_loss: [13.94485401 15.40940569 31.68485039], cur_train_grp_loss: [0.09450962 0.10458317 0.21439559], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6609, max_kl_dist_index: 0, max_train_grp_loss:  13.0729, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6820, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2144, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:12:54,918 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  147, train_loss:  12.1561, val_loss:  12.4266, grad_norm: 0.0032, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6609, 0.3074, 0.6537, param: [5.45060785 8.27634991 5.18302011 8.632731  ], weights: [0.311488   0.31611532 0.37239668], train_wt_loss:  36.4682, val_wt_loss: 37.2798, train_grp_loss: [11.81378972 13.07290693 10.71957452], val_grp_loss: [12.68213002 12.45007857 12.14677877], train_hist_grp_loss: [14.03936398 15.5139889  31.89924393], cur_train_grp_loss: [0.09450997 0.10458321 0.21439354], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6609, max_kl_dist_index: 0, max_train_grp_loss:  13.0729, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6821, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2144, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:12:55,938 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  148, train_loss:  12.1561, val_loss:  12.4266, grad_norm: 0.0032, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6610, 0.3074, 0.6537, param: [5.45065725 8.27619769 5.18329418 8.63318384], weights: [0.31133901 0.31599594 0.37266504], train_wt_loss:  36.4682, val_wt_loss: 37.2799, train_grp_loss: [11.81383299 13.07291271 10.71947184], val_grp_loss: [12.68222198 12.45008785 12.14677711], train_hist_grp_loss: [14.13387429 15.61857215 32.11363542], cur_train_grp_loss: [0.09451032 0.10458326 0.21439149], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6610, max_kl_dist_index: 0, max_train_grp_loss:  13.0729, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6822, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2144, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:12:56,984 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  149, train_loss:  12.1561, val_loss:  12.4267, grad_norm: 0.0033, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6610, 0.3075, 0.6537, param: [5.45070658 8.27604561 5.18356836 8.63363726], weights: [0.31119    0.31587652 0.37293348], train_wt_loss:  36.4682, val_wt_loss: 37.2800, train_grp_loss: [11.81387605 13.0729188  10.71936905], val_grp_loss: [12.68231378 12.45009749 12.14677536], train_hist_grp_loss: [14.22838496 15.72315546 32.32802486], cur_train_grp_loss: [0.09451066 0.1045833  0.21438944], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6610, max_kl_dist_index: 0, max_train_grp_loss:  13.0729, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6823, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2144, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:12:58,018 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  150, train_loss:  12.1561, val_loss:  12.4267, grad_norm: 0.0033, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6610, 0.3075, 0.6538, param: [5.45075584 8.27589364 5.18384267 8.63409127], weights: [0.31104097 0.31575704 0.37320199], train_wt_loss:  36.4682, val_wt_loss: 37.2801, train_grp_loss: [11.81391891 13.0729252  10.71926614], val_grp_loss: [12.6824054  12.45010748 12.14677354], train_hist_grp_loss: [14.32289597 15.82773881 32.54241224], cur_train_grp_loss: [0.09451101 0.10458335 0.21438738], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6610, max_kl_dist_index: 0, max_train_grp_loss:  13.0729, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6824, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2144, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:12:59,038 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  151, train_loss:  12.1561, val_loss:  12.4267, grad_norm: 0.0033, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6611, 0.3075, 0.6538, param: [5.45080502 8.2757418  5.18411711 8.63454586], weights: [0.31089191 0.31563752 0.37347057], train_wt_loss:  36.4682, val_wt_loss: 37.2802, train_grp_loss: [11.81396157 13.07293191 10.71916312], val_grp_loss: [12.68249686 12.45011783 12.14677165], train_hist_grp_loss: [14.41740732 15.93232221 32.75679756], cur_train_grp_loss: [0.09451135 0.1045834  0.21438532], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6611, max_kl_dist_index: 0, max_train_grp_loss:  13.0729, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6825, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2144, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:13:00,084 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  152, train_loss:  12.1561, val_loss:  12.4268, grad_norm: 0.0033, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6611, 0.3075, 0.6538, param: [5.45085414 8.27559009 5.18439167 8.63500104], weights: [0.31074284 0.31551794 0.37373922], train_wt_loss:  36.4682, val_wt_loss: 37.2803, train_grp_loss: [11.81400402 13.07293894 10.71905999], val_grp_loss: [12.68258815 12.45012853 12.14676968], train_hist_grp_loss: [14.51191901 16.03690566 32.97118082], cur_train_grp_loss: [0.09451169 0.10458346 0.21438326], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6611, max_kl_dist_index: 0, max_train_grp_loss:  13.0729, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6826, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2144, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:13:01,107 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  153, train_loss:  12.1561, val_loss:  12.4268, grad_norm: 0.0034, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6611, 0.3075, 0.6539, param: [5.45090318 8.27543851 5.18466635 8.63545681], weights: [0.31059374 0.31539831 0.37400795], train_wt_loss:  36.4682, val_wt_loss: 37.2804, train_grp_loss: [11.81404627 13.07294627 10.71895675], val_grp_loss: [12.68267927 12.45013959 12.14676763], train_hist_grp_loss: [14.60643104 16.14148917 33.18556202], cur_train_grp_loss: [0.09451203 0.10458351 0.2143812 ], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6611, max_kl_dist_index: 0, max_train_grp_loss:  13.0729, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6827, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2144, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:13:02,177 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  154, train_loss:  12.1561, val_loss:  12.4268, grad_norm: 0.0034, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6612, 0.3075, 0.6539, param: [5.45095215 8.27528704 5.18494116 8.63591316], weights: [0.31044462 0.31527864 0.37427675], train_wt_loss:  36.4682, val_wt_loss: 37.2805, train_grp_loss: [11.81408832 13.07295392 10.71885339], val_grp_loss: [12.68277023 12.450151   12.14676551], train_hist_grp_loss: [14.70094341 16.24607274 33.39994116], cur_train_grp_loss: [0.09451237 0.10458357 0.21437913], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6612, max_kl_dist_index: 0, max_train_grp_loss:  13.0730, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6828, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2144, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:13:03,195 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  155, train_loss:  12.1561, val_loss:  12.4269, grad_norm: 0.0034, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6612, 0.3076, 0.6539, param: [5.45100105 8.27513571 5.1852161  8.6363701 ], weights: [0.31029547 0.31515891 0.37454562], train_wt_loss:  36.4682, val_wt_loss: 37.2806, train_grp_loss: [11.81413016 13.07296188 10.71874993], val_grp_loss: [12.68286102 12.45016277 12.14676331], train_hist_grp_loss: [14.79545612 16.35065638 33.61431822], cur_train_grp_loss: [0.09451271 0.10458363 0.21437707], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6612, max_kl_dist_index: 0, max_train_grp_loss:  13.0730, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6829, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2144, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:13:04,239 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  156, train_loss:  12.1561, val_loss:  12.4269, grad_norm: 0.0034, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6612, 0.3076, 0.6539, param: [5.45104988 8.2749845  5.18549116 8.63682762], weights: [0.31014631 0.31503913 0.37481456], train_wt_loss:  36.4683, val_wt_loss: 37.2807, train_grp_loss: [11.81417179 13.07297016 10.71864635], val_grp_loss: [12.68295164 12.4501749  12.14676104], train_hist_grp_loss: [14.88996916 16.45524007 33.82869322], cur_train_grp_loss: [0.09451304 0.1045837  0.214375  ], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6612, max_kl_dist_index: 0, max_train_grp_loss:  13.0730, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6830, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2144, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:13:05,270 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  157, train_loss:  12.1561, val_loss:  12.4269, grad_norm: 0.0035, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6613, 0.3076, 0.6540, param: [5.45109864 8.27483341 5.18576634 8.63728573], weights: [0.30999712 0.31491931 0.37508357], train_wt_loss:  36.4683, val_wt_loss: 37.2808, train_grp_loss: [11.81421323 13.07297874 10.71854266], val_grp_loss: [12.68304209 12.45018737 12.14675869], train_hist_grp_loss: [14.98448254 16.55982383 34.04306615], cur_train_grp_loss: [0.09451337 0.10458376 0.21437293], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6613, max_kl_dist_index: 0, max_train_grp_loss:  13.0730, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6830, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2144, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:13:06,290 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  158, train_loss:  12.1561, val_loss:  12.4270, grad_norm: 0.0035, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6613, 0.3076, 0.6540, param: [5.45114733 8.27468245 5.18604165 8.63774443], weights: [0.30984792 0.31479943 0.37535265], train_wt_loss:  36.4683, val_wt_loss: 37.2809, train_grp_loss: [11.81425446 13.07298764 10.71843886], val_grp_loss: [12.68313238 12.45020021 12.14675627], train_hist_grp_loss: [15.07899624 16.66440766 34.257437  ], cur_train_grp_loss: [0.09451371 0.10458383 0.21437085], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6613, max_kl_dist_index: 0, max_train_grp_loss:  13.0730, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6831, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2144, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:13:07,322 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  159, train_loss:  12.1561, val_loss:  12.4270, grad_norm: 0.0035, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6613, 0.3076, 0.6540, param: [5.45119594 8.27453161 5.18631709 8.63820372], weights: [0.30969869 0.3146795  0.37562181], train_wt_loss:  36.4683, val_wt_loss: 37.2810, train_grp_loss: [11.81429548 13.07299685 10.71833494], val_grp_loss: [12.6832225  12.4502134  12.14675377], train_hist_grp_loss: [15.17351028 16.76899156 34.47180578], cur_train_grp_loss: [0.09451404 0.1045839  0.21436878], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6613, max_kl_dist_index: 0, max_train_grp_loss:  13.0730, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6832, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2144, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:13:08,351 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  160, train_loss:  12.1561, val_loss:  12.4270, grad_norm: 0.0035, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6614, 0.3077, 0.6541, param: [5.45124449 8.2743809  5.18659265 8.63866359], weights: [0.30954944 0.31455953 0.37589103], train_wt_loss:  36.4683, val_wt_loss: 37.2811, train_grp_loss: [11.8143363  13.07300637 10.71823092], val_grp_loss: [12.68331245 12.45022694 12.14675119], train_hist_grp_loss: [15.26802464 16.87357554 34.68617248], cur_train_grp_loss: [0.09451436 0.10458397 0.2143667 ], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6614, max_kl_dist_index: 0, max_train_grp_loss:  13.0730, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6833, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2144, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:13:09,360 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  161, train_loss:  12.1561, val_loss:  12.4271, grad_norm: 0.0036, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6614, 0.3077, 0.6541, param: [5.45129296 8.27423032 5.18686834 8.63912405], weights: [0.30940017 0.3144395  0.37616033], train_wt_loss:  36.4683, val_wt_loss: 37.2812, train_grp_loss: [11.81437692 13.07301621 10.71812678], val_grp_loss: [12.68340224 12.45024084 12.14674854], train_hist_grp_loss: [15.36253933 16.97815959 34.9005371 ], cur_train_grp_loss: [0.09451469 0.10458405 0.21436462], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6614, max_kl_dist_index: 0, max_train_grp_loss:  13.0730, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6834, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2144, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:13:10,373 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  162, train_loss:  12.1561, val_loss:  12.4271, grad_norm: 0.0036, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6614, 0.3077, 0.6541, param: [5.45134136 8.27407985 5.18714416 8.6395851 ], weights: [0.30925088 0.31431942 0.3764297 ], train_wt_loss:  36.4683, val_wt_loss: 37.2813, train_grp_loss: [11.81441733 13.07302636 10.71802253], val_grp_loss: [12.68349185 12.4502551  12.14674582], train_hist_grp_loss: [15.45705435 17.08274372 35.11489963], cur_train_grp_loss: [0.09451502 0.10458413 0.21436254], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6614, max_kl_dist_index: 0, max_train_grp_loss:  13.0730, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6835, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2144, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:13:11,394 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  163, train_loss:  12.1561, val_loss:  12.4271, grad_norm: 0.0036, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6614, 0.3077, 0.6542, param: [5.45138969 8.27392951 5.1874201  8.64004674], weights: [0.30910157 0.3141993  0.37669913], train_wt_loss:  36.4683, val_wt_loss: 37.2814, train_grp_loss: [11.81445754 13.07303682 10.71791817], val_grp_loss: [12.68358131 12.45026971 12.14674302], train_hist_grp_loss: [15.55156969 17.18732793 35.32926008], cur_train_grp_loss: [0.09451534 0.10458421 0.21436045], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6614, max_kl_dist_index: 0, max_train_grp_loss:  13.0730, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6836, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2144, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:13:12,451 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  164, train_loss:  12.1561, val_loss:  12.4272, grad_norm: 0.0037, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6615, 0.3077, 0.6542, param: [5.45143795 8.2737793  5.18769616 8.64050897], weights: [0.30895223 0.31407913 0.37696864], train_wt_loss:  36.4683, val_wt_loss: 37.2815, train_grp_loss: [11.81449755 13.07304759 10.7178137 ], val_grp_loss: [12.68367059 12.45028468 12.14674014], train_hist_grp_loss: [15.64608535 17.29191222 35.54361845], cur_train_grp_loss: [0.09451566 0.10458429 0.21435836], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6615, max_kl_dist_index: 0, max_train_grp_loss:  13.0730, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6837, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2144, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:13:13,508 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  165, train_loss:  12.1561, val_loss:  12.4272, grad_norm: 0.0037, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6615, 0.3077, 0.6542, param: [5.45148613 8.27362921 5.18797235 8.64097178], weights: [0.30880288 0.3139589  0.37723822], train_wt_loss:  36.4683, val_wt_loss: 37.2816, train_grp_loss: [11.81453735 13.07305868 10.71770911], val_grp_loss: [12.68375971 12.45030001 12.14673719], train_hist_grp_loss: [15.74060133 17.39649661 35.75797472], cur_train_grp_loss: [0.09451598 0.10458438 0.21435627], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6615, max_kl_dist_index: 0, max_train_grp_loss:  13.0731, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6838, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2144, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:13:14,556 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  166, train_loss:  12.1561, val_loss:  12.4272, grad_norm: 0.0037, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6615, 0.3078, 0.6542, param: [5.45153425 8.27347925 5.18824867 8.64143519], weights: [0.3086535  0.31383863 0.37750787], train_wt_loss:  36.4684, val_wt_loss: 37.2817, train_grp_loss: [11.81457695 13.07307008 10.71760441], val_grp_loss: [12.68384866 12.45031569 12.14673416], train_hist_grp_loss: [15.83511762 17.50108107 35.9723289 ], cur_train_grp_loss: [0.0945163  0.10458447 0.21435418], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6615, max_kl_dist_index: 0, max_train_grp_loss:  13.0731, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6838, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2144, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:13:15,565 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  167, train_loss:  12.1561, val_loss:  12.4273, grad_norm: 0.0037, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6616, 0.3078, 0.6543, param: [5.45158229 8.2733294  5.18852512 8.64189918], weights: [0.30850411 0.31371831 0.37777759], train_wt_loss:  36.4684, val_wt_loss: 37.2818, train_grp_loss: [11.81461635 13.07308179 10.7174996 ], val_grp_loss: [12.68393744 12.45033172 12.14673106], train_hist_grp_loss: [15.92963424 17.60566564 36.18668099], cur_train_grp_loss: [0.09451662 0.10458456 0.21435209], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6616, max_kl_dist_index: 0, max_train_grp_loss:  13.0731, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6839, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2144, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:13:16,608 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  168, train_loss:  12.1561, val_loss:  12.4273, grad_norm: 0.0038, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6616, 0.3078, 0.6543, param: [5.45163026 8.27317969 5.18880169 8.64236376], weights: [0.30835469 0.31359794 0.37804737], train_wt_loss:  36.4684, val_wt_loss: 37.2819, train_grp_loss: [11.81465554 13.07309382 10.71739468], val_grp_loss: [12.68402605 12.45034812 12.14672788], train_hist_grp_loss: [16.02415117 17.71025029 36.40103098], cur_train_grp_loss: [0.09451693 0.10458465 0.21434999], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6616, max_kl_dist_index: 0, max_train_grp_loss:  13.0731, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6840, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2143, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:13:17,619 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  169, train_loss:  12.1561, val_loss:  12.4273, grad_norm: 0.0038, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6616, 0.3078, 0.6543, param: [5.45167816 8.27303009 5.18907838 8.64282893], weights: [0.30820525 0.31347752 0.37831723], train_wt_loss:  36.4684, val_wt_loss: 37.2820, train_grp_loss: [11.81469453 13.07310616 10.71728965], val_grp_loss: [12.6841145  12.45036487 12.14672463], train_hist_grp_loss: [16.11866842 17.81483504 36.61537888], cur_train_grp_loss: [0.09451724 0.10458475 0.21434789], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6616, max_kl_dist_index: 0, max_train_grp_loss:  13.0731, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6841, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2143, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:13:18,652 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  170, train_loss:  12.1561, val_loss:  12.4274, grad_norm: 0.0038, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6617, 0.3078, 0.6544, param: [5.45172599 8.27288062 5.18935521 8.6432947 ], weights: [0.3080558  0.31335705 0.37858716], train_wt_loss:  36.4684, val_wt_loss: 37.2821, train_grp_loss: [11.81473332 13.07311881 10.7171845 ], val_grp_loss: [12.68420279 12.45038198 12.14672131], train_hist_grp_loss: [16.21318597 17.91941989 36.82972467], cur_train_grp_loss: [0.09451756 0.10458485 0.21434579], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6617, max_kl_dist_index: 0, max_train_grp_loss:  13.0731, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6842, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2143, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:13:19,688 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  171, train_loss:  12.1561, val_loss:  12.4274, grad_norm: 0.0038, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6617, 0.3078, 0.6544, param: [5.45177374 8.27273128 5.18963216 8.64376105], weights: [0.30790632 0.31323653 0.37885715], train_wt_loss:  36.4684, val_wt_loss: 37.2822, train_grp_loss: [11.8147719  13.07313178 10.71707925], val_grp_loss: [12.6842909  12.45039944 12.1467179 ], train_hist_grp_loss: [16.30770384 18.02400484 37.04406836], cur_train_grp_loss: [0.09451787 0.10458495 0.21434369], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6617, max_kl_dist_index: 0, max_train_grp_loss:  13.0731, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6843, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2143, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:13:20,722 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  172, train_loss:  12.1561, val_loss:  12.4274, grad_norm: 0.0039, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6617, 0.3079, 0.6544, param: [5.45182142 8.27258205 5.18990924 8.64422799], weights: [0.30775682 0.31311596 0.37912722], train_wt_loss:  36.4684, val_wt_loss: 37.2823, train_grp_loss: [11.81481028 13.07314506 10.71697388], val_grp_loss: [12.68437885 12.45041726 12.14671443], train_hist_grp_loss: [16.40222201 18.12858989 37.25840995], cur_train_grp_loss: [0.09451818 0.10458505 0.21434158], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6617, max_kl_dist_index: 0, max_train_grp_loss:  13.0731, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6844, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2143, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:13:21,770 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  173, train_loss:  12.1561, val_loss:  12.4275, grad_norm: 0.0039, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6618, 0.3079, 0.6545, param: [5.45186904 8.27243295 5.19018644 8.64469552], weights: [0.3076073  0.31299535 0.37939735], train_wt_loss:  36.4684, val_wt_loss: 37.2824, train_grp_loss: [11.81484845 13.07315866 10.7168684 ], val_grp_loss: [12.68446663 12.45043544 12.14671088], train_hist_grp_loss: [16.4967405  18.23317505 37.47274942], cur_train_grp_loss: [0.09451848 0.10458516 0.21433948], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6618, max_kl_dist_index: 0, max_train_grp_loss:  13.0732, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6845, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2143, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:13:22,807 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  174, train_loss:  12.1562, val_loss:  12.4275, grad_norm: 0.0039, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6618, 0.3079, 0.6545, param: [5.45191657 8.27228398 5.19046377 8.64516364], weights: [0.30745777 0.31287468 0.37966755], train_wt_loss:  36.4685, val_wt_loss: 37.2825, train_grp_loss: [11.81488643 13.07317257 10.7167628 ], val_grp_loss: [12.68455425 12.45045397 12.14670725], train_hist_grp_loss: [16.59125928 18.33776032 37.68708679], cur_train_grp_loss: [0.09451879 0.10458527 0.21433737], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6618, max_kl_dist_index: 0, max_train_grp_loss:  13.0732, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6846, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2143, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:13:23,840 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  175, train_loss:  12.1562, val_loss:  12.4275, grad_norm: 0.0039, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6618, 0.3079, 0.6545, param: [5.45196404 8.27213512 5.19074123 8.64563236], weights: [0.30730821 0.31275397 0.37993782], train_wt_loss:  36.4685, val_wt_loss: 37.2826, train_grp_loss: [11.8149242  13.07318679 10.7166571 ], val_grp_loss: [12.6846417  12.45047286 12.14670355], train_hist_grp_loss: [16.68577837 18.4423457  37.90142205], cur_train_grp_loss: [0.09451909 0.10458538 0.21433526], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6618, max_kl_dist_index: 0, max_train_grp_loss:  13.0732, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6846, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2143, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:13:24,874 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  176, train_loss:  12.1562, val_loss:  12.4276, grad_norm: 0.0040, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6619, 0.3079, 0.6546, param: [5.45201143 8.27198639 5.19101881 8.64610166], weights: [0.30715863 0.31263321 0.38020816], train_wt_loss:  36.4685, val_wt_loss: 37.2827, train_grp_loss: [11.81496176 13.07320132 10.71655128], val_grp_loss: [12.68472898 12.45049211 12.14669977], train_hist_grp_loss: [16.78029777 18.5469312  38.11575519], cur_train_grp_loss: [0.09451939 0.10458549 0.21433314], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6619, max_kl_dist_index: 0, max_train_grp_loss:  13.0732, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6847, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2143, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:13:25,924 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  177, train_loss:  12.1562, val_loss:  12.4276, grad_norm: 0.0040, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6619, 0.3079, 0.6546, param: [5.45205876 8.27183778 5.19129652 8.64657156], weights: [0.30700903 0.3125124  0.38047857], train_wt_loss:  36.4685, val_wt_loss: 37.2828, train_grp_loss: [11.81499913 13.07321617 10.71644535], val_grp_loss: [12.68481609 12.45051172 12.14669592], train_hist_grp_loss: [16.87481746 18.65151681 38.33008622], cur_train_grp_loss: [0.09451969 0.10458561 0.21433103], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6619, max_kl_dist_index: 0, max_train_grp_loss:  13.0732, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6848, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2143, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:13:26,981 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  178, train_loss:  12.1562, val_loss:  12.4276, grad_norm: 0.0040, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6619, 0.3080, 0.6546, param: [5.452106   8.2716893  5.19157436 8.64704205], weights: [0.30685941 0.31239154 0.38074904], train_wt_loss:  36.4685, val_wt_loss: 37.2829, train_grp_loss: [11.81503629 13.07323134 10.71633931], val_grp_loss: [12.68490304 12.45053168 12.146692  ], train_hist_grp_loss: [16.96933746 18.75610254 38.54441512], cur_train_grp_loss: [0.09451999 0.10458573 0.21432891], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6619, max_kl_dist_index: 0, max_train_grp_loss:  13.0732, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6849, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2143, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:13:28,029 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  179, train_loss:  12.1562, val_loss:  12.4277, grad_norm: 0.0040, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6620, 0.3080, 0.6546, param: [5.45215318 8.27154094 5.19185233 8.64751313], weights: [0.30670977 0.31227064 0.38101959], train_wt_loss:  36.4685, val_wt_loss: 37.2830, train_grp_loss: [11.81507325 13.07324682 10.71623316], val_grp_loss: [12.68498983 12.45055201 12.146688  ], train_hist_grp_loss: [17.06385775 18.86068839 38.75874191], cur_train_grp_loss: [0.09452029 0.10458585 0.21432679], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6620, max_kl_dist_index: 0, max_train_grp_loss:  13.0732, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6850, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2143, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:13:29,039 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  180, train_loss:  12.1562, val_loss:  12.4277, grad_norm: 0.0041, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6620, 0.3080, 0.6547, param: [5.45220029 8.2713927  5.19213042 8.6479848 ], weights: [0.30656012 0.31214969 0.3812902 ], train_wt_loss:  36.4685, val_wt_loss: 37.2831, train_grp_loss: [11.81511    13.07326261 10.7161269 ], val_grp_loss: [12.68507644 12.45057268 12.14668393], train_hist_grp_loss: [17.15837833 18.96527436 38.97306657], cur_train_grp_loss: [0.09452059 0.10458597 0.21432466], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6620, max_kl_dist_index: 0, max_train_grp_loss:  13.0733, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6851, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2143, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:13:30,049 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  181, train_loss:  12.1562, val_loss:  12.4277, grad_norm: 0.0041, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6620, 0.3080, 0.6547, param: [5.45224732 8.27124458 5.19240864 8.64845706], weights: [0.30641044 0.31202868 0.38156088], train_wt_loss:  36.4685, val_wt_loss: 37.2832, train_grp_loss: [11.81514655 13.07327872 10.71602052], val_grp_loss: [12.68516289 12.45059372 12.14667978], train_hist_grp_loss: [17.25289921 19.06986046 39.18738911], cur_train_grp_loss: [0.09452088 0.1045861  0.21432254], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6620, max_kl_dist_index: 0, max_train_grp_loss:  13.0733, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6852, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2143, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:13:31,065 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  182, train_loss:  12.1562, val_loss:  12.4278, grad_norm: 0.0041, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6621, 0.3080, 0.6547, param: [5.45229428 8.27109659 5.19268699 8.64892992], weights: [0.30626074 0.31190764 0.38183162], train_wt_loss:  36.4686, val_wt_loss: 37.2833, train_grp_loss: [11.8151829  13.07329514 10.71591403], val_grp_loss: [12.68524918 12.45061512 12.14667556], train_hist_grp_loss: [17.34742038 19.17444669 39.40170952], cur_train_grp_loss: [0.09452117 0.10458623 0.21432041], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6621, max_kl_dist_index: 0, max_train_grp_loss:  13.0733, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6852, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2143, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:13:32,102 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  183, train_loss:  12.1562, val_loss:  12.4278, grad_norm: 0.0042, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6621, 0.3081, 0.6548, param: [5.45234116 8.27094871 5.19296547 8.64940336], weights: [0.30611103 0.31178654 0.38210244], train_wt_loss:  36.4686, val_wt_loss: 37.2834, train_grp_loss: [11.81521905 13.07331188 10.71580743], val_grp_loss: [12.68533529 12.45063687 12.14667126], train_hist_grp_loss: [17.44194185 19.27903306 39.6160278 ], cur_train_grp_loss: [0.09452146 0.10458636 0.21431828], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6621, max_kl_dist_index: 0, max_train_grp_loss:  13.0733, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6853, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2143, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:13:33,142 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  184, train_loss:  12.1562, val_loss:  12.4278, grad_norm: 0.0042, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6621, 0.3081, 0.6548, param: [5.45238798 8.27080096 5.19324407 8.6498774 ], weights: [0.30596129 0.31166539 0.38237332], train_wt_loss:  36.4686, val_wt_loss: 37.2835, train_grp_loss: [11.81525499 13.07332893 10.71570072], val_grp_loss: [12.68542124 12.45065898 12.14666689], train_hist_grp_loss: [17.5364636  19.38361955 39.83034395], cur_train_grp_loss: [0.09452175 0.1045865  0.21431615], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6621, max_kl_dist_index: 0, max_train_grp_loss:  13.0733, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6854, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2143, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:13:34,145 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  185, train_loss:  12.1562, val_loss:  12.4279, grad_norm: 0.0042, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6622, 0.3081, 0.6548, param: [5.45243472 8.27065333 5.1935228  8.65035204], weights: [0.30581154 0.3115442  0.38264426], train_wt_loss:  36.4686, val_wt_loss: 37.2836, train_grp_loss: [11.81529074 13.0733463  10.7155939 ], val_grp_loss: [12.68550703 12.45068145 12.14666244], train_hist_grp_loss: [17.63098564 19.48820618 40.04465796], cur_train_grp_loss: [0.09452204 0.10458663 0.21431401], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6622, max_kl_dist_index: 0, max_train_grp_loss:  13.0733, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6855, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2143, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:13:35,169 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  186, train_loss:  12.1562, val_loss:  12.4279, grad_norm: 0.0042, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6622, 0.3081, 0.6549, param: [5.45248139 8.27050583 5.19380166 8.65082727], weights: [0.30566176 0.31142296 0.38291528], train_wt_loss:  36.4686, val_wt_loss: 37.2837, train_grp_loss: [11.81532628 13.07336398 10.71548697], val_grp_loss: [12.68559265 12.45070428 12.14665792], train_hist_grp_loss: [17.72550797 19.59279295 40.25896984], cur_train_grp_loss: [0.09452233 0.10458677 0.21431188], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6622, max_kl_dist_index: 0, max_train_grp_loss:  13.0734, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6856, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2143, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:13:36,175 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  187, train_loss:  12.1562, val_loss:  12.4279, grad_norm: 0.0043, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6622, 0.3081, 0.6549, param: [5.45252798 8.27035844 5.19408065 8.65130309], weights: [0.30551197 0.31130167 0.38318636], train_wt_loss:  36.4686, val_wt_loss: 37.2838, train_grp_loss: [11.81536161 13.07338197 10.71537992], val_grp_loss: [12.6856781  12.45072746 12.14665333], train_hist_grp_loss: [17.82003058 19.69737986 40.47327958], cur_train_grp_loss: [0.09452261 0.10458691 0.21430974], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6622, max_kl_dist_index: 0, max_train_grp_loss:  13.0734, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6857, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2143, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:13:37,239 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  188, train_loss:  12.1562, val_loss:  12.4280, grad_norm: 0.0043, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6623, 0.3081, 0.6549, param: [5.45257451 8.27021118 5.19435976 8.6517795 ], weights: [0.30536216 0.31118034 0.38345751], train_wt_loss:  36.4686, val_wt_loss: 37.2839, train_grp_loss: [11.81539675 13.07340028 10.71527276], val_grp_loss: [12.68576339 12.45075101 12.14664866], train_hist_grp_loss: [17.91455347 19.80196692 40.68758718], cur_train_grp_loss: [0.09452289 0.10458706 0.2143076 ], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6623, max_kl_dist_index: 0, max_train_grp_loss:  13.0734, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6858, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2143, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:13:38,259 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  189, train_loss:  12.1562, val_loss:  12.4280, grad_norm: 0.0043, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6623, 0.3082, 0.6550, param: [5.45262096 8.27006404 5.19463901 8.65225651], weights: [0.30521233 0.31105895 0.38372872], train_wt_loss:  36.4686, val_wt_loss: 37.2840, train_grp_loss: [11.81543168 13.07341891 10.71516549], val_grp_loss: [12.68584851 12.45077491 12.14664392], train_hist_grp_loss: [18.00907664 19.90655412 40.90189263], cur_train_grp_loss: [0.09452317 0.1045872  0.21430546], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6623, max_kl_dist_index: 0, max_train_grp_loss:  13.0734, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6858, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2143, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:13:39,281 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  190, train_loss:  12.1562, val_loss:  12.4280, grad_norm: 0.0043, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6623, 0.3082, 0.6550, param: [5.45266733 8.26991702 5.19491838 8.65273411], weights: [0.30506248 0.31093752 0.384     ], train_wt_loss:  36.4687, val_wt_loss: 37.2841, train_grp_loss: [11.81546641 13.07343785 10.71505811], val_grp_loss: [12.68593346 12.45079917 12.14663911], train_hist_grp_loss: [18.1036001  20.01114147 41.11619594], cur_train_grp_loss: [0.09452345 0.10458735 0.21430331], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6623, max_kl_dist_index: 0, max_train_grp_loss:  13.0734, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6859, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2143, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:13:40,319 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  191, train_loss:  12.1562, val_loss:  12.4281, grad_norm: 0.0044, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6624, 0.3082, 0.6550, param: [5.45271364 8.26977012 5.19519788 8.65321231], weights: [0.30491261 0.31081605 0.38427135], train_wt_loss:  36.4687, val_wt_loss: 37.2843, train_grp_loss: [11.81550093 13.07345711 10.71495061], val_grp_loss: [12.68601825 12.45082379 12.14663422], train_hist_grp_loss: [18.19812383 20.11572898 41.33049711], cur_train_grp_loss: [0.09452373 0.1045875  0.21430116], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6624, max_kl_dist_index: 0, max_train_grp_loss:  13.0735, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6860, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2143, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:13:41,366 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  192, train_loss:  12.1562, val_loss:  12.4281, grad_norm: 0.0044, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6624, 0.3082, 0.6550, param: [5.45275987 8.26962335 5.19547751 8.6536911 ], weights: [0.30476272 0.31069452 0.38454276], train_wt_loss:  36.4687, val_wt_loss: 37.2844, train_grp_loss: [11.81553526 13.07347668 10.71484301], val_grp_loss: [12.68610288 12.45084877 12.14662925], train_hist_grp_loss: [18.29264784 20.22031663 41.54479612], cur_train_grp_loss: [0.09452401 0.10458766 0.21429901], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6624, max_kl_dist_index: 0, max_train_grp_loss:  13.0735, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6861, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2143, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:13:42,382 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  193, train_loss:  12.1562, val_loss:  12.4282, grad_norm: 0.0044, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6624, 0.3082, 0.6551, param: [5.45280602 8.26947669 5.19575726 8.65417048], weights: [0.30461281 0.31057295 0.38481423], train_wt_loss:  36.4687, val_wt_loss: 37.2845, train_grp_loss: [11.81556938 13.07349657 10.71473529], val_grp_loss: [12.68618733 12.45087411 12.14662421], train_hist_grp_loss: [18.38717212 20.32490445 41.75909298], cur_train_grp_loss: [0.09452428 0.10458781 0.21429686], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6624, max_kl_dist_index: 0, max_train_grp_loss:  13.0735, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6862, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2143, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:13:43,390 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  194, train_loss:  12.1562, val_loss:  12.4282, grad_norm: 0.0044, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6625, 0.3083, 0.6551, param: [5.45285211 8.26933016 5.19603715 8.65465046], weights: [0.30446289 0.31045133 0.38508578], train_wt_loss:  36.4687, val_wt_loss: 37.2846, train_grp_loss: [11.8156033  13.07351677 10.71462746], val_grp_loss: [12.68627162 12.45089981 12.1466191 ], train_hist_grp_loss: [18.48169667 20.42949242 41.97338768], cur_train_grp_loss: [0.09452456 0.10458797 0.21429471], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6625, max_kl_dist_index: 0, max_train_grp_loss:  13.0735, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6863, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2143, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:13:44,428 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  195, train_loss:  12.1562, val_loss:  12.4282, grad_norm: 0.0045, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6625, 0.3083, 0.6551, param: [5.45289812 8.26918374 5.19631716 8.65513104], weights: [0.30431294 0.31032967 0.38535739], train_wt_loss:  36.4687, val_wt_loss: 37.2847, train_grp_loss: [11.81563702 13.07353729 10.71451952], val_grp_loss: [12.68635575 12.45092587 12.14661392], train_hist_grp_loss: [18.5762215  20.53408055 42.18768023], cur_train_grp_loss: [0.09452483 0.10458813 0.21429255], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6625, max_kl_dist_index: 0, max_train_grp_loss:  13.0735, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6864, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2143, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:13:45,452 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  196, train_loss:  12.1562, val_loss:  12.4283, grad_norm: 0.0045, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6625, 0.3083, 0.6552, param: [5.45294406 8.26903745 5.19659731 8.65561221], weights: [0.30416298 0.31020796 0.38562906], train_wt_loss:  36.4687, val_wt_loss: 37.2848, train_grp_loss: [11.81567054 13.07355813 10.71441147], val_grp_loss: [12.68643971 12.45095228 12.14660866], train_hist_grp_loss: [18.67074659 20.63866885 42.40197062], cur_train_grp_loss: [0.0945251  0.1045883  0.21429039], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6625, max_kl_dist_index: 0, max_train_grp_loss:  13.0736, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6864, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2143, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:13:46,469 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  197, train_loss:  12.1563, val_loss:  12.4283, grad_norm: 0.0045, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6626, 0.3083, 0.6552, param: [5.45298992 8.26889128 5.19687758 8.65609398], weights: [0.304013  0.3100862 0.3859008], train_wt_loss:  36.4688, val_wt_loss: 37.2849, train_grp_loss: [11.81570385 13.07357928 10.7143033 ], val_grp_loss: [12.6865235  12.45097906 12.14660333], train_hist_grp_loss: [18.76527196 20.74325732 42.61625885], cur_train_grp_loss: [0.09452536 0.10458847 0.21428823], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6626, max_kl_dist_index: 0, max_train_grp_loss:  13.0736, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6865, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2143, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:13:47,496 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  198, train_loss:  12.1563, val_loss:  12.4283, grad_norm: 0.0046, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6626, 0.3083, 0.6552, param: [5.45303572 8.26874523 5.19715798 8.65657634], weights: [0.303863   0.30996439 0.3861726 ], train_wt_loss:  36.4688, val_wt_loss: 37.2850, train_grp_loss: [11.81573697 13.07360075 10.71419502], val_grp_loss: [12.68660713 12.45100619 12.14659792], train_hist_grp_loss: [18.85979759 20.84784595 42.83054492], cur_train_grp_loss: [0.09452563 0.10458863 0.21428607], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6626, max_kl_dist_index: 0, max_train_grp_loss:  13.0736, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6866, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2143, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:13:48,520 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  199, train_loss:  12.1563, val_loss:  12.4284, grad_norm: 0.0046, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6626, 0.3083, 0.6553, param: [5.45308143 8.2685993  5.19743851 8.6570593 ], weights: [0.30371299 0.30984254 0.38644447], train_wt_loss:  36.4688, val_wt_loss: 37.2851, train_grp_loss: [11.81576988 13.07362253 10.71408664], val_grp_loss: [12.6866906  12.45103369 12.14659244], train_hist_grp_loss: [18.95432349 20.95243476 43.04482882], cur_train_grp_loss: [0.0945259  0.10458881 0.2142839 ], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6626, max_kl_dist_index: 0, max_train_grp_loss:  13.0736, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6867, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2143, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:13:49,469 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1654] - INFO: Iteration:  199, train_loss:  12.1563, val_loss:  12.4284, grad_norm: 0.0046,  live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6626, 0.3083, 0.6553, param: [5.45308143 8.2685993  5.19743851 8.6570593 ], weights: [0.30371299 0.30984254 0.38644447], train_wt_loss:  36.4688, val_wt_loss: 37.2851, train_grp_loss: [11.81576988 13.07362253 10.71408664], val_grp_loss: [12.6866906  12.45103369 12.14659244], train_hist_grp_loss: [18.95432349 20.95243476 43.04482882], cur_train_grp_loss: [0.0945259  0.10458881 0.2142839 ], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6626, max_kl_dist_index: 0, max_train_grp_loss:  13.0736, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6867, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2143, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:13:49,698 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:388] - INFO: Policy parameter learned solely on the preference data rdpo: [5.45308143 8.2685993  5.19743851 8.6570593 ].
2024-10-07 01:13:50,051 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Uniform reward: 3.8318, 3.8318, 3.1647
2024-10-07 01:13:50,051 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Optimal reward: 3.8678, 7.2446, 3.2763
2024-10-07 01:13:50,052 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Policy reward: 3.8283, 7.1413, 3.2759
2024-10-07 01:13:50,052 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:402] - INFO: Reward Error: 0.0102, 0.0142, 0.0001
2024-10-07 01:13:50,764 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:417] - INFO: Optimal reward: 3.8678, 7.2446, 3.2763
Known param reward: [[3.867779541015625, 6.77779443359375, 3.255072021484375], [3.441058349609375, 7.24455908203125, 3.05710986328125], [3.841189453125, 7.1339345703125, 3.27631982421875]], Known param reward error: [[0.0, 0.06442968345654335, 0.0064852651372159075], [0.11032717529039895, 0.0, 0.06690737556116683], [0.006874768225192712, 0.015270013049259644, 0.0]].
