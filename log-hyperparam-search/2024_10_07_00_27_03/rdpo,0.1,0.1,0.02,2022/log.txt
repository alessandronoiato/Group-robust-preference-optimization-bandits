2024-10-07 00:41:28,559 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log-hyperparam-search/2024_10_07_00_27_03/rdpo,0.1,0.1,0.02,2022
2024-10-07 00:41:28,561 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2022
2024-10-07 00:41:28,562 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-10-07 00:41:28,653 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.3214, l2 distance: 25.6155, acc: 0.89.
2024-10-07 00:41:28,654 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-10-07 00:41:28,655 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [ 4.91492317 13.51244723  6.71533233  9.49961375]
2024-10-07 00:41:28,873 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.8530, 6.9304, 3.3326
2024-10-07 00:41:29,106 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1314] - INFO: unique_group_ids: {0, 1, 2}
2024-10-07 00:41:30,371 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  0, train_loss:  13.4334, val_loss:  12.2619, grad_norm: 0.5704, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6506, 0.3478, 0.6807, param: [4.1508262  9.52426175 4.95548794 8.85653162], weights: [0.33267478 0.33275415 0.33457107], train_wt_loss:  40.3003, val_wt_loss: 36.7857, train_grp_loss: [11.73538699 15.8963272  11.15342789], val_grp_loss: [10.62053484 14.91092252 11.27012295], train_hist_grp_loss: [0.17243466 0.18436246 0.45663202], cur_train_grp_loss: [0.17243466 0.18436246 0.45663202], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6807, max_kl_dist_index: 2, max_train_grp_loss:  15.8963, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9109, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.4566, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:41:31,435 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  1, train_loss:  13.4334, val_loss:  12.2619, grad_norm: 0.0001, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6506, 0.3478, 0.6807, param: [4.15086982 9.52367791 4.95580479 8.8567021 ], weights: [0.33229387 0.33256323 0.3351429 ], train_wt_loss:  40.3003, val_wt_loss: 36.7856, train_grp_loss: [11.73574059 15.89594564 11.15354201], val_grp_loss: [10.62080368 14.91041062 11.27026321], train_hist_grp_loss: [0.26707488 0.3075898  0.693939  ], cur_train_grp_loss: [0.09464022 0.12322734 0.23730698], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6807, max_kl_dist_index: 2, max_train_grp_loss:  15.8959, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9104, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2373, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:41:32,555 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  2, train_loss:  13.4334, val_loss:  12.2618, grad_norm: 0.0001, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6505, 0.3478, 0.6807, param: [4.15091251 9.52309607 4.95612097 8.85687469], weights: [0.3319129 0.3323719 0.3357152], train_wt_loss:  40.3003, val_wt_loss: 36.7855, train_grp_loss: [11.73609217 15.89556642 11.15365527], val_grp_loss: [10.62107075 14.90990221 11.27040282], train_hist_grp_loss: [0.36171795 0.43081419 0.9312484 ], cur_train_grp_loss: [0.09464307 0.12322438 0.2373094 ], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6807, max_kl_dist_index: 2, max_train_grp_loss:  15.8956, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9099, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2373, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:41:33,677 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  3, train_loss:  13.4334, val_loss:  12.2618, grad_norm: 0.0000, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6505, 0.3478, 0.6807, param: [4.15095428 9.52251623 4.95643648 8.85704938], weights: [0.33153188 0.33218014 0.33628799], train_wt_loss:  40.3003, val_wt_loss: 36.7854, train_grp_loss: [11.73644174 15.89518955 11.15376766], val_grp_loss: [10.62133602 14.90939732 11.27054176], train_hist_grp_loss: [0.45636385 0.55403563 1.16856022], cur_train_grp_loss: [0.0946459  0.12322145 0.23731181], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6807, max_kl_dist_index: 2, max_train_grp_loss:  15.8952, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9094, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2373, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:41:34,806 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  4, train_loss:  13.4334, val_loss:  12.2618, grad_norm: 0.0001, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6505, 0.3478, 0.6807, param: [4.15099513 9.52193837 4.95675132 8.85722618], weights: [0.3311508  0.33198796 0.33686124], train_wt_loss:  40.3003, val_wt_loss: 36.7853, train_grp_loss: [11.73678928 15.89481504 11.1538792 ], val_grp_loss: [10.62159951 14.90889594 11.27068005], train_hist_grp_loss: [0.55101258 0.67725416 1.40587442], cur_train_grp_loss: [0.09464872 0.12321852 0.23731421], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6807, max_kl_dist_index: 2, max_train_grp_loss:  15.8948, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9089, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2373, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:41:35,907 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  5, train_loss:  13.4334, val_loss:  12.2617, grad_norm: 0.0001, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6505, 0.3478, 0.6806, param: [4.15103504 9.52136251 4.95706548 8.85740509], weights: [0.33076967 0.33179536 0.33743497], train_wt_loss:  40.3003, val_wt_loss: 36.7852, train_grp_loss: [11.7371348  15.89444288 11.15398987], val_grp_loss: [10.62186121 14.90839807 11.27081768], train_hist_grp_loss: [0.6456641  0.80046978 1.643191  ], cur_train_grp_loss: [0.09465153 0.12321562 0.23731658], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6806, max_kl_dist_index: 2, max_train_grp_loss:  15.8944, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9084, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2373, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:41:37,012 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  6, train_loss:  13.4334, val_loss:  12.2617, grad_norm: 0.0001, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6505, 0.3477, 0.6806, param: [4.15107403 9.52078865 4.95737897 8.85758612], weights: [0.33038849 0.33160234 0.33800917], train_wt_loss:  40.3003, val_wt_loss: 36.7851, train_grp_loss: [11.7374783  15.89407308 11.15409968], val_grp_loss: [10.62212112 14.90790372 11.27095465], train_hist_grp_loss: [0.74031842 0.92368251 1.88050994], cur_train_grp_loss: [0.09465431 0.12321274 0.23731893], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6806, max_kl_dist_index: 2, max_train_grp_loss:  15.8941, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9079, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2373, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:41:38,056 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  7, train_loss:  13.4334, val_loss:  12.2617, grad_norm: 0.0001, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6505, 0.3477, 0.6806, param: [4.15111209 9.52021679 4.95769179 8.85776926], weights: [0.33000725 0.3314089  0.33858384], train_wt_loss:  40.3003, val_wt_loss: 36.7850, train_grp_loss: [11.73781977 15.89370563 11.15420863], val_grp_loss: [10.62237923 14.90741288 11.27109096], train_hist_grp_loss: [0.8349755  1.04689238 2.11783121], cur_train_grp_loss: [0.09465708 0.12320987 0.23732127], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6806, max_kl_dist_index: 2, max_train_grp_loss:  15.8937, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9074, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2373, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:41:39,102 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  8, train_loss:  13.4334, val_loss:  12.2616, grad_norm: 0.0002, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6505, 0.3477, 0.6806, param: [4.15114922 9.51964692 4.95800392 8.85795452], weights: [0.32962597 0.33121505 0.33915898], train_wt_loss:  40.3003, val_wt_loss: 36.7849, train_grp_loss: [11.73815921 15.89334055 11.1543167 ], val_grp_loss: [10.62263555 14.90692556 11.2712266 ], train_hist_grp_loss: [0.92963534 1.1700994  2.35515479], cur_train_grp_loss: [0.09465984 0.12320702 0.23732359], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6806, max_kl_dist_index: 2, max_train_grp_loss:  15.8933, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9069, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2373, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:41:40,150 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  9, train_loss:  13.4334, val_loss:  12.2616, grad_norm: 0.0002, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6505, 0.3477, 0.6806, param: [4.15118542 9.51907905 4.95831539 8.85814189], weights: [0.32924463 0.33102078 0.33973459], train_wt_loss:  40.3003, val_wt_loss: 36.7849, train_grp_loss: [11.73849662 15.89297782 11.15442392], val_grp_loss: [10.62289007 14.90644177 11.27136158], train_hist_grp_loss: [1.02429791 1.29330359 2.59248068], cur_train_grp_loss: [0.09466257 0.12320419 0.23732589], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6806, max_kl_dist_index: 2, max_train_grp_loss:  15.8930, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9064, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2373, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:41:41,163 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  10, train_loss:  13.4334, val_loss:  12.2616, grad_norm: 0.0002, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6505, 0.3477, 0.6805, param: [4.1512207  9.51851318 4.95862617 8.85833139], weights: [0.32886325 0.33082609 0.34031066], train_wt_loss:  40.3003, val_wt_loss: 36.7848, train_grp_loss: [11.738832   15.89261745 11.15453026], val_grp_loss: [10.6231428 14.9059615 11.2714959], train_hist_grp_loss: [1.11896321 1.41650497 2.82980885], cur_train_grp_loss: [0.0946653  0.12320138 0.23732817], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6805, max_kl_dist_index: 2, max_train_grp_loss:  15.8926, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9060, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2373, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:41:42,221 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  11, train_loss:  13.4334, val_loss:  12.2616, grad_norm: 0.0002, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6505, 0.3477, 0.6805, param: [4.15125504 9.51794932 4.95893628 8.85852302], weights: [0.32848181 0.33063099 0.3408872 ], train_wt_loss:  40.3003, val_wt_loss: 36.7847, train_grp_loss: [11.73916534 15.89225944 11.15463573], val_grp_loss: [10.62339372 14.90548476 11.27162955], train_hist_grp_loss: [1.21363121 1.53970356 3.06713928], cur_train_grp_loss: [0.094668   0.12319858 0.23733043], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6805, max_kl_dist_index: 2, max_train_grp_loss:  15.8923, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9055, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2373, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:41:43,283 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  12, train_loss:  13.4334, val_loss:  12.2615, grad_norm: 0.0003, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6505, 0.3477, 0.6805, param: [4.15128845 9.51738745 4.9592457  8.85871677], weights: [0.32810033 0.33043547 0.3414642 ], train_wt_loss:  40.3003, val_wt_loss: 36.7846, train_grp_loss: [11.73949665 15.8919038  11.15474034], val_grp_loss: [10.62364284 14.90501155 11.27176253], train_hist_grp_loss: [1.30830189 1.66289937 3.30447196], cur_train_grp_loss: [0.09467069 0.12319581 0.23733268], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6805, max_kl_dist_index: 2, max_train_grp_loss:  15.8919, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9050, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2373, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:41:44,311 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  13, train_loss:  13.4334, val_loss:  12.2615, grad_norm: 0.0003, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6505, 0.3476, 0.6805, param: [4.15132094 9.51682759 4.95955445 8.85891265], weights: [0.3277188  0.33023954 0.34204166], train_wt_loss:  40.3003, val_wt_loss: 36.7845, train_grp_loss: [11.73982591 15.89155052 11.15484407], val_grp_loss: [10.62389016 14.90454187 11.27189485], train_hist_grp_loss: [1.40297525 1.78609242 3.54180686], cur_train_grp_loss: [0.09467336 0.12319305 0.2373349 ], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6805, max_kl_dist_index: 2, max_train_grp_loss:  15.8916, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9045, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2373, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:41:45,351 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  14, train_loss:  13.4334, val_loss:  12.2615, grad_norm: 0.0003, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6505, 0.3476, 0.6805, param: [4.15135249 9.51626974 4.95986251 8.85911066], weights: [0.32733722 0.33004319 0.34261959], train_wt_loss:  40.3003, val_wt_loss: 36.7844, train_grp_loss: [11.74015314 15.89119961 11.15494693], val_grp_loss: [10.62413567 14.90407572 11.2720265 ], train_hist_grp_loss: [1.49765127 1.90928273 3.77914396], cur_train_grp_loss: [0.09467602 0.12319031 0.23733711], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6805, max_kl_dist_index: 2, max_train_grp_loss:  15.8912, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9041, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2373, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:41:46,385 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  15, train_loss:  13.4334, val_loss:  12.2614, grad_norm: 0.0004, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6505, 0.3476, 0.6805, param: [4.15138311 9.51571389 4.9601699  8.85931081], weights: [0.3269556  0.32984643 0.34319797], train_wt_loss:  40.3003, val_wt_loss: 36.7843, train_grp_loss: [11.74047832 15.89085107 11.15504891], val_grp_loss: [10.62437938 14.90361311 11.27215748], train_hist_grp_loss: [1.59232992 2.03247033 4.01648326], cur_train_grp_loss: [0.09467865 0.12318759 0.2373393 ], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6805, max_kl_dist_index: 2, max_train_grp_loss:  15.8909, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9036, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2373, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:41:47,430 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  16, train_loss:  13.4334, val_loss:  12.2614, grad_norm: 0.0004, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6505, 0.3476, 0.6805, param: [4.1514128  9.51516004 4.9604766  8.85951309], weights: [0.32657393 0.32964926 0.34377681], train_wt_loss:  40.3003, val_wt_loss: 36.7842, train_grp_loss: [11.74080146 15.89050489 11.15515003], val_grp_loss: [10.62462127 14.90315404 11.27228778], train_hist_grp_loss: [1.6870112  2.15565522 4.25382473], cur_train_grp_loss: [0.09468128 0.12318489 0.23734147], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6805, max_kl_dist_index: 2, max_train_grp_loss:  15.8905, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9032, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2373, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:41:48,493 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  17, train_loss:  13.4334, val_loss:  12.2614, grad_norm: 0.0004, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6505, 0.3476, 0.6804, param: [4.15144156 9.5146082  4.96078262 8.8597175 ], weights: [0.32619222 0.32945168 0.3443561 ], train_wt_loss:  40.3003, val_wt_loss: 36.7842, train_grp_loss: [11.74112254 15.89016109 11.15525026], val_grp_loss: [10.62486135 14.90269851 11.27241742], train_hist_grp_loss: [1.78169508 2.27883743 4.49116835], cur_train_grp_loss: [0.09468388 0.12318221 0.23734362], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6804, max_kl_dist_index: 2, max_train_grp_loss:  15.8902, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9027, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2373, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:41:49,542 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  18, train_loss:  13.4334, val_loss:  12.2614, grad_norm: 0.0004, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6505, 0.3476, 0.6804, param: [4.15146938 9.51405837 4.96108795 8.85992406], weights: [0.32581046 0.32925368 0.34493585], train_wt_loss:  40.3003, val_wt_loss: 36.7841, train_grp_loss: [11.74144158 15.88981966 11.15534962], val_grp_loss: [10.62509963 14.90224652 11.27254639], train_hist_grp_loss: [1.87638156 2.40201697 4.7285141 ], cur_train_grp_loss: [0.09468647 0.12317954 0.23734575], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6804, max_kl_dist_index: 2, max_train_grp_loss:  15.8898, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9022, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2373, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:41:50,569 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  19, train_loss:  13.4334, val_loss:  12.2613, grad_norm: 0.0005, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6504, 0.3476, 0.6804, param: [4.15149627 9.51351055 4.9613926  8.86013275], weights: [0.32542867 0.32905528 0.34551606], train_wt_loss:  40.3003, val_wt_loss: 36.7840, train_grp_loss: [11.74175857 15.8894806  11.1554481 ], val_grp_loss: [10.62533608 14.90179808 11.27267468], train_hist_grp_loss: [1.9710706  2.52519387 4.96586196], cur_train_grp_loss: [0.09468905 0.1231769  0.23734786], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6804, max_kl_dist_index: 2, max_train_grp_loss:  15.8895, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9018, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2373, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:41:51,586 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  20, train_loss:  13.4334, val_loss:  12.2613, grad_norm: 0.0005, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6504, 0.3475, 0.6804, param: [4.15152223 9.51296474 4.96169656 8.86034359], weights: [0.32504683 0.32885646 0.34609671], train_wt_loss:  40.3003, val_wt_loss: 36.7839, train_grp_loss: [11.7420735  15.88914391 11.1555457 ], val_grp_loss: [10.62557073 14.90135319 11.27280229], train_hist_grp_loss: [2.0657622  2.64836813 5.20321192], cur_train_grp_loss: [0.0946916  0.12317427 0.23734996], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6804, max_kl_dist_index: 2, max_train_grp_loss:  15.8891, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9014, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2373, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:41:52,628 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  21, train_loss:  13.4334, val_loss:  12.2613, grad_norm: 0.0005, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6504, 0.3475, 0.6804, param: [4.15154725 9.51242094 4.96199984 8.86055658], weights: [0.32466495 0.32865724 0.34667782], train_wt_loss:  40.3003, val_wt_loss: 36.7838, train_grp_loss: [11.74238638 15.8888096  11.15564242], val_grp_loss: [10.62580355 14.90091184 11.27292923], train_hist_grp_loss: [2.16045634 2.77153979 5.44056396], cur_train_grp_loss: [0.09469414 0.12317166 0.23735204], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6804, max_kl_dist_index: 2, max_train_grp_loss:  15.8888, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9009, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:41:53,703 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  22, train_loss:  13.4334, val_loss:  12.2613, grad_norm: 0.0006, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6504, 0.3475, 0.6804, param: [4.15157134 9.51187916 4.96230243 8.86077171], weights: [0.32428302 0.32845761 0.34725937], train_wt_loss:  40.3003, val_wt_loss: 36.7838, train_grp_loss: [11.7426972  15.88847766 11.15573826], val_grp_loss: [10.62603455 14.90047405 11.2730555 ], train_hist_grp_loss: [2.25515301 2.89470886 5.67791805], cur_train_grp_loss: [0.09469666 0.12316907 0.23735409], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6804, max_kl_dist_index: 2, max_train_grp_loss:  15.8885, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9005, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:41:54,753 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  23, train_loss:  13.4334, val_loss:  12.2612, grad_norm: 0.0006, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6504, 0.3475, 0.6804, param: [4.15159449 9.51133938 4.96260433 8.86098899], weights: [0.32390106 0.32825757 0.34784137], train_wt_loss:  40.3003, val_wt_loss: 36.7837, train_grp_loss: [11.74300596 15.88814811 11.15583322], val_grp_loss: [10.62626374 14.90003981 11.27318109], train_hist_grp_loss: [2.34985218 3.01787535 5.91527418], cur_train_grp_loss: [0.09469917 0.12316649 0.23735613], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6804, max_kl_dist_index: 2, max_train_grp_loss:  15.8881, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9000, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:41:55,834 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  24, train_loss:  13.4334, val_loss:  12.2612, grad_norm: 0.0006, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6504, 0.3475, 0.6803, param: [4.15161671 9.51080162 4.96290554 8.86120843], weights: [0.32351906 0.32805712 0.34842382], train_wt_loss:  40.3003, val_wt_loss: 36.7836, train_grp_loss: [11.74331266 15.88782093 11.15592729], val_grp_loss: [10.6264911  14.89960913 11.273306  ], train_hist_grp_loss: [2.44455384 3.14103929 6.15263234], cur_train_grp_loss: [0.09470166 0.12316394 0.23735815], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6803, max_kl_dist_index: 2, max_train_grp_loss:  15.8878, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8996, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:41:56,872 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  25, train_loss:  13.4334, val_loss:  12.2612, grad_norm: 0.0006, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6504, 0.3475, 0.6803, param: [4.15163799 9.51026587 4.96320607 8.86143001], weights: [0.32313702 0.32785627 0.34900671], train_wt_loss:  40.3003, val_wt_loss: 36.7835, train_grp_loss: [11.74361729 15.88749614 11.15602048], val_grp_loss: [10.62671663 14.89918201 11.27343023], train_hist_grp_loss: [2.53925797 3.26420069 6.38999249], cur_train_grp_loss: [0.09470413 0.1231614  0.23736016], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6803, max_kl_dist_index: 2, max_train_grp_loss:  15.8875, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8992, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:41:57,932 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  26, train_loss:  13.4334, val_loss:  12.2612, grad_norm: 0.0007, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6504, 0.3475, 0.6803, param: [4.15165833 9.50973214 4.9635059  8.86165376], weights: [0.32275495 0.32765501 0.34959004], train_wt_loss:  40.3003, val_wt_loss: 36.7835, train_grp_loss: [11.74391986 15.88717372 11.15611279], val_grp_loss: [10.62694035 14.89875845 11.27355378], train_hist_grp_loss: [2.63396456 3.38735958 6.62735463], cur_train_grp_loss: [0.09470659 0.12315888 0.23736214], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6803, max_kl_dist_index: 2, max_train_grp_loss:  15.8872, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8988, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:41:58,981 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  27, train_loss:  13.4334, val_loss:  12.2611, grad_norm: 0.0007, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6504, 0.3475, 0.6803, param: [4.15167774 9.50920042 4.96380504 8.86187966], weights: [0.32237284 0.32745335 0.35017382], train_wt_loss:  40.3003, val_wt_loss: 36.7834, train_grp_loss: [11.74422036 15.88685369 11.15620421], val_grp_loss: [10.62716223 14.89833845 11.27367665], train_hist_grp_loss: [2.7286736  3.51051596 6.86471873], cur_train_grp_loss: [0.09470903 0.12315639 0.2373641 ], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6803, max_kl_dist_index: 2, max_train_grp_loss:  15.8869, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8983, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:42:00,023 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  28, train_loss:  13.4334, val_loss:  12.2611, grad_norm: 0.0007, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6504, 0.3474, 0.6803, param: [4.15169621 9.50867073 4.96410348 8.86210771], weights: [0.32199069 0.32725128 0.35075803], train_wt_loss:  40.3003, val_wt_loss: 36.7833, train_grp_loss: [11.74451879 15.88653604 11.15629474], val_grp_loss: [10.62738228 14.89792202 11.27379884], train_hist_grp_loss: [2.82338505 3.63366987 7.10208478], cur_train_grp_loss: [0.09471145 0.1231539  0.23736605], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6803, max_kl_dist_index: 2, max_train_grp_loss:  15.8865, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8979, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:42:01,061 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  29, train_loss:  13.4334, val_loss:  12.2611, grad_norm: 0.0008, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6504, 0.3474, 0.6803, param: [4.15171375 9.50814304 4.96440124 8.86233794], weights: [0.3216085  0.32704881 0.35134268], train_wt_loss:  40.3003, val_wt_loss: 36.7832, train_grp_loss: [11.74481515 15.88622078 11.15638438], val_grp_loss: [10.62760051 14.89750915 11.27392035], train_hist_grp_loss: [2.91809891 3.75682131 7.33945275], cur_train_grp_loss: [0.09471386 0.12315144 0.23736797], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6803, max_kl_dist_index: 2, max_train_grp_loss:  15.8862, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8975, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:42:02,097 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  30, train_loss:  13.4334, val_loss:  12.2611, grad_norm: 0.0008, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6504, 0.3474, 0.6803, param: [4.15173034 9.50761738 4.9646983  8.86257032], weights: [0.32122629 0.32684594 0.35192777], train_wt_loss:  40.3003, val_wt_loss: 36.7832, train_grp_loss: [11.74510944 15.88590791 11.15647313], val_grp_loss: [10.6278169  14.89709986 11.27404117], train_hist_grp_loss: [3.01281516 3.87997031 7.57682263], cur_train_grp_loss: [0.09471625 0.123149   0.23736988], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6803, max_kl_dist_index: 2, max_train_grp_loss:  15.8859, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8971, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:42:03,120 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  31, train_loss:  13.4334, val_loss:  12.2610, grad_norm: 0.0008, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6504, 0.3474, 0.6802, param: [4.151746   9.50709374 4.96499466 8.86280487], weights: [0.32084404 0.32664266 0.3525133 ], train_wt_loss:  40.3003, val_wt_loss: 36.7831, train_grp_loss: [11.74540165 15.88559743 11.156561  ], val_grp_loss: [10.62803145 14.89669413 11.27416131], train_hist_grp_loss: [3.10753379 4.00311688 7.8141944 ], cur_train_grp_loss: [0.09471862 0.12314657 0.23737177], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6802, max_kl_dist_index: 2, max_train_grp_loss:  15.8856, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8967, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:42:04,163 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  32, train_loss:  13.4334, val_loss:  12.2610, grad_norm: 0.0008, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6504, 0.3474, 0.6802, param: [4.15176072 9.50657212 4.96529033 8.86304159], weights: [0.32046175 0.32643899 0.35309926], train_wt_loss:  40.3003, val_wt_loss: 36.7830, train_grp_loss: [11.74569178 15.88528933 11.15664797], val_grp_loss: [10.62824417 14.89629198 11.27428077], train_hist_grp_loss: [3.20225477 4.12626105 8.05156804], cur_train_grp_loss: [0.09472098 0.12314417 0.23737364], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6802, max_kl_dist_index: 2, max_train_grp_loss:  15.8853, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8963, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:42:05,246 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  33, train_loss:  13.4334, val_loss:  12.2610, grad_norm: 0.0009, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6504, 0.3474, 0.6802, param: [4.15177449 9.50605252 4.9655853  8.86328047], weights: [0.32007944 0.32623491 0.35368565], train_wt_loss:  40.3003, val_wt_loss: 36.7830, train_grp_loss: [11.74597983 15.88498363 11.15673405], val_grp_loss: [10.62845506 14.89589341 11.27439953], train_hist_grp_loss: [3.29697809 4.24940283 8.28894353], cur_train_grp_loss: [0.09472332 0.12314178 0.23737549], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6802, max_kl_dist_index: 2, max_train_grp_loss:  15.8850, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8959, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:42:06,285 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  34, train_loss:  13.4334, val_loss:  12.2610, grad_norm: 0.0009, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6504, 0.3474, 0.6802, param: [4.15178733 9.50553494 4.96587958 8.86352153], weights: [0.31969709 0.32603044 0.35427247], train_wt_loss:  40.3003, val_wt_loss: 36.7829, train_grp_loss: [11.74626581 15.88468031 11.15681924], val_grp_loss: [10.6286641  14.89549842 11.27451762], train_hist_grp_loss: [3.39170373 4.37254223 8.52632085], cur_train_grp_loss: [0.09472564 0.12313941 0.23737732], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6802, max_kl_dist_index: 2, max_train_grp_loss:  15.8847, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8955, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:42:07,334 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  35, train_loss:  13.4334, val_loss:  12.2609, grad_norm: 0.0009, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6504, 0.3474, 0.6802, param: [4.15179923 9.50501938 4.96617315 8.86376476], weights: [0.31931472 0.32582556 0.35485972], train_wt_loss:  40.3003, val_wt_loss: 36.7828, train_grp_loss: [11.7465497  15.8843794  11.15690353], val_grp_loss: [10.62887131 14.89510701 11.27463501], train_hist_grp_loss: [3.48643168 4.49567929 8.76369998], cur_train_grp_loss: [0.09472795 0.12313706 0.23737913], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6802, max_kl_dist_index: 2, max_train_grp_loss:  15.8844, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8951, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:42:08,398 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  36, train_loss:  13.4334, val_loss:  12.2609, grad_norm: 0.0010, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6504, 0.3474, 0.6802, param: [4.15181019 9.50450585 4.96646603 8.86401017], weights: [0.31893231 0.32562029 0.3554474 ], train_wt_loss:  40.3003, val_wt_loss: 36.7828, train_grp_loss: [11.7468315  15.88408087 11.15698692], val_grp_loss: [10.62907667 14.89471918 11.27475172], train_hist_grp_loss: [3.58116192 4.61881401 9.00108091], cur_train_grp_loss: [0.09473024 0.12313472 0.23738093], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6802, max_kl_dist_index: 2, max_train_grp_loss:  15.8841, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8947, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:42:09,467 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  37, train_loss:  13.4334, val_loss:  12.2609, grad_norm: 0.0010, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6504, 0.3473, 0.6802, param: [4.1518202  9.50399434 4.96675821 8.86425775], weights: [0.31854988 0.32541462 0.3560355 ], train_wt_loss:  40.3003, val_wt_loss: 36.7827, train_grp_loss: [11.74711122 15.88378474 11.15706943], val_grp_loss: [10.62928019 14.89433493 11.27486773], train_hist_grp_loss: [3.67589443 4.74194642 9.23846361], cur_train_grp_loss: [0.09473251 0.12313241 0.2373827 ], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6802, max_kl_dist_index: 2, max_train_grp_loss:  15.8838, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8943, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:42:10,530 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  38, train_loss:  13.4334, val_loss:  12.2609, grad_norm: 0.0010, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6504, 0.3473, 0.6802, param: [4.15182928 9.50348486 4.96704968 8.86450751], weights: [0.31816742 0.32520855 0.35662403], train_wt_loss:  40.3003, val_wt_loss: 36.7827, train_grp_loss: [11.74738885 15.88349101 11.15715103], val_grp_loss: [10.62948187 14.89395427 11.27498306], train_hist_grp_loss: [3.7706292  4.86507654 9.47584806], cur_train_grp_loss: [0.09473477 0.12313011 0.23738446], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6802, max_kl_dist_index: 2, max_train_grp_loss:  15.8835, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8940, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:42:11,559 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  39, train_loss:  13.4334, val_loss:  12.2609, grad_norm: 0.0010, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6504, 0.3473, 0.6802, param: [4.15183741 9.5029774  4.96734046 8.86475945], weights: [0.31778493 0.32500209 0.35721298], train_wt_loss:  40.3003, val_wt_loss: 36.7826, train_grp_loss: [11.74766438 15.88319968 11.15723174], val_grp_loss: [10.62968169 14.89357721 11.27509769], train_hist_grp_loss: [3.86536621 4.98820438 9.71323425], cur_train_grp_loss: [0.09473701 0.12312784 0.23738619], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6802, max_kl_dist_index: 2, max_train_grp_loss:  15.8832, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8936, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:42:12,620 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  40, train_loss:  13.4334, val_loss:  12.2608, grad_norm: 0.0011, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6504, 0.3473, 0.6802, param: [4.1518446  9.50247197 4.96763053 8.86501358], weights: [0.31740242 0.32479523 0.35780236], train_wt_loss:  40.3003, val_wt_loss: 36.7825, train_grp_loss: [11.74793783 15.88291075 11.15731154], val_grp_loss: [10.62987968 14.89320373 11.27521164], train_hist_grp_loss: [3.96010544 5.11132996 9.95062216], cur_train_grp_loss: [0.09473923 0.12312558 0.23738791], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6802, max_kl_dist_index: 2, max_train_grp_loss:  15.8829, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8932, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:42:13,655 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  41, train_loss:  13.4334, val_loss:  12.2608, grad_norm: 0.0011, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6504, 0.3473, 0.6801, param: [4.15185085 9.50196857 4.96791989 8.86526989], weights: [0.31701988 0.32458797 0.35839215], train_wt_loss:  40.3003, val_wt_loss: 36.7825, train_grp_loss: [11.74820918 15.88262422 11.15739045], val_grp_loss: [10.63007581 14.89283385 11.27532489], train_hist_grp_loss: [ 4.05484687  5.23445329 10.18801177], cur_train_grp_loss: [0.09474143 0.12312334 0.23738961], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6801, max_kl_dist_index: 2, max_train_grp_loss:  15.8826, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8928, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:42:14,741 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  42, train_loss:  13.4334, val_loss:  12.2608, grad_norm: 0.0011, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6504, 0.3473, 0.6801, param: [4.15185615 9.5014672  4.96820856 8.86552838], weights: [0.31663731 0.32438033 0.35898236], train_wt_loss:  40.3003, val_wt_loss: 36.7824, train_grp_loss: [11.74847844 15.88234009 11.15746846], val_grp_loss: [10.63027009 14.89246756 11.27543744], train_hist_grp_loss: [ 4.14959049  5.35757441 10.42540306], cur_train_grp_loss: [0.09474362 0.12312112 0.23739129], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6801, max_kl_dist_index: 2, max_train_grp_loss:  15.8823, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8925, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:42:15,782 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  43, train_loss:  13.4334, val_loss:  12.2608, grad_norm: 0.0012, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6504, 0.3473, 0.6801, param: [4.15186051 9.50096785 4.96849651 8.86578907], weights: [0.31625473 0.32417229 0.35957299], train_wt_loss:  40.3003, val_wt_loss: 36.7824, train_grp_loss: [11.74874559 15.88205836 11.15754556], val_grp_loss: [10.63046251 14.89210487 11.27554931], train_hist_grp_loss: [ 4.24433629  5.48069333 10.662796  ], cur_train_grp_loss: [0.09474579 0.12311892 0.23739295], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6801, max_kl_dist_index: 2, max_train_grp_loss:  15.8821, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8921, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:42:16,816 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  44, train_loss:  13.4335, val_loss:  12.2608, grad_norm: 0.0012, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6504, 0.3473, 0.6801, param: [4.15186393 9.50047053 4.96878376 8.86605194], weights: [0.31587212 0.32396386 0.36016403], train_wt_loss:  40.3004, val_wt_loss: 36.7823, train_grp_loss: [11.74901065 15.88177904 11.15762176], val_grp_loss: [10.63065309 14.89174578 11.27566047], train_hist_grp_loss: [ 4.33908424  5.60381006 10.90019059], cur_train_grp_loss: [0.09474795 0.12311673 0.23739459], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6801, max_kl_dist_index: 2, max_train_grp_loss:  15.8818, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8917, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:42:17,853 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  45, train_loss:  13.4335, val_loss:  12.2608, grad_norm: 0.0012, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6504, 0.3473, 0.6801, param: [4.1518664  9.49997525 4.96907031 8.86631701], weights: [0.31548948 0.32375503 0.36075548], train_wt_loss:  40.3004, val_wt_loss: 36.7823, train_grp_loss: [11.7492736  15.88150213 11.15769706], val_grp_loss: [10.6308418  14.89139029 11.27577094], train_hist_grp_loss: [ 4.43383432  5.72692463 11.1375868 ], cur_train_grp_loss: [0.09475009 0.12311457 0.23739621], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6801, max_kl_dist_index: 2, max_train_grp_loss:  15.8815, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8914, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:42:18,887 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  46, train_loss:  13.4335, val_loss:  12.2607, grad_norm: 0.0012, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6504, 0.3473, 0.6801, param: [4.15186792 9.49948199 4.96935614 8.86658426], weights: [0.31510683 0.32354582 0.36134735], train_wt_loss:  40.3004, val_wt_loss: 36.7822, train_grp_loss: [11.74953446 15.88122762 11.15777145], val_grp_loss: [10.63102867 14.89103841 11.27588072], train_hist_grp_loss: [ 4.52858653  5.85003705 11.37498461], cur_train_grp_loss: [0.09475221 0.12311242 0.23739781], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6801, max_kl_dist_index: 2, max_train_grp_loss:  15.8812, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8910, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:42:19,896 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  47, train_loss:  13.4335, val_loss:  12.2607, grad_norm: 0.0013, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6504, 0.3473, 0.6801, param: [4.1518685  9.49899077 4.96964127 8.86685372], weights: [0.31472416 0.32333621 0.36193963], train_wt_loss:  40.3004, val_wt_loss: 36.7821, train_grp_loss: [11.7497932  15.88095552 11.15784494], val_grp_loss: [10.63121367 14.89069013 11.2759898 ], train_hist_grp_loss: [ 4.62334084  5.97314734 11.612384  ], cur_train_grp_loss: [0.09475431 0.12311029 0.23739939], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6801, max_kl_dist_index: 2, max_train_grp_loss:  15.8810, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8907, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:42:20,914 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  48, train_loss:  13.4335, val_loss:  12.2607, grad_norm: 0.0013, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6504, 0.3472, 0.6801, param: [4.15186814 9.49850158 4.96992569 8.86712537], weights: [0.31434146 0.32312622 0.36253231], train_wt_loss:  40.3004, val_wt_loss: 36.7821, train_grp_loss: [11.75004984 15.88068583 11.15791752], val_grp_loss: [10.63139681 14.89034546 11.27609817], train_hist_grp_loss: [ 4.71809724  6.09625552 11.84978496], cur_train_grp_loss: [0.0947564  0.12310818 0.23740096], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6801, max_kl_dist_index: 2, max_train_grp_loss:  15.8807, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8903, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:42:21,940 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  49, train_loss:  13.4335, val_loss:  12.2607, grad_norm: 0.0013, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6504, 0.3472, 0.6801, param: [4.15186683 9.49801442 4.97020939 8.86739922], weights: [0.31395875 0.32291584 0.36312541], train_wt_loss:  40.3004, val_wt_loss: 36.7820, train_grp_loss: [11.75030437 15.88041855 11.1579892 ], val_grp_loss: [10.63157809 14.8900044  11.27620585], train_hist_grp_loss: [ 4.8128557   6.21936161 12.08718746], cur_train_grp_loss: [0.09475847 0.12310609 0.2374025 ], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6801, max_kl_dist_index: 2, max_train_grp_loss:  15.8804, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8900, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:42:22,993 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  50, train_loss:  13.4335, val_loss:  12.2607, grad_norm: 0.0014, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6504, 0.3472, 0.6801, param: [4.15186457 9.4975293  4.97049239 8.86767527], weights: [0.31357602 0.32270507 0.36371891], train_wt_loss:  40.3004, val_wt_loss: 36.7820, train_grp_loss: [11.75055679 15.88015369 11.15805997], val_grp_loss: [10.63175751 14.88966695 11.27631283], train_hist_grp_loss: [ 4.90761622  6.34246563 12.32459148], cur_train_grp_loss: [0.09476052 0.12310402 0.23740403], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6801, max_kl_dist_index: 2, max_train_grp_loss:  15.8802, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8897, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:42:24,054 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  51, train_loss:  13.4335, val_loss:  12.2606, grad_norm: 0.0014, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6504, 0.3472, 0.6801, param: [4.15186136 9.49704621 4.97077467 8.86795352], weights: [0.31319328 0.32249392 0.36431281], train_wt_loss:  40.3004, val_wt_loss: 36.7819, train_grp_loss: [11.7508071  15.87989123 11.15812982], val_grp_loss: [10.63193507 14.88933312 11.27641911], train_hist_grp_loss: [ 5.00237878  6.4655676  12.56199701], cur_train_grp_loss: [0.09476255 0.12310197 0.23740553], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6801, max_kl_dist_index: 2, max_train_grp_loss:  15.8799, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8893, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:42:25,105 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  52, train_loss:  13.4335, val_loss:  12.2606, grad_norm: 0.0014, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6504, 0.3472, 0.6801, param: [4.15185721 9.49656515 4.97105624 8.86823397], weights: [0.31281051 0.32228238 0.36490711], train_wt_loss:  40.3004, val_wt_loss: 36.7819, train_grp_loss: [11.7510553  15.8796312  11.15819877], val_grp_loss: [10.63211076 14.8890029  11.27652469], train_hist_grp_loss: [ 5.09714335  6.58866753 12.79940403], cur_train_grp_loss: [0.09476457 0.12309993 0.23740702], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6801, max_kl_dist_index: 2, max_train_grp_loss:  15.8796, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8890, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:42:26,159 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  53, train_loss:  13.4335, val_loss:  12.2606, grad_norm: 0.0014, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6504, 0.3472, 0.6801, param: [4.15185211 9.49608613 4.97133709 8.86851663], weights: [0.31242774 0.32207045 0.36550182], train_wt_loss:  40.3004, val_wt_loss: 36.7819, train_grp_loss: [11.75130137 15.87937357 11.15826681], val_grp_loss: [10.63228458 14.88867631 11.27662957], train_hist_grp_loss: [ 5.19190992  6.71176545 13.03681252], cur_train_grp_loss: [0.09476657 0.12309792 0.23740848], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6801, max_kl_dist_index: 2, max_train_grp_loss:  15.8794, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8887, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:42:27,211 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  54, train_loss:  13.4335, val_loss:  12.2606, grad_norm: 0.0015, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6504, 0.3472, 0.6801, param: [4.15184606 9.49560915 4.97161723 8.8688015 ], weights: [0.31204494 0.32185814 0.36609692], train_wt_loss:  40.3004, val_wt_loss: 36.7818, train_grp_loss: [11.75154534 15.87911837 11.15833394], val_grp_loss: [10.63245654 14.88835333 11.27673374], train_hist_grp_loss: [ 5.28667848  6.83486136 13.27422245], cur_train_grp_loss: [0.09476856 0.12309592 0.23740993], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6801, max_kl_dist_index: 2, max_train_grp_loss:  15.8791, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8884, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:42:28,259 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  55, train_loss:  13.4335, val_loss:  12.2606, grad_norm: 0.0015, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6504, 0.3472, 0.6800, param: [4.15183906 9.4951342  4.97189665 8.86908858], weights: [0.31166214 0.32164544 0.36669242], train_wt_loss:  40.3004, val_wt_loss: 36.7818, train_grp_loss: [11.75178718 15.87886558 11.15840015], val_grp_loss: [10.63262662 14.88803397 11.27683721], train_hist_grp_loss: [ 5.38144901  6.95795531 13.51163381], cur_train_grp_loss: [0.09477053 0.12309394 0.23741136], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6800, max_kl_dist_index: 2, max_train_grp_loss:  15.8789, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8880, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:42:29,328 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  56, train_loss:  13.4335, val_loss:  12.2606, grad_norm: 0.0015, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6504, 0.3472, 0.6800, param: [4.15183111 9.4946613  4.97217536 8.86937787], weights: [0.31127932 0.32143237 0.36728832], train_wt_loss:  40.3004, val_wt_loss: 36.7817, train_grp_loss: [11.7520269  15.87861521 11.15846545], val_grp_loss: [10.63279484 14.88771824 11.27693997], train_hist_grp_loss: [ 5.47622149  7.08104729 13.74904658], cur_train_grp_loss: [0.09477248 0.12309198 0.23741277], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6800, max_kl_dist_index: 2, max_train_grp_loss:  15.8786, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8877, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:42:30,366 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  57, train_loss:  13.4335, val_loss:  12.2606, grad_norm: 0.0015, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6504, 0.3472, 0.6800, param: [4.15182221 9.49419042 4.97245335 8.86966937], weights: [0.31089649 0.32121891 0.3678846 ], train_wt_loss:  40.3004, val_wt_loss: 36.7817, train_grp_loss: [11.7522645  15.87836726 11.15852984], val_grp_loss: [10.63296118 14.88740614 11.27704203], train_hist_grp_loss: [ 5.5709959   7.20413733 13.98646074], cur_train_grp_loss: [0.09477441 0.12309004 0.23741416], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6800, max_kl_dist_index: 2, max_train_grp_loss:  15.8784, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8874, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:42:31,407 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  58, train_loss:  13.4335, val_loss:  12.2605, grad_norm: 0.0016, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6504, 0.3472, 0.6800, param: [4.15181237 9.49372159 4.97273061 8.86996308], weights: [0.31051365 0.32100507 0.36848129], train_wt_loss:  40.3004, val_wt_loss: 36.7816, train_grp_loss: [11.75249997 15.87812173 11.15859331], val_grp_loss: [10.63312565 14.88709766 11.27714339], train_hist_grp_loss: [ 5.66577223  7.32722545 14.22387626], cur_train_grp_loss: [0.09477633 0.12308812 0.23741553], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6800, max_kl_dist_index: 2, max_train_grp_loss:  15.8781, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8871, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:42:32,438 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  59, train_loss:  13.4335, val_loss:  12.2605, grad_norm: 0.0016, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6504, 0.3472, 0.6800, param: [4.15180157 9.4932548  4.97300716 8.87025901], weights: [0.31013079 0.32079085 0.36907836], train_wt_loss:  40.3004, val_wt_loss: 36.7816, train_grp_loss: [11.75273332 15.87787863 11.15865587], val_grp_loss: [10.63328824 14.88679282 11.27724403], train_hist_grp_loss: [ 5.76055045  7.45031166 14.46129314], cur_train_grp_loss: [0.09477823 0.12308621 0.23741688], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6800, max_kl_dist_index: 2, max_train_grp_loss:  15.8779, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8868, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:42:33,468 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  60, train_loss:  13.4335, val_loss:  12.2605, grad_norm: 0.0016, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6504, 0.3472, 0.6800, param: [4.15178982 9.49279005 4.97328299 8.87055716], weights: [0.30974793 0.32057625 0.36967582], train_wt_loss:  40.3004, val_wt_loss: 36.7816, train_grp_loss: [11.75296454 15.87763795 11.15871751], val_grp_loss: [10.63344896 14.88649161 11.27734397], train_hist_grp_loss: [ 5.85533056  7.57339599 14.69871135], cur_train_grp_loss: [0.09478011 0.12308433 0.23741821], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6800, max_kl_dist_index: 2, max_train_grp_loss:  15.8776, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8865, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:42:34,542 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  61, train_loss:  13.4335, val_loss:  12.2605, grad_norm: 0.0017, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6504, 0.3472, 0.6800, param: [4.15177712 9.49232733 4.9735581  8.87085752], weights: [0.30936506 0.32036127 0.37027367], train_wt_loss:  40.3004, val_wt_loss: 36.7815, train_grp_loss: [11.75319363 15.87739969 11.15877824], val_grp_loss: [10.6336078  14.88619403 11.2774432 ], train_hist_grp_loss: [ 5.95011253  7.69647846 14.93613087], cur_train_grp_loss: [0.09478197 0.12308246 0.23741952], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6800, max_kl_dist_index: 2, max_train_grp_loss:  15.8774, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8862, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:42:35,590 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  62, train_loss:  13.4335, val_loss:  12.2605, grad_norm: 0.0017, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6504, 0.3471, 0.6800, param: [4.15176347 9.49186666 4.97383248 8.87116011], weights: [0.30898218 0.32014591 0.3708719 ], train_wt_loss:  40.3004, val_wt_loss: 36.7815, train_grp_loss: [11.75342059 15.87716386 11.15883804], val_grp_loss: [10.63376476 14.88590009 11.27754173], train_hist_grp_loss: [ 6.04489635  7.81955907 15.17355169], cur_train_grp_loss: [0.09478382 0.12308062 0.23742081], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6800, max_kl_dist_index: 2, max_train_grp_loss:  15.8772, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8859, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:42:36,637 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  63, train_loss:  13.4335, val_loss:  12.2605, grad_norm: 0.0017, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6504, 0.3471, 0.6800, param: [4.15174886 9.49140803 4.97410615 8.87146492], weights: [0.3085993  0.31993018 0.37147052], train_wt_loss:  40.3004, val_wt_loss: 36.7814, train_grp_loss: [11.75364542 15.87693046 11.15889693], val_grp_loss: [10.63391984 14.88560978 11.27763954], train_hist_grp_loss: [ 6.139682    7.94263786 15.41097377], cur_train_grp_loss: [0.09478565 0.12307879 0.23742209], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6800, max_kl_dist_index: 2, max_train_grp_loss:  15.8769, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8856, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:42:37,676 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  64, train_loss:  13.4335, val_loss:  12.2605, grad_norm: 0.0017, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6504, 0.3471, 0.6800, param: [4.15173331 9.49095144 4.97437908 8.87177195], weights: [0.30821641 0.31971407 0.37206952], train_wt_loss:  40.3004, val_wt_loss: 36.7814, train_grp_loss: [11.75386812 15.87669949 11.1589549 ], val_grp_loss: [10.63407304 14.88532312 11.27773664], train_hist_grp_loss: [ 6.23446946  8.06571484 15.64839711], cur_train_grp_loss: [0.09478746 0.12307698 0.23742334], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6800, max_kl_dist_index: 2, max_train_grp_loss:  15.8767, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8853, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:42:38,728 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  65, train_loss:  13.4335, val_loss:  12.2605, grad_norm: 0.0018, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6504, 0.3471, 0.6800, param: [4.1517168  9.4904969  4.9746513  8.87208121], weights: [0.30783351 0.31949759 0.3726689 ], train_wt_loss:  40.3005, val_wt_loss: 36.7814, train_grp_loss: [11.75408868 15.87647094 11.15901194], val_grp_loss: [10.63422435 14.8850401  11.27783304], train_hist_grp_loss: [ 6.32925872  8.18879003 15.88582169], cur_train_grp_loss: [0.09478926 0.12307519 0.23742457], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6800, max_kl_dist_index: 2, max_train_grp_loss:  15.8765, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8850, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:42:39,829 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  66, train_loss:  13.4335, val_loss:  12.2604, grad_norm: 0.0018, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6504, 0.3471, 0.6800, param: [4.15169933 9.49004439 4.97492278 8.87239269], weights: [0.30745061 0.31928073 0.37326866], train_wt_loss:  40.3005, val_wt_loss: 36.7813, train_grp_loss: [11.7543071  15.87624483 11.15906807], val_grp_loss: [10.63437379 14.88476072 11.27792872], train_hist_grp_loss: [ 6.42404976  8.31186345 16.12324747], cur_train_grp_loss: [0.09479104 0.12307342 0.23742579], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6800, max_kl_dist_index: 2, max_train_grp_loss:  15.8762, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8848, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:42:40,865 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  67, train_loss:  13.4335, val_loss:  12.2604, grad_norm: 0.0018, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6504, 0.3471, 0.6800, param: [4.15168092 9.48959393 4.97519354 8.8727064 ], weights: [0.30706771 0.3190635  0.37386879], train_wt_loss:  40.3005, val_wt_loss: 36.7813, train_grp_loss: [11.75452338 15.87602115 11.15912327], val_grp_loss: [10.63452133 14.88448499 11.27802369], train_hist_grp_loss: [ 6.51884256  8.43493512 16.36067445], cur_train_grp_loss: [0.0947928  0.12307167 0.23742698], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6800, max_kl_dist_index: 2, max_train_grp_loss:  15.8760, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8845, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:42:41,903 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  68, train_loss:  13.4335, val_loss:  12.2604, grad_norm: 0.0018, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6504, 0.3471, 0.6800, param: [4.15166155 9.48914552 4.97546357 8.87302234], weights: [0.3066848  0.31884589 0.3744693 ], train_wt_loss:  40.3005, val_wt_loss: 36.7813, train_grp_loss: [11.75473752 15.8757999  11.15917755], val_grp_loss: [10.63466699 14.88421291 11.27811794], train_hist_grp_loss: [ 6.6136371   8.55800505 16.59810261], cur_train_grp_loss: [0.09479454 0.12306993 0.23742815], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6800, max_kl_dist_index: 2, max_train_grp_loss:  15.8758, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8842, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:42:42,928 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  69, train_loss:  13.4335, val_loss:  12.2604, grad_norm: 0.0019, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6505, 0.3471, 0.6800, param: [4.15164122 9.48869914 4.97573287 8.87334051], weights: [0.3063019  0.31862791 0.37507019], train_wt_loss:  40.3005, val_wt_loss: 36.7813, train_grp_loss: [11.75494952 15.87558109 11.15923091], val_grp_loss: [10.63481077 14.88394447 11.27821149], train_hist_grp_loss: [ 6.70843337  8.68107326 16.83553192], cur_train_grp_loss: [0.09479627 0.12306822 0.23742931], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6800, max_kl_dist_index: 2, max_train_grp_loss:  15.8756, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8839, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:42:43,985 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  70, train_loss:  13.4335, val_loss:  12.2604, grad_norm: 0.0019, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6505, 0.3471, 0.6800, param: [4.15161994 9.48825482 4.97600144 8.87366092], weights: [0.30591899 0.31840957 0.37567145], train_wt_loss:  40.3005, val_wt_loss: 36.7812, train_grp_loss: [11.75515938 15.87536471 11.15928335], val_grp_loss: [10.63495265 14.88367969 11.27830431], train_hist_grp_loss: [ 6.80323135  8.80413978 17.07296236], cur_train_grp_loss: [0.09479798 0.12306652 0.23743044], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6800, max_kl_dist_index: 2, max_train_grp_loss:  15.8754, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8837, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:42:45,015 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  71, train_loss:  13.4335, val_loss:  12.2604, grad_norm: 0.0019, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6505, 0.3471, 0.6800, param: [4.1515977  9.48781254 4.97626929 8.87398356], weights: [0.30553608 0.31819085 0.37627307], train_wt_loss:  40.3005, val_wt_loss: 36.7812, train_grp_loss: [11.75536709 15.87515076 11.15933486], val_grp_loss: [10.63509264 14.88341856 11.27839643], train_hist_grp_loss: [ 6.89803103  8.92720463 17.31039392], cur_train_grp_loss: [0.09479967 0.12306484 0.23743156], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6800, max_kl_dist_index: 2, max_train_grp_loss:  15.8752, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8834, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:42:46,063 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  72, train_loss:  13.4335, val_loss:  12.2604, grad_norm: 0.0019, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6505, 0.3471, 0.6800, param: [4.15157451 9.4873723  4.9765364  8.87430843], weights: [0.30515317 0.31797176 0.37687507], train_wt_loss:  40.3005, val_wt_loss: 36.7812, train_grp_loss: [11.75557266 15.87493926 11.15938544], val_grp_loss: [10.63523075 14.88316109 11.27848783], train_hist_grp_loss: [ 6.99283237  9.05026781 17.54782658], cur_train_grp_loss: [0.09480135 0.12306318 0.23743266], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6800, max_kl_dist_index: 2, max_train_grp_loss:  15.8749, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8832, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:42:47,079 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  73, train_loss:  13.4335, val_loss:  12.2604, grad_norm: 0.0020, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6505, 0.3471, 0.6800, param: [4.15155037 9.48693411 4.97680277 8.87463555], weights: [0.30477027 0.3177523  0.37747743], train_wt_loss:  40.3005, val_wt_loss: 36.7811, train_grp_loss: [11.75577608 15.87473019 11.1594351 ], val_grp_loss: [10.63536696 14.88290727 11.27857851], train_hist_grp_loss: [ 7.08763538  9.17332936 17.78526031], cur_train_grp_loss: [0.09480301 0.12306154 0.23743373], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6800, max_kl_dist_index: 2, max_train_grp_loss:  15.8747, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8829, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:42:48,118 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  74, train_loss:  13.4335, val_loss:  12.2604, grad_norm: 0.0020, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6505, 0.3471, 0.6800, param: [4.15152526 9.48649797 4.97706842 8.8749649 ], weights: [0.30438737 0.31753248 0.37808016], train_wt_loss:  40.3005, val_wt_loss: 36.7811, train_grp_loss: [11.75597734 15.87452357 11.15948383], val_grp_loss: [10.63550127 14.88265712 11.27866848], train_hist_grp_loss: [ 7.18244002  9.29638928 18.0226951 ], cur_train_grp_loss: [0.09480465 0.12305992 0.23743479], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6800, max_kl_dist_index: 2, max_train_grp_loss:  15.8745, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8827, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:42:49,166 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  75, train_loss:  13.4335, val_loss:  12.2604, grad_norm: 0.0020, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6505, 0.3471, 0.6800, param: [4.1514992  9.48606387 4.97733332 8.87529649], weights: [0.30400447 0.31731229 0.37868324], train_wt_loss:  40.3005, val_wt_loss: 36.7811, train_grp_loss: [11.75617646 15.87431938 11.15953163], val_grp_loss: [10.63563369 14.88241062 11.27875772], train_hist_grp_loss: [ 7.27724629  9.4194476  18.26013093], cur_train_grp_loss: [0.09480627 0.12305832 0.23743583], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6800, max_kl_dist_index: 2, max_train_grp_loss:  15.8743, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8824, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:42:50,230 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  76, train_loss:  13.4335, val_loss:  12.2604, grad_norm: 0.0021, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6505, 0.3471, 0.6800, param: [4.15147218 9.48563182 4.9775975  8.87563032], weights: [0.30362157 0.31709173 0.3792867 ], train_wt_loss:  40.3005, val_wt_loss: 36.7811, train_grp_loss: [11.75637342 15.87411764 11.15957851], val_grp_loss: [10.63576422 14.88216779 11.27884625], train_hist_grp_loss: [ 7.37205417  9.54250434 18.49756777], cur_train_grp_loss: [0.09480787 0.12305674 0.23743684], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6800, max_kl_dist_index: 2, max_train_grp_loss:  15.8741, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8822, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:42:51,287 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  77, train_loss:  13.4335, val_loss:  12.2604, grad_norm: 0.0021, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6505, 0.3471, 0.6800, param: [4.15144421 9.48520182 4.97786094 8.8759664 ], weights: [0.30323868 0.31687081 0.37989051], train_wt_loss:  40.3005, val_wt_loss: 36.7811, train_grp_loss: [11.75656823 15.87391834 11.15962446], val_grp_loss: [10.63589285 14.88192862 11.27893407], train_hist_grp_loss: [ 7.46686363  9.66555952 18.73500561], cur_train_grp_loss: [0.09480946 0.12305518 0.23743784], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6800, max_kl_dist_index: 2, max_train_grp_loss:  15.8739, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8819, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:42:52,303 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  78, train_loss:  13.4335, val_loss:  12.2603, grad_norm: 0.0021, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6505, 0.3471, 0.6800, param: [4.15141527 9.48477387 4.97812363 8.87630471], weights: [0.3028558  0.31664952 0.38049468], train_wt_loss:  40.3005, val_wt_loss: 36.7810, train_grp_loss: [11.75676089 15.87372148 11.15966947], val_grp_loss: [10.63601958 14.88169312 11.27902116], train_hist_grp_loss: [ 7.56167466  9.78861315 18.97244443], cur_train_grp_loss: [0.09481103 0.12305363 0.23743882], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6800, max_kl_dist_index: 2, max_train_grp_loss:  15.8737, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8817, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:42:53,364 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  79, train_loss:  13.4335, val_loss:  12.2603, grad_norm: 0.0021, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6505, 0.3471, 0.6800, param: [4.15138538 9.48434797 4.9783856  8.87664528], weights: [0.30247293 0.31642787 0.3810992 ], train_wt_loss:  40.3005, val_wt_loss: 36.7810, train_grp_loss: [11.75695139 15.87352707 11.15971356], val_grp_loss: [10.63614441 14.88146129 11.27910753], train_hist_grp_loss: [ 7.65648725  9.91166525 19.2098842 ], cur_train_grp_loss: [0.09481259 0.1230521  0.23743978], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6800, max_kl_dist_index: 2, max_train_grp_loss:  15.8735, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8815, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:42:54,419 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  80, train_loss:  13.4335, val_loss:  12.2603, grad_norm: 0.0022, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6505, 0.3471, 0.6800, param: [4.15135453 9.48392411 4.97864682 8.87698809], weights: [0.30209006 0.31620586 0.38170408], train_wt_loss:  40.3005, val_wt_loss: 36.7810, train_grp_loss: [11.75713973 15.87333511 11.15975671], val_grp_loss: [10.63626734 14.88123312 11.27919318], train_hist_grp_loss: [ 7.75130138 10.03471585 19.44732492], cur_train_grp_loss: [0.09481412 0.1230506  0.23744071], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6800, max_kl_dist_index: 2, max_train_grp_loss:  15.8733, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8812, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:42:55,436 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  81, train_loss:  13.4335, val_loss:  12.2603, grad_norm: 0.0022, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6505, 0.3471, 0.6800, param: [4.15132272 9.48350231 4.9789073  8.87733315], weights: [0.3017072  0.31598349 0.38230931], train_wt_loss:  40.3005, val_wt_loss: 36.7810, train_grp_loss: [11.75732591 15.87314559 11.15979894], val_grp_loss: [10.63638836 14.88100863 11.27927812], train_hist_grp_loss: [ 7.84611702 10.15776496 19.68476655], cur_train_grp_loss: [0.09481564 0.12304911 0.23744163], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6800, max_kl_dist_index: 2, max_train_grp_loss:  15.8731, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8810, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:42:56,471 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  82, train_loss:  13.4335, val_loss:  12.2603, grad_norm: 0.0022, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6505, 0.3471, 0.6800, param: [4.15128995 9.48308255 4.97916704 8.87768046], weights: [0.30132435 0.31576076 0.38291489], train_wt_loss:  40.3006, val_wt_loss: 36.7810, train_grp_loss: [11.75750993 15.87295852 11.15984023], val_grp_loss: [10.63650749 14.88078781 11.27936233], train_hist_grp_loss: [ 7.94093416 10.2808126  19.92220908], cur_train_grp_loss: [0.09481714 0.12304764 0.23744253], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6800, max_kl_dist_index: 2, max_train_grp_loss:  15.8730, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8808, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:42:57,492 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  83, train_loss:  13.4335, val_loss:  12.2603, grad_norm: 0.0022, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6505, 0.3470, 0.6800, param: [4.15125622 9.48266484 4.97942604 8.87803002], weights: [0.30094151 0.31553766 0.38352083], train_wt_loss:  40.3006, val_wt_loss: 36.7810, train_grp_loss: [11.75769178 15.8727739  11.15988059], val_grp_loss: [10.63662471 14.88057067 11.27944581], train_hist_grp_loss: [ 8.03575279 10.40385879 20.15965249], cur_train_grp_loss: [0.09481863 0.12304619 0.23744341], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6800, max_kl_dist_index: 2, max_train_grp_loss:  15.8728, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8806, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:42:58,550 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  84, train_loss:  13.4335, val_loss:  12.2603, grad_norm: 0.0023, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6505, 0.3470, 0.6800, param: [4.15122152 9.48224919 4.9796843  8.87838183], weights: [0.30055868 0.31531421 0.38412711], train_wt_loss:  40.3006, val_wt_loss: 36.7809, train_grp_loss: [11.75787147 15.87259173 11.15992001], val_grp_loss: [10.63674002 14.88035721 11.27952858], train_hist_grp_loss: [ 8.13057289 10.52690355 20.39709676], cur_train_grp_loss: [0.0948201  0.12304476 0.23744427], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6800, max_kl_dist_index: 2, max_train_grp_loss:  15.8726, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8804, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:42:59,621 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  85, train_loss:  13.4335, val_loss:  12.2603, grad_norm: 0.0023, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6506, 0.3470, 0.6800, param: [4.15118587 9.48183558 4.97994181 8.8787359 ], weights: [0.30017587 0.3150904  0.38473373], train_wt_loss:  40.3006, val_wt_loss: 36.7809, train_grp_loss: [11.758049   15.87241201 11.1599585 ], val_grp_loss: [10.63685343 14.88014742 11.27961062], train_hist_grp_loss: [ 8.22539443 10.64994689 20.63454186], cur_train_grp_loss: [0.09482154 0.12304335 0.23744511], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6800, max_kl_dist_index: 2, max_train_grp_loss:  15.8724, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8801, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:43:00,656 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  86, train_loss:  13.4335, val_loss:  12.2603, grad_norm: 0.0023, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6506, 0.3470, 0.6800, param: [4.15114926 9.48142403 4.98019858 8.87909222], weights: [0.29979307 0.31486623 0.3853407 ], train_wt_loss:  40.3006, val_wt_loss: 36.7809, train_grp_loss: [11.75822436 15.87223475 11.15999606], val_grp_loss: [10.63696494 14.87994132 11.27969194], train_hist_grp_loss: [ 8.32021741 10.77298885 20.87198779], cur_train_grp_loss: [0.09482298 0.12304195 0.23744593], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6800, max_kl_dist_index: 2, max_train_grp_loss:  15.8722, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8799, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:43:01,679 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  87, train_loss:  13.4335, val_loss:  12.2603, grad_norm: 0.0023, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6506, 0.3470, 0.6800, param: [4.15111168 9.48101453 4.9804546  8.8794508 ], weights: [0.29941028 0.31464171 0.38594801], train_wt_loss:  40.3006, val_wt_loss: 36.7809, train_grp_loss: [11.75839755 15.87205994 11.16003268], val_grp_loss: [10.63707453 14.87973889 11.27977254], train_hist_grp_loss: [ 8.4150418  10.89602943 21.10943452], cur_train_grp_loss: [0.09482439 0.12304058 0.23744672], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6800, max_kl_dist_index: 2, max_train_grp_loss:  15.8721, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8797, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:43:02,700 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  88, train_loss:  13.4335, val_loss:  12.2603, grad_norm: 0.0024, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6506, 0.3470, 0.6800, param: [4.15107315 9.48060708 4.98070987 8.87981164], weights: [0.29902751 0.31441683 0.38655566], train_wt_loss:  40.3006, val_wt_loss: 36.7809, train_grp_loss: [11.75856857 15.87188758 11.16006836], val_grp_loss: [10.63718222 14.87954015 11.2798524 ], train_hist_grp_loss: [ 8.50986758 11.01906865 21.34688202], cur_train_grp_loss: [0.09482579 0.12303922 0.2374475 ], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6800, max_kl_dist_index: 2, max_train_grp_loss:  15.8719, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8795, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:43:03,740 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  89, train_loss:  13.4335, val_loss:  12.2603, grad_norm: 0.0024, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6506, 0.3470, 0.6800, param: [4.15103365 9.48020168 4.9809644  8.88017473], weights: [0.29864475 0.3141916  0.38716365], train_wt_loss:  40.3006, val_wt_loss: 36.7809, train_grp_loss: [11.75873742 15.87171768 11.16010311], val_grp_loss: [10.63728799 14.8793451  11.27993155], train_hist_grp_loss: [ 8.60469475 11.14210654 21.58433028], cur_train_grp_loss: [0.09482717 0.12303789 0.23744826], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6800, max_kl_dist_index: 2, max_train_grp_loss:  15.8717, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8793, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:43:04,812 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  90, train_loss:  13.4335, val_loss:  12.2603, grad_norm: 0.0024, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6506, 0.3470, 0.6800, param: [4.15099319 9.47979833 4.98121818 8.88054008], weights: [0.29826202 0.31396601 0.38777197], train_wt_loss:  40.3006, val_wt_loss: 36.7809, train_grp_loss: [11.7589041  15.87155023 11.16013692], val_grp_loss: [10.63739186 14.87915374 11.28000997], train_hist_grp_loss: [ 8.69952328 11.26514311 21.82177928], cur_train_grp_loss: [0.09482853 0.12303657 0.237449  ], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6800, max_kl_dist_index: 2, max_train_grp_loss:  15.8716, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8792, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:43:05,875 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  91, train_loss:  13.4335, val_loss:  12.2603, grad_norm: 0.0024, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6506, 0.3470, 0.6800, param: [4.15095176 9.47939703 4.98147121 8.8809077 ], weights: [0.29787929 0.31374007 0.38838063], train_wt_loss:  40.3006, val_wt_loss: 36.7809, train_grp_loss: [11.75906861 15.87138525 11.16016979], val_grp_loss: [10.63749381 14.87896606 11.28008766], train_hist_grp_loss: [ 8.79435315 11.38817838 22.05922901], cur_train_grp_loss: [0.09482987 0.12303527 0.23744972], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6800, max_kl_dist_index: 2, max_train_grp_loss:  15.8714, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8790, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:43:06,929 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  92, train_loss:  13.4335, val_loss:  12.2603, grad_norm: 0.0025, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6506, 0.3470, 0.6800, param: [4.15090937 9.47899779 4.98172348 8.88127757], weights: [0.29749659 0.31351378 0.38898962], train_wt_loss:  40.3006, val_wt_loss: 36.7809, train_grp_loss: [11.75923094 15.87122272 11.16020172], val_grp_loss: [10.63759385 14.87878208 11.28016462], train_hist_grp_loss: [ 8.88918435 11.51121238 22.29667943], cur_train_grp_loss: [0.0948312  0.12303399 0.23745042], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6800, max_kl_dist_index: 2, max_train_grp_loss:  15.8712, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8788, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2375, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:43:07,992 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  93, train_loss:  13.4335, val_loss:  12.2603, grad_norm: 0.0025, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6506, 0.3470, 0.6800, param: [4.15086602 9.4786006  4.98197501 8.88164972], weights: [0.29711391 0.31328714 0.38959895], train_wt_loss:  40.3006, val_wt_loss: 36.7809, train_grp_loss: [11.75939109 15.87106265 11.16023272], val_grp_loss: [10.63769197 14.87860179 11.28024086], train_hist_grp_loss: [ 8.98401686 11.63424511 22.53413053], cur_train_grp_loss: [0.09483251 0.12303273 0.2374511 ], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6800, max_kl_dist_index: 2, max_train_grp_loss:  15.8711, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8786, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2375, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:43:09,088 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  94, train_loss:  13.4335, val_loss:  12.2603, grad_norm: 0.0025, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6506, 0.3470, 0.6800, param: [4.1508217  9.47820546 4.98222578 8.88202412], weights: [0.29673125 0.31306015 0.3902086 ], train_wt_loss:  40.3006, val_wt_loss: 36.7809, train_grp_loss: [11.75954907 15.87090504 11.16026277], val_grp_loss: [10.63778818 14.87842519 11.28031637], train_hist_grp_loss: [ 9.07885065 11.75727661 22.77158229], cur_train_grp_loss: [0.0948338  0.12303149 0.23745176], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6800, max_kl_dist_index: 2, max_train_grp_loss:  15.8709, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8784, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2375, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:43:10,111 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  95, train_loss:  13.4335, val_loss:  12.2603, grad_norm: 0.0025, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6506, 0.3470, 0.6800, param: [4.15077642 9.47781238 4.9824758  8.88240079], weights: [0.29634861 0.31283281 0.39081858], train_wt_loss:  40.3006, val_wt_loss: 36.7808, train_grp_loss: [11.75970487 15.8707499  11.16029189], val_grp_loss: [10.63788248 14.87825229 11.28039115], train_hist_grp_loss: [ 9.17368573 11.88030688 23.00903469], cur_train_grp_loss: [0.09483507 0.12303027 0.2374524 ], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6800, max_kl_dist_index: 2, max_train_grp_loss:  15.8707, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8783, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2375, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:43:11,144 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  96, train_loss:  13.4335, val_loss:  12.2603, grad_norm: 0.0026, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6506, 0.3470, 0.6801, param: [4.15073018 9.47742135 4.98272507 8.88277973], weights: [0.29596599 0.31260513 0.39142889], train_wt_loss:  40.3006, val_wt_loss: 36.7808, train_grp_loss: [11.75985849 15.87059722 11.16032006], val_grp_loss: [10.63797485 14.87808308 11.2804652 ], train_hist_grp_loss: [ 9.26852206 12.00333595 23.24648771], cur_train_grp_loss: [0.09483633 0.12302907 0.23745302], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6801, max_kl_dist_index: 2, max_train_grp_loss:  15.8706, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8781, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2375, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:43:12,203 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  97, train_loss:  13.4336, val_loss:  12.2603, grad_norm: 0.0026, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6507, 0.3470, 0.6801, param: [4.15068297 9.47703237 4.98297358 8.88316094], weights: [0.29558339 0.31237709 0.39203952], train_wt_loss:  40.3007, val_wt_loss: 36.7808, train_grp_loss: [11.76000992 15.870447   11.16034729], val_grp_loss: [10.63806531 14.87791758 11.28053852], train_hist_grp_loss: [ 9.36335963 12.12636383 23.48394132], cur_train_grp_loss: [0.09483757 0.12302789 0.23745362], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6801, max_kl_dist_index: 2, max_train_grp_loss:  15.8704, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8779, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2375, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:43:13,251 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  98, train_loss:  13.4336, val_loss:  12.2603, grad_norm: 0.0026, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6507, 0.3470, 0.6801, param: [4.15063479 9.47664545 4.98322133 8.88354441], weights: [0.29520082 0.31214871 0.39265047], train_wt_loss:  40.3007, val_wt_loss: 36.7808, train_grp_loss: [11.76015918 15.87029924 11.16037359], val_grp_loss: [10.63815385 14.87775577 11.28061112], train_hist_grp_loss: [ 9.45819842 12.24939055 23.72139552], cur_train_grp_loss: [0.09483879 0.12302672 0.2374542 ], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6801, max_kl_dist_index: 2, max_train_grp_loss:  15.8703, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8778, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2375, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:43:14,307 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  99, train_loss:  13.4336, val_loss:  12.2603, grad_norm: 0.0026, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6507, 0.3470, 0.6801, param: [4.15058565 9.47626058 4.98346833 8.88393016], weights: [0.29481828 0.31191999 0.39326174], train_wt_loss:  40.3007, val_wt_loss: 36.7808, train_grp_loss: [11.76030625 15.87015395 11.16039893], val_grp_loss: [10.63824047 14.87759767 11.28068298], train_hist_grp_loss: [ 9.55303841 12.37241613 23.95885028], cur_train_grp_loss: [0.09483999 0.12302558 0.23745476], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6801, max_kl_dist_index: 2, max_train_grp_loss:  15.8702, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8776, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2375, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:43:15,361 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  100, train_loss:  13.4336, val_loss:  12.2603, grad_norm: 0.0027, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6507, 0.3470, 0.6801, param: [4.15053554 9.47587777 4.98371457 8.88431817], weights: [0.29443576 0.31169092 0.39387333], train_wt_loss:  40.3007, val_wt_loss: 36.7809, train_grp_loss: [11.76045114 15.87001113 11.16042334], val_grp_loss: [10.63832517 14.87744328 11.28075411], train_hist_grp_loss: [ 9.64787959 12.49544058 24.19630558], cur_train_grp_loss: [0.09484118 0.12302445 0.2374553 ], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6801, max_kl_dist_index: 2, max_train_grp_loss:  15.8700, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8774, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2375, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:43:16,371 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  101, train_loss:  13.4336, val_loss:  12.2603, grad_norm: 0.0027, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6507, 0.3470, 0.6801, param: [4.15048446 9.475497   4.98396005 8.88470846], weights: [0.29405326 0.31146151 0.39448523], train_wt_loss:  40.3007, val_wt_loss: 36.7809, train_grp_loss: [11.76059384 15.86987078 11.1604468 ], val_grp_loss: [10.63840795 14.87729258 11.28082451], train_hist_grp_loss: [ 9.74272194 12.61846392 24.43376139], cur_train_grp_loss: [0.09484235 0.12302334 0.23745582], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6801, max_kl_dist_index: 2, max_train_grp_loss:  15.8699, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8773, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2375, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:43:17,397 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  102, train_loss:  13.4336, val_loss:  12.2603, grad_norm: 0.0027, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6507, 0.3470, 0.6801, param: [4.15043242 9.4751183  4.98420476 8.88510103], weights: [0.2936708  0.31123175 0.39509745], train_wt_loss:  40.3007, val_wt_loss: 36.7809, train_grp_loss: [11.76073435 15.86973289 11.16046932], val_grp_loss: [10.63848881 14.8771456  11.28089418], train_hist_grp_loss: [ 9.83756543 12.74148617 24.67121771], cur_train_grp_loss: [0.0948435  0.12302225 0.23745631], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6801, max_kl_dist_index: 2, max_train_grp_loss:  15.8697, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8771, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2375, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:43:18,457 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  103, train_loss:  13.4336, val_loss:  12.2603, grad_norm: 0.0027, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6507, 0.3470, 0.6801, param: [4.1503794  9.47474165 4.98444872 8.88549587], weights: [0.29328836 0.31100166 0.39570998], train_wt_loss:  40.3007, val_wt_loss: 36.7809, train_grp_loss: [11.76087268 15.86959748 11.1604909 ], val_grp_loss: [10.63856774 14.87700233 11.28096311], train_hist_grp_loss: [ 9.93241007 12.86450736 24.9086745 ], cur_train_grp_loss: [0.09484463 0.12302119 0.23745679], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6801, max_kl_dist_index: 2, max_train_grp_loss:  15.8696, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8770, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2375, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:43:19,503 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  104, train_loss:  13.4336, val_loss:  12.2603, grad_norm: 0.0028, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6507, 0.3470, 0.6801, param: [4.15032543 9.47436705 4.98469191 8.88589298], weights: [0.29290595 0.31077122 0.39632283], train_wt_loss:  40.3007, val_wt_loss: 36.7809, train_grp_loss: [11.76100881 15.86946453 11.16051153], val_grp_loss: [10.63864475 14.87686276 11.28103131], train_hist_grp_loss: [10.02725581 12.9875275  25.14613175], cur_train_grp_loss: [0.09484575 0.12302014 0.23745725], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6801, max_kl_dist_index: 2, max_train_grp_loss:  15.8695, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8769, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2375, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:43:20,565 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  105, train_loss:  13.4336, val_loss:  12.2603, grad_norm: 0.0028, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6507, 0.3470, 0.6801, param: [4.15027048 9.47399451 4.98493435 8.88629237], weights: [0.29252358 0.31054044 0.39693598], train_wt_loss:  40.3007, val_wt_loss: 36.7809, train_grp_loss: [11.76114276 15.86933406 11.16053121], val_grp_loss: [10.63871983 14.87672691 11.28109878], train_hist_grp_loss: [10.12210266 13.1105466  25.38358945], cur_train_grp_loss: [0.09484685 0.1230191  0.23745769], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6801, max_kl_dist_index: 2, max_train_grp_loss:  15.8693, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8767, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2375, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:43:21,607 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  106, train_loss:  13.4336, val_loss:  12.2603, grad_norm: 0.0028, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6507, 0.3470, 0.6801, param: [4.15021456 9.47362402 4.98517601 8.88669404], weights: [0.29214123 0.31030933 0.39754944], train_wt_loss:  40.3007, val_wt_loss: 36.7809, train_grp_loss: [11.76127451 15.86920606 11.16054995], val_grp_loss: [10.63879299 14.87659477 11.28116552], train_hist_grp_loss: [10.21695058 13.23356469 25.62104756], cur_train_grp_loss: [0.09484793 0.12301809 0.23745811], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6801, max_kl_dist_index: 2, max_train_grp_loss:  15.8692, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8766, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2375, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:43:22,651 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  107, train_loss:  13.4336, val_loss:  12.2603, grad_norm: 0.0028, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6508, 0.3470, 0.6801, param: [4.15015768 9.47325558 4.98541691 8.88709799], weights: [0.29175892 0.31007788 0.3981632 ], train_wt_loss:  40.3007, val_wt_loss: 36.7809, train_grp_loss: [11.76140407 15.86908053 11.16056774], val_grp_loss: [10.63886422 14.87646635 11.28123152], train_hist_grp_loss: [10.31179957 13.35658179 25.85850607], cur_train_grp_loss: [0.09484899 0.1230171  0.23745851], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6801, max_kl_dist_index: 2, max_train_grp_loss:  15.8691, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8765, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2375, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:43:23,695 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  108, train_loss:  13.4336, val_loss:  12.2603, grad_norm: 0.0029, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6508, 0.3470, 0.6801, param: [4.15009982 9.47288921 4.98565705 8.88750421], weights: [0.29137664 0.30984609 0.39877727], train_wt_loss:  40.3007, val_wt_loss: 36.7809, train_grp_loss: [11.76153144 15.86895747 11.16058459], val_grp_loss: [10.63893353 14.87634164 11.28129679], train_hist_grp_loss: [10.40664961 13.47959792 26.09596495], cur_train_grp_loss: [0.09485003 0.12301613 0.23745889], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6801, max_kl_dist_index: 2, max_train_grp_loss:  15.8690, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8763, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2375, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:43:24,743 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  109, train_loss:  13.4336, val_loss:  12.2603, grad_norm: 0.0029, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6508, 0.3470, 0.6801, param: [4.150041   9.47252488 4.98589642 8.88791272], weights: [0.2909944  0.30961397 0.39939164], train_wt_loss:  40.3007, val_wt_loss: 36.7809, train_grp_loss: [11.76165661 15.86883689 11.16060049], val_grp_loss: [10.6390009  14.87622065 11.28136133], train_hist_grp_loss: [10.50150067 13.6026131  26.3334242 ], cur_train_grp_loss: [0.09485106 0.12301517 0.23745925], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6801, max_kl_dist_index: 2, max_train_grp_loss:  15.8688, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8762, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2375, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:43:25,807 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  110, train_loss:  13.4336, val_loss:  12.2603, grad_norm: 0.0029, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6508, 0.3470, 0.6802, param: [4.14998121 9.47216262 4.98613502 8.88832351], weights: [0.29061219 0.30938151 0.4000063 ], train_wt_loss:  40.3007, val_wt_loss: 36.7809, train_grp_loss: [11.76177958 15.86871879 11.16061544], val_grp_loss: [10.63906635 14.87610339 11.28142512], train_hist_grp_loss: [10.59635273 13.72562734 26.57088379], cur_train_grp_loss: [0.09485207 0.12301424 0.23745958], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6802, max_kl_dist_index: 2, max_train_grp_loss:  15.8687, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8761, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2375, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:43:26,841 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  111, train_loss:  13.4336, val_loss:  12.2603, grad_norm: 0.0029, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6508, 0.3470, 0.6802, param: [4.14992044 9.4718024  4.98637285 8.88873658], weights: [0.29023001 0.30914872 0.40062127], train_wt_loss:  40.3008, val_wt_loss: 36.7809, train_grp_loss: [11.76190036 15.86860317 11.16062944], val_grp_loss: [10.63912987 14.87598984 11.28148819], train_hist_grp_loss: [10.6912058  13.84864066 26.80834369], cur_train_grp_loss: [0.09485306 0.12301332 0.2374599 ], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6802, max_kl_dist_index: 2, max_train_grp_loss:  15.8686, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8760, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2375, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:43:27,879 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  112, train_loss:  13.4336, val_loss:  12.2603, grad_norm: 0.0029, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6508, 0.3470, 0.6802, param: [4.14985871 9.47144424 4.98660991 8.88915194], weights: [0.28984788 0.3089156  0.40123653], train_wt_loss:  40.3008, val_wt_loss: 36.7810, train_grp_loss: [11.76201894 15.86849002 11.16064249], val_grp_loss: [10.63919145 14.87588002 11.28155051], train_hist_grp_loss: [10.78605983 13.97165309 27.04580389], cur_train_grp_loss: [0.09485404 0.12301243 0.2374602 ], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6802, max_kl_dist_index: 2, max_train_grp_loss:  15.8685, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8759, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2375, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:43:28,946 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  113, train_loss:  13.4336, val_loss:  12.2603, grad_norm: 0.0030, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6508, 0.3470, 0.6802, param: [4.149796   9.47108814 4.98684619 8.88956958], weights: [0.28946578 0.30868214 0.40185208], train_wt_loss:  40.3008, val_wt_loss: 36.7810, train_grp_loss: [11.76213532 15.86837935 11.1606546 ], val_grp_loss: [10.63925111 14.87577392 11.2816121 ], train_hist_grp_loss: [10.88091482 14.09466464 27.28326437], cur_train_grp_loss: [0.09485499 0.12301155 0.23746048], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6802, max_kl_dist_index: 2, max_train_grp_loss:  15.8684, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8758, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2375, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:43:29,947 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  114, train_loss:  13.4336, val_loss:  12.2603, grad_norm: 0.0030, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6508, 0.3470, 0.6802, param: [4.14973232 9.47073409 4.98708171 8.8899895 ], weights: [0.28908372 0.30844835 0.40246793], train_wt_loss:  40.3008, val_wt_loss: 36.7810, train_grp_loss: [11.7622495  15.86827116 11.16066576], val_grp_loss: [10.63930883 14.87567154 11.28167296], train_hist_grp_loss: [10.97577075 14.21767533 27.5207251 ], cur_train_grp_loss: [0.09485593 0.12301069 0.23746074], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6802, max_kl_dist_index: 2, max_train_grp_loss:  15.8683, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8757, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2375, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:43:30,945 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  115, train_loss:  13.4336, val_loss:  12.2603, grad_norm: 0.0030, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6509, 0.3470, 0.6802, param: [4.14966767 9.4703821  4.98731645 8.89041171], weights: [0.2887017  0.30821424 0.40308406], train_wt_loss:  40.3008, val_wt_loss: 36.7810, train_grp_loss: [11.76236147 15.86816545 11.16067596], val_grp_loss: [10.63936462 14.87557289 11.28173307], train_hist_grp_loss: [11.0706276  14.34068519 27.75818608], cur_train_grp_loss: [0.09485685 0.12300985 0.23746097], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6802, max_kl_dist_index: 2, max_train_grp_loss:  15.8682, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8756, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2375, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:43:32,002 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  116, train_loss:  13.4336, val_loss:  12.2603, grad_norm: 0.0030, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6509, 0.3470, 0.6802, param: [4.14960205 9.47003216 4.98755042 8.89083621], weights: [0.28831972 0.30797979 0.40370049], train_wt_loss:  40.3008, val_wt_loss: 36.7810, train_grp_loss: [11.76247125 15.86806222 11.16068522], val_grp_loss: [10.63941848 14.87547798 11.28179245], train_hist_grp_loss: [11.16548536 14.46369422 27.99564727], cur_train_grp_loss: [0.09485775 0.12300903 0.23746119], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6802, max_kl_dist_index: 2, max_train_grp_loss:  15.8681, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8755, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2375, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:43:33,041 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  117, train_loss:  13.4336, val_loss:  12.2603, grad_norm: 0.0031, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6509, 0.3470, 0.6802, param: [4.14953546 9.46968428 4.98778362 8.891263  ], weights: [0.28793778 0.30774502 0.4043172 ], train_wt_loss:  40.3008, val_wt_loss: 36.7810, train_grp_loss: [11.76257882 15.86796148 11.16069352], val_grp_loss: [10.6394704  14.87538679 11.2818511 ], train_hist_grp_loss: [11.260344   14.58670245 28.23310866], cur_train_grp_loss: [0.09485864 0.12300823 0.23746139], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6802, max_kl_dist_index: 2, max_train_grp_loss:  15.8680, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8754, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2375, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:43:34,095 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  118, train_loss:  13.4336, val_loss:  12.2604, grad_norm: 0.0031, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6509, 0.3470, 0.6802, param: [4.14946789 9.46933845 4.98801603 8.89169207], weights: [0.28755589 0.30750992 0.40493419], train_wt_loss:  40.3008, val_wt_loss: 36.7811, train_grp_loss: [11.76268419 15.86786321 11.16070088], val_grp_loss: [10.63952039 14.87529933 11.281909  ], train_hist_grp_loss: [11.3552035  14.70970991 28.47057022], cur_train_grp_loss: [0.09485951 0.12300745 0.23746156], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6802, max_kl_dist_index: 2, max_train_grp_loss:  15.8679, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8753, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2375, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:43:35,147 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  119, train_loss:  13.4336, val_loss:  12.2604, grad_norm: 0.0031, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6509, 0.3470, 0.6802, param: [4.14939935 9.46899468 4.98824767 8.89212343], weights: [0.28717403 0.3072745  0.40555147], train_wt_loss:  40.3008, val_wt_loss: 36.7811, train_grp_loss: [11.76278735 15.86776744 11.16070728], val_grp_loss: [10.63956844 14.87521561 11.28196616], train_hist_grp_loss: [11.45006386 14.8327166  28.70803194], cur_train_grp_loss: [0.09486036 0.12300669 0.23746172], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6802, max_kl_dist_index: 2, max_train_grp_loss:  15.8678, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8752, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2375, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:43:36,183 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  120, train_loss:  13.4336, val_loss:  12.2604, grad_norm: 0.0031, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6509, 0.3471, 0.6803, param: [4.14932984 9.46865296 4.98847854 8.89255709], weights: [0.28679223 0.30703875 0.40616902], train_wt_loss:  40.3008, val_wt_loss: 36.7811, train_grp_loss: [11.7628883  15.86767414 11.16071274], val_grp_loss: [10.63961456 14.87513562 11.28202259], train_hist_grp_loss: [11.54492505 14.95572255 28.9454938 ], cur_train_grp_loss: [0.09486119 0.12300595 0.23746186], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6803, max_kl_dist_index: 2, max_train_grp_loss:  15.8677, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8751, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2375, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:43:37,198 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  121, train_loss:  13.4336, val_loss:  12.2604, grad_norm: 0.0032, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6509, 0.3471, 0.6803, param: [4.14925936 9.4683133  4.98870862 8.89299303], weights: [0.28641047 0.30680268 0.40678686], train_wt_loss:  40.3008, val_wt_loss: 36.7811, train_grp_loss: [11.76298705 15.86758334 11.16071724], val_grp_loss: [10.63965874 14.87505936 11.28207828], train_hist_grp_loss: [11.63978705 15.07872777 29.18295577], cur_train_grp_loss: [0.094862   0.12300523 0.23746197], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6803, max_kl_dist_index: 2, max_train_grp_loss:  15.8676, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8751, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2375, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:43:38,257 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  122, train_loss:  13.4336, val_loss:  12.2604, grad_norm: 0.0032, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6509, 0.3471, 0.6803, param: [4.1491879  9.46797569 4.98893792 8.89343127], weights: [0.28602875 0.30656628 0.40740497], train_wt_loss:  40.3008, val_wt_loss: 36.7812, train_grp_loss: [11.76308359 15.86749502 11.16072078], val_grp_loss: [10.63970098 14.87498685 11.28213323], train_hist_grp_loss: [11.73464985 15.2017323  29.42041784], cur_train_grp_loss: [0.0948628  0.12300452 0.23746207], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6803, max_kl_dist_index: 2, max_train_grp_loss:  15.8675, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8750, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2375, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:43:39,349 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  123, train_loss:  13.4336, val_loss:  12.2604, grad_norm: 0.0032, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6510, 0.3471, 0.6803, param: [4.14911546 9.46764014 4.98916644 8.8938718 ], weights: [0.28564708 0.30632956 0.40802335], train_wt_loss:  40.3008, val_wt_loss: 36.7812, train_grp_loss: [11.76317792 15.86740918 11.16072338], val_grp_loss: [10.63974129 14.87491807 11.28218743], train_hist_grp_loss: [11.82951343 15.32473613 29.65787998], cur_train_grp_loss: [0.09486358 0.12300384 0.23746214], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6803, max_kl_dist_index: 2, max_train_grp_loss:  15.8674, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8749, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2375, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:43:40,398 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  124, train_loss:  13.4336, val_loss:  12.2604, grad_norm: 0.0032, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6510, 0.3471, 0.6803, param: [4.14904205 9.46730664 4.98939418 8.89431462], weights: [0.28526546 0.30609253 0.40864201], train_wt_loss:  40.3008, val_wt_loss: 36.7812, train_grp_loss: [11.76327004 15.86732584 11.16072502], val_grp_loss: [10.63977965 14.87485303 11.2822409 ], train_hist_grp_loss: [11.92437776 15.44773931 29.89534218], cur_train_grp_loss: [0.09486434 0.12300317 0.2374622 ], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6803, max_kl_dist_index: 2, max_train_grp_loss:  15.8673, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8749, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2375, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:43:41,434 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  125, train_loss:  13.4336, val_loss:  12.2604, grad_norm: 0.0032, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6510, 0.3471, 0.6803, param: [4.14896767 9.46697519 4.98962114 8.89475974], weights: [0.28488389 0.30585517 0.40926094], train_wt_loss:  40.3009, val_wt_loss: 36.7812, train_grp_loss: [11.76335995 15.86724498 11.16072571], val_grp_loss: [10.63981608 14.87479173 11.28229363], train_hist_grp_loss: [12.01924285 15.57074183 30.13280442], cur_train_grp_loss: [0.09486508 0.12300253 0.23746223], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6803, max_kl_dist_index: 2, max_train_grp_loss:  15.8672, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8748, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2375, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:43:42,471 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  126, train_loss:  13.4336, val_loss:  12.2604, grad_norm: 0.0033, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6510, 0.3471, 0.6803, param: [4.14889231 9.4666458  4.98984731 8.89520715], weights: [0.28450237 0.30561749 0.40988013], train_wt_loss:  40.3009, val_wt_loss: 36.7813, train_grp_loss: [11.76344764 15.86716662 11.16072545], val_grp_loss: [10.63985057 14.87473418 11.28234562], train_hist_grp_loss: [12.11410865 15.69374373 30.37026667], cur_train_grp_loss: [0.09486581 0.1230019  0.23746225], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6803, max_kl_dist_index: 2, max_train_grp_loss:  15.8672, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8747, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2375, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:43:43,504 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  127, train_loss:  13.4336, val_loss:  12.2604, grad_norm: 0.0033, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6510, 0.3471, 0.6803, param: [4.14881597 9.46631847 4.99007269 8.89565686], weights: [0.2841209 0.3053795 0.4104996], train_wt_loss:  40.3009, val_wt_loss: 36.7813, train_grp_loss: [11.76353313 15.86709074 11.16072423], val_grp_loss: [10.63988311 14.87468037 11.28239687], train_hist_grp_loss: [12.20897516 15.81674502 30.60772891], cur_train_grp_loss: [0.09486651 0.12300129 0.23746224], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6803, max_kl_dist_index: 2, max_train_grp_loss:  15.8671, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8747, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2375, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:43:44,543 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  128, train_loss:  13.4336, val_loss:  12.2604, grad_norm: 0.0033, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6510, 0.3471, 0.6804, param: [4.14873866 9.46599319 4.99029729 8.89610887], weights: [0.28373949 0.30514119 0.41111932], train_wt_loss:  40.3009, val_wt_loss: 36.7813, train_grp_loss: [11.7636164  15.86701736 11.16072206], val_grp_loss: [10.63991372 14.8746303  11.28244737], train_hist_grp_loss: [12.30384237 15.93974573 30.84519113], cur_train_grp_loss: [0.0948672  0.1230007  0.23746222], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6804, max_kl_dist_index: 2, max_train_grp_loss:  15.8670, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8746, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2375, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:43:45,558 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  129, train_loss:  13.4336, val_loss:  12.2605, grad_norm: 0.0033, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6511, 0.3471, 0.6804, param: [4.14866037 9.46566996 4.9905211  8.89656317], weights: [0.28335812 0.30490256 0.41173931], train_wt_loss:  40.3009, val_wt_loss: 36.7814, train_grp_loss: [11.76369745 15.86694646 11.16071893], val_grp_loss: [10.63994238 14.87458398 11.28249714], train_hist_grp_loss: [12.39871024 16.06274586 31.0826533 ], cur_train_grp_loss: [0.09486787 0.12300013 0.23746217], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6804, max_kl_dist_index: 2, max_train_grp_loss:  15.8669, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8746, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2375, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:43:46,608 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  130, train_loss:  13.4336, val_loss:  12.2605, grad_norm: 0.0034, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6511, 0.3471, 0.6804, param: [4.1485811  9.46534878 4.99074413 8.89701977], weights: [0.28297681 0.30466362 0.41235956], train_wt_loss:  40.3009, val_wt_loss: 36.7814, train_grp_loss: [11.76377629 15.86687807 11.16071485], val_grp_loss: [10.63996911 14.87454141 11.28254616], train_hist_grp_loss: [12.49357877 16.18574544 31.3201154 ], cur_train_grp_loss: [0.09486853 0.12299958 0.2374621 ], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6804, max_kl_dist_index: 2, max_train_grp_loss:  15.8669, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8745, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2375, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:43:47,654 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  131, train_loss:  13.4336, val_loss:  12.2605, grad_norm: 0.0034, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6511, 0.3471, 0.6804, param: [4.14850086 9.46502966 4.99096636 8.89747866], weights: [0.28259556 0.30442437 0.41298007], train_wt_loss:  40.3009, val_wt_loss: 36.7814, train_grp_loss: [11.76385291 15.86681216 11.16070981], val_grp_loss: [10.63999388 14.87450259 11.28259444], train_hist_grp_loss: [12.58844793 16.3087445  31.55757742], cur_train_grp_loss: [0.09486916 0.12299905 0.23746202], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6804, max_kl_dist_index: 2, max_train_grp_loss:  15.8668, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8745, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2375, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:43:48,691 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  132, train_loss:  13.4336, val_loss:  12.2605, grad_norm: 0.0034, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6511, 0.3471, 0.6804, param: [4.14841964 9.46471259 4.99118781 8.89793986], weights: [0.28221436 0.3041848  0.41360084], train_wt_loss:  40.3009, val_wt_loss: 36.7815, train_grp_loss: [11.76392732 15.86674875 11.16070382], val_grp_loss: [10.64001672 14.87446751 11.28264198], train_hist_grp_loss: [12.68331771 16.43174304 31.79503933], cur_train_grp_loss: [0.09486978 0.12299854 0.23746191], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6804, max_kl_dist_index: 2, max_train_grp_loss:  15.8667, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8745, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2375, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:43:49,750 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  133, train_loss:  13.4336, val_loss:  12.2605, grad_norm: 0.0034, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6511, 0.3471, 0.6804, param: [4.14833744 9.46439758 4.99140846 8.89840335], weights: [0.28183322 0.30394493 0.41422186], train_wt_loss:  40.3009, val_wt_loss: 36.7815, train_grp_loss: [11.76399951 15.86668784 11.16069687], val_grp_loss: [10.64003761 14.87443619 11.28268877], train_hist_grp_loss: [12.7781881  16.5547411  32.03250112], cur_train_grp_loss: [0.09487038 0.12299805 0.23746178], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6804, max_kl_dist_index: 2, max_train_grp_loss:  15.8667, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8744, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2375, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:43:50,800 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  134, train_loss:  13.4336, val_loss:  12.2605, grad_norm: 0.0034, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6511, 0.3471, 0.6804, param: [4.14825427 9.46408462 4.99162832 8.89886915], weights: [0.28145213 0.30370474 0.41484313], train_wt_loss:  40.3009, val_wt_loss: 36.7815, train_grp_loss: [11.76406948 15.86662942 11.16068897], val_grp_loss: [10.64005656 14.87440863 11.28273483], train_hist_grp_loss: [12.87305906 16.67773868 32.26996275], cur_train_grp_loss: [0.09487096 0.12299758 0.23746164], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6804, max_kl_dist_index: 2, max_train_grp_loss:  15.8666, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8744, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2375, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:43:51,862 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  135, train_loss:  13.4336, val_loss:  12.2605, grad_norm: 0.0035, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6511, 0.3471, 0.6805, param: [4.14817012 9.46377371 4.99184739 8.89933724], weights: [0.2810711  0.30346424 0.41546466], train_wt_loss:  40.3009, val_wt_loss: 36.7816, train_grp_loss: [11.76413723 15.8665735  11.16068011], val_grp_loss: [10.64007357 14.87438481 11.28278014], train_hist_grp_loss: [12.96793059 16.8007358  32.50742422], cur_train_grp_loss: [0.09487153 0.12299713 0.23746147], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6805, max_kl_dist_index: 2, max_train_grp_loss:  15.8666, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8744, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2375, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:43:52,900 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  136, train_loss:  13.4336, val_loss:  12.2605, grad_norm: 0.0035, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6512, 0.3471, 0.6805, param: [4.14808498 9.46346485 4.99206566 8.89980764], weights: [0.28069014 0.30322343 0.41608643], train_wt_loss:  40.3009, val_wt_loss: 36.7816, train_grp_loss: [11.76420276 15.86652008 11.16067029], val_grp_loss: [10.64008862 14.87436475 11.28282471], train_hist_grp_loss: [13.06280266 16.9237325  32.7448855 ], cur_train_grp_loss: [0.09487207 0.12299669 0.23746128], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6805, max_kl_dist_index: 2, max_train_grp_loss:  15.8665, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8744, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2375, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:43:53,931 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  137, train_loss:  13.4336, val_loss:  12.2606, grad_norm: 0.0035, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6512, 0.3471, 0.6805, param: [4.14799887 9.46315804 4.99228313 8.90028034], weights: [0.28030923 0.30298232 0.41670845], train_wt_loss:  40.3009, val_wt_loss: 36.7817, train_grp_loss: [11.76426606 15.86646915 11.16065952], val_grp_loss: [10.64010174 14.87434845 11.28286853], train_hist_grp_loss: [13.15767526 17.04672878 32.98234657], cur_train_grp_loss: [0.0948726  0.12299628 0.23746107], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6805, max_kl_dist_index: 2, max_train_grp_loss:  15.8665, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8743, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2375, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:43:54,995 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  138, train_loss:  13.4337, val_loss:  12.2606, grad_norm: 0.0035, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6512, 0.3471, 0.6805, param: [4.14791178 9.46285329 4.99249982 8.90075534], weights: [0.27992839 0.3027409  0.41733071], train_wt_loss:  40.3010, val_wt_loss: 36.7817, train_grp_loss: [11.76432715 15.86642073 11.16064779], val_grp_loss: [10.6401129  14.87433591 11.28291161], train_hist_grp_loss: [13.25254838 17.16972466 33.21980741], cur_train_grp_loss: [0.09487311 0.12299588 0.23746084], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6805, max_kl_dist_index: 2, max_train_grp_loss:  15.8664, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8743, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2375, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:43:56,070 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  139, train_loss:  13.4337, val_loss:  12.2606, grad_norm: 0.0036, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6512, 0.3471, 0.6805, param: [4.14782371 9.46255059 4.9927157  8.90123264], weights: [0.2795476  0.30249918 0.41795322], train_wt_loss:  40.3010, val_wt_loss: 36.7818, train_grp_loss: [11.76438602 15.8663748  11.1606351 ], val_grp_loss: [10.64012213 14.87432712 11.28295395], train_hist_grp_loss: [13.34742198 17.29272017 33.457268  ], cur_train_grp_loss: [0.09487361 0.12299551 0.23746059], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6805, max_kl_dist_index: 2, max_train_grp_loss:  15.8664, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8743, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2375, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:43:57,127 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  140, train_loss:  13.4337, val_loss:  12.2606, grad_norm: 0.0036, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6512, 0.3471, 0.6805, param: [4.14773466 9.46224994 4.99293078 8.90171225], weights: [0.27916688 0.30225715 0.41857597], train_wt_loss:  40.3010, val_wt_loss: 36.7818, train_grp_loss: [11.76444266 15.86633138 11.16062146], val_grp_loss: [10.6401294  14.8743221  11.28299554], train_hist_grp_loss: [13.44229607 17.41571532 33.69472832], cur_train_grp_loss: [0.09487408 0.12299515 0.23746032], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6805, max_kl_dist_index: 2, max_train_grp_loss:  15.8663, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8743, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2375, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:43:58,182 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  141, train_loss:  13.4337, val_loss:  12.2606, grad_norm: 0.0036, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6513, 0.3472, 0.6806, param: [4.14764463 9.46195134 4.99314507 8.90219416], weights: [0.27878623 0.30201482 0.41919895], train_wt_loss:  40.3010, val_wt_loss: 36.7818, train_grp_loss: [11.76449707 15.86629045 11.16060686], val_grp_loss: [10.64013473 14.87432083 11.28303639], train_hist_grp_loss: [13.5371706  17.53871014 33.93218835], cur_train_grp_loss: [0.09487454 0.12299482 0.23746003], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6806, max_kl_dist_index: 2, max_train_grp_loss:  15.8663, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8743, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2375, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:43:59,279 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  142, train_loss:  13.4337, val_loss:  12.2606, grad_norm: 0.0036, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6513, 0.3472, 0.6806, param: [4.14755362 9.46165479 4.99335855 8.90267837], weights: [0.27840564 0.30177218 0.41982218], train_wt_loss:  40.3010, val_wt_loss: 36.7819, train_grp_loss: [11.76454927 15.86625203 11.1605913 ], val_grp_loss: [10.64013811 14.87432333 11.2830765 ], train_hist_grp_loss: [13.63204558 17.66170464 34.16964807], cur_train_grp_loss: [0.09487498 0.1229945  0.23745972], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6806, max_kl_dist_index: 2, max_train_grp_loss:  15.8663, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8743, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2375, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:44:00,300 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  143, train_loss:  13.4337, val_loss:  12.2606, grad_norm: 0.0036, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6513, 0.3472, 0.6806, param: [4.14746163 9.46136029 4.99357123 8.90316489], weights: [0.27802512 0.30152925 0.42044564], train_wt_loss:  40.3010, val_wt_loss: 36.7819, train_grp_loss: [11.76459923 15.86621611 11.16057478], val_grp_loss: [10.64013954 14.8743296  11.28311586], train_hist_grp_loss: [13.72692098 17.78469884 34.40710746], cur_train_grp_loss: [0.0948754  0.1229942  0.23745939], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6806, max_kl_dist_index: 2, max_train_grp_loss:  15.8662, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8743, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2375, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:44:01,344 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  144, train_loss:  13.4337, val_loss:  12.2607, grad_norm: 0.0037, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6513, 0.3472, 0.6806, param: [4.14736866 9.46106784 4.99378311 8.90365371], weights: [0.27764466 0.30128601 0.42106933], train_wt_loss:  40.3010, val_wt_loss: 36.7820, train_grp_loss: [11.76464698 15.8661827  11.16055731], val_grp_loss: [10.64013902 14.87433962 11.28315448], train_hist_grp_loss: [13.82179678 17.90769277 34.6445665 ], cur_train_grp_loss: [0.0948758  0.12299392 0.23745904], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6806, max_kl_dist_index: 2, max_train_grp_loss:  15.8662, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8743, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2375, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:44:02,404 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  145, train_loss:  13.4337, val_loss:  12.2607, grad_norm: 0.0037, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6513, 0.3472, 0.6806, param: [4.14727471 9.46077744 4.99399419 8.90414484], weights: [0.27726427 0.30104248 0.42169325], train_wt_loss:  40.3010, val_wt_loss: 36.7820, train_grp_loss: [11.76469249 15.86615179 11.16053887], val_grp_loss: [10.64013655 14.87435342 11.28319235], train_hist_grp_loss: [13.91667296 18.03068643 34.88202517], cur_train_grp_loss: [0.09487619 0.12299366 0.23745867], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6806, max_kl_dist_index: 2, max_train_grp_loss:  15.8662, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8744, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2375, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:44:03,452 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  146, train_loss:  13.4337, val_loss:  12.2607, grad_norm: 0.0037, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6513, 0.3472, 0.6807, param: [4.14717977 9.46048909 4.99420446 8.90463828], weights: [0.27688396 0.30079865 0.4223174 ], train_wt_loss:  40.3010, val_wt_loss: 36.7821, train_grp_loss: [11.76473578 15.86612338 11.16051948], val_grp_loss: [10.64013214 14.87437098 11.28322948], train_hist_grp_loss: [14.01154951 18.15367986 35.11948344], cur_train_grp_loss: [0.09487655 0.12299342 0.23745827], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6807, max_kl_dist_index: 2, max_train_grp_loss:  15.8661, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8744, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2375, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:44:04,511 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  147, train_loss:  13.4337, val_loss:  12.2607, grad_norm: 0.0037, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6514, 0.3472, 0.6807, param: [4.14708386 9.46020279 4.99441392 8.90513402], weights: [0.27650371 0.30055452 0.42294178], train_wt_loss:  40.3010, val_wt_loss: 36.7821, train_grp_loss: [11.76477684 15.86609748 11.16049914], val_grp_loss: [10.64012578 14.8743923  11.28326586], train_hist_grp_loss: [14.10642642 18.27667306 35.3569413 ], cur_train_grp_loss: [0.0948769  0.1229932  0.23745786], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6807, max_kl_dist_index: 2, max_train_grp_loss:  15.8661, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8744, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2375, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:44:05,541 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  148, train_loss:  13.4337, val_loss:  12.2607, grad_norm: 0.0037, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6514, 0.3472, 0.6807, param: [4.14698696 9.45991854 4.99462258 8.90563207], weights: [0.27612353 0.30031009 0.42356638], train_wt_loss:  40.3010, val_wt_loss: 36.7822, train_grp_loss: [11.76481567 15.86607409 11.16047783], val_grp_loss: [10.64011746 14.8744174  11.2833015 ], train_hist_grp_loss: [14.20130365 18.39966606 35.59439873], cur_train_grp_loss: [0.09487723 0.122993   0.23745743], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6807, max_kl_dist_index: 2, max_train_grp_loss:  15.8661, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8744, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2375, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:44:06,594 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  149, train_loss:  13.4337, val_loss:  12.2607, grad_norm: 0.0038, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6514, 0.3472, 0.6807, param: [4.14688907 9.45963634 4.99483043 8.90613242], weights: [0.27574342 0.30006537 0.4241912 ], train_wt_loss:  40.3010, val_wt_loss: 36.7822, train_grp_loss: [11.76485228 15.8660532  11.16045556], val_grp_loss: [10.6401072  14.87444627 11.28333639], train_hist_grp_loss: [14.29618119 18.52265889 35.83185571], cur_train_grp_loss: [0.09487755 0.12299282 0.23745698], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6807, max_kl_dist_index: 2, max_train_grp_loss:  15.8661, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8744, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2375, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:44:07,620 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  150, train_loss:  13.4337, val_loss:  12.2608, grad_norm: 0.0038, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6514, 0.3472, 0.6807, param: [4.14679021 9.45935618 4.99503747 8.90663508], weights: [0.27536339 0.29982036 0.42481625], train_wt_loss:  40.3010, val_wt_loss: 36.7823, train_grp_loss: [11.76488665 15.86603483 11.16043234], val_grp_loss: [10.64009498 14.87447891 11.28337054], train_hist_grp_loss: [14.39105903 18.64565155 36.06931221], cur_train_grp_loss: [0.09487784 0.12299266 0.2374565 ], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6807, max_kl_dist_index: 2, max_train_grp_loss:  15.8660, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8745, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2375, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:44:08,706 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  151, train_loss:  13.4337, val_loss:  12.2608, grad_norm: 0.0038, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6514, 0.3472, 0.6807, param: [4.14669036 9.45907807 4.9952437  8.90714005], weights: [0.27498343 0.29957506 0.42544151], train_wt_loss:  40.3011, val_wt_loss: 36.7823, train_grp_loss: [11.76491879 15.86601896 11.16040815], val_grp_loss: [10.64008082 14.87451532 11.28340394], train_hist_grp_loss: [14.48593715 18.76864406 36.30676821], cur_train_grp_loss: [0.09487812 0.12299252 0.23745601], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6807, max_kl_dist_index: 2, max_train_grp_loss:  15.8660, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8745, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2375, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:44:09,742 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  152, train_loss:  13.4337, val_loss:  12.2608, grad_norm: 0.0038, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6515, 0.3472, 0.6808, param: [4.14658953 9.45880201 4.99544913 8.90764733], weights: [0.27460355 0.29932946 0.42606699], train_wt_loss:  40.3011, val_wt_loss: 36.7824, train_grp_loss: [11.7649487  15.86600559 11.16038301], val_grp_loss: [10.6400647  14.8745555  11.28343659], train_hist_grp_loss: [14.58081553 18.89163646 36.54422371], cur_train_grp_loss: [0.09487838 0.1229924  0.23745549], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6808, max_kl_dist_index: 2, max_train_grp_loss:  15.8660, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8746, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2375, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:44:10,769 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  153, train_loss:  13.4337, val_loss:  12.2608, grad_norm: 0.0038, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6515, 0.3472, 0.6808, param: [4.14648772 9.45852799 4.99565373 8.90815692], weights: [0.27422374 0.29908357 0.42669268], train_wt_loss:  40.3011, val_wt_loss: 36.7825, train_grp_loss: [11.76497639 15.86599474 11.16035691], val_grp_loss: [10.64004664 14.87459946 11.2834685 ], train_hist_grp_loss: [14.67569415 19.01462875 36.78167866], cur_train_grp_loss: [0.09487862 0.12299229 0.23745496], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6808, max_kl_dist_index: 2, max_train_grp_loss:  15.8660, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8746, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2375, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:44:11,823 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  154, train_loss:  13.4337, val_loss:  12.2608, grad_norm: 0.0039, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6515, 0.3473, 0.6808, param: [4.14638492 9.45825602 4.99585753 8.90866881], weights: [0.27384401 0.2988374  0.42731859], train_wt_loss:  40.3011, val_wt_loss: 36.7825, train_grp_loss: [11.76500184 15.8659864  11.16032985], val_grp_loss: [10.64002662 14.87464719 11.28349967], train_hist_grp_loss: [14.77057299 19.13762096 37.01913307], cur_train_grp_loss: [0.09487884 0.12299221 0.2374544 ], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6808, max_kl_dist_index: 2, max_train_grp_loss:  15.8660, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8746, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2375, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:44:12,860 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  155, train_loss:  13.4337, val_loss:  12.2609, grad_norm: 0.0039, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6515, 0.3473, 0.6808, param: [4.14628114 9.4579861  4.99606051 8.90918302], weights: [0.27346436 0.29859093 0.42794471], train_wt_loss:  40.3011, val_wt_loss: 36.7826, train_grp_loss: [11.76502505 15.86598057 11.16030183], val_grp_loss: [10.64000465 14.8746987  11.28353009], train_hist_grp_loss: [14.86545204 19.2606131  37.25658689], cur_train_grp_loss: [0.09487905 0.12299214 0.23745383], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6808, max_kl_dist_index: 2, max_train_grp_loss:  15.8660, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8747, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2375, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:44:13,904 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  156, train_loss:  13.4337, val_loss:  12.2609, grad_norm: 0.0039, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6515, 0.3473, 0.6809, param: [4.14617637 9.45771822 4.99626268 8.90969953], weights: [0.27308479 0.29834418 0.42857103], train_wt_loss:  40.3011, val_wt_loss: 36.7826, train_grp_loss: [11.76504604 15.86597725 11.16027285], val_grp_loss: [10.63998073 14.87475399 11.28355976], train_hist_grp_loss: [14.96033127 19.3836052  37.49404012], cur_train_grp_loss: [0.09487923 0.1229921  0.23745323], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6809, max_kl_dist_index: 2, max_train_grp_loss:  15.8660, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8748, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2375, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:44:14,961 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  157, train_loss:  13.4337, val_loss:  12.2609, grad_norm: 0.0039, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6516, 0.3473, 0.6809, param: [4.14607062 9.45745238 4.99646403 8.91021835], weights: [0.27270529 0.29809715 0.42919756], train_wt_loss:  40.3011, val_wt_loss: 36.7827, train_grp_loss: [11.76506479 15.86597644 11.16024291], val_grp_loss: [10.63995485 14.87481306 11.28358869], train_hist_grp_loss: [15.05521068 19.50659727 37.73149274], cur_train_grp_loss: [0.0948794  0.12299207 0.23745261], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6809, max_kl_dist_index: 2, max_train_grp_loss:  15.8660, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8748, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2375, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:44:16,006 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  158, train_loss:  13.4337, val_loss:  12.2609, grad_norm: 0.0039, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6516, 0.3473, 0.6809, param: [4.14596388 9.45718859 4.99666456 8.91073948], weights: [0.27232588 0.29784982 0.4298243 ], train_wt_loss:  40.3011, val_wt_loss: 36.7828, train_grp_loss: [11.76508131 15.86597815 11.16021201], val_grp_loss: [10.63992703 14.8748759  11.28361687], train_hist_grp_loss: [15.15009023 19.62958934 37.96894471], cur_train_grp_loss: [0.09487955 0.12299207 0.23745198], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6809, max_kl_dist_index: 2, max_train_grp_loss:  15.8660, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8749, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2375, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:44:17,063 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  159, train_loss:  13.4337, val_loss:  12.2609, grad_norm: 0.0040, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6516, 0.3473, 0.6809, param: [4.14585616 9.45692684 4.99686427 8.91126292], weights: [0.27194655 0.29760222 0.43045124], train_wt_loss:  40.3011, val_wt_loss: 36.7828, train_grp_loss: [11.76509559 15.86598237 11.16018015], val_grp_loss: [10.63989725 14.87494253 11.2836443 ], train_hist_grp_loss: [15.24496992 19.75258141 38.20639603], cur_train_grp_loss: [0.09487969 0.12299208 0.23745132], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6809, max_kl_dist_index: 2, max_train_grp_loss:  15.8660, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8749, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2375, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:44:18,099 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  160, train_loss:  13.4337, val_loss:  12.2610, grad_norm: 0.0040, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6516, 0.3473, 0.6809, param: [4.14574745 9.45666714 4.99706317 8.91178867], weights: [0.2715673  0.29735433 0.43107837], train_wt_loss:  40.3011, val_wt_loss: 36.7829, train_grp_loss: [11.76510764 15.8659891  11.16014733], val_grp_loss: [10.63986552 14.87501293 11.28367099], train_hist_grp_loss: [15.33984972 19.87557353 38.44384667], cur_train_grp_loss: [0.0948798  0.12299211 0.23745064], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6809, max_kl_dist_index: 2, max_train_grp_loss:  15.8660, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8750, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2375, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:44:19,148 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  161, train_loss:  13.4337, val_loss:  12.2610, grad_norm: 0.0040, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6516, 0.3473, 0.6810, param: [4.14563776 9.45640947 4.99726124 8.91231673], weights: [0.27118813 0.29710616 0.43170571], train_wt_loss:  40.3011, val_wt_loss: 36.7830, train_grp_loss: [11.76511746 15.86599835 11.16011356], val_grp_loss: [10.63983184 14.87508712 11.28369694], train_hist_grp_loss: [15.43472962 19.99856569 38.68129662], cur_train_grp_loss: [0.0948799  0.12299216 0.23744994], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6810, max_kl_dist_index: 2, max_train_grp_loss:  15.8660, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8751, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:44:20,200 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  162, train_loss:  13.4337, val_loss:  12.2610, grad_norm: 0.0040, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6517, 0.3473, 0.6810, param: [4.14552708 9.45615385 4.9974585  8.9128471 ], weights: [0.27080905 0.29685771 0.43233324], train_wt_loss:  40.3011, val_wt_loss: 36.7830, train_grp_loss: [11.76512503 15.86601011 11.16007882], val_grp_loss: [10.6397962  14.87516509 11.28372213], train_hist_grp_loss: [15.5296096  20.12155792 38.91874584], cur_train_grp_loss: [0.09487998 0.12299224 0.23744922], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6810, max_kl_dist_index: 2, max_train_grp_loss:  15.8660, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8752, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:44:21,229 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  163, train_loss:  13.4337, val_loss:  12.2610, grad_norm: 0.0040, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6517, 0.3473, 0.6810, param: [4.14541541 9.45590027 4.99765493 8.91337978], weights: [0.27043005 0.29660898 0.43296097], train_wt_loss:  40.3012, val_wt_loss: 36.7831, train_grp_loss: [11.76513038 15.86602439 11.16004312], val_grp_loss: [10.63975861 14.87524685 11.28374659], train_hist_grp_loss: [15.62448964 20.24455025 39.15619433], cur_train_grp_loss: [0.09488004 0.12299233 0.23744849], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6810, max_kl_dist_index: 2, max_train_grp_loss:  15.8660, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8752, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:44:22,281 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  164, train_loss:  13.4337, val_loss:  12.2611, grad_norm: 0.0041, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6517, 0.3473, 0.6810, param: [4.14530276 9.45564874 4.99785054 8.91391477], weights: [0.27005115 0.29635997 0.43358889], train_wt_loss:  40.3012, val_wt_loss: 36.7832, train_grp_loss: [11.76513348 15.86604119 11.16000647], val_grp_loss: [10.63971907 14.87533239 11.28377029], train_hist_grp_loss: [15.71936973 20.36754269 39.39364205], cur_train_grp_loss: [0.09488008 0.12299244 0.23744773], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6810, max_kl_dist_index: 2, max_train_grp_loss:  15.8660, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8753, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:44:23,310 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  165, train_loss:  13.4337, val_loss:  12.2611, grad_norm: 0.0041, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6517, 0.3474, 0.6811, param: [4.14518912 9.45539924 4.99804532 8.91445207], weights: [0.26967232 0.29611068 0.43421699], train_wt_loss:  40.3012, val_wt_loss: 36.7832, train_grp_loss: [11.76513436 15.8660605  11.15996885], val_grp_loss: [10.63967758 14.87542172 11.28379325], train_hist_grp_loss: [15.81424983 20.49053526 39.631089  ], cur_train_grp_loss: [0.09488011 0.12299257 0.23744695], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6811, max_kl_dist_index: 2, max_train_grp_loss:  15.8661, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8754, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:44:24,370 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  166, train_loss:  13.4337, val_loss:  12.2611, grad_norm: 0.0041, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6517, 0.3474, 0.6811, param: [4.1450745  9.45515178 4.99823928 8.91499168], weights: [0.26929359 0.29586112 0.43484529], train_wt_loss:  40.3012, val_wt_loss: 36.7833, train_grp_loss: [11.76513299 15.86608233 11.15993028], val_grp_loss: [10.63963413 14.87551483 11.28381546], train_hist_grp_loss: [15.90912995 20.61352797 39.86853515], cur_train_grp_loss: [0.09488012 0.12299272 0.23744615], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6811, max_kl_dist_index: 2, max_train_grp_loss:  15.8661, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8755, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:44:25,410 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  167, train_loss:  13.4337, val_loss:  12.2611, grad_norm: 0.0041, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6518, 0.3474, 0.6811, param: [4.14495888 9.45490636 4.99843241 8.91553361], weights: [0.26891495 0.29561129 0.43547377], train_wt_loss:  40.3012, val_wt_loss: 36.7834, train_grp_loss: [11.76512938 15.86610667 11.15989074], val_grp_loss: [10.63958873 14.87561173 11.28383693], train_hist_grp_loss: [16.00401006 20.73652086 40.10598047], cur_train_grp_loss: [0.0948801  0.12299289 0.23744533], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6811, max_kl_dist_index: 2, max_train_grp_loss:  15.8661, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8756, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:44:26,440 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  168, train_loss:  13.4337, val_loss:  12.2612, grad_norm: 0.0041, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6518, 0.3474, 0.6811, param: [4.14484228 9.45466298 4.99862471 8.91607784], weights: [0.26853639 0.29536117 0.43610243], train_wt_loss:  40.3012, val_wt_loss: 36.7835, train_grp_loss: [11.76512354 15.86613354 11.15985025], val_grp_loss: [10.63954137 14.87571242 11.28385765], train_hist_grp_loss: [16.09889013 20.85951393 40.34342496], cur_train_grp_loss: [0.09488008 0.12299307 0.23744448], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6811, max_kl_dist_index: 2, max_train_grp_loss:  15.8661, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8757, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:44:27,483 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  169, train_loss:  13.4337, val_loss:  12.2612, grad_norm: 0.0042, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6518, 0.3474, 0.6812, param: [4.14472469 9.45442163 4.99881618 8.91662438], weights: [0.26815793 0.29511079 0.43673128], train_wt_loss:  40.3012, val_wt_loss: 36.7835, train_grp_loss: [11.76511546 15.86616292 11.1598088 ], val_grp_loss: [10.63949206 14.8758169  11.28387763], train_hist_grp_loss: [16.19377016 20.98250722 40.58086858], cur_train_grp_loss: [0.09488003 0.12299328 0.23744362], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6812, max_kl_dist_index: 2, max_train_grp_loss:  15.8662, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8758, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:44:28,522 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  170, train_loss:  13.4337, val_loss:  12.2612, grad_norm: 0.0042, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6518, 0.3474, 0.6812, param: [4.14460611 9.45418233 4.99900683 8.91717324], weights: [0.26777956 0.29486014 0.4373603 ], train_wt_loss:  40.3012, val_wt_loss: 36.7836, train_grp_loss: [11.76510515 15.86619483 11.15976638], val_grp_loss: [10.6394408  14.87592517 11.28389685], train_hist_grp_loss: [16.28865012 21.10550073 40.81831132], cur_train_grp_loss: [0.09487996 0.12299351 0.23744274], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6812, max_kl_dist_index: 2, max_train_grp_loss:  15.8662, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8759, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:44:29,607 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  171, train_loss:  13.4337, val_loss:  12.2612, grad_norm: 0.0042, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6519, 0.3474, 0.6812, param: [4.14448655 9.45394506 4.99919664 8.9177244 ], weights: [0.26740129 0.29460921 0.4379895 ], train_wt_loss:  40.3012, val_wt_loss: 36.7837, train_grp_loss: [11.76509259 15.86622925 11.15972301], val_grp_loss: [10.63938759 14.87603722 11.28391534], train_hist_grp_loss: [16.38353    21.22849449 41.05575316], cur_train_grp_loss: [0.09487988 0.12299376 0.23744184], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6812, max_kl_dist_index: 2, max_train_grp_loss:  15.8662, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8760, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:44:30,643 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  172, train_loss:  13.4337, val_loss:  12.2613, grad_norm: 0.0042, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6519, 0.3474, 0.6812, param: [4.14436599 9.45370982 4.99938562 8.91827788], weights: [0.26702311 0.29435802 0.43861888], train_wt_loss:  40.3012, val_wt_loss: 36.7838, train_grp_loss: [11.7650778  15.8662662  11.15967868], val_grp_loss: [10.63933242 14.87615307 11.28393307], train_hist_grp_loss: [16.47840978 21.35148851 41.29319407], cur_train_grp_loss: [0.09487978 0.12299403 0.23744092], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6812, max_kl_dist_index: 2, max_train_grp_loss:  15.8663, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8762, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:44:31,672 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  173, train_loss:  13.4337, val_loss:  12.2613, grad_norm: 0.0042, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6519, 0.3474, 0.6813, param: [4.14424445 9.45347662 4.99957377 8.91883366], weights: [0.26664502 0.29410655 0.43924843], train_wt_loss:  40.3012, val_wt_loss: 36.7838, train_grp_loss: [11.76506076 15.86630566 11.15963339], val_grp_loss: [10.6392753  14.87627271 11.28395006], train_hist_grp_loss: [16.57328944 21.47448282 41.53063404], cur_train_grp_loss: [0.09487966 0.12299431 0.23743997], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6813, max_kl_dist_index: 2, max_train_grp_loss:  15.8663, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8763, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:44:32,699 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  174, train_loss:  13.4337, val_loss:  12.2613, grad_norm: 0.0043, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6519, 0.3475, 0.6813, param: [4.14412192 9.45324546 4.99976109 8.91939176], weights: [0.26626703 0.29385482 0.43987815], train_wt_loss:  40.3012, val_wt_loss: 36.7839, train_grp_loss: [11.76504149 15.86634765 11.15958714], val_grp_loss: [10.63921622 14.87639615 11.28396631], train_hist_grp_loss: [16.66816896 21.59747744 41.76807305], cur_train_grp_loss: [0.09487952 0.12299462 0.23743901], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6813, max_kl_dist_index: 2, max_train_grp_loss:  15.8663, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8764, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:44:33,760 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  175, train_loss:  13.4338, val_loss:  12.2613, grad_norm: 0.0043, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6519, 0.3475, 0.6813, param: [4.1439984  9.45301633 4.99994757 8.91995216], weights: [0.26588914 0.29360283 0.44050804], train_wt_loss:  40.3013, val_wt_loss: 36.7840, train_grp_loss: [11.76501998 15.86639216 11.15953993], val_grp_loss: [10.63915519 14.87652338 11.28398181], train_hist_grp_loss: [16.76304833 21.72047238 42.00551108], cur_train_grp_loss: [0.09487937 0.12299494 0.23743802], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6813, max_kl_dist_index: 2, max_train_grp_loss:  15.8664, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8765, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:44:34,802 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  176, train_loss:  13.4338, val_loss:  12.2614, grad_norm: 0.0043, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6520, 0.3475, 0.6813, param: [4.14387388 9.45278923 5.00013321 8.92051488], weights: [0.26551134 0.29335056 0.44113809], train_wt_loss:  40.3013, val_wt_loss: 36.7841, train_grp_loss: [11.76499622 15.86643919 11.15949176], val_grp_loss: [10.63909221 14.8766544  11.28399656], train_hist_grp_loss: [16.85792752 21.84346767 42.2429481 ], cur_train_grp_loss: [0.09487919 0.12299529 0.23743702], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6813, max_kl_dist_index: 2, max_train_grp_loss:  15.8664, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8767, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:44:35,829 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  177, train_loss:  13.4338, val_loss:  12.2614, grad_norm: 0.0043, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6520, 0.3475, 0.6814, param: [4.14374838 9.45256416 5.00031802 8.92107991], weights: [0.26513365 0.29309804 0.44176832], train_wt_loss:  40.3013, val_wt_loss: 36.7842, train_grp_loss: [11.76497023 15.86648874 11.15944264], val_grp_loss: [10.63902727 14.87678922 11.28401057], train_hist_grp_loss: [16.95280653 21.96646332 42.48038409], cur_train_grp_loss: [0.094879   0.12299565 0.23743599], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6814, max_kl_dist_index: 2, max_train_grp_loss:  15.8665, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8768, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:44:36,861 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  178, train_loss:  13.4338, val_loss:  12.2614, grad_norm: 0.0043, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6520, 0.3475, 0.6814, param: [4.14362189 9.45234113 5.00050198 8.92164724], weights: [0.26475605 0.29284525 0.4423987 ], train_wt_loss:  40.3013, val_wt_loss: 36.7843, train_grp_loss: [11.764942   15.86654082 11.15939255], val_grp_loss: [10.63896039 14.87692783 11.28402383], train_hist_grp_loss: [17.04768532 22.08945936 42.71781904], cur_train_grp_loss: [0.09487879 0.12299604 0.23743495], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6814, max_kl_dist_index: 2, max_train_grp_loss:  15.8665, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8769, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:44:37,909 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  179, train_loss:  13.4338, val_loss:  12.2614, grad_norm: 0.0043, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6520, 0.3475, 0.6814, param: [4.14349441 9.45212012 5.00068511 8.92221689], weights: [0.26437856 0.2925922  0.44302924], train_wt_loss:  40.3013, val_wt_loss: 36.7843, train_grp_loss: [11.76491152 15.86659542 11.15934151], val_grp_loss: [10.63889154 14.87707025 11.28403635], train_hist_grp_loss: [17.14256388 22.2124558  42.95525292], cur_train_grp_loss: [0.09487856 0.12299644 0.23743388], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6814, max_kl_dist_index: 2, max_train_grp_loss:  15.8666, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8771, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:44:38,992 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  180, train_loss:  13.4338, val_loss:  12.2615, grad_norm: 0.0044, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6521, 0.3475, 0.6814, param: [4.14336594 9.45190115 5.0008674  8.92278885], weights: [0.26400116 0.29233889 0.44365994], train_wt_loss:  40.3013, val_wt_loss: 36.7844, train_grp_loss: [11.76487881 15.86665255 11.15928951], val_grp_loss: [10.63882075 14.87721645 11.28404812], train_hist_grp_loss: [17.2374422  22.33545267 43.19268572], cur_train_grp_loss: [0.09487832 0.12299686 0.2374328 ], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6814, max_kl_dist_index: 2, max_train_grp_loss:  15.8667, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8772, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:44:40,023 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  181, train_loss:  13.4338, val_loss:  12.2615, grad_norm: 0.0044, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6521, 0.3475, 0.6815, param: [4.14323647 9.4516842  5.00104885 8.92336311], weights: [0.26362387 0.29208532 0.4442908 ], train_wt_loss:  40.3013, val_wt_loss: 36.7845, train_grp_loss: [11.76484386 15.8667122  11.15923655], val_grp_loss: [10.638748   14.87736646 11.28405915], train_hist_grp_loss: [17.33232026 22.45844997 43.43011741], cur_train_grp_loss: [0.09487805 0.12299731 0.23743169], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6815, max_kl_dist_index: 2, max_train_grp_loss:  15.8667, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8774, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:44:41,094 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  182, train_loss:  13.4338, val_loss:  12.2615, grad_norm: 0.0044, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6521, 0.3476, 0.6815, param: [4.14310602 9.45146929 5.00122945 8.92393969], weights: [0.26324669 0.2918315  0.44492182], train_wt_loss:  40.3013, val_wt_loss: 36.7846, train_grp_loss: [11.76480666 15.86677438 11.15918263], val_grp_loss: [10.6386733  14.87752026 11.28406943], train_hist_grp_loss: [17.42719803 22.58144774 43.66754798], cur_train_grp_loss: [0.09487777 0.12299777 0.23743056], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6815, max_kl_dist_index: 2, max_train_grp_loss:  15.8668, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8775, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:44:42,123 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  183, train_loss:  13.4338, val_loss:  12.2616, grad_norm: 0.0044, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6521, 0.3476, 0.6815, param: [4.14297457 9.4512564  5.00140922 8.92451858], weights: [0.26286961 0.29157741 0.44555298], train_wt_loss:  40.3013, val_wt_loss: 36.7847, train_grp_loss: [11.76476723 15.86683908 11.15912775], val_grp_loss: [10.63859665 14.87767787 11.28407897], train_hist_grp_loss: [17.5220755  22.70444599 43.9049774 ], cur_train_grp_loss: [0.09487747 0.12299825 0.23742942], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6815, max_kl_dist_index: 2, max_train_grp_loss:  15.8668, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8777, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:44:43,148 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  184, train_loss:  13.4338, val_loss:  12.2616, grad_norm: 0.0044, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6522, 0.3476, 0.6816, param: [4.14284213 9.45104554 5.00158813 8.92509977], weights: [0.26249263 0.29132307 0.44618429], train_wt_loss:  40.3013, val_wt_loss: 36.7848, train_grp_loss: [11.76472555 15.86690631 11.15907192], val_grp_loss: [10.63851804 14.87783927 11.28408776], train_hist_grp_loss: [17.61695266 22.82744474 44.14240565], cur_train_grp_loss: [0.09487716 0.12299875 0.23742825], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6816, max_kl_dist_index: 2, max_train_grp_loss:  15.8669, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8778, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:44:44,206 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  185, train_loss:  13.4338, val_loss:  12.2616, grad_norm: 0.0045, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6522, 0.3476, 0.6816, param: [4.14270871 9.4508367  5.0017662  8.92568327], weights: [0.26211577 0.29106848 0.44681576], train_wt_loss:  40.3013, val_wt_loss: 36.7849, train_grp_loss: [11.76468163 15.86697606 11.15901512], val_grp_loss: [10.63843748 14.87800448 11.28409581], train_hist_grp_loss: [17.71182948 22.95044402 44.37983271], cur_train_grp_loss: [0.09487682 0.12299927 0.23742706], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6816, max_kl_dist_index: 2, max_train_grp_loss:  15.8670, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8780, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:44:45,264 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  186, train_loss:  13.4338, val_loss:  12.2617, grad_norm: 0.0045, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6522, 0.3476, 0.6816, param: [4.14257429 9.45062989 5.00194343 8.92626908], weights: [0.26173901 0.29081363 0.44744736], train_wt_loss:  40.3014, val_wt_loss: 36.7850, train_grp_loss: [11.76463547 15.86704834 11.15895737], val_grp_loss: [10.63835497 14.87817348 11.28410311], train_hist_grp_loss: [17.80670594 23.07344383 44.61725856], cur_train_grp_loss: [0.09487646 0.12299981 0.23742585], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6816, max_kl_dist_index: 2, max_train_grp_loss:  15.8670, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8782, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:44:46,316 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  187, train_loss:  13.4338, val_loss:  12.2617, grad_norm: 0.0045, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6522, 0.3476, 0.6816, param: [4.14243887 9.4504251  5.0021198  8.9268572 ], weights: [0.26136236 0.29055853 0.44807911], train_wt_loss:  40.3014, val_wt_loss: 36.7851, train_grp_loss: [11.76458707 15.86712315 11.15889867], val_grp_loss: [10.63827051 14.87834629 11.28410967], train_hist_grp_loss: [17.90158203 23.19644421 44.85468319], cur_train_grp_loss: [0.09487609 0.12300037 0.23742462], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6816, max_kl_dist_index: 2, max_train_grp_loss:  15.8671, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8783, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:44:47,372 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  188, train_loss:  13.4338, val_loss:  12.2617, grad_norm: 0.0045, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6523, 0.3476, 0.6817, param: [4.14230247 9.45022234 5.00229533 8.92744763], weights: [0.26098582 0.29030318 0.44871101], train_wt_loss:  40.3014, val_wt_loss: 36.7852, train_grp_loss: [11.76453643 15.86720049 11.158839  ], val_grp_loss: [10.6381841  14.8785229  11.28411549], train_hist_grp_loss: [17.99645774 23.31944516 45.09210656], cur_train_grp_loss: [0.0948757  0.12300095 0.23742338], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6817, max_kl_dist_index: 2, max_train_grp_loss:  15.8672, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8785, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:44:48,400 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  189, train_loss:  13.4338, val_loss:  12.2617, grad_norm: 0.0045, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6523, 0.3477, 0.6817, param: [4.14216507 9.4500216  5.00247001 8.92804036], weights: [0.26060939 0.29004757 0.44934304], train_wt_loss:  40.3014, val_wt_loss: 36.7852, train_grp_loss: [11.76448355 15.86728035 11.15877838], val_grp_loss: [10.63809573 14.87870331 11.28412056], train_hist_grp_loss: [18.09133303 23.44244672 45.32952867], cur_train_grp_loss: [0.09487529 0.12300155 0.23742211], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6817, max_kl_dist_index: 2, max_train_grp_loss:  15.8673, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8787, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:44:49,482 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  190, train_loss:  13.4338, val_loss:  12.2618, grad_norm: 0.0045, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6523, 0.3477, 0.6817, param: [4.14202668 9.44982288 5.00264384 8.9286354 ], weights: [0.26023307 0.28979172 0.44997521], train_wt_loss:  40.3014, val_wt_loss: 36.7853, train_grp_loss: [11.76442843 15.86736274 11.15871681], val_grp_loss: [10.63800542 14.87888752 11.28412489], train_hist_grp_loss: [18.1862079  23.56544889 45.56694949], cur_train_grp_loss: [0.09487487 0.12300217 0.23742082], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6817, max_kl_dist_index: 2, max_train_grp_loss:  15.8674, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8789, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:44:50,536 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  191, train_loss:  13.4338, val_loss:  12.2618, grad_norm: 0.0046, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6523, 0.3477, 0.6818, param: [4.1418873  9.44962618 5.00281681 8.92923275], weights: [0.25985686 0.28953563 0.45060751], train_wt_loss:  40.3014, val_wt_loss: 36.7854, train_grp_loss: [11.76437106 15.86744766 11.15865427], val_grp_loss: [10.63791315 14.87907554 11.28412847], train_hist_grp_loss: [18.28108232 23.6884517  45.80436899], cur_train_grp_loss: [0.09487442 0.12300281 0.23741951], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6818, max_kl_dist_index: 2, max_train_grp_loss:  15.8674, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8791, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:44:51,564 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  192, train_loss:  13.4338, val_loss:  12.2618, grad_norm: 0.0046, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6524, 0.3477, 0.6818, param: [4.14174692 9.4494315  5.00298893 8.92983241], weights: [0.25948077 0.28927928 0.45123995], train_wt_loss:  40.3014, val_wt_loss: 36.7855, train_grp_loss: [11.76431145 15.86753511 11.15859078], val_grp_loss: [10.63781893 14.87926736 11.28413131], train_hist_grp_loss: [18.37595628 23.81145517 46.04178717], cur_train_grp_loss: [0.09487396 0.12300347 0.23741818], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6818, max_kl_dist_index: 2, max_train_grp_loss:  15.8675, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8793, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:44:52,624 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  193, train_loss:  13.4338, val_loss:  12.2619, grad_norm: 0.0046, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6524, 0.3477, 0.6818, param: [4.14160555 9.44923884 5.0031602  8.93043437], weights: [0.2591048  0.28902269 0.45187251], train_wt_loss:  40.3014, val_wt_loss: 36.7856, train_grp_loss: [11.76424961 15.86762509 11.15852634], val_grp_loss: [10.63772276 14.87946299 11.28413341], train_hist_grp_loss: [18.47082976 23.93445932 46.27920399], cur_train_grp_loss: [0.09487348 0.12300415 0.23741683], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6818, max_kl_dist_index: 2, max_train_grp_loss:  15.8676, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8795, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:44:53,666 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  194, train_loss:  13.4338, val_loss:  12.2619, grad_norm: 0.0046, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6524, 0.3477, 0.6818, param: [4.14146318 9.4490482  5.00333061 8.93103864], weights: [0.25872894 0.28876585 0.45250521], train_wt_loss:  40.3014, val_wt_loss: 36.7857, train_grp_loss: [11.76418552 15.8677176  11.15846093], val_grp_loss: [10.63762464 14.87966243 11.28413476], train_hist_grp_loss: [18.56570274 24.05746417 46.51661945], cur_train_grp_loss: [0.09487298 0.12300485 0.23741545], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6818, max_kl_dist_index: 2, max_train_grp_loss:  15.8677, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8797, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:44:54,741 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  195, train_loss:  13.4338, val_loss:  12.2619, grad_norm: 0.0046, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6525, 0.3477, 0.6819, param: [4.14131983 9.44885958 5.00350017 8.93164521], weights: [0.25835319 0.28850878 0.45313803], train_wt_loss:  40.3014, val_wt_loss: 36.7858, train_grp_loss: [11.76411919 15.86781264 11.15839458], val_grp_loss: [10.63752457 14.87986567 11.28413537], train_hist_grp_loss: [18.6605752  24.18046973 46.75403351], cur_train_grp_loss: [0.09487246 0.12300556 0.23741406], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6819, max_kl_dist_index: 2, max_train_grp_loss:  15.8678, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8799, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:44:55,876 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  196, train_loss:  13.4338, val_loss:  12.2620, grad_norm: 0.0046, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6525, 0.3478, 0.6819, param: [4.14117548 9.44867297 5.00366887 8.93225408], weights: [0.25797757 0.28825146 0.45377098], train_wt_loss:  40.3014, val_wt_loss: 36.7860, train_grp_loss: [11.76405061 15.86791021 11.15832727], val_grp_loss: [10.63742256 14.88007271 11.28413524], train_hist_grp_loss: [18.75544713 24.30347603 46.99144616], cur_train_grp_loss: [0.09487193 0.1230063  0.23741265], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6819, max_kl_dist_index: 2, max_train_grp_loss:  15.8679, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8801, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:44:56,877 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  197, train_loss:  13.4338, val_loss:  12.2620, grad_norm: 0.0047, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6525, 0.3478, 0.6819, param: [4.14103013 9.44848838 5.00383671 8.93286527], weights: [0.25760206 0.2879939  0.45440404], train_wt_loss:  40.3014, val_wt_loss: 36.7861, train_grp_loss: [11.7639798  15.86801032 11.158259  ], val_grp_loss: [10.63731859 14.88028356 11.28413437], train_hist_grp_loss: [18.85031851 24.42648308 47.22885738], cur_train_grp_loss: [0.09487138 0.12300706 0.23741122], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6819, max_kl_dist_index: 2, max_train_grp_loss:  15.8680, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8803, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:44:57,916 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  198, train_loss:  13.4338, val_loss:  12.2621, grad_norm: 0.0047, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6525, 0.3478, 0.6820, param: [4.14088379 9.4483058  5.00400369 8.93347875], weights: [0.25722667 0.28773609 0.45503723], train_wt_loss:  40.3015, val_wt_loss: 36.7862, train_grp_loss: [11.76390675 15.86811295 11.15818978], val_grp_loss: [10.63721267 14.88049822 11.28413275], train_hist_grp_loss: [18.94518931 24.54949092 47.46626715], cur_train_grp_loss: [0.0948708  0.12300783 0.23740977], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6820, max_kl_dist_index: 2, max_train_grp_loss:  15.8681, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8805, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:44:58,984 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  199, train_loss:  13.4338, val_loss:  12.2621, grad_norm: 0.0047, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6526, 0.3478, 0.6820, param: [4.14073645 9.44812523 5.00416981 8.93409454], weights: [0.25685141 0.28747806 0.45567054], train_wt_loss:  40.3015, val_wt_loss: 36.7863, train_grp_loss: [11.76383145 15.86821811 11.1581196 ], val_grp_loss: [10.63710481 14.88071669 11.2841304 ], train_hist_grp_loss: [19.04005953 24.67249954 47.70367544], cur_train_grp_loss: [0.09487022 0.12300863 0.23740829], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6820, max_kl_dist_index: 2, max_train_grp_loss:  15.8682, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8807, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:44:59,946 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1654] - INFO: Iteration:  199, train_loss:  13.4338, val_loss:  12.2621, grad_norm: 0.0047,  live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6526, 0.3478, 0.6820, param: [4.14073645 9.44812523 5.00416981 8.93409454], weights: [0.25685141 0.28747806 0.45567054], train_wt_loss:  40.3015, val_wt_loss: 36.7863, train_grp_loss: [11.76383145 15.86821811 11.1581196 ], val_grp_loss: [10.63710481 14.88071669 11.2841304 ], train_hist_grp_loss: [19.04005953 24.67249954 47.70367544], cur_train_grp_loss: [0.09487022 0.12300863 0.23740829], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6820, max_kl_dist_index: 2, max_train_grp_loss:  15.8682, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8807, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:45:00,184 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:388] - INFO: Policy parameter learned solely on the preference data rdpo: [4.14073645 9.44812523 5.00416981 8.93409454].
2024-10-07 00:45:00,544 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Uniform reward: 3.8269, 3.8269, 3.1987
2024-10-07 00:45:00,544 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Optimal reward: 3.8681, 7.1581, 3.3364
2024-10-07 00:45:00,545 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Policy reward: 3.8540, 6.9363, 3.3325
2024-10-07 00:45:00,545 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:402] - INFO: Reward Error: 0.0036, 0.0310, 0.0012
2024-10-07 00:45:01,264 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:417] - INFO: Optimal reward: 3.8681, 7.1581, 3.3364
Known param reward: [[3.8680634765625, 6.699916015625, 3.30809521484375], [3.46072314453125, 7.1581357421875, 3.12821826171875], [3.83464501953125, 7.0068994140625, 3.336449462890625]], Known param reward error: [[0.0, 0.06401383587376193, 0.00849832984501714], [0.10530859550248342, 0.0, 0.06241101610796404], [0.008639583407495802, 0.02112789329121925, 0.0]].
