2024-10-07 00:48:43,631 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log-hyperparam-search/2024_10_07_00_27_03/rdpo,0.1,0.1,0.03,2021
2024-10-07 00:48:43,633 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2021
2024-10-07 00:48:43,633 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-10-07 00:48:43,725 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.2351, l2 distance: 36.4442, acc: 0.90.
2024-10-07 00:48:43,726 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-10-07 00:48:43,728 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [ 9.05939251 17.1373287   9.50347978 12.39752865]
2024-10-07 00:48:43,950 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.8285, 7.1348, 3.2752
2024-10-07 00:48:44,183 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1314] - INFO: unique_group_ids: {0, 1, 2}
2024-10-07 00:48:45,442 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  0, train_loss:  12.1558, val_loss:  12.4221, grad_norm: 0.4595, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6569, 0.3052, 0.6501, param: [5.44237945 8.3010521  5.14444083 8.57486251], weights: [0.33266582 0.33255027 0.33478392], train_wt_loss:  36.4675, val_wt_loss: 37.2663, train_grp_loss: [11.80405126 13.07676556 10.73288033], val_grp_loss: [12.66582996 12.45403453 12.14569395], train_hist_grp_loss: [0.15100158 0.13942111 0.36256349], cur_train_grp_loss: [0.15100158 0.13942111 0.36256349], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6569, max_kl_dist_index: 0, max_train_grp_loss:  13.0768, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6658, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.3626, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:48:46,501 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  1, train_loss:  12.1558, val_loss:  12.4222, grad_norm: 0.0001, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6570, 0.3053, 0.6502, param: [5.44255734 8.30053637 5.14521359 8.57597671], weights: [0.33223018 0.33221624 0.33555358], train_wt_loss:  36.4675, val_wt_loss: 37.2665, train_grp_loss: [11.8042716  13.07665009 10.73262024], val_grp_loss: [12.66618064 12.45391131 12.14572326], train_hist_grp_loss: [0.24543399 0.24403523 0.57722109], cur_train_grp_loss: [0.09443241 0.10461412 0.21465761], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6570, max_kl_dist_index: 0, max_train_grp_loss:  13.0767, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6662, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2147, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:48:47,595 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  2, train_loss:  12.1558, val_loss:  12.4223, grad_norm: 0.0001, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6571, 0.3053, 0.6502, param: [5.44273466 8.30002189 5.14598734 8.57709587], weights: [0.33179425 0.33188166 0.33632408], train_wt_loss:  36.4675, val_wt_loss: 37.2668, train_grp_loss: [11.80449007 13.07653731 10.73235915], val_grp_loss: [12.66652976 12.45379116 12.14575185], train_hist_grp_loss: [0.33986816 0.34864843 0.7918735 ], cur_train_grp_loss: [0.09443417 0.1046132  0.2146524 ], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6571, max_kl_dist_index: 0, max_train_grp_loss:  13.0765, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6665, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2147, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:48:48,677 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  3, train_loss:  12.1558, val_loss:  12.4224, grad_norm: 0.0002, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6571, 0.3054, 0.6503, param: [5.44291139 8.29950866 5.14676211 8.57822001], weights: [0.33135805 0.33154654 0.33709541], train_wt_loss:  36.4675, val_wt_loss: 37.2671, train_grp_loss: [11.80470666 13.07642722 10.73209706], val_grp_loss: [12.66687735 12.45367408 12.14577971], train_hist_grp_loss: [0.43430408 0.45326073 1.00652068], cur_train_grp_loss: [0.09443592 0.1046123  0.21464718], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6571, max_kl_dist_index: 0, max_train_grp_loss:  13.0764, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6669, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2146, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:48:49,801 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  4, train_loss:  12.1558, val_loss:  12.4224, grad_norm: 0.0003, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6572, 0.3054, 0.6504, param: [5.44308753 8.29899667 5.14753787 8.57934912], weights: [0.33092156 0.33121088 0.33786756], train_wt_loss:  36.4675, val_wt_loss: 37.2673, train_grp_loss: [11.80492137 13.07631983 10.73183398], val_grp_loss: [12.66722339 12.45356006 12.14580685], train_hist_grp_loss: [0.52874173 0.55787215 1.22116262], cur_train_grp_loss: [0.09443765 0.10461142 0.21464194], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6572, max_kl_dist_index: 0, max_train_grp_loss:  13.0763, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6672, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2146, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:48:50,943 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  5, train_loss:  12.1558, val_loss:  12.4225, grad_norm: 0.0003, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6573, 0.3054, 0.6504, param: [5.44326309 8.29848592 5.14831465 8.58048322], weights: [0.33048479 0.33087468 0.33864054], train_wt_loss:  36.4675, val_wt_loss: 37.2676, train_grp_loss: [11.80513421 13.07621514 10.7315699 ], val_grp_loss: [12.66756788 12.45344911 12.14583327], train_hist_grp_loss: [0.62318111 0.66248271 1.4357993 ], cur_train_grp_loss: [0.09443937 0.10461056 0.21463668], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6573, max_kl_dist_index: 0, max_train_grp_loss:  13.0762, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6676, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2146, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:48:52,018 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  6, train_loss:  12.1558, val_loss:  12.4226, grad_norm: 0.0004, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6574, 0.3055, 0.6505, param: [5.44343807 8.29797641 5.14909244 8.58162231], weights: [0.33004774 0.33053793 0.33941433], train_wt_loss:  36.4675, val_wt_loss: 37.2678, train_grp_loss: [11.80534518 13.07611315 10.73130483], val_grp_loss: [12.66791083 12.45334124 12.14585897], train_hist_grp_loss: [0.71762218 0.76709243 1.6504307 ], cur_train_grp_loss: [0.09444107 0.10460972 0.2146314 ], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6574, max_kl_dist_index: 0, max_train_grp_loss:  13.0761, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6679, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2146, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:48:53,025 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  7, train_loss:  12.1558, val_loss:  12.4227, grad_norm: 0.0004, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6575, 0.3055, 0.6506, param: [5.44361245 8.29746814 5.14987124 8.5827664 ], weights: [0.32961042 0.33020065 0.34018894], train_wt_loss:  36.4675, val_wt_loss: 37.2681, train_grp_loss: [11.80555427 13.07601387 10.73103876], val_grp_loss: [12.66825224 12.45323644 12.14588395], train_hist_grp_loss: [0.81206494 0.87170133 1.8650568 ], cur_train_grp_loss: [0.09444276 0.10460891 0.2146261 ], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6575, max_kl_dist_index: 0, max_train_grp_loss:  13.0760, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6683, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2146, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:48:54,071 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  8, train_loss:  12.1558, val_loss:  12.4228, grad_norm: 0.0005, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6575, 0.3056, 0.6506, param: [5.44378624 8.29696111 5.15065106 8.58391549], weights: [0.32917282 0.32986283 0.34096435], train_wt_loss:  36.4675, val_wt_loss: 37.2684, train_grp_loss: [11.80576149 13.0759173  10.73077169], val_grp_loss: [12.66859211 12.45313472 12.1459082 ], train_hist_grp_loss: [0.90650937 0.97630945 2.07967757], cur_train_grp_loss: [0.09444443 0.10460811 0.21462078], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6575, max_kl_dist_index: 0, max_train_grp_loss:  13.0759, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6686, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2146, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:48:55,095 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  9, train_loss:  12.1558, val_loss:  12.4229, grad_norm: 0.0005, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6576, 0.3056, 0.6507, param: [5.44395944 8.29645531 5.1514319  8.5850696 ], weights: [0.32873495 0.32952447 0.34174058], train_wt_loss:  36.4675, val_wt_loss: 37.2686, train_grp_loss: [11.80596683 13.07582343 10.73050362], val_grp_loss: [12.66893044 12.45303608 12.14593174], train_hist_grp_loss: [1.00095547 1.08091678 2.29429301], cur_train_grp_loss: [0.09444609 0.10460734 0.21461543], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6576, max_kl_dist_index: 0, max_train_grp_loss:  13.0758, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6689, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2146, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:48:56,103 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  10, train_loss:  12.1558, val_loss:  12.4230, grad_norm: 0.0006, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6577, 0.3057, 0.6508, param: [5.44413206 8.29595074 5.15221376 8.58622873], weights: [0.3282968  0.32918559 0.34251761], train_wt_loss:  36.4675, val_wt_loss: 37.2689, train_grp_loss: [11.80617031 13.07573228 10.73023455], val_grp_loss: [12.66926722 12.45294052 12.14595456], train_hist_grp_loss: [1.0954032  1.18552337 2.50890308], cur_train_grp_loss: [0.09444773 0.10460659 0.21461007], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6577, max_kl_dist_index: 0, max_train_grp_loss:  13.0757, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6693, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2146, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:48:57,116 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  11, train_loss:  12.1558, val_loss:  12.4231, grad_norm: 0.0007, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6578, 0.3057, 0.6509, param: [5.44430407 8.2954474  5.15299664 8.58739288], weights: [0.32785839 0.32884617 0.34329544], train_wt_loss:  36.4675, val_wt_loss: 37.2692, train_grp_loss: [11.80637191 13.07564384 10.72996449], val_grp_loss: [12.66960247 12.45284806 12.14597665], train_hist_grp_loss: [1.18985256 1.29012923 2.72350777], cur_train_grp_loss: [0.09444936 0.10460586 0.21460469], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6578, max_kl_dist_index: 0, max_train_grp_loss:  13.0756, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6696, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2146, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:48:58,139 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  12, train_loss:  12.1558, val_loss:  12.4231, grad_norm: 0.0007, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6579, 0.3057, 0.6509, param: [5.4444755  8.29494528 5.15378056 8.58856206], weights: [0.32741971 0.32850622 0.34407407], train_wt_loss:  36.4675, val_wt_loss: 37.2694, train_grp_loss: [11.80657164 13.07555811 10.72969342], val_grp_loss: [12.66993617 12.45275868 12.14599804], train_hist_grp_loss: [1.28430354 1.39473438 2.93810706], cur_train_grp_loss: [0.09445098 0.10460515 0.21459929], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6579, max_kl_dist_index: 0, max_train_grp_loss:  13.0756, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6699, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2146, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:48:59,178 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  13, train_loss:  12.1558, val_loss:  12.4232, grad_norm: 0.0008, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6579, 0.3058, 0.6510, param: [5.44464633 8.2944444  5.1545655  8.58973628], weights: [0.32698076 0.32816575 0.34485349], train_wt_loss:  36.4675, val_wt_loss: 37.2697, train_grp_loss: [11.8067695  13.07547511 10.72942136], val_grp_loss: [12.67026833 12.4526724  12.1460187 ], train_hist_grp_loss: [1.37875611 1.49933885 3.15270093], cur_train_grp_loss: [0.09445257 0.10460446 0.21459387], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6579, max_kl_dist_index: 0, max_train_grp_loss:  13.0755, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6703, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2146, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:49:00,183 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  14, train_loss:  12.1558, val_loss:  12.4233, grad_norm: 0.0008, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6580, 0.3058, 0.6511, param: [5.44481656 8.29394473 5.15535148 8.59091555], weights: [0.32654155 0.32782475 0.34563371], train_wt_loss:  36.4675, val_wt_loss: 37.2700, train_grp_loss: [11.80696549 13.07539483 10.72914829], val_grp_loss: [12.67059896 12.45258921 12.14603865], train_hist_grp_loss: [1.47321027 1.60394265 3.36728935], cur_train_grp_loss: [0.09445416 0.1046038  0.21458843], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6580, max_kl_dist_index: 0, max_train_grp_loss:  13.0754, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6706, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2146, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:49:01,204 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  15, train_loss:  12.1558, val_loss:  12.4234, grad_norm: 0.0009, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6581, 0.3059, 0.6512, param: [5.44498619 8.29344629 5.15613849 8.59209987], weights: [0.32610207 0.32748322 0.3464147 ], train_wt_loss:  36.4675, val_wt_loss: 37.2702, train_grp_loss: [11.80715961 13.07531727 10.72887422], val_grp_loss: [12.67092805 12.45250912 12.14605788], train_hist_grp_loss: [1.56766599 1.7085458  3.58187232], cur_train_grp_loss: [0.09445572 0.10460316 0.21458297], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6581, max_kl_dist_index: 0, max_train_grp_loss:  13.0753, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6709, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2146, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:49:02,210 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  16, train_loss:  12.1558, val_loss:  12.4235, grad_norm: 0.0010, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6582, 0.3059, 0.6512, param: [5.44515523 8.29294906 5.15692654 8.59328925], weights: [0.32566234 0.32714118 0.34719649], train_wt_loss:  36.4675, val_wt_loss: 37.2705, train_grp_loss: [11.80735186 13.07524244 10.72859915], val_grp_loss: [12.6712556  12.45243213 12.1460764 ], train_hist_grp_loss: [1.66212327 1.81314834 3.7964498 ], cur_train_grp_loss: [0.09445728 0.10460254 0.21457748], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6582, max_kl_dist_index: 0, max_train_grp_loss:  13.0752, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6713, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2146, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:49:03,216 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  17, train_loss:  12.1559, val_loss:  12.4236, grad_norm: 0.0010, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6583, 0.3060, 0.6513, param: [5.44532366 8.29245305 5.15771563 8.5944837 ], weights: [0.32522234 0.32679861 0.34797905], train_wt_loss:  36.4676, val_wt_loss: 37.2708, train_grp_loss: [11.80754224 13.07517034 10.72832309], val_grp_loss: [12.67158161 12.45235825 12.14609421], train_hist_grp_loss: [1.75658208 1.91775028 4.01102179], cur_train_grp_loss: [0.09445881 0.10460194 0.21457198], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6583, max_kl_dist_index: 0, max_train_grp_loss:  13.0752, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6716, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2146, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:49:04,243 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  18, train_loss:  12.1559, val_loss:  12.4237, grad_norm: 0.0011, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6584, 0.3060, 0.6514, param: [5.4454915  8.29195825 5.15850576 8.59568322], weights: [0.32478209 0.32645553 0.34876238], train_wt_loss:  36.4676, val_wt_loss: 37.2711, train_grp_loss: [11.80773075 13.07510097 10.72804601], val_grp_loss: [12.67190609 12.45228747 12.1461113 ], train_hist_grp_loss: [1.85104242 2.02235164 4.22558825], cur_train_grp_loss: [0.09446034 0.10460136 0.21456646], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6584, max_kl_dist_index: 0, max_train_grp_loss:  13.0751, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6719, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2146, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:49:05,286 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  19, train_loss:  12.1559, val_loss:  12.4238, grad_norm: 0.0012, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6584, 0.3061, 0.6515, param: [5.44565873 8.29146466 5.15929694 8.59688781], weights: [0.32434158 0.32611193 0.34954649], train_wt_loss:  36.4676, val_wt_loss: 37.2713, train_grp_loss: [11.8079174  13.07503434 10.72776794], val_grp_loss: [12.67222903 12.4522198  12.14612768], train_hist_grp_loss: [1.94550427 2.12695245 4.44014917], cur_train_grp_loss: [0.09446185 0.10460081 0.21456092], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6584, max_kl_dist_index: 0, max_train_grp_loss:  13.0750, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6722, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2146, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:49:06,366 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  20, train_loss:  12.1559, val_loss:  12.4239, grad_norm: 0.0012, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6585, 0.3061, 0.6515, param: [5.44582536 8.29097229 5.16008916 8.59809749], weights: [0.32390082 0.32576782 0.35033136], train_wt_loss:  36.4676, val_wt_loss: 37.2716, train_grp_loss: [11.80810217 13.07497044 10.72748886], val_grp_loss: [12.67255043 12.45215525 12.14614334], train_hist_grp_loss: [2.03996761 2.23155273 4.65470453], cur_train_grp_loss: [0.09446334 0.10460027 0.21455536], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6585, max_kl_dist_index: 0, max_train_grp_loss:  13.0750, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6726, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2146, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:49:07,392 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  21, train_loss:  12.1559, val_loss:  12.4240, grad_norm: 0.0013, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6586, 0.3062, 0.6516, param: [5.44599139 8.29048111 5.16088244 8.59931227], weights: [0.32345981 0.32542319 0.351117  ], train_wt_loss:  36.4676, val_wt_loss: 37.2719, train_grp_loss: [11.80828509 13.07490928 10.72720878], val_grp_loss: [12.6728703  12.45209381 12.1461583 ], train_hist_grp_loss: [2.13443242 2.33615249 4.86925431], cur_train_grp_loss: [0.09446482 0.10459976 0.21454978], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6586, max_kl_dist_index: 0, max_train_grp_loss:  13.0749, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6729, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2145, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:49:08,398 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  22, train_loss:  12.1559, val_loss:  12.4240, grad_norm: 0.0013, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6587, 0.3062, 0.6517, param: [5.4461568  8.28999115 5.16167677 8.60053214], weights: [0.32301854 0.32507805 0.3519034 ], train_wt_loss:  36.4676, val_wt_loss: 37.2721, train_grp_loss: [11.80846613 13.07485087 10.7269277 ], val_grp_loss: [12.67318864 12.45203549 12.14617255], train_hist_grp_loss: [2.2288987  2.44075177 5.08379848], cur_train_grp_loss: [0.09446628 0.10459927 0.21454418], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6587, max_kl_dist_index: 0, max_train_grp_loss:  13.0749, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6732, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2145, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:49:09,411 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  23, train_loss:  12.1559, val_loss:  12.4241, grad_norm: 0.0014, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6588, 0.3062, 0.6518, param: [5.44632162 8.28950238 5.16247216 8.60175711], weights: [0.32257703 0.32473241 0.35269056], train_wt_loss:  36.4676, val_wt_loss: 37.2724, train_grp_loss: [11.80864532 13.07479519 10.72664561], val_grp_loss: [12.67350544 12.45198029 12.14618609], train_hist_grp_loss: [2.32336643 2.54535057 5.29833704], cur_train_grp_loss: [0.09446773 0.10459881 0.21453855], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6588, max_kl_dist_index: 0, max_train_grp_loss:  13.0748, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6735, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2145, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:49:10,462 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  24, train_loss:  12.1559, val_loss:  12.4242, grad_norm: 0.0015, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6589, 0.3063, 0.6518, param: [5.44648582 8.28901482 5.1632686  8.6029872 ], weights: [0.32213527 0.32438626 0.35347847], train_wt_loss:  36.4676, val_wt_loss: 37.2727, train_grp_loss: [11.80882263 13.07474227 10.72636252], val_grp_loss: [12.67382071 12.45192822 12.14619891], train_hist_grp_loss: [2.4178356  2.64994893 5.51286995], cur_train_grp_loss: [0.09446916 0.10459836 0.21453291], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6589, max_kl_dist_index: 0, max_train_grp_loss:  13.0747, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6738, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2145, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:49:11,483 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  25, train_loss:  12.1559, val_loss:  12.4243, grad_norm: 0.0015, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6590, 0.3063, 0.6519, param: [5.44664941 8.28852845 5.16406611 8.6042224 ], weights: [0.32169327 0.3240396  0.35426713], train_wt_loss:  36.4677, val_wt_loss: 37.2730, train_grp_loss: [11.80899809 13.07469209 10.72607843], val_grp_loss: [12.67413445 12.45187927 12.14621104], train_hist_grp_loss: [2.51230618 2.75454687 5.7273972 ], cur_train_grp_loss: [0.09447058 0.10459794 0.21452725], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6590, max_kl_dist_index: 0, max_train_grp_loss:  13.0747, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6741, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2145, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:49:12,510 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  26, train_loss:  12.1559, val_loss:  12.4244, grad_norm: 0.0016, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6590, 0.3064, 0.6520, param: [5.4468124  8.28804328 5.16486468 8.60546273], weights: [0.32125102 0.32369244 0.35505654], train_wt_loss:  36.4677, val_wt_loss: 37.2733, train_grp_loss: [11.80917168 13.07464467 10.72579333], val_grp_loss: [12.67444666 12.45183346 12.14622245], train_hist_grp_loss: [2.60677816 2.85914441 5.94191877], cur_train_grp_loss: [0.09447198 0.10459754 0.21452157], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6590, max_kl_dist_index: 0, max_train_grp_loss:  13.0746, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6744, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2145, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:49:13,576 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  27, train_loss:  12.1559, val_loss:  12.4245, grad_norm: 0.0017, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6591, 0.3064, 0.6521, param: [5.44697477 8.2875593  5.16566432 8.60670819], weights: [0.32080854 0.32334478 0.35584668], train_wt_loss:  36.4677, val_wt_loss: 37.2735, train_grp_loss: [11.80934341 13.0746     10.72550722], val_grp_loss: [12.67475734 12.45179077 12.14623316], train_hist_grp_loss: [2.70125154 2.96374157 6.15643463], cur_train_grp_loss: [0.09447337 0.10459716 0.21451587], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6591, max_kl_dist_index: 0, max_train_grp_loss:  13.0746, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6748, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2145, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:49:14,628 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  28, train_loss:  12.1559, val_loss:  12.4246, grad_norm: 0.0017, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6592, 0.3065, 0.6521, param: [5.44713653 8.28707651 5.16646502 8.60795879], weights: [0.32036581 0.32299662 0.35663757], train_wt_loss:  36.4677, val_wt_loss: 37.2738, train_grp_loss: [11.80951328 13.07455808 10.72522011], val_grp_loss: [12.67506649 12.45175122 12.14624317], train_hist_grp_loss: [2.79572628 3.06833837 6.37094478], cur_train_grp_loss: [0.09447475 0.1045968  0.21451014], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6592, max_kl_dist_index: 0, max_train_grp_loss:  13.0746, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6751, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2145, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:49:15,645 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  29, train_loss:  12.1559, val_loss:  12.4247, grad_norm: 0.0018, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6593, 0.3065, 0.6522, param: [5.44729768 8.2865949  5.1672668  8.60921452], weights: [0.31992285 0.32264796 0.35742919], train_wt_loss:  36.4677, val_wt_loss: 37.2741, train_grp_loss: [11.80968129 13.07451893 10.72493199], val_grp_loss: [12.67537411 12.45171481 12.14625247], train_hist_grp_loss: [2.89020239 3.17293483 6.58544918], cur_train_grp_loss: [0.09447611 0.10459646 0.2145044 ], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6593, max_kl_dist_index: 0, max_train_grp_loss:  13.0745, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6754, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2145, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:49:16,678 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  30, train_loss:  12.1559, val_loss:  12.4248, grad_norm: 0.0019, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6594, 0.3066, 0.6523, param: [5.44745821 8.28611448 5.16806965 8.61047541], weights: [0.31947965 0.32229881 0.35822154], train_wt_loss:  36.4677, val_wt_loss: 37.2744, train_grp_loss: [11.80984744 13.07448253 10.72464287], val_grp_loss: [12.6756802  12.45168154 12.14626106], train_hist_grp_loss: [2.98467984 3.27753098 6.79994782], cur_train_grp_loss: [0.09447745 0.10459615 0.21449864], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6594, max_kl_dist_index: 0, max_train_grp_loss:  13.0745, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6757, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2145, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:49:17,719 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  31, train_loss:  12.1559, val_loss:  12.4249, grad_norm: 0.0019, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6595, 0.3066, 0.6524, param: [5.44761812 8.28563525 5.16887358 8.61174146], weights: [0.31903622 0.32194917 0.35901461], train_wt_loss:  36.4678, val_wt_loss: 37.2747, train_grp_loss: [11.81001173 13.07444891 10.72435275], val_grp_loss: [12.67598476 12.45165141 12.14626896], train_hist_grp_loss: [3.07915862 3.38212684 7.01444068], cur_train_grp_loss: [0.09447878 0.10459586 0.21449286], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6595, max_kl_dist_index: 0, max_train_grp_loss:  13.0744, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6760, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2145, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:49:18,739 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  32, train_loss:  12.1559, val_loss:  12.4250, grad_norm: 0.0020, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6596, 0.3067, 0.6525, param: [5.44777741 8.28515719 5.16967859 8.61301267], weights: [0.31859255 0.32159904 0.35980841], train_wt_loss:  36.4678, val_wt_loss: 37.2749, train_grp_loss: [11.81017416 13.07441804 10.72406161], val_grp_loss: [12.6762878  12.45162443 12.14627615], train_hist_grp_loss: [3.17363871 3.48672243 7.22892773], cur_train_grp_loss: [0.09448009 0.10459559 0.21448705], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6596, max_kl_dist_index: 0, max_train_grp_loss:  13.0744, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6763, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2145, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:49:19,774 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  33, train_loss:  12.1559, val_loss:  12.4251, grad_norm: 0.0021, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6597, 0.3067, 0.6526, param: [5.44793609 8.28468032 5.17048467 8.61428904], weights: [0.31814866 0.32124841 0.36060293], train_wt_loss:  36.4678, val_wt_loss: 37.2752, train_grp_loss: [11.81033473 13.07438995 10.72376947], val_grp_loss: [12.67658931 12.4516006  12.14628265], train_hist_grp_loss: [3.26812011 3.59131778 7.44340896], cur_train_grp_loss: [0.09448139 0.10459534 0.21448123], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6597, max_kl_dist_index: 0, max_train_grp_loss:  13.0744, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6766, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2145, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:49:20,817 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  34, train_loss:  12.1559, val_loss:  12.4252, grad_norm: 0.0022, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6597, 0.3068, 0.6526, param: [5.44809415 8.28420461 5.17129185 8.61557059], weights: [0.31770454 0.3208973  0.36139816], train_wt_loss:  36.4678, val_wt_loss: 37.2755, train_grp_loss: [11.81049345 13.07436463 10.72347633], val_grp_loss: [12.6768893  12.45157993 12.14628844], train_hist_grp_loss: [3.36260278 3.6959129  7.65788435], cur_train_grp_loss: [0.09448268 0.10459512 0.21447539], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6597, max_kl_dist_index: 0, max_train_grp_loss:  13.0744, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6769, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2145, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:49:21,831 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  35, train_loss:  12.1559, val_loss:  12.4253, grad_norm: 0.0022, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6598, 0.3068, 0.6527, param: [5.44825158 8.28373008 5.1721001  8.61685733], weights: [0.31726019 0.32054571 0.3621941 ], train_wt_loss:  36.4678, val_wt_loss: 37.2758, train_grp_loss: [11.81065031 13.07434208 10.72318218], val_grp_loss: [12.67718776 12.45156241 12.14629354], train_hist_grp_loss: [3.45708673 3.80050781 7.87235388], cur_train_grp_loss: [0.09448395 0.10459492 0.21446953], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6598, max_kl_dist_index: 0, max_train_grp_loss:  13.0743, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6772, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2145, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:49:22,844 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  36, train_loss:  12.1560, val_loss:  12.4254, grad_norm: 0.0023, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6599, 0.3069, 0.6528, param: [5.44840839 8.28325672 5.17290945 8.61814925], weights: [0.31681562 0.32019363 0.36299075], train_wt_loss:  36.4679, val_wt_loss: 37.2761, train_grp_loss: [11.81080532 13.0743223  10.72288702], val_grp_loss: [12.6774847  12.45154804 12.14629793], train_hist_grp_loss: [3.55157193 3.90510255 8.08681752], cur_train_grp_loss: [0.0944852  0.10459474 0.21446364], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6599, max_kl_dist_index: 0, max_train_grp_loss:  13.0743, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6775, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2145, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:49:23,891 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  37, train_loss:  12.1560, val_loss:  12.4255, grad_norm: 0.0024, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6600, 0.3069, 0.6529, param: [5.44856458 8.28278453 5.17371989 8.61944636], weights: [0.31637083 0.31984107 0.3637881 ], train_wt_loss:  36.4679, val_wt_loss: 37.2764, train_grp_loss: [11.81095848 13.07430531 10.72259085], val_grp_loss: [12.67778012 12.45153684 12.14630164], train_hist_grp_loss: [3.64605838 4.00969713 8.30127526], cur_train_grp_loss: [0.09448644 0.10459458 0.21445774], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6600, max_kl_dist_index: 0, max_train_grp_loss:  13.0743, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6778, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2145, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:49:24,934 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  38, train_loss:  12.1560, val_loss:  12.4256, grad_norm: 0.0024, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6601, 0.3070, 0.6530, param: [5.44872014 8.28231351 5.17453142 8.62074868], weights: [0.31592582 0.31948803 0.36458615], train_wt_loss:  36.4679, val_wt_loss: 37.2767, train_grp_loss: [11.81110978 13.0742911  10.72229368], val_grp_loss: [12.67807402 12.4515288  12.14630464], train_hist_grp_loss: [3.74054604 4.11429157 8.51572708], cur_train_grp_loss: [0.09448767 0.10459444 0.21445182], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6601, max_kl_dist_index: 0, max_train_grp_loss:  13.0743, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6781, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2145, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:49:25,950 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  39, train_loss:  12.1560, val_loss:  12.4257, grad_norm: 0.0025, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6602, 0.3070, 0.6530, param: [5.44887508 8.28184364 5.17534405 8.6220562 ], weights: [0.31548059 0.31913451 0.36538489], train_wt_loss:  36.4679, val_wt_loss: 37.2770, train_grp_loss: [11.81125923 13.07427967 10.7219955 ], val_grp_loss: [12.67836639 12.45152393 12.14630695], train_hist_grp_loss: [3.83503492 4.2188859  8.73017295], cur_train_grp_loss: [0.09448888 0.10459433 0.21444587], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6602, max_kl_dist_index: 0, max_train_grp_loss:  13.0743, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6784, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2144, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:49:27,000 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  40, train_loss:  12.1560, val_loss:  12.4257, grad_norm: 0.0026, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6603, 0.3071, 0.6531, param: [5.44902939 8.28137494 5.17615778 8.62336894], weights: [0.31503514 0.31878053 0.36618433], train_wt_loss:  36.4679, val_wt_loss: 37.2772, train_grp_loss: [11.81140683 13.07427103 10.72169631], val_grp_loss: [12.67865725 12.45152222 12.14630857], train_hist_grp_loss: [3.929525   4.32348014 8.94461286], cur_train_grp_loss: [0.09449007 0.10459424 0.21443991], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6603, max_kl_dist_index: 0, max_train_grp_loss:  13.0743, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6787, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2144, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:49:28,053 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  41, train_loss:  12.1560, val_loss:  12.4258, grad_norm: 0.0026, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6604, 0.3071, 0.6532, param: [5.44918307 8.28090739 5.17697261 8.62468689], weights: [0.31458948 0.31842606 0.36698445], train_wt_loss:  36.4680, val_wt_loss: 37.2775, train_grp_loss: [11.81155258 13.07426517 10.72139611], val_grp_loss: [12.67894659 12.45152369 12.1463095 ], train_hist_grp_loss: [4.02401625 4.42807431 9.15904679], cur_train_grp_loss: [0.09449125 0.10459417 0.21443393], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6604, max_kl_dist_index: 0, max_train_grp_loss:  13.0743, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6789, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2144, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:49:29,101 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  42, train_loss:  12.1560, val_loss:  12.4259, grad_norm: 0.0027, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6605, 0.3072, 0.6533, param: [5.44933612 8.280441   5.17778854 8.62601007], weights: [0.31414361 0.31807113 0.36778526], train_wt_loss:  36.4680, val_wt_loss: 37.2778, train_grp_loss: [11.81169648 13.07426211 10.72109491], val_grp_loss: [12.6792344  12.45152834 12.14630973], train_hist_grp_loss: [4.11850867 4.53266843 9.37347471], cur_train_grp_loss: [0.09449242 0.10459412 0.21442792], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6605, max_kl_dist_index: 0, max_train_grp_loss:  13.0743, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6792, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2144, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:49:30,121 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  43, train_loss:  12.1560, val_loss:  12.4260, grad_norm: 0.0028, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6606, 0.3072, 0.6534, param: [5.44948853 8.27997575 5.17860558 8.62733848], weights: [0.31369753 0.31771573 0.36858674], train_wt_loss:  36.4680, val_wt_loss: 37.2781, train_grp_loss: [11.81183854 13.07426184 10.7207927 ], val_grp_loss: [12.67952071 12.45153616 12.14630928], train_hist_grp_loss: [4.21300224 4.63726252 9.58789661], cur_train_grp_loss: [0.09449357 0.1045941  0.2144219 ], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6606, max_kl_dist_index: 0, max_train_grp_loss:  13.0743, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6795, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2144, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:49:31,134 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  44, train_loss:  12.1560, val_loss:  12.4261, grad_norm: 0.0029, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6607, 0.3073, 0.6535, param: [5.44964032 8.27951166 5.17942373 8.62867213], weights: [0.31325124 0.31735986 0.3693889 ], train_wt_loss:  36.4680, val_wt_loss: 37.2784, train_grp_loss: [11.81197874 13.07426436 10.72048948], val_grp_loss: [12.67980549 12.45154716 12.14630813], train_hist_grp_loss: [4.30749695 4.74185662 9.80231247], cur_train_grp_loss: [0.09449471 0.10459409 0.21441585], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6607, max_kl_dist_index: 0, max_train_grp_loss:  13.0743, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6798, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2144, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:49:32,169 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  45, train_loss:  12.1560, val_loss:  12.4262, grad_norm: 0.0029, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6608, 0.3073, 0.6536, param: [5.44979147 8.27904872 5.18024298 8.63001102], weights: [0.31280474 0.31700353 0.37019173], train_wt_loss:  36.4681, val_wt_loss: 37.2787, train_grp_loss: [11.81211711 13.07426969 10.72018526], val_grp_loss: [12.68008876 12.45156134 12.1463063 ], train_hist_grp_loss: [ 4.40199278  4.84645073 10.01672226], cur_train_grp_loss: [0.09449583 0.10459411 0.21440979], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6608, max_kl_dist_index: 0, max_train_grp_loss:  13.0743, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6801, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2144, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:49:33,194 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  46, train_loss:  12.1560, val_loss:  12.4263, grad_norm: 0.0030, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6608, 0.3074, 0.6536, param: [5.44994198 8.27858692 5.18106335 8.63135516], weights: [0.31235804 0.31664674 0.37099522], train_wt_loss:  36.4681, val_wt_loss: 37.2790, train_grp_loss: [11.81225362 13.07427781 10.71988003], val_grp_loss: [12.68037052 12.45157872 12.14630378], train_hist_grp_loss: [ 4.49648972  4.95104489 10.23112596], cur_train_grp_loss: [0.09449694 0.10459416 0.21440371], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6608, max_kl_dist_index: 0, max_train_grp_loss:  13.0743, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6804, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2144, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:49:34,245 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  47, train_loss:  12.1560, val_loss:  12.4264, grad_norm: 0.0031, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6609, 0.3074, 0.6537, param: [5.45009186 8.27812626 5.18188484 8.63270455], weights: [0.31191114 0.31628948 0.37179938], train_wt_loss:  36.4681, val_wt_loss: 37.2793, train_grp_loss: [11.8123883  13.07428874 10.71957379], val_grp_loss: [12.68065076 12.45159928 12.14630058], train_hist_grp_loss: [ 4.59098775  5.05563911 10.44552356], cur_train_grp_loss: [0.09449803 0.10459422 0.2143976 ], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6609, max_kl_dist_index: 0, max_train_grp_loss:  13.0743, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6807, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2144, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:49:35,280 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  48, train_loss:  12.1561, val_loss:  12.4265, grad_norm: 0.0032, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6610, 0.3075, 0.6538, param: [5.4502411  8.27766674 5.18270745 8.63405921], weights: [0.31146403 0.31593177 0.3726042 ], train_wt_loss:  36.4682, val_wt_loss: 37.2796, train_grp_loss: [11.81252113 13.07430247 10.71926654], val_grp_loss: [12.68092949 12.45162303 12.14629669], train_hist_grp_loss: [ 4.68548685  5.16023342 10.65991504], cur_train_grp_loss: [0.09449911 0.10459431 0.21439148], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6610, max_kl_dist_index: 0, max_train_grp_loss:  13.0743, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6809, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2144, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:49:36,318 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  49, train_loss:  12.1561, val_loss:  12.4266, grad_norm: 0.0032, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6611, 0.3075, 0.6539, param: [5.4503897  8.27720835 5.18353117 8.63541914], weights: [0.31101673 0.3155736  0.37340967], train_wt_loss:  36.4682, val_wt_loss: 37.2799, train_grp_loss: [11.81265212 13.07431901 10.71895828], val_grp_loss: [12.68120671 12.45164998 12.14629211], train_hist_grp_loss: [ 4.77998702  5.26482784 10.87430037], cur_train_grp_loss: [0.09450017 0.10459442 0.21438533], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6611, max_kl_dist_index: 0, max_train_grp_loss:  13.0743, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6812, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2144, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:49:37,299 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  50, train_loss:  12.1561, val_loss:  12.4267, grad_norm: 0.0033, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6612, 0.3076, 0.6540, param: [5.45053766 8.2767511  5.18435602 8.63678434], weights: [0.31056924 0.31521498 0.37421578], train_wt_loss:  36.4682, val_wt_loss: 37.2802, train_grp_loss: [11.81278127 13.07433836 10.71864902], val_grp_loss: [12.68148242 12.45168012 12.14628686], train_hist_grp_loss: [ 4.87448824  5.3694224  11.08867953], cur_train_grp_loss: [0.09450122 0.10459455 0.21437917], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6612, max_kl_dist_index: 0, max_train_grp_loss:  13.0743, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6815, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2144, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:49:38,323 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  51, train_loss:  12.1561, val_loss:  12.4268, grad_norm: 0.0034, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6613, 0.3076, 0.6541, param: [5.45068498 8.27629498 5.185182   8.63815482], weights: [0.31012154 0.31485591 0.37502255], train_wt_loss:  36.4683, val_wt_loss: 37.2805, train_grp_loss: [11.81290859 13.07436053 10.71833875], val_grp_loss: [12.68175662 12.45171347 12.14628092], train_hist_grp_loss: [ 4.96899049  5.4740171  11.30305251], cur_train_grp_loss: [0.09450225 0.10459471 0.21437298], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6613, max_kl_dist_index: 0, max_train_grp_loss:  13.0744, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6818, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2144, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:49:39,337 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  52, train_loss:  12.1561, val_loss:  12.4269, grad_norm: 0.0035, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6614, 0.3077, 0.6542, param: [5.45083165 8.27583998 5.1860091  8.63953058], weights: [0.30967366 0.31449638 0.37582996], train_wt_loss:  36.4683, val_wt_loss: 37.2808, train_grp_loss: [11.81303406 13.07438551 10.71802747], val_grp_loss: [12.68202931 12.45175002 12.1462743 ], train_hist_grp_loss: [ 5.06349376  5.57861199 11.51741929], cur_train_grp_loss: [0.09450327 0.10459488 0.21436677], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6614, max_kl_dist_index: 0, max_train_grp_loss:  13.0744, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6820, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2144, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:49:40,354 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  53, train_loss:  12.1561, val_loss:  12.4270, grad_norm: 0.0035, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6615, 0.3077, 0.6543, param: [5.45097768 8.27538612 5.18683733 8.64091164], weights: [0.30922559 0.31413641 0.376638  ], train_wt_loss:  36.4683, val_wt_loss: 37.2811, train_grp_loss: [11.8131577  13.07441331 10.71771518], val_grp_loss: [12.6823005  12.45178977 12.146267  ], train_hist_grp_loss: [ 5.15799803  5.68320707 11.73177984], cur_train_grp_loss: [0.09450427 0.10459508 0.21436055], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6615, max_kl_dist_index: 0, max_train_grp_loss:  13.0744, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6823, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2144, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:49:41,394 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  54, train_loss:  12.1561, val_loss:  12.4271, grad_norm: 0.0036, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6616, 0.3078, 0.6544, param: [5.45112306 8.27493337 5.18766669 8.642298  ], weights: [0.30877732 0.313776   0.37744668], train_wt_loss:  36.4684, val_wt_loss: 37.2814, train_grp_loss: [11.8132795  13.07444392 10.71740189], val_grp_loss: [12.68257018 12.45183273 12.14625903], train_hist_grp_loss: [ 5.25250329  5.78780238 11.94613414], cur_train_grp_loss: [0.09450526 0.10459531 0.2143543 ], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6616, max_kl_dist_index: 0, max_train_grp_loss:  13.0744, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6826, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2144, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:49:42,432 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  55, train_loss:  12.1561, val_loss:  12.4272, grad_norm: 0.0037, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6617, 0.3078, 0.6544, param: [5.4512678  8.27448174 5.18849719 8.64368966], weights: [0.30832888 0.31341514 0.37825598], train_wt_loss:  36.4684, val_wt_loss: 37.2817, train_grp_loss: [11.81339947 13.07447736 10.71708759], val_grp_loss: [12.68283835 12.45187891 12.14625038], train_hist_grp_loss: [ 5.34700953  5.89239793 12.16048218], cur_train_grp_loss: [0.09450624 0.10459555 0.21434804], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6617, max_kl_dist_index: 0, max_train_grp_loss:  13.0745, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6828, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2143, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:49:43,474 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  56, train_loss:  12.1561, val_loss:  12.4273, grad_norm: 0.0038, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6618, 0.3079, 0.6545, param: [5.45141188 8.27403123 5.18932883 8.64508663], weights: [0.30788024 0.31305384 0.37906591], train_wt_loss:  36.4684, val_wt_loss: 37.2820, train_grp_loss: [11.81351761 13.07451363 10.71677228], val_grp_loss: [12.68310502 12.45192829 12.14624105], train_hist_grp_loss: [ 5.44151672  5.99699375 12.37482393], cur_train_grp_loss: [0.0945072  0.10459582 0.21434175], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6618, max_kl_dist_index: 0, max_train_grp_loss:  13.0745, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6831, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2143, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:49:44,525 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  57, train_loss:  12.1562, val_loss:  12.4275, grad_norm: 0.0039, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6619, 0.3079, 0.6546, param: [5.45155532 8.27358183 5.1901616  8.64648891], weights: [0.30743143 0.31269211 0.37987646], train_wt_loss:  36.4685, val_wt_loss: 37.2824, train_grp_loss: [11.81363392 13.07455272 10.71645597], val_grp_loss: [12.68337019 12.4519809  12.14623105], train_hist_grp_loss: [ 5.53602487  6.10158986 12.58915938], cur_train_grp_loss: [0.09450814 0.10459611 0.21433545], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6619, max_kl_dist_index: 0, max_train_grp_loss:  13.0746, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6834, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2143, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:49:45,572 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  58, train_loss:  12.1562, val_loss:  12.4276, grad_norm: 0.0039, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6620, 0.3080, 0.6547, param: [5.45169811 8.27313354 5.19099552 8.64789652], weights: [0.30698244 0.31232993 0.38068763], train_wt_loss:  36.4685, val_wt_loss: 37.2827, train_grp_loss: [11.81374839 13.07459464 10.71613864], val_grp_loss: [12.68363386 12.45203672 12.14622038], train_hist_grp_loss: [ 5.63053394  6.20618628 12.8034885 ], cur_train_grp_loss: [0.09450907 0.10459642 0.21432912], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6620, max_kl_dist_index: 0, max_train_grp_loss:  13.0746, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6836, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2143, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:49:46,589 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  59, train_loss:  12.1562, val_loss:  12.4277, grad_norm: 0.0040, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6621, 0.3081, 0.6548, param: [5.45184024 8.27268636 5.19183058 8.64930945], weights: [0.30653327 0.31196733 0.38149941], train_wt_loss:  36.4685, val_wt_loss: 37.2830, train_grp_loss: [11.81386104 13.07463939 10.71582032], val_grp_loss: [12.68389602 12.45209577 12.14620904], train_hist_grp_loss: [ 5.72504392  6.31078304 13.01781127], cur_train_grp_loss: [0.09450999 0.10459676 0.21432277], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6621, max_kl_dist_index: 0, max_train_grp_loss:  13.0746, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6839, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2143, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:49:47,612 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  60, train_loss:  12.1562, val_loss:  12.4278, grad_norm: 0.0041, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6622, 0.3081, 0.6549, param: [5.45198172 8.27224029 5.19266679 8.65072771], weights: [0.30608392 0.31160429 0.3823118 ], train_wt_loss:  36.4686, val_wt_loss: 37.2833, train_grp_loss: [11.81397186 13.07468698 10.71550098], val_grp_loss: [12.68415669 12.45215804 12.14619702], train_hist_grp_loss: [ 5.81955481  6.41538015 13.23212767], cur_train_grp_loss: [0.09451089 0.10459712 0.21431641], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6622, max_kl_dist_index: 0, max_train_grp_loss:  13.0747, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6842, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2143, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:49:48,632 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  61, train_loss:  12.1562, val_loss:  12.4279, grad_norm: 0.0042, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6623, 0.3082, 0.6550, param: [5.45212254 8.27179532 5.19350414 8.65215132], weights: [0.3056344  0.31124082 0.38312478], train_wt_loss:  36.4686, val_wt_loss: 37.2836, train_grp_loss: [11.81408085 13.07473741 10.71518064], val_grp_loss: [12.68441585 12.45222354 12.14618434], train_hist_grp_loss: [ 5.91406659  6.51997765 13.44643769], cur_train_grp_loss: [0.09451177 0.1045975  0.21431002], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6623, max_kl_dist_index: 0, max_train_grp_loss:  13.0747, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6844, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2143, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:49:49,642 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  62, train_loss:  12.1562, val_loss:  12.4280, grad_norm: 0.0043, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6624, 0.3082, 0.6551, param: [5.45226271 8.27135144 5.19434265 8.65358027], weights: [0.30518471 0.31087692 0.38393837], train_wt_loss:  36.4687, val_wt_loss: 37.2839, train_grp_loss: [11.81418802 13.07479067 10.71485929], val_grp_loss: [12.68467352 12.45229227 12.14617099], train_hist_grp_loss: [ 6.00857923  6.62457555 13.66074131], cur_train_grp_loss: [0.09451265 0.1045979  0.21430361], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6624, max_kl_dist_index: 0, max_train_grp_loss:  13.0748, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6847, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2143, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:49:50,686 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  63, train_loss:  12.1562, val_loss:  12.4281, grad_norm: 0.0043, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6625, 0.3083, 0.6552, param: [5.45240222 8.27090867 5.19518231 8.65501457], weights: [0.30473485 0.3105126  0.38475256], train_wt_loss:  36.4687, val_wt_loss: 37.2842, train_grp_loss: [11.81429337 13.07484678 10.71453694], val_grp_loss: [12.6849297  12.45236424 12.14615697], train_hist_grp_loss: [ 6.10309274  6.72917387 13.87503849], cur_train_grp_loss: [0.0945135  0.10459833 0.21429719], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6625, max_kl_dist_index: 0, max_train_grp_loss:  13.0748, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6849, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2143, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:49:51,732 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  64, train_loss:  12.1562, val_loss:  12.4282, grad_norm: 0.0044, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6626, 0.3083, 0.6553, param: [5.45254107 8.27046698 5.19602313 8.65645422], weights: [0.30428482 0.31014785 0.38556733], train_wt_loss:  36.4687, val_wt_loss: 37.2845, train_grp_loss: [11.8143969  13.07490573 10.71421358], val_grp_loss: [12.68518438 12.45243944 12.14614229], train_hist_grp_loss: [ 6.19760709  6.83377265 14.08932923], cur_train_grp_loss: [0.09451435 0.10459877 0.21429074], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6626, max_kl_dist_index: 0, max_train_grp_loss:  13.0749, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6852, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2143, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:49:52,748 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  65, train_loss:  12.1563, val_loss:  12.4283, grad_norm: 0.0045, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6627, 0.3084, 0.6554, param: [5.45267926 8.27002639 5.1968651  8.65789924], weights: [0.30383463 0.30978269 0.38638269], train_wt_loss:  36.4688, val_wt_loss: 37.2849, train_grp_loss: [11.8144986  13.07496752 10.71388921], val_grp_loss: [12.68543757 12.45251788 12.14612694], train_hist_grp_loss: [ 6.29212226  6.93837189 14.3036135 ], cur_train_grp_loss: [0.09451518 0.10459925 0.21428427], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6627, max_kl_dist_index: 0, max_train_grp_loss:  13.0750, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6854, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2143, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:49:53,802 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  66, train_loss:  12.1563, val_loss:  12.4284, grad_norm: 0.0046, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6628, 0.3084, 0.6555, param: [5.45281678 8.26958688 5.19770823 8.65934963], weights: [0.30338427 0.3094171  0.38719863], train_wt_loss:  36.4688, val_wt_loss: 37.2852, train_grp_loss: [11.81459849 13.07503217 10.71356384], val_grp_loss: [12.68568926 12.45259956 12.14611094], train_hist_grp_loss: [ 6.38663825  7.04297163 14.51789129], cur_train_grp_loss: [0.09451599 0.10459974 0.21427778], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6628, max_kl_dist_index: 0, max_train_grp_loss:  13.0750, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6857, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2143, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:49:54,841 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  67, train_loss:  12.1563, val_loss:  12.4285, grad_norm: 0.0047, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6629, 0.3085, 0.6556, param: [5.45295364 8.26914846 5.19855252 8.66080538], weights: [0.30293375 0.3090511  0.38801514], train_wt_loss:  36.4689, val_wt_loss: 37.2855, train_grp_loss: [11.81469656 13.07509966 10.71323746], val_grp_loss: [12.68593946 12.45268449 12.14609427], train_hist_grp_loss: [ 6.48115504  7.14757189 14.73216256], cur_train_grp_loss: [0.09451679 0.10460026 0.21427128], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6629, max_kl_dist_index: 0, max_train_grp_loss:  13.0751, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6859, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2143, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:49:55,913 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  68, train_loss:  12.1563, val_loss:  12.4286, grad_norm: 0.0047, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6630, 0.3085, 0.6557, param: [5.45308984 8.26871112 5.19939798 8.66226652], weights: [0.30248308 0.30868469 0.38883223], train_wt_loss:  36.4689, val_wt_loss: 37.2858, train_grp_loss: [11.81479281 13.07517001 10.71291008], val_grp_loss: [12.68618818 12.45277266 12.14607694], train_hist_grp_loss: [ 6.57567261  7.25217269 14.94642731], cur_train_grp_loss: [0.09451757 0.1046008  0.21426475], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6630, max_kl_dist_index: 0, max_train_grp_loss:  13.0752, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6862, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2143, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:49:56,920 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  69, train_loss:  12.1563, val_loss:  12.4287, grad_norm: 0.0048, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6631, 0.3086, 0.6558, param: [5.45322537 8.26827486 5.20024461 8.66373304], weights: [0.30203225 0.30831786 0.38964989], train_wt_loss:  36.4690, val_wt_loss: 37.2861, train_grp_loss: [11.81488725 13.07524321 10.71258169], val_grp_loss: [12.6864354  12.45286408 12.14605895], train_hist_grp_loss: [ 6.67019095  7.35677405 15.16068552], cur_train_grp_loss: [0.09451834 0.10460136 0.2142582 ], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6631, max_kl_dist_index: 0, max_train_grp_loss:  13.0752, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6864, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2143, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:49:57,945 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  70, train_loss:  12.1563, val_loss:  12.4288, grad_norm: 0.0049, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6632, 0.3087, 0.6558, param: [5.45336023 8.26783967 5.2010924  8.66520495], weights: [0.30158126 0.30795063 0.39046811], train_wt_loss:  36.4690, val_wt_loss: 37.2865, train_grp_loss: [11.81497988 13.07531928 10.7122523 ], val_grp_loss: [12.68668114 12.45295876 12.14604031], train_hist_grp_loss: [ 6.76471005  7.46137599 15.37493715], cur_train_grp_loss: [0.0945191  0.10460195 0.21425163], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6632, max_kl_dist_index: 0, max_train_grp_loss:  13.0753, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6867, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2143, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:49:58,974 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  71, train_loss:  12.1563, val_loss:  12.4289, grad_norm: 0.0050, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6633, 0.3087, 0.6559, param: [5.45349443 8.26740555 5.20194136 8.66668226], weights: [0.30113012 0.30758299 0.39128689], train_wt_loss:  36.4690, val_wt_loss: 37.2868, train_grp_loss: [11.81507069 13.0753982  10.71192191], val_grp_loss: [12.68692539 12.45305669 12.14602101], train_hist_grp_loss: [ 6.85922989  7.56597855 15.5891822 ], cur_train_grp_loss: [0.09451984 0.10460255 0.21424505], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6633, max_kl_dist_index: 0, max_train_grp_loss:  13.0754, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6869, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2142, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:49:59,984 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  72, train_loss:  12.1564, val_loss:  12.4290, grad_norm: 0.0051, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6634, 0.3088, 0.6560, param: [5.45362795 8.26697251 5.2027915  8.66816496], weights: [0.30067883 0.30721494 0.39210623], train_wt_loss:  36.4691, val_wt_loss: 37.2871, train_grp_loss: [11.8151597  13.07547998 10.71159051], val_grp_loss: [12.68716816 12.45315788 12.14600106], train_hist_grp_loss: [ 6.95375045  7.67058173 15.80342063], cur_train_grp_loss: [0.09452057 0.10460319 0.21423844], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6634, max_kl_dist_index: 0, max_train_grp_loss:  13.0755, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6872, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2142, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:50:01,012 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  73, train_loss:  12.1564, val_loss:  12.4291, grad_norm: 0.0052, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6635, 0.3088, 0.6561, param: [5.4537608  8.26654052 5.20364281 8.66965308], weights: [0.3002274  0.30684649 0.39292612], train_wt_loss:  36.4691, val_wt_loss: 37.2874, train_grp_loss: [11.81524689 13.07556463 10.71125811], val_grp_loss: [12.68740944 12.45326233 12.14598046], train_hist_grp_loss: [ 7.04827173  7.77518557 16.01765244], cur_train_grp_loss: [0.09452128 0.10460384 0.21423181], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6635, max_kl_dist_index: 0, max_train_grp_loss:  13.0756, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6874, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2142, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:50:02,059 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  74, train_loss:  12.1564, val_loss:  12.4293, grad_norm: 0.0053, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6636, 0.3089, 0.6562, param: [5.45389298 8.26610961 5.2044953  8.6711466 ], weights: [0.29977581 0.30647764 0.39374655], train_wt_loss:  36.4692, val_wt_loss: 37.2878, train_grp_loss: [11.81533229 13.07565215 10.71092471], val_grp_loss: [12.68764925 12.45337004 12.1459592 ], train_hist_grp_loss: [ 7.14279371  7.87979009 16.23187761], cur_train_grp_loss: [0.09452198 0.10460452 0.21422516], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6636, max_kl_dist_index: 0, max_train_grp_loss:  13.0757, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6876, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2142, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:50:03,105 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  75, train_loss:  12.1564, val_loss:  12.4294, grad_norm: 0.0053, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6637, 0.3089, 0.6563, param: [5.45402448 8.26567975 5.20534897 8.67264555], weights: [0.29932409 0.30610839 0.39456752], train_wt_loss:  36.4692, val_wt_loss: 37.2881, train_grp_loss: [11.81541587 13.07574254 10.7105903 ], val_grp_loss: [12.68788757 12.45348103 12.1459373 ], train_hist_grp_loss: [ 7.23731637  7.98439531 16.4460961 ], cur_train_grp_loss: [0.09452266 0.10460522 0.21421849], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6637, max_kl_dist_index: 0, max_train_grp_loss:  13.0757, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6879, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2142, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:50:04,153 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  76, train_loss:  12.1564, val_loss:  12.4295, grad_norm: 0.0054, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6638, 0.3090, 0.6564, param: [5.45415531 8.26525095 5.20620382 8.67414991], weights: [0.29887222 0.30573875 0.39538903], train_wt_loss:  36.4693, val_wt_loss: 37.2884, train_grp_loss: [11.81549766 13.0758358  10.71025489], val_grp_loss: [12.68812441 12.45359527 12.14591475], train_hist_grp_loss: [ 7.33183969  8.08900125 16.66030791], cur_train_grp_loss: [0.09452333 0.10460594 0.21421181], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6638, max_kl_dist_index: 0, max_train_grp_loss:  13.0758, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6881, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2142, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:50:05,206 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  77, train_loss:  12.1564, val_loss:  12.4296, grad_norm: 0.0055, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6639, 0.3090, 0.6565, param: [5.45428546 8.2648232  5.20705986 8.67565971], weights: [0.29842021 0.30536871 0.39621108], train_wt_loss:  36.4693, val_wt_loss: 37.2887, train_grp_loss: [11.81557764 13.07593193 10.70991848], val_grp_loss: [12.68835977 12.4537128  12.14589155], train_hist_grp_loss: [ 7.42636367  8.19360793 16.874513  ], cur_train_grp_loss: [0.09452398 0.10460669 0.2142051 ], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6639, max_kl_dist_index: 0, max_train_grp_loss:  13.0759, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6884, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2142, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:50:06,272 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  78, train_loss:  12.1565, val_loss:  12.4297, grad_norm: 0.0056, live_grad: 0.0000, reward_err: 0.0105, 0.0142, 0.0002, KL_dist: 0.6640, 0.3091, 0.6566, param: [5.45441492 8.2643965  5.20791708 8.67717493], weights: [0.29796807 0.30499828 0.39703365], train_wt_loss:  36.4694, val_wt_loss: 37.2891, train_grp_loss: [11.81565583 13.07603094 10.70958107], val_grp_loss: [12.68859366 12.45383359 12.14586771], train_hist_grp_loss: [ 7.52088829  8.29821539 17.08871137], cur_train_grp_loss: [0.09452462 0.10460746 0.21419837], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6640, max_kl_dist_index: 0, max_train_grp_loss:  13.0760, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6886, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2142, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:50:07,304 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  79, train_loss:  12.1565, val_loss:  12.4298, grad_norm: 0.0057, live_grad: 0.0000, reward_err: 0.0105, 0.0142, 0.0002, KL_dist: 0.6641, 0.3092, 0.6567, param: [5.45454371 8.26397085 5.20877549 8.6786956 ], weights: [0.29751579 0.30462747 0.39785674], train_wt_loss:  36.4695, val_wt_loss: 37.2894, train_grp_loss: [11.81573221 13.07613283 10.70924265], val_grp_loss: [12.68882608 12.45395766 12.14584322], train_hist_grp_loss: [ 7.61541354  8.40282364 17.30290299], cur_train_grp_loss: [0.09452525 0.10460825 0.21419162], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6641, max_kl_dist_index: 0, max_train_grp_loss:  13.0761, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6888, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2142, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:50:08,325 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  80, train_loss:  12.1565, val_loss:  12.4299, grad_norm: 0.0058, live_grad: 0.0000, reward_err: 0.0105, 0.0142, 0.0002, KL_dist: 0.6642, 0.3092, 0.6568, param: [5.45467182 8.26354624 5.20963508 8.68022171], weights: [0.29706338 0.30425626 0.39868035], train_wt_loss:  36.4695, val_wt_loss: 37.2897, train_grp_loss: [11.8158068  13.0762376  10.70890324], val_grp_loss: [12.68905701 12.45408501 12.14581809], train_hist_grp_loss: [ 7.7099394   8.5074327  17.51708785], cur_train_grp_loss: [0.09452586 0.10460906 0.21418485], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6642, max_kl_dist_index: 0, max_train_grp_loss:  13.0762, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6891, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2142, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:50:09,353 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  81, train_loss:  12.1565, val_loss:  12.4300, grad_norm: 0.0059, live_grad: 0.0000, reward_err: 0.0105, 0.0142, 0.0002, KL_dist: 0.6643, 0.3093, 0.6569, param: [5.45479924 8.26312267 5.21049588 8.68175327], weights: [0.29661084 0.30388468 0.39950448], train_wt_loss:  36.4696, val_wt_loss: 37.2901, train_grp_loss: [11.8158796  13.07634525 10.70856282], val_grp_loss: [12.68928648 12.45421565 12.14579232], train_hist_grp_loss: [ 7.80446585  8.6120426  17.73126591], cur_train_grp_loss: [0.09452645 0.1046099  0.21417806], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6643, max_kl_dist_index: 0, max_train_grp_loss:  13.0763, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6893, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2142, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:50:10,396 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  82, train_loss:  12.1565, val_loss:  12.4301, grad_norm: 0.0060, live_grad: 0.0000, reward_err: 0.0105, 0.0139, 0.0002, KL_dist: 0.6644, 0.3093, 0.6570, param: [5.45492598 8.26270014 5.21135786 8.68329029], weights: [0.29615817 0.30351271 0.40032912], train_wt_loss:  36.4696, val_wt_loss: 37.2904, train_grp_loss: [11.8159506  13.07645579 10.70822141], val_grp_loss: [12.68951448 12.45434957 12.14576592], train_hist_grp_loss: [ 7.89899289  8.71665336 17.94543717], cur_train_grp_loss: [0.09452704 0.10461076 0.21417126], max_reward_err:  0.0139, max_reward_err_index: 1, max_kl_dist:  0.6644, max_kl_dist_index: 0, max_train_grp_loss:  13.0765, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6895, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2142, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:50:11,443 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  83, train_loss:  12.1566, val_loss:  12.4302, grad_norm: 0.0061, live_grad: 0.0000, reward_err: 0.0105, 0.0139, 0.0002, KL_dist: 0.6646, 0.3094, 0.6571, param: [5.45505203 8.26227864 5.21222104 8.68483276], weights: [0.29570538 0.30314036 0.40115426], train_wt_loss:  36.4697, val_wt_loss: 37.2907, train_grp_loss: [11.81601981 13.07656922 10.707879  ], val_grp_loss: [12.689741   12.45448678 12.14573887], train_hist_grp_loss: [ 7.9935205   8.82126501 18.1596016 ], cur_train_grp_loss: [0.0945276  0.10461165 0.21416443], max_reward_err:  0.0139, max_reward_err_index: 1, max_kl_dist:  0.6646, max_kl_dist_index: 0, max_train_grp_loss:  13.0766, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6897, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2142, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:50:12,461 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  84, train_loss:  12.1566, val_loss:  12.4304, grad_norm: 0.0061, live_grad: 0.0000, reward_err: 0.0105, 0.0139, 0.0002, KL_dist: 0.6647, 0.3094, 0.6572, param: [5.4551774  8.26185818 5.21308542 8.6863807 ], weights: [0.29525246 0.30276764 0.4019799 ], train_wt_loss:  36.4697, val_wt_loss: 37.2911, train_grp_loss: [11.81608724 13.07668554 10.70753559], val_grp_loss: [12.68996606 12.45462727 12.14571119], train_hist_grp_loss: [ 8.08804865  8.92587756 18.37375918], cur_train_grp_loss: [0.09452816 0.10461255 0.21415758], max_reward_err:  0.0139, max_reward_err_index: 1, max_kl_dist:  0.6647, max_kl_dist_index: 0, max_train_grp_loss:  13.0767, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6900, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2142, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:50:13,510 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  85, train_loss:  12.1566, val_loss:  12.4305, grad_norm: 0.0062, live_grad: 0.0000, reward_err: 0.0105, 0.0139, 0.0002, KL_dist: 0.6648, 0.3095, 0.6573, param: [5.45530207 8.26143874 5.213951   8.68793412], weights: [0.29479942 0.30239454 0.40280604], train_wt_loss:  36.4698, val_wt_loss: 37.2914, train_grp_loss: [11.81615287 13.07680475 10.70719118], val_grp_loss: [12.69018966 12.45477106 12.14568288], train_hist_grp_loss: [ 8.18257735  9.03049105 18.58790989], cur_train_grp_loss: [0.0945287  0.10461348 0.21415071], max_reward_err:  0.0139, max_reward_err_index: 1, max_kl_dist:  0.6648, max_kl_dist_index: 0, max_train_grp_loss:  13.0768, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6902, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2142, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:50:14,581 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  86, train_loss:  12.1566, val_loss:  12.4306, grad_norm: 0.0063, live_grad: 0.0000, reward_err: 0.0105, 0.0139, 0.0002, KL_dist: 0.6649, 0.3096, 0.6575, param: [5.45542606 8.26102033 5.21481778 8.689493  ], weights: [0.29434626 0.30202107 0.40363267], train_wt_loss:  36.4699, val_wt_loss: 37.2918, train_grp_loss: [11.81621673 13.07692685 10.70684577], val_grp_loss: [12.69041178 12.45491815 12.14565393], train_hist_grp_loss: [ 8.27710657  9.13510548 18.80205371], cur_train_grp_loss: [0.09452922 0.10461444 0.21414382], max_reward_err:  0.0139, max_reward_err_index: 1, max_kl_dist:  0.6649, max_kl_dist_index: 0, max_train_grp_loss:  13.0769, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6904, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2141, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:50:15,612 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  87, train_loss:  12.1566, val_loss:  12.4307, grad_norm: 0.0064, live_grad: 0.0000, reward_err: 0.0105, 0.0139, 0.0002, KL_dist: 0.6650, 0.3096, 0.6576, param: [5.45554935 8.26060293 5.21568577 8.69105737], weights: [0.29389298 0.30164723 0.40445979], train_wt_loss:  36.4699, val_wt_loss: 37.2921, train_grp_loss: [11.81627879 13.07705186 10.70649936], val_grp_loss: [12.69063245 12.45506853 12.14562436], train_hist_grp_loss: [ 8.37163631  9.2397209  19.01619063], cur_train_grp_loss: [0.09452973 0.10461541 0.21413692], max_reward_err:  0.0139, max_reward_err_index: 1, max_kl_dist:  0.6650, max_kl_dist_index: 0, max_train_grp_loss:  13.0771, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6906, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2141, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:50:16,644 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  88, train_loss:  12.1567, val_loss:  12.4308, grad_norm: 0.0065, live_grad: 0.0000, reward_err: 0.0105, 0.0139, 0.0002, KL_dist: 0.6651, 0.3097, 0.6577, param: [5.45567195 8.26018656 5.21655496 8.69262722], weights: [0.29343959 0.30127302 0.40528739], train_wt_loss:  36.4700, val_wt_loss: 37.2924, train_grp_loss: [11.81633908 13.07717976 10.70615196], val_grp_loss: [12.69085165 12.45522222 12.14559415], train_hist_grp_loss: [ 8.46616654  9.34433731 19.23032061], cur_train_grp_loss: [0.09453023 0.10461641 0.21412999], max_reward_err:  0.0139, max_reward_err_index: 1, max_kl_dist:  0.6651, max_kl_dist_index: 0, max_train_grp_loss:  13.0772, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6909, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2141, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:50:17,686 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  89, train_loss:  12.1567, val_loss:  12.4309, grad_norm: 0.0066, live_grad: 0.0000, reward_err: 0.0105, 0.0139, 0.0002, KL_dist: 0.6652, 0.3097, 0.6578, param: [5.45579385 8.2597712  5.21742536 8.69420257], weights: [0.29298609 0.30089845 0.40611546], train_wt_loss:  36.4700, val_wt_loss: 37.2928, train_grp_loss: [11.81639759 13.07731056 10.70580357], val_grp_loss: [12.69106939 12.45537921 12.14556332], train_hist_grp_loss: [ 8.56069725  9.44895475 19.44444365], cur_train_grp_loss: [0.09453071 0.10461744 0.21412304], max_reward_err:  0.0139, max_reward_err_index: 1, max_kl_dist:  0.6652, max_kl_dist_index: 0, max_train_grp_loss:  13.0773, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6911, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2141, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:50:18,692 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  90, train_loss:  12.1567, val_loss:  12.4310, grad_norm: 0.0067, live_grad: 0.0000, reward_err: 0.0105, 0.0139, 0.0002, KL_dist: 0.6653, 0.3098, 0.6579, param: [5.45591506 8.25935684 5.21829697 8.69578341], weights: [0.29253247 0.30052352 0.40694401], train_wt_loss:  36.4701, val_wt_loss: 37.2931, train_grp_loss: [11.81645432 13.07744426 10.70545417], val_grp_loss: [12.69128568 12.4555395  12.14553186], train_hist_grp_loss: [ 8.65522843  9.55357324 19.65855973], cur_train_grp_loss: [0.09453118 0.10461848 0.21411607], max_reward_err:  0.0139, max_reward_err_index: 1, max_kl_dist:  0.6653, max_kl_dist_index: 0, max_train_grp_loss:  13.0774, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6913, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2141, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:50:19,722 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  91, train_loss:  12.1567, val_loss:  12.4312, grad_norm: 0.0068, live_grad: 0.0000, reward_err: 0.0105, 0.0139, 0.0002, KL_dist: 0.6654, 0.3099, 0.6580, param: [5.45603557 8.2589435  5.2191698  8.69736975], weights: [0.29207875 0.30014822 0.40777303], train_wt_loss:  36.4702, val_wt_loss: 37.2935, train_grp_loss: [11.81650927 13.07758088 10.70510379], val_grp_loss: [12.6915005  12.45570311 12.14549978], train_hist_grp_loss: [ 8.74976007  9.65819279 19.87266881], cur_train_grp_loss: [0.09453163 0.10461955 0.21410908], max_reward_err:  0.0139, max_reward_err_index: 1, max_kl_dist:  0.6654, max_kl_dist_index: 0, max_train_grp_loss:  13.0776, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6915, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2141, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:50:20,767 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  92, train_loss:  12.1567, val_loss:  12.4313, grad_norm: 0.0069, live_grad: 0.0000, reward_err: 0.0105, 0.0139, 0.0002, KL_dist: 0.6655, 0.3099, 0.6581, param: [5.45615538 8.25853116 5.22004384 8.6989616 ], weights: [0.29162492 0.29977257 0.40860251], train_wt_loss:  36.4702, val_wt_loss: 37.2938, train_grp_loss: [11.81656246 13.0777204  10.70475241], val_grp_loss: [12.69171387 12.45587002 12.14546708], train_hist_grp_loss: [ 8.84429214  9.76281344 20.08677088], cur_train_grp_loss: [0.09453207 0.10462065 0.21410208], max_reward_err:  0.0139, max_reward_err_index: 1, max_kl_dist:  0.6655, max_kl_dist_index: 0, max_train_grp_loss:  13.0777, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6917, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2141, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:50:21,789 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  93, train_loss:  12.1568, val_loss:  12.4314, grad_norm: 0.0070, live_grad: 0.0000, reward_err: 0.0105, 0.0139, 0.0002, KL_dist: 0.6656, 0.3100, 0.6582, param: [5.45627448 8.25811982 5.22091909 8.70055896], weights: [0.29117099 0.29939657 0.40943245], train_wt_loss:  36.4703, val_wt_loss: 37.2942, train_grp_loss: [11.81661387 13.07786283 10.70440003], val_grp_loss: [12.69192579 12.45604025 12.14543376], train_hist_grp_loss: [ 8.93882464  9.8674352  20.30086593], cur_train_grp_loss: [0.0945325  0.10462176 0.21409505], max_reward_err:  0.0139, max_reward_err_index: 1, max_kl_dist:  0.6656, max_kl_dist_index: 0, max_train_grp_loss:  13.0779, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6919, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2141, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:50:22,848 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  94, train_loss:  12.1568, val_loss:  12.4315, grad_norm: 0.0071, live_grad: 0.0000, reward_err: 0.0105, 0.0139, 0.0002, KL_dist: 0.6657, 0.3100, 0.6583, param: [5.45639289 8.25770948 5.22179556 8.70216184], weights: [0.29071696 0.29902021 0.41026284], train_wt_loss:  36.4704, val_wt_loss: 37.2945, train_grp_loss: [11.81666351 13.07800817 10.70404666], val_grp_loss: [12.69213626 12.4562138  12.14539982], train_hist_grp_loss: [ 9.03335755  9.9720581  20.51495393], cur_train_grp_loss: [0.09453291 0.1046229  0.214088  ], max_reward_err:  0.0139, max_reward_err_index: 1, max_kl_dist:  0.6657, max_kl_dist_index: 0, max_train_grp_loss:  13.0780, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6921, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2141, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:50:23,882 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  95, train_loss:  12.1568, val_loss:  12.4316, grad_norm: 0.0072, live_grad: 0.0000, reward_err: 0.0105, 0.0139, 0.0002, KL_dist: 0.6659, 0.3101, 0.6584, param: [5.45651059 8.25730013 5.22267326 8.70377024], weights: [0.29026282 0.2986435  0.41109368], train_wt_loss:  36.4704, val_wt_loss: 37.2949, train_grp_loss: [11.81671138 13.07815643 10.7036923 ], val_grp_loss: [12.69234527 12.45639066 12.14536526], train_hist_grp_loss: [ 9.12789086 10.07668217 20.72903487], cur_train_grp_loss: [0.09453331 0.10462407 0.21408093], max_reward_err:  0.0139, max_reward_err_index: 1, max_kl_dist:  0.6659, max_kl_dist_index: 0, max_train_grp_loss:  13.0782, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6923, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2141, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:50:24,904 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  96, train_loss:  12.1568, val_loss:  12.4317, grad_norm: 0.0073, live_grad: 0.0000, reward_err: 0.0105, 0.0139, 0.0002, KL_dist: 0.6660, 0.3102, 0.6585, param: [5.45662759 8.25689177 5.22355217 8.70538416], weights: [0.2898086  0.29826644 0.41192497], train_wt_loss:  36.4705, val_wt_loss: 37.2952, train_grp_loss: [11.81675749 13.0783076  10.70333695], val_grp_loss: [12.69255283 12.45657085 12.14533008], train_hist_grp_loss: [ 9.22242455 10.18130742 20.94310871], cur_train_grp_loss: [0.09453369 0.10462525 0.21407385], max_reward_err:  0.0139, max_reward_err_index: 1, max_kl_dist:  0.6660, max_kl_dist_index: 0, max_train_grp_loss:  13.0783, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6926, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2141, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:50:25,903 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  97, train_loss:  12.1569, val_loss:  12.4319, grad_norm: 0.0074, live_grad: 0.0000, reward_err: 0.0105, 0.0139, 0.0002, KL_dist: 0.6661, 0.3102, 0.6586, param: [5.45674388 8.2564844  5.22443231 8.70700361], weights: [0.28935427 0.29788903 0.41275669], train_wt_loss:  36.4706, val_wt_loss: 37.2956, train_grp_loss: [11.81680184 13.0784617  10.70298061], val_grp_loss: [12.69275895 12.45675436 12.1452943 ], train_hist_grp_loss: [ 9.31695861 10.28593388 21.15717545], cur_train_grp_loss: [0.09453406 0.10462646 0.21406674], max_reward_err:  0.0139, max_reward_err_index: 1, max_kl_dist:  0.6661, max_kl_dist_index: 0, max_train_grp_loss:  13.0785, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6928, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2141, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:50:26,934 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  98, train_loss:  12.1569, val_loss:  12.4320, grad_norm: 0.0075, live_grad: 0.0000, reward_err: 0.0105, 0.0139, 0.0002, KL_dist: 0.6662, 0.3103, 0.6587, param: [5.45685946 8.25607801 5.22531368 8.7086286 ], weights: [0.28889986 0.29751129 0.41358885], train_wt_loss:  36.4706, val_wt_loss: 37.2959, train_grp_loss: [11.81684442 13.07861871 10.70262328], val_grp_loss: [12.69296362 12.4569412  12.1452579 ], train_hist_grp_loss: [ 9.41149303 10.39056157 21.37123506], cur_train_grp_loss: [0.09453441 0.10462769 0.21405961], max_reward_err:  0.0139, max_reward_err_index: 1, max_kl_dist:  0.6662, max_kl_dist_index: 0, max_train_grp_loss:  13.0786, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6930, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2141, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:50:27,968 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  99, train_loss:  12.1569, val_loss:  12.4321, grad_norm: 0.0076, live_grad: 0.0000, reward_err: 0.0105, 0.0139, 0.0002, KL_dist: 0.6663, 0.3103, 0.6588, param: [5.45697433 8.2556726  5.22619627 8.71025913], weights: [0.28844535 0.2971332  0.41442145], train_wt_loss:  36.4707, val_wt_loss: 37.2963, train_grp_loss: [11.81688525 13.07877865 10.70226496], val_grp_loss: [12.69316685 12.45713136 12.14522089], train_hist_grp_loss: [ 9.50602778 10.49519052 21.58528753], cur_train_grp_loss: [0.09453476 0.10462895 0.21405247], max_reward_err:  0.0139, max_reward_err_index: 1, max_kl_dist:  0.6663, max_kl_dist_index: 0, max_train_grp_loss:  13.0788, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6932, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2141, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:50:29,025 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  100, train_loss:  12.1569, val_loss:  12.4322, grad_norm: 0.0077, live_grad: 0.0000, reward_err: 0.0105, 0.0139, 0.0002, KL_dist: 0.6664, 0.3104, 0.6589, param: [5.45708849 8.25526816 5.22708009 8.71189521], weights: [0.28799076 0.29675478 0.41525446], train_wt_loss:  36.4708, val_wt_loss: 37.2967, train_grp_loss: [11.81692432 13.07894152 10.70190565], val_grp_loss: [12.69336864 12.45732486 12.14518327], train_hist_grp_loss: [ 9.60056286 10.59982075 21.79933283], cur_train_grp_loss: [0.09453508 0.10463023 0.2140453 ], max_reward_err:  0.0139, max_reward_err_index: 1, max_kl_dist:  0.6664, max_kl_dist_index: 0, max_train_grp_loss:  13.0789, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6934, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2140, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:50:30,065 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  101, train_loss:  12.1570, val_loss:  12.4323, grad_norm: 0.0078, live_grad: 0.0000, reward_err: 0.0105, 0.0139, 0.0002, KL_dist: 0.6665, 0.3105, 0.6591, param: [5.45720194 8.2548647  5.22796515 8.71353684], weights: [0.28753608 0.29637602 0.4160879 ], train_wt_loss:  36.4709, val_wt_loss: 37.2970, train_grp_loss: [11.81696164 13.07910731 10.70154535], val_grp_loss: [12.69356898 12.4575217  12.14514505], train_hist_grp_loss: [ 9.69509826 10.70445228 22.01337094], cur_train_grp_loss: [0.09453539 0.10463153 0.21403811], max_reward_err:  0.0139, max_reward_err_index: 1, max_kl_dist:  0.6665, max_kl_dist_index: 0, max_train_grp_loss:  13.0791, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6936, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2140, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:50:31,101 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  102, train_loss:  12.1570, val_loss:  12.4325, grad_norm: 0.0078, live_grad: 0.0000, reward_err: 0.0105, 0.0139, 0.0002, KL_dist: 0.6666, 0.3105, 0.6592, param: [5.45731467 8.25446221 5.22885143 8.71518402], weights: [0.28708132 0.29599692 0.41692175], train_wt_loss:  36.4709, val_wt_loss: 37.2974, train_grp_loss: [11.8169972  13.07927603 10.70118407], val_grp_loss: [12.69376789 12.45772187 12.14510623], train_hist_grp_loss: [ 9.78963395 10.80908514 22.22740185], cur_train_grp_loss: [0.09453569 0.10463286 0.21403091], max_reward_err:  0.0139, max_reward_err_index: 1, max_kl_dist:  0.6666, max_kl_dist_index: 0, max_train_grp_loss:  13.0793, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6938, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2140, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:50:32,133 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  103, train_loss:  12.1570, val_loss:  12.4326, grad_norm: 0.0079, live_grad: 0.0000, reward_err: 0.0105, 0.0139, 0.0002, KL_dist: 0.6668, 0.3106, 0.6593, param: [5.45742668 8.25406068 5.22973896 8.71683676], weights: [0.28662648 0.2956175  0.41775602], train_wt_loss:  36.4710, val_wt_loss: 37.2977, train_grp_loss: [11.81703101 13.07944768 10.70082179], val_grp_loss: [12.69396536 12.45792538 12.1450668 ], train_hist_grp_loss: [ 9.88416993 10.91371935 22.44142553], cur_train_grp_loss: [0.09453598 0.10463421 0.21402368], max_reward_err:  0.0139, max_reward_err_index: 1, max_kl_dist:  0.6668, max_kl_dist_index: 0, max_train_grp_loss:  13.0794, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6940, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2140, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:50:33,137 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  104, train_loss:  12.1570, val_loss:  12.4327, grad_norm: 0.0080, live_grad: 0.0000, reward_err: 0.0105, 0.0139, 0.0002, KL_dist: 0.6669, 0.3107, 0.6594, param: [5.45753798 8.25366011 5.23062771 8.71849506], weights: [0.28617156 0.29523775 0.41859069], train_wt_loss:  36.4711, val_wt_loss: 37.2981, train_grp_loss: [11.81706308 13.07962227 10.70045854], val_grp_loss: [12.69416139 12.45813223 12.14502677], train_hist_grp_loss: [ 9.97870618 11.01835493 22.65544197], cur_train_grp_loss: [0.09453625 0.10463558 0.21401644], max_reward_err:  0.0139, max_reward_err_index: 1, max_kl_dist:  0.6669, max_kl_dist_index: 0, max_train_grp_loss:  13.0796, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6942, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2140, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:50:34,182 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  105, train_loss:  12.1571, val_loss:  12.4328, grad_norm: 0.0081, live_grad: 0.0000, reward_err: 0.0105, 0.0139, 0.0002, KL_dist: 0.6670, 0.3107, 0.6595, param: [5.45764856 8.2532605  5.23151771 8.72015893], weights: [0.28571657 0.29485767 0.41942576], train_wt_loss:  36.4712, val_wt_loss: 37.2985, train_grp_loss: [11.8170934 13.0797998 10.7000943], val_grp_loss: [12.69435599 12.45834243 12.14498614], train_hist_grp_loss: [10.07324268 11.12299191 22.86945114], cur_train_grp_loss: [0.0945365  0.10463698 0.21400917], max_reward_err:  0.0139, max_reward_err_index: 1, max_kl_dist:  0.6670, max_kl_dist_index: 0, max_train_grp_loss:  13.0798, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6944, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2140, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:50:35,208 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  106, train_loss:  12.1571, val_loss:  12.4329, grad_norm: 0.0083, live_grad: 0.0000, reward_err: 0.0105, 0.0139, 0.0002, KL_dist: 0.6671, 0.3108, 0.6596, param: [5.45775842 8.25286185 5.23240895 8.72182838], weights: [0.2852615  0.29447727 0.42026123], train_wt_loss:  36.4712, val_wt_loss: 37.2988, train_grp_loss: [11.81712198 13.07998026 10.69972907], val_grp_loss: [12.69454916 12.45855597 12.14494492], train_hist_grp_loss: [10.16777943 11.22763031 23.08345302], cur_train_grp_loss: [0.09453675 0.1046384  0.21400189], max_reward_err:  0.0139, max_reward_err_index: 1, max_kl_dist:  0.6671, max_kl_dist_index: 0, max_train_grp_loss:  13.0800, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6945, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2140, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:50:36,224 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  107, train_loss:  12.1571, val_loss:  12.4331, grad_norm: 0.0084, live_grad: 0.0000, reward_err: 0.0105, 0.0139, 0.0002, KL_dist: 0.6672, 0.3108, 0.6597, param: [5.45786756 8.25246415 5.23330143 8.7235034 ], weights: [0.28480636 0.29409655 0.42109709], train_wt_loss:  36.4713, val_wt_loss: 37.2992, train_grp_loss: [11.81714881 13.08016366 10.69936286], val_grp_loss: [12.6947409  12.45877286 12.1449031 ], train_hist_grp_loss: [10.2623164  11.33227015 23.2974476 ], cur_train_grp_loss: [0.09453698 0.10463984 0.21399458], max_reward_err:  0.0139, max_reward_err_index: 1, max_kl_dist:  0.6672, max_kl_dist_index: 0, max_train_grp_loss:  13.0802, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6947, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2140, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:50:37,257 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  108, train_loss:  12.1571, val_loss:  12.4332, grad_norm: 0.0085, live_grad: 0.0000, reward_err: 0.0105, 0.0139, 0.0002, KL_dist: 0.6673, 0.3109, 0.6598, param: [5.45797597 8.25206739 5.23419516 8.725184  ], weights: [0.28435115 0.29371551 0.42193334], train_wt_loss:  36.4714, val_wt_loss: 37.2996, train_grp_loss: [11.81717391 13.08035001 10.69899567], val_grp_loss: [12.69493121 12.45899311 12.14486069], train_hist_grp_loss: [10.35685359 11.43691146 23.51143486], cur_train_grp_loss: [0.09453719 0.10464131 0.21398726], max_reward_err:  0.0139, max_reward_err_index: 1, max_kl_dist:  0.6673, max_kl_dist_index: 0, max_train_grp_loss:  13.0804, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6949, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2140, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:50:38,290 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  109, train_loss:  12.1572, val_loss:  12.4333, grad_norm: 0.0086, live_grad: 0.0000, reward_err: 0.0105, 0.0139, 0.0002, KL_dist: 0.6675, 0.3110, 0.6599, param: [5.45808366 8.25167158 5.23509013 8.7268702 ], weights: [0.28389587 0.29333415 0.42276997], train_wt_loss:  36.4715, val_wt_loss: 37.2999, train_grp_loss: [11.81719727 13.0805393  10.6986275 ], val_grp_loss: [12.69512009 12.45921671 12.14481769], train_hist_grp_loss: [10.45139099 11.54155426 23.72541477], cur_train_grp_loss: [0.09453739 0.1046428  0.21397991], max_reward_err:  0.0139, max_reward_err_index: 1, max_kl_dist:  0.6675, max_kl_dist_index: 0, max_train_grp_loss:  13.0805, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6951, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2140, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:50:39,316 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  110, train_loss:  12.1572, val_loss:  12.4334, grad_norm: 0.0087, live_grad: 0.0000, reward_err: 0.0105, 0.0139, 0.0002, KL_dist: 0.6676, 0.3110, 0.6601, param: [5.45819062 8.2512767  5.23598635 8.72856198], weights: [0.28344053 0.29295249 0.42360698], train_wt_loss:  36.4716, val_wt_loss: 37.3003, train_grp_loss: [11.8172189  13.08073153 10.69825835], val_grp_loss: [12.69530755 12.45944367 12.1447741 ], train_hist_grp_loss: [10.54592856 11.64619858 23.93938732], cur_train_grp_loss: [0.09453758 0.10464431 0.21397255], max_reward_err:  0.0139, max_reward_err_index: 1, max_kl_dist:  0.6676, max_kl_dist_index: 0, max_train_grp_loss:  13.0807, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6953, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2140, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:50:40,345 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  111, train_loss:  12.1572, val_loss:  12.4336, grad_norm: 0.0088, live_grad: 0.0000, reward_err: 0.0105, 0.0139, 0.0002, KL_dist: 0.6677, 0.3111, 0.6602, param: [5.45829686 8.25088276 5.23688381 8.73025936], weights: [0.28298513 0.29257051 0.42444436], train_wt_loss:  36.4717, val_wt_loss: 37.3007, train_grp_loss: [11.8172388  13.08092672 10.69788822], val_grp_loss: [12.69549358 12.45967398 12.14472992], train_hist_grp_loss: [10.64046631 11.75084443 24.15335249], cur_train_grp_loss: [0.09453775 0.10464585 0.21396517], max_reward_err:  0.0139, max_reward_err_index: 1, max_kl_dist:  0.6677, max_kl_dist_index: 0, max_train_grp_loss:  13.0809, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6955, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2140, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:50:41,379 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  112, train_loss:  12.1572, val_loss:  12.4337, grad_norm: 0.0089, live_grad: 0.0000, reward_err: 0.0105, 0.0139, 0.0002, KL_dist: 0.6678, 0.3112, 0.6603, param: [5.45840236 8.25048975 5.23778253 8.73196234], weights: [0.28252967 0.29218822 0.42528211], train_wt_loss:  36.4717, val_wt_loss: 37.3011, train_grp_loss: [11.81725697 13.08112486 10.69751711], val_grp_loss: [12.6956782  12.45990766 12.14468516], train_hist_grp_loss: [10.73500423 11.85549184 24.36731026], cur_train_grp_loss: [0.09453791 0.10464741 0.21395776], max_reward_err:  0.0139, max_reward_err_index: 1, max_kl_dist:  0.6678, max_kl_dist_index: 0, max_train_grp_loss:  13.0811, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6957, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2140, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:50:42,404 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  113, train_loss:  12.1573, val_loss:  12.4338, grad_norm: 0.0090, live_grad: 0.0000, reward_err: 0.0105, 0.0139, 0.0002, KL_dist: 0.6679, 0.3112, 0.6604, param: [5.45850713 8.25009768 5.23868251 8.73367092], weights: [0.28207415 0.29180563 0.42612022], train_wt_loss:  36.4718, val_wt_loss: 37.3014, train_grp_loss: [11.81727341 13.08132595 10.69714502], val_grp_loss: [12.6958614  12.4601447  12.14463981], train_hist_grp_loss: [10.82954228 11.96014084 24.5812606 ], cur_train_grp_loss: [0.09453806 0.104649   0.21395034], max_reward_err:  0.0139, max_reward_err_index: 1, max_kl_dist:  0.6679, max_kl_dist_index: 0, max_train_grp_loss:  13.0813, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6959, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2140, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:50:43,439 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  114, train_loss:  12.1573, val_loss:  12.4339, grad_norm: 0.0091, live_grad: 0.0000, reward_err: 0.0105, 0.0139, 0.0002, KL_dist: 0.6680, 0.3113, 0.6605, param: [5.45861117 8.24970652 5.23958373 8.73538512], weights: [0.28161857 0.29142273 0.42695869], train_wt_loss:  36.4719, val_wt_loss: 37.3018, train_grp_loss: [11.81728813 13.08152999 10.69677196], val_grp_loss: [12.69604318 12.46038511 12.14459389], train_hist_grp_loss: [10.92408047 12.06479145 24.7952035 ], cur_train_grp_loss: [0.09453819 0.10465061 0.2139429 ], max_reward_err:  0.0139, max_reward_err_index: 1, max_kl_dist:  0.6680, max_kl_dist_index: 0, max_train_grp_loss:  13.0815, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6960, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2139, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:50:44,517 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  115, train_loss:  12.1573, val_loss:  12.4341, grad_norm: 0.0092, live_grad: 0.0000, reward_err: 0.0105, 0.0139, 0.0002, KL_dist: 0.6682, 0.3114, 0.6606, param: [5.45871448 8.24931629 5.24048621 8.73710492], weights: [0.28116295 0.29103954 0.42779751], train_wt_loss:  36.4720, val_wt_loss: 37.3022, train_grp_loss: [11.81730113 13.08173699 10.69639792], val_grp_loss: [12.69622354 12.46062889 12.14454738], train_hist_grp_loss: [11.01861877 12.16944369 25.00913894], cur_train_grp_loss: [0.09453831 0.10465224 0.21393544], max_reward_err:  0.0139, max_reward_err_index: 1, max_kl_dist:  0.6682, max_kl_dist_index: 0, max_train_grp_loss:  13.0817, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6962, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2139, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:50:45,555 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  116, train_loss:  12.1574, val_loss:  12.4342, grad_norm: 0.0093, live_grad: 0.0000, reward_err: 0.0105, 0.0139, 0.0002, KL_dist: 0.6683, 0.3114, 0.6607, param: [5.45881705 8.24892697 5.24138995 8.73883034], weights: [0.28070727 0.29065605 0.42863669], train_wt_loss:  36.4721, val_wt_loss: 37.3026, train_grp_loss: [11.81731241 13.08194695 10.6960229 ], val_grp_loss: [12.69640249 12.46087604 12.1445003 ], train_hist_grp_loss: [11.11315718 12.27409758 25.2230669 ], cur_train_grp_loss: [0.09453841 0.1046539  0.21392796], max_reward_err:  0.0139, max_reward_err_index: 1, max_kl_dist:  0.6683, max_kl_dist_index: 0, max_train_grp_loss:  13.0819, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6964, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2139, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:50:46,586 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  117, train_loss:  12.1574, val_loss:  12.4343, grad_norm: 0.0094, live_grad: 0.0000, reward_err: 0.0105, 0.0139, 0.0002, KL_dist: 0.6684, 0.3115, 0.6609, param: [5.45891888 8.24853857 5.24229495 8.74056139], weights: [0.28025154 0.29027226 0.4294762 ], train_wt_loss:  36.4722, val_wt_loss: 37.3029, train_grp_loss: [11.81732197 13.08215987 10.69564691], val_grp_loss: [12.69658003 12.46112657 12.14445264], train_hist_grp_loss: [11.20769568 12.37875316 25.43698735], cur_train_grp_loss: [0.0945385  0.10465558 0.21392046], max_reward_err:  0.0139, max_reward_err_index: 1, max_kl_dist:  0.6684, max_kl_dist_index: 0, max_train_grp_loss:  13.0822, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6966, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2139, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:50:47,569 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  118, train_loss:  12.1574, val_loss:  12.4344, grad_norm: 0.0095, live_grad: 0.0000, reward_err: 0.0105, 0.0139, 0.0002, KL_dist: 0.6685, 0.3115, 0.6610, param: [5.45901998 8.24815107 5.24320121 8.74229806], weights: [0.27979577 0.28988817 0.43031605], train_wt_loss:  36.4723, val_wt_loss: 37.3033, train_grp_loss: [11.81732982 13.08237576 10.69526995], val_grp_loss: [12.69675617 12.46138047 12.14440442], train_hist_grp_loss: [11.30223426 12.48341044 25.65090029], cur_train_grp_loss: [0.09453858 0.10465728 0.21391294], max_reward_err:  0.0139, max_reward_err_index: 1, max_kl_dist:  0.6685, max_kl_dist_index: 0, max_train_grp_loss:  13.0824, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6968, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2139, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:50:48,600 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  119, train_loss:  12.1575, val_loss:  12.4346, grad_norm: 0.0096, live_grad: 0.0000, reward_err: 0.0105, 0.0139, 0.0002, KL_dist: 0.6686, 0.3116, 0.6611, param: [5.45912033 8.24776448 5.24410874 8.74404036], weights: [0.27933996 0.2895038  0.43115624], train_wt_loss:  36.4724, val_wt_loss: 37.3037, train_grp_loss: [11.81733596 13.0825946  10.69489202], val_grp_loss: [12.69693089 12.46163775 12.14435562], train_hist_grp_loss: [11.3967729  12.58806944 25.86480569], cur_train_grp_loss: [0.09453864 0.10465901 0.2139054 ], max_reward_err:  0.0139, max_reward_err_index: 1, max_kl_dist:  0.6686, max_kl_dist_index: 0, max_train_grp_loss:  13.0826, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6969, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2139, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:50:49,649 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  120, train_loss:  12.1575, val_loss:  12.4347, grad_norm: 0.0097, live_grad: 0.0000, reward_err: 0.0105, 0.0139, 0.0002, KL_dist: 0.6688, 0.3117, 0.6612, param: [5.45921994 8.24737879 5.24501752 8.7457883 ], weights: [0.27888411 0.28911914 0.43199675], train_wt_loss:  36.4725, val_wt_loss: 37.3041, train_grp_loss: [11.81734039 13.08281642 10.69451312], val_grp_loss: [12.69710421 12.46189841 12.14430625], train_hist_grp_loss: [11.49131158 12.6927302  26.07870353], cur_train_grp_loss: [0.09453869 0.10466076 0.21389784], max_reward_err:  0.0139, max_reward_err_index: 1, max_kl_dist:  0.6688, max_kl_dist_index: 0, max_train_grp_loss:  13.0828, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6971, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2139, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:50:50,677 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  121, train_loss:  12.1575, val_loss:  12.4348, grad_norm: 0.0098, live_grad: 0.0000, reward_err: 0.0105, 0.0143, 0.0002, KL_dist: 0.6689, 0.3117, 0.6613, param: [5.45931881 8.246994   5.24592758 8.74754187], weights: [0.27842821 0.2887342  0.43283759], train_wt_loss:  36.4725, val_wt_loss: 37.3045, train_grp_loss: [11.81734311 13.0830412  10.69413324], val_grp_loss: [12.69727613 12.46216245 12.14425632], train_hist_grp_loss: [11.58585031 12.79739273 26.29259379], cur_train_grp_loss: [0.09453872 0.10466253 0.21389026], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6689, max_kl_dist_index: 0, max_train_grp_loss:  13.0830, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6973, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2139, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:50:51,717 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  122, train_loss:  12.1575, val_loss:  12.4350, grad_norm: 0.0099, live_grad: 0.0000, reward_err: 0.0105, 0.0143, 0.0002, KL_dist: 0.6690, 0.3118, 0.6615, param: [5.45941693 8.2466101  5.2468389  8.74930108], weights: [0.27797228 0.28834897 0.43367874], train_wt_loss:  36.4726, val_wt_loss: 37.3049, train_grp_loss: [11.81734414 13.08326896 10.6937524 ], val_grp_loss: [12.69744664 12.46242988 12.14420582], train_hist_grp_loss: [11.68038905 12.90205706 26.50647646], cur_train_grp_loss: [0.09453874 0.10466433 0.21388266], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6690, max_kl_dist_index: 0, max_train_grp_loss:  13.0833, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6974, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2139, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:50:52,729 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  123, train_loss:  12.1576, val_loss:  12.4351, grad_norm: 0.0100, live_grad: 0.0000, reward_err: 0.0105, 0.0143, 0.0002, KL_dist: 0.6691, 0.3119, 0.6616, param: [5.45951431 8.24622709 5.24775149 8.75106595], weights: [0.27751632 0.28796346 0.43452021], train_wt_loss:  36.4727, val_wt_loss: 37.3053, train_grp_loss: [11.81734346 13.08349969 10.6933706 ], val_grp_loss: [12.69761576 12.4627007  12.14415476], train_hist_grp_loss: [11.7749278  13.00672321 26.72035151], cur_train_grp_loss: [0.09453875 0.10466615 0.21387505], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6691, max_kl_dist_index: 0, max_train_grp_loss:  13.0835, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6976, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2139, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:50:53,752 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  124, train_loss:  12.1576, val_loss:  12.4352, grad_norm: 0.0102, live_grad: 0.0000, reward_err: 0.0105, 0.0143, 0.0002, KL_dist: 0.6692, 0.3119, 0.6617, param: [5.45961093 8.24584496 5.24866535 8.75283646], weights: [0.27706033 0.28757768 0.43536199], train_wt_loss:  36.4728, val_wt_loss: 37.3057, train_grp_loss: [11.81734108 13.08373339 10.69298782], val_grp_loss: [12.69778348 12.46297491 12.14410314], train_hist_grp_loss: [11.86946655 13.11139121 26.93421892], cur_train_grp_loss: [0.09453875 0.104668   0.21386741], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6692, max_kl_dist_index: 0, max_train_grp_loss:  13.0837, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6978, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2139, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:50:54,780 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  125, train_loss:  12.1576, val_loss:  12.4353, grad_norm: 0.0103, live_grad: 0.0000, reward_err: 0.0105, 0.0143, 0.0002, KL_dist: 0.6694, 0.3120, 0.6618, param: [5.45970681 8.24546372 5.24958048 8.75461262], weights: [0.27660431 0.28719162 0.43620407], train_wt_loss:  36.4729, val_wt_loss: 37.3060, train_grp_loss: [11.81733701 13.08397007 10.69260408], val_grp_loss: [12.6979498  12.46325251 12.14405097], train_hist_grp_loss: [11.96400528 13.21606108 27.14807868], cur_train_grp_loss: [0.09453873 0.10466987 0.21385976], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6694, max_kl_dist_index: 0, max_train_grp_loss:  13.0840, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6979, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2139, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:50:55,800 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  126, train_loss:  12.1577, val_loss:  12.4355, grad_norm: 0.0104, live_grad: 0.0000, reward_err: 0.0105, 0.0143, 0.0002, KL_dist: 0.6695, 0.3121, 0.6619, param: [5.45980194 8.24508336 5.25049688 8.75639445], weights: [0.27614826 0.28680529 0.43704645], train_wt_loss:  36.4730, val_wt_loss: 37.3064, train_grp_loss: [11.81733124 13.08420973 10.69221938], val_grp_loss: [12.69811473 12.46353351 12.14399823], train_hist_grp_loss: [12.05854398 13.32073284 27.36193076], cur_train_grp_loss: [0.0945387  0.10467176 0.21385208], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6695, max_kl_dist_index: 0, max_train_grp_loss:  13.0842, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6981, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2139, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:50:56,836 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  127, train_loss:  12.1577, val_loss:  12.4356, grad_norm: 0.0105, live_grad: 0.0000, reward_err: 0.0105, 0.0143, 0.0002, KL_dist: 0.6696, 0.3121, 0.6621, param: [5.45989631 8.24470386 5.25141457 8.75818194], weights: [0.27569218 0.28641869 0.43788913], train_wt_loss:  36.4731, val_wt_loss: 37.3068, train_grp_loss: [11.81732379 13.08445237 10.69183371], val_grp_loss: [12.69827827 12.4638179  12.14394495], train_hist_grp_loss: [12.15308263 13.42540652 27.57577514], cur_train_grp_loss: [0.09453865 0.10467368 0.21384439], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6696, max_kl_dist_index: 0, max_train_grp_loss:  13.0845, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6983, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2138, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:50:57,853 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  128, train_loss:  12.1577, val_loss:  12.4357, grad_norm: 0.0106, live_grad: 0.0000, reward_err: 0.0105, 0.0143, 0.0002, KL_dist: 0.6697, 0.3122, 0.6622, param: [5.45998993 8.24432524 5.25233352 8.75997509], weights: [0.27523609 0.28603182 0.43873209], train_wt_loss:  36.4732, val_wt_loss: 37.3072, train_grp_loss: [11.81731465 13.08469799 10.69144708], val_grp_loss: [12.69844043 12.4641057  12.14389111], train_hist_grp_loss: [12.24762122 13.53008214 27.78961182], cur_train_grp_loss: [0.09453859 0.10467562 0.21383667], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6697, max_kl_dist_index: 0, max_train_grp_loss:  13.0847, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6984, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2138, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:50:58,907 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  129, train_loss:  12.1578, val_loss:  12.4359, grad_norm: 0.0107, live_grad: 0.0000, reward_err: 0.0105, 0.0143, 0.0002, KL_dist: 0.6698, 0.3123, 0.6623, param: [5.46008279 8.24394748 5.25325376 8.76177391], weights: [0.27477998 0.28564469 0.43957534], train_wt_loss:  36.4733, val_wt_loss: 37.3076, train_grp_loss: [11.81730383 13.08494659 10.6910595 ], val_grp_loss: [12.69860119 12.46439689 12.14383673], train_hist_grp_loss: [12.34215973 13.63475972 28.00344076], cur_train_grp_loss: [0.09453852 0.10467758 0.21382894], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6698, max_kl_dist_index: 0, max_train_grp_loss:  13.0849, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6986, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2138, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:50:59,940 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  130, train_loss:  12.1578, val_loss:  12.4360, grad_norm: 0.0108, live_grad: 0.0000, reward_err: 0.0105, 0.0143, 0.0002, KL_dist: 0.6700, 0.3123, 0.6624, param: [5.46017489 8.24357058 5.25417527 8.76357841], weights: [0.27432384 0.28525729 0.44041886], train_wt_loss:  36.4734, val_wt_loss: 37.3080, train_grp_loss: [11.81729132 13.08519819 10.69067095], val_grp_loss: [12.69876057 12.4646915  12.1437818 ], train_hist_grp_loss: [12.43669817 13.73943929 28.21726195], cur_train_grp_loss: [0.09453843 0.10467957 0.21382119], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6700, max_kl_dist_index: 0, max_train_grp_loss:  13.0852, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6988, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2138, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:51:00,952 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  131, train_loss:  12.1579, val_loss:  12.4361, grad_norm: 0.0109, live_grad: 0.0000, reward_err: 0.0105, 0.0143, 0.0002, KL_dist: 0.6701, 0.3124, 0.6625, param: [5.46026624 8.24319454 5.25509807 8.76538858], weights: [0.2738677  0.28486964 0.44126266], train_wt_loss:  36.4736, val_wt_loss: 37.3084, train_grp_loss: [11.81727714 13.08545276 10.69028145], val_grp_loss: [12.69891857 12.4649895  12.14372632], train_hist_grp_loss: [12.5312365  13.84412088 28.43107537], cur_train_grp_loss: [0.09453833 0.10468159 0.21381342], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6701, max_kl_dist_index: 0, max_train_grp_loss:  13.0855, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6989, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2138, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:51:01,984 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  132, train_loss:  12.1579, val_loss:  12.4363, grad_norm: 0.0110, live_grad: 0.0000, reward_err: 0.0105, 0.0143, 0.0002, KL_dist: 0.6702, 0.3125, 0.6627, param: [5.46035682 8.24281936 5.25602215 8.76720444], weights: [0.27341154 0.28448173 0.44210673], train_wt_loss:  36.4737, val_wt_loss: 37.3088, train_grp_loss: [11.81726128 13.08571033 10.68989098], val_grp_loss: [12.69907519 12.46529092 12.1436703 ], train_hist_grp_loss: [12.62577471 13.9488045  28.644881  ], cur_train_grp_loss: [0.09453822 0.10468362 0.21380563], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6702, max_kl_dist_index: 0, max_train_grp_loss:  13.0857, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6991, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2138, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:51:03,026 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  133, train_loss:  12.1579, val_loss:  12.4364, grad_norm: 0.0112, live_grad: 0.0000, reward_err: 0.0105, 0.0143, 0.0002, KL_dist: 0.6703, 0.3125, 0.6628, param: [5.46044664 8.24244502 5.25694751 8.76902598], weights: [0.27295537 0.28409356 0.44295106], train_wt_loss:  36.4738, val_wt_loss: 37.3092, train_grp_loss: [11.81724375 13.0859709  10.68949957], val_grp_loss: [12.69923044 12.46559575 12.14361375], train_hist_grp_loss: [12.7203128  14.05349018 28.85867882], cur_train_grp_loss: [0.09453809 0.10468568 0.21379782], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6703, max_kl_dist_index: 0, max_train_grp_loss:  13.0860, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6992, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2138, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:51:04,072 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  134, train_loss:  12.1580, val_loss:  12.4365, grad_norm: 0.0113, live_grad: 0.0000, reward_err: 0.0105, 0.0143, 0.0002, KL_dist: 0.6705, 0.3126, 0.6629, param: [5.4605357  8.24207152 5.25787416 8.7708532 ], weights: [0.2724992  0.28370515 0.44379565], train_wt_loss:  36.4739, val_wt_loss: 37.3096, train_grp_loss: [11.81722455 13.08623445 10.6891072 ], val_grp_loss: [12.6993843  12.46590399 12.14355665], train_hist_grp_loss: [12.81485075 14.15817795 29.07246881], cur_train_grp_loss: [0.09453795 0.10468777 0.21378999], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6705, max_kl_dist_index: 0, max_train_grp_loss:  13.0862, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6994, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2138, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:51:05,098 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  135, train_loss:  12.1580, val_loss:  12.4367, grad_norm: 0.0114, live_grad: 0.0000, reward_err: 0.0105, 0.0143, 0.0002, KL_dist: 0.6706, 0.3127, 0.6630, param: [5.46062399 8.24169887 5.25880209 8.77268612], weights: [0.27204302 0.28331648 0.4446405 ], train_wt_loss:  36.4740, val_wt_loss: 37.3100, train_grp_loss: [11.81720368 13.086501   10.68871387], val_grp_loss: [12.6995368  12.46621565 12.14349902], train_hist_grp_loss: [12.90938855 14.26286783 29.28625095], cur_train_grp_loss: [0.0945378  0.10468988 0.21378214], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6706, max_kl_dist_index: 0, max_train_grp_loss:  13.0865, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6995, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2138, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:51:06,128 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  136, train_loss:  12.1580, val_loss:  12.4368, grad_norm: 0.0115, live_grad: 0.0000, reward_err: 0.0102, 0.0143, 0.0001, KL_dist: 0.6707, 0.3128, 0.6632, param: [5.46071152 8.24132705 5.25973132 8.77452474], weights: [0.27158684 0.28292757 0.44548559], train_wt_loss:  36.4741, val_wt_loss: 37.3104, train_grp_loss: [11.81718116 13.08677055 10.6883196 ], val_grp_loss: [12.69968792 12.46653072 12.14344086], train_hist_grp_loss: [13.00392618 14.36755983 29.50002523], cur_train_grp_loss: [0.09453763 0.10469201 0.21377428], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6707, max_kl_dist_index: 0, max_train_grp_loss:  13.0868, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6997, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2138, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:51:07,170 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  137, train_loss:  12.1581, val_loss:  12.4370, grad_norm: 0.0116, live_grad: 0.0000, reward_err: 0.0102, 0.0143, 0.0001, KL_dist: 0.6708, 0.3128, 0.6633, param: [5.46079827 8.24095607 5.26066183 8.77636905], weights: [0.27113065 0.28253842 0.44633093], train_wt_loss:  36.4742, val_wt_loss: 37.3109, train_grp_loss: [11.81715697 13.08704309 10.68792437], val_grp_loss: [12.69983767 12.46684921 12.14338217], train_hist_grp_loss: [13.09846363 14.472254   29.71379162], cur_train_grp_loss: [0.09453745 0.10469416 0.21376639], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6708, max_kl_dist_index: 0, max_train_grp_loss:  13.0870, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6998, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2138, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:51:08,211 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  138, train_loss:  12.1581, val_loss:  12.4371, grad_norm: 0.0117, live_grad: 0.0000, reward_err: 0.0102, 0.0143, 0.0001, KL_dist: 0.6710, 0.3129, 0.6634, param: [5.46088426 8.24058591 5.26159363 8.77821907], weights: [0.27067447 0.28214902 0.4471765 ], train_wt_loss:  36.4743, val_wt_loss: 37.3113, train_grp_loss: [11.81713112 13.08731864 10.6875282 ], val_grp_loss: [12.69998606 12.46717113 12.14332295], train_hist_grp_loss: [13.19300088 14.57695034 29.92755011], cur_train_grp_loss: [0.09453726 0.10469634 0.21375849], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6710, max_kl_dist_index: 0, max_train_grp_loss:  13.0873, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7000, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2138, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:51:09,233 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  139, train_loss:  12.1581, val_loss:  12.4372, grad_norm: 0.0119, live_grad: 0.0000, reward_err: 0.0102, 0.0143, 0.0001, KL_dist: 0.6711, 0.3130, 0.6635, param: [5.46096947 8.24021658 5.26252673 8.7800748 ], weights: [0.2702183  0.28175939 0.44802231], train_wt_loss:  36.4744, val_wt_loss: 37.3117, train_grp_loss: [11.81710362 13.08759719 10.68713108], val_grp_loss: [12.70013308 12.46749647 12.1432632 ], train_hist_grp_loss: [13.28753793 14.68164889 30.14130067], cur_train_grp_loss: [0.09453705 0.10469855 0.21375056], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6711, max_kl_dist_index: 0, max_train_grp_loss:  13.0876, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7001, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2138, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:51:10,255 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  140, train_loss:  12.1582, val_loss:  12.4374, grad_norm: 0.0120, live_grad: 0.0000, reward_err: 0.0102, 0.0143, 0.0001, KL_dist: 0.6712, 0.3130, 0.6637, param: [5.46105391 8.23984806 5.26346111 8.78193623], weights: [0.26976213 0.28136952 0.44886835], train_wt_loss:  36.4746, val_wt_loss: 37.3121, train_grp_loss: [11.81707446 13.08787875 10.68673301], val_grp_loss: [12.70027874 12.46782524 12.14320293], train_hist_grp_loss: [13.38207476 14.78634967 30.3550433 ], cur_train_grp_loss: [0.09453683 0.10470078 0.21374262], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6712, max_kl_dist_index: 0, max_train_grp_loss:  13.0879, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7003, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2137, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:51:11,313 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  141, train_loss:  12.1582, val_loss:  12.4375, grad_norm: 0.0121, live_grad: 0.0000, reward_err: 0.0102, 0.0143, 0.0001, KL_dist: 0.6714, 0.3131, 0.6638, param: [5.46113757 8.23948036 5.2643968  8.78380337], weights: [0.26930597 0.28097942 0.44971461], train_wt_loss:  36.4747, val_wt_loss: 37.3125, train_grp_loss: [11.81704366 13.08816331 10.686334  ], val_grp_loss: [12.70042304 12.46815744 12.14314214], train_hist_grp_loss: [13.47661136 14.8910527  30.56877796], cur_train_grp_loss: [0.0945366  0.10470303 0.21373466], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6714, max_kl_dist_index: 0, max_train_grp_loss:  13.0882, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7004, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2137, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:51:12,312 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  142, train_loss:  12.1583, val_loss:  12.4376, grad_norm: 0.0122, live_grad: 0.0000, reward_err: 0.0102, 0.0143, 0.0001, KL_dist: 0.6715, 0.3132, 0.6639, param: [5.46122046 8.23911347 5.26533377 8.78567624], weights: [0.26884983 0.28058909 0.45056109], train_wt_loss:  36.4748, val_wt_loss: 37.3129, train_grp_loss: [11.81701122 13.08845087 10.68593404], val_grp_loss: [12.70056599 12.46849306 12.14308084], train_hist_grp_loss: [13.57114771 14.99575801 30.78250464], cur_train_grp_loss: [0.09453635 0.10470531 0.21372668], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6715, max_kl_dist_index: 0, max_train_grp_loss:  13.0885, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7006, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2137, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:51:13,355 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  143, train_loss:  12.1583, val_loss:  12.4378, grad_norm: 0.0123, live_grad: 0.0000, reward_err: 0.0102, 0.0143, 0.0001, KL_dist: 0.6716, 0.3132, 0.6640, param: [5.46130257 8.23874739 5.26627205 8.78755482], weights: [0.2683937  0.28019852 0.45140778], train_wt_loss:  36.4749, val_wt_loss: 37.3133, train_grp_loss: [11.81697713 13.08874145 10.68553314], val_grp_loss: [12.70070758 12.46883212 12.14301901], train_hist_grp_loss: [13.6656838  15.10046561 30.99622332], cur_train_grp_loss: [0.09453609 0.10470761 0.21371868], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6716, max_kl_dist_index: 0, max_train_grp_loss:  13.0887, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7007, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2137, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:51:14,419 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  144, train_loss:  12.1583, val_loss:  12.4379, grad_norm: 0.0125, live_grad: 0.0000, reward_err: 0.0102, 0.0143, 0.0001, KL_dist: 0.6717, 0.3133, 0.6642, param: [5.4613839  8.23838211 5.26721162 8.78943912], weights: [0.26793758 0.27980774 0.45225468], train_wt_loss:  36.4750, val_wt_loss: 37.3138, train_grp_loss: [11.8169414  13.08903504 10.68513131], val_grp_loss: [12.70084781 12.46917462 12.14295667], train_hist_grp_loss: [13.76021961 15.20517554 31.20993398], cur_train_grp_loss: [0.09453582 0.10470993 0.21371066], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6717, max_kl_dist_index: 0, max_train_grp_loss:  13.0890, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7008, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2137, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:51:15,460 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  145, train_loss:  12.1584, val_loss:  12.4381, grad_norm: 0.0126, live_grad: 0.0000, reward_err: 0.0102, 0.0143, 0.0001, KL_dist: 0.6719, 0.3134, 0.6643, param: [5.46146445 8.23801762 5.2681525  8.79132915], weights: [0.26748148 0.27941673 0.45310178], train_wt_loss:  36.4752, val_wt_loss: 37.3142, train_grp_loss: [11.81690404 13.08933164 10.68472853], val_grp_loss: [12.7009867  12.46952055 12.14289382], train_hist_grp_loss: [13.85475514 15.30988782 31.42363661], cur_train_grp_loss: [0.09453553 0.10471228 0.21370263], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6719, max_kl_dist_index: 0, max_train_grp_loss:  13.0893, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7010, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2137, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:51:16,499 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  146, train_loss:  12.1584, val_loss:  12.4382, grad_norm: 0.0127, live_grad: 0.0000, reward_err: 0.0102, 0.0143, 0.0001, KL_dist: 0.6720, 0.3135, 0.6644, param: [5.46154421 8.23765393 5.26909467 8.79322492], weights: [0.26702541 0.2790255  0.45394909], train_wt_loss:  36.4753, val_wt_loss: 37.3146, train_grp_loss: [11.81686505 13.08963126 10.68432481], val_grp_loss: [12.70112424 12.46986992 12.14283047], train_hist_grp_loss: [13.94929038 15.41460248 31.63733118], cur_train_grp_loss: [0.09453523 0.10471465 0.21369457], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6720, max_kl_dist_index: 0, max_train_grp_loss:  13.0896, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7011, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2137, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:51:17,557 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  147, train_loss:  12.1585, val_loss:  12.4383, grad_norm: 0.0128, live_grad: 0.0000, reward_err: 0.0102, 0.0143, 0.0001, KL_dist: 0.6721, 0.3135, 0.6646, param: [5.46162319 8.23729103 5.27003815 8.79512641], weights: [0.26656936 0.27863406 0.45479658], train_wt_loss:  36.4754, val_wt_loss: 37.3150, train_grp_loss: [11.81682443 13.08993389 10.68392016], val_grp_loss: [12.70126043 12.47022273 12.1427666 ], train_hist_grp_loss: [14.0438253  15.51931953 31.85101767], cur_train_grp_loss: [0.09453492 0.10471705 0.2136865 ], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6721, max_kl_dist_index: 0, max_train_grp_loss:  13.0899, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7013, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2137, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:51:18,586 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  148, train_loss:  12.1585, val_loss:  12.4385, grad_norm: 0.0129, live_grad: 0.0000, reward_err: 0.0102, 0.0143, 0.0001, KL_dist: 0.6723, 0.3136, 0.6647, param: [5.46170138 8.23692891 5.27098293 8.79703364], weights: [0.26611334 0.2782424  0.45564426], train_wt_loss:  36.4755, val_wt_loss: 37.3155, train_grp_loss: [11.81678218 13.09023954 10.68351458], val_grp_loss: [12.70139529 12.47057899 12.14270224], train_hist_grp_loss: [14.13835989 15.624039   32.06469608], cur_train_grp_loss: [0.0945346  0.10471947 0.2136784 ], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6723, max_kl_dist_index: 0, max_train_grp_loss:  13.0902, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7014, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2137, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:51:19,619 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  149, train_loss:  12.1586, val_loss:  12.4386, grad_norm: 0.0131, live_grad: 0.0000, reward_err: 0.0102, 0.0143, 0.0001, KL_dist: 0.6724, 0.3137, 0.6648, param: [5.46177879 8.23656757 5.27192901 8.7989466 ], weights: [0.26565734 0.27785053 0.45649213], train_wt_loss:  36.4757, val_wt_loss: 37.3159, train_grp_loss: [11.81673831 13.09054821 10.68310806], val_grp_loss: [12.7015288  12.47093869 12.14263737], train_hist_grp_loss: [14.23289415 15.72876092 32.27836637], cur_train_grp_loss: [0.09453426 0.10472192 0.21367029], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6724, max_kl_dist_index: 0, max_train_grp_loss:  13.0905, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7015, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2137, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:51:20,650 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  150, train_loss:  12.1586, val_loss:  12.4388, grad_norm: 0.0132, live_grad: 0.0000, reward_err: 0.0102, 0.0143, 0.0001, KL_dist: 0.6725, 0.3137, 0.6650, param: [5.4618554  8.23620701 5.2728764  8.80086531], weights: [0.26520138 0.27745845 0.45734017], train_wt_loss:  36.4758, val_wt_loss: 37.3163, train_grp_loss: [11.81669282 13.0908599  10.68270061], val_grp_loss: [12.70166097 12.47130184 12.142572  ], train_hist_grp_loss: [14.32742806 15.8334853  32.49202853], cur_train_grp_loss: [0.09453391 0.10472439 0.21366216], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6725, max_kl_dist_index: 0, max_train_grp_loss:  13.0909, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7017, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2137, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:51:21,687 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  151, train_loss:  12.1586, val_loss:  12.4389, grad_norm: 0.0133, live_grad: 0.0000, reward_err: 0.0102, 0.0143, 0.0001, KL_dist: 0.6727, 0.3138, 0.6651, param: [5.46193123 8.23584722 5.2738251  8.80278977], weights: [0.26474545 0.27706616 0.45818839], train_wt_loss:  36.4759, val_wt_loss: 37.3168, train_grp_loss: [11.81664571 13.09117462 10.68229223], val_grp_loss: [12.70179181 12.47166843 12.14250614], train_hist_grp_loss: [14.4219616  15.93821218 32.70568254], cur_train_grp_loss: [0.09453354 0.10472688 0.21365401], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6727, max_kl_dist_index: 0, max_train_grp_loss:  13.0912, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7018, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2137, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:51:22,714 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  152, train_loss:  12.1587, val_loss:  12.4391, grad_norm: 0.0134, live_grad: 0.0000, reward_err: 0.0102, 0.0143, 0.0001, KL_dist: 0.6728, 0.3139, 0.6652, param: [5.46200626 8.23548819 5.27477511 8.80471997], weights: [0.26428956 0.27667367 0.45903677], train_wt_loss:  36.4761, val_wt_loss: 37.3172, train_grp_loss: [11.81659699 13.09149236 10.68188293], val_grp_loss: [12.70192131 12.47203848 12.14243978], train_hist_grp_loss: [14.51649477 16.04294158 32.91932839], cur_train_grp_loss: [0.09453317 0.1047294  0.21364584], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6728, max_kl_dist_index: 0, max_train_grp_loss:  13.0915, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7019, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2136, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:51:23,744 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  153, train_loss:  12.1587, val_loss:  12.4392, grad_norm: 0.0136, live_grad: 0.0000, reward_err: 0.0102, 0.0143, 0.0001, KL_dist: 0.6729, 0.3140, 0.6654, param: [5.46208049 8.23512993 5.27572642 8.80665592], weights: [0.2638337  0.27628098 0.45988532], train_wt_loss:  36.4762, val_wt_loss: 37.3176, train_grp_loss: [11.81654666 13.09181312 10.68147269], val_grp_loss: [12.70204948 12.47241199 12.14237294], train_hist_grp_loss: [14.61102754 16.14767352 33.13296604], cur_train_grp_loss: [0.09453278 0.10473194 0.21363766], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6729, max_kl_dist_index: 0, max_train_grp_loss:  13.0918, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7020, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2136, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:51:24,754 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  154, train_loss:  12.1588, val_loss:  12.4394, grad_norm: 0.0137, live_grad: 0.0000, reward_err: 0.0102, 0.0143, 0.0001, KL_dist: 0.6731, 0.3140, 0.6655, param: [5.46215393 8.23477242 5.27667904 8.80859762], weights: [0.26337789 0.27588809 0.46073402], train_wt_loss:  36.4763, val_wt_loss: 37.3181, train_grp_loss: [11.81649473 13.09213692 10.68106153], val_grp_loss: [12.70217633 12.47278894 12.1423056 ], train_hist_grp_loss: [14.70555991 16.25240802 33.3465955 ], cur_train_grp_loss: [0.09453237 0.1047345  0.21362945], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6731, max_kl_dist_index: 0, max_train_grp_loss:  13.0921, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7022, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2136, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:51:25,781 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  155, train_loss:  12.1588, val_loss:  12.4395, grad_norm: 0.0138, live_grad: 0.0000, reward_err: 0.0102, 0.0143, 0.0001, KL_dist: 0.6732, 0.3141, 0.6656, param: [5.46222658 8.23441567 5.27763298 8.81054508], weights: [0.26292212 0.275495   0.46158288], train_wt_loss:  36.4765, val_wt_loss: 37.3185, train_grp_loss: [11.81644119 13.09246374 10.68064945], val_grp_loss: [12.70230185 12.47316936 12.14223778], train_hist_grp_loss: [14.80009187 16.35714512 33.56021673], cur_train_grp_loss: [0.09453196 0.1047371  0.21362123], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6732, max_kl_dist_index: 0, max_train_grp_loss:  13.0925, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7023, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2136, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:51:26,846 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  156, train_loss:  12.1589, val_loss:  12.4396, grad_norm: 0.0139, live_grad: 0.0000, reward_err: 0.0102, 0.0143, 0.0001, KL_dist: 0.6733, 0.3142, 0.6657, param: [5.46229842 8.23405967 5.27858822 8.81249831], weights: [0.2624664  0.27510172 0.46243188], train_wt_loss:  36.4766, val_wt_loss: 37.3189, train_grp_loss: [11.81638606 13.09279359 10.68023645], val_grp_loss: [12.70242605 12.47355323 12.14216948], train_hist_grp_loss: [14.8946234  16.46188483 33.77382972], cur_train_grp_loss: [0.09453153 0.10473971 0.21361299], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6733, max_kl_dist_index: 0, max_train_grp_loss:  13.0928, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7024, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2136, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:51:27,880 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  157, train_loss:  12.1589, val_loss:  12.4398, grad_norm: 0.0141, live_grad: 0.0000, reward_err: 0.0102, 0.0143, 0.0001, KL_dist: 0.6735, 0.3142, 0.6659, param: [5.46236946 8.2337044  5.27954478 8.81445729], weights: [0.26201073 0.27470825 0.46328103], train_wt_loss:  36.4767, val_wt_loss: 37.3194, train_grp_loss: [11.81632933 13.09312648 10.67982252], val_grp_loss: [12.70254893 12.47394057 12.14210069], train_hist_grp_loss: [14.98915449 16.56662717 33.98743445], cur_train_grp_loss: [0.09453109 0.10474235 0.21360473], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6735, max_kl_dist_index: 0, max_train_grp_loss:  13.0931, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7025, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2136, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:51:28,934 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  158, train_loss:  12.1590, val_loss:  12.4399, grad_norm: 0.0142, live_grad: 0.0000, reward_err: 0.0102, 0.0143, 0.0001, KL_dist: 0.6736, 0.3143, 0.6660, param: [5.4624397  8.23334988 5.28050266 8.81642204], weights: [0.2615551  0.27431459 0.46413031], train_wt_loss:  36.4769, val_wt_loss: 37.3198, train_grp_loss: [11.816271   13.0934624  10.67940768], val_grp_loss: [12.70267049 12.47433137 12.14203143], train_hist_grp_loss: [15.08368512 16.67137219 34.2010309 ], cur_train_grp_loss: [0.09453063 0.10474501 0.21359645], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6736, max_kl_dist_index: 0, max_train_grp_loss:  13.0935, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7027, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2136, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:51:29,967 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  159, train_loss:  12.1590, val_loss:  12.4401, grad_norm: 0.0143, live_grad: 0.0000, reward_err: 0.0102, 0.0143, 0.0001, KL_dist: 0.6737, 0.3144, 0.6662, param: [5.46250914 8.23299609 5.28146185 8.81839255], weights: [0.26109953 0.27392075 0.46497972], train_wt_loss:  36.4770, val_wt_loss: 37.3203, train_grp_loss: [11.81621109 13.09380135 10.67899192], val_grp_loss: [12.70279073 12.47472563 12.14196169], train_hist_grp_loss: [15.17821529 16.77611989 34.41461905], cur_train_grp_loss: [0.09453017 0.1047477  0.21358815], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6737, max_kl_dist_index: 0, max_train_grp_loss:  13.0938, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7028, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2136, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:51:30,998 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  160, train_loss:  12.1591, val_loss:  12.4402, grad_norm: 0.0145, live_grad: 0.0000, reward_err: 0.0102, 0.0143, 0.0001, KL_dist: 0.6739, 0.3145, 0.6663, param: [5.46257777 8.23264304 5.28242235 8.82036883], weights: [0.26064402 0.27352672 0.46582926], train_wt_loss:  36.4772, val_wt_loss: 37.3207, train_grp_loss: [11.8161496  13.09414334 10.67857525], val_grp_loss: [12.70290966 12.47512336 12.14189148], train_hist_grp_loss: [15.27274498 16.8808703  34.62819889], cur_train_grp_loss: [0.09452969 0.10475041 0.21357984], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6739, max_kl_dist_index: 0, max_train_grp_loss:  13.0941, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7029, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2136, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:51:32,038 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  161, train_loss:  12.1591, val_loss:  12.4404, grad_norm: 0.0146, live_grad: 0.0000, reward_err: 0.0102, 0.0143, 0.0001, KL_dist: 0.6740, 0.3145, 0.6664, param: [5.46264559 8.2322907  5.28338418 8.82235089], weights: [0.26018856 0.27313252 0.46667892], train_wt_loss:  36.4773, val_wt_loss: 37.3212, train_grp_loss: [11.81608652 13.09448837 10.67815766], val_grp_loss: [12.70302728 12.47552456 12.14182081], train_hist_grp_loss: [15.36727418 16.98562344 34.84177039], cur_train_grp_loss: [0.0945292  0.10475315 0.2135715 ], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6740, max_kl_dist_index: 0, max_train_grp_loss:  13.0945, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7030, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2136, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:51:33,066 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  162, train_loss:  12.1591, val_loss:  12.4405, grad_norm: 0.0147, live_grad: 0.0000, reward_err: 0.0102, 0.0143, 0.0001, KL_dist: 0.6741, 0.3146, 0.6666, param: [5.4627126  8.23193909 5.28434732 8.82433872], weights: [0.25973317 0.27273813 0.4675287 ], train_wt_loss:  36.4774, val_wt_loss: 37.3216, train_grp_loss: [11.81602187 13.09483644 10.67773916], val_grp_loss: [12.7031436  12.47592923 12.14174966], train_hist_grp_loss: [15.46180287 17.09037935 35.05533355], cur_train_grp_loss: [0.09452869 0.10475591 0.21356315], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6741, max_kl_dist_index: 0, max_train_grp_loss:  13.0948, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7031, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2136, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:51:34,097 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  163, train_loss:  12.1592, val_loss:  12.4407, grad_norm: 0.0148, live_grad: 0.0000, reward_err: 0.0102, 0.0143, 0.0001, KL_dist: 0.6743, 0.3147, 0.6667, param: [5.46277881 8.2315882  5.28531178 8.82633233], weights: [0.25927783 0.27234358 0.46837859], train_wt_loss:  36.4776, val_wt_loss: 37.3221, train_grp_loss: [11.81595564 13.09518756 10.67731975], val_grp_loss: [12.70325861 12.47633738 12.14167805], train_hist_grp_loss: [15.55633105 17.19513804 35.26888833], cur_train_grp_loss: [0.09452817 0.10475869 0.21355478], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6743, max_kl_dist_index: 0, max_train_grp_loss:  13.0952, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7033, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2136, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:51:35,124 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  164, train_loss:  12.1592, val_loss:  12.4408, grad_norm: 0.0150, live_grad: 0.0000, reward_err: 0.0102, 0.0143, 0.0001, KL_dist: 0.6744, 0.3148, 0.6668, param: [5.4628442  8.23123801 5.28627756 8.82833172], weights: [0.25882257 0.27194885 0.46922859], train_wt_loss:  36.4777, val_wt_loss: 37.3225, train_grp_loss: [11.81588784 13.09554171 10.67689943], val_grp_loss: [12.70337232 12.47674899 12.14160598], train_hist_grp_loss: [15.65085869 17.29989954 35.48243472], cur_train_grp_loss: [0.09452765 0.1047615  0.21354639], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6744, max_kl_dist_index: 0, max_train_grp_loss:  13.0955, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7034, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2135, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:51:36,153 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  165, train_loss:  12.1593, val_loss:  12.4410, grad_norm: 0.0151, live_grad: 0.0000, reward_err: 0.0102, 0.0143, 0.0001, KL_dist: 0.6745, 0.3148, 0.6670, param: [5.46290877 8.23088853 5.28724466 8.83033689], weights: [0.25836737 0.27155395 0.47007868], train_wt_loss:  36.4779, val_wt_loss: 37.3230, train_grp_loss: [11.81581847 13.09589891 10.67647821], val_grp_loss: [12.70348473 12.47716409 12.14153344], train_hist_grp_loss: [15.74538579 17.40466388 35.69597271], cur_train_grp_loss: [0.0945271  0.10476433 0.21353799], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6745, max_kl_dist_index: 0, max_train_grp_loss:  13.0959, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7035, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2135, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:51:37,185 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  166, train_loss:  12.1593, val_loss:  12.4411, grad_norm: 0.0152, live_grad: 0.0000, reward_err: 0.0102, 0.0143, 0.0001, KL_dist: 0.6747, 0.3149, 0.6671, param: [5.46297254 8.23053976 5.28821308 8.83234785], weights: [0.25791224 0.27115888 0.47092887], train_wt_loss:  36.4780, val_wt_loss: 37.3234, train_grp_loss: [11.81574755 13.09625916 10.67605608], val_grp_loss: [12.70359584 12.47758266 12.14146046], train_hist_grp_loss: [15.83991234 17.50943107 35.90950228], cur_train_grp_loss: [0.09452655 0.10476719 0.21352956], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6747, max_kl_dist_index: 0, max_train_grp_loss:  13.0963, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7036, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2135, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:51:38,229 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  167, train_loss:  12.1594, val_loss:  12.4413, grad_norm: 0.0154, live_grad: 0.0000, reward_err: 0.0102, 0.0143, 0.0001, KL_dist: 0.6748, 0.3150, 0.6672, param: [5.46303548 8.23019167 5.28918282 8.83436459], weights: [0.25745719 0.27076366 0.47177916], train_wt_loss:  36.4782, val_wt_loss: 37.3239, train_grp_loss: [11.81567506 13.09662245 10.67563305], val_grp_loss: [12.70370566 12.47800471 12.14138702], train_hist_grp_loss: [15.93443832 17.61420114 36.1230234 ], cur_train_grp_loss: [0.09452598 0.10477007 0.21352112], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6748, max_kl_dist_index: 0, max_train_grp_loss:  13.0966, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7037, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2135, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:51:39,283 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  168, train_loss:  12.1594, val_loss:  12.4414, grad_norm: 0.0155, live_grad: 0.0000, reward_err: 0.0102, 0.0143, 0.0001, KL_dist: 0.6749, 0.3151, 0.6674, param: [5.46309761 8.22984429 5.29015389 8.83638713], weights: [0.25700221 0.27036827 0.47262953], train_wt_loss:  36.4783, val_wt_loss: 37.3243, train_grp_loss: [11.81560101 13.09698879 10.67520912], val_grp_loss: [12.70381419 12.47843025 12.14131312], train_hist_grp_loss: [16.02896372 17.71897412 36.33653606], cur_train_grp_loss: [0.0945254  0.10477298 0.21351266], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6749, max_kl_dist_index: 0, max_train_grp_loss:  13.0970, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7038, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2135, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:51:40,320 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  169, train_loss:  12.1595, val_loss:  12.4416, grad_norm: 0.0156, live_grad: 0.0000, reward_err: 0.0102, 0.0143, 0.0001, KL_dist: 0.6751, 0.3151, 0.6675, param: [5.46315891 8.22949758 5.29112629 8.83841545], weights: [0.2565473  0.26997272 0.47347998], train_wt_loss:  36.4785, val_wt_loss: 37.3248, train_grp_loss: [11.81552542 13.09735818 10.67478429], val_grp_loss: [12.70392143 12.47885926 12.14123878], train_hist_grp_loss: [16.12348853 17.82375003 36.55004024], cur_train_grp_loss: [0.09452481 0.10477591 0.21350418], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6751, max_kl_dist_index: 0, max_train_grp_loss:  13.0974, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7039, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2135, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:51:41,359 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  170, train_loss:  12.1596, val_loss:  12.4418, grad_norm: 0.0158, live_grad: 0.0000, reward_err: 0.0102, 0.0143, 0.0001, KL_dist: 0.6752, 0.3152, 0.6677, param: [5.46321939 8.22915157 5.2921     8.84044957], weights: [0.25609248 0.26957702 0.4743305 ], train_wt_loss:  36.4787, val_wt_loss: 37.3253, train_grp_loss: [11.81544827 13.09773062 10.67435856], val_grp_loss: [12.70402738 12.47929176 12.141164  ], train_hist_grp_loss: [16.21801273 17.9285289  36.76353593], cur_train_grp_loss: [0.0945242  0.10477887 0.21349569], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6752, max_kl_dist_index: 0, max_train_grp_loss:  13.0977, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7040, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2135, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:51:42,372 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  171, train_loss:  12.1596, val_loss:  12.4419, grad_norm: 0.0159, live_grad: 0.0000, reward_err: 0.0102, 0.0143, 0.0001, KL_dist: 0.6754, 0.3153, 0.6678, param: [5.46327905 8.22880622 5.29307505 8.84248949], weights: [0.25563774 0.26918116 0.47518109], train_wt_loss:  36.4788, val_wt_loss: 37.3257, train_grp_loss: [11.81536958 13.09810611 10.67393194], val_grp_loss: [12.70413206 12.47972775 12.14108877], train_hist_grp_loss: [16.31253632 18.03331074 36.9770231 ], cur_train_grp_loss: [0.09452359 0.10478184 0.21348717], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6754, max_kl_dist_index: 0, max_train_grp_loss:  13.0981, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7041, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2135, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:51:43,369 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  172, train_loss:  12.1597, val_loss:  12.4421, grad_norm: 0.0160, live_grad: 0.0000, reward_err: 0.0102, 0.0143, 0.0001, KL_dist: 0.6755, 0.3154, 0.6679, param: [5.46333789 8.22846156 5.29405142 8.8445352 ], weights: [0.25518309 0.26878515 0.47603175], train_wt_loss:  36.4790, val_wt_loss: 37.3262, train_grp_loss: [11.81528936 13.09848466 10.67350442], val_grp_loss: [12.70423545 12.48016723 12.14101311], train_hist_grp_loss: [16.40705928 18.13809559 37.19050174], cur_train_grp_loss: [0.09452296 0.10478485 0.21347864], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6755, max_kl_dist_index: 0, max_train_grp_loss:  13.0985, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7042, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2135, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:51:44,409 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  173, train_loss:  12.1597, val_loss:  12.4422, grad_norm: 0.0162, live_grad: 0.0000, reward_err: 0.0102, 0.0143, 0.0001, KL_dist: 0.6756, 0.3154, 0.6681, param: [5.4633959  8.22811755 5.29502911 8.84658672], weights: [0.25472852 0.268389   0.47688247], train_wt_loss:  36.4791, val_wt_loss: 37.3267, train_grp_loss: [11.81520759 13.09886627 10.67307601], val_grp_loss: [12.70433756 12.4806102  12.14093701], train_hist_grp_loss: [16.50158159 18.24288347 37.40397183], cur_train_grp_loss: [0.09452231 0.10478788 0.21347009], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6756, max_kl_dist_index: 0, max_train_grp_loss:  13.0989, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7043, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2135, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:51:45,430 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  174, train_loss:  12.1598, val_loss:  12.4424, grad_norm: 0.0163, live_grad: 0.0000, reward_err: 0.0102, 0.0143, 0.0001, KL_dist: 0.6758, 0.3155, 0.6682, param: [5.46345308 8.22777422 5.29600814 8.84864403], weights: [0.25427405 0.2679927  0.47773325], train_wt_loss:  36.4793, val_wt_loss: 37.3271, train_grp_loss: [11.81512429 13.09925093 10.67264672], val_grp_loss: [12.70443841 12.48105666 12.14086047], train_hist_grp_loss: [16.59610325 18.3476744  37.61743335], cur_train_grp_loss: [0.09452166 0.10479093 0.21346152], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6758, max_kl_dist_index: 0, max_train_grp_loss:  13.0993, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7044, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2135, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:51:46,451 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  175, train_loss:  12.1598, val_loss:  12.4425, grad_norm: 0.0165, live_grad: 0.0000, reward_err: 0.0102, 0.0143, 0.0001, KL_dist: 0.6759, 0.3156, 0.6684, param: [5.46350943 8.22743154 5.29698849 8.85070715], weights: [0.25381967 0.26759626 0.47858407], train_wt_loss:  36.4795, val_wt_loss: 37.3276, train_grp_loss: [11.81503946 13.09963864 10.67221653], val_grp_loss: [12.70453798 12.48150661 12.1407835 ], train_hist_grp_loss: [16.69062425 18.4524684  37.83088628], cur_train_grp_loss: [0.09452099 0.10479401 0.21345293], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6759, max_kl_dist_index: 0, max_train_grp_loss:  13.0996, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7045, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2135, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:51:47,507 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  176, train_loss:  12.1599, val_loss:  12.4427, grad_norm: 0.0166, live_grad: 0.0000, reward_err: 0.0102, 0.0143, 0.0001, KL_dist: 0.6761, 0.3157, 0.6685, param: [5.46356494 8.22708951 5.29797018 8.85277608], weights: [0.25336538 0.26719968 0.47943494], train_wt_loss:  36.4796, val_wt_loss: 37.3281, train_grp_loss: [11.81495311 13.10002942 10.67178546], val_grp_loss: [12.70463628 12.48196006 12.14070611], train_hist_grp_loss: [16.78514456 18.55726551 38.04433061], cur_train_grp_loss: [0.09452032 0.10479711 0.21344433], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6761, max_kl_dist_index: 0, max_train_grp_loss:  13.1000, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7046, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2134, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:51:48,552 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  177, train_loss:  12.1599, val_loss:  12.4429, grad_norm: 0.0167, live_grad: 0.0000, reward_err: 0.0102, 0.0143, 0.0001, KL_dist: 0.6762, 0.3157, 0.6687, param: [5.46361963 8.22674813 5.29895319 8.85485082], weights: [0.25291119 0.26680297 0.48028585], train_wt_loss:  36.4798, val_wt_loss: 37.3286, train_grp_loss: [11.81486524 13.10042326 10.67135351], val_grp_loss: [12.70473331 12.482417   12.14062829], train_hist_grp_loss: [16.87966419 18.66206575 38.25776632], cur_train_grp_loss: [0.09451962 0.10480024 0.21343571], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6762, max_kl_dist_index: 0, max_train_grp_loss:  13.1004, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7047, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2134, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:51:49,566 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  178, train_loss:  12.1600, val_loss:  12.4430, grad_norm: 0.0169, live_grad: 0.0000, reward_err: 0.0102, 0.0143, 0.0001, KL_dist: 0.6763, 0.3158, 0.6688, param: [5.46367348 8.22640739 5.29993754 8.85693136], weights: [0.25245709 0.26640611 0.48113679], train_wt_loss:  36.4800, val_wt_loss: 37.3290, train_grp_loss: [11.81477585 13.10082016 10.67092068], val_grp_loss: [12.70482908 12.48287745 12.14055005], train_hist_grp_loss: [16.97418311 18.76686914 38.47119339], cur_train_grp_loss: [0.09451892 0.10480339 0.21342707], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6763, max_kl_dist_index: 0, max_train_grp_loss:  13.1008, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7048, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2134, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:51:50,581 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  179, train_loss:  12.1600, val_loss:  12.4432, grad_norm: 0.0170, live_grad: 0.0000, reward_err: 0.0102, 0.0143, 0.0001, KL_dist: 0.6765, 0.3159, 0.6689, param: [5.46372649 8.2260673  5.30092321 8.85901772], weights: [0.25200311 0.26600913 0.48198776], train_wt_loss:  36.4801, val_wt_loss: 37.3295, train_grp_loss: [11.81468494 13.10122012 10.67048696], val_grp_loss: [12.7049236  12.48334139 12.14047138], train_hist_grp_loss: [17.06870132 18.8716757  38.68461181], cur_train_grp_loss: [0.09451821 0.10480656 0.21341841], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6765, max_kl_dist_index: 0, max_train_grp_loss:  13.1012, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7049, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2134, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:51:51,590 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  180, train_loss:  12.1601, val_loss:  12.4433, grad_norm: 0.0172, live_grad: 0.0000, reward_err: 0.0102, 0.0143, 0.0001, KL_dist: 0.6766, 0.3160, 0.6691, param: [5.46377867 8.22572783 5.30191022 8.86110989], weights: [0.25154922 0.26561202 0.48283876], train_wt_loss:  36.4803, val_wt_loss: 37.3300, train_grp_loss: [11.81459253 13.10162314 10.67005237], val_grp_loss: [12.70501685 12.48380884 12.14039231], train_hist_grp_loss: [17.16321879 18.97648546 38.89802154], cur_train_grp_loss: [0.09451748 0.10480976 0.21340974], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6766, max_kl_dist_index: 0, max_train_grp_loss:  13.1016, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7050, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2134, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:51:52,634 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  181, train_loss:  12.1602, val_loss:  12.4435, grad_norm: 0.0173, live_grad: 0.0000, reward_err: 0.0102, 0.0143, 0.0001, KL_dist: 0.6768, 0.3161, 0.6692, param: [5.46383    8.22538899 5.30289856 8.86320788], weights: [0.25109544 0.26521479 0.48368977], train_wt_loss:  36.4805, val_wt_loss: 37.3305, train_grp_loss: [11.81449861 13.10202924 10.66961691], val_grp_loss: [12.70510886 12.48427979 12.14031282], train_hist_grp_loss: [17.25773554 19.08129844 39.11142259], cur_train_grp_loss: [0.09451674 0.10481299 0.21340105], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6768, max_kl_dist_index: 0, max_train_grp_loss:  13.1020, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7051, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2134, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:51:53,646 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  182, train_loss:  12.1602, val_loss:  12.4437, grad_norm: 0.0174, live_grad: 0.0000, reward_err: 0.0102, 0.0143, 0.0001, KL_dist: 0.6769, 0.3161, 0.6694, param: [5.4638805  8.22505078 5.30388824 8.86531168], weights: [0.25064178 0.26481743 0.4845408 ], train_wt_loss:  36.4806, val_wt_loss: 37.3310, train_grp_loss: [11.81440319 13.10243839 10.66918057], val_grp_loss: [12.70519961 12.48475424 12.14023291], train_hist_grp_loss: [17.35225152 19.18611468 39.32481493], cur_train_grp_loss: [0.09451599 0.10481623 0.21339234], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6769, max_kl_dist_index: 0, max_train_grp_loss:  13.1024, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7052, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2134, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:51:54,683 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  183, train_loss:  12.1603, val_loss:  12.4438, grad_norm: 0.0176, live_grad: 0.0000, reward_err: 0.0102, 0.0143, 0.0001, KL_dist: 0.6771, 0.3162, 0.6695, param: [5.46393015 8.22471318 5.30487924 8.86742131], weights: [0.25018822 0.26441994 0.48539183], train_wt_loss:  36.4808, val_wt_loss: 37.3315, train_grp_loss: [11.81430628 13.10285062 10.66874336], val_grp_loss: [12.70528911 12.4852322  12.14015261], train_hist_grp_loss: [17.44676675 19.29093418 39.53819854], cur_train_grp_loss: [0.09451523 0.10481951 0.21338361], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6771, max_kl_dist_index: 0, max_train_grp_loss:  13.1029, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7053, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2134, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:51:55,715 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  184, train_loss:  12.1603, val_loss:  12.4440, grad_norm: 0.0177, live_grad: 0.0000, reward_err: 0.0102, 0.0143, 0.0001, KL_dist: 0.6772, 0.3163, 0.6697, param: [5.46397896 8.2243762  5.30587159 8.86953675], weights: [0.24973478 0.26402235 0.48624287], train_wt_loss:  36.4810, val_wt_loss: 37.3319, train_grp_loss: [11.81420787 13.10326591 10.66830528], val_grp_loss: [12.70537737 12.48571367 12.14007189], train_hist_grp_loss: [17.5412812  19.39575699 39.75157341], cur_train_grp_loss: [0.09451445 0.1048228  0.21337487], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6772, max_kl_dist_index: 0, max_train_grp_loss:  13.1033, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7054, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2134, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:51:56,738 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  185, train_loss:  12.1604, val_loss:  12.4441, grad_norm: 0.0179, live_grad: 0.0000, reward_err: 0.0102, 0.0143, 0.0001, KL_dist: 0.6773, 0.3164, 0.6698, param: [5.46402692 8.22403982 5.30686526 8.87165802], weights: [0.24928146 0.26362463 0.48709391], train_wt_loss:  36.4812, val_wt_loss: 37.3324, train_grp_loss: [11.81410797 13.10368427 10.66786633], val_grp_loss: [12.70546438 12.48619864 12.13999078], train_hist_grp_loss: [17.63579486 19.50058312 39.96493951], cur_train_grp_loss: [0.09451366 0.10482613 0.21336611], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6773, max_kl_dist_index: 0, max_train_grp_loss:  13.1037, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7055, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2134, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:51:57,791 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  186, train_loss:  12.1605, val_loss:  12.4443, grad_norm: 0.0180, live_grad: 0.0000, reward_err: 0.0102, 0.0143, 0.0001, KL_dist: 0.6775, 0.3164, 0.6700, param: [5.46407403 8.22370405 5.30786028 8.87378511], weights: [0.24882825 0.26322681 0.48794494], train_wt_loss:  36.4814, val_wt_loss: 37.3329, train_grp_loss: [11.81400659 13.10410571 10.66742652], val_grp_loss: [12.70555016 12.48668713 12.13990927], train_hist_grp_loss: [17.73030773 19.60541259 40.17829684], cur_train_grp_loss: [0.09451286 0.10482947 0.21335733], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6775, max_kl_dist_index: 0, max_train_grp_loss:  13.1041, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7056, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2134, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:51:58,828 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  187, train_loss:  12.1605, val_loss:  12.4445, grad_norm: 0.0181, live_grad: 0.0000, reward_err: 0.0102, 0.0143, 0.0001, KL_dist: 0.6776, 0.3165, 0.6701, param: [5.46412029 8.22336887 5.30885663 8.87591802], weights: [0.24837517 0.26282887 0.48879596], train_wt_loss:  36.4815, val_wt_loss: 37.3334, train_grp_loss: [11.81390372 13.10453021 10.66698584], val_grp_loss: [12.7056347  12.48717913 12.13982736], train_hist_grp_loss: [17.82481978 19.71024544 40.39164537], cur_train_grp_loss: [0.09451205 0.10483285 0.21334853], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6776, max_kl_dist_index: 0, max_train_grp_loss:  13.1045, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7056, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2133, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:51:59,896 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  188, train_loss:  12.1606, val_loss:  12.4446, grad_norm: 0.0183, live_grad: 0.0000, reward_err: 0.0102, 0.0143, 0.0001, KL_dist: 0.6778, 0.3166, 0.6702, param: [5.46416571 8.22303429 5.30985431 8.87805676], weights: [0.24792221 0.26243083 0.48964696], train_wt_loss:  36.4817, val_wt_loss: 37.3339, train_grp_loss: [11.81379938 13.10495779 10.66654431], val_grp_loss: [12.70571801 12.48767465 12.13974506], train_hist_grp_loss: [17.91933101 19.81508168 40.60498509], cur_train_grp_loss: [0.09451123 0.10483624 0.21333972], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6778, max_kl_dist_index: 0, max_train_grp_loss:  13.1050, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7057, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2133, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:52:00,908 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  189, train_loss:  12.1606, val_loss:  12.4448, grad_norm: 0.0184, live_grad: 0.0000, reward_err: 0.0102, 0.0143, 0.0001, KL_dist: 0.6779, 0.3167, 0.6704, param: [5.46421027 8.22270029 5.31085333 8.88020133], weights: [0.24746938 0.26203268 0.49049794], train_wt_loss:  36.4819, val_wt_loss: 37.3344, train_grp_loss: [11.81369357 13.10538845 10.66610192], val_grp_loss: [12.70580009 12.48817368 12.13966237], train_hist_grp_loss: [18.0138414  19.91992134 40.81831597], cur_train_grp_loss: [0.0945104  0.10483966 0.21333089], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6779, max_kl_dist_index: 0, max_train_grp_loss:  13.1054, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7058, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2133, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:52:01,940 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  190, train_loss:  12.1607, val_loss:  12.4450, grad_norm: 0.0186, live_grad: 0.0000, reward_err: 0.0102, 0.0143, 0.0001, KL_dist: 0.6781, 0.3168, 0.6705, param: [5.46425397 8.22236688 5.31185369 8.88235173], weights: [0.24701667 0.26163443 0.49134889], train_wt_loss:  36.4821, val_wt_loss: 37.3349, train_grp_loss: [11.81358629 13.10582217 10.66565867], val_grp_loss: [12.70588094 12.48867622 12.1395793 ], train_hist_grp_loss: [18.10835095 20.02476445 41.03163801], cur_train_grp_loss: [0.09450955 0.10484311 0.21332204], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6781, max_kl_dist_index: 0, max_train_grp_loss:  13.1058, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7059, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2133, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:52:02,979 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  191, train_loss:  12.1608, val_loss:  12.4451, grad_norm: 0.0187, live_grad: 0.0000, reward_err: 0.0102, 0.0143, 0.0001, KL_dist: 0.6782, 0.3168, 0.6707, param: [5.46429683 8.22203404 5.31285539 8.88450795], weights: [0.2465641  0.26123609 0.49219981], train_wt_loss:  36.4823, val_wt_loss: 37.3354, train_grp_loss: [11.81347755 13.10625898 10.66521456], val_grp_loss: [12.70596057 12.48918229 12.13949584], train_hist_grp_loss: [18.20285964 20.12961102 41.24495119], cur_train_grp_loss: [0.09450869 0.10484658 0.21331317], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6782, max_kl_dist_index: 0, max_train_grp_loss:  13.1063, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7060, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2133, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:52:04,027 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  192, train_loss:  12.1608, val_loss:  12.4453, grad_norm: 0.0189, live_grad: 0.0000, reward_err: 0.0102, 0.0143, 0.0001, KL_dist: 0.6784, 0.3169, 0.6708, param: [5.46433882 8.22170177 5.31385842 8.88667001], weights: [0.24611166 0.26083764 0.49305069], train_wt_loss:  36.4825, val_wt_loss: 37.3359, train_grp_loss: [11.81336735 13.10669886 10.66476961], val_grp_loss: [12.70603897 12.48969187 12.139412  ], train_hist_grp_loss: [18.29736746 20.2344611  41.45825548], cur_train_grp_loss: [0.09450782 0.10485007 0.21330429], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6784, max_kl_dist_index: 0, max_train_grp_loss:  13.1067, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7060, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2133, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:52:05,086 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  193, train_loss:  12.1609, val_loss:  12.4455, grad_norm: 0.0190, live_grad: 0.0000, reward_err: 0.0102, 0.0143, 0.0001, KL_dist: 0.6785, 0.3170, 0.6710, param: [5.46437995 8.22137007 5.3148628  8.88883791], weights: [0.24565936 0.26043911 0.49390153], train_wt_loss:  36.4827, val_wt_loss: 37.3364, train_grp_loss: [11.81325569 13.10714182 10.66432381], val_grp_loss: [12.70611616 12.49020497 12.13932778], train_hist_grp_loss: [18.3918744  20.33931469 41.67155087], cur_train_grp_loss: [0.09450694 0.10485359 0.21329539], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6785, max_kl_dist_index: 0, max_train_grp_loss:  13.1071, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7061, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2133, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:52:06,144 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  194, train_loss:  12.1610, val_loss:  12.4456, grad_norm: 0.0192, live_grad: 0.0000, reward_err: 0.0102, 0.0143, 0.0001, KL_dist: 0.6787, 0.3171, 0.6711, param: [5.46442023 8.22103893 5.31586851 8.89101163], weights: [0.2452072  0.26004048 0.49475232], train_wt_loss:  36.4829, val_wt_loss: 37.3369, train_grp_loss: [11.81314258 13.10758786 10.66387716], val_grp_loss: [12.70619214 12.4907216  12.13924319], train_hist_grp_loss: [18.48638045 20.44417182 41.88483735], cur_train_grp_loss: [0.09450605 0.10485713 0.21328648], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6787, max_kl_dist_index: 0, max_train_grp_loss:  13.1076, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7062, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2133, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:52:07,176 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  195, train_loss:  12.1610, val_loss:  12.4458, grad_norm: 0.0193, live_grad: 0.0000, reward_err: 0.0102, 0.0143, 0.0001, KL_dist: 0.6788, 0.3172, 0.6713, param: [5.46445964 8.22070835 5.31687556 8.89319119], weights: [0.24475518 0.25964176 0.49560306], train_wt_loss:  36.4830, val_wt_loss: 37.3374, train_grp_loss: [11.81302803 13.10803698 10.66342966], val_grp_loss: [12.7062669  12.49124175 12.13915823], train_hist_grp_loss: [18.58088559 20.54903252 42.09811489], cur_train_grp_loss: [0.09450514 0.1048607  0.21327754], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6788, max_kl_dist_index: 0, max_train_grp_loss:  13.1080, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7063, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2133, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:52:08,177 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  196, train_loss:  12.1611, val_loss:  12.4460, grad_norm: 0.0195, live_grad: 0.0000, reward_err: 0.0102, 0.0143, 0.0001, KL_dist: 0.6790, 0.3172, 0.6714, param: [5.46449819 8.22037831 5.31788395 8.89537659], weights: [0.2443033  0.25924296 0.49645374], train_wt_loss:  36.4832, val_wt_loss: 37.3380, train_grp_loss: [11.81291203 13.10848918 10.66298132], val_grp_loss: [12.70634046 12.49176542 12.13907291], train_hist_grp_loss: [18.67538981 20.65389682 42.31138348], cur_train_grp_loss: [0.09450422 0.1048643  0.21326859], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6790, max_kl_dist_index: 0, max_train_grp_loss:  13.1085, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7063, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2133, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:52:09,197 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  197, train_loss:  12.1611, val_loss:  12.4462, grad_norm: 0.0196, live_grad: 0.0000, reward_err: 0.0102, 0.0143, 0.0001, KL_dist: 0.6791, 0.3173, 0.6716, param: [5.46453587 8.22004882 5.31889368 8.89756782], weights: [0.24385157 0.25884408 0.49730435], train_wt_loss:  36.4834, val_wt_loss: 37.3385, train_grp_loss: [11.8127946  13.10894446 10.66253215], val_grp_loss: [12.70641281 12.49229263 12.13898722], train_hist_grp_loss: [18.76989311 20.75876473 42.52464311], cur_train_grp_loss: [0.0945033  0.10486791 0.21325963], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6791, max_kl_dist_index: 0, max_train_grp_loss:  13.1089, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7064, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2133, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:52:10,219 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  198, train_loss:  12.1612, val_loss:  12.4463, grad_norm: 0.0198, live_grad: 0.0000, reward_err: 0.0102, 0.0143, 0.0001, KL_dist: 0.6792, 0.3174, 0.6717, param: [5.46457269 8.21971988 5.31990475 8.8997649 ], weights: [0.24339999 0.25844511 0.4981549 ], train_wt_loss:  36.4836, val_wt_loss: 37.3390, train_grp_loss: [11.81267573 13.10940283 10.66208213], val_grp_loss: [12.70648396 12.49282335 12.13890116], train_hist_grp_loss: [18.86439547 20.86363629 42.73789375], cur_train_grp_loss: [0.09450236 0.10487156 0.21325064], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6792, max_kl_dist_index: 0, max_train_grp_loss:  13.1094, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7065, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2133, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:52:11,246 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  199, train_loss:  12.1613, val_loss:  12.4465, grad_norm: 0.0199, live_grad: 0.0000, reward_err: 0.0102, 0.0143, 0.0001, KL_dist: 0.6794, 0.3175, 0.6719, param: [5.46460863 8.21939146 5.32091716 8.90196781], weights: [0.24294855 0.25804607 0.49900537], train_wt_loss:  36.4838, val_wt_loss: 37.3395, train_grp_loss: [11.81255544 13.10986427 10.66163128], val_grp_loss: [12.70655391 12.49335761 12.13881475], train_hist_grp_loss: [18.95889687 20.96851151 42.95113539], cur_train_grp_loss: [0.09450141 0.10487522 0.21324164], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6794, max_kl_dist_index: 0, max_train_grp_loss:  13.1099, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7066, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2132, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:52:12,194 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1654] - INFO: Iteration:  199, train_loss:  12.1613, val_loss:  12.4465, grad_norm: 0.0199,  live_grad: 0.0000, reward_err: 0.0102, 0.0143, 0.0001, KL_dist: 0.6794, 0.3175, 0.6719, param: [5.46460863 8.21939146 5.32091716 8.90196781], weights: [0.24294855 0.25804607 0.49900537], train_wt_loss:  36.4838, val_wt_loss: 37.3395, train_grp_loss: [11.81255544 13.10986427 10.66163128], val_grp_loss: [12.70655391 12.49335761 12.13881475], train_hist_grp_loss: [18.95889687 20.96851151 42.95113539], cur_train_grp_loss: [0.09450141 0.10487522 0.21324164], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6794, max_kl_dist_index: 0, max_train_grp_loss:  13.1099, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7066, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2132, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:52:12,426 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:388] - INFO: Policy parameter learned solely on the preference data rdpo: [5.46460863 8.21939146 5.32091716 8.90196781].
2024-10-07 00:52:12,778 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Uniform reward: 3.8318, 3.8318, 3.1647
2024-10-07 00:52:12,779 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Optimal reward: 3.8678, 7.2446, 3.2763
2024-10-07 00:52:12,779 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Policy reward: 3.8282, 7.1412, 3.2759
2024-10-07 00:52:12,780 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:402] - INFO: Reward Error: 0.0102, 0.0143, 0.0001
2024-10-07 00:52:13,483 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:417] - INFO: Optimal reward: 3.8678, 7.2446, 3.2763
Known param reward: [[3.867779541015625, 6.77779443359375, 3.255072021484375], [3.441058349609375, 7.24455908203125, 3.05710986328125], [3.841189453125, 7.1339345703125, 3.27631982421875]], Known param reward error: [[0.0, 0.06442968345654335, 0.0064852651372159075], [0.11032717529039895, 0.0, 0.06690737556116683], [0.006874768225192712, 0.015270013049259644, 0.0]].
