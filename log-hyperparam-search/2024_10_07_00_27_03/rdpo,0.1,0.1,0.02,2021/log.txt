2024-10-07 00:37:53,870 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log-hyperparam-search/2024_10_07_00_27_03/rdpo,0.1,0.1,0.02,2021
2024-10-07 00:37:53,872 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2021
2024-10-07 00:37:53,872 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-10-07 00:37:53,963 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.2351, l2 distance: 36.4442, acc: 0.90.
2024-10-07 00:37:53,964 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-10-07 00:37:53,965 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [ 9.05939251 17.1373287   9.50347978 12.39752865]
2024-10-07 00:37:54,184 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.8285, 7.1348, 3.2752
2024-10-07 00:37:54,413 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1314] - INFO: unique_group_ids: {0, 1, 2}
2024-10-07 00:37:55,643 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  0, train_loss:  12.1558, val_loss:  12.4221, grad_norm: 0.4595, live_grad: 0.0000, reward_err: 0.0104, 0.0142, 0.0002, KL_dist: 0.6568, 0.3052, 0.6500, param: [5.44248962 8.3005987  5.14424008 8.57363224], weights: [0.33288853 0.33281143 0.33430004], train_wt_loss:  36.4675, val_wt_loss: 37.2662, train_grp_loss: [11.80461978 13.07608153 10.73316709], val_grp_loss: [12.66630053 12.4532737  12.14593623], train_hist_grp_loss: [0.15100158 0.13942111 0.36256349], cur_train_grp_loss: [0.15100158 0.13942111 0.36256349], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6568, max_kl_dist_index: 0, max_train_grp_loss:  13.0761, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6663, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.3626, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:37:56,759 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  1, train_loss:  12.1558, val_loss:  12.4221, grad_norm: 0.0001, live_grad: 0.0000, reward_err: 0.0104, 0.0142, 0.0002, KL_dist: 0.6569, 0.3052, 0.6500, param: [5.44260824 8.30025507 5.14475441 8.57437301], weights: [0.33259833 0.33258896 0.33481271], train_wt_loss:  36.4675, val_wt_loss: 37.2664, train_grp_loss: [11.80476687 13.076004   10.7329941 ], val_grp_loss: [12.66653435 12.45319094 12.14595587], train_hist_grp_loss: [0.24543854 0.24402976 0.57722683], cur_train_grp_loss: [0.09443696 0.10460865 0.21466334], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6569, max_kl_dist_index: 0, max_train_grp_loss:  13.0760, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6665, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2147, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:37:57,812 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  2, train_loss:  12.1558, val_loss:  12.4222, grad_norm: 0.0001, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6569, 0.3052, 0.6501, param: [5.44272661 8.299912   5.14526918 8.57511599], weights: [0.33230801 0.33236624 0.33532576], train_wt_loss:  36.4675, val_wt_loss: 37.2666, train_grp_loss: [11.80491313 13.07592767 10.73282066], val_grp_loss: [12.66676748 12.45310954 12.14597518], train_hist_grp_loss: [0.33987667 0.34863779 0.79188671], cur_train_grp_loss: [0.09443813 0.10460803 0.21465988], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6569, max_kl_dist_index: 0, max_train_grp_loss:  13.0759, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6668, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2147, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:37:58,906 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  3, train_loss:  12.1558, val_loss:  12.4223, grad_norm: 0.0001, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6570, 0.3053, 0.6501, param: [5.44284472 8.29956949 5.14578439 8.57586117], weights: [0.33201755 0.33214328 0.33583917], train_wt_loss:  36.4675, val_wt_loss: 37.2668, train_grp_loss: [11.80505856 13.07585253 10.73264678], val_grp_loss: [12.66699993 12.4530295  12.14599418], train_hist_grp_loss: [0.43431598 0.45324521 1.00654312], cur_train_grp_loss: [0.09443931 0.10460742 0.21465641], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6570, max_kl_dist_index: 0, max_train_grp_loss:  13.0759, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6670, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2147, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:38:00,043 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  4, train_loss:  12.1558, val_loss:  12.4223, grad_norm: 0.0002, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6570, 0.3053, 0.6502, param: [5.44296258 8.29922753 5.14630005 8.57660856], weights: [0.33172698 0.33192007 0.33635295], train_wt_loss:  36.4675, val_wt_loss: 37.2669, train_grp_loss: [11.80520316 13.07577859 10.73247245], val_grp_loss: [12.66723169 12.45295082 12.14601285], train_hist_grp_loss: [0.52875644 0.55785203 1.22119606], cur_train_grp_loss: [0.09444047 0.10460682 0.21465294], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6570, max_kl_dist_index: 0, max_train_grp_loss:  13.0758, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6672, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2147, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:38:01,132 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  5, train_loss:  12.1558, val_loss:  12.4224, grad_norm: 0.0002, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6571, 0.3053, 0.6502, param: [5.44308017 8.29888612 5.14681616 8.57735815], weights: [0.33143627 0.33169662 0.3368671 ], train_wt_loss:  36.4675, val_wt_loss: 37.2671, train_grp_loss: [11.80534692 13.07570585 10.73229769], val_grp_loss: [12.66746276 12.4528735  12.1460312 ], train_hist_grp_loss: [0.62319807 0.66245826 1.43584551], cur_train_grp_loss: [0.09444163 0.10460623 0.21464945], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6571, max_kl_dist_index: 0, max_train_grp_loss:  13.0757, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6675, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2146, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:38:02,213 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  6, train_loss:  12.1558, val_loss:  12.4224, grad_norm: 0.0002, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6571, 0.3054, 0.6503, param: [5.4431975  8.29854526 5.14733271 8.57810996], weights: [0.33114545 0.33147293 0.33738162], train_wt_loss:  36.4675, val_wt_loss: 37.2673, train_grp_loss: [11.80548984 13.0756343  10.73212248], val_grp_loss: [12.66769315 12.45279754 12.14604924], train_hist_grp_loss: [0.71764085 0.76706391 1.65049146], cur_train_grp_loss: [0.09444278 0.10460565 0.21464595], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6571, max_kl_dist_index: 0, max_train_grp_loss:  13.0756, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6677, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2146, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:38:03,298 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  7, train_loss:  12.1558, val_loss:  12.4225, grad_norm: 0.0003, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6572, 0.3054, 0.6503, param: [5.44331457 8.29820496 5.14784971 8.57886398], weights: [0.33085449 0.331249   0.33789651], train_wt_loss:  36.4675, val_wt_loss: 37.2674, train_grp_loss: [11.80563194 13.07556395 10.73194683], val_grp_loss: [12.66792286 12.45272295 12.14606695], train_hist_grp_loss: [0.81208476 0.87166898 1.86513391], cur_train_grp_loss: [0.09444392 0.10460507 0.21464245], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6572, max_kl_dist_index: 0, max_train_grp_loss:  13.0756, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6679, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2146, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:38:04,298 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  8, train_loss:  12.1558, val_loss:  12.4225, grad_norm: 0.0003, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6572, 0.3054, 0.6503, param: [5.44343138 8.29786521 5.14836716 8.57962022], weights: [0.33056341 0.33102483 0.33841176], train_wt_loss:  36.4675, val_wt_loss: 37.2676, train_grp_loss: [11.8057732  13.0754948  10.73177073], val_grp_loss: [12.66815187 12.45264972 12.14608433], train_hist_grp_loss: [0.90652982 0.9762735  2.07977285], cur_train_grp_loss: [0.09444506 0.10460451 0.21463894], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6572, max_kl_dist_index: 0, max_train_grp_loss:  13.0755, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6682, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2146, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:38:05,314 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  9, train_loss:  12.1558, val_loss:  12.4226, grad_norm: 0.0004, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6573, 0.3054, 0.6504, param: [5.44354794 8.297526   5.14888506 8.58037868], weights: [0.33027221 0.33080042 0.33892737], train_wt_loss:  36.4675, val_wt_loss: 37.2678, train_grp_loss: [11.80591363 13.07542685 10.7315942 ], val_grp_loss: [12.6683802  12.45257785 12.1461014 ], train_hist_grp_loss: [1.000976   1.08087745 2.29440826], cur_train_grp_loss: [0.09444619 0.10460396 0.21463541], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6573, max_kl_dist_index: 0, max_train_grp_loss:  13.0754, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6684, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2146, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:38:06,321 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  10, train_loss:  12.1558, val_loss:  12.4227, grad_norm: 0.0004, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6573, 0.3055, 0.6504, param: [5.44366423 8.29718735 5.14940341 8.58113935], weights: [0.32998089 0.33057577 0.33944335], train_wt_loss:  36.4675, val_wt_loss: 37.2680, train_grp_loss: [11.80605323 13.0753601  10.73141722], val_grp_loss: [12.66860785 12.45250735 12.14611815], train_hist_grp_loss: [1.09542331 1.18548087 2.50904015], cur_train_grp_loss: [0.09444731 0.10460341 0.21463188], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6573, max_kl_dist_index: 0, max_train_grp_loss:  13.0754, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6686, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2146, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:38:07,337 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  11, train_loss:  12.1558, val_loss:  12.4227, grad_norm: 0.0004, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6574, 0.3055, 0.6505, param: [5.44378025 8.29684925 5.14992221 8.58190224], weights: [0.32968944 0.33035088 0.33995969], train_wt_loss:  36.4675, val_wt_loss: 37.2681, train_grp_loss: [11.806192   13.07529455 10.73123979], val_grp_loss: [12.66883481 12.45243821 12.14613458], train_hist_grp_loss: [1.18987174 1.29008375 2.72366849], cur_train_grp_loss: [0.09444843 0.10460288 0.21462834], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6574, max_kl_dist_index: 0, max_train_grp_loss:  13.0753, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6688, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2146, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:38:08,382 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  12, train_loss:  12.1558, val_loss:  12.4228, grad_norm: 0.0005, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6574, 0.3055, 0.6505, param: [5.44389602 8.2965117  5.15044147 8.58266736], weights: [0.32939787 0.33012575 0.34047639], train_wt_loss:  36.4675, val_wt_loss: 37.2683, train_grp_loss: [11.80632993 13.0752302  10.73106193], val_grp_loss: [12.66906109 12.45237044 12.14615069], train_hist_grp_loss: [1.28432128 1.39468611 2.93829329], cur_train_grp_loss: [0.09444954 0.10460236 0.2146248 ], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6574, max_kl_dist_index: 0, max_train_grp_loss:  13.0752, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6691, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2146, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:38:09,414 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  13, train_loss:  12.1558, val_loss:  12.4228, grad_norm: 0.0005, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6575, 0.3056, 0.6506, param: [5.44401153 8.29617469 5.15096117 8.58343471], weights: [0.32910617 0.32990038 0.34099345], train_wt_loss:  36.4675, val_wt_loss: 37.2685, train_grp_loss: [11.80646703 13.07516706 10.73088362], val_grp_loss: [12.66928668 12.45230404 12.14616647], train_hist_grp_loss: [1.37877192 1.49928795 3.15291453], cur_train_grp_loss: [0.09445064 0.10460184 0.21462124], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6575, max_kl_dist_index: 0, max_train_grp_loss:  13.0752, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6693, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2146, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:38:10,448 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  14, train_loss:  12.1558, val_loss:  12.4229, grad_norm: 0.0006, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6576, 0.3056, 0.6506, param: [5.44412677 8.29583823 5.15148133 8.58420428], weights: [0.32881436 0.32967478 0.34151087], train_wt_loss:  36.4675, val_wt_loss: 37.2687, train_grp_loss: [11.8066033  13.07510512 10.73070486], val_grp_loss: [12.66951159 12.45223901 12.14618194], train_hist_grp_loss: [1.47322365 1.60388928 3.3675322 ], cur_train_grp_loss: [0.09445174 0.10460134 0.21461767], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6576, max_kl_dist_index: 0, max_train_grp_loss:  13.0751, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6695, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2146, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:38:11,450 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  15, train_loss:  12.1558, val_loss:  12.4229, grad_norm: 0.0006, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6576, 0.3056, 0.6507, param: [5.44424175 8.29550232 5.15200194 8.58497608], weights: [0.32852242 0.32944893 0.34202864], train_wt_loss:  36.4675, val_wt_loss: 37.2688, train_grp_loss: [11.80673874 13.07504438 10.73052567], val_grp_loss: [12.66973581 12.45217535 12.14619709], train_hist_grp_loss: [1.56767648 1.70849012 3.5821463 ], cur_train_grp_loss: [0.09445283 0.10460084 0.2146141 ], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6576, max_kl_dist_index: 0, max_train_grp_loss:  13.0750, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6697, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2146, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:38:12,483 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  16, train_loss:  12.1558, val_loss:  12.4230, grad_norm: 0.0006, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6577, 0.3056, 0.6507, param: [5.44435647 8.29516696 5.15252301 8.58575011], weights: [0.32823037 0.32922286 0.34254678], train_wt_loss:  36.4675, val_wt_loss: 37.2690, train_grp_loss: [11.80687334 13.07498485 10.73034602], val_grp_loss: [12.66995935 12.45211306 12.14621192], train_hist_grp_loss: [1.66213039 1.81309048 3.79675681], cur_train_grp_loss: [0.09445391 0.10460036 0.21461051], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6577, max_kl_dist_index: 0, max_train_grp_loss:  13.0750, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6700, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2146, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:38:13,530 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  17, train_loss:  12.1558, val_loss:  12.4231, grad_norm: 0.0007, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6577, 0.3057, 0.6508, param: [5.44447092 8.29483214 5.15304454 8.58652637], weights: [0.32793819 0.32899654 0.34306527], train_wt_loss:  36.4675, val_wt_loss: 37.2692, train_grp_loss: [11.80700712 13.07492653 10.73016594], val_grp_loss: [12.6701822  12.45205214 12.14622643], train_hist_grp_loss: [1.75658537 1.91769036 4.01136373], cur_train_grp_loss: [0.09445499 0.10459988 0.21460692], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6577, max_kl_dist_index: 0, max_train_grp_loss:  13.0749, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6702, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2146, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:38:14,575 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  18, train_loss:  12.1558, val_loss:  12.4231, grad_norm: 0.0007, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6578, 0.3057, 0.6508, param: [5.44458511 8.29449786 5.15356652 8.58730487], weights: [0.32764589 0.32876999 0.34358411], train_wt_loss:  36.4675, val_wt_loss: 37.2694, train_grp_loss: [11.80714006 13.07486941 10.72998541], val_grp_loss: [12.67040437 12.45199259 12.14624062], train_hist_grp_loss: [1.85104143 2.02228977 4.22596705], cur_train_grp_loss: [0.09445606 0.10459941 0.21460332], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6578, max_kl_dist_index: 0, max_train_grp_loss:  13.0749, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6704, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2146, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:38:15,540 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  19, train_loss:  12.1558, val_loss:  12.4232, grad_norm: 0.0008, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6578, 0.3057, 0.6509, param: [5.44469904 8.29416413 5.15408896 8.58808561], weights: [0.32735348 0.32854321 0.34410331], train_wt_loss:  36.4675, val_wt_loss: 37.2696, train_grp_loss: [11.80727218 13.07481349 10.72980443], val_grp_loss: [12.67062586 12.45193441 12.1462545 ], train_hist_grp_loss: [1.94549855 2.12688873 4.44056676], cur_train_grp_loss: [0.09445712 0.10459896 0.21459971], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6578, max_kl_dist_index: 0, max_train_grp_loss:  13.0748, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6706, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2146, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:38:16,603 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  20, train_loss:  12.1558, val_loss:  12.4232, grad_norm: 0.0008, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6579, 0.3058, 0.6509, param: [5.4448127  8.29383095 5.15461185 8.58886859], weights: [0.32706095 0.32831619 0.34462286], train_wt_loss:  36.4675, val_wt_loss: 37.2697, train_grp_loss: [11.80740346 13.07475879 10.72962301], val_grp_loss: [12.67084666 12.45187761 12.14626805], train_hist_grp_loss: [2.03995673 2.23148723 4.65516285], cur_train_grp_loss: [0.09445818 0.10459851 0.21459609], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6579, max_kl_dist_index: 0, max_train_grp_loss:  13.0748, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6708, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2146, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:38:17,650 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  21, train_loss:  12.1558, val_loss:  12.4233, grad_norm: 0.0008, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6579, 0.3058, 0.6510, param: [5.4449261  8.2934983  5.15513521 8.58965381], weights: [0.3267683  0.32808894 0.34514276], train_wt_loss:  36.4675, val_wt_loss: 37.2699, train_grp_loss: [11.80753391 13.07470529 10.72944115], val_grp_loss: [12.67106678 12.45182218 12.14628129], train_hist_grp_loss: [2.13441596 2.3360853  4.86975531], cur_train_grp_loss: [0.09445923 0.10459807 0.21459246], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6579, max_kl_dist_index: 0, max_train_grp_loss:  13.0747, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6711, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2146, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:38:18,666 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  22, train_loss:  12.1558, val_loss:  12.4234, grad_norm: 0.0009, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6580, 0.3058, 0.6510, param: [5.44503923 8.2931662  5.15565902 8.59044127], weights: [0.32647553 0.32786146 0.34566301], train_wt_loss:  36.4675, val_wt_loss: 37.2701, train_grp_loss: [11.80766353 13.07465301 10.72925884], val_grp_loss: [12.67128622 12.45176813 12.1462942 ], train_hist_grp_loss: [2.22887623 2.44068295 5.08434413], cur_train_grp_loss: [0.09446027 0.10459764 0.21458882], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6580, max_kl_dist_index: 0, max_train_grp_loss:  13.0747, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6713, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2146, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:38:19,680 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  23, train_loss:  12.1558, val_loss:  12.4234, grad_norm: 0.0009, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6580, 0.3058, 0.6511, param: [5.4451521  8.29283464 5.1561833  8.59123097], weights: [0.32618264 0.32763374 0.34618362], train_wt_loss:  36.4675, val_wt_loss: 37.2703, train_grp_loss: [11.80779232 13.07460193 10.72907609], val_grp_loss: [12.67150497 12.45171545 12.1463068 ], train_hist_grp_loss: [2.32333754 2.54528017 5.29892931], cur_train_grp_loss: [0.09446131 0.10459722 0.21458518], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6580, max_kl_dist_index: 0, max_train_grp_loss:  13.0746, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6715, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2146, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:38:20,718 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  24, train_loss:  12.1558, val_loss:  12.4235, grad_norm: 0.0010, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6581, 0.3059, 0.6511, param: [5.4452647  8.29250362 5.15670803 8.59202292], weights: [0.32588964 0.32740579 0.34670457], train_wt_loss:  36.4675, val_wt_loss: 37.2705, train_grp_loss: [11.80792028 13.07455206 10.72889289], val_grp_loss: [12.67172304 12.45166415 12.14631909], train_hist_grp_loss: [2.41779988 2.64987699 5.51351083], cur_train_grp_loss: [0.09446234 0.10459682 0.21458152], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6581, max_kl_dist_index: 0, max_train_grp_loss:  13.0746, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6717, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2146, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:38:21,764 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  25, train_loss:  12.1558, val_loss:  12.4235, grad_norm: 0.0010, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6582, 0.3059, 0.6512, param: [5.44537703 8.29217314 5.15723323 8.59281713], weights: [0.32559653 0.32717761 0.34722586], train_wt_loss:  36.4675, val_wt_loss: 37.2706, train_grp_loss: [11.80804741 13.07450341 10.72870925], val_grp_loss: [12.67194042 12.45161423 12.14633105], train_hist_grp_loss: [2.51226324 2.7544734  5.72808869], cur_train_grp_loss: [0.09446336 0.10459642 0.21457786], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6582, max_kl_dist_index: 0, max_train_grp_loss:  13.0745, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6719, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2146, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:38:22,804 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  26, train_loss:  12.1558, val_loss:  12.4236, grad_norm: 0.0010, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6582, 0.3059, 0.6512, param: [5.4454891  8.2918432  5.1577589  8.59361358], weights: [0.32530329 0.3269492  0.34774751], train_wt_loss:  36.4675, val_wt_loss: 37.2708, train_grp_loss: [11.80817371 13.07445597 10.72852516], val_grp_loss: [12.67215713 12.45156569 12.1463427 ], train_hist_grp_loss: [2.60672762 2.85906943 5.94266287], cur_train_grp_loss: [0.09446438 0.10459603 0.21457418], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6582, max_kl_dist_index: 0, max_train_grp_loss:  13.0745, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6722, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2146, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:38:23,822 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  27, train_loss:  12.1559, val_loss:  12.4237, grad_norm: 0.0011, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6583, 0.3060, 0.6513, param: [5.44560091 8.2915138  5.15828502 8.59441228], weights: [0.32500995 0.32672055 0.3482695 ], train_wt_loss:  36.4676, val_wt_loss: 37.2710, train_grp_loss: [11.80829917 13.07440974 10.72834063], val_grp_loss: [12.67237315 12.45151853 12.14635403], train_hist_grp_loss: [2.70119301 2.96366508 6.15723337], cur_train_grp_loss: [0.09446539 0.10459565 0.2145705 ], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6583, max_kl_dist_index: 0, max_train_grp_loss:  13.0744, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6724, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2146, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:38:24,877 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  28, train_loss:  12.1559, val_loss:  12.4237, grad_norm: 0.0011, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6583, 0.3060, 0.6513, param: [5.44571244 8.29118494 5.15881161 8.59521324], weights: [0.32471649 0.32649168 0.34879183], train_wt_loss:  36.4676, val_wt_loss: 37.2712, train_grp_loss: [11.80842381 13.07436472 10.72815565], val_grp_loss: [12.67258849 12.45147274 12.14636504], train_hist_grp_loss: [2.7956594  3.06826036 6.37180019], cur_train_grp_loss: [0.09446639 0.10459528 0.21456681], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6583, max_kl_dist_index: 0, max_train_grp_loss:  13.0744, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6726, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2146, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:38:25,886 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  29, train_loss:  12.1559, val_loss:  12.4238, grad_norm: 0.0012, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6584, 0.3060, 0.6514, param: [5.44582371 8.29085662 5.15933866 8.59601646], weights: [0.32442291 0.32626258 0.34931451], train_wt_loss:  36.4676, val_wt_loss: 37.2714, train_grp_loss: [11.80854762 13.07432092 10.72797022], val_grp_loss: [12.67280315 12.45142834 12.14637574], train_hist_grp_loss: [2.89012679 3.17285527 6.5863633 ], cur_train_grp_loss: [0.09446739 0.10459492 0.21456311], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6584, max_kl_dist_index: 0, max_train_grp_loss:  13.0743, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6728, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2146, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:38:26,899 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  30, train_loss:  12.1559, val_loss:  12.4238, grad_norm: 0.0012, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6584, 0.3061, 0.6514, param: [5.44593471 8.29052883 5.15986619 8.59682194], weights: [0.32412923 0.32603325 0.34983752], train_wt_loss:  36.4676, val_wt_loss: 37.2715, train_grp_loss: [11.8086706  13.07427833 10.72778435], val_grp_loss: [12.67301712 12.45138532 12.14638612], train_hist_grp_loss: [2.98459517 3.27744984 6.8009227 ], cur_train_grp_loss: [0.09446838 0.10459457 0.2145594 ], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6584, max_kl_dist_index: 0, max_train_grp_loss:  13.0743, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6730, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2146, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:38:27,917 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  31, train_loss:  12.1559, val_loss:  12.4239, grad_norm: 0.0013, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6585, 0.3061, 0.6515, param: [5.44604544 8.29020158 5.16039417 8.59762967], weights: [0.32383542 0.32580369 0.35036088], train_wt_loss:  36.4676, val_wt_loss: 37.2717, train_grp_loss: [11.80879276 13.07423696 10.72759803], val_grp_loss: [12.67323042 12.45134369 12.14639619], train_hist_grp_loss: [3.07906454 3.38204407 7.01547839], cur_train_grp_loss: [0.09446936 0.10459423 0.21455569], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6585, max_kl_dist_index: 0, max_train_grp_loss:  13.0742, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6732, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2146, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:38:28,929 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  32, train_loss:  12.1559, val_loss:  12.4240, grad_norm: 0.0013, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6585, 0.3061, 0.6515, param: [5.4461559  8.28987486 5.16092263 8.59843967], weights: [0.32354151 0.32557391 0.35088458], train_wt_loss:  36.4676, val_wt_loss: 37.2719, train_grp_loss: [11.80891408 13.07419681 10.72741127], val_grp_loss: [12.67344303 12.45130343 12.14640594], train_hist_grp_loss: [3.17353488 3.48663796 7.23003035], cur_train_grp_loss: [0.09447034 0.1045939  0.21455196], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6585, max_kl_dist_index: 0, max_train_grp_loss:  13.0742, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6734, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2146, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:38:29,969 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  33, train_loss:  12.1559, val_loss:  12.4240, grad_norm: 0.0013, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6586, 0.3062, 0.6516, param: [5.4462661  8.28954868 5.16145155 8.59925193], weights: [0.32324749 0.32534389 0.35140862], train_wt_loss:  36.4676, val_wt_loss: 37.2721, train_grp_loss: [11.80903457 13.07415787 10.72722406], val_grp_loss: [12.67365496 12.45126456 12.14641537], train_hist_grp_loss: [3.26800619 3.59123154 7.44457858], cur_train_grp_loss: [0.09447131 0.10459357 0.21454823], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6586, max_kl_dist_index: 0, max_train_grp_loss:  13.0742, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6737, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2145, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:38:30,996 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  34, train_loss:  12.1559, val_loss:  12.4241, grad_norm: 0.0014, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6587, 0.3062, 0.6516, param: [5.44637602 8.28922303 5.16198094 8.60006646], weights: [0.32295335 0.32511365 0.35193299], train_wt_loss:  36.4676, val_wt_loss: 37.2723, train_grp_loss: [11.80915424 13.07412016 10.72703641], val_grp_loss: [12.67386621 12.45122708 12.14642449], train_hist_grp_loss: [3.36247847 3.6958248  7.65912306], cur_train_grp_loss: [0.09447228 0.10459326 0.21454448], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6587, max_kl_dist_index: 0, max_train_grp_loss:  13.0741, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6739, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2145, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:38:32,010 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  35, train_loss:  12.1559, val_loss:  12.4242, grad_norm: 0.0014, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6587, 0.3062, 0.6517, param: [5.44648568 8.28889792 5.1625108  8.60088326], weights: [0.32265911 0.32488319 0.3524577 ], train_wt_loss:  36.4676, val_wt_loss: 37.2725, train_grp_loss: [11.80927308 13.07408366 10.72684831], val_grp_loss: [12.67407678 12.45119098 12.1464333 ], train_hist_grp_loss: [3.4569517  3.80041776 7.87366379], cur_train_grp_loss: [0.09447323 0.10459296 0.21454073], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6587, max_kl_dist_index: 0, max_train_grp_loss:  13.0741, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6741, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2145, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:38:33,028 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  36, train_loss:  12.1559, val_loss:  12.4242, grad_norm: 0.0015, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6588, 0.3062, 0.6517, param: [5.44659507 8.28857334 5.16304114 8.60170233], weights: [0.32236475 0.3246525  0.35298275], train_wt_loss:  36.4676, val_wt_loss: 37.2726, train_grp_loss: [11.80939109 13.07404838 10.72665976], val_grp_loss: [12.67428667 12.45115628 12.14644179], train_hist_grp_loss: [3.55142589 3.90501043 8.08820075], cur_train_grp_loss: [0.09447418 0.10459267 0.21453697], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6588, max_kl_dist_index: 0, max_train_grp_loss:  13.0740, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6743, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2145, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:38:34,065 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  37, train_loss:  12.1559, val_loss:  12.4243, grad_norm: 0.0015, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6588, 0.3063, 0.6518, param: [5.44670418 8.28824929 5.16357194 8.60252367], weights: [0.32207029 0.32442158 0.35350813], train_wt_loss:  36.4676, val_wt_loss: 37.2728, train_grp_loss: [11.80950827 13.07401432 10.72647077], val_grp_loss: [12.67449588 12.45112295 12.14644996], train_hist_grp_loss: [3.64590101 4.00960282 8.30273395], cur_train_grp_loss: [0.09447513 0.10459239 0.2145332 ], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6588, max_kl_dist_index: 0, max_train_grp_loss:  13.0740, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6745, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2145, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:38:35,106 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  38, train_loss:  12.1559, val_loss:  12.4243, grad_norm: 0.0016, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6589, 0.3063, 0.6518, param: [5.44681303 8.28792577 5.16410321 8.60334729], weights: [0.32177572 0.32419044 0.35403384], train_wt_loss:  36.4676, val_wt_loss: 37.2730, train_grp_loss: [11.80962462 13.07398148 10.72628133], val_grp_loss: [12.67470441 12.45109102 12.14645782], train_hist_grp_loss: [3.74037708 4.11419493 8.51726336], cur_train_grp_loss: [0.09447607 0.10459211 0.21452942], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6589, max_kl_dist_index: 0, max_train_grp_loss:  13.0740, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6747, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2145, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:38:36,127 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  39, train_loss:  12.1559, val_loss:  12.4244, grad_norm: 0.0016, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6589, 0.3063, 0.6519, param: [5.4469216  8.28760279 5.16463496 8.60417318], weights: [0.32148104 0.32395908 0.35455988], train_wt_loss:  36.4677, val_wt_loss: 37.2732, train_grp_loss: [11.80974015 13.07394986 10.72609145], val_grp_loss: [12.67491226 12.45106048 12.14646537], train_hist_grp_loss: [3.83485408 4.21878678 8.73178899], cur_train_grp_loss: [0.094477   0.10459185 0.21452563], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6589, max_kl_dist_index: 0, max_train_grp_loss:  13.0739, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6749, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2145, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:38:37,152 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  40, train_loss:  12.1559, val_loss:  12.4245, grad_norm: 0.0016, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6590, 0.3064, 0.6519, param: [5.44702991 8.28728033 5.16516718 8.60500135], weights: [0.32118625 0.32372749 0.35508626], train_wt_loss:  36.4677, val_wt_loss: 37.2734, train_grp_loss: [11.80985485 13.07391947 10.72590111], val_grp_loss: [12.67511943 12.45103133 12.1464726 ], train_hist_grp_loss: [3.929332   4.32337838 8.94631082], cur_train_grp_loss: [0.09447792 0.1045916  0.21452183], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6590, max_kl_dist_index: 0, max_train_grp_loss:  13.0739, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6751, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2145, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:38:38,164 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  41, train_loss:  12.1559, val_loss:  12.4245, grad_norm: 0.0017, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6591, 0.3064, 0.6520, param: [5.44713794 8.2869584  5.16569988 8.60583179], weights: [0.32089135 0.32349569 0.35561296], train_wt_loss:  36.4677, val_wt_loss: 37.2736, train_grp_loss: [11.80996872 13.0738903  10.72571033], val_grp_loss: [12.67532591 12.45100356 12.14647952], train_hist_grp_loss: [4.02381084 4.42796974 9.16082884], cur_train_grp_loss: [0.09447884 0.10459136 0.21451802], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6591, max_kl_dist_index: 0, max_train_grp_loss:  13.0739, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6753, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2145, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:38:39,191 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  42, train_loss:  12.1559, val_loss:  12.4246, grad_norm: 0.0017, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6591, 0.3064, 0.6520, param: [5.4472457  8.286637   5.16623305 8.60666452], weights: [0.32059635 0.32326365 0.35614   ], train_wt_loss:  36.4677, val_wt_loss: 37.2737, train_grp_loss: [11.81008176 13.07386235 10.72551911], val_grp_loss: [12.67553172 12.45097719 12.14648612], train_hist_grp_loss: [4.11829059 4.53256086 9.37534305], cur_train_grp_loss: [0.09447975 0.10459112 0.21451421], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6591, max_kl_dist_index: 0, max_train_grp_loss:  13.0739, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6755, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2145, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:38:40,220 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  43, train_loss:  12.1559, val_loss:  12.4246, grad_norm: 0.0018, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6592, 0.3065, 0.6521, param: [5.44735318 8.28631613 5.1667667  8.60749954], weights: [0.32030124 0.3230314  0.35666736], train_wt_loss:  36.4677, val_wt_loss: 37.2739, train_grp_loss: [11.81019398 13.07383563 10.72532744], val_grp_loss: [12.67573685 12.45095222 12.14649242], train_hist_grp_loss: [4.21277124 4.63715176 9.58985343], cur_train_grp_loss: [0.09448065 0.1045909  0.21451038], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6592, max_kl_dist_index: 0, max_train_grp_loss:  13.0738, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6757, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2145, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:38:41,234 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  44, train_loss:  12.1559, val_loss:  12.4247, grad_norm: 0.0018, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6592, 0.3065, 0.6521, param: [5.4474604  8.28599579 5.16730082 8.60833684], weights: [0.32000603 0.32279893 0.35719504], train_wt_loss:  36.4677, val_wt_loss: 37.2741, train_grp_loss: [11.81030538 13.07381013 10.72513532], val_grp_loss: [12.67594131 12.45092864 12.14649839], train_hist_grp_loss: [4.30725279 4.74174245 9.80435998], cur_train_grp_loss: [0.09448155 0.10459069 0.21450655], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6592, max_kl_dist_index: 0, max_train_grp_loss:  13.0738, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6759, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2145, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:38:42,235 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  45, train_loss:  12.1559, val_loss:  12.4248, grad_norm: 0.0019, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6593, 0.3065, 0.6522, param: [5.44756734 8.28567597 5.16783542 8.60917643], weights: [0.31971071 0.32256624 0.35772305], train_wt_loss:  36.4677, val_wt_loss: 37.2743, train_grp_loss: [11.81041594 13.07378586 10.72494275], val_grp_loss: [12.67614508 12.45090645 12.14650406], train_hist_grp_loss: [ 4.40173524  4.84633293 10.01886268], cur_train_grp_loss: [0.09448244 0.10459048 0.21450271], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6593, max_kl_dist_index: 0, max_train_grp_loss:  13.0738, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6761, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2145, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:38:43,261 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  46, train_loss:  12.1559, val_loss:  12.4248, grad_norm: 0.0019, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6594, 0.3066, 0.6523, param: [5.44767401 8.28535667 5.1683705  8.6100183 ], weights: [0.31941528 0.32233333 0.35825139], train_wt_loss:  36.4677, val_wt_loss: 37.2745, train_grp_loss: [11.81052568 13.07376281 10.72474974], val_grp_loss: [12.67634817 12.45088566 12.14650942], train_hist_grp_loss: [ 4.49621856  4.95092321 10.23336154], cur_train_grp_loss: [0.09448333 0.10459029 0.21449886], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6594, max_kl_dist_index: 0, max_train_grp_loss:  13.0738, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6763, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2145, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:38:44,330 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  47, train_loss:  12.1559, val_loss:  12.4249, grad_norm: 0.0020, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6594, 0.3066, 0.6523, param: [5.4477804  8.28503791 5.16890606 8.61086247], weights: [0.31911976 0.32210019 0.35878005], train_wt_loss:  36.4677, val_wt_loss: 37.2747, train_grp_loss: [11.8106346  13.073741   10.72455628], val_grp_loss: [12.67655059 12.45086626 12.14651446], train_hist_grp_loss: [ 4.59070277  5.05551332 10.44785653], cur_train_grp_loss: [0.09448421 0.1045901  0.21449499], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6594, max_kl_dist_index: 0, max_train_grp_loss:  13.0737, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6766, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2145, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:38:45,372 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  48, train_loss:  12.1559, val_loss:  12.4250, grad_norm: 0.0020, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6595, 0.3066, 0.6524, param: [5.44788652 8.28471966 5.16944209 8.61170893], weights: [0.31882413 0.32186684 0.35930903], train_wt_loss:  36.4678, val_wt_loss: 37.2749, train_grp_loss: [11.81074269 13.07372041 10.72436237], val_grp_loss: [12.67675233 12.45084826 12.14651919], train_hist_grp_loss: [ 4.68518785  5.16010324 10.66234766], cur_train_grp_loss: [0.09448508 0.10458993 0.21449113], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6595, max_kl_dist_index: 0, max_train_grp_loss:  13.0737, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6768, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2145, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:38:46,377 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  49, train_loss:  12.1559, val_loss:  12.4250, grad_norm: 0.0021, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6595, 0.3067, 0.6524, param: [5.44799237 8.28440194 5.16997861 8.61255769], weights: [0.31852839 0.32163328 0.35983833], train_wt_loss:  36.4678, val_wt_loss: 37.2751, train_grp_loss: [11.81084995 13.07370105 10.72416802], val_grp_loss: [12.67695339 12.45083166 12.14652361], train_hist_grp_loss: [ 4.77967379  5.26469301 10.87683491], cur_train_grp_loss: [0.09448594 0.10458976 0.21448725], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6595, max_kl_dist_index: 0, max_train_grp_loss:  13.0737, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6770, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2145, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:38:47,402 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  50, train_loss:  12.1559, val_loss:  12.4251, grad_norm: 0.0021, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6596, 0.3067, 0.6525, param: [5.44809794 8.28408474 5.17051561 8.61340874], weights: [0.31823256 0.32139949 0.36036795], train_wt_loss:  36.4678, val_wt_loss: 37.2753, train_grp_loss: [11.81095639 13.07368292 10.72397321], val_grp_loss: [12.67715377 12.45081646 12.14652772], train_hist_grp_loss: [ 4.87416059  5.36928262 11.09131827], cur_train_grp_loss: [0.0944868  0.10458961 0.21448336], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6596, max_kl_dist_index: 0, max_train_grp_loss:  13.0737, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6772, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2145, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:38:48,427 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  51, train_loss:  12.1559, val_loss:  12.4251, grad_norm: 0.0021, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6597, 0.3067, 0.6525, param: [5.44820323 8.28376807 5.17105309 8.61426209], weights: [0.31793662 0.32116549 0.36089789], train_wt_loss:  36.4678, val_wt_loss: 37.2754, train_grp_loss: [11.81106201 13.07366602 10.72377796], val_grp_loss: [12.67735348 12.45080266 12.14653152], train_hist_grp_loss: [ 4.96864824  5.47387208 11.30579773], cur_train_grp_loss: [0.09448765 0.10458946 0.21447946], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6597, max_kl_dist_index: 0, max_train_grp_loss:  13.0737, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6774, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2145, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:38:49,474 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  52, train_loss:  12.1559, val_loss:  12.4252, grad_norm: 0.0022, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6597, 0.3068, 0.6526, param: [5.44830825 8.28345191 5.17159105 8.61511774], weights: [0.31764059 0.32093127 0.36142814], train_wt_loss:  36.4678, val_wt_loss: 37.2756, train_grp_loss: [11.8111668  13.07365036 10.72358227], val_grp_loss: [12.6775525  12.45079026 12.14653501], train_hist_grp_loss: [ 5.06313673  5.57846141 11.52027329], cur_train_grp_loss: [0.0944885  0.10458933 0.21447556], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6597, max_kl_dist_index: 0, max_train_grp_loss:  13.0737, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6776, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2145, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:38:50,498 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  53, train_loss:  12.1559, val_loss:  12.4253, grad_norm: 0.0022, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6598, 0.3068, 0.6526, param: [5.448413   8.28313628 5.17212949 8.6159757 ], weights: [0.31734445 0.32069684 0.36195871], train_wt_loss:  36.4678, val_wt_loss: 37.2758, train_grp_loss: [11.81127076 13.07363592 10.72338612], val_grp_loss: [12.67775086 12.45077926 12.14653818], train_hist_grp_loss: [ 5.15762607  5.68305061 11.73474494], cur_train_grp_loss: [0.09448933 0.1045892  0.21447165], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6598, max_kl_dist_index: 0, max_train_grp_loss:  13.0736, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6778, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2145, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:38:51,526 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  54, train_loss:  12.1559, val_loss:  12.4253, grad_norm: 0.0023, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6598, 0.3068, 0.6527, param: [5.44851746 8.28282116 5.17266842 8.61683595], weights: [0.31704821 0.32046219 0.3624896 ], train_wt_loss:  36.4678, val_wt_loss: 37.2760, train_grp_loss: [11.81137391 13.07362272 10.72318953], val_grp_loss: [12.67794853 12.45076966 12.14654105], train_hist_grp_loss: [ 5.25211623  5.7876397  11.94921266], cur_train_grp_loss: [0.09449017 0.10458909 0.21446772], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6598, max_kl_dist_index: 0, max_train_grp_loss:  13.0736, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6779, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2145, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:38:52,546 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  55, train_loss:  12.1560, val_loss:  12.4254, grad_norm: 0.0023, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6599, 0.3069, 0.6527, param: [5.44862165 8.28250657 5.17320784 8.61769852], weights: [0.31675187 0.32022733 0.36302079], train_wt_loss:  36.4679, val_wt_loss: 37.2762, train_grp_loss: [11.81147623 13.07361075 10.72299249], val_grp_loss: [12.67814553 12.45076146 12.14654361], train_hist_grp_loss: [ 5.34660723  5.89222868 12.16367645], cur_train_grp_loss: [0.09449099 0.10458898 0.21446379], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6599, max_kl_dist_index: 0, max_train_grp_loss:  13.0736, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6781, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2145, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:38:53,589 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  56, train_loss:  12.1560, val_loss:  12.4255, grad_norm: 0.0024, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6600, 0.3069, 0.6528, param: [5.44872557 8.28219249 5.17374774 8.61856339], weights: [0.31645544 0.31999226 0.3635523 ], train_wt_loss:  36.4679, val_wt_loss: 37.2764, train_grp_loss: [11.81157772 13.07360001 10.72279501], val_grp_loss: [12.67834185 12.45075467 12.14654585], train_hist_grp_loss: [ 5.44109904  5.99681756 12.3781363 ], cur_train_grp_loss: [0.09449181 0.10458889 0.21445985], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6600, max_kl_dist_index: 0, max_train_grp_loss:  13.0736, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6783, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2145, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:38:54,690 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  57, train_loss:  12.1560, val_loss:  12.4255, grad_norm: 0.0024, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6600, 0.3069, 0.6529, param: [5.4488292  8.28187893 5.17428812 8.61943058], weights: [0.3161589  0.31975697 0.36408413], train_wt_loss:  36.4679, val_wt_loss: 37.2766, train_grp_loss: [11.8116784  13.07359051 10.72259707], val_grp_loss: [12.6785375  12.45074929 12.14654779], train_hist_grp_loss: [ 5.53559166  6.10140637 12.5925922 ], cur_train_grp_loss: [0.09449262 0.1045888  0.2144559 ], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6600, max_kl_dist_index: 0, max_train_grp_loss:  13.0736, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6785, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2145, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:38:55,715 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  58, train_loss:  12.1560, val_loss:  12.4256, grad_norm: 0.0025, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6601, 0.3070, 0.6529, param: [5.44893256 8.28156589 5.17482899 8.62030007], weights: [0.31586227 0.31952147 0.36461626], train_wt_loss:  36.4679, val_wt_loss: 37.2768, train_grp_loss: [11.81177825 13.07358225 10.72239869], val_grp_loss: [12.67873247 12.45074531 12.14654942], train_hist_grp_loss: [ 5.63008508  6.20599509 12.80704414], cur_train_grp_loss: [0.09449343 0.10458872 0.21445194], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6601, max_kl_dist_index: 0, max_train_grp_loss:  13.0736, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6787, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2145, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:38:56,738 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  59, train_loss:  12.1560, val_loss:  12.4257, grad_norm: 0.0025, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6601, 0.3070, 0.6530, param: [5.44903564 8.28125336 5.17537035 8.62117188], weights: [0.31556554 0.31928576 0.3651487 ], train_wt_loss:  36.4679, val_wt_loss: 37.2770, train_grp_loss: [11.81187727 13.07357522 10.72219986], val_grp_loss: [12.67892677 12.45074273 12.14655075], train_hist_grp_loss: [ 5.72457931  6.31058375 13.02149211], cur_train_grp_loss: [0.09449423 0.10458866 0.21444797], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6601, max_kl_dist_index: 0, max_train_grp_loss:  13.0736, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6789, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2144, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:38:57,778 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  60, train_loss:  12.1560, val_loss:  12.4257, grad_norm: 0.0026, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6602, 0.3070, 0.6530, param: [5.44913844 8.28094135 5.1759122  8.622046  ], weights: [0.31526872 0.31904983 0.36568145], train_wt_loss:  36.4679, val_wt_loss: 37.2772, train_grp_loss: [11.81197548 13.07356943 10.72200059], val_grp_loss: [12.67912039 12.45074156 12.14655176], train_hist_grp_loss: [ 5.81907433  6.41517235 13.23593611], cur_train_grp_loss: [0.09449502 0.1045886  0.214444  ], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6602, max_kl_dist_index: 0, max_train_grp_loss:  13.0736, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6791, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2144, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:38:58,779 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  61, train_loss:  12.1560, val_loss:  12.4258, grad_norm: 0.0026, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6603, 0.3071, 0.6531, param: [5.44924096 8.28062985 5.17645454 8.62292244], weights: [0.3149718 0.3188137 0.3662145], train_wt_loss:  36.4679, val_wt_loss: 37.2774, train_grp_loss: [11.81207287 13.07356488 10.72180086], val_grp_loss: [12.67931333 12.45074181 12.14655246], train_hist_grp_loss: [ 5.91357013  6.5197609  13.45037612], cur_train_grp_loss: [0.0944958  0.10458856 0.21444001], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6603, max_kl_dist_index: 0, max_train_grp_loss:  13.0736, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6793, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2144, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:38:59,785 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  62, train_loss:  12.1560, val_loss:  12.4259, grad_norm: 0.0027, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6603, 0.3071, 0.6531, param: [5.44934321 8.28031886 5.17699737 8.6238012 ], weights: [0.31467478 0.31857736 0.36674786], train_wt_loss:  36.4680, val_wt_loss: 37.2776, train_grp_loss: [11.81216943 13.07356156 10.72160069], val_grp_loss: [12.67950561 12.45074346 12.14655286], train_hist_grp_loss: [ 6.00806672  6.62434942 13.66481214], cur_train_grp_loss: [0.09449658 0.10458852 0.21443602], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6603, max_kl_dist_index: 0, max_train_grp_loss:  13.0736, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6795, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2144, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:39:00,810 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  63, train_loss:  12.1560, val_loss:  12.4259, grad_norm: 0.0027, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6604, 0.3071, 0.6532, param: [5.44944517 8.28000839 5.17754068 8.62468229], weights: [0.31437767 0.3183408  0.36728152], train_wt_loss:  36.4680, val_wt_loss: 37.2778, train_grp_loss: [11.81226517 13.07355949 10.72140007], val_grp_loss: [12.6796972  12.45074652 12.14655295], train_hist_grp_loss: [ 6.10256407  6.72893792 13.87924415], cur_train_grp_loss: [0.09449736 0.10458849 0.21443201], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6604, max_kl_dist_index: 0, max_train_grp_loss:  13.0736, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6797, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2144, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:39:01,825 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  64, train_loss:  12.1560, val_loss:  12.4260, grad_norm: 0.0028, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6604, 0.3072, 0.6532, param: [5.44954685 8.27969843 5.17808449 8.62556569], weights: [0.31408047 0.31810404 0.36781549], train_wt_loss:  36.4680, val_wt_loss: 37.2780, train_grp_loss: [11.81236009 13.07355865 10.721199  ], val_grp_loss: [12.67988813 12.45075099 12.14655274], train_hist_grp_loss: [ 6.19706219  6.83352639 14.09367216], cur_train_grp_loss: [0.09449812 0.10458848 0.214428  ], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6604, max_kl_dist_index: 0, max_train_grp_loss:  13.0736, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6799, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2144, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:39:02,860 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  65, train_loss:  12.1560, val_loss:  12.4261, grad_norm: 0.0028, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6605, 0.3072, 0.6533, param: [5.44964826 8.27938898 5.17862879 8.62645142], weights: [0.31378317 0.31786707 0.36834976], train_wt_loss:  36.4680, val_wt_loss: 37.2782, train_grp_loss: [11.81245419 13.07355906 10.72099749], val_grp_loss: [12.68007838 12.45075687 12.14655221], train_hist_grp_loss: [ 6.29156107  6.93811486 14.30809614], cur_train_grp_loss: [0.09449888 0.10458847 0.21442398], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6605, max_kl_dist_index: 0, max_train_grp_loss:  13.0736, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6801, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2144, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:39:03,874 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  66, train_loss:  12.1560, val_loss:  12.4261, grad_norm: 0.0029, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6606, 0.3072, 0.6534, param: [5.44974938 8.27908004 5.17917359 8.62733947], weights: [0.31348578 0.3176299  0.36888432], train_wt_loss:  36.4680, val_wt_loss: 37.2783, train_grp_loss: [11.81254747 13.0735607  10.72079552], val_grp_loss: [12.68026795 12.45076416 12.14655139], train_hist_grp_loss: [ 6.38606071  7.04270333 14.52251609], cur_train_grp_loss: [0.09449963 0.10458847 0.21441995], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6606, max_kl_dist_index: 0, max_train_grp_loss:  13.0736, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6803, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2144, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:39:04,916 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  67, train_loss:  12.1560, val_loss:  12.4262, grad_norm: 0.0029, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6606, 0.3073, 0.6534, param: [5.44985022 8.27877162 5.17971887 8.62822986], weights: [0.3131883  0.31739251 0.36941919], train_wt_loss:  36.4681, val_wt_loss: 37.2785, train_grp_loss: [11.81263993 13.07356359 10.72059311], val_grp_loss: [12.68045686 12.45077287 12.14655025], train_hist_grp_loss: [ 6.48056109  7.14729182 14.736932  ], cur_train_grp_loss: [0.09450038 0.10458849 0.21441591], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6606, max_kl_dist_index: 0, max_train_grp_loss:  13.0736, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6805, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2144, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:39:05,928 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  68, train_loss:  12.1560, val_loss:  12.4262, grad_norm: 0.0030, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6607, 0.3073, 0.6535, param: [5.44995078 8.2784637  5.18026465 8.62912257], weights: [0.31289072 0.31715492 0.36995436], train_wt_loss:  36.4681, val_wt_loss: 37.2787, train_grp_loss: [11.81273157 13.07356772 10.72039025], val_grp_loss: [12.68064509 12.45078299 12.14654881], train_hist_grp_loss: [ 6.57506221  7.25188033 14.95134386], cur_train_grp_loss: [0.09450112 0.10458851 0.21441186], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6607, max_kl_dist_index: 0, max_train_grp_loss:  13.0736, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6806, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2144, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:39:06,955 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  69, train_loss:  12.1560, val_loss:  12.4263, grad_norm: 0.0030, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6608, 0.3073, 0.6535, param: [5.45005105 8.27815628 5.18081093 8.63001762], weights: [0.31259306 0.31691713 0.37048982], train_wt_loss:  36.4681, val_wt_loss: 37.2789, train_grp_loss: [11.81282239 13.0735731  10.72018694], val_grp_loss: [12.68083265 12.45079452 12.14654706], train_hist_grp_loss: [ 6.66956406  7.35646887 15.16575166], cur_train_grp_loss: [0.09450185 0.10458854 0.21440781], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6608, max_kl_dist_index: 0, max_train_grp_loss:  13.0736, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6808, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2144, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:39:07,949 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  70, train_loss:  12.1560, val_loss:  12.4264, grad_norm: 0.0031, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6608, 0.3074, 0.6536, param: [5.45015105 8.27784938 5.1813577  8.630915  ], weights: [0.3122953  0.31667912 0.37102557], train_wt_loss:  36.4681, val_wt_loss: 37.2791, train_grp_loss: [11.81291239 13.07357972 10.71998319], val_grp_loss: [12.68101953 12.45080748 12.14654501], train_hist_grp_loss: [ 6.76406664  7.46105745 15.3801554 ], cur_train_grp_loss: [0.09450258 0.10458858 0.21440374], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6608, max_kl_dist_index: 0, max_train_grp_loss:  13.0736, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6810, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2144, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:39:08,972 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  71, train_loss:  12.1560, val_loss:  12.4264, grad_norm: 0.0031, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6609, 0.3074, 0.6536, param: [5.45025076 8.27754298 5.18190497 8.63181471], weights: [0.31199746 0.31644092 0.37156163], train_wt_loss:  36.4681, val_wt_loss: 37.2793, train_grp_loss: [11.81300157 13.07358758 10.71977899], val_grp_loss: [12.68120575 12.45082184 12.14654266], train_hist_grp_loss: [ 6.85856994  7.56564609 15.59455507], cur_train_grp_loss: [0.0945033  0.10458864 0.21439966], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6609, max_kl_dist_index: 0, max_train_grp_loss:  13.0736, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6812, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2144, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:39:09,985 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  72, train_loss:  12.1560, val_loss:  12.4265, grad_norm: 0.0032, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6609, 0.3074, 0.6537, param: [5.45035019 8.27723709 5.18245273 8.63271676], weights: [0.31169952 0.31620251 0.37209797], train_wt_loss:  36.4681, val_wt_loss: 37.2795, train_grp_loss: [11.81308994 13.07359669 10.71957434], val_grp_loss: [12.68139129 12.45083763 12.14654   ], train_hist_grp_loss: [ 6.95307395  7.67023479 15.80895065], cur_train_grp_loss: [0.09450401 0.1045887  0.21439558], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6609, max_kl_dist_index: 0, max_train_grp_loss:  13.0736, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6814, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2144, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:39:11,030 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  73, train_loss:  12.1561, val_loss:  12.4266, grad_norm: 0.0032, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6610, 0.3075, 0.6538, param: [5.45044933 8.2769317  5.183001   8.63362115], weights: [0.3114015  0.3159639  0.37263461], train_wt_loss:  36.4682, val_wt_loss: 37.2797, train_grp_loss: [11.81317748 13.07360705 10.71936924], val_grp_loss: [12.68157616 12.45085483 12.14653703], train_hist_grp_loss: [ 7.04757867  7.77482357 16.02334213], cur_train_grp_loss: [0.09450472 0.10458877 0.21439149], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6610, max_kl_dist_index: 0, max_train_grp_loss:  13.0736, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6816, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2144, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:39:12,060 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  74, train_loss:  12.1561, val_loss:  12.4266, grad_norm: 0.0033, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6611, 0.3075, 0.6538, param: [5.45054819 8.27662682 5.18354976 8.63452788], weights: [0.31110338 0.31572508 0.37317153], train_wt_loss:  36.4682, val_wt_loss: 37.2799, train_grp_loss: [11.81326421 13.07361865 10.71916369], val_grp_loss: [12.68176036 12.45087345 12.14653376], train_hist_grp_loss: [ 7.14208409  7.87941242 16.23772952], cur_train_grp_loss: [0.09450542 0.10458886 0.21438738], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6611, max_kl_dist_index: 0, max_train_grp_loss:  13.0736, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6818, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2144, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:39:13,068 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  75, train_loss:  12.1561, val_loss:  12.4267, grad_norm: 0.0033, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6611, 0.3075, 0.6539, param: [5.45064677 8.27632244 5.18409902 8.63543696], weights: [0.31080518 0.31548607 0.37370875], train_wt_loss:  36.4682, val_wt_loss: 37.2801, train_grp_loss: [11.81335012 13.0736315  10.7189577 ], val_grp_loss: [12.68194389 12.45089349 12.14653019], train_hist_grp_loss: [ 7.2365902   7.98400137 16.45211279], cur_train_grp_loss: [0.09450611 0.10458895 0.21438327], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6611, max_kl_dist_index: 0, max_train_grp_loss:  13.0736, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6819, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2144, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:39:14,111 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  76, train_loss:  12.1561, val_loss:  12.4268, grad_norm: 0.0034, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6612, 0.3076, 0.6539, param: [5.45074506 8.27601856 5.18464877 8.63634838], weights: [0.3105069  0.31524685 0.37424625], train_wt_loss:  36.4682, val_wt_loss: 37.2803, train_grp_loss: [11.81343522 13.0736456  10.71875126], val_grp_loss: [12.68212675 12.45091496 12.14652632], train_hist_grp_loss: [ 7.331097    8.08859042 16.66649195], cur_train_grp_loss: [0.0945068  0.10458905 0.21437915], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6612, max_kl_dist_index: 0, max_train_grp_loss:  13.0736, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6821, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2144, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:39:15,155 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  77, train_loss:  12.1561, val_loss:  12.4268, grad_norm: 0.0034, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6613, 0.3076, 0.6540, param: [5.45084307 8.27571518 5.18519903 8.63726214], weights: [0.31020852 0.31500743 0.37478404], train_wt_loss:  36.4682, val_wt_loss: 37.2805, train_grp_loss: [11.8135195  13.07366095 10.71854437], val_grp_loss: [12.68230893 12.45093784 12.14652214], train_hist_grp_loss: [ 7.42560449  8.19317959 16.88086697], cur_train_grp_loss: [0.09450748 0.10458916 0.21437503], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6613, max_kl_dist_index: 0, max_train_grp_loss:  13.0737, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6823, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2144, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:39:16,173 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  78, train_loss:  12.1561, val_loss:  12.4269, grad_norm: 0.0035, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6613, 0.3076, 0.6541, param: [5.45094079 8.27541231 5.1857498  8.63817826], weights: [0.30991007 0.31476781 0.37532212], train_wt_loss:  36.4683, val_wt_loss: 37.2807, train_grp_loss: [11.81360296 13.07367755 10.71833703], val_grp_loss: [12.68249045 12.45096215 12.14651766], train_hist_grp_loss: [ 7.52011264  8.29776888 17.09523786], cur_train_grp_loss: [0.09450816 0.10458929 0.21437089], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6613, max_kl_dist_index: 0, max_train_grp_loss:  13.0737, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6825, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2144, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:39:17,202 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  79, train_loss:  12.1561, val_loss:  12.4270, grad_norm: 0.0035, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6614, 0.3077, 0.6541, param: [5.45103822 8.27510993 5.18630106 8.63909672], weights: [0.30961152 0.314528   0.37586048], train_wt_loss:  36.4683, val_wt_loss: 37.2809, train_grp_loss: [11.8136856  13.0736954  10.71812924], val_grp_loss: [12.6826713  12.45098788 12.14651288], train_hist_grp_loss: [ 7.61462146  8.4023583  17.3096046 ], cur_train_grp_loss: [0.09450882 0.10458942 0.21436674], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6614, max_kl_dist_index: 0, max_train_grp_loss:  13.0737, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6827, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2144, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:39:18,246 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  80, train_loss:  12.1561, val_loss:  12.4270, grad_norm: 0.0036, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6614, 0.3077, 0.6542, param: [5.45113537 8.27480806 5.18685282 8.64001753], weights: [0.30931289 0.31428798 0.37639913], train_wt_loss:  36.4683, val_wt_loss: 37.2811, train_grp_loss: [11.81376743 13.07371451 10.71792101], val_grp_loss: [12.68285148 12.45101503 12.1465078 ], train_hist_grp_loss: [ 7.70913095  8.50694786 17.52396718], cur_train_grp_loss: [0.09450948 0.10458956 0.21436258], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6614, max_kl_dist_index: 0, max_train_grp_loss:  13.0737, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6829, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2144, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:39:19,271 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  81, train_loss:  12.1561, val_loss:  12.4271, grad_norm: 0.0036, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6615, 0.3077, 0.6542, param: [5.45123223 8.27450668 5.18740509 8.6409407 ], weights: [0.30901418 0.31404777 0.37693805], train_wt_loss:  36.4683, val_wt_loss: 37.2813, train_grp_loss: [11.81384845 13.07373486 10.71771233], val_grp_loss: [12.68303099 12.4510436  12.14650242], train_hist_grp_loss: [ 7.80364109  8.61153758 17.7383256 ], cur_train_grp_loss: [0.09451014 0.10458972 0.21435842], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6615, max_kl_dist_index: 0, max_train_grp_loss:  13.0737, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6830, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2144, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:39:20,304 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  82, train_loss:  12.1561, val_loss:  12.4272, grad_norm: 0.0037, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6616, 0.3078, 0.6543, param: [5.45132881 8.2742058  5.18795787 8.64186622], weights: [0.30871538 0.31380736 0.37747726], train_wt_loss:  36.4684, val_wt_loss: 37.2815, train_grp_loss: [11.81392865 13.07375647 10.7175032 ], val_grp_loss: [12.68320983 12.45107361 12.14649673], train_hist_grp_loss: [ 7.89815188  8.71612745 17.95267985], cur_train_grp_loss: [0.09451079 0.10458988 0.21435425], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6616, max_kl_dist_index: 0, max_train_grp_loss:  13.0738, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6832, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2144, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:39:21,315 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  83, train_loss:  12.1561, val_loss:  12.4273, grad_norm: 0.0037, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6616, 0.3078, 0.6544, param: [5.4514251  8.27390542 5.18851114 8.6427941 ], weights: [0.30841651 0.31356675 0.37801675], train_wt_loss:  36.4684, val_wt_loss: 37.2818, train_grp_loss: [11.81400803 13.07377933 10.71729362], val_grp_loss: [12.68338801 12.45110504 12.14649075], train_hist_grp_loss: [ 7.99266331  8.82071751 18.16702991], cur_train_grp_loss: [0.09451143 0.10459005 0.21435006], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6616, max_kl_dist_index: 0, max_train_grp_loss:  13.0738, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6834, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2144, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:39:22,326 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  84, train_loss:  12.1561, val_loss:  12.4273, grad_norm: 0.0038, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6617, 0.3078, 0.6544, param: [5.4515211  8.27360553 5.18906492 8.64372434], weights: [0.30811755 0.31332594 0.37855651], train_wt_loss:  36.4684, val_wt_loss: 37.2820, train_grp_loss: [11.81408661 13.07380344 10.7170836 ], val_grp_loss: [12.68356551 12.45113789 12.14648446], train_hist_grp_loss: [ 8.08717537  8.92530774 18.38137579], cur_train_grp_loss: [0.09451206 0.10459023 0.21434587], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6617, max_kl_dist_index: 0, max_train_grp_loss:  13.0738, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6836, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2143, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:39:23,351 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  85, train_loss:  12.1561, val_loss:  12.4274, grad_norm: 0.0038, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6618, 0.3079, 0.6545, param: [5.45161681 8.27330613 5.18961921 8.64465694], weights: [0.3078185  0.31308494 0.37909655], train_wt_loss:  36.4684, val_wt_loss: 37.2822, train_grp_loss: [11.81416436 13.07382881 10.71687313], val_grp_loss: [12.68374235 12.45117218 12.14647787], train_hist_grp_loss: [ 8.18168806  9.02989817 18.59571746], cur_train_grp_loss: [0.09451269 0.10459043 0.21434167], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6618, max_kl_dist_index: 0, max_train_grp_loss:  13.0738, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6837, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2143, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:39:24,398 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  86, train_loss:  12.1562, val_loss:  12.4275, grad_norm: 0.0039, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6618, 0.3079, 0.6545, param: [5.45171223 8.27300724 5.19017401 8.6455919 ], weights: [0.30751938 0.31284375 0.37963687], train_wt_loss:  36.4685, val_wt_loss: 37.2824, train_grp_loss: [11.81424131 13.07385544 10.71666221], val_grp_loss: [12.68391852 12.45120789 12.14647099], train_hist_grp_loss: [ 8.27620138  9.1344888  18.81005492], cur_train_grp_loss: [0.09451331 0.10459063 0.21433746], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6618, max_kl_dist_index: 0, max_train_grp_loss:  13.0739, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6839, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2143, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:39:25,419 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  87, train_loss:  12.1562, val_loss:  12.4275, grad_norm: 0.0039, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6619, 0.3079, 0.6546, param: [5.45180737 8.27270883 5.19072931 8.64652923], weights: [0.30722018 0.31260236 0.38017746], train_wt_loss:  36.4685, val_wt_loss: 37.2826, train_grp_loss: [11.81431744 13.07388332 10.71645084], val_grp_loss: [12.68409403 12.45124503 12.14646381], train_hist_grp_loss: [ 8.37071531  9.23907964 19.02438817], cur_train_grp_loss: [0.09451393 0.10459084 0.21433324], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6619, max_kl_dist_index: 0, max_train_grp_loss:  13.0739, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6841, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2143, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:39:26,435 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  88, train_loss:  12.1562, val_loss:  12.4276, grad_norm: 0.0040, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6620, 0.3080, 0.6547, param: [5.45190221 8.27241092 5.19128512 8.64746892], weights: [0.3069209  0.31236078 0.38071832], train_wt_loss:  36.4685, val_wt_loss: 37.2828, train_grp_loss: [11.81439276 13.07391246 10.71623903], val_grp_loss: [12.68426886 12.45128361 12.14645632], train_hist_grp_loss: [ 8.46522985  9.34367071 19.23871718], cur_train_grp_loss: [0.09451454 0.10459107 0.21432902], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6620, max_kl_dist_index: 0, max_train_grp_loss:  13.0739, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6843, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2143, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:39:27,484 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  89, train_loss:  12.1562, val_loss:  12.4277, grad_norm: 0.0040, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6620, 0.3080, 0.6547, param: [5.45199676 8.2721135  5.19184144 8.64841097], weights: [0.30662153 0.31211901 0.38125946], train_wt_loss:  36.4685, val_wt_loss: 37.2830, train_grp_loss: [11.81446727 13.07394286 10.71602677], val_grp_loss: [12.68444303 12.45132361 12.14644854], train_hist_grp_loss: [ 8.55974499  9.44826201 19.45304196], cur_train_grp_loss: [0.09451514 0.1045913  0.21432478], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6620, max_kl_dist_index: 0, max_train_grp_loss:  13.0739, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6844, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2143, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:39:28,515 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  90, train_loss:  12.1562, val_loss:  12.4277, grad_norm: 0.0041, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6621, 0.3081, 0.6548, param: [5.45209103 8.27181657 5.19239827 8.6493554 ], weights: [0.30632209 0.31187704 0.38180087], train_wt_loss:  36.4686, val_wt_loss: 37.2832, train_grp_loss: [11.81454096 13.07397451 10.71581406], val_grp_loss: [12.68461654 12.45136505 12.14644047], train_hist_grp_loss: [ 8.65426073  9.55285355 19.6673625 ], cur_train_grp_loss: [0.09451574 0.10459154 0.21432054], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6621, max_kl_dist_index: 0, max_train_grp_loss:  13.0740, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6846, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2143, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:39:29,562 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  91, train_loss:  12.1562, val_loss:  12.4278, grad_norm: 0.0041, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6622, 0.3081, 0.6548, param: [5.452185   8.27152012 5.19295561 8.6503022 ], weights: [0.30602258 0.31163488 0.38234254], train_wt_loss:  36.4686, val_wt_loss: 37.2834, train_grp_loss: [11.81461384 13.07400743 10.7156009 ], val_grp_loss: [12.68478938 12.45140792 12.14643209], train_hist_grp_loss: [ 8.74877706  9.65744535 19.88167878], cur_train_grp_loss: [0.09451633 0.1045918  0.21431628], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6622, max_kl_dist_index: 0, max_train_grp_loss:  13.0740, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6848, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2143, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:39:30,586 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  92, train_loss:  12.1562, val_loss:  12.4279, grad_norm: 0.0042, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6622, 0.3081, 0.6549, param: [5.45227868 8.27122417 5.19351346 8.65125136], weights: [0.30572298 0.31139253 0.38288449], train_wt_loss:  36.4686, val_wt_loss: 37.2836, train_grp_loss: [11.81468592 13.0740416  10.7153873 ], val_grp_loss: [12.68496155 12.45145222 12.14642342], train_hist_grp_loss: [ 8.84329397  9.76203741 20.0959908 ], cur_train_grp_loss: [0.09451691 0.10459206 0.21431202], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6622, max_kl_dist_index: 0, max_train_grp_loss:  13.0740, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6850, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2143, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:39:31,599 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  93, train_loss:  12.1562, val_loss:  12.4279, grad_norm: 0.0042, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6623, 0.3082, 0.6550, param: [5.45237207 8.27092871 5.19407182 8.65220291], weights: [0.30542331 0.31114999 0.3834267 ], train_wt_loss:  36.4686, val_wt_loss: 37.2838, train_grp_loss: [11.81475718 13.07407704 10.71517325], val_grp_loss: [12.68513306 12.45149796 12.14641445], train_hist_grp_loss: [ 8.93781145  9.86662974 20.31029854], cur_train_grp_loss: [0.09451749 0.10459233 0.21430775], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6623, max_kl_dist_index: 0, max_train_grp_loss:  13.0741, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6851, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2143, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:39:32,625 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  94, train_loss:  12.1562, val_loss:  12.4280, grad_norm: 0.0043, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6624, 0.3082, 0.6550, param: [5.45246517 8.27063373 5.19463069 8.65315683], weights: [0.30512356 0.31090726 0.38396917], train_wt_loss:  36.4687, val_wt_loss: 37.2840, train_grp_loss: [11.81482763 13.07411374 10.71495875], val_grp_loss: [12.68530391 12.45154513 12.14640518], train_hist_grp_loss: [ 9.03232951  9.97122236 20.52460201], cur_train_grp_loss: [0.09451806 0.10459262 0.21430346], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6624, max_kl_dist_index: 0, max_train_grp_loss:  13.0741, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6853, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2143, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:39:33,619 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  95, train_loss:  12.1562, val_loss:  12.4281, grad_norm: 0.0044, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6624, 0.3082, 0.6551, param: [5.45255798 8.27033924 5.19519008 8.65411312], weights: [0.30482374 0.31066435 0.38451191], train_wt_loss:  36.4687, val_wt_loss: 37.2842, train_grp_loss: [11.81489727 13.07415169 10.7147438 ], val_grp_loss: [12.68547409 12.45159374 12.14639562], train_hist_grp_loss: [ 9.12684813 10.07581527 20.73890118], cur_train_grp_loss: [0.09451862 0.10459291 0.21429917], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6624, max_kl_dist_index: 0, max_train_grp_loss:  13.0742, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6855, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2143, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:39:34,672 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  96, train_loss:  12.1562, val_loss:  12.4281, grad_norm: 0.0044, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6625, 0.3083, 0.6552, param: [5.45265049 8.27004524 5.19574998 8.6550718 ], weights: [0.30452384 0.31042124 0.38505492], train_wt_loss:  36.4687, val_wt_loss: 37.2844, train_grp_loss: [11.81496611 13.07419092 10.71452841], val_grp_loss: [12.6856436  12.45164379 12.14638576], train_hist_grp_loss: [ 9.22136731 10.18040848 20.95319606], cur_train_grp_loss: [0.09451918 0.10459321 0.21429488], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6625, max_kl_dist_index: 0, max_train_grp_loss:  13.0742, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6856, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2143, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:39:35,671 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  97, train_loss:  12.1562, val_loss:  12.4282, grad_norm: 0.0045, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6626, 0.3083, 0.6552, param: [5.45274271 8.26975172 5.19631039 8.65603286], weights: [0.30422387 0.31017795 0.38559818], train_wt_loss:  36.4687, val_wt_loss: 37.2847, train_grp_loss: [11.81503413 13.0742314  10.71431257], val_grp_loss: [12.68581245 12.45169527 12.14637561], train_hist_grp_loss: [ 9.31588704 10.28500201 21.16748663], cur_train_grp_loss: [0.09451973 0.10459353 0.21429057], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6626, max_kl_dist_index: 0, max_train_grp_loss:  13.0742, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6858, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2143, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:39:36,711 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  98, train_loss:  12.1563, val_loss:  12.4283, grad_norm: 0.0045, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6626, 0.3083, 0.6553, param: [5.45283464 8.26945868 5.19687132 8.6569963 ], weights: [0.30392383 0.30993447 0.38614171], train_wt_loss:  36.4688, val_wt_loss: 37.2849, train_grp_loss: [11.81510135 13.07427315 10.71409628], val_grp_loss: [12.68598064 12.45174819 12.14636516], train_hist_grp_loss: [ 9.41040731 10.38959586 21.38177288], cur_train_grp_loss: [0.09452027 0.10459385 0.21428625], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6626, max_kl_dist_index: 0, max_train_grp_loss:  13.0743, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6860, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2143, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:39:37,731 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  99, train_loss:  12.1563, val_loss:  12.4284, grad_norm: 0.0046, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6627, 0.3084, 0.6553, param: [5.45292628 8.26916613 5.19743277 8.65796212], weights: [0.30362371 0.3096908  0.38668549], train_wt_loss:  36.4688, val_wt_loss: 37.2851, train_grp_loss: [11.81516775 13.07431617 10.71387955], val_grp_loss: [12.68614817 12.45180256 12.14635442], train_hist_grp_loss: [ 9.50492812 10.49419004 21.5960548 ], cur_train_grp_loss: [0.09452081 0.10459419 0.21428193], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6627, max_kl_dist_index: 0, max_train_grp_loss:  13.0743, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6861, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2143, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:39:38,749 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  100, train_loss:  12.1563, val_loss:  12.4284, grad_norm: 0.0046, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6628, 0.3084, 0.6554, param: [5.45301761 8.26887406 5.19799473 8.65893033], weights: [0.30332352 0.30944695 0.38722953], train_wt_loss:  36.4688, val_wt_loss: 37.2853, train_grp_loss: [11.81523336 13.07436045 10.71366237], val_grp_loss: [12.68631503 12.45185836 12.14634338], train_hist_grp_loss: [ 9.59944947 10.59878457 21.8103324 ], cur_train_grp_loss: [0.09452134 0.10459453 0.21427759], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6628, max_kl_dist_index: 0, max_train_grp_loss:  13.0744, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6863, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2143, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:39:39,770 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  101, train_loss:  12.1563, val_loss:  12.4285, grad_norm: 0.0047, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6628, 0.3085, 0.6555, param: [5.45310866 8.26858247 5.1985572  8.65990093], weights: [0.30302326 0.30920291 0.38777383], train_wt_loss:  36.4689, val_wt_loss: 37.2855, train_grp_loss: [11.81529815 13.07440599 10.71344474], val_grp_loss: [12.68648124 12.4519156  12.14633205], train_hist_grp_loss: [ 9.69397133 10.70337946 22.02460564], cur_train_grp_loss: [0.09452187 0.10459488 0.21427325], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6628, max_kl_dist_index: 0, max_train_grp_loss:  13.0744, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6865, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2143, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:39:40,788 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  102, train_loss:  12.1563, val_loss:  12.4286, grad_norm: 0.0047, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6629, 0.3085, 0.6555, param: [5.45319941 8.26829136 5.1991202  8.66087391], weights: [0.30272293 0.30895869 0.38831838], train_wt_loss:  36.4689, val_wt_loss: 37.2857, train_grp_loss: [11.81536214 13.07445281 10.71322667], val_grp_loss: [12.68664678 12.45197429 12.14632043], train_hist_grp_loss: [ 9.78849372 10.8079747  22.23887454], cur_train_grp_loss: [0.09452239 0.10459525 0.21426889], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6629, max_kl_dist_index: 0, max_train_grp_loss:  13.0745, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6866, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2143, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:39:41,799 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  103, train_loss:  12.1563, val_loss:  12.4286, grad_norm: 0.0048, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6630, 0.3085, 0.6556, param: [5.45328986 8.26800073 5.19968371 8.66184929], weights: [0.30242253 0.30871429 0.38886319], train_wt_loss:  36.4689, val_wt_loss: 37.2859, train_grp_loss: [11.81542532 13.07450089 10.71300815], val_grp_loss: [12.68681166 12.45203442 12.14630851], train_hist_grp_loss: [ 9.88301661 10.91257033 22.45313907], cur_train_grp_loss: [0.0945229  0.10459562 0.21426453], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6630, max_kl_dist_index: 0, max_train_grp_loss:  13.0745, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6868, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2143, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:39:42,822 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  104, train_loss:  12.1563, val_loss:  12.4287, grad_norm: 0.0048, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6630, 0.3086, 0.6557, param: [5.45338002 8.26771058 5.20024774 8.66282706], weights: [0.30212205 0.3084697  0.38940825], train_wt_loss:  36.4689, val_wt_loss: 37.2861, train_grp_loss: [11.81548769 13.07455024 10.71278918], val_grp_loss: [12.68697587 12.45209599 12.14629631], train_hist_grp_loss: [ 9.97754002 11.01716633 22.66739923], cur_train_grp_loss: [0.0945234  0.10459601 0.21426016], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6630, max_kl_dist_index: 0, max_train_grp_loss:  13.0746, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6870, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2143, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:39:43,861 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  105, train_loss:  12.1563, val_loss:  12.4288, grad_norm: 0.0049, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6631, 0.3086, 0.6557, param: [5.45346988 8.2674209  5.20081229 8.66380722], weights: [0.30182151 0.30822493 0.38995356], train_wt_loss:  36.4690, val_wt_loss: 37.2864, train_grp_loss: [11.81554926 13.07460086 10.71256977], val_grp_loss: [12.68713943 12.45215901 12.14628381], train_hist_grp_loss: [10.07206392 11.12176274 22.88165502], cur_train_grp_loss: [0.0945239  0.1045964  0.21425578], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6631, max_kl_dist_index: 0, max_train_grp_loss:  13.0746, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6871, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2143, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:39:44,895 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  106, train_loss:  12.1563, val_loss:  12.4289, grad_norm: 0.0050, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6632, 0.3086, 0.6558, param: [5.45355944 8.2671317  5.20137736 8.66478978], weights: [0.3015209  0.30797998 0.39049912], train_wt_loss:  36.4690, val_wt_loss: 37.2866, train_grp_loss: [11.81561003 13.07465275 10.71234991], val_grp_loss: [12.68730233 12.45222347 12.14627102], train_hist_grp_loss: [10.16658831 11.22635954 23.09590641], cur_train_grp_loss: [0.09452439 0.10459681 0.2142514 ], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6632, max_kl_dist_index: 0, max_train_grp_loss:  13.0747, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6873, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2143, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:39:45,941 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  107, train_loss:  12.1563, val_loss:  12.4289, grad_norm: 0.0050, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6632, 0.3087, 0.6559, param: [5.45364871 8.26684298 5.20194295 8.66577474], weights: [0.30122023 0.30773485 0.39104493], train_wt_loss:  36.4690, val_wt_loss: 37.2868, train_grp_loss: [11.81566999 13.07470591 10.7121296 ], val_grp_loss: [12.68746457 12.45228937 12.14625793], train_hist_grp_loss: [10.26111319 11.33095676 23.31015341], cur_train_grp_loss: [0.09452488 0.10459722 0.214247  ], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6632, max_kl_dist_index: 0, max_train_grp_loss:  13.0747, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6875, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2142, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:39:46,962 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  108, train_loss:  12.1564, val_loss:  12.4290, grad_norm: 0.0051, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6633, 0.3087, 0.6559, param: [5.45373768 8.26655473 5.20250907 8.6667621 ], weights: [0.30091948 0.30748953 0.39159098], train_wt_loss:  36.4691, val_wt_loss: 37.2870, train_grp_loss: [11.81572914 13.07476034 10.71190885], val_grp_loss: [12.68762614 12.45235673 12.14624456], train_hist_grp_loss: [10.35563855 11.43555441 23.524396  ], cur_train_grp_loss: [0.09452536 0.10459765 0.21424259], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6633, max_kl_dist_index: 0, max_train_grp_loss:  13.0748, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6876, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2142, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:39:47,998 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  109, train_loss:  12.1564, val_loss:  12.4291, grad_norm: 0.0051, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6634, 0.3087, 0.6560, param: [5.45382635 8.26626696 5.2030757  8.66775185], weights: [0.30061867 0.30724404 0.39213728], train_wt_loss:  36.4691, val_wt_loss: 37.2872, train_grp_loss: [11.8157875  13.07481604 10.71168765], val_grp_loss: [12.68778706 12.45242553 12.1462309 ], train_hist_grp_loss: [10.45016439 11.54015249 23.73863418], cur_train_grp_loss: [0.09452583 0.10459808 0.21423818], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6634, max_kl_dist_index: 0, max_train_grp_loss:  13.0748, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6878, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2142, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:39:49,007 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  110, train_loss:  12.1564, val_loss:  12.4291, grad_norm: 0.0052, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6634, 0.3088, 0.6561, param: [5.45391473 8.26597966 5.20364286 8.66874401], weights: [0.3003178  0.30699837 0.39268383], train_wt_loss:  36.4691, val_wt_loss: 37.2874, train_grp_loss: [11.81584505 13.07487301 10.71146601], val_grp_loss: [12.68794732 12.45249578 12.14621695], train_hist_grp_loss: [10.54469069 11.64475102 23.95286793], cur_train_grp_loss: [0.0945263  0.10459853 0.21423375], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6634, max_kl_dist_index: 0, max_train_grp_loss:  13.0749, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6879, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2142, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:39:50,042 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  111, train_loss:  12.1564, val_loss:  12.4292, grad_norm: 0.0052, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6635, 0.3088, 0.6561, param: [5.4540028  8.26569283 5.20421054 8.66973858], weights: [0.30001686 0.30675252 0.39323062], train_wt_loss:  36.4692, val_wt_loss: 37.2877, train_grp_loss: [11.81590179 13.07493126 10.71124392], val_grp_loss: [12.68810692 12.45256748 12.1462027 ], train_hist_grp_loss: [10.63921745 11.74935001 24.16709725], cur_train_grp_loss: [0.09452676 0.10459898 0.21422932], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6635, max_kl_dist_index: 0, max_train_grp_loss:  13.0749, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6881, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2142, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:39:51,072 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  112, train_loss:  12.1564, val_loss:  12.4293, grad_norm: 0.0053, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6636, 0.3089, 0.6562, param: [5.45409057 8.26540647 5.20477874 8.67073555], weights: [0.29971585 0.3065065  0.39377765], train_wt_loss:  36.4692, val_wt_loss: 37.2879, train_grp_loss: [11.81595774 13.07499078 10.71102139], val_grp_loss: [12.68826587 12.45264063 12.14618817], train_hist_grp_loss: [10.73374466 11.85394946 24.38132213], cur_train_grp_loss: [0.09452721 0.10459945 0.21422488], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6636, max_kl_dist_index: 0, max_train_grp_loss:  13.0750, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6883, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2142, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:39:52,130 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  113, train_loss:  12.1564, val_loss:  12.4294, grad_norm: 0.0054, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6636, 0.3089, 0.6563, param: [5.45417805 8.26512059 5.20534747 8.67173493], weights: [0.29941478 0.3062603  0.39432492], train_wt_loss:  36.4692, val_wt_loss: 37.2881, train_grp_loss: [11.81601288 13.07505158 10.7107984 ], val_grp_loss: [12.68842416 12.45271523 12.14617335], train_hist_grp_loss: [10.82827232 11.95854938 24.59554256], cur_train_grp_loss: [0.09452766 0.10459993 0.21422043], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6636, max_kl_dist_index: 0, max_train_grp_loss:  13.0751, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6884, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2142, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:39:53,192 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  114, train_loss:  12.1564, val_loss:  12.4294, grad_norm: 0.0054, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6637, 0.3089, 0.6563, param: [5.45426522 8.26483517 5.20591673 8.67273671], weights: [0.29911365 0.30601392 0.39487243], train_wt_loss:  36.4693, val_wt_loss: 37.2883, train_grp_loss: [11.81606723 13.07511365 10.71057498], val_grp_loss: [12.68858179 12.45279128 12.14615825], train_hist_grp_loss: [10.92280043 12.0631498  24.80975853], cur_train_grp_loss: [0.0945281  0.10460041 0.21421597], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6637, max_kl_dist_index: 0, max_train_grp_loss:  13.0751, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6886, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2142, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:39:54,284 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  115, train_loss:  12.1564, val_loss:  12.4295, grad_norm: 0.0055, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6638, 0.3090, 0.6564, param: [5.4543521  8.26455022 5.20648651 8.67374091], weights: [0.29881245 0.30576736 0.39542018], train_wt_loss:  36.4693, val_wt_loss: 37.2885, train_grp_loss: [11.81612077 13.075177   10.71035111], val_grp_loss: [12.68873876 12.45286878 12.14614285], train_hist_grp_loss: [11.01732896 12.16775071 25.02397003], cur_train_grp_loss: [0.09452854 0.10460091 0.2142115 ], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6638, max_kl_dist_index: 0, max_train_grp_loss:  13.0752, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6887, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2142, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:39:55,305 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  116, train_loss:  12.1564, val_loss:  12.4296, grad_norm: 0.0055, live_grad: 0.0000, reward_err: 0.0105, 0.0142, 0.0002, KL_dist: 0.6639, 0.3090, 0.6565, param: [5.45443867 8.26426574 5.20705681 8.67474752], weights: [0.2985112  0.30552064 0.39596817], train_wt_loss:  36.4693, val_wt_loss: 37.2887, train_grp_loss: [11.81617351 13.07524162 10.71012679], val_grp_loss: [12.68889507 12.45294774 12.14612717], train_hist_grp_loss: [11.11185793 12.27235212 25.23817705], cur_train_grp_loss: [0.09452897 0.10460142 0.21420702], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6639, max_kl_dist_index: 0, max_train_grp_loss:  13.0752, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6889, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2142, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:39:56,325 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  117, train_loss:  12.1565, val_loss:  12.4297, grad_norm: 0.0056, live_grad: 0.0000, reward_err: 0.0105, 0.0142, 0.0002, KL_dist: 0.6639, 0.3090, 0.6565, param: [5.45452494 8.26398172 5.20762765 8.67575654], weights: [0.29820988 0.30527373 0.39651639], train_wt_loss:  36.4694, val_wt_loss: 37.2890, train_grp_loss: [11.81622546 13.07530753 10.70990203], val_grp_loss: [12.68905074 12.45302815 12.1461112 ], train_hist_grp_loss: [11.20638732 12.37695405 25.45237959], cur_train_grp_loss: [0.09452939 0.10460193 0.21420254], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6639, max_kl_dist_index: 0, max_train_grp_loss:  13.0753, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6891, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2142, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:39:57,359 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  118, train_loss:  12.1565, val_loss:  12.4297, grad_norm: 0.0056, live_grad: 0.0000, reward_err: 0.0105, 0.0142, 0.0002, KL_dist: 0.6640, 0.3091, 0.6566, param: [5.45461091 8.26369817 5.20819901 8.67676798], weights: [0.2979085  0.30502666 0.39706484], train_wt_loss:  36.4694, val_wt_loss: 37.2892, train_grp_loss: [11.8162766  13.07537471 10.70967682], val_grp_loss: [12.68920574 12.45311001 12.14609495], train_hist_grp_loss: [11.30091712 12.48155651 25.66657763], cur_train_grp_loss: [0.0945298  0.10460246 0.21419804], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6640, max_kl_dist_index: 0, max_train_grp_loss:  13.0754, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6892, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2142, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:39:58,407 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  119, train_loss:  12.1565, val_loss:  12.4298, grad_norm: 0.0057, live_grad: 0.0000, reward_err: 0.0105, 0.0142, 0.0002, KL_dist: 0.6641, 0.3091, 0.6567, param: [5.45469658 8.26341509 5.2087709  8.67778183], weights: [0.29760706 0.30477941 0.39761353], train_wt_loss:  36.4694, val_wt_loss: 37.2894, train_grp_loss: [11.81632695 13.07544316 10.70945117], val_grp_loss: [12.68936009 12.45319334 12.14607841], train_hist_grp_loss: [11.39544733 12.58615951 25.88077116], cur_train_grp_loss: [0.09453021 0.104603   0.21419354], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6641, max_kl_dist_index: 0, max_train_grp_loss:  13.0754, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6894, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2142, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:39:59,437 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  120, train_loss:  12.1565, val_loss:  12.4299, grad_norm: 0.0058, live_grad: 0.0000, reward_err: 0.0105, 0.0142, 0.0002, KL_dist: 0.6641, 0.3092, 0.6567, param: [5.45478195 8.26313246 5.20934331 8.67879811], weights: [0.29730556 0.30453199 0.39816245], train_wt_loss:  36.4695, val_wt_loss: 37.2896, train_grp_loss: [11.81637649 13.0755129  10.70922507], val_grp_loss: [12.68951379 12.45327811 12.14606158], train_hist_grp_loss: [11.48997795 12.69076306 26.09496019], cur_train_grp_loss: [0.09453062 0.10460355 0.21418902], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6641, max_kl_dist_index: 0, max_train_grp_loss:  13.0755, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6895, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2142, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:40:00,463 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  121, train_loss:  12.1565, val_loss:  12.4300, grad_norm: 0.0058, live_grad: 0.0000, reward_err: 0.0105, 0.0142, 0.0002, KL_dist: 0.6642, 0.3092, 0.6568, param: [5.45486701 8.2628503  5.20991626 8.6798168 ], weights: [0.29700401 0.3042844  0.3987116 ], train_wt_loss:  36.4695, val_wt_loss: 37.2899, train_grp_loss: [11.81642525 13.07558392 10.70899853], val_grp_loss: [12.68966683 12.45336435 12.14604447], train_hist_grp_loss: [11.58450896 12.79536716 26.30914469], cur_train_grp_loss: [0.09453101 0.1046041  0.2141845 ], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6642, max_kl_dist_index: 0, max_train_grp_loss:  13.0756, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6897, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2142, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:40:01,496 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  122, train_loss:  12.1565, val_loss:  12.4300, grad_norm: 0.0059, live_grad: 0.0000, reward_err: 0.0105, 0.0142, 0.0002, KL_dist: 0.6643, 0.3092, 0.6569, param: [5.45495177 8.26256861 5.21048974 8.68083791], weights: [0.29670239 0.30403664 0.39926097], train_wt_loss:  36.4695, val_wt_loss: 37.2901, train_grp_loss: [11.8164732  13.07565622 10.70877154], val_grp_loss: [12.68981922 12.45345204 12.14602708], train_hist_grp_loss: [11.67904036 12.89997183 26.52332466], cur_train_grp_loss: [0.0945314  0.10460467 0.21417997], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6643, max_kl_dist_index: 0, max_train_grp_loss:  13.0757, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6898, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2142, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:40:02,536 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  123, train_loss:  12.1565, val_loss:  12.4301, grad_norm: 0.0059, live_grad: 0.0000, reward_err: 0.0105, 0.0139, 0.0002, KL_dist: 0.6643, 0.3093, 0.6569, param: [5.45503622 8.26228737 5.21106375 8.68186145], weights: [0.29640072 0.30378871 0.39981058], train_wt_loss:  36.4696, val_wt_loss: 37.2903, train_grp_loss: [11.81652036 13.0757298  10.70854411], val_grp_loss: [12.68997095 12.45354119 12.1460094 ], train_hist_grp_loss: [11.77357215 13.00457708 26.73750009], cur_train_grp_loss: [0.09453179 0.10460525 0.21417543], max_reward_err:  0.0139, max_reward_err_index: 1, max_kl_dist:  0.6643, max_kl_dist_index: 0, max_train_grp_loss:  13.0757, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6900, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2142, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:40:03,569 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  124, train_loss:  12.1565, val_loss:  12.4302, grad_norm: 0.0060, live_grad: 0.0000, reward_err: 0.0105, 0.0139, 0.0002, KL_dist: 0.6644, 0.3093, 0.6570, param: [5.45512037 8.26200659 5.21163829 8.68288742], weights: [0.29609899 0.30354061 0.40036041], train_wt_loss:  36.4696, val_wt_loss: 37.2905, train_grp_loss: [11.81656672 13.07580466 10.70831624], val_grp_loss: [12.69012203 12.4536318  12.14599143], train_hist_grp_loss: [11.86810431 13.10918292 26.95167097], cur_train_grp_loss: [0.09453216 0.10460584 0.21417088], max_reward_err:  0.0139, max_reward_err_index: 1, max_kl_dist:  0.6644, max_kl_dist_index: 0, max_train_grp_loss:  13.0758, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6901, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2142, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:40:04,633 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  125, train_loss:  12.1566, val_loss:  12.4303, grad_norm: 0.0061, live_grad: 0.0000, reward_err: 0.0105, 0.0139, 0.0002, KL_dist: 0.6645, 0.3094, 0.6571, param: [5.45520422 8.26172627 5.21221336 8.6839158 ], weights: [0.2957972  0.30329234 0.40091046], train_wt_loss:  36.4697, val_wt_loss: 37.2908, train_grp_loss: [11.81661228 13.07588081 10.70808792], val_grp_loss: [12.69027246 12.45372387 12.14597319], train_hist_grp_loss: [11.96263685 13.21378936 27.1658373 ], cur_train_grp_loss: [0.09453253 0.10460644 0.21416632], max_reward_err:  0.0139, max_reward_err_index: 1, max_kl_dist:  0.6645, max_kl_dist_index: 0, max_train_grp_loss:  13.0759, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6903, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2142, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:40:05,650 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  126, train_loss:  12.1566, val_loss:  12.4303, grad_norm: 0.0061, live_grad: 0.0000, reward_err: 0.0105, 0.0139, 0.0002, KL_dist: 0.6646, 0.3094, 0.6571, param: [5.45528776 8.26144641 5.21278897 8.68494662], weights: [0.29549536 0.3030439  0.40146074], train_wt_loss:  36.4697, val_wt_loss: 37.2910, train_grp_loss: [11.81665706 13.07595823 10.70785916], val_grp_loss: [12.69042224 12.4538174  12.14595466], train_hist_grp_loss: [12.05716974 13.3183964  27.37999905], cur_train_grp_loss: [0.0945329  0.10460705 0.21416176], max_reward_err:  0.0139, max_reward_err_index: 1, max_kl_dist:  0.6646, max_kl_dist_index: 0, max_train_grp_loss:  13.0760, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6904, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2142, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:40:06,646 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  127, train_loss:  12.1566, val_loss:  12.4304, grad_norm: 0.0062, live_grad: 0.0000, reward_err: 0.0105, 0.0139, 0.0002, KL_dist: 0.6646, 0.3094, 0.6572, param: [5.45537099 8.26116701 5.2133651  8.68597987], weights: [0.29519347 0.3027953  0.40201123], train_wt_loss:  36.4697, val_wt_loss: 37.2912, train_grp_loss: [11.81670103 13.07603695 10.70762995], val_grp_loss: [12.69057136 12.4539124  12.14593585], train_hist_grp_loss: [12.151703   13.42300407 27.59415624], cur_train_grp_loss: [0.09453326 0.10460767 0.21415718], max_reward_err:  0.0139, max_reward_err_index: 1, max_kl_dist:  0.6646, max_kl_dist_index: 0, max_train_grp_loss:  13.0760, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6906, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2142, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:40:07,659 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  128, train_loss:  12.1566, val_loss:  12.4305, grad_norm: 0.0062, live_grad: 0.0000, reward_err: 0.0105, 0.0139, 0.0002, KL_dist: 0.6647, 0.3095, 0.6573, param: [5.45545392 8.26088806 5.21394178 8.68701555], weights: [0.29489152 0.30254653 0.40256195], train_wt_loss:  36.4698, val_wt_loss: 37.2914, train_grp_loss: [11.81674422 13.07611694 10.7074003 ], val_grp_loss: [12.69071984 12.45400885 12.14591676], train_hist_grp_loss: [12.24623661 13.52761237 27.80830884], cur_train_grp_loss: [0.09453361 0.1046083  0.2141526 ], max_reward_err:  0.0139, max_reward_err_index: 1, max_kl_dist:  0.6647, max_kl_dist_index: 0, max_train_grp_loss:  13.0761, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6907, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2142, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:40:08,680 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  129, train_loss:  12.1566, val_loss:  12.4306, grad_norm: 0.0063, live_grad: 0.0000, reward_err: 0.0105, 0.0139, 0.0002, KL_dist: 0.6648, 0.3095, 0.6573, param: [5.45553654 8.26060957 5.21451898 8.68805366], weights: [0.29458952 0.30229759 0.40311289], train_wt_loss:  36.4698, val_wt_loss: 37.2917, train_grp_loss: [11.81678661 13.07619823 10.70717021], val_grp_loss: [12.69086766 12.45410677 12.14589739], train_hist_grp_loss: [12.34077056 13.6322213  28.02245684], cur_train_grp_loss: [0.09453395 0.10460894 0.21414801], max_reward_err:  0.0139, max_reward_err_index: 1, max_kl_dist:  0.6648, max_kl_dist_index: 0, max_train_grp_loss:  13.0762, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6909, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2141, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:40:09,693 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  130, train_loss:  12.1566, val_loss:  12.4306, grad_norm: 0.0064, live_grad: 0.0000, reward_err: 0.0105, 0.0139, 0.0002, KL_dist: 0.6648, 0.3096, 0.6574, param: [5.45561886 8.26033153 5.21509672 8.6890942 ], weights: [0.29428746 0.30204849 0.40366405], train_wt_loss:  36.4699, val_wt_loss: 37.2919, train_grp_loss: [11.81682821 13.0762808  10.70693967], val_grp_loss: [12.69101484 12.45420616 12.14587774], train_hist_grp_loss: [12.43530486 13.73683089 28.23660025], cur_train_grp_loss: [0.09453429 0.10460959 0.2141434 ], max_reward_err:  0.0139, max_reward_err_index: 1, max_kl_dist:  0.6648, max_kl_dist_index: 0, max_train_grp_loss:  13.0763, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6910, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2141, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:40:10,725 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  131, train_loss:  12.1566, val_loss:  12.4307, grad_norm: 0.0064, live_grad: 0.0000, reward_err: 0.0105, 0.0139, 0.0002, KL_dist: 0.6649, 0.3096, 0.6575, param: [5.45570086 8.26005394 5.215675   8.69013718], weights: [0.29398536 0.30179923 0.40421542], train_wt_loss:  36.4699, val_wt_loss: 37.2921, train_grp_loss: [11.81686901 13.07636465 10.7067087 ], val_grp_loss: [12.69116136 12.45430701 12.1458578 ], train_hist_grp_loss: [12.52983948 13.84144113 28.45073904], cur_train_grp_loss: [0.09453463 0.10461025 0.21413879], max_reward_err:  0.0139, max_reward_err_index: 1, max_kl_dist:  0.6649, max_kl_dist_index: 0, max_train_grp_loss:  13.0764, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6912, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2141, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:40:11,737 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  132, train_loss:  12.1566, val_loss:  12.4308, grad_norm: 0.0065, live_grad: 0.0000, reward_err: 0.0105, 0.0139, 0.0002, KL_dist: 0.6650, 0.3096, 0.6575, param: [5.45578256 8.25977681 5.21625381 8.6911826 ], weights: [0.2936832 0.3015498 0.404767 ], train_wt_loss:  36.4699, val_wt_loss: 37.2923, train_grp_loss: [11.81690903 13.07644979 10.70647727], val_grp_loss: [12.69130723 12.45440932 12.14583759], train_hist_grp_loss: [12.62437443 13.94605205 28.66487321], cur_train_grp_loss: [0.09453495 0.10461092 0.21413417], max_reward_err:  0.0139, max_reward_err_index: 1, max_kl_dist:  0.6650, max_kl_dist_index: 0, max_train_grp_loss:  13.0764, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6913, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2141, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:40:12,770 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  133, train_loss:  12.1567, val_loss:  12.4309, grad_norm: 0.0066, live_grad: 0.0000, reward_err: 0.0105, 0.0139, 0.0002, KL_dist: 0.6651, 0.3097, 0.6576, param: [5.45586395 8.25950012 5.21683316 8.69223045], weights: [0.29338099 0.30130021 0.4053188 ], train_wt_loss:  36.4700, val_wt_loss: 37.2926, train_grp_loss: [11.81694825 13.07653623 10.70624541], val_grp_loss: [12.69145246 12.4545131  12.1458171 ], train_hist_grp_loss: [12.71890971 14.05066365 28.87900276], cur_train_grp_loss: [0.09453527 0.1046116  0.21412955], max_reward_err:  0.0139, max_reward_err_index: 1, max_kl_dist:  0.6651, max_kl_dist_index: 0, max_train_grp_loss:  13.0765, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6915, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2141, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:40:13,797 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  134, train_loss:  12.1567, val_loss:  12.4309, grad_norm: 0.0066, live_grad: 0.0000, reward_err: 0.0105, 0.0139, 0.0002, KL_dist: 0.6651, 0.3097, 0.6577, param: [5.45594504 8.25922389 5.21741305 8.69328075], weights: [0.29307873 0.30105046 0.40587081], train_wt_loss:  36.4700, val_wt_loss: 37.2928, train_grp_loss: [11.81698669 13.07662395 10.7060131 ], val_grp_loss: [12.69159704 12.45461835 12.14579633], train_hist_grp_loss: [12.81344529 14.15527594 29.09312767], cur_train_grp_loss: [0.09453559 0.10461229 0.21412491], max_reward_err:  0.0139, max_reward_err_index: 1, max_kl_dist:  0.6651, max_kl_dist_index: 0, max_train_grp_loss:  13.0766, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6916, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2141, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:40:14,863 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  135, train_loss:  12.1567, val_loss:  12.4310, grad_norm: 0.0067, live_grad: 0.0000, reward_err: 0.0105, 0.0139, 0.0002, KL_dist: 0.6652, 0.3097, 0.6577, param: [5.45602581 8.2589481  5.21799348 8.69433348], weights: [0.29277642 0.30080054 0.40642304], train_wt_loss:  36.4701, val_wt_loss: 37.2930, train_grp_loss: [11.81702433 13.07671296 10.70578035], val_grp_loss: [12.69174097 12.45472507 12.14577528], train_hist_grp_loss: [12.90798118 14.25988893 29.30724793], cur_train_grp_loss: [0.09453589 0.10461299 0.21412026], max_reward_err:  0.0139, max_reward_err_index: 1, max_kl_dist:  0.6652, max_kl_dist_index: 0, max_train_grp_loss:  13.0767, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6917, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2141, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:40:15,917 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  136, train_loss:  12.1567, val_loss:  12.4311, grad_norm: 0.0067, live_grad: 0.0000, reward_err: 0.0105, 0.0139, 0.0002, KL_dist: 0.6653, 0.3098, 0.6578, param: [5.45610627 8.25867277 5.21857444 8.69538866], weights: [0.29247406 0.30055047 0.40697547], train_wt_loss:  36.4701, val_wt_loss: 37.2933, train_grp_loss: [11.81706119 13.07680326 10.70554716], val_grp_loss: [12.69188425 12.45483326 12.14575396], train_hist_grp_loss: [13.00251738 14.36450263 29.52136354], cur_train_grp_loss: [0.09453619 0.1046137  0.21411561], max_reward_err:  0.0139, max_reward_err_index: 1, max_kl_dist:  0.6653, max_kl_dist_index: 0, max_train_grp_loss:  13.0768, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6919, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2141, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:40:16,949 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  137, train_loss:  12.1567, val_loss:  12.4312, grad_norm: 0.0068, live_grad: 0.0000, reward_err: 0.0105, 0.0139, 0.0002, KL_dist: 0.6654, 0.3098, 0.6579, param: [5.45618643 8.25839788 5.21915594 8.69644629], weights: [0.29217166 0.30030024 0.40752811], train_wt_loss:  36.4701, val_wt_loss: 37.2935, train_grp_loss: [11.81709725 13.07689485 10.70531352], val_grp_loss: [12.69202688 12.45494291 12.14573235], train_hist_grp_loss: [13.09705387 14.46911706 29.73547448], cur_train_grp_loss: [0.09453649 0.10461443 0.21411094], max_reward_err:  0.0139, max_reward_err_index: 1, max_kl_dist:  0.6654, max_kl_dist_index: 0, max_train_grp_loss:  13.0769, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6920, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2141, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:40:17,964 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  138, train_loss:  12.1567, val_loss:  12.4312, grad_norm: 0.0069, live_grad: 0.0000, reward_err: 0.0105, 0.0139, 0.0002, KL_dist: 0.6654, 0.3099, 0.6580, param: [5.45626627 8.25812343 5.21973799 8.69750636], weights: [0.2918692  0.30004984 0.40808095], train_wt_loss:  36.4702, val_wt_loss: 37.2937, train_grp_loss: [11.81713253 13.07698773 10.70507945], val_grp_loss: [12.69216887 12.45505404 12.14571048], train_hist_grp_loss: [13.19159065 14.57373222 29.94958075], cur_train_grp_loss: [0.09453678 0.10461516 0.21410627], max_reward_err:  0.0139, max_reward_err_index: 1, max_kl_dist:  0.6654, max_kl_dist_index: 0, max_train_grp_loss:  13.0770, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6922, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2141, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:40:18,989 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  139, train_loss:  12.1567, val_loss:  12.4313, grad_norm: 0.0069, live_grad: 0.0000, reward_err: 0.0105, 0.0139, 0.0002, KL_dist: 0.6655, 0.3099, 0.6580, param: [5.4563458  8.25784943 5.22032057 8.69856888], weights: [0.2915667  0.29979929 0.40863401], train_wt_loss:  36.4702, val_wt_loss: 37.2939, train_grp_loss: [11.81716703 13.0770819  10.70484493], val_grp_loss: [12.69231021 12.45516663 12.14568832], train_hist_grp_loss: [13.28612771 14.67834812 30.16368234], cur_train_grp_loss: [0.09453706 0.1046159  0.21410159], max_reward_err:  0.0139, max_reward_err_index: 1, max_kl_dist:  0.6655, max_kl_dist_index: 0, max_train_grp_loss:  13.0771, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6923, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2141, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:40:20,011 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  140, train_loss:  12.1568, val_loss:  12.4314, grad_norm: 0.0070, live_grad: 0.0000, reward_err: 0.0105, 0.0139, 0.0002, KL_dist: 0.6656, 0.3099, 0.6581, param: [5.45642502 8.25757588 5.22090369 8.69963384], weights: [0.29126416 0.29954858 0.40918726], train_wt_loss:  36.4703, val_wt_loss: 37.2942, train_grp_loss: [11.81720073 13.07717737 10.70460997], val_grp_loss: [12.69245091 12.4552807  12.14566589], train_hist_grp_loss: [13.38066504 14.78296478 30.37777924], cur_train_grp_loss: [0.09453734 0.10461666 0.2140969 ], max_reward_err:  0.0139, max_reward_err_index: 1, max_kl_dist:  0.6656, max_kl_dist_index: 0, max_train_grp_loss:  13.0772, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6925, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2141, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:40:21,027 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  141, train_loss:  12.1568, val_loss:  12.4315, grad_norm: 0.0071, live_grad: 0.0000, reward_err: 0.0105, 0.0139, 0.0002, KL_dist: 0.6656, 0.3100, 0.6582, param: [5.45650393 8.25730277 5.22148736 8.70070126], weights: [0.29096157 0.29929771 0.40974072], train_wt_loss:  36.4703, val_wt_loss: 37.2944, train_grp_loss: [11.81723365 13.07727413 10.70437457], val_grp_loss: [12.69259096 12.45539625 12.14564318], train_hist_grp_loss: [13.47520265 14.88758219 30.59187144], cur_train_grp_loss: [0.09453761 0.10461742 0.2140922 ], max_reward_err:  0.0139, max_reward_err_index: 1, max_kl_dist:  0.6656, max_kl_dist_index: 0, max_train_grp_loss:  13.0773, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6926, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2141, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:40:22,064 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  142, train_loss:  12.1568, val_loss:  12.4315, grad_norm: 0.0071, live_grad: 0.0000, reward_err: 0.0105, 0.0139, 0.0002, KL_dist: 0.6657, 0.3100, 0.6582, param: [5.45658253 8.2570301  5.22207156 8.70177113], weights: [0.29065893 0.29904669 0.41029438], train_wt_loss:  36.4704, val_wt_loss: 37.2946, train_grp_loss: [11.81726578 13.07737218 10.70413873], val_grp_loss: [12.69273037 12.45551326 12.1456202 ], train_hist_grp_loss: [13.56974052 14.99220039 30.80595893], cur_train_grp_loss: [0.09453787 0.10461819 0.21408749], max_reward_err:  0.0139, max_reward_err_index: 1, max_kl_dist:  0.6657, max_kl_dist_index: 0, max_train_grp_loss:  13.0774, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6927, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2141, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:40:23,095 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  143, train_loss:  12.1568, val_loss:  12.4316, grad_norm: 0.0072, live_grad: 0.0000, reward_err: 0.0105, 0.0139, 0.0002, KL_dist: 0.6658, 0.3101, 0.6583, param: [5.45666082 8.25675787 5.22265631 8.70284345], weights: [0.29035625 0.29879551 0.41084823], train_wt_loss:  36.4704, val_wt_loss: 37.2949, train_grp_loss: [11.81729713 13.07747153 10.70390244], val_grp_loss: [12.69286913 12.45563175 12.14559695], train_hist_grp_loss: [13.66427864 15.09681936 31.0200417 ], cur_train_grp_loss: [0.09453813 0.10461898 0.21408277], max_reward_err:  0.0139, max_reward_err_index: 1, max_kl_dist:  0.6658, max_kl_dist_index: 0, max_train_grp_loss:  13.0775, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6929, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2141, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:40:24,145 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  144, train_loss:  12.1568, val_loss:  12.4317, grad_norm: 0.0072, live_grad: 0.0000, reward_err: 0.0105, 0.0139, 0.0002, KL_dist: 0.6659, 0.3101, 0.6584, param: [5.45673879 8.25648608 5.22324161 8.70391823], weights: [0.29005353 0.29854418 0.41140229], train_wt_loss:  36.4705, val_wt_loss: 37.2951, train_grp_loss: [11.8173277  13.07757217 10.70366572], val_grp_loss: [12.69300725 12.45575172 12.14557342], train_hist_grp_loss: [13.75881702 15.20143914 31.23411975], cur_train_grp_loss: [0.09453838 0.10461977 0.21407805], max_reward_err:  0.0139, max_reward_err_index: 1, max_kl_dist:  0.6659, max_kl_dist_index: 0, max_train_grp_loss:  13.0776, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6930, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2141, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:40:25,193 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  145, train_loss:  12.1568, val_loss:  12.4318, grad_norm: 0.0073, live_grad: 0.0000, reward_err: 0.0105, 0.0139, 0.0002, KL_dist: 0.6659, 0.3102, 0.6585, param: [5.45681644 8.25621473 5.22382744 8.70499546], weights: [0.28975076 0.29829269 0.41195654], train_wt_loss:  36.4705, val_wt_loss: 37.2954, train_grp_loss: [11.81735748 13.07767411 10.70342855], val_grp_loss: [12.69314472 12.45587316 12.14554962], train_hist_grp_loss: [13.85335564 15.30605971 31.44819307], cur_train_grp_loss: [0.09453862 0.10462058 0.21407331], max_reward_err:  0.0139, max_reward_err_index: 1, max_kl_dist:  0.6659, max_kl_dist_index: 0, max_train_grp_loss:  13.0777, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6931, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2141, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:40:26,215 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  146, train_loss:  12.1569, val_loss:  12.4319, grad_norm: 0.0074, live_grad: 0.0000, reward_err: 0.0105, 0.0139, 0.0002, KL_dist: 0.6660, 0.3102, 0.6585, param: [5.45689379 8.25594381 5.22441383 8.70607516], weights: [0.28944796 0.29804105 0.41251099], train_wt_loss:  36.4706, val_wt_loss: 37.2956, train_grp_loss: [11.81738648 13.07777735 10.70319095], val_grp_loss: [12.69328155 12.45599607 12.14552555], train_hist_grp_loss: [13.9478945  15.41068111 31.66226164], cur_train_grp_loss: [0.09453886 0.10462139 0.21406857], max_reward_err:  0.0139, max_reward_err_index: 1, max_kl_dist:  0.6660, max_kl_dist_index: 0, max_train_grp_loss:  13.0778, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6933, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2141, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:40:27,223 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  147, train_loss:  12.1569, val_loss:  12.4319, grad_norm: 0.0074, live_grad: 0.0000, reward_err: 0.0105, 0.0139, 0.0002, KL_dist: 0.6661, 0.3102, 0.6586, param: [5.45697082 8.25567334 5.22500075 8.70715731], weights: [0.28914511 0.29778926 0.41306563], train_wt_loss:  36.4706, val_wt_loss: 37.2958, train_grp_loss: [11.81741469 13.07788188 10.70295291], val_grp_loss: [12.69341775 12.45612047 12.1455012 ], train_hist_grp_loss: [14.0424336  15.51530333 31.87632546], cur_train_grp_loss: [0.09453909 0.10462222 0.21406382], max_reward_err:  0.0139, max_reward_err_index: 1, max_kl_dist:  0.6661, max_kl_dist_index: 0, max_train_grp_loss:  13.0779, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6934, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2141, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:40:28,244 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  148, train_loss:  12.1569, val_loss:  12.4320, grad_norm: 0.0075, live_grad: 0.0000, reward_err: 0.0105, 0.0139, 0.0002, KL_dist: 0.6662, 0.3103, 0.6587, param: [5.45704753 8.25540329 5.22558822 8.70824192], weights: [0.28884222 0.29753732 0.41362047], train_wt_loss:  36.4706, val_wt_loss: 37.2961, train_grp_loss: [11.81744213 13.07798771 10.70271442], val_grp_loss: [12.69355329 12.45624634 12.14547659], train_hist_grp_loss: [14.13697291 15.61992638 32.09038451], cur_train_grp_loss: [0.09453932 0.10462306 0.21405906], max_reward_err:  0.0139, max_reward_err_index: 1, max_kl_dist:  0.6662, max_kl_dist_index: 0, max_train_grp_loss:  13.0780, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6936, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2141, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:40:29,288 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  149, train_loss:  12.1569, val_loss:  12.4321, grad_norm: 0.0076, live_grad: 0.0000, reward_err: 0.0105, 0.0139, 0.0002, KL_dist: 0.6662, 0.3103, 0.6587, param: [5.45712393 8.25513369 5.22617624 8.70932899], weights: [0.28853929 0.29728522 0.41417549], train_wt_loss:  36.4707, val_wt_loss: 37.2963, train_grp_loss: [11.81746878 13.07809484 10.7024755 ], val_grp_loss: [12.6936882  12.45637369 12.1454517 ], train_hist_grp_loss: [14.23151245 15.72455028 32.3044388 ], cur_train_grp_loss: [0.09453954 0.1046239  0.21405429], max_reward_err:  0.0139, max_reward_err_index: 1, max_kl_dist:  0.6662, max_kl_dist_index: 0, max_train_grp_loss:  13.0781, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6937, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2141, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:40:30,316 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  150, train_loss:  12.1569, val_loss:  12.4322, grad_norm: 0.0076, live_grad: 0.0000, reward_err: 0.0105, 0.0139, 0.0002, KL_dist: 0.6663, 0.3104, 0.6588, param: [5.45720001 8.25486451 5.2267648  8.71041853], weights: [0.28823632 0.29703297 0.41473071], train_wt_loss:  36.4707, val_wt_loss: 37.2965, train_grp_loss: [11.81749465 13.07820327 10.70223613], val_grp_loss: [12.69382247 12.45650252 12.14542655], train_hist_grp_loss: [14.3260522  15.82917504 32.51848831], cur_train_grp_loss: [0.09453975 0.10462476 0.21404951], max_reward_err:  0.0139, max_reward_err_index: 1, max_kl_dist:  0.6663, max_kl_dist_index: 0, max_train_grp_loss:  13.0782, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6938, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2140, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:40:31,353 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  151, train_loss:  12.1569, val_loss:  12.4323, grad_norm: 0.0077, live_grad: 0.0000, reward_err: 0.0105, 0.0139, 0.0002, KL_dist: 0.6664, 0.3104, 0.6589, param: [5.45727578 8.25459577 5.22735392 8.71151053], weights: [0.28793331 0.29678058 0.41528611], train_wt_loss:  36.4708, val_wt_loss: 37.2968, train_grp_loss: [11.81751974 13.078313   10.70199633], val_grp_loss: [12.69395609 12.45663283 12.14540112], train_hist_grp_loss: [14.42059216 15.93380067 32.73253304], cur_train_grp_loss: [0.09453996 0.10462563 0.21404472], max_reward_err:  0.0139, max_reward_err_index: 1, max_kl_dist:  0.6664, max_kl_dist_index: 0, max_train_grp_loss:  13.0783, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6940, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2140, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:40:32,399 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  152, train_loss:  12.1569, val_loss:  12.4323, grad_norm: 0.0078, live_grad: 0.0000, reward_err: 0.0105, 0.0139, 0.0002, KL_dist: 0.6665, 0.3104, 0.6590, param: [5.45735123 8.25432746 5.22794357 8.712605  ], weights: [0.28763027 0.29652803 0.4158417 ], train_wt_loss:  36.4708, val_wt_loss: 37.2970, train_grp_loss: [11.81754406 13.07842403 10.70175609], val_grp_loss: [12.69408908 12.45676463 12.14537542], train_hist_grp_loss: [14.51513232 16.03842717 32.94657296], cur_train_grp_loss: [0.09454016 0.1046265  0.21403993], max_reward_err:  0.0139, max_reward_err_index: 1, max_kl_dist:  0.6665, max_kl_dist_index: 0, max_train_grp_loss:  13.0784, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6941, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2140, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:40:33,418 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  153, train_loss:  12.1570, val_loss:  12.4324, grad_norm: 0.0078, live_grad: 0.0000, reward_err: 0.0105, 0.0139, 0.0002, KL_dist: 0.6665, 0.3105, 0.6590, param: [5.45742637 8.25405959 5.22853378 8.71370193], weights: [0.28732718 0.29627534 0.41639748], train_wt_loss:  36.4709, val_wt_loss: 37.2973, train_grp_loss: [11.81756759 13.07853636 10.70151541], val_grp_loss: [12.69422143 12.4568979  12.14534946], train_hist_grp_loss: [14.60967267 16.14305456 33.16060808], cur_train_grp_loss: [0.09454035 0.10462739 0.21403512], max_reward_err:  0.0139, max_reward_err_index: 1, max_kl_dist:  0.6665, max_kl_dist_index: 0, max_train_grp_loss:  13.0785, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6942, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2140, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:40:34,514 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  154, train_loss:  12.1570, val_loss:  12.4325, grad_norm: 0.0079, live_grad: 0.0000, reward_err: 0.0105, 0.0139, 0.0002, KL_dist: 0.6666, 0.3105, 0.6591, param: [5.45750118 8.25379214 5.22912454 8.71480134], weights: [0.28702406 0.2960225  0.41695344], train_wt_loss:  36.4709, val_wt_loss: 37.2975, train_grp_loss: [11.81759035 13.07865    10.70127429], val_grp_loss: [12.69435314 12.45703266 12.14532323], train_hist_grp_loss: [14.70421321 16.24768286 33.37463839], cur_train_grp_loss: [0.09454054 0.10462829 0.21403031], max_reward_err:  0.0139, max_reward_err_index: 1, max_kl_dist:  0.6666, max_kl_dist_index: 0, max_train_grp_loss:  13.0786, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6944, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2140, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:40:35,532 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  155, train_loss:  12.1570, val_loss:  12.4326, grad_norm: 0.0080, live_grad: 0.0000, reward_err: 0.0105, 0.0139, 0.0002, KL_dist: 0.6667, 0.3106, 0.6592, param: [5.45757568 8.25352511 5.22971584 8.71590321], weights: [0.28672091 0.29576951 0.41750958], train_wt_loss:  36.4710, val_wt_loss: 37.2977, train_grp_loss: [11.81761233 13.07876493 10.70103273], val_grp_loss: [12.69448421 12.4571689  12.14529673], train_hist_grp_loss: [14.79875393 16.35231206 33.58866388], cur_train_grp_loss: [0.09454072 0.1046292  0.21402549], max_reward_err:  0.0139, max_reward_err_index: 1, max_kl_dist:  0.6667, max_kl_dist_index: 0, max_train_grp_loss:  13.0788, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6945, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2140, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:40:36,567 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  156, train_loss:  12.1570, val_loss:  12.4327, grad_norm: 0.0080, live_grad: 0.0000, reward_err: 0.0105, 0.0139, 0.0002, KL_dist: 0.6668, 0.3106, 0.6593, param: [5.45764986 8.25325852 5.2303077  8.71700756], weights: [0.28641772 0.29551637 0.41806591], train_wt_loss:  36.4710, val_wt_loss: 37.2980, train_grp_loss: [11.81763353 13.07888117 10.70079073], val_grp_loss: [12.69461464 12.45730662 12.14526996], train_hist_grp_loss: [14.89329483 16.45694217 33.80268453], cur_train_grp_loss: [0.0945409  0.10463012 0.21402065], max_reward_err:  0.0139, max_reward_err_index: 1, max_kl_dist:  0.6668, max_kl_dist_index: 0, max_train_grp_loss:  13.0789, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6946, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2140, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:40:37,587 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  157, train_loss:  12.1570, val_loss:  12.4327, grad_norm: 0.0081, live_grad: 0.0000, reward_err: 0.0105, 0.0139, 0.0002, KL_dist: 0.6668, 0.3106, 0.6593, param: [5.45772372 8.25299235 5.2309001  8.71811438], weights: [0.28611449 0.29526309 0.41862241], train_wt_loss:  36.4711, val_wt_loss: 37.2982, train_grp_loss: [11.81765396 13.07899871 10.7005483 ], val_grp_loss: [12.69474444 12.45744583 12.14524293], train_hist_grp_loss: [14.9878359  16.56157322 34.01670035], cur_train_grp_loss: [0.09454107 0.10463105 0.21401581], max_reward_err:  0.0139, max_reward_err_index: 1, max_kl_dist:  0.6668, max_kl_dist_index: 0, max_train_grp_loss:  13.0790, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6947, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2140, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:40:38,601 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  158, train_loss:  12.1570, val_loss:  12.4328, grad_norm: 0.0082, live_grad: 0.0000, reward_err: 0.0105, 0.0139, 0.0002, KL_dist: 0.6669, 0.3107, 0.6594, param: [5.45779726 8.25272661 5.23149306 8.71922367], weights: [0.28581124 0.29500967 0.41917909], train_wt_loss:  36.4711, val_wt_loss: 37.2985, train_grp_loss: [11.81767361 13.07911755 10.70030543], val_grp_loss: [12.6948736  12.45758653 12.14521563], train_hist_grp_loss: [15.08237713 16.66620521 34.23071131], cur_train_grp_loss: [0.09454123 0.10463199 0.21401097], max_reward_err:  0.0139, max_reward_err_index: 1, max_kl_dist:  0.6669, max_kl_dist_index: 0, max_train_grp_loss:  13.0791, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6949, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2140, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:40:39,617 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  159, train_loss:  12.1571, val_loss:  12.4329, grad_norm: 0.0082, live_grad: 0.0000, reward_err: 0.0105, 0.0139, 0.0002, KL_dist: 0.6670, 0.3107, 0.6595, param: [5.45787048 8.25246129 5.23208656 8.72033544], weights: [0.28550794 0.2947561  0.41973595], train_wt_loss:  36.4712, val_wt_loss: 37.2987, train_grp_loss: [11.81769249 13.0792377  10.70006212], val_grp_loss: [12.69500212 12.45772871 12.14518806], train_hist_grp_loss: [15.17691852 16.77083815 34.44471742], cur_train_grp_loss: [0.09454139 0.10463294 0.21400611], max_reward_err:  0.0139, max_reward_err_index: 1, max_kl_dist:  0.6670, max_kl_dist_index: 0, max_train_grp_loss:  13.0792, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6950, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2140, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:40:40,661 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  160, train_loss:  12.1571, val_loss:  12.4330, grad_norm: 0.0083, live_grad: 0.0000, reward_err: 0.0105, 0.0139, 0.0002, KL_dist: 0.6671, 0.3108, 0.6596, param: [5.45794338 8.25219639 5.23268062 8.72144969], weights: [0.28520462 0.29450239 0.42029299], train_wt_loss:  36.4712, val_wt_loss: 37.2989, train_grp_loss: [11.8177106  13.07935916 10.69981837], val_grp_loss: [12.69513001 12.45787237 12.14516023], train_hist_grp_loss: [15.27146006 16.87547206 34.65871866], cur_train_grp_loss: [0.09454154 0.1046339  0.21400124], max_reward_err:  0.0139, max_reward_err_index: 1, max_kl_dist:  0.6671, max_kl_dist_index: 0, max_train_grp_loss:  13.0794, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6951, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2140, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:40:41,686 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  161, train_loss:  12.1571, val_loss:  12.4331, grad_norm: 0.0084, live_grad: 0.0000, reward_err: 0.0105, 0.0139, 0.0002, KL_dist: 0.6672, 0.3108, 0.6596, param: [5.45801596 8.25193192 5.23327523 8.72256642], weights: [0.28490126 0.29424854 0.4208502 ], train_wt_loss:  36.4713, val_wt_loss: 37.2992, train_grp_loss: [11.81772793 13.07948192 10.69957419], val_grp_loss: [12.69525726 12.45801753 12.14513214], train_hist_grp_loss: [15.36600174 16.98010693 34.87271503], cur_train_grp_loss: [0.09454168 0.10463487 0.21399637], max_reward_err:  0.0139, max_reward_err_index: 1, max_kl_dist:  0.6672, max_kl_dist_index: 0, max_train_grp_loss:  13.0795, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6953, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2140, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:40:42,700 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  162, train_loss:  12.1571, val_loss:  12.4331, grad_norm: 0.0084, live_grad: 0.0000, reward_err: 0.0105, 0.0139, 0.0002, KL_dist: 0.6672, 0.3109, 0.6597, param: [5.45808822 8.25166786 5.2338704  8.72368562], weights: [0.28459788 0.29399454 0.42140758], train_wt_loss:  36.4714, val_wt_loss: 37.2994, train_grp_loss: [11.81774449 13.07960599 10.69932957], val_grp_loss: [12.69538388 12.45816418 12.14510378], train_hist_grp_loss: [15.46054357 17.08474278 35.08670652], cur_train_grp_loss: [0.09454182 0.10463586 0.21399148], max_reward_err:  0.0139, max_reward_err_index: 1, max_kl_dist:  0.6672, max_kl_dist_index: 0, max_train_grp_loss:  13.0796, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6954, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2140, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:40:43,736 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  163, train_loss:  12.1571, val_loss:  12.4332, grad_norm: 0.0085, live_grad: 0.0000, reward_err: 0.0105, 0.0139, 0.0002, KL_dist: 0.6673, 0.3109, 0.6598, param: [5.45816016 8.25140423 5.23446612 8.72480731], weights: [0.28429446 0.29374041 0.42196513], train_wt_loss:  36.4714, val_wt_loss: 37.2997, train_grp_loss: [11.81776028 13.07973137 10.69908452], val_grp_loss: [12.69550987 12.45831231 12.14507517], train_hist_grp_loss: [15.55508552 17.18937963 35.30069311], cur_train_grp_loss: [0.09454196 0.10463685 0.21398659], max_reward_err:  0.0139, max_reward_err_index: 1, max_kl_dist:  0.6673, max_kl_dist_index: 0, max_train_grp_loss:  13.0797, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6955, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2140, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:40:44,780 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  164, train_loss:  12.1572, val_loss:  12.4333, grad_norm: 0.0086, live_grad: 0.0000, reward_err: 0.0105, 0.0139, 0.0002, KL_dist: 0.6674, 0.3109, 0.6599, param: [5.45823178 8.25114101 5.23506239 8.72593148], weights: [0.28399101 0.29348613 0.42252285], train_wt_loss:  36.4715, val_wt_loss: 37.2999, train_grp_loss: [11.81777529 13.07985805 10.69883903], val_grp_loss: [12.69563522 12.45846193 12.14504628], train_hist_grp_loss: [15.6496276  17.29401748 35.5146748 ], cur_train_grp_loss: [0.09454208 0.10463785 0.21398169], max_reward_err:  0.0139, max_reward_err_index: 1, max_kl_dist:  0.6674, max_kl_dist_index: 0, max_train_grp_loss:  13.0799, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6956, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2140, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:40:45,786 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  165, train_loss:  12.1572, val_loss:  12.4334, grad_norm: 0.0086, live_grad: 0.0000, reward_err: 0.0105, 0.0139, 0.0002, KL_dist: 0.6675, 0.3110, 0.6599, param: [5.45830307 8.25087821 5.23565922 8.72705813], weights: [0.28368754 0.29323172 0.42308074], train_wt_loss:  36.4715, val_wt_loss: 37.3002, train_grp_loss: [11.81778954 13.07998604 10.6985931 ], val_grp_loss: [12.69575994 12.45861305 12.14501714], train_hist_grp_loss: [15.74416981 17.39865635 35.72865158], cur_train_grp_loss: [0.0945422  0.10463886 0.21397678], max_reward_err:  0.0139, max_reward_err_index: 1, max_kl_dist:  0.6675, max_kl_dist_index: 0, max_train_grp_loss:  13.0800, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6958, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2140, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:40:46,831 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  166, train_loss:  12.1572, val_loss:  12.4335, grad_norm: 0.0087, live_grad: 0.0000, reward_err: 0.0105, 0.0139, 0.0002, KL_dist: 0.6675, 0.3110, 0.6600, param: [5.45837404 8.25061583 5.2362566  8.72818727], weights: [0.28338403 0.29297716 0.4236388 ], train_wt_loss:  36.4716, val_wt_loss: 37.3004, train_grp_loss: [11.81780302 13.08011535 10.69834673], val_grp_loss: [12.69588403 12.45876565 12.14498773], train_hist_grp_loss: [15.83871212 17.50329624 35.94262344], cur_train_grp_loss: [0.09454232 0.10463989 0.21397186], max_reward_err:  0.0139, max_reward_err_index: 1, max_kl_dist:  0.6675, max_kl_dist_index: 0, max_train_grp_loss:  13.0801, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6959, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2140, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:40:47,846 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  167, train_loss:  12.1572, val_loss:  12.4336, grad_norm: 0.0088, live_grad: 0.0000, reward_err: 0.0105, 0.0139, 0.0002, KL_dist: 0.6676, 0.3111, 0.6601, param: [5.45844469 8.25035386 5.23685453 8.7293189 ], weights: [0.2830805  0.29272247 0.42419703], train_wt_loss:  36.4716, val_wt_loss: 37.3007, train_grp_loss: [11.81781572 13.08024596 10.69809994], val_grp_loss: [12.69600748 12.45891975 12.14495807], train_hist_grp_loss: [15.93325455 17.60793716 36.15659037], cur_train_grp_loss: [0.09454242 0.10464092 0.21396693], max_reward_err:  0.0139, max_reward_err_index: 1, max_kl_dist:  0.6676, max_kl_dist_index: 0, max_train_grp_loss:  13.0802, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6960, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2140, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:40:48,877 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  168, train_loss:  12.1572, val_loss:  12.4336, grad_norm: 0.0088, live_grad: 0.0000, reward_err: 0.0105, 0.0139, 0.0002, KL_dist: 0.6677, 0.3111, 0.6602, param: [5.45851501 8.25009231 5.23745303 8.73045301], weights: [0.28277694 0.29246764 0.42475541], train_wt_loss:  36.4717, val_wt_loss: 37.3009, train_grp_loss: [11.81782766 13.08037788 10.6978527 ], val_grp_loss: [12.6961303  12.45907534 12.14492814], train_hist_grp_loss: [16.02779707 17.71257913 36.37055237], cur_train_grp_loss: [0.09454253 0.10464197 0.213962  ], max_reward_err:  0.0139, max_reward_err_index: 1, max_kl_dist:  0.6677, max_kl_dist_index: 0, max_train_grp_loss:  13.0804, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6961, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2140, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:40:49,925 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  169, train_loss:  12.1572, val_loss:  12.4337, grad_norm: 0.0089, live_grad: 0.0000, reward_err: 0.0105, 0.0139, 0.0002, KL_dist: 0.6678, 0.3111, 0.6602, param: [5.45858501 8.24983117 5.23805208 8.73158961], weights: [0.28247336 0.29221268 0.42531396], train_wt_loss:  36.4717, val_wt_loss: 37.3012, train_grp_loss: [11.81783884 13.08051111 10.69760504], val_grp_loss: [12.6962525  12.45923243 12.14489796], train_hist_grp_loss: [16.12233969 17.81722215 36.58450943], cur_train_grp_loss: [0.09454262 0.10464302 0.21395705], max_reward_err:  0.0139, max_reward_err_index: 1, max_kl_dist:  0.6678, max_kl_dist_index: 0, max_train_grp_loss:  13.0805, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6963, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2140, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:40:50,948 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  170, train_loss:  12.1573, val_loss:  12.4338, grad_norm: 0.0090, live_grad: 0.0000, reward_err: 0.0105, 0.0139, 0.0002, KL_dist: 0.6679, 0.3112, 0.6603, param: [5.45865468 8.24957044 5.23865168 8.7327287 ], weights: [0.28216975 0.29195758 0.42587267], train_wt_loss:  36.4718, val_wt_loss: 37.3014, train_grp_loss: [11.81784924 13.08064566 10.69735693], val_grp_loss: [12.69637406 12.45939101 12.14486752], train_hist_grp_loss: [16.21688241 17.92186624 36.79846153], cur_train_grp_loss: [0.09454271 0.10464409 0.2139521 ], max_reward_err:  0.0139, max_reward_err_index: 1, max_kl_dist:  0.6679, max_kl_dist_index: 0, max_train_grp_loss:  13.0806, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6964, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2140, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:40:51,996 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  171, train_loss:  12.1573, val_loss:  12.4339, grad_norm: 0.0091, live_grad: 0.0000, reward_err: 0.0105, 0.0139, 0.0002, KL_dist: 0.6679, 0.3112, 0.6604, param: [5.45872403 8.24931012 5.23925185 8.73387029], weights: [0.28186611 0.29170234 0.42643155], train_wt_loss:  36.4719, val_wt_loss: 37.3017, train_grp_loss: [11.81785888 13.08078151 10.6971084 ], val_grp_loss: [12.696495   12.45955108 12.14483681], train_hist_grp_loss: [16.3114252  18.0265114  37.01240867], cur_train_grp_loss: [0.09454279 0.10464517 0.21394714], max_reward_err:  0.0139, max_reward_err_index: 1, max_kl_dist:  0.6679, max_kl_dist_index: 0, max_train_grp_loss:  13.0808, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6965, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2139, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:40:53,021 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  172, train_loss:  12.1573, val_loss:  12.4340, grad_norm: 0.0091, live_grad: 0.0000, reward_err: 0.0105, 0.0139, 0.0002, KL_dist: 0.6680, 0.3113, 0.6605, param: [5.45879305 8.24905021 5.23985257 8.73501437], weights: [0.28156245 0.29144697 0.42699057], train_wt_loss:  36.4719, val_wt_loss: 37.3019, train_grp_loss: [11.81786776 13.08091868 10.69685943], val_grp_loss: [12.6966153  12.45971265 12.14480585], train_hist_grp_loss: [16.40596807 18.13115766 37.22635083], cur_train_grp_loss: [0.09454287 0.10464625 0.21394217], max_reward_err:  0.0139, max_reward_err_index: 1, max_kl_dist:  0.6680, max_kl_dist_index: 0, max_train_grp_loss:  13.0809, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6966, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2139, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:40:54,037 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  173, train_loss:  12.1573, val_loss:  12.4341, grad_norm: 0.0092, live_grad: 0.0000, reward_err: 0.0105, 0.0139, 0.0002, KL_dist: 0.6681, 0.3113, 0.6605, param: [5.45886175 8.24879071 5.24045385 8.73616094], weights: [0.28125877 0.29119147 0.42754976], train_wt_loss:  36.4720, val_wt_loss: 37.3022, train_grp_loss: [11.81787587 13.08105716 10.69661002], val_grp_loss: [12.69673498 12.45987572 12.14477464], train_hist_grp_loss: [16.50051101 18.23580501 37.44028802], cur_train_grp_loss: [0.09454294 0.10464735 0.21393719], max_reward_err:  0.0139, max_reward_err_index: 1, max_kl_dist:  0.6681, max_kl_dist_index: 0, max_train_grp_loss:  13.0811, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6967, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2139, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:40:55,085 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  174, train_loss:  12.1573, val_loss:  12.4341, grad_norm: 0.0093, live_grad: 0.0000, reward_err: 0.0105, 0.0139, 0.0002, KL_dist: 0.6682, 0.3114, 0.6606, param: [5.45893012 8.24853162 5.24105569 8.73731001], weights: [0.28095507 0.29093583 0.4281091 ], train_wt_loss:  36.4720, val_wt_loss: 37.3024, train_grp_loss: [11.81788322 13.08119696 10.69636019], val_grp_loss: [12.69685403 12.46004028 12.14474316], train_hist_grp_loss: [16.59505402 18.34045346 37.65422022], cur_train_grp_loss: [0.09454301 0.10464846 0.2139322 ], max_reward_err:  0.0139, max_reward_err_index: 1, max_kl_dist:  0.6682, max_kl_dist_index: 0, max_train_grp_loss:  13.0812, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6969, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2139, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:40:56,121 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  175, train_loss:  12.1574, val_loss:  12.4342, grad_norm: 0.0093, live_grad: 0.0000, reward_err: 0.0105, 0.0139, 0.0002, KL_dist: 0.6682, 0.3114, 0.6607, param: [5.45899816 8.24827293 5.24165809 8.73846157], weights: [0.28065134 0.29068007 0.4286686 ], train_wt_loss:  36.4721, val_wt_loss: 37.3027, train_grp_loss: [11.8178898  13.08133807 10.69610991], val_grp_loss: [12.69697245 12.46020635 12.14471144], train_hist_grp_loss: [16.68959709 18.44510304 37.86814743], cur_train_grp_loss: [0.09454307 0.10464958 0.2139272 ], max_reward_err:  0.0139, max_reward_err_index: 1, max_kl_dist:  0.6682, max_kl_dist_index: 0, max_train_grp_loss:  13.0813, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6970, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2139, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:40:57,151 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  176, train_loss:  12.1574, val_loss:  12.4343, grad_norm: 0.0094, live_grad: 0.0000, reward_err: 0.0105, 0.0139, 0.0002, KL_dist: 0.6683, 0.3114, 0.6608, param: [5.45906588 8.24801465 5.24226105 8.73961563], weights: [0.28034759 0.29042417 0.42922824], train_wt_loss:  36.4721, val_wt_loss: 37.3029, train_grp_loss: [11.81789562 13.0814805  10.69585921], val_grp_loss: [12.69709024 12.46037391 12.14467945], train_hist_grp_loss: [16.7841402  18.54975374 38.08206963], cur_train_grp_loss: [0.09454312 0.1046507  0.2139222 ], max_reward_err:  0.0139, max_reward_err_index: 1, max_kl_dist:  0.6683, max_kl_dist_index: 0, max_train_grp_loss:  13.0815, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6971, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2139, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:40:58,175 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  177, train_loss:  12.1574, val_loss:  12.4344, grad_norm: 0.0095, live_grad: 0.0000, reward_err: 0.0105, 0.0139, 0.0002, KL_dist: 0.6684, 0.3115, 0.6609, param: [5.45913327 8.24775677 5.24286457 8.74077219], weights: [0.28004382 0.29016814 0.42978804], train_wt_loss:  36.4722, val_wt_loss: 37.3032, train_grp_loss: [11.81790068 13.08162424 10.69560808], val_grp_loss: [12.69720741 12.46054297 12.14464721], train_hist_grp_loss: [16.87868337 18.65440559 38.29598681], cur_train_grp_loss: [0.09454316 0.10465184 0.21391718], max_reward_err:  0.0139, max_reward_err_index: 1, max_kl_dist:  0.6684, max_kl_dist_index: 0, max_train_grp_loss:  13.0816, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6972, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2139, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:40:59,210 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  178, train_loss:  12.1574, val_loss:  12.4345, grad_norm: 0.0096, live_grad: 0.0000, reward_err: 0.0105, 0.0139, 0.0002, KL_dist: 0.6685, 0.3115, 0.6609, param: [5.45920033 8.24749929 5.24346865 8.74193126], weights: [0.27974003 0.28991198 0.43034799], train_wt_loss:  36.4723, val_wt_loss: 37.3034, train_grp_loss: [11.81790498 13.0817693  10.69535651], val_grp_loss: [12.69732396 12.46071353 12.14461472], train_hist_grp_loss: [16.97322657 18.75905858 38.50989897], cur_train_grp_loss: [0.09454321 0.10465299 0.21391216], max_reward_err:  0.0139, max_reward_err_index: 1, max_kl_dist:  0.6685, max_kl_dist_index: 0, max_train_grp_loss:  13.0818, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6973, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2139, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:41:00,215 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  179, train_loss:  12.1574, val_loss:  12.4346, grad_norm: 0.0096, live_grad: 0.0000, reward_err: 0.0105, 0.0139, 0.0002, KL_dist: 0.6686, 0.3116, 0.6610, param: [5.45926706 8.24724222 5.2440733  8.74309282], weights: [0.27943622 0.28965569 0.43090809], train_wt_loss:  36.4723, val_wt_loss: 37.3037, train_grp_loss: [11.81790852 13.08191568 10.69510451], val_grp_loss: [12.69743988 12.46088559 12.14458198], train_hist_grp_loss: [17.06776981 18.86371274 38.7238061 ], cur_train_grp_loss: [0.09454324 0.10465415 0.21390713], max_reward_err:  0.0139, max_reward_err_index: 1, max_kl_dist:  0.6686, max_kl_dist_index: 0, max_train_grp_loss:  13.0819, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6974, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2139, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:41:01,257 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  180, train_loss:  12.1575, val_loss:  12.4347, grad_norm: 0.0097, live_grad: 0.0000, reward_err: 0.0105, 0.0139, 0.0002, KL_dist: 0.6686, 0.3116, 0.6611, param: [5.45933346 8.24698554 5.2446785  8.74425689], weights: [0.2791324  0.28939927 0.43146833], train_wt_loss:  36.4724, val_wt_loss: 37.3040, train_grp_loss: [11.8179113  13.08206337 10.69485208], val_grp_loss: [12.69755517 12.46105915 12.14454898], train_hist_grp_loss: [17.16231308 18.96836806 38.93770819], cur_train_grp_loss: [0.09454327 0.10465533 0.21390209], max_reward_err:  0.0139, max_reward_err_index: 1, max_kl_dist:  0.6686, max_kl_dist_index: 0, max_train_grp_loss:  13.0821, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6976, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2139, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:41:02,287 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  181, train_loss:  12.1575, val_loss:  12.4347, grad_norm: 0.0098, live_grad: 0.0000, reward_err: 0.0105, 0.0139, 0.0002, KL_dist: 0.6687, 0.3117, 0.6612, param: [5.45939953 8.24672927 5.24528427 8.74542346], weights: [0.27882855 0.28914273 0.43202872], train_wt_loss:  36.4725, val_wt_loss: 37.3042, train_grp_loss: [11.81791333 13.08221238 10.69459922], val_grp_loss: [12.69766984 12.46123422 12.14451573], train_hist_grp_loss: [17.25685637 19.07302457 39.15160523], cur_train_grp_loss: [0.09454329 0.10465651 0.21389704], max_reward_err:  0.0139, max_reward_err_index: 1, max_kl_dist:  0.6687, max_kl_dist_index: 0, max_train_grp_loss:  13.0822, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6977, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2139, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:41:03,330 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  182, train_loss:  12.1575, val_loss:  12.4348, grad_norm: 0.0098, live_grad: 0.0000, reward_err: 0.0105, 0.0139, 0.0002, KL_dist: 0.6688, 0.3117, 0.6613, param: [5.45946527 8.24647339 5.2458906  8.74659253], weights: [0.27852469 0.28888606 0.43258925], train_wt_loss:  36.4725, val_wt_loss: 37.3045, train_grp_loss: [11.81791459 13.08236271 10.69434593], val_grp_loss: [12.69778389 12.46141078 12.14448222], train_hist_grp_loss: [17.35139968 19.17768227 39.36549722], cur_train_grp_loss: [0.09454331 0.1046577  0.21389198], max_reward_err:  0.0139, max_reward_err_index: 1, max_kl_dist:  0.6688, max_kl_dist_index: 0, max_train_grp_loss:  13.0824, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6978, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2139, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:41:04,378 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  183, train_loss:  12.1575, val_loss:  12.4349, grad_norm: 0.0099, live_grad: 0.0000, reward_err: 0.0105, 0.0143, 0.0002, KL_dist: 0.6689, 0.3118, 0.6613, param: [5.45953068 8.24621791 5.24649749 8.74776412], weights: [0.27822081 0.28862927 0.43314992], train_wt_loss:  36.4726, val_wt_loss: 37.3047, train_grp_loss: [11.8179151  13.08251436 10.6940922 ], val_grp_loss: [12.69789732 12.46158886 12.14444847], train_hist_grp_loss: [17.445943   19.28234117 39.57938414], cur_train_grp_loss: [0.09454332 0.1046589  0.21388692], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6689, max_kl_dist_index: 0, max_train_grp_loss:  13.0825, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6979, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2139, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:41:05,415 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  184, train_loss:  12.1575, val_loss:  12.4350, grad_norm: 0.0100, live_grad: 0.0000, reward_err: 0.0105, 0.0143, 0.0002, KL_dist: 0.6690, 0.3118, 0.6614, param: [5.45959576 8.24596283 5.24710495 8.74893821], weights: [0.27791692 0.28837235 0.43371074], train_wt_loss:  36.4726, val_wt_loss: 37.3050, train_grp_loss: [11.81791485 13.08266733 10.69383805], val_grp_loss: [12.69801012 12.46176843 12.14441447], train_hist_grp_loss: [17.54048632 19.38700128 39.79326598], cur_train_grp_loss: [0.09454332 0.10466011 0.21388184], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6690, max_kl_dist_index: 0, max_train_grp_loss:  13.0827, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6980, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2139, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:41:06,506 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  185, train_loss:  12.1576, val_loss:  12.4351, grad_norm: 0.0101, live_grad: 0.0000, reward_err: 0.0105, 0.0143, 0.0002, KL_dist: 0.6690, 0.3118, 0.6615, param: [5.45966051 8.24570814 5.24771297 8.75011481], weights: [0.27761301 0.2881153  0.43427169], train_wt_loss:  36.4727, val_wt_loss: 37.3052, train_grp_loss: [11.81791385 13.08282162 10.69358347], val_grp_loss: [12.6981223  12.46194951 12.14438022], train_hist_grp_loss: [17.63502964 19.49166262 40.00714274], cur_train_grp_loss: [0.09454332 0.10466134 0.21387676], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6690, max_kl_dist_index: 0, max_train_grp_loss:  13.0828, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6981, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2139, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:41:07,558 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  186, train_loss:  12.1576, val_loss:  12.4352, grad_norm: 0.0101, live_grad: 0.0000, reward_err: 0.0105, 0.0143, 0.0002, KL_dist: 0.6691, 0.3119, 0.6616, param: [5.45972492 8.24545384 5.24832156 8.75129392], weights: [0.27730909 0.28785813 0.43483278], train_wt_loss:  36.4728, val_wt_loss: 37.3055, train_grp_loss: [11.81791209 13.08297724 10.69332845], val_grp_loss: [12.69823387 12.4621321  12.14434571], train_hist_grp_loss: [17.72957295 19.59632519 40.22101441], cur_train_grp_loss: [0.09454331 0.10466257 0.21387167], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6691, max_kl_dist_index: 0, max_train_grp_loss:  13.0830, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6982, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2139, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:41:08,551 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  187, train_loss:  12.1576, val_loss:  12.4353, grad_norm: 0.0102, live_grad: 0.0000, reward_err: 0.0105, 0.0143, 0.0002, KL_dist: 0.6692, 0.3119, 0.6616, param: [5.459789   8.24519993 5.24893071 8.75247554], weights: [0.27700515 0.28760084 0.43539401], train_wt_loss:  36.4728, val_wt_loss: 37.3058, train_grp_loss: [11.81790958 13.08313417 10.69307301], val_grp_loss: [12.69834481 12.46231619 12.14431096], train_hist_grp_loss: [17.82411624 19.70098901 40.43488098], cur_train_grp_loss: [0.0945433  0.10466382 0.21386657], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6692, max_kl_dist_index: 0, max_train_grp_loss:  13.0831, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6983, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2139, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:41:09,630 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  188, train_loss:  12.1576, val_loss:  12.4353, grad_norm: 0.0103, live_grad: 0.0000, reward_err: 0.0105, 0.0143, 0.0002, KL_dist: 0.6693, 0.3120, 0.6617, param: [5.45985275 8.24494642 5.24954042 8.75365968], weights: [0.2767012  0.28734343 0.43595537], train_wt_loss:  36.4729, val_wt_loss: 37.3060, train_grp_loss: [11.81790632 13.08329242 10.69281714], val_grp_loss: [12.69845513 12.46250179 12.14427597], train_hist_grp_loss: [17.91865952 19.80565409 40.64874244], cur_train_grp_loss: [0.09454328 0.10466507 0.21386146], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6693, max_kl_dist_index: 0, max_train_grp_loss:  13.0833, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6985, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2139, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:41:10,630 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  189, train_loss:  12.1577, val_loss:  12.4354, grad_norm: 0.0104, live_grad: 0.0000, reward_err: 0.0105, 0.0143, 0.0002, KL_dist: 0.6694, 0.3120, 0.6618, param: [5.45991617 8.2446933  5.25015071 8.75484632], weights: [0.27639724 0.28708589 0.43651687], train_wt_loss:  36.4730, val_wt_loss: 37.3063, train_grp_loss: [11.8179023  13.083452   10.69256084], val_grp_loss: [12.69856483 12.4626889  12.14424072], train_hist_grp_loss: [18.01320277 19.91032043 40.86259878], cur_train_grp_loss: [0.09454325 0.10466634 0.21385634], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6694, max_kl_dist_index: 0, max_train_grp_loss:  13.0835, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6986, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2139, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:41:11,649 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  190, train_loss:  12.1577, val_loss:  12.4355, grad_norm: 0.0104, live_grad: 0.0000, reward_err: 0.0105, 0.0143, 0.0002, KL_dist: 0.6695, 0.3121, 0.6619, param: [5.45997925 8.24444056 5.25076156 8.75603549], weights: [0.27609326 0.28682824 0.4370785 ], train_wt_loss:  36.4730, val_wt_loss: 37.3065, train_grp_loss: [11.81789754 13.0836129  10.69230411], val_grp_loss: [12.69867392 12.46287751 12.14420523], train_hist_grp_loss: [18.10774599 20.01498804 41.07645   ], cur_train_grp_loss: [0.09454322 0.10466762 0.21385122], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6695, max_kl_dist_index: 0, max_train_grp_loss:  13.0836, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6987, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2139, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:41:12,678 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  191, train_loss:  12.1577, val_loss:  12.4356, grad_norm: 0.0105, live_grad: 0.0000, reward_err: 0.0105, 0.0143, 0.0002, KL_dist: 0.6695, 0.3121, 0.6620, param: [5.460042   8.24418821 5.25137297 8.75722717], weights: [0.27578928 0.28657046 0.43764025], train_wt_loss:  36.4731, val_wt_loss: 37.3068, train_grp_loss: [11.81789202 13.08377513 10.69204696], val_grp_loss: [12.69878239 12.46306764 12.1441695 ], train_hist_grp_loss: [18.20228917 20.11965694 41.29029608], cur_train_grp_loss: [0.09454318 0.1046689  0.21384608], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6695, max_kl_dist_index: 0, max_train_grp_loss:  13.0838, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6988, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2138, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:41:13,735 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  192, train_loss:  12.1577, val_loss:  12.4357, grad_norm: 0.0106, live_grad: 0.0000, reward_err: 0.0105, 0.0143, 0.0002, KL_dist: 0.6696, 0.3122, 0.6621, param: [5.46010441 8.24393625 5.25198496 8.75842136], weights: [0.27548529 0.28631257 0.43820214], train_wt_loss:  36.4732, val_wt_loss: 37.3071, train_grp_loss: [11.81788576 13.08393868 10.69178938], val_grp_loss: [12.69889024 12.46325928 12.14413351], train_hist_grp_loss: [18.2968323  20.22432715 41.50413702], cur_train_grp_loss: [0.09454314 0.1046702  0.21384094], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6696, max_kl_dist_index: 0, max_train_grp_loss:  13.0839, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6989, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2138, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:41:14,782 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  193, train_loss:  12.1577, val_loss:  12.4358, grad_norm: 0.0106, live_grad: 0.0000, reward_err: 0.0105, 0.0143, 0.0002, KL_dist: 0.6697, 0.3122, 0.6621, param: [5.46016649 8.24368468 5.25259751 8.75961808], weights: [0.27518128 0.28605456 0.43876416], train_wt_loss:  36.4732, val_wt_loss: 37.3073, train_grp_loss: [11.81787874 13.08410355 10.69153137], val_grp_loss: [12.69899748 12.46345242 12.14409729], train_hist_grp_loss: [18.39137539 20.32899866 41.71797281], cur_train_grp_loss: [0.09454309 0.10467151 0.21383579], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6697, max_kl_dist_index: 0, max_train_grp_loss:  13.0841, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6990, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2138, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:41:15,779 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  194, train_loss:  12.1578, val_loss:  12.4359, grad_norm: 0.0107, live_grad: 0.0000, reward_err: 0.0105, 0.0143, 0.0002, KL_dist: 0.6698, 0.3122, 0.6622, param: [5.46022823 8.24343348 5.25321063 8.76081731], weights: [0.27487727 0.28579643 0.4393263 ], train_wt_loss:  36.4733, val_wt_loss: 37.3076, train_grp_loss: [11.81787098 13.08426975 10.69127293], val_grp_loss: [12.6991041  12.46364708 12.14406082], train_hist_grp_loss: [18.48591842 20.43367148 41.93180344], cur_train_grp_loss: [0.09454303 0.10467283 0.21383063], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6698, max_kl_dist_index: 0, max_train_grp_loss:  13.0843, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6991, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2138, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:41:16,833 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  195, train_loss:  12.1578, val_loss:  12.4360, grad_norm: 0.0108, live_grad: 0.0000, reward_err: 0.0105, 0.0143, 0.0002, KL_dist: 0.6699, 0.3123, 0.6623, param: [5.46028963 8.24318267 5.25382432 8.76201907], weights: [0.27457325 0.28553818 0.43988856], train_wt_loss:  36.4734, val_wt_loss: 37.3079, train_grp_loss: [11.81786247 13.08443728 10.69101407], val_grp_loss: [12.6992101  12.46384325 12.14402411], train_hist_grp_loss: [18.58046139 20.53834564 42.14562889], cur_train_grp_loss: [0.09454297 0.10467416 0.21382546], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6699, max_kl_dist_index: 0, max_train_grp_loss:  13.0844, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6992, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2138, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:41:17,835 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  196, train_loss:  12.1578, val_loss:  12.4360, grad_norm: 0.0109, live_grad: 0.0000, reward_err: 0.0105, 0.0143, 0.0002, KL_dist: 0.6699, 0.3123, 0.6624, param: [5.4603507  8.24293224 5.25443858 8.76322334], weights: [0.27426922 0.28527982 0.44045095], train_wt_loss:  36.4735, val_wt_loss: 37.3081, train_grp_loss: [11.81785322 13.08460613 10.69075478], val_grp_loss: [12.69931549 12.46404093 12.14398715], train_hist_grp_loss: [18.67500429 20.64302114 42.35944918], cur_train_grp_loss: [0.0945429  0.1046755  0.21382028], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6699, max_kl_dist_index: 0, max_train_grp_loss:  13.0846, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6993, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2138, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:41:18,864 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  197, train_loss:  12.1578, val_loss:  12.4361, grad_norm: 0.0110, live_grad: 0.0000, reward_err: 0.0105, 0.0143, 0.0002, KL_dist: 0.6700, 0.3124, 0.6625, param: [5.46041143 8.2426822  5.25505341 8.76443014], weights: [0.27396519 0.28502135 0.44101346], train_wt_loss:  36.4735, val_wt_loss: 37.3084, train_grp_loss: [11.81784322 13.08477631 10.69049506], val_grp_loss: [12.69942027 12.46424012 12.14394996], train_hist_grp_loss: [18.76954711 20.74769799 42.57326427], cur_train_grp_loss: [0.09454283 0.10467685 0.2138151 ], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6700, max_kl_dist_index: 0, max_train_grp_loss:  13.0848, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6994, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2138, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:41:19,878 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  198, train_loss:  12.1579, val_loss:  12.4362, grad_norm: 0.0110, live_grad: 0.0000, reward_err: 0.0105, 0.0143, 0.0002, KL_dist: 0.6701, 0.3124, 0.6625, param: [5.46047182 8.24243253 5.25566881 8.76563946], weights: [0.27366115 0.28476276 0.44157609], train_wt_loss:  36.4736, val_wt_loss: 37.3087, train_grp_loss: [11.81783247 13.08494782 10.69023492], val_grp_loss: [12.69952443 12.46444083 12.14391252], train_hist_grp_loss: [18.86408986 20.8523762  42.78707417], cur_train_grp_loss: [0.09454275 0.10467821 0.2138099 ], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6701, max_kl_dist_index: 0, max_train_grp_loss:  13.0849, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6995, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2138, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:41:20,899 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  199, train_loss:  12.1579, val_loss:  12.4363, grad_norm: 0.0111, live_grad: 0.0000, reward_err: 0.0105, 0.0143, 0.0002, KL_dist: 0.6702, 0.3125, 0.6626, param: [5.46053188 8.24218323 5.25628477 8.76685131], weights: [0.27335711 0.28450405 0.44213884], train_wt_loss:  36.4737, val_wt_loss: 37.3089, train_grp_loss: [11.81782098 13.08512066 10.68997436], val_grp_loss: [12.69962799 12.46464305 12.14387484], train_hist_grp_loss: [18.95863252 20.95705578 43.00087887], cur_train_grp_loss: [0.09454266 0.10467958 0.2138047 ], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6702, max_kl_dist_index: 0, max_train_grp_loss:  13.0851, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6996, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2138, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:41:21,840 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1654] - INFO: Iteration:  199, train_loss:  12.1579, val_loss:  12.4363, grad_norm: 0.0111,  live_grad: 0.0000, reward_err: 0.0105, 0.0143, 0.0002, KL_dist: 0.6702, 0.3125, 0.6626, param: [5.46053188 8.24218323 5.25628477 8.76685131], weights: [0.27335711 0.28450405 0.44213884], train_wt_loss:  36.4737, val_wt_loss: 37.3089, train_grp_loss: [11.81782098 13.08512066 10.68997436], val_grp_loss: [12.69962799 12.46464305 12.14387484], train_hist_grp_loss: [18.95863252 20.95705578 43.00087887], cur_train_grp_loss: [0.09454266 0.10467958 0.2138047 ], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6702, max_kl_dist_index: 0, max_train_grp_loss:  13.0851, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6996, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2138, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:41:22,069 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:388] - INFO: Policy parameter learned solely on the preference data rdpo: [5.46053188 8.24218323 5.25628477 8.76685131].
2024-10-07 00:41:22,423 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Uniform reward: 3.8318, 3.8318, 3.1647
2024-10-07 00:41:22,423 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Optimal reward: 3.8678, 7.2446, 3.2763
2024-10-07 00:41:22,424 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Policy reward: 3.8273, 7.1412, 3.2758
2024-10-07 00:41:22,424 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:402] - INFO: Reward Error: 0.0105, 0.0143, 0.0002
2024-10-07 00:41:23,126 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:417] - INFO: Optimal reward: 3.8678, 7.2446, 3.2763
Known param reward: [[3.867779541015625, 6.77779443359375, 3.255072021484375], [3.441058349609375, 7.24455908203125, 3.05710986328125], [3.841189453125, 7.1339345703125, 3.27631982421875]], Known param reward error: [[0.0, 0.06442968345654335, 0.0064852651372159075], [0.11032717529039895, 0.0, 0.06690737556116683], [0.006874768225192712, 0.015270013049259644, 0.0]].
