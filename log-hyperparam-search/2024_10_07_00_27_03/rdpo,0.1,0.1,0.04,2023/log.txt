2024-10-07 01:06:45,661 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log-hyperparam-search/2024_10_07_00_27_03/rdpo,0.1,0.1,0.04,2023
2024-10-07 01:06:45,663 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2023
2024-10-07 01:06:45,663 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-10-07 01:06:45,754 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.2729, l2 distance: 29.4548, acc: 0.92.
2024-10-07 01:06:45,754 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-10-07 01:06:45,755 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [ 6.99981245 12.85202501  8.22225193 12.39503134]
2024-10-07 01:06:45,973 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.8503, 7.1054, 3.3198
2024-10-07 01:06:46,203 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1314] - INFO: unique_group_ids: {0, 1, 2}
2024-10-07 01:06:47,435 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  0, train_loss:  12.6261, val_loss:  12.2166, grad_norm: 0.4066, live_grad: 0.0000, reward_err: 0.0095, 0.0189, 0.0009, KL_dist: 0.6768, 0.3238, 0.6777, param: [ 4.89950164  6.9788959   5.67511288 10.23466789], weights: [0.3322965  0.33244357 0.33525993], train_wt_loss:  37.8784, val_wt_loss: 36.6497, train_grp_loss: [11.44673755 13.75198256 13.00542884], val_grp_loss: [12.59492607 12.82818821 11.2247546 ], train_hist_grp_loss: [0.1342519  0.14531453 0.3562142 ], cur_train_grp_loss: [0.1342519  0.14531453 0.3562142 ], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6777, max_kl_dist_index: 2, max_train_grp_loss:  13.7520, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8282, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.3562, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:06:48,520 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  1, train_loss:  12.6261, val_loss:  12.2167, grad_norm: 0.0001, live_grad: 0.0000, reward_err: 0.0095, 0.0189, 0.0009, KL_dist: 0.6768, 0.3238, 0.6776, param: [ 4.89929671  6.97713763  5.67628934 10.23433124], weights: [0.33143064 0.33194242 0.33662694], train_wt_loss:  37.8784, val_wt_loss: 36.6501, train_grp_loss: [11.44786213 13.75069881 13.00555906], val_grp_loss: [12.59605193 12.82693902 11.22530838], train_hist_grp_loss: [0.22230373 0.26087741 0.61122261], cur_train_grp_loss: [0.08805183 0.11556288 0.25500841], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6776, max_kl_dist_index: 2, max_train_grp_loss:  13.7507, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8269, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:06:49,640 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  2, train_loss:  12.6261, val_loss:  12.2169, grad_norm: 0.0001, live_grad: 0.0000, reward_err: 0.0095, 0.0189, 0.0009, KL_dist: 0.6768, 0.3238, 0.6775, param: [ 4.89908586  6.97538445  5.67746375 10.23401256], weights: [0.33056432 0.33143902 0.33799666], train_wt_loss:  37.8784, val_wt_loss: 36.6506, train_grp_loss: [11.44897605 13.74942905 13.00568619], val_grp_loss: [12.59716809 12.82570661 11.22585761], train_hist_grp_loss: [0.31036421 0.3764295  0.86623357], cur_train_grp_loss: [0.08806048 0.11555209 0.25501096], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6775, max_kl_dist_index: 2, max_train_grp_loss:  13.7494, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8257, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:06:50,715 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  3, train_loss:  12.6261, val_loss:  12.2170, grad_norm: 0.0002, live_grad: 0.0000, reward_err: 0.0095, 0.0189, 0.0009, KL_dist: 0.6767, 0.3238, 0.6774, param: [ 4.89886909  6.97363637  5.67863609 10.23371191], weights: [0.32969753 0.3309334  0.33936907], train_wt_loss:  37.8784, val_wt_loss: 36.6510, train_grp_loss: [11.45007929 13.74817332 13.0058102 ], val_grp_loss: [12.59827452 12.82449103 11.22640227], train_hist_grp_loss: [0.39843325 0.49197092 1.12124702], cur_train_grp_loss: [0.08806905 0.11554142 0.25501345], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6774, max_kl_dist_index: 2, max_train_grp_loss:  13.7482, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8245, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:06:51,831 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  4, train_loss:  12.6261, val_loss:  12.2171, grad_norm: 0.0003, live_grad: 0.0000, reward_err: 0.0095, 0.0189, 0.0009, KL_dist: 0.6767, 0.3238, 0.6774, param: [ 4.89864638  6.97189339  5.67980638 10.23342933], weights: [0.32883029 0.33042557 0.34074414], train_wt_loss:  37.8784, val_wt_loss: 36.6514, train_grp_loss: [11.45117181 13.74693165 13.00593109], val_grp_loss: [12.59937117 12.82329231 11.22694234], train_hist_grp_loss: [0.48651079 0.60750179 1.37626291], cur_train_grp_loss: [0.08807753 0.11553087 0.25501589], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6774, max_kl_dist_index: 2, max_train_grp_loss:  13.7469, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8233, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:06:52,907 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  5, train_loss:  12.6261, val_loss:  12.2173, grad_norm: 0.0003, live_grad: 0.0000, reward_err: 0.0095, 0.0189, 0.0009, KL_dist: 0.6767, 0.3237, 0.6773, param: [ 4.8984177   6.97015551  5.68097459 10.2331649 ], weights: [0.32796261 0.32991553 0.34212186], train_wt_loss:  37.8784, val_wt_loss: 36.6519, train_grp_loss: [11.45225358 13.74570405 13.00604884], val_grp_loss: [12.60045803 12.8221105  11.2274778 ], train_hist_grp_loss: [0.57459672 0.72302222 1.63128116], cur_train_grp_loss: [0.08808594 0.11552043 0.25501826], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6773, max_kl_dist_index: 2, max_train_grp_loss:  13.7457, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8221, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:06:53,974 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  6, train_loss:  12.6261, val_loss:  12.2174, grad_norm: 0.0004, live_grad: 0.0000, reward_err: 0.0095, 0.0189, 0.0009, KL_dist: 0.6766, 0.3237, 0.6772, param: [ 4.89818306  6.96842272  5.68214073 10.23291867], weights: [0.3270945  0.32940328 0.34350221], train_wt_loss:  37.8784, val_wt_loss: 36.6523, train_grp_loss: [11.45332456 13.74449056 13.00616344], val_grp_loss: [12.60153505 12.82094563 11.22800863], train_hist_grp_loss: [0.66269098 0.83853234 1.88630173], cur_train_grp_loss: [0.08809426 0.11551012 0.25502057], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6772, max_kl_dist_index: 2, max_train_grp_loss:  13.7445, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8209, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:06:55,033 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  7, train_loss:  12.6261, val_loss:  12.2176, grad_norm: 0.0005, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6766, 0.3237, 0.6771, param: [ 4.89794244  6.96669501  5.6833048  10.2326907 ], weights: [0.32622597 0.32888885 0.34488518], train_wt_loss:  37.8784, val_wt_loss: 36.6527, train_grp_loss: [11.45438471 13.74329121 13.00627488], val_grp_loss: [12.60260221 12.81979774 11.22853482], train_hist_grp_loss: [0.75079348 0.95403226 2.14132454], cur_train_grp_loss: [0.0881025  0.11549992 0.25502281], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6771, max_kl_dist_index: 2, max_train_grp_loss:  13.7433, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8198, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:06:56,090 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  8, train_loss:  12.6261, val_loss:  12.2177, grad_norm: 0.0006, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6765, 0.3237, 0.6771, param: [ 4.89769582  6.9649724   5.68446677 10.23248105], weights: [0.32535703 0.32837224 0.34627073], train_wt_loss:  37.8784, val_wt_loss: 36.6532, train_grp_loss: [11.45543402 13.74210602 13.00638315], val_grp_loss: [12.60365948 12.81866688 11.22905634], train_hist_grp_loss: [0.83890413 1.0695221  2.39634954], cur_train_grp_loss: [0.08811065 0.11548984 0.255025  ], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6771, max_kl_dist_index: 2, max_train_grp_loss:  13.7421, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8187, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:06:57,114 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  9, train_loss:  12.6261, val_loss:  12.2179, grad_norm: 0.0007, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6765, 0.3237, 0.6770, param: [ 4.89744319  6.96325486  5.68562666 10.23228979], weights: [0.32448768 0.32785346 0.34765886], train_wt_loss:  37.8784, val_wt_loss: 36.6536, train_grp_loss: [11.45647243 13.74093503 13.00648822], val_grp_loss: [12.60470681 12.81755307 11.22957317], train_hist_grp_loss: [0.92702285 1.18500199 2.65137666], cur_train_grp_loss: [0.08811872 0.11547988 0.25502712], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6770, max_kl_dist_index: 2, max_train_grp_loss:  13.7409, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8176, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:06:58,119 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  10, train_loss:  12.6261, val_loss:  12.2180, grad_norm: 0.0007, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6765, 0.3236, 0.6769, param: [ 4.89718453  6.96154241  5.68678446 10.23211697], weights: [0.32361794 0.32733252 0.34904954], train_wt_loss:  37.8784, val_wt_loss: 36.6541, train_grp_loss: [11.45749992 13.73977826 13.0065901 ], val_grp_loss: [12.60574419 12.81645636 11.2300853 ], train_hist_grp_loss: [1.01514956 1.30047203 2.90640584], cur_train_grp_loss: [0.08812671 0.11547004 0.25502918], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6769, max_kl_dist_index: 2, max_train_grp_loss:  13.7398, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8165, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:06:59,145 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  11, train_loss:  12.6262, val_loss:  12.2182, grad_norm: 0.0008, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6765, 0.3236, 0.6769, param: [ 4.89691983  6.95983504  5.68794015 10.23196265], weights: [0.32274782 0.32680942 0.35044276], train_wt_loss:  37.8785, val_wt_loss: 36.6545, train_grp_loss: [11.45851646 13.73863574 13.00668876], val_grp_loss: [12.60677158 12.81537679 11.23059271], train_hist_grp_loss: [1.10328418 1.41593235 3.16143702], cur_train_grp_loss: [0.08813461 0.11546032 0.25503118], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6769, max_kl_dist_index: 2, max_train_grp_loss:  13.7386, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8154, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:07:00,172 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  12, train_loss:  12.6262, val_loss:  12.2183, grad_norm: 0.0009, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6764, 0.3236, 0.6768, param: [ 4.89664908  6.95813274  5.68909374 10.2318269 ], weights: [0.32187732 0.32628419 0.35183849], train_wt_loss:  37.8785, val_wt_loss: 36.6550, train_grp_loss: [11.45952201 13.73750751 13.00678419], val_grp_loss: [12.60778894 12.8143144  11.23109537], train_hist_grp_loss: [1.19142661 1.53138307 3.41647013], cur_train_grp_loss: [0.08814243 0.11545072 0.25503311], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6768, max_kl_dist_index: 2, max_train_grp_loss:  13.7375, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8143, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:07:01,215 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  13, train_loss:  12.6262, val_loss:  12.2185, grad_norm: 0.0010, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6764, 0.3236, 0.6767, param: [ 4.89637226  6.95643551  5.69024521 10.23170977], weights: [0.32100647 0.32575682 0.35323671], train_wt_loss:  37.8785, val_wt_loss: 36.6554, train_grp_loss: [11.46051654 13.73639358 13.00687639], val_grp_loss: [12.60879625 12.81326923 11.23159327], train_hist_grp_loss: [1.27957678 1.64682431 3.67150512], cur_train_grp_loss: [0.08815017 0.11544124 0.25503498], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6767, max_kl_dist_index: 2, max_train_grp_loss:  13.7364, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8133, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:07:02,226 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  14, train_loss:  12.6262, val_loss:  12.2186, grad_norm: 0.0011, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6764, 0.3236, 0.6767, param: [ 4.89608936  6.95474335  5.69139457 10.23161132], weights: [0.32013526 0.32522734 0.3546374 ], train_wt_loss:  37.8785, val_wt_loss: 36.6559, train_grp_loss: [11.46150002 13.73529399 13.00696533], val_grp_loss: [12.60979348 12.81224131 11.2320864 ], train_hist_grp_loss: [1.3677346  1.76225619 3.92654191], cur_train_grp_loss: [0.08815782 0.11543188 0.25503679], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6767, max_kl_dist_index: 2, max_train_grp_loss:  13.7353, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8122, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:07:03,254 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  15, train_loss:  12.6262, val_loss:  12.2188, grad_norm: 0.0012, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6763, 0.3236, 0.6766, param: [ 4.89580036  6.95305625  5.6925418  10.23153162], weights: [0.3192637  0.32469574 0.35604055], train_wt_loss:  37.8785, val_wt_loss: 36.6564, train_grp_loss: [11.46247241 13.73420877 13.007051  ], val_grp_loss: [12.61078059 12.8112307  11.23257473], train_hist_grp_loss: [1.45589999 1.87767883 4.18158044], cur_train_grp_loss: [0.08816538 0.11542264 0.25503854], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6766, max_kl_dist_index: 2, max_train_grp_loss:  13.7342, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8112, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:07:04,288 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  16, train_loss:  12.6262, val_loss:  12.2189, grad_norm: 0.0013, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6763, 0.3236, 0.6765, param: [ 4.89550525  6.95137422  5.6936869  10.23147072], weights: [0.31839182 0.32416205 0.35744613], train_wt_loss:  37.8785, val_wt_loss: 36.6568, train_grp_loss: [11.46343367 13.73313795 13.0071334 ], val_grp_loss: [12.61175755 12.81023743 11.23305824], train_hist_grp_loss: [1.54407285 1.99309235 4.43662066], cur_train_grp_loss: [0.08817286 0.11541352 0.25504022], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6765, max_kl_dist_index: 2, max_train_grp_loss:  13.7331, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8102, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:07:05,325 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  17, train_loss:  12.6262, val_loss:  12.2191, grad_norm: 0.0013, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6763, 0.3235, 0.6765, param: [ 4.89520401  6.94969723  5.69482987 10.23142869], weights: [0.31751961 0.32362626 0.35885412], train_wt_loss:  37.8786, val_wt_loss: 36.6573, train_grp_loss: [11.46438379 13.73208155 13.0072125 ], val_grp_loss: [12.61272433 12.80926153 11.23353692], train_hist_grp_loss: [1.63225311 2.10849687 4.69166249], cur_train_grp_loss: [0.08818026 0.11540452 0.25504183], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6765, max_kl_dist_index: 2, max_train_grp_loss:  13.7321, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8093, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:07:06,389 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  18, train_loss:  12.6262, val_loss:  12.2193, grad_norm: 0.0014, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6763, 0.3235, 0.6764, param: [ 4.89489664  6.9480253   5.69597069 10.23140559], weights: [0.3166471  0.3230884  0.36026451], train_wt_loss:  37.8786, val_wt_loss: 36.6578, train_grp_loss: [11.46532271 13.73103961 13.0072883 ], val_grp_loss: [12.61368089 12.80830306 11.23401075], train_hist_grp_loss: [1.72044068 2.22389251 4.94670587], cur_train_grp_loss: [0.08818757 0.11539564 0.25504338], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6764, max_kl_dist_index: 2, max_train_grp_loss:  13.7310, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8083, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:07:07,426 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  19, train_loss:  12.6262, val_loss:  12.2194, grad_norm: 0.0015, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6762, 0.3235, 0.6764, param: [ 4.89458311  6.94635842  5.69710936 10.23140147], weights: [0.31577428 0.32254847 0.36167726], train_wt_loss:  37.8786, val_wt_loss: 36.6582, train_grp_loss: [11.46625042 13.73001216 13.00736079], val_grp_loss: [12.61462722 12.80736204 11.2344797 ], train_hist_grp_loss: [1.80863547 2.3392794  5.20175074], cur_train_grp_loss: [0.08819479 0.11538689 0.25504487], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6764, max_kl_dist_index: 2, max_train_grp_loss:  13.7300, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8074, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:07:08,478 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  20, train_loss:  12.6262, val_loss:  12.2196, grad_norm: 0.0016, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6762, 0.3235, 0.6763, param: [ 4.89426342  6.94469657  5.69824588 10.23141641], weights: [0.31490117 0.32200647 0.36309236], train_wt_loss:  37.8786, val_wt_loss: 36.6587, train_grp_loss: [11.46716687 13.72899923 13.00742994], val_grp_loss: [12.61556327 12.80643854 11.23494377], train_hist_grp_loss: [1.89683739 2.45465765 5.45679703], cur_train_grp_loss: [0.08820193 0.11537825 0.25504629], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6763, max_kl_dist_index: 2, max_train_grp_loss:  13.7290, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8064, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:07:09,525 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  21, train_loss:  12.6262, val_loss:  12.2197, grad_norm: 0.0017, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6762, 0.3235, 0.6763, param: [ 4.89393754  6.94303977  5.69938024 10.23145045], weights: [0.31402778 0.32146244 0.36450978], train_wt_loss:  37.8786, val_wt_loss: 36.6592, train_grp_loss: [11.46807204 13.72800084 13.00749575], val_grp_loss: [12.61648902 12.80553257 11.23540294], train_hist_grp_loss: [1.98504637 2.57002739 5.71184468], cur_train_grp_loss: [0.08820898 0.11536974 0.25504765], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6763, max_kl_dist_index: 2, max_train_grp_loss:  13.7280, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8055, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:07:10,583 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  22, train_loss:  12.6262, val_loss:  12.2199, grad_norm: 0.0018, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6762, 0.3235, 0.6762, param: [ 4.89360546  6.941388    5.70051243 10.23150367], weights: [0.31315412 0.32091636 0.36592951], train_wt_loss:  37.8787, val_wt_loss: 36.6597, train_grp_loss: [11.46896588 13.72701703 13.00755821], val_grp_loss: [12.61740443 12.80464419 11.23585718], train_hist_grp_loss: [2.07326231 2.68538874 5.96689362], cur_train_grp_loss: [0.08821594 0.11536135 0.25504894], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6762, max_kl_dist_index: 2, max_train_grp_loss:  13.7270, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8046, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:07:11,595 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  23, train_loss:  12.6262, val_loss:  12.2200, grad_norm: 0.0019, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6762, 0.3235, 0.6762, param: [ 4.89326717  6.93974125  5.70164245 10.23157611], weights: [0.31228021 0.32036826 0.36735153], train_wt_loss:  37.8787, val_wt_loss: 36.6601, train_grp_loss: [11.46984838 13.72604783 13.0076173 ], val_grp_loss: [12.61830947 12.80377344 11.23630648], train_hist_grp_loss: [2.16148512 2.80074183 6.22194378], cur_train_grp_loss: [0.08822281 0.11535308 0.25505016], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6762, max_kl_dist_index: 2, max_train_grp_loss:  13.7260, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8038, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:07:12,643 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  24, train_loss:  12.6262, val_loss:  12.2202, grad_norm: 0.0019, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6761, 0.3235, 0.6761, param: [ 4.89292266  6.93809952  5.70277028 10.23166785], weights: [0.31140604 0.31981815 0.36877581], train_wt_loss:  37.8787, val_wt_loss: 36.6606, train_grp_loss: [11.47071949 13.72509327 13.00767302], val_grp_loss: [12.61920411 12.80292036 11.23675082], train_hist_grp_loss: [2.24971473 2.91608677 6.4769951 ], cur_train_grp_loss: [0.0882296  0.11534494 0.25505132], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6761, max_kl_dist_index: 0, max_train_grp_loss:  13.7251, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8029, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:07:13,689 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  25, train_loss:  12.6262, val_loss:  12.2204, grad_norm: 0.0020, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6761, 0.3235, 0.6761, param: [ 4.8925719   6.93646281  5.70389593 10.23177894], weights: [0.31053164 0.31926603 0.37020232], train_wt_loss:  37.8787, val_wt_loss: 36.6611, train_grp_loss: [11.47157919 13.72415338 13.00772534], val_grp_loss: [12.62008832 12.80208499 11.23719018], train_hist_grp_loss: [2.33795103 3.03142369 6.73204751], cur_train_grp_loss: [0.0882363  0.11533692 0.25505241], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6761, max_kl_dist_index: 0, max_train_grp_loss:  13.7242, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8021, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:07:14,744 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  26, train_loss:  12.6263, val_loss:  12.2205, grad_norm: 0.0021, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6761, 0.3234, 0.6760, param: [ 4.89221489  6.93483112  5.70501938 10.23190945], weights: [0.30965702 0.31871193 0.37163105], train_wt_loss:  37.8788, val_wt_loss: 36.6616, train_grp_loss: [11.47242743 13.72322818 13.00777425], val_grp_loss: [12.62096207 12.80126737 11.23762456], train_hist_grp_loss: [2.42619395 3.14675271 6.98710095], cur_train_grp_loss: [0.08824292 0.11532902 0.25505344], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6761, max_kl_dist_index: 0, max_train_grp_loss:  13.7232, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8013, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:07:15,815 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  27, train_loss:  12.6263, val_loss:  12.2207, grad_norm: 0.0022, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6761, 0.3234, 0.6760, param: [ 4.89185161  6.93320442  5.70614063 10.23205943], weights: [0.30878218 0.31815584 0.37306198], train_wt_loss:  37.8788, val_wt_loss: 36.6621, train_grp_loss: [11.4732642  13.72231772 13.00781975], val_grp_loss: [12.62182533 12.80046755 11.23805392], train_hist_grp_loss: [2.51444339 3.26207395 7.24215534], cur_train_grp_loss: [0.08824944 0.11532125 0.2550544 ], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6761, max_kl_dist_index: 0, max_train_grp_loss:  13.7223, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8005, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:07:16,844 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  28, train_loss:  12.6263, val_loss:  12.2209, grad_norm: 0.0023, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6761, 0.3234, 0.6759, param: [ 4.89148204  6.93158273  5.70725967 10.23222896], weights: [0.30790713 0.31759778 0.37449508], train_wt_loss:  37.8788, val_wt_loss: 36.6626, train_grp_loss: [11.47408945 13.72142202 13.00786182], val_grp_loss: [12.62267806 12.79968557 11.23847825], train_hist_grp_loss: [2.60269927 3.37738755 7.49721063], cur_train_grp_loss: [0.08825588 0.11531359 0.25505529], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6761, max_kl_dist_index: 0, max_train_grp_loss:  13.7214, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7997, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:07:17,892 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  29, train_loss:  12.6263, val_loss:  12.2210, grad_norm: 0.0024, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6761, 0.3234, 0.6759, param: [ 4.89110617  6.92996602  5.70837649 10.23241808], weights: [0.30703189 0.31703777 0.37593033], train_wt_loss:  37.8788, val_wt_loss: 36.6631, train_grp_loss: [11.47490315 13.72054112 13.00790045], val_grp_loss: [12.62352024 12.79892147 11.23889754], train_hist_grp_loss: [2.69096149 3.49269361 7.75226675], cur_train_grp_loss: [0.08826223 0.11530607 0.25505611], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6761, max_kl_dist_index: 0, max_train_grp_loss:  13.7205, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7989, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:07:18,924 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  30, train_loss:  12.6263, val_loss:  12.2212, grad_norm: 0.0025, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6760, 0.3234, 0.6758, param: [ 4.89072399  6.9283543   5.70949109 10.23262686], weights: [0.30615648 0.31647581 0.37736771], train_wt_loss:  37.8789, val_wt_loss: 36.6636, train_grp_loss: [11.47570528 13.71967504 13.00793562], val_grp_loss: [12.62435184 12.79817529 11.23931177], train_hist_grp_loss: [2.77922998 3.60799228 8.00732362], cur_train_grp_loss: [0.08826849 0.11529866 0.25505687], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6760, max_kl_dist_index: 0, max_train_grp_loss:  13.7197, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7982, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:07:19,987 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  31, train_loss:  12.6263, val_loss:  12.2214, grad_norm: 0.0026, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6760, 0.3234, 0.6758, param: [ 4.89033548  6.92674757  5.71060346 10.23285536], weights: [0.30528088 0.31591192 0.37880719], train_wt_loss:  37.8789, val_wt_loss: 36.6641, train_grp_loss: [11.47649579 13.71882381 13.00796733], val_grp_loss: [12.62517282 12.79744708 11.23972092], train_hist_grp_loss: [2.86750463 3.72328367 8.26238118], cur_train_grp_loss: [0.08827466 0.11529139 0.25505756], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6760, max_kl_dist_index: 0, max_train_grp_loss:  13.7188, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7974, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:07:21,008 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  32, train_loss:  12.6263, val_loss:  12.2215, grad_norm: 0.0026, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6760, 0.3234, 0.6758, param: [ 4.88994063  6.9251458   5.71171359 10.23310365], weights: [0.30440514 0.31534611 0.38024875], train_wt_loss:  37.8789, val_wt_loss: 36.6646, train_grp_loss: [11.47727466 13.71798747 13.00799556], val_grp_loss: [12.62598315 12.79673688 11.24012498], train_hist_grp_loss: [2.95578537 3.8385679  8.51743936], cur_train_grp_loss: [0.08828074 0.11528423 0.25505818], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6760, max_kl_dist_index: 0, max_train_grp_loss:  13.7180, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7967, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:07:22,044 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  33, train_loss:  12.6263, val_loss:  12.2217, grad_norm: 0.0027, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6760, 0.3234, 0.6757, param: [ 4.88953941  6.923549    5.71282148 10.23337178], weights: [0.30352924 0.31477839 0.38169237], train_wt_loss:  37.8790, val_wt_loss: 36.6651, train_grp_loss: [11.47804186 13.71716605 13.0080203 ], val_grp_loss: [12.62678281 12.79604473 11.24052393], train_hist_grp_loss: [3.0440721 3.9538451 8.7724981], cur_train_grp_loss: [0.08828673 0.11527721 0.25505874], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6760, max_kl_dist_index: 0, max_train_grp_loss:  13.7172, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7960, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:07:23,062 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  34, train_loss:  12.6263, val_loss:  12.2219, grad_norm: 0.0028, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6760, 0.3234, 0.6757, param: [ 4.88913182  6.92195715  5.71392711 10.23365981], weights: [0.3026532  0.31420877 0.38313803], train_wt_loss:  37.8790, val_wt_loss: 36.6656, train_grp_loss: [11.47879735 13.71635958 13.00804153], val_grp_loss: [12.62757176 12.79537068 11.24091774], train_hist_grp_loss: [3.13236473 4.06911541 9.02755732], cur_train_grp_loss: [0.08829263 0.1152703  0.25505922], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6760, max_kl_dist_index: 0, max_train_grp_loss:  13.7164, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7954, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:07:24,151 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  35, train_loss:  12.6263, val_loss:  12.2220, grad_norm: 0.0029, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6760, 0.3234, 0.6757, param: [ 4.88871785  6.92037026  5.71503048 10.23396782], weights: [0.30177704 0.31363726 0.38458569], train_wt_loss:  37.8790, val_wt_loss: 36.6661, train_grp_loss: [11.4795411  13.7155681  13.00805926], val_grp_loss: [12.62834997 12.79471477 11.24130642], train_hist_grp_loss: [3.22066317 4.18437893 9.28261696], cur_train_grp_loss: [0.08829844 0.11526353 0.25505964], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6760, max_kl_dist_index: 0, max_train_grp_loss:  13.7156, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7947, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:07:25,165 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  36, train_loss:  12.6264, val_loss:  12.2222, grad_norm: 0.0030, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6760, 0.3234, 0.6756, param: [ 4.88829747  6.91878831  5.71613158 10.23429585], weights: [0.30090077 0.31306389 0.38603534], train_wt_loss:  37.8791, val_wt_loss: 36.6666, train_grp_loss: [11.48027308 13.71479163 13.00807345], val_grp_loss: [12.62911742 12.79407704 11.24168993], train_hist_grp_loss: [3.30896733 4.29963581 9.53767694], cur_train_grp_loss: [0.08830416 0.11525687 0.25505999], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6760, max_kl_dist_index: 0, max_train_grp_loss:  13.7148, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7941, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:07:26,248 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  37, train_loss:  12.6264, val_loss:  12.2224, grad_norm: 0.0031, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6760, 0.3234, 0.6756, param: [ 4.88787067  6.9172113   5.71723041 10.23464397], weights: [0.30002439 0.31248865 0.38748696], train_wt_loss:  37.8791, val_wt_loss: 36.6671, train_grp_loss: [11.48099326 13.71403021 13.00808411], val_grp_loss: [12.62987406 12.79345753 11.24206827], train_hist_grp_loss: [3.39727713 4.41488616 9.79273721], cur_train_grp_loss: [0.08830979 0.11525035 0.25506026], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6760, max_kl_dist_index: 0, max_train_grp_loss:  13.7140, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7935, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:07:27,281 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  38, train_loss:  12.6264, val_loss:  12.2225, grad_norm: 0.0032, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6760, 0.3234, 0.6756, param: [ 4.88743743  6.91563921  5.71832695 10.23501225], weights: [0.29914793 0.31191156 0.38894051], train_wt_loss:  37.8791, val_wt_loss: 36.6676, train_grp_loss: [11.4817016  13.71328386 13.00809121], val_grp_loss: [12.63061988 12.7928563  11.24244142], train_hist_grp_loss: [ 3.48559246  4.53013011 10.04779768], cur_train_grp_loss: [0.08831533 0.11524395 0.25506047], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6760, max_kl_dist_index: 0, max_train_grp_loss:  13.7133, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7929, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:07:28,306 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  39, train_loss:  12.6264, val_loss:  12.2227, grad_norm: 0.0033, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6760, 0.3234, 0.6755, param: [ 4.88699775  6.91407204  5.7194212  10.23540074], weights: [0.29827138 0.31133264 0.39039598], train_wt_loss:  37.8792, val_wt_loss: 36.6681, train_grp_loss: [11.48239808 13.71255263 13.00809476], val_grp_loss: [12.63135484 12.79227339 11.24280936], train_hist_grp_loss: [ 3.57391324  4.64536779 10.30285829], cur_train_grp_loss: [0.08832078 0.11523768 0.25506061], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6760, max_kl_dist_index: 0, max_train_grp_loss:  13.7126, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7923, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:07:29,330 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  40, train_loss:  12.6264, val_loss:  12.2229, grad_norm: 0.0034, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6760, 0.3234, 0.6755, param: [ 4.88655161  6.91250978  5.72051315 10.2358095 ], weights: [0.29739477 0.3107519  0.39185333], train_wt_loss:  37.8792, val_wt_loss: 36.6687, train_grp_loss: [11.48308266 13.71183654 13.00809473], val_grp_loss: [12.6320789  12.79170883 11.24317208], train_hist_grp_loss: [ 3.66223938  4.76059932 10.55791897], cur_train_grp_loss: [0.08832614 0.11523153 0.25506068], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6760, max_kl_dist_index: 0, max_train_grp_loss:  13.7118, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7917, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:07:30,355 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  41, train_loss:  12.6264, val_loss:  12.2231, grad_norm: 0.0034, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6759, 0.3234, 0.6755, param: [ 4.88609898  6.91095242  5.72160279 10.2362386 ], weights: [0.2965181  0.31016934 0.39331256], train_wt_loss:  37.8793, val_wt_loss: 36.6692, train_grp_loss: [11.48375532 13.71113563 13.00809111], val_grp_loss: [12.63279205 12.79116268 11.24352955], train_hist_grp_loss: [ 3.75057078  4.87582484 10.81297965], cur_train_grp_loss: [0.08833141 0.11522552 0.25506068], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6759, max_kl_dist_index: 0, max_train_grp_loss:  13.7111, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7912, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:07:31,381 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  42, train_loss:  12.6264, val_loss:  12.2232, grad_norm: 0.0035, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6759, 0.3234, 0.6755, param: [ 4.88563986  6.90939996  5.72269011 10.2366881 ], weights: [0.29564138 0.30958499 0.39477362], train_wt_loss:  37.8793, val_wt_loss: 36.6697, train_grp_loss: [11.48441602 13.71044993 13.0080839 ], val_grp_loss: [12.63349425 12.79063498 11.24388178], train_hist_grp_loss: [ 3.83890736  4.99104447 11.06804026], cur_train_grp_loss: [0.08833658 0.11521963 0.25506061], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6759, max_kl_dist_index: 0, max_train_grp_loss:  13.7104, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7906, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:07:32,418 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  43, train_loss:  12.6264, val_loss:  12.2234, grad_norm: 0.0036, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6759, 0.3234, 0.6754, param: [ 4.88517423  6.90785238  5.7237751  10.23715806], weights: [0.29476464 0.30899886 0.39623651], train_wt_loss:  37.8793, val_wt_loss: 36.6702, train_grp_loss: [11.48506473 13.70977947 13.00807308], val_grp_loss: [12.63418548 12.79012577 11.24422874], train_hist_grp_loss: [ 3.92724903  5.10625833 11.32310073], cur_train_grp_loss: [0.08834166 0.11521386 0.25506047], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6759, max_kl_dist_index: 0, max_train_grp_loss:  13.7098, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7901, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:07:33,449 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  44, train_loss:  12.6265, val_loss:  12.2236, grad_norm: 0.0037, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6759, 0.3234, 0.6754, param: [ 4.88470208  6.90630967  5.72485777 10.23764854], weights: [0.29388787 0.30841095 0.39770118], train_wt_loss:  37.8794, val_wt_loss: 36.6708, train_grp_loss: [11.48570141 13.70912428 13.00805863], val_grp_loss: [12.63486569 12.7896351  11.24457041], train_hist_grp_loss: [ 4.01559568  5.22146656 11.57816099], cur_train_grp_loss: [0.08834665 0.11520823 0.25506026], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6759, max_kl_dist_index: 0, max_train_grp_loss:  13.7091, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7896, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:07:34,482 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  45, train_loss:  12.6265, val_loss:  12.2238, grad_norm: 0.0038, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6759, 0.3234, 0.6754, param: [ 4.88422339  6.90477183  5.72593809 10.2381596 ], weights: [0.2930111  0.30782128 0.39916762], train_wt_loss:  37.8794, val_wt_loss: 36.6713, train_grp_loss: [11.48632605 13.70848441 13.00804056], val_grp_loss: [12.63553487 12.78916301 11.24490678], train_hist_grp_loss: [ 4.10394723  5.33666929 11.83322096], cur_train_grp_loss: [0.08835155 0.11520273 0.25505997], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6759, max_kl_dist_index: 0, max_train_grp_loss:  13.7085, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7892, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:07:35,500 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  46, train_loss:  12.6265, val_loss:  12.2239, grad_norm: 0.0039, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6759, 0.3234, 0.6754, param: [ 4.88373814  6.90323885  5.72701606 10.2386913 ], weights: [0.29213432 0.30722987 0.4006358 ], train_wt_loss:  37.8795, val_wt_loss: 36.6718, train_grp_loss: [11.48693861 13.70785987 13.00801883], val_grp_loss: [12.63619298 12.78870955 11.24523784], train_hist_grp_loss: [ 4.19230358  5.45186664 12.08828058], cur_train_grp_loss: [0.08835635 0.11519735 0.25505962], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6759, max_kl_dist_index: 0, max_train_grp_loss:  13.7079, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7887, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:07:36,538 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  47, train_loss:  12.6265, val_loss:  12.2241, grad_norm: 0.0040, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6759, 0.3234, 0.6754, param: [ 4.88324633  6.90171071  5.72809167 10.23924372], weights: [0.29125757 0.30663673 0.4021057 ], train_wt_loss:  37.8795, val_wt_loss: 36.6724, train_grp_loss: [11.48753905 13.70725071 13.00799346], val_grp_loss: [12.63683999 12.78827476 11.24556357], train_hist_grp_loss: [ 4.28066465  5.56705874 12.34333977], cur_train_grp_loss: [0.08836107 0.1151921  0.25505919], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6759, max_kl_dist_index: 0, max_train_grp_loss:  13.7073, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7883, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:07:37,566 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  48, train_loss:  12.6265, val_loss:  12.2243, grad_norm: 0.0041, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6759, 0.3234, 0.6753, param: [ 4.88274793  6.90018741  5.72916491 10.23981689], weights: [0.29038084 0.30604187 0.40357729], train_wt_loss:  37.8795, val_wt_loss: 36.6729, train_grp_loss: [11.48812735 13.70665696 13.00796442], val_grp_loss: [12.63747588 12.7878587  11.24588396], train_hist_grp_loss: [ 4.36903033  5.68224572 12.59839847], cur_train_grp_loss: [0.08836568 0.11518698 0.2550587 ], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6759, max_kl_dist_index: 0, max_train_grp_loss:  13.7067, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7879, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:07:38,602 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  49, train_loss:  12.6265, val_loss:  12.2245, grad_norm: 0.0042, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6760, 0.3234, 0.6753, param: [ 4.88224293  6.89866893  5.73023577 10.2404109 ], weights: [0.28950415 0.3054453  0.40505055], train_wt_loss:  37.8796, val_wt_loss: 36.6735, train_grp_loss: [11.48870348 13.70607865 13.00793169], val_grp_loss: [12.63810061 12.78746139 11.246199  ], train_hist_grp_loss: [ 4.45740054  5.79742771 12.8534566 ], cur_train_grp_loss: [0.08837021 0.11518199 0.25505813], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6760, max_kl_dist_index: 0, max_train_grp_loss:  13.7061, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7875, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:07:39,645 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  50, train_loss:  12.6265, val_loss:  12.2247, grad_norm: 0.0043, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6760, 0.3234, 0.6753, param: [ 4.88173131  6.89715527  5.73130425 10.2410258 ], weights: [0.28862751 0.30484704 0.40652545], train_wt_loss:  37.8796, val_wt_loss: 36.6740, train_grp_loss: [11.4892674  13.70551581 13.00789528], val_grp_loss: [12.63871416 12.7870829  11.24650866], train_hist_grp_loss: [ 4.54577518  5.91260484 13.10851408], cur_train_grp_loss: [0.08837464 0.11517713 0.25505748], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6760, max_kl_dist_index: 0, max_train_grp_loss:  13.7055, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7871, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:07:40,685 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  51, train_loss:  12.6266, val_loss:  12.2248, grad_norm: 0.0044, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6760, 0.3234, 0.6753, param: [ 4.88121306  6.89564641  5.73237033 10.24166165], weights: [0.28775094 0.30424711 0.40800196], train_wt_loss:  37.8797, val_wt_loss: 36.6745, train_grp_loss: [11.48981909 13.70496848 13.00785517], val_grp_loss: [12.63931649 12.78672326 11.24681294], train_hist_grp_loss: [ 4.63415416  6.02777724 13.36357085], cur_train_grp_loss: [0.08837898 0.1151724  0.25505677], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6760, max_kl_dist_index: 0, max_train_grp_loss:  13.7050, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7867, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:07:41,740 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  52, train_loss:  12.6266, val_loss:  12.2250, grad_norm: 0.0044, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6760, 0.3234, 0.6753, param: [ 4.88068817  6.89414234  5.733434   10.24231851], weights: [0.28687444 0.30364551 0.40948006], train_wt_loss:  37.8797, val_wt_loss: 36.6751, train_grp_loss: [11.49035852 13.7044367  13.00781135], val_grp_loss: [12.63990758 12.78638253 11.24711181], train_hist_grp_loss: [ 4.72253739  6.14294504 13.61862683], cur_train_grp_loss: [0.08838322 0.1151678  0.25505598], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6760, max_kl_dist_index: 0, max_train_grp_loss:  13.7044, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7864, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:07:42,766 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  53, train_loss:  12.6266, val_loss:  12.2252, grad_norm: 0.0045, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6760, 0.3235, 0.6753, param: [ 4.88015661  6.89264305  5.73449527 10.24299645], weights: [0.28599803 0.30304226 0.41095972], train_wt_loss:  37.8798, val_wt_loss: 36.6756, train_grp_loss: [11.49088566 13.70392049 13.0077638 ], val_grp_loss: [12.64048741 12.78606074 11.24740528], train_hist_grp_loss: [ 4.81092476  6.25810838 13.87368196], cur_train_grp_loss: [0.08838737 0.11516333 0.25505512], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6760, max_kl_dist_index: 0, max_train_grp_loss:  13.7039, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7861, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:07:43,802 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  54, train_loss:  12.6266, val_loss:  12.2254, grad_norm: 0.0046, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6760, 0.3235, 0.6753, param: [ 4.87961838  6.89114854  5.7355541  10.24369552], weights: [0.28512172 0.30243737 0.41244092], train_wt_loss:  37.8798, val_wt_loss: 36.6762, train_grp_loss: [11.49140047 13.70341989 13.00771252], val_grp_loss: [12.64105593 12.78575795 11.24769332], train_hist_grp_loss: [ 4.89931619  6.37326737 14.12873615], cur_train_grp_loss: [0.08839143 0.115159   0.25505419], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6760, max_kl_dist_index: 0, max_train_grp_loss:  13.7034, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7858, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:07:44,869 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  55, train_loss:  12.6266, val_loss:  12.2256, grad_norm: 0.0047, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6760, 0.3235, 0.6753, param: [ 4.87907346  6.88965878  5.73661051 10.24441579], weights: [0.28424552 0.30183086 0.41392362], train_wt_loss:  37.8799, val_wt_loss: 36.6767, train_grp_loss: [11.49190293 13.70293493 13.0076575 ], val_grp_loss: [12.64161312 12.7854742  11.24797592], train_hist_grp_loss: [ 4.98771158  6.48842216 14.38378934], cur_train_grp_loss: [0.08839539 0.11515479 0.25505319], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6760, max_kl_dist_index: 0, max_train_grp_loss:  13.7029, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7855, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:07:45,900 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  56, train_loss:  12.6266, val_loss:  12.2258, grad_norm: 0.0048, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6760, 0.3235, 0.6753, param: [ 4.87852182  6.88817377  5.73766448 10.24515732], weights: [0.28336944 0.30122274 0.41540782], train_wt_loss:  37.8799, val_wt_loss: 36.6773, train_grp_loss: [11.49239302 13.70246566 13.00759872], val_grp_loss: [12.64215896 12.78520953 11.24825307], train_hist_grp_loss: [ 5.07611083  6.60357288 14.63884144], cur_train_grp_loss: [0.08839925 0.11515071 0.25505211], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6760, max_kl_dist_index: 0, max_train_grp_loss:  13.7025, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7852, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:07:46,916 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  57, train_loss:  12.6267, val_loss:  12.2260, grad_norm: 0.0049, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6760, 0.3235, 0.6752, param: [ 4.87796347  6.8866935   5.73871599 10.24592016], weights: [0.28249351 0.30061302 0.41689347], train_wt_loss:  37.8800, val_wt_loss: 36.6779, train_grp_loss: [11.49287069 13.70201209 13.00753617], val_grp_loss: [12.64269342 12.784964   11.24852475], train_hist_grp_loss: [ 5.16451385  6.71871965 14.8938924 ], cur_train_grp_loss: [0.08840302 0.11514677 0.25505096], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6760, max_kl_dist_index: 0, max_train_grp_loss:  13.7020, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7850, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:07:47,934 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  58, train_loss:  12.6267, val_loss:  12.2261, grad_norm: 0.0050, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6760, 0.3235, 0.6752, param: [ 4.87739838  6.88521794  5.73976504 10.24670439], weights: [0.28161772 0.30000173 0.41838055], train_wt_loss:  37.8800, val_wt_loss: 36.6784, train_grp_loss: [11.49333592 13.70157428 13.00746984], val_grp_loss: [12.64321646 12.78473765 11.24879095], train_hist_grp_loss: [ 5.25292055  6.83386261 15.14894213], cur_train_grp_loss: [0.0884067  0.11514296 0.25504973], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6760, max_kl_dist_index: 0, max_train_grp_loss:  13.7016, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7847, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:07:48,966 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  59, train_loss:  12.6267, val_loss:  12.2263, grad_norm: 0.0051, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6760, 0.3235, 0.6752, param: [ 4.87682653  6.8837471   5.74081162 10.24751006], weights: [0.2807421  0.29938887 0.41986903], train_wt_loss:  37.8801, val_wt_loss: 36.6790, train_grp_loss: [11.49378869 13.70115224 13.00739973], val_grp_loss: [12.64372806 12.78453053 11.24905166], train_hist_grp_loss: [ 5.34133083  6.94900189 15.40399056], cur_train_grp_loss: [0.08841028 0.11513928 0.25504843], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6760, max_kl_dist_index: 0, max_train_grp_loss:  13.7012, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7845, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:07:49,978 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  60, train_loss:  12.6267, val_loss:  12.2265, grad_norm: 0.0052, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6761, 0.3235, 0.6752, param: [ 4.87624791  6.88228095  5.74185572 10.24833723], weights: [0.27986665 0.29877445 0.4213589 ], train_wt_loss:  37.8801, val_wt_loss: 36.6796, train_grp_loss: [11.49422895 13.70074602 13.00732582], val_grp_loss: [12.6442282  12.78434268 11.24930687], train_hist_grp_loss: [ 5.42974459  7.06413762 15.65903761], cur_train_grp_loss: [0.08841376 0.11513573 0.25504705], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6761, max_kl_dist_index: 0, max_train_grp_loss:  13.7007, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7843, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:07:51,009 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  61, train_loss:  12.6267, val_loss:  12.2267, grad_norm: 0.0053, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6761, 0.3235, 0.6752, param: [ 4.87566251  6.88081948  5.74289733 10.24918597], weights: [0.27899139 0.2981585  0.42285011], train_wt_loss:  37.8802, val_wt_loss: 36.6801, train_grp_loss: [11.4946567  13.70035565 13.00724809], val_grp_loss: [12.64471683 12.78417415 11.24955657], train_hist_grp_loss: [ 5.51816173  7.17926994 15.91408321], cur_train_grp_loss: [0.08841715 0.11513232 0.2550456 ], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6761, max_kl_dist_index: 0, max_train_grp_loss:  13.7004, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7842, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:07:52,017 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  62, train_loss:  12.6267, val_loss:  12.2269, grad_norm: 0.0054, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6761, 0.3236, 0.6753, param: [ 4.87507031  6.87936269  5.74393643 10.25005633], weights: [0.27811632 0.29754103 0.42434265], train_wt_loss:  37.8802, val_wt_loss: 36.6807, train_grp_loss: [11.49507189 13.69998117 13.00716655], val_grp_loss: [12.64519395 12.78402499 11.24980073], train_hist_grp_loss: [ 5.60658217  7.29439898 16.16912729], cur_train_grp_loss: [0.08842044 0.11512904 0.25504408], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6761, max_kl_dist_index: 0, max_train_grp_loss:  13.7000, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7840, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:07:53,051 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  63, train_loss:  12.6268, val_loss:  12.2271, grad_norm: 0.0055, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6761, 0.3236, 0.6753, param: [ 4.87447129  6.87791055  5.74497303 10.25094838], weights: [0.27724147 0.29692205 0.42583648], train_wt_loss:  37.8803, val_wt_loss: 36.6813, train_grp_loss: [11.4954745  13.6996226  13.00708118], val_grp_loss: [12.64565951 12.78389524 11.25003935], train_hist_grp_loss: [ 5.6950058   7.40952487 16.42416978], cur_train_grp_loss: [0.08842363 0.11512589 0.25504248], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6761, max_kl_dist_index: 0, max_train_grp_loss:  13.6996, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7839, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:07:54,079 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  64, train_loss:  12.6268, val_loss:  12.2273, grad_norm: 0.0056, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6761, 0.3236, 0.6753, param: [ 4.87386544  6.87646305  5.7460071  10.25186217], weights: [0.27636685 0.29630157 0.42733159], train_wt_loss:  37.8803, val_wt_loss: 36.6818, train_grp_loss: [11.4958645  13.69927999 13.00699197], val_grp_loss: [12.6461135  12.78378496 11.25027243], train_hist_grp_loss: [ 5.78343253  7.52464775 16.67921058], cur_train_grp_loss: [0.08842673 0.11512288 0.25504081], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6761, max_kl_dist_index: 0, max_train_grp_loss:  13.6993, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7838, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:07:55,101 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  65, train_loss:  12.6268, val_loss:  12.2275, grad_norm: 0.0057, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6761, 0.3236, 0.6753, param: [ 4.87325275  6.87502018  5.74703865 10.25279777], weights: [0.27549246 0.29567961 0.42882793], train_wt_loss:  37.8804, val_wt_loss: 36.6824, train_grp_loss: [11.49624186 13.69895337 13.0068989 ], val_grp_loss: [12.64655588 12.78369419 11.25049994], train_hist_grp_loss: [ 5.87186225  7.63976775 16.93424964], cur_train_grp_loss: [0.08842973 0.11512    0.25503906], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6761, max_kl_dist_index: 0, max_train_grp_loss:  13.6990, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7837, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:07:56,177 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  66, train_loss:  12.6268, val_loss:  12.2277, grad_norm: 0.0058, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6762, 0.3236, 0.6753, param: [ 4.87263319  6.87358193  5.74806765 10.25375524], weights: [0.27461832 0.29505619 0.43032549], train_wt_loss:  37.8804, val_wt_loss: 36.6830, train_grp_loss: [11.49660655 13.69864278 13.00680198], val_grp_loss: [12.64698663 12.78362297 11.25072187], train_hist_grp_loss: [ 5.96029488  7.754885   17.18928688], cur_train_grp_loss: [0.08843263 0.11511726 0.25503723], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6762, max_kl_dist_index: 0, max_train_grp_loss:  13.6986, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7836, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:07:57,230 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  67, train_loss:  12.6268, val_loss:  12.2279, grad_norm: 0.0058, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6762, 0.3236, 0.6753, param: [ 4.87200676  6.87214827  5.7490941  10.25473464], weights: [0.27374444 0.29443132 0.43182424], train_wt_loss:  37.8805, val_wt_loss: 36.6836, train_grp_loss: [11.49695856 13.69834824 13.00670118], val_grp_loss: [12.64740572 12.78357136 11.25093822], train_hist_grp_loss: [ 6.04873032  7.86999965 17.44432221], cur_train_grp_loss: [0.08843544 0.11511465 0.25503533], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6762, max_kl_dist_index: 0, max_train_grp_loss:  13.6983, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7836, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:07:58,272 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  68, train_loss:  12.6269, val_loss:  12.2281, grad_norm: 0.0059, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6762, 0.3237, 0.6753, param: [ 4.87137343  6.8707192   5.75011799 10.25573602], weights: [0.27287084 0.29380501 0.43332415], train_wt_loss:  37.8806, val_wt_loss: 36.6842, train_grp_loss: [11.49729784 13.6980698  13.0065965 ], val_grp_loss: [12.64781313 12.78353941 11.25114897], train_hist_grp_loss: [ 6.13716846  7.98511182 17.69935556], cur_train_grp_loss: [0.08843814 0.11511217 0.25503336], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6762, max_kl_dist_index: 0, max_train_grp_loss:  13.6981, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7835, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:07:59,298 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  69, train_loss:  12.6269, val_loss:  12.2283, grad_norm: 0.0060, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6762, 0.3237, 0.6753, param: [ 4.87073319  6.8692947   5.7511393  10.25675946], weights: [0.27199753 0.29317728 0.43482519], train_wt_loss:  37.8806, val_wt_loss: 36.6848, train_grp_loss: [11.49762438 13.6978075  13.00648793], val_grp_loss: [12.64820882 12.78352715 11.25135411], train_hist_grp_loss: [ 6.22560921  8.10022165 17.95438687], cur_train_grp_loss: [0.08844075 0.11510983 0.2550313 ], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6762, max_kl_dist_index: 0, max_train_grp_loss:  13.6978, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7835, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:08:00,316 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  70, train_loss:  12.6269, val_loss:  12.2284, grad_norm: 0.0061, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6763, 0.3237, 0.6753, param: [ 4.87008603  6.86787476  5.75215803 10.25780501], weights: [0.27112452 0.29254815 0.43632734], train_wt_loss:  37.8807, val_wt_loss: 36.6853, train_grp_loss: [11.49793814 13.69756135 13.00637546], val_grp_loss: [12.64859278 12.78353465 11.25155363], train_hist_grp_loss: [ 6.31405248  8.21532927 18.20941604], cur_train_grp_loss: [0.08844326 0.11510763 0.25502918], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6763, max_kl_dist_index: 0, max_train_grp_loss:  13.6976, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7835, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:08:01,363 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  71, train_loss:  12.6269, val_loss:  12.2286, grad_norm: 0.0062, live_grad: 0.0000, reward_err: 0.0103, 0.0186, 0.0011, KL_dist: 0.6763, 0.3237, 0.6753, param: [ 4.86943193  6.86645935  5.75317416 10.25887272], weights: [0.27025182 0.29191762 0.43783056], train_wt_loss:  37.8807, val_wt_loss: 36.6859, train_grp_loss: [11.49823911 13.69733141 13.00625907], val_grp_loss: [12.64896497 12.78356194 11.25174752], train_hist_grp_loss: [ 6.40249816  8.33043483 18.46444301], cur_train_grp_loss: [0.08844568 0.11510556 0.25502697], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6763, max_kl_dist_index: 0, max_train_grp_loss:  13.6973, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7836, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:08:02,403 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  72, train_loss:  12.6269, val_loss:  12.2288, grad_norm: 0.0063, live_grad: 0.0000, reward_err: 0.0103, 0.0186, 0.0011, KL_dist: 0.6763, 0.3237, 0.6754, param: [ 4.86877088  6.86504847  5.75418769 10.25996267], weights: [0.26937945 0.29128573 0.43933483], train_wt_loss:  37.8808, val_wt_loss: 36.6865, train_grp_loss: [11.49852724 13.6971177  13.00613877], val_grp_loss: [12.64932537 12.78360908 11.25193578], train_hist_grp_loss: [ 6.49094615  8.44553846 18.7194677 ], cur_train_grp_loss: [0.08844799 0.11510363 0.25502469], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6763, max_kl_dist_index: 0, max_train_grp_loss:  13.6971, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7836, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:08:03,409 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  73, train_loss:  12.6269, val_loss:  12.2290, grad_norm: 0.0064, live_grad: 0.0000, reward_err: 0.0103, 0.0186, 0.0011, KL_dist: 0.6763, 0.3237, 0.6754, param: [ 4.86810285  6.86364209  5.75519861 10.26107491], weights: [0.26850741 0.29065247 0.44084012], train_wt_loss:  37.8808, val_wt_loss: 36.6871, train_grp_loss: [11.49880252 13.69692027 13.00601453], val_grp_loss: [12.64967395 12.78367611 11.25211838], train_hist_grp_loss: [ 6.57939636  8.56064029 18.97449003], cur_train_grp_loss: [0.08845021 0.11510183 0.25502233], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6763, max_kl_dist_index: 0, max_train_grp_loss:  13.6969, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7837, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:08:04,439 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  74, train_loss:  12.6270, val_loss:  12.2292, grad_norm: 0.0065, live_grad: 0.0000, reward_err: 0.0103, 0.0186, 0.0011, KL_dist: 0.6764, 0.3238, 0.6754, param: [ 4.86742784  6.8622402   5.75620689 10.26220949], weights: [0.26763573 0.29001786 0.4423464 ], train_wt_loss:  37.8809, val_wt_loss: 36.6877, train_grp_loss: [11.49906492 13.69673915 13.00588636], val_grp_loss: [12.65001069 12.78376308 11.25229532], train_hist_grp_loss: [ 6.66784869  8.67574046 19.22950992], cur_train_grp_loss: [0.08845233 0.11510017 0.25501989], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6764, max_kl_dist_index: 0, max_train_grp_loss:  13.6967, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7838, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:08:05,467 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  75, train_loss:  12.6270, val_loss:  12.2294, grad_norm: 0.0066, live_grad: 0.0000, reward_err: 0.0103, 0.0186, 0.0011, KL_dist: 0.6764, 0.3238, 0.6754, param: [ 4.86674583  6.86084279  5.75721254 10.26336649], weights: [0.26676442 0.28938193 0.44385365], train_wt_loss:  37.8810, val_wt_loss: 36.6883, train_grp_loss: [11.49931442 13.69657437 13.00575423], val_grp_loss: [12.65033557 12.78387005 11.2524666 ], train_hist_grp_loss: [ 6.75630303  8.79083911 19.4845273 ], cur_train_grp_loss: [0.08845435 0.11509865 0.25501738], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6764, max_kl_dist_index: 0, max_train_grp_loss:  13.6966, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7839, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:08:06,502 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  76, train_loss:  12.6270, val_loss:  12.2296, grad_norm: 0.0067, live_grad: 0.0000, reward_err: 0.0103, 0.0186, 0.0011, KL_dist: 0.6764, 0.3238, 0.6755, param: [ 4.86605679  6.85944983  5.75821554 10.26454596], weights: [0.26589348 0.28874468 0.44536184], train_wt_loss:  37.8810, val_wt_loss: 36.6889, train_grp_loss: [11.49955098 13.69642597 13.00561815], val_grp_loss: [12.65064855 12.78399705 11.25263219], train_hist_grp_loss: [ 6.8447593   8.90593637 19.73954209], cur_train_grp_loss: [0.08845626 0.11509726 0.25501479], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6764, max_kl_dist_index: 0, max_train_grp_loss:  13.6964, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7840, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:08:07,523 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  77, train_loss:  12.6270, val_loss:  12.2299, grad_norm: 0.0068, live_grad: 0.0000, reward_err: 0.0103, 0.0186, 0.0011, KL_dist: 0.6765, 0.3238, 0.6755, param: [ 4.86536073  6.85806131  5.75921588 10.26574796], weights: [0.26502293 0.28810614 0.44687093], train_wt_loss:  37.8811, val_wt_loss: 36.6896, train_grp_loss: [11.49977459 13.69629398 13.00547809], val_grp_loss: [12.65094961 12.78414415 11.2527921 ], train_hist_grp_loss: [ 6.93321738  9.02103239 19.99455421], cur_train_grp_loss: [0.08845808 0.11509602 0.25501212], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6765, max_kl_dist_index: 0, max_train_grp_loss:  13.6963, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7841, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:08:08,570 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  78, train_loss:  12.6271, val_loss:  12.2301, grad_norm: 0.0069, live_grad: 0.0000, reward_err: 0.0103, 0.0186, 0.0011, KL_dist: 0.6765, 0.3239, 0.6755, param: [ 4.86465762  6.85667722  5.76021354 10.26697254], weights: [0.26415278 0.28746631 0.44838091], train_wt_loss:  37.8812, val_wt_loss: 36.6902, train_grp_loss: [11.49998522 13.69617845 13.00533406], val_grp_loss: [12.65123873 12.78431138 11.2529463 ], train_hist_grp_loss: [ 7.02167718  9.13612729 20.24956359], cur_train_grp_loss: [0.0884598  0.11509491 0.25500937], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6765, max_kl_dist_index: 0, max_train_grp_loss:  13.6962, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7843, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:08:09,607 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  79, train_loss:  12.6271, val_loss:  12.2303, grad_norm: 0.0070, live_grad: 0.0000, reward_err: 0.0103, 0.0186, 0.0011, KL_dist: 0.6765, 0.3239, 0.6755, param: [ 4.86394744  6.85529753  5.76120852 10.26821978], weights: [0.26328305 0.28682521 0.44989174], train_wt_loss:  37.8812, val_wt_loss: 36.6908, train_grp_loss: [11.50018283 13.6960794  13.00518604], val_grp_loss: [12.65151589 12.78449879 11.25309481], train_hist_grp_loss: [ 7.11013861  9.25122123 20.50457014], cur_train_grp_loss: [0.08846142 0.11509394 0.25500655], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6765, max_kl_dist_index: 0, max_train_grp_loss:  13.6961, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7845, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:08:10,652 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  80, train_loss:  12.6271, val_loss:  12.2305, grad_norm: 0.0071, live_grad: 0.0000, reward_err: 0.0103, 0.0186, 0.0011, KL_dist: 0.6766, 0.3239, 0.6756, param: [ 4.86323018  6.85392222  5.76220081 10.26948972], weights: [0.26241375 0.28618286 0.45140338], train_wt_loss:  37.8813, val_wt_loss: 36.6914, train_grp_loss: [11.50036742 13.69599688 13.00503403], val_grp_loss: [12.65178105 12.78470644 11.25323759], train_hist_grp_loss: [ 7.19860155  9.36631433 20.75957378], cur_train_grp_loss: [0.08846294 0.1150931  0.25500365], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6766, max_kl_dist_index: 0, max_train_grp_loss:  13.6960, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7847, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:08:11,687 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  81, train_loss:  12.6271, val_loss:  12.2307, grad_norm: 0.0072, live_grad: 0.0000, reward_err: 0.0103, 0.0186, 0.0011, KL_dist: 0.6766, 0.3239, 0.6756, param: [ 4.86250583  6.85255129  5.76319039 10.27078243], weights: [0.2615449  0.28553928 0.45291583], train_wt_loss:  37.8813, val_wt_loss: 36.6920, train_grp_loss: [11.50053895 13.69593091 13.00487801], val_grp_loss: [12.65203419 12.78493438 11.25337465], train_hist_grp_loss: [ 7.28706592  9.48140674 21.01457445], cur_train_grp_loss: [0.08846436 0.11509241 0.25500067], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6766, max_kl_dist_index: 0, max_train_grp_loss:  13.6959, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7849, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:08:12,729 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  82, train_loss:  12.6271, val_loss:  12.2309, grad_norm: 0.0073, live_grad: 0.0000, reward_err: 0.0103, 0.0186, 0.0011, KL_dist: 0.6766, 0.3240, 0.6756, param: [ 4.86177437  6.8511847   5.76417725 10.27209797], weights: [0.26067649 0.28489447 0.45442904], train_wt_loss:  37.8814, val_wt_loss: 36.6926, train_grp_loss: [11.50069739 13.69588154 13.00471797], val_grp_loss: [12.6522753  12.78518264 11.25350599], train_hist_grp_loss: [ 7.3755316   9.5964986  21.26957206], cur_train_grp_loss: [0.08846568 0.11509186 0.25499761], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6766, max_kl_dist_index: 0, max_train_grp_loss:  13.6959, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7852, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:08:13,749 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  83, train_loss:  12.6272, val_loss:  12.2311, grad_norm: 0.0074, live_grad: 0.0000, reward_err: 0.0103, 0.0186, 0.0011, KL_dist: 0.6767, 0.3240, 0.6757, param: [ 4.86103578  6.84982245  5.76516139 10.27343639], weights: [0.25980856 0.28424846 0.45594298], train_wt_loss:  37.8815, val_wt_loss: 36.6933, train_grp_loss: [11.50084273 13.69584881 13.00455392], val_grp_loss: [12.65250434 12.78545129 11.25363158], train_hist_grp_loss: [ 7.46399851  9.71159004 21.52456653], cur_train_grp_loss: [0.0884669  0.11509144 0.25499447], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6767, max_kl_dist_index: 0, max_train_grp_loss:  13.6958, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7855, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:08:14,808 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  84, train_loss:  12.6272, val_loss:  12.2313, grad_norm: 0.0075, live_grad: 0.0000, reward_err: 0.0105, 0.0186, 0.0012, KL_dist: 0.6767, 0.3240, 0.6757, param: [ 4.86029005  6.8484645   5.76614278 10.27479776], weights: [0.2589411  0.28360126 0.45745764], train_wt_loss:  37.8815, val_wt_loss: 36.6939, train_grp_loss: [11.50097494 13.69583274 13.00438583], val_grp_loss: [12.65272129 12.78574037 11.25375142], train_hist_grp_loss: [ 7.55246653  9.82668121 21.77955778], cur_train_grp_loss: [0.08846802 0.11509117 0.25499125], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6767, max_kl_dist_index: 0, max_train_grp_loss:  13.6958, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7857, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:08:15,868 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  85, train_loss:  12.6272, val_loss:  12.2315, grad_norm: 0.0076, live_grad: 0.0000, reward_err: 0.0107, 0.0186, 0.0013, KL_dist: 0.6767, 0.3240, 0.6757, param: [ 4.85953717  6.84711086  5.76712141 10.27618213], weights: [0.25807414 0.28295288 0.45897297], train_wt_loss:  37.8816, val_wt_loss: 36.6945, train_grp_loss: [11.501094   13.69583338 13.0042137 ], val_grp_loss: [12.65292613 12.78604994 11.25386551], train_hist_grp_loss: [ 7.64093557  9.94177224 22.03454574], cur_train_grp_loss: [0.08846904 0.11509103 0.25498796], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6767, max_kl_dist_index: 0, max_train_grp_loss:  13.6958, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7860, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:08:16,888 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  86, train_loss:  12.6272, val_loss:  12.2317, grad_norm: 0.0077, live_grad: 0.0000, reward_err: 0.0107, 0.0186, 0.0013, KL_dist: 0.6768, 0.3241, 0.6758, param: [ 4.85877711  6.84576148  5.76809729 10.27758956], weights: [0.25720769 0.28230335 0.46048896], train_wt_loss:  37.8817, val_wt_loss: 36.6951, train_grp_loss: [11.50119988 13.69585076 13.00403752], val_grp_loss: [12.65311883 12.78638003 11.25397383], train_hist_grp_loss: [ 7.72940552 10.05686328 22.28953032], cur_train_grp_loss: [0.08846995 0.11509104 0.25498458], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6768, max_kl_dist_index: 0, max_train_grp_loss:  13.6959, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7864, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:08:17,952 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  87, train_loss:  12.6273, val_loss:  12.2319, grad_norm: 0.0078, live_grad: 0.0000, reward_err: 0.0105, 0.0186, 0.0013, KL_dist: 0.6768, 0.3241, 0.6758, param: [ 4.85800986  6.84441636  5.76907038 10.27902011], weights: [0.25634176 0.28165268 0.46200557], train_wt_loss:  37.8818, val_wt_loss: 36.6958, train_grp_loss: [11.50129256 13.69588491 13.00385729], val_grp_loss: [12.65329938 12.7867307  11.25407639], train_hist_grp_loss: [ 7.81787629 10.17195446 22.54451145], cur_train_grp_loss: [0.08847077 0.11509118 0.25498113], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6768, max_kl_dist_index: 0, max_train_grp_loss:  13.6959, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7867, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:08:19,002 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  88, train_loss:  12.6273, val_loss:  12.2321, grad_norm: 0.0079, live_grad: 0.0000, reward_err: 0.0105, 0.0186, 0.0013, KL_dist: 0.6769, 0.3241, 0.6759, param: [ 4.85723541  6.84307547  5.77004069 10.28047383], weights: [0.25547635 0.28100088 0.46352277], train_wt_loss:  37.8818, val_wt_loss: 36.6964, train_grp_loss: [11.50137201 13.69593588 13.00367299], val_grp_loss: [12.65346775 12.787102   11.25417316], train_hist_grp_loss: [ 7.90634777 10.28704593 22.79948904], cur_train_grp_loss: [0.08847148 0.11509147 0.25497759], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6769, max_kl_dist_index: 0, max_train_grp_loss:  13.6959, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7871, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:08:20,023 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  89, train_loss:  12.6273, val_loss:  12.2323, grad_norm: 0.0080, live_grad: 0.0000, reward_err: 0.0105, 0.0186, 0.0013, KL_dist: 0.6769, 0.3242, 0.6759, param: [ 4.85645374  6.84173879  5.77100819 10.2819508 ], weights: [0.2546115  0.28034797 0.46504054], train_wt_loss:  37.8819, val_wt_loss: 36.6970, train_grp_loss: [11.50143822 13.6960037  13.00348461], val_grp_loss: [12.65362391 12.78749398 11.25426416], train_hist_grp_loss: [ 7.99481986 10.40213783 23.05446302], cur_train_grp_loss: [0.08847209 0.1150919  0.25497398], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6769, max_kl_dist_index: 0, max_train_grp_loss:  13.6960, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7875, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:08:21,068 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  90, train_loss:  12.6273, val_loss:  12.2326, grad_norm: 0.0081, live_grad: 0.0000, reward_err: 0.0105, 0.0186, 0.0013, KL_dist: 0.6770, 0.3242, 0.6759, param: [ 4.85566484  6.84040631  5.77197288 10.28345105], weights: [0.2537472  0.27969396 0.46655884], train_wt_loss:  37.8820, val_wt_loss: 36.6977, train_grp_loss: [11.50149116 13.69608841 13.00329215], val_grp_loss: [12.65376784 12.78790668 11.25434936], train_hist_grp_loss: [ 8.08329246 10.5172303  23.30943331], cur_train_grp_loss: [0.0884726  0.11509247 0.25497029], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6770, max_kl_dist_index: 0, max_train_grp_loss:  13.6961, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7879, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:08:22,083 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  91, train_loss:  12.6273, val_loss:  12.2328, grad_norm: 0.0082, live_grad: 0.0000, reward_err: 0.0105, 0.0186, 0.0013, KL_dist: 0.6770, 0.3242, 0.6760, param: [ 4.85486868  6.839078    5.77293475 10.28497466], weights: [0.25288348 0.27903888 0.46807764], train_wt_loss:  37.8820, val_wt_loss: 36.6983, train_grp_loss: [11.50153081 13.69619005 13.00309561], val_grp_loss: [12.65389953 12.78834017 11.25442877], train_hist_grp_loss: [ 8.17176547 10.63232348 23.56439982], cur_train_grp_loss: [0.08847301 0.11509318 0.25496651], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6770, max_kl_dist_index: 0, max_train_grp_loss:  13.6962, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7883, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:08:23,120 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  92, train_loss:  12.6274, val_loss:  12.2330, grad_norm: 0.0083, live_grad: 0.0000, reward_err: 0.0105, 0.0186, 0.0013, KL_dist: 0.6770, 0.3243, 0.6760, param: [ 4.85406526  6.83775384  5.77389377 10.28652167], weights: [0.25202033 0.27838274 0.46959693], train_wt_loss:  37.8821, val_wt_loss: 36.6990, train_grp_loss: [11.50155714 13.69630864 13.00289496], val_grp_loss: [12.65401894 12.78879448 11.25450237], train_hist_grp_loss: [ 8.26023879 10.74741751 23.81936248], cur_train_grp_loss: [0.08847331 0.11509403 0.25496266], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6770, max_kl_dist_index: 0, max_train_grp_loss:  13.6963, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7888, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:08:24,213 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  93, train_loss:  12.6274, val_loss:  12.2332, grad_norm: 0.0084, live_grad: 0.0000, reward_err: 0.0105, 0.0186, 0.0013, KL_dist: 0.6771, 0.3243, 0.6761, param: [ 4.85325456  6.8364338   5.77484995 10.28809215], weights: [0.25115779 0.27772555 0.47111666], train_wt_loss:  37.8822, val_wt_loss: 36.6996, train_grp_loss: [11.50157014 13.69644423 13.00269021], val_grp_loss: [12.65412607 12.78926967 11.25457017], train_hist_grp_loss: [ 8.3487123  10.86251254 24.07432121], cur_train_grp_loss: [0.08847352 0.11509503 0.25495872], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6771, max_kl_dist_index: 0, max_train_grp_loss:  13.6964, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7893, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:08:25,241 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  94, train_loss:  12.6274, val_loss:  12.2334, grad_norm: 0.0085, live_grad: 0.0000, reward_err: 0.0105, 0.0186, 0.0013, KL_dist: 0.6771, 0.3243, 0.6761, param: [ 4.85243657  6.83511788  5.77580326 10.28968616], weights: [0.25029586 0.27706733 0.47263681], train_wt_loss:  37.8823, val_wt_loss: 36.7003, train_grp_loss: [11.50156978 13.69659685 13.00248134], val_grp_loss: [12.65422087 12.78976579 11.25463215], train_hist_grp_loss: [ 8.43718592 10.97760871 24.32927592], cur_train_grp_loss: [0.08847362 0.11509617 0.25495471], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6771, max_kl_dist_index: 0, max_train_grp_loss:  13.6966, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7898, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:08:26,278 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  95, train_loss:  12.6274, val_loss:  12.2336, grad_norm: 0.0086, live_grad: 0.0000, reward_err: 0.0105, 0.0186, 0.0013, KL_dist: 0.6772, 0.3244, 0.6762, param: [ 4.85161126  6.83380604  5.7767537  10.29130374], weights: [0.24943455 0.2764081  0.47415735], train_wt_loss:  37.8823, val_wt_loss: 36.7009, train_grp_loss: [11.50155604 13.69676655 13.00226836], val_grp_loss: [12.65430335 12.79028289 11.25468832], train_hist_grp_loss: [ 8.52565953 11.09270616 24.58422653], cur_train_grp_loss: [0.08847361 0.11509745 0.25495061], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6772, max_kl_dist_index: 0, max_train_grp_loss:  13.6968, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7903, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:08:27,339 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  96, train_loss:  12.6275, val_loss:  12.2339, grad_norm: 0.0087, live_grad: 0.0000, reward_err: 0.0105, 0.0186, 0.0013, KL_dist: 0.6772, 0.3244, 0.6762, param: [ 4.85077863  6.83249826  5.77770125 10.29294496], weights: [0.24857387 0.27574788 0.47567825], train_wt_loss:  37.8824, val_wt_loss: 36.7016, train_grp_loss: [11.50152891 13.69695335 13.00205124], val_grp_loss: [12.65437346 12.79082101 11.25473866], train_hist_grp_loss: [ 8.61413304 11.20780504 24.83917297], cur_train_grp_loss: [0.08847351 0.11509888 0.25494644], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6772, max_kl_dist_index: 0, max_train_grp_loss:  13.6970, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7908, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2549, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:08:28,366 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  97, train_loss:  12.6275, val_loss:  12.2341, grad_norm: 0.0088, live_grad: 0.0000, reward_err: 0.0105, 0.0186, 0.0013, KL_dist: 0.6773, 0.3244, 0.6763, param: [ 4.84993865  6.83119452  5.77864589 10.29460988], weights: [0.24771385 0.27508667 0.47719948], train_wt_loss:  37.8825, val_wt_loss: 36.7023, train_grp_loss: [11.50148835 13.6971573  13.00182999], val_grp_loss: [12.6544312  12.79138021 11.25478317], train_hist_grp_loss: [ 8.70260634 11.32290549 25.09411515], cur_train_grp_loss: [0.0884733  0.11510045 0.25494218], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6773, max_kl_dist_index: 0, max_train_grp_loss:  13.6972, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7914, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2549, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:08:29,370 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  98, train_loss:  12.6275, val_loss:  12.2343, grad_norm: 0.0089, live_grad: 0.0000, reward_err: 0.0105, 0.0186, 0.0013, KL_dist: 0.6773, 0.3245, 0.6763, param: [ 4.84909132  6.8298948   5.77958763 10.29629854], weights: [0.24685449 0.2744245  0.47872101], train_wt_loss:  37.8826, val_wt_loss: 36.7029, train_grp_loss: [11.50143436 13.69737843 13.00160459], val_grp_loss: [12.65447654 12.79196054 11.25482184], train_hist_grp_loss: [ 8.79107933 11.43800765 25.34905299], cur_train_grp_loss: [0.08847299 0.11510216 0.25493784], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6773, max_kl_dist_index: 0, max_train_grp_loss:  13.6974, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7920, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2549, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:08:30,435 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  99, train_loss:  12.6275, val_loss:  12.2345, grad_norm: 0.0090, live_grad: 0.0000, reward_err: 0.0105, 0.0186, 0.0013, KL_dist: 0.6774, 0.3245, 0.6764, param: [ 4.84823661  6.82859907  5.78052644 10.29801101], weights: [0.2459958  0.27376138 0.48024282], train_wt_loss:  37.8826, val_wt_loss: 36.7036, train_grp_loss: [11.5013669  13.69761678 13.00137504], val_grp_loss: [12.65450946 12.79256204 11.25485468], train_hist_grp_loss: [ 8.8795519  11.55311167 25.60398642], cur_train_grp_loss: [0.08847257 0.11510402 0.25493342], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6774, max_kl_dist_index: 0, max_train_grp_loss:  13.6976, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7926, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2549, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:08:31,460 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  100, train_loss:  12.6276, val_loss:  12.2348, grad_norm: 0.0091, live_grad: 0.0000, reward_err: 0.0105, 0.0186, 0.0013, KL_dist: 0.6774, 0.3245, 0.6765, param: [ 4.84737452  6.82730731  5.7814623  10.29974735], weights: [0.2451378  0.27309733 0.48176487], train_wt_loss:  37.8827, val_wt_loss: 36.7043, train_grp_loss: [11.50128596 13.69787239 13.00114134], val_grp_loss: [12.65452995 12.79318477 11.25488168], train_hist_grp_loss: [ 8.96802395 11.6682177  25.85891534], cur_train_grp_loss: [0.08847205 0.11510602 0.25492892], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6774, max_kl_dist_index: 0, max_train_grp_loss:  13.6979, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7932, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2549, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:08:32,483 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  101, train_loss:  12.6276, val_loss:  12.2350, grad_norm: 0.0092, live_grad: 0.0000, reward_err: 0.0105, 0.0186, 0.0013, KL_dist: 0.6775, 0.3246, 0.6765, param: [ 4.84650502  6.8260195   5.78239522 10.3015076 ], weights: [0.2442805  0.27243237 0.48328713], train_wt_loss:  37.8828, val_wt_loss: 36.7049, train_grp_loss: [11.50119153 13.69814529 13.00090347], val_grp_loss: [12.65453797 12.79382879 11.25490283], train_hist_grp_loss: [ 9.05649538 11.78332587 26.11383968], cur_train_grp_loss: [0.08847143 0.11510817 0.25492434], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6775, max_kl_dist_index: 0, max_train_grp_loss:  13.6981, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7938, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2549, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:08:33,505 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  102, train_loss:  12.6276, val_loss:  12.2352, grad_norm: 0.0093, live_grad: 0.0000, reward_err: 0.0105, 0.0186, 0.0013, KL_dist: 0.6776, 0.3246, 0.6766, param: [ 4.84562811  6.82473561  5.78332517 10.30329182], weights: [0.24342392 0.27176651 0.48480957], train_wt_loss:  37.8829, val_wt_loss: 36.7056, train_grp_loss: [11.50108357 13.69843551 13.00066143], val_grp_loss: [12.65453352 12.79449413 11.25491813], train_hist_grp_loss: [ 9.14496609 11.89843633 26.36875936], cur_train_grp_loss: [0.0884707  0.11511046 0.25491968], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6776, max_kl_dist_index: 0, max_train_grp_loss:  13.6984, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7945, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2549, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:08:34,516 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  103, train_loss:  12.6277, val_loss:  12.2354, grad_norm: 0.0094, live_grad: 0.0000, reward_err: 0.0105, 0.0186, 0.0013, KL_dist: 0.6776, 0.3247, 0.6767, param: [ 4.84474376  6.82345562  5.78425214 10.30510008], weights: [0.24256806 0.27109976 0.48633218], train_wt_loss:  37.8830, val_wt_loss: 36.7063, train_grp_loss: [11.50096207 13.69874311 13.0004152 ], val_grp_loss: [12.65451656 12.79518084 11.25492758], train_hist_grp_loss: [ 9.23343596 12.01354924 26.62367429], cur_train_grp_loss: [0.08846987 0.1151129  0.25491493], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6776, max_kl_dist_index: 0, max_train_grp_loss:  13.6987, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7952, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2549, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:08:35,540 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  104, train_loss:  12.6277, val_loss:  12.2357, grad_norm: 0.0095, live_grad: 0.0000, reward_err: 0.0105, 0.0186, 0.0013, KL_dist: 0.6777, 0.3247, 0.6767, param: [ 4.84385196  6.8221795   5.78517612 10.30693241], weights: [0.24171295 0.27043215 0.4878549 ], train_wt_loss:  37.8831, val_wt_loss: 36.7070, train_grp_loss: [11.50082702 13.69906811 13.0001648 ], val_grp_loss: [12.6544871  12.79588899 11.25493117], train_hist_grp_loss: [ 9.3219049  12.12866472 26.87858439], cur_train_grp_loss: [0.08846894 0.11511549 0.2549101 ], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6777, max_kl_dist_index: 0, max_train_grp_loss:  13.6991, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7959, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2549, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:08:36,597 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  105, train_loss:  12.6277, val_loss:  12.2359, grad_norm: 0.0096, live_grad: 0.0000, reward_err: 0.0105, 0.0186, 0.0013, KL_dist: 0.6777, 0.3247, 0.6768, param: [ 4.8429527   6.82090723  5.78609709 10.30878889], weights: [0.24085858 0.26976369 0.48937772], train_wt_loss:  37.8831, val_wt_loss: 36.7077, train_grp_loss: [11.50067839 13.69941055 12.9999102 ], val_grp_loss: [12.65444509 12.79661862 11.2549289 ], train_hist_grp_loss: [ 9.4103728  12.24378294 27.13348958], cur_train_grp_loss: [0.0884679  0.11511822 0.25490519], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6777, max_kl_dist_index: 0, max_train_grp_loss:  13.6994, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7966, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2549, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:08:37,645 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  106, train_loss:  12.6277, val_loss:  12.2361, grad_norm: 0.0097, live_grad: 0.0000, reward_err: 0.0105, 0.0186, 0.0013, KL_dist: 0.6778, 0.3248, 0.6769, param: [ 4.84204597  6.81963879  5.78701505 10.31066956], weights: [0.24000498 0.2690944  0.49090061], train_wt_loss:  37.8832, val_wt_loss: 36.7084, train_grp_loss: [11.50051617 13.69977046 12.9996514 ], val_grp_loss: [12.65439053 12.79736977 11.25492077], train_hist_grp_loss: [ 9.49883956 12.35890404 27.38838978], cur_train_grp_loss: [0.08846676 0.1151211  0.2549002 ], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6778, max_kl_dist_index: 0, max_train_grp_loss:  13.6998, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7974, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2549, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:08:38,690 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  107, train_loss:  12.6278, val_loss:  12.2364, grad_norm: 0.0098, live_grad: 0.0000, reward_err: 0.0105, 0.0186, 0.0013, KL_dist: 0.6779, 0.3248, 0.6769, param: [ 4.84113173  6.81837414  5.78792997 10.31257448], weights: [0.23915216 0.2684243  0.49242354], train_wt_loss:  37.8833, val_wt_loss: 36.7091, train_grp_loss: [11.50034033 13.7001479  12.9993884 ], val_grp_loss: [12.6543234  12.79814251 11.25490678], train_hist_grp_loss: [ 9.58730506 12.47402816 27.64328491], cur_train_grp_loss: [0.08846551 0.11512412 0.25489513], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6779, max_kl_dist_index: 0, max_train_grp_loss:  13.7001, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7981, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2549, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:08:39,742 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  108, train_loss:  12.6278, val_loss:  12.2366, grad_norm: 0.0099, live_grad: 0.0000, reward_err: 0.0105, 0.0186, 0.0013, KL_dist: 0.6779, 0.3249, 0.6770, param: [ 4.84020999  6.81711326  5.78884185 10.3145037 ], weights: [0.23830013 0.26775339 0.49394647], train_wt_loss:  37.8834, val_wt_loss: 36.7098, train_grp_loss: [11.50015086 13.70054288 12.99912118], val_grp_loss: [12.65424368 12.79893687 11.25488692], train_hist_grp_loss: [ 9.67576922 12.58915546 27.89817487], cur_train_grp_loss: [0.08846416 0.11512729 0.25488997], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6779, max_kl_dist_index: 0, max_train_grp_loss:  13.7005, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7989, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2549, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:08:40,789 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  109, train_loss:  12.6278, val_loss:  12.2368, grad_norm: 0.0100, live_grad: 0.0000, reward_err: 0.0105, 0.0186, 0.0013, KL_dist: 0.6780, 0.3249, 0.6771, param: [ 4.83928073  6.81585613  5.78975067 10.31645728], weights: [0.23744891 0.26708171 0.49546939], train_wt_loss:  37.8835, val_wt_loss: 36.7105, train_grp_loss: [11.49994775 13.70095546 12.99884975], val_grp_loss: [12.65415135 12.79975292 11.2548612 ], train_hist_grp_loss: [ 9.76423192 12.70428607 28.1530596 ], cur_train_grp_loss: [0.0884627  0.11513061 0.25488473], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6780, max_kl_dist_index: 0, max_train_grp_loss:  13.7010, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7998, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2549, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:08:41,803 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  110, train_loss:  12.6279, val_loss:  12.2371, grad_norm: 0.0101, live_grad: 0.0000, reward_err: 0.0105, 0.0186, 0.0013, KL_dist: 0.6780, 0.3250, 0.6771, param: [ 4.83834392  6.81460272  5.79065642 10.31843526], weights: [0.2365985  0.26640925 0.49699225], train_wt_loss:  37.8836, val_wt_loss: 36.7112, train_grp_loss: [11.49973097 13.70138566 12.99857409], val_grp_loss: [12.65404639 12.8005907  11.25482961], train_hist_grp_loss: [ 9.85269306 12.81942015 28.40793901], cur_train_grp_loss: [0.08846114 0.11513408 0.25487941], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6780, max_kl_dist_index: 0, max_train_grp_loss:  13.7014, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8006, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2549, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:08:42,833 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  111, train_loss:  12.6279, val_loss:  12.2373, grad_norm: 0.0102, live_grad: 0.0000, reward_err: 0.0105, 0.0186, 0.0013, KL_dist: 0.6781, 0.3250, 0.6772, param: [ 4.83739957  6.81335301  5.79155909 10.32043771], weights: [0.23574892 0.26573605 0.49851503], train_wt_loss:  37.8837, val_wt_loss: 36.7119, train_grp_loss: [11.49950052 13.70183353 12.99829421], val_grp_loss: [12.65392879 12.80145026 11.25479214], train_hist_grp_loss: [ 9.94115253 12.93455784 28.66281301], cur_train_grp_loss: [0.08845947 0.11513769 0.254874  ], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6781, max_kl_dist_index: 0, max_train_grp_loss:  13.7018, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8015, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2549, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:08:43,874 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  112, train_loss:  12.6279, val_loss:  12.2375, grad_norm: 0.0104, live_grad: 0.0000, reward_err: 0.0105, 0.0186, 0.0013, KL_dist: 0.6782, 0.3251, 0.6773, param: [ 4.83644764  6.81210695  5.79245865 10.32246468], weights: [0.23490018 0.26506212 0.5000377 ], train_wt_loss:  37.8838, val_wt_loss: 36.7126, train_grp_loss: [11.49925636 13.7022991  12.99801009], val_grp_loss: [12.65379853 12.80233165 11.2547488 ], train_hist_grp_loss: [10.02961022 13.0496993  28.91768153], cur_train_grp_loss: [0.0884577  0.11514146 0.25486851], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6782, max_kl_dist_index: 0, max_train_grp_loss:  13.7023, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8023, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2549, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:08:44,887 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  113, train_loss:  12.6279, val_loss:  12.2378, grad_norm: 0.0105, live_grad: 0.0000, reward_err: 0.0105, 0.0186, 0.0013, KL_dist: 0.6782, 0.3251, 0.6774, param: [ 4.83548813  6.81086454  5.79335511 10.32451622], weights: [0.23405229 0.26438747 0.50156023], train_wt_loss:  37.8838, val_wt_loss: 36.7133, train_grp_loss: [11.4989985  13.7027824  12.99772173], val_grp_loss: [12.6536556  12.80323492 11.2546996 ], train_hist_grp_loss: [10.11806604 13.16484467 29.17254447], cur_train_grp_loss: [0.08845582 0.11514537 0.25486294], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6782, max_kl_dist_index: 0, max_train_grp_loss:  13.7028, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8032, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2549, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:08:45,924 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  114, train_loss:  12.6280, val_loss:  12.2380, grad_norm: 0.0106, live_grad: 0.0000, reward_err: 0.0105, 0.0186, 0.0013, KL_dist: 0.6783, 0.3251, 0.6775, param: [ 4.83452103  6.80962574  5.79424843 10.32659238], weights: [0.23320528 0.26371212 0.5030826 ], train_wt_loss:  37.8839, val_wt_loss: 36.7140, train_grp_loss: [11.4987269  13.70328349 12.99742912], val_grp_loss: [12.65349997 12.80416013 11.25464452], train_hist_grp_loss: [10.20651987 13.2799941  29.42740176], cur_train_grp_loss: [0.08845383 0.11514943 0.25485729], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6783, max_kl_dist_index: 0, max_train_grp_loss:  13.7033, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8042, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2549, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:08:46,976 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  115, train_loss:  12.6280, val_loss:  12.2382, grad_norm: 0.0107, live_grad: 0.0000, reward_err: 0.0103, 0.0186, 0.0014, KL_dist: 0.6784, 0.3252, 0.6775, param: [ 4.83354631  6.80839052  5.79513862 10.32869322], weights: [0.23235914 0.26303609 0.50460476], train_wt_loss:  37.8840, val_wt_loss: 36.7147, train_grp_loss: [11.49844156 13.70380238 12.99713226], val_grp_loss: [12.65333163 12.80510732 11.25458356], train_hist_grp_loss: [10.29497162 13.39514775 29.68225331], cur_train_grp_loss: [0.08845175 0.11515364 0.25485155], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6784, max_kl_dist_index: 0, max_train_grp_loss:  13.7038, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8051, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2549, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:08:48,006 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  116, train_loss:  12.6280, val_loss:  12.2385, grad_norm: 0.0108, live_grad: 0.0000, reward_err: 0.0106, 0.0186, 0.0015, KL_dist: 0.6784, 0.3252, 0.6776, param: [ 4.83256396  6.80715886  5.79602565 10.33081878], weights: [0.2315139 0.2623594 0.5061267], train_wt_loss:  37.8841, val_wt_loss: 36.7154, train_grp_loss: [11.49814246 13.70433913 12.99683115], val_grp_loss: [12.65315056 12.80607654 11.25451674], train_hist_grp_loss: [10.38342117 13.51030575 29.93709904], cur_train_grp_loss: [0.08844955 0.115158   0.25484573], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6784, max_kl_dist_index: 0, max_train_grp_loss:  13.7043, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8061, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2548, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:08:49,022 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  117, train_loss:  12.6281, val_loss:  12.2387, grad_norm: 0.0109, live_grad: 0.0000, reward_err: 0.0106, 0.0186, 0.0015, KL_dist: 0.6785, 0.3253, 0.6777, param: [ 4.83157398  6.80593072  5.79690952 10.33296912], weights: [0.23066956 0.26168205 0.50764838], train_wt_loss:  37.8842, val_wt_loss: 36.7162, train_grp_loss: [11.49782959 13.70489376 12.99652577], val_grp_loss: [12.65295676 12.80706785 11.25444404], train_hist_grp_loss: [10.47186842 13.62546826 30.19193887], cur_train_grp_loss: [0.08844725 0.11516251 0.25483983], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6785, max_kl_dist_index: 0, max_train_grp_loss:  13.7049, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8071, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2548, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:08:50,025 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  118, train_loss:  12.6281, val_loss:  12.2390, grad_norm: 0.0110, live_grad: 0.0000, reward_err: 0.0104, 0.0186, 0.0015, KL_dist: 0.6786, 0.3253, 0.6778, param: [ 4.83057633  6.80470608  5.7977902  10.3351443 ], weights: [0.22982615 0.26100408 0.50916978], train_wt_loss:  37.8843, val_wt_loss: 36.7169, train_grp_loss: [11.49750293 13.70546632 12.99621613], val_grp_loss: [12.6527502  12.80808129 11.25436547], train_hist_grp_loss: [10.56031326 13.74063544 30.4467727 ], cur_train_grp_loss: [0.08844484 0.11516717 0.25483384], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6786, max_kl_dist_index: 0, max_train_grp_loss:  13.7055, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8081, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2548, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:08:51,045 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  119, train_loss:  12.6281, val_loss:  12.2392, grad_norm: 0.0111, live_grad: 0.0000, reward_err: 0.0104, 0.0186, 0.0015, KL_dist: 0.6787, 0.3254, 0.6779, param: [ 4.82957102  6.80348491  5.79866769 10.33734435], weights: [0.22898366 0.26032548 0.51069086], train_wt_loss:  37.8844, val_wt_loss: 36.7176, train_grp_loss: [11.49716247 13.70605683 12.99590221], val_grp_loss: [12.65253087 12.80911691 11.25428103], train_hist_grp_loss: [10.64875559 13.85580742 30.70160047], cur_train_grp_loss: [0.08844233 0.11517199 0.25482777], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6787, max_kl_dist_index: 0, max_train_grp_loss:  13.7061, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8091, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2548, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:08:52,050 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  120, train_loss:  12.6282, val_loss:  12.2395, grad_norm: 0.0112, live_grad: 0.0000, reward_err: 0.0104, 0.0186, 0.0015, KL_dist: 0.6787, 0.3254, 0.6780, param: [ 4.82855801  6.80226718  5.79954197 10.33956934], weights: [0.22814211 0.25964629 0.51221159], train_wt_loss:  37.8845, val_wt_loss: 36.7184, train_grp_loss: [11.49680819 13.70666535 12.99558402], val_grp_loss: [12.65229876 12.81017478 11.25419072], train_hist_grp_loss: [10.7371953  13.97098437 30.95642208], cur_train_grp_loss: [0.08843971 0.11517695 0.25482161], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6787, max_kl_dist_index: 0, max_train_grp_loss:  13.7067, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8102, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2548, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:08:53,073 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  121, train_loss:  12.6282, val_loss:  12.2397, grad_norm: 0.0113, live_grad: 0.0000, reward_err: 0.0104, 0.0186, 0.0015, KL_dist: 0.6788, 0.3255, 0.6781, param: [ 4.82753731  6.80105286  5.80041302 10.34181931], weights: [0.22730152 0.25896652 0.51373195], train_wt_loss:  37.8846, val_wt_loss: 36.7191, train_grp_loss: [11.49644008 13.70729191 12.99526154], val_grp_loss: [12.65205384 12.81125492 11.25409454], train_hist_grp_loss: [10.82563229 14.08616643 31.21123746], cur_train_grp_loss: [0.08843699 0.11518206 0.25481537], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6788, max_kl_dist_index: 0, max_train_grp_loss:  13.7073, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8113, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2548, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:08:54,096 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  122, train_loss:  12.6282, val_loss:  12.2400, grad_norm: 0.0115, live_grad: 0.0000, reward_err: 0.0104, 0.0186, 0.0015, KL_dist: 0.6789, 0.3256, 0.6782, param: [ 4.8265089   6.79984192  5.80128084 10.34409432], weights: [0.2264619  0.25828619 0.51525191], train_wt_loss:  37.8847, val_wt_loss: 36.7199, train_grp_loss: [11.49605813 13.70793653 12.99493478], val_grp_loss: [12.65179611 12.81235741 11.2539925 ], train_hist_grp_loss: [10.91406645 14.20135376 31.46604651], cur_train_grp_loss: [0.08843415 0.11518733 0.25480905], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6789, max_kl_dist_index: 0, max_train_grp_loss:  13.7079, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8124, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2548, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:08:55,121 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  123, train_loss:  12.6283, val_loss:  12.2402, grad_norm: 0.0116, live_grad: 0.0000, reward_err: 0.0104, 0.0186, 0.0015, KL_dist: 0.6790, 0.3256, 0.6783, param: [ 4.82547275  6.79863433  5.8021454  10.34639441], weights: [0.22562326 0.2576053  0.51677144], train_wt_loss:  37.8848, val_wt_loss: 36.7206, train_grp_loss: [11.49566232 13.70859927 12.99460373], val_grp_loss: [12.65152556 12.81348228 11.25388459], train_hist_grp_loss: [11.00249766 14.3165465  31.72084915], cur_train_grp_loss: [0.08843122 0.11519274 0.25480264], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6790, max_kl_dist_index: 0, max_train_grp_loss:  13.7086, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8135, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2548, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:08:56,184 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  124, train_loss:  12.6283, val_loss:  12.2405, grad_norm: 0.0117, live_grad: 0.0000, reward_err: 0.0104, 0.0186, 0.0015, KL_dist: 0.6790, 0.3257, 0.6784, param: [ 4.82442887  6.79743006  5.8030067  10.34871964], weights: [0.22478561 0.25692389 0.5182905 ], train_wt_loss:  37.8849, val_wt_loss: 36.7214, train_grp_loss: [11.49525265 13.70928015 12.99426839], val_grp_loss: [12.65124217 12.81462958 11.25377083], train_hist_grp_loss: [11.09092583 14.43174482 31.9756453 ], cur_train_grp_loss: [0.08842817 0.11519831 0.25479615], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6790, max_kl_dist_index: 0, max_train_grp_loss:  13.7093, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8146, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2548, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:08:57,238 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  125, train_loss:  12.6284, val_loss:  12.2407, grad_norm: 0.0118, live_grad: 0.0000, reward_err: 0.0104, 0.0186, 0.0015, KL_dist: 0.6791, 0.3257, 0.6784, param: [ 4.82337722  6.79622907  5.80386472 10.35107004], weights: [0.22394897 0.25624196 0.51980907], train_wt_loss:  37.8851, val_wt_loss: 36.7221, train_grp_loss: [11.4948291  13.70997922 12.99392874], val_grp_loss: [12.65094592 12.81579938 11.2536512 ], train_hist_grp_loss: [11.17935085 14.54694885 32.23043488], cur_train_grp_loss: [0.08842502 0.11520403 0.25478958], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6791, max_kl_dist_index: 0, max_train_grp_loss:  13.7100, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8158, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2548, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:08:58,283 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  126, train_loss:  12.6284, val_loss:  12.2410, grad_norm: 0.0119, live_grad: 0.0000, reward_err: 0.0104, 0.0186, 0.0015, KL_dist: 0.6792, 0.3258, 0.6785, param: [ 4.82231781  6.79503135  5.80471944 10.35344569], weights: [0.22311335 0.25555953 0.52132713], train_wt_loss:  37.8852, val_wt_loss: 36.7229, train_grp_loss: [11.49439166 13.71069651 12.9935848 ], val_grp_loss: [12.65063681 12.81699171 11.25352571], train_hist_grp_loss: [11.26777262 14.66215876 32.48521779], cur_train_grp_loss: [0.08842176 0.11520991 0.25478292], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6792, max_kl_dist_index: 0, max_train_grp_loss:  13.7107, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8170, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2548, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:08:59,312 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  127, train_loss:  12.6284, val_loss:  12.2412, grad_norm: 0.0120, live_grad: 0.0000, reward_err: 0.0104, 0.0186, 0.0015, KL_dist: 0.6793, 0.3258, 0.6786, param: [ 4.82125061  6.79383685  5.80557086 10.35584661], weights: [0.22227875 0.25487662 0.52284463], train_wt_loss:  37.8853, val_wt_loss: 36.7236, train_grp_loss: [11.49394032 13.71143206 12.99323654], val_grp_loss: [12.65031481 12.81820663 11.25339438], train_hist_grp_loss: [11.35619101 14.7773747  32.73999397], cur_train_grp_loss: [0.0884184  0.11521594 0.25477617], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6793, max_kl_dist_index: 0, max_train_grp_loss:  13.7114, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8182, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2548, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:09:00,365 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  128, train_loss:  12.6285, val_loss:  12.2415, grad_norm: 0.0121, live_grad: 0.0000, reward_err: 0.0104, 0.0186, 0.0015, KL_dist: 0.6794, 0.3259, 0.6788, param: [ 4.82017561  6.79264555  5.80641895 10.35827287], weights: [0.2214452  0.25419324 0.52436156], train_wt_loss:  37.8854, val_wt_loss: 36.7244, train_grp_loss: [11.49347506 13.71218591 12.99288398], val_grp_loss: [12.64997993 12.81944418 11.25325719], train_hist_grp_loss: [11.44460594 14.89259682 32.99476331], cur_train_grp_loss: [0.08841493 0.11522212 0.25476934], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6794, max_kl_dist_index: 0, max_train_grp_loss:  13.7122, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8194, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2548, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:09:01,408 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  129, train_loss:  12.6285, val_loss:  12.2417, grad_norm: 0.0123, live_grad: 0.0000, reward_err: 0.0104, 0.0186, 0.0015, KL_dist: 0.6795, 0.3259, 0.6789, param: [ 4.81909279  6.7914574   5.8072637  10.3607245 ], weights: [0.2206127  0.25350942 0.52587788], train_wt_loss:  37.8855, val_wt_loss: 36.7252, train_grp_loss: [11.49299588 13.71295809 12.9925271 ], val_grp_loss: [12.64963215 12.82070443 11.25311416], train_hist_grp_loss: [11.53301729 15.00782527 33.24952574], cur_train_grp_loss: [0.08841135 0.11522845 0.25476243], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6795, max_kl_dist_index: 0, max_train_grp_loss:  13.7130, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8207, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2548, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:09:02,415 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  130, train_loss:  12.6285, val_loss:  12.2420, grad_norm: 0.0124, live_grad: 0.0000, reward_err: 0.0104, 0.0186, 0.0015, KL_dist: 0.6795, 0.3260, 0.6790, param: [ 4.81800215  6.79027239  5.80810511 10.36320156], weights: [0.21978127 0.25282517 0.52739356], train_wt_loss:  37.8856, val_wt_loss: 36.7260, train_grp_loss: [11.49250277 13.71374863 12.99216591], val_grp_loss: [12.64927146 12.82198741 11.25296529], train_hist_grp_loss: [11.62142495 15.12306021 33.50428117], cur_train_grp_loss: [0.08840766 0.11523494 0.25475543], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6795, max_kl_dist_index: 0, max_train_grp_loss:  13.7137, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8220, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2548, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:09:03,434 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  131, train_loss:  12.6286, val_loss:  12.2422, grad_norm: 0.0125, live_grad: 0.0000, reward_err: 0.0104, 0.0186, 0.0015, KL_dist: 0.6796, 0.3261, 0.6791, param: [ 4.81690367  6.78909048  5.80894314 10.3657041 ], weights: [0.21895091 0.2521405  0.52890858], train_wt_loss:  37.8857, val_wt_loss: 36.7267, train_grp_loss: [11.49199572 13.71455759 12.99180039], val_grp_loss: [12.64889784 12.82329318 11.25281058], train_hist_grp_loss: [11.70982881 15.2383018  33.75902953], cur_train_grp_loss: [0.08840387 0.11524159 0.25474835], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6796, max_kl_dist_index: 0, max_train_grp_loss:  13.7146, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8233, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2547, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:09:04,457 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  132, train_loss:  12.6286, val_loss:  12.2425, grad_norm: 0.0126, live_grad: 0.0000, reward_err: 0.0104, 0.0186, 0.0015, KL_dist: 0.6797, 0.3261, 0.6792, param: [ 4.81579733  6.78791163  5.8097778  10.36823215], weights: [0.21812165 0.25145544 0.53042291], train_wt_loss:  37.8859, val_wt_loss: 36.7275, train_grp_loss: [11.49147471 13.71538499 12.99143056], val_grp_loss: [12.64851128 12.82462179 11.25265004], train_hist_grp_loss: [11.79822878 15.35355018 34.01377071], cur_train_grp_loss: [0.08839997 0.11524838 0.25474118], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6797, max_kl_dist_index: 0, max_train_grp_loss:  13.7154, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8246, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2547, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:09:05,472 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  133, train_loss:  12.6287, val_loss:  12.2428, grad_norm: 0.0127, live_grad: 0.0000, reward_err: 0.0104, 0.0186, 0.0015, KL_dist: 0.6798, 0.3262, 0.6793, param: [ 4.81468313  6.78673581  5.81060905 10.37078578], weights: [0.21729349 0.25077    0.53193651], train_wt_loss:  37.8860, val_wt_loss: 36.7283, train_grp_loss: [11.49093974 13.71623086 12.99105639], val_grp_loss: [12.64811179 12.82597329 11.25248367], train_hist_grp_loss: [11.88662474 15.46880552 34.26850464], cur_train_grp_loss: [0.08839596 0.11525534 0.25473393], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6798, max_kl_dist_index: 0, max_train_grp_loss:  13.7162, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8260, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2547, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:09:06,500 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  134, train_loss:  12.6287, val_loss:  12.2430, grad_norm: 0.0128, live_grad: 0.0000, reward_err: 0.0104, 0.0186, 0.0015, KL_dist: 0.6799, 0.3262, 0.6794, param: [ 4.81356104  6.785563    5.8114369  10.37336502], weights: [0.21646645 0.25008419 0.53344936], train_wt_loss:  37.8861, val_wt_loss: 36.7291, train_grp_loss: [11.4903908  13.71709526 12.9906779 ], val_grp_loss: [12.64769933 12.82734772 11.25231148], train_hist_grp_loss: [11.97501658 15.58406796 34.52323124], cur_train_grp_loss: [0.08839184 0.11526244 0.2547266 ], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6799, max_kl_dist_index: 0, max_train_grp_loss:  13.7171, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8273, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2547, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:09:07,532 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  135, train_loss:  12.6287, val_loss:  12.2433, grad_norm: 0.0130, live_grad: 0.0000, reward_err: 0.0104, 0.0186, 0.0015, KL_dist: 0.6800, 0.3263, 0.6795, param: [ 4.81243106  6.78439314  5.81226133 10.37596992], weights: [0.21564053 0.24939803 0.53496144], train_wt_loss:  37.8862, val_wt_loss: 36.7299, train_grp_loss: [11.48982789 13.71797821 12.99029507], val_grp_loss: [12.64727392 12.82874514 11.25213348], train_hist_grp_loss: [12.06340421 15.69933767 34.77795041], cur_train_grp_loss: [0.08838762 0.11526971 0.25471917], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6800, max_kl_dist_index: 0, max_train_grp_loss:  13.7180, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8287, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2547, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:09:08,546 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  136, train_loss:  12.6288, val_loss:  12.2436, grad_norm: 0.0131, live_grad: 0.0000, reward_err: 0.0104, 0.0186, 0.0015, KL_dist: 0.6801, 0.3264, 0.6796, param: [ 4.81129317  6.78322622  5.81308231 10.37860053], weights: [0.21481575 0.24871155 0.5364727 ], train_wt_loss:  37.8863, val_wt_loss: 36.7307, train_grp_loss: [11.48925099 13.71887975 12.98990791], val_grp_loss: [12.64683552 12.8301656  11.25194966], train_hist_grp_loss: [12.1517875  15.8146148  35.03266208], cur_train_grp_loss: [0.08838329 0.11527713 0.25471167], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6801, max_kl_dist_index: 0, max_train_grp_loss:  13.7189, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8302, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2547, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:09:09,566 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  137, train_loss:  12.6288, val_loss:  12.2438, grad_norm: 0.0132, live_grad: 0.0000, reward_err: 0.0104, 0.0186, 0.0015, KL_dist: 0.6802, 0.3264, 0.6797, param: [ 4.81014735  6.78206219  5.81389984 10.38125689], weights: [0.21399212 0.24802475 0.53798313], train_wt_loss:  37.8865, val_wt_loss: 36.7315, train_grp_loss: [11.48866009 13.71979991 12.98951641], val_grp_loss: [12.64638415 12.83160915 11.25176004], train_hist_grp_loss: [12.24016635 15.9298995  35.28736616], cur_train_grp_loss: [0.08837885 0.1152847  0.25470408], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6802, max_kl_dist_index: 0, max_train_grp_loss:  13.7198, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8316, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2547, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:09:10,586 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  138, train_loss:  12.6289, val_loss:  12.2441, grad_norm: 0.0133, live_grad: 0.0000, reward_err: 0.0104, 0.0186, 0.0015, KL_dist: 0.6802, 0.3265, 0.6799, param: [ 4.8089936   6.78090103  5.8147139  10.38393904], weights: [0.21316966 0.24733765 0.53949269], train_wt_loss:  37.8866, val_wt_loss: 36.7323, train_grp_loss: [11.4880552  13.72073874 12.98912057], val_grp_loss: [12.64591979 12.83307583 11.25156462], train_hist_grp_loss: [12.32854066 16.04519194 35.54206256], cur_train_grp_loss: [0.08837431 0.11529244 0.2546964 ], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6802, max_kl_dist_index: 0, max_train_grp_loss:  13.7207, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8331, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2547, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:09:11,659 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  139, train_loss:  12.6289, val_loss:  12.2444, grad_norm: 0.0135, live_grad: 0.0000, reward_err: 0.0104, 0.0186, 0.0015, KL_dist: 0.6803, 0.3266, 0.6800, param: [ 4.8078319   6.77974269  5.81552448 10.38664704], weights: [0.21234837 0.24665027 0.54100136], train_wt_loss:  37.8867, val_wt_loss: 36.7331, train_grp_loss: [11.4874363  13.72169627 12.98872039], val_grp_loss: [12.64544243 12.8345657  11.25136341], train_hist_grp_loss: [12.41691031 16.16049226 35.7967512 ], cur_train_grp_loss: [0.08836966 0.11530033 0.25468864], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6803, max_kl_dist_index: 0, max_train_grp_loss:  13.7217, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8346, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2547, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:09:12,707 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  140, train_loss:  12.6290, val_loss:  12.2447, grad_norm: 0.0136, live_grad: 0.0000, reward_err: 0.0104, 0.0189, 0.0015, KL_dist: 0.6804, 0.3266, 0.6801, param: [ 4.80666224  6.77858714  5.81633156 10.38938093], weights: [0.21152826 0.24596263 0.54250911], train_wt_loss:  37.8869, val_wt_loss: 36.7340, train_grp_loss: [11.48680339 13.72267254 12.98831586], val_grp_loss: [12.64495206 12.83607881 11.25115642], train_hist_grp_loss: [12.50527521 16.27580063 36.05143199], cur_train_grp_loss: [0.08836489 0.11530837 0.25468079], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6804, max_kl_dist_index: 0, max_train_grp_loss:  13.7227, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8361, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2547, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:09:13,739 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  141, train_loss:  12.6290, val_loss:  12.2449, grad_norm: 0.0137, live_grad: 0.0000, reward_err: 0.0104, 0.0189, 0.0015, KL_dist: 0.6805, 0.3267, 0.6802, param: [ 4.8054846   6.77743435  5.81713513 10.39214074], weights: [0.21070935 0.24527474 0.54401591], train_wt_loss:  37.8870, val_wt_loss: 36.7348, train_grp_loss: [11.48615646 13.72366758 12.98790699], val_grp_loss: [12.64444867 12.8376152  11.25094366], train_hist_grp_loss: [12.59363524 16.39111721 36.30610485], cur_train_grp_loss: [0.08836003 0.11531658 0.25467286], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6805, max_kl_dist_index: 0, max_train_grp_loss:  13.7237, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8376, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2547, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:09:14,766 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  142, train_loss:  12.6290, val_loss:  12.2452, grad_norm: 0.0138, live_grad: 0.0000, reward_err: 0.0104, 0.0189, 0.0015, KL_dist: 0.6806, 0.3268, 0.6804, param: [ 4.80429898  6.77628429  5.81793517 10.39492653], weights: [0.20989165 0.24458662 0.54552173], train_wt_loss:  37.8871, val_wt_loss: 36.7356, train_grp_loss: [11.4854955  13.72468143 12.98749377], val_grp_loss: [12.64393227 12.83917492 11.25072512], train_hist_grp_loss: [12.68199029 16.50644215 36.56076969], cur_train_grp_loss: [0.08835505 0.11532494 0.25466484], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6806, max_kl_dist_index: 0, max_train_grp_loss:  13.7247, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8392, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2547, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:09:15,801 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  143, train_loss:  12.6291, val_loss:  12.2455, grad_norm: 0.0140, live_grad: 0.0000, reward_err: 0.0103, 0.0189, 0.0016, KL_dist: 0.6807, 0.3268, 0.6805, param: [ 4.80310535  6.7751369   5.81873167 10.39773833], weights: [0.20907517 0.24389829 0.54702654], train_wt_loss:  37.8873, val_wt_loss: 36.7364, train_grp_loss: [11.48482052 13.72571412 12.98707621], val_grp_loss: [12.64340283 12.84075803 11.25050083], train_hist_grp_loss: [12.77034025 16.6217756  36.81542643], cur_train_grp_loss: [0.08834997 0.11533346 0.25465674], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6807, max_kl_dist_index: 0, max_train_grp_loss:  13.7257, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8408, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2547, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:09:16,871 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  144, train_loss:  12.6291, val_loss:  12.2458, grad_norm: 0.0141, live_grad: 0.0000, reward_err: 0.0103, 0.0189, 0.0016, KL_dist: 0.6808, 0.3269, 0.6806, param: [ 4.80190371  6.77399217  5.81952461 10.4005762 ], weights: [0.20825993 0.24320976 0.54853032], train_wt_loss:  37.8874, val_wt_loss: 36.7373, train_grp_loss: [11.4841315  13.7267657  12.98665429], val_grp_loss: [12.64286037 12.84236458 11.25027078], train_hist_grp_loss: [12.85868502 16.73711774 37.07007498], cur_train_grp_loss: [0.08834477 0.11534214 0.25464855], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6808, max_kl_dist_index: 0, max_train_grp_loss:  13.7268, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8424, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2546, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:09:17,897 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  145, train_loss:  12.6292, val_loss:  12.2460, grad_norm: 0.0142, live_grad: 0.0000, reward_err: 0.0103, 0.0189, 0.0016, KL_dist: 0.6809, 0.3270, 0.6807, param: [ 4.80069404  6.77285004  5.82031398 10.40344016], weights: [0.20744593 0.24252104 0.55003303], train_wt_loss:  37.8876, val_wt_loss: 36.7381, train_grp_loss: [11.48342845 13.7278362  12.98622802], val_grp_loss: [12.64230486 12.8439946  11.25003499], train_hist_grp_loss: [12.9470245  16.85246871 37.32471526], cur_train_grp_loss: [0.08833947 0.11535097 0.25464028], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6809, max_kl_dist_index: 0, max_train_grp_loss:  13.7278, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8440, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2546, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:09:18,927 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  146, train_loss:  12.6292, val_loss:  12.2463, grad_norm: 0.0144, live_grad: 0.0000, reward_err: 0.0103, 0.0189, 0.0016, KL_dist: 0.6810, 0.3270, 0.6809, param: [ 4.79947633  6.7717105   5.82109977 10.40633027], weights: [0.20663318 0.24183216 0.55153466], train_wt_loss:  37.8877, val_wt_loss: 36.7390, train_grp_loss: [11.48271136 13.72892565 12.9857974 ], val_grp_loss: [12.64173631 12.84564816 11.24979347], train_hist_grp_loss: [13.03535856 16.96782868 37.57934719], cur_train_grp_loss: [0.08833407 0.11535997 0.25463192], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6810, max_kl_dist_index: 0, max_train_grp_loss:  13.7289, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8456, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2546, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:09:19,970 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  147, train_loss:  12.6293, val_loss:  12.2466, grad_norm: 0.0145, live_grad: 0.0000, reward_err: 0.0103, 0.0189, 0.0016, KL_dist: 0.6811, 0.3271, 0.6810, param: [ 4.79825057  6.77057349  5.82188195 10.40924656], weights: [0.2058217  0.24114313 0.55303517], train_wt_loss:  37.8878, val_wt_loss: 36.7398, train_grp_loss: [11.48198022 13.73003409 12.98536242], val_grp_loss: [12.64115471 12.84732529 11.24954622], train_hist_grp_loss: [13.12368711 17.0831978  37.83397066], cur_train_grp_loss: [0.08832855 0.11536912 0.25462348], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6811, max_kl_dist_index: 0, max_train_grp_loss:  13.7300, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8473, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2546, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:09:20,987 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  148, train_loss:  12.6293, val_loss:  12.2469, grad_norm: 0.0146, live_grad: 0.0000, reward_err: 0.0103, 0.0189, 0.0016, KL_dist: 0.6812, 0.3272, 0.6811, param: [ 4.79701675  6.76943898  5.82266051 10.41218908], weights: [0.2050115  0.24045398 0.55453453], train_wt_loss:  37.8880, val_wt_loss: 36.7407, train_grp_loss: [11.48123503 13.73116155 12.98492309], val_grp_loss: [12.64056005 12.84902606 11.24929326], train_hist_grp_loss: [13.21201004 17.19857624 38.08858561], cur_train_grp_loss: [0.08832292 0.11537844 0.25461495], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6812, max_kl_dist_index: 0, max_train_grp_loss:  13.7312, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8490, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2546, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:09:22,049 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  149, train_loss:  12.6294, val_loss:  12.2472, grad_norm: 0.0147, live_grad: 0.0000, reward_err: 0.0103, 0.0189, 0.0016, KL_dist: 0.6813, 0.3273, 0.6813, param: [ 4.79577485  6.76830693  5.82343545 10.41515787], weights: [0.20420258 0.2397647  0.55603272], train_wt_loss:  37.8881, val_wt_loss: 36.7415, train_grp_loss: [11.4804758  13.73230808 12.98447941], val_grp_loss: [12.63995233 12.8507505  11.24903459], train_hist_grp_loss: [13.30032723 17.31396415 38.34319195], cur_train_grp_loss: [0.08831719 0.11538791 0.25460634], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6813, max_kl_dist_index: 0, max_train_grp_loss:  13.7323, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8508, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2546, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:09:23,077 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  150, train_loss:  12.6294, val_loss:  12.2475, grad_norm: 0.0149, live_grad: 0.0000, reward_err: 0.0103, 0.0189, 0.0016, KL_dist: 0.6814, 0.3273, 0.6814, param: [ 4.79452486  6.76717731  5.82420674 10.41815296], weights: [0.20339497 0.23907533 0.55752971], train_wt_loss:  37.8883, val_wt_loss: 36.7424, train_grp_loss: [11.47970251 13.73347371 12.98403137], val_grp_loss: [12.63933155 12.85249867 11.24877023], train_hist_grp_loss: [13.38863858 17.4293617  38.59778958], cur_train_grp_loss: [0.08831135 0.11539755 0.25459764], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6814, max_kl_dist_index: 0, max_train_grp_loss:  13.7335, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8525, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2546, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:09:24,104 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  151, train_loss:  12.6295, val_loss:  12.2478, grad_norm: 0.0150, live_grad: 0.0000, reward_err: 0.0102, 0.0189, 0.0017, KL_dist: 0.6815, 0.3274, 0.6815, param: [ 4.79326677  6.76605007  5.82497436 10.4211744 ], weights: [0.20258867 0.23838587 0.55902547], train_wt_loss:  37.8885, val_wt_loss: 36.7433, train_grp_loss: [11.47891517 13.73465847 12.98357897], val_grp_loss: [12.6386977  12.85427061 11.24850019], train_hist_grp_loss: [13.47694398 17.54476904 38.85237844], cur_train_grp_loss: [0.0883054  0.11540734 0.25458885], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6815, max_kl_dist_index: 0, max_train_grp_loss:  13.7347, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8543, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2546, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:09:25,140 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  152, train_loss:  12.6295, val_loss:  12.2481, grad_norm: 0.0152, live_grad: 0.0000, reward_err: 0.0102, 0.0189, 0.0017, KL_dist: 0.6817, 0.3275, 0.6817, param: [ 4.79200057  6.76492519  5.82573832 10.42422222], weights: [0.20178369 0.23769634 0.56051997], train_wt_loss:  37.8886, val_wt_loss: 36.7442, train_grp_loss: [11.47811378 13.7358624  12.98312222], val_grp_loss: [12.63805078 12.85606638 11.24822447], train_hist_grp_loss: [13.56524333 17.66018634 39.10695842], cur_train_grp_loss: [0.08829935 0.1154173  0.25457998], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6817, max_kl_dist_index: 2, max_train_grp_loss:  13.7359, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8561, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2546, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:09:26,183 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  153, train_loss:  12.6296, val_loss:  12.2484, grad_norm: 0.0153, live_grad: 0.0000, reward_err: 0.0102, 0.0189, 0.0017, KL_dist: 0.6818, 0.3276, 0.6818, param: [ 4.79072624  6.76380261  5.82649858 10.42729647], weights: [0.20098004 0.23700677 0.56201319], train_wt_loss:  37.8888, val_wt_loss: 36.7451, train_grp_loss: [11.47729833 13.73708553 12.98266111], val_grp_loss: [12.63739079 12.85788601 11.24794309], train_hist_grp_loss: [13.65353651 17.77561375 39.36152944], cur_train_grp_loss: [0.08829318 0.11542742 0.25457102], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6818, max_kl_dist_index: 2, max_train_grp_loss:  13.7371, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8579, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2546, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:09:27,186 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  154, train_loss:  12.6296, val_loss:  12.2486, grad_norm: 0.0154, live_grad: 0.0000, reward_err: 0.0102, 0.0189, 0.0017, KL_dist: 0.6819, 0.3276, 0.6820, param: [ 4.78944377  6.7626823   5.82725513 10.43039719], weights: [0.20017774 0.23631716 0.5635051 ], train_wt_loss:  37.8889, val_wt_loss: 36.7459, train_grp_loss: [11.47646883 13.73832791 12.98219564], val_grp_loss: [12.63671773 12.85972957 11.24765607], train_hist_grp_loss: [13.74182343 17.89105145 39.61609142], cur_train_grp_loss: [0.08828691 0.11543769 0.25456198], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6820, max_kl_dist_index: 2, max_train_grp_loss:  13.7383, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8597, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2546, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:09:28,209 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  155, train_loss:  12.6297, val_loss:  12.2489, grad_norm: 0.0156, live_grad: 0.0000, reward_err: 0.0102, 0.0189, 0.0017, KL_dist: 0.6820, 0.3277, 0.6821, param: [ 4.78815316  6.76156422  5.82800797 10.4335244 ], weights: [0.19937679 0.23562753 0.56499568], train_wt_loss:  37.8891, val_wt_loss: 36.7468, train_grp_loss: [11.47562527 13.73958956 12.98172582], val_grp_loss: [12.63603158 12.86159709 11.2473634 ], train_hist_grp_loss: [13.83010395 18.00649958 39.87064428], cur_train_grp_loss: [0.08828053 0.11544813 0.25455286], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6821, max_kl_dist_index: 2, max_train_grp_loss:  13.7396, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8616, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2546, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:09:29,255 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  156, train_loss:  12.6298, val_loss:  12.2492, grad_norm: 0.0157, live_grad: 0.0000, reward_err: 0.0102, 0.0189, 0.0017, KL_dist: 0.6821, 0.3278, 0.6823, param: [ 4.78685438  6.76044834  5.82875707 10.43667815], weights: [0.19857721 0.2349379  0.56648489], train_wt_loss:  37.8893, val_wt_loss: 36.7477, train_grp_loss: [11.47476766 13.74087052 12.98125164], val_grp_loss: [12.63533236 12.86348862 11.24706511], train_hist_grp_loss: [13.918378   18.12195832 40.12518792], cur_train_grp_loss: [0.08827404 0.11545874 0.25454364], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6823, max_kl_dist_index: 2, max_train_grp_loss:  13.7409, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8635, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2545, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:09:30,264 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  157, train_loss:  12.6298, val_loss:  12.2495, grad_norm: 0.0158, live_grad: 0.0000, reward_err: 0.0102, 0.0189, 0.0017, KL_dist: 0.6822, 0.3279, 0.6824, param: [ 4.78554744  6.75933461  5.82950242 10.43985847], weights: [0.19777901 0.23424828 0.56797271], train_wt_loss:  37.8894, val_wt_loss: 36.7486, train_grp_loss: [11.473896   13.74217083 12.98077311], val_grp_loss: [12.63462005 12.86540422 11.24676121], train_hist_grp_loss: [14.00664544 18.23742782 40.37972227], cur_train_grp_loss: [0.08826744 0.1154695  0.25453435], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6824, max_kl_dist_index: 2, max_train_grp_loss:  13.7422, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8654, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2545, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:09:31,290 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  158, train_loss:  12.6299, val_loss:  12.2498, grad_norm: 0.0160, live_grad: 0.0000, reward_err: 0.0102, 0.0189, 0.0017, KL_dist: 0.6823, 0.3279, 0.6826, param: [ 4.78423231  6.75822299  5.830244   10.44306541], weights: [0.19698219 0.2335587  0.56945911], train_wt_loss:  37.8896, val_wt_loss: 36.7495, train_grp_loss: [11.47301029 13.74349051 12.98029022], val_grp_loss: [12.63389467 12.86734393 11.24645171], train_hist_grp_loss: [14.09490618 18.35290825 40.63424723], cur_train_grp_loss: [0.08826074 0.11548043 0.25452496], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6826, max_kl_dist_index: 2, max_train_grp_loss:  13.7435, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8673, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2545, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:09:32,316 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  159, train_loss:  12.6299, val_loss:  12.2502, grad_norm: 0.0161, live_grad: 0.0000, reward_err: 0.0102, 0.0189, 0.0017, KL_dist: 0.6824, 0.3280, 0.6827, param: [ 4.78290898  6.75711344  5.8309818  10.446299  ], weights: [0.19618678 0.23286916 0.57094407], train_wt_loss:  37.8898, val_wt_loss: 36.7505, train_grp_loss: [11.47211052 13.74482962 12.97980298], val_grp_loss: [12.6331562  12.86930779 11.24613662], train_hist_grp_loss: [14.1831601  18.46839976 40.88876272], cur_train_grp_loss: [0.08825393 0.11549152 0.25451549], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6827, max_kl_dist_index: 2, max_train_grp_loss:  13.7448, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8693, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2545, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:09:33,380 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  160, train_loss:  12.6300, val_loss:  12.2505, grad_norm: 0.0163, live_grad: 0.0000, reward_err: 0.0102, 0.0189, 0.0017, KL_dist: 0.6826, 0.3281, 0.6829, param: [ 4.78157745  6.75600592  5.83171581 10.44955927], weights: [0.19539277 0.23217968 0.57242756], train_wt_loss:  37.8900, val_wt_loss: 36.7514, train_grp_loss: [11.47119671 13.74618817 12.97931139], val_grp_loss: [12.63240466 12.87129586 11.24581595], train_hist_grp_loss: [14.27140711 18.58390253 41.14326866], cur_train_grp_loss: [0.088247   0.11550277 0.25450594], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6829, max_kl_dist_index: 2, max_train_grp_loss:  13.7462, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8713, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2545, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:09:34,411 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  161, train_loss:  12.6300, val_loss:  12.2508, grad_norm: 0.0164, live_grad: 0.0000, reward_err: 0.0102, 0.0189, 0.0017, KL_dist: 0.6827, 0.3282, 0.6830, param: [ 4.78023771  6.75490039  5.83244601 10.45284626], weights: [0.19460018 0.23149028 0.57390955], train_wt_loss:  37.8901, val_wt_loss: 36.7523, train_grp_loss: [11.47026886 13.74756621 12.97881545], val_grp_loss: [12.63164003 12.87330819 11.24548973], train_hist_grp_loss: [14.35964708 18.69941672 41.39776497], cur_train_grp_loss: [0.08823997 0.11551419 0.2544963 ], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6830, max_kl_dist_index: 2, max_train_grp_loss:  13.7476, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8733, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2545, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:09:35,431 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  162, train_loss:  12.6301, val_loss:  12.2511, grad_norm: 0.0166, live_grad: 0.0000, reward_err: 0.0102, 0.0189, 0.0017, KL_dist: 0.6828, 0.3283, 0.6832, param: [ 4.77888973  6.75379681  5.83317239 10.45616   ], weights: [0.19380902 0.23080097 0.57539001], train_wt_loss:  37.8903, val_wt_loss: 36.7532, train_grp_loss: [11.46932697 13.74896377 12.97831516], val_grp_loss: [12.63086233 12.87534481 11.24515797], train_hist_grp_loss: [14.44787992 18.81494248 41.65225154], cur_train_grp_loss: [0.08823284 0.11552577 0.25448658], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6832, max_kl_dist_index: 2, max_train_grp_loss:  13.7490, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8753, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2545, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:09:36,465 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  163, train_loss:  12.6302, val_loss:  12.2514, grad_norm: 0.0167, live_grad: 0.0000, reward_err: 0.0102, 0.0189, 0.0017, KL_dist: 0.6829, 0.3283, 0.6833, param: [ 4.77753352  6.75269513  5.83389492 10.45950053], weights: [0.1930193  0.23011177 0.57686893], train_wt_loss:  37.8905, val_wt_loss: 36.7542, train_grp_loss: [11.46837104 13.75038089 12.97781052], val_grp_loss: [12.63007154 12.87740577 11.24482067], train_hist_grp_loss: [14.53610551 18.93048    41.90672831], cur_train_grp_loss: [0.08822559 0.11553751 0.25447677], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6833, max_kl_dist_index: 2, max_train_grp_loss:  13.7504, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8774, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2545, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:09:37,493 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  164, train_loss:  12.6302, val_loss:  12.2517, grad_norm: 0.0169, live_grad: 0.0000, reward_err: 0.0102, 0.0189, 0.0017, KL_dist: 0.6830, 0.3284, 0.6835, param: [ 4.77616906  6.75159532  5.8346136  10.46286788], weights: [0.19223103 0.2294227  0.57834627], train_wt_loss:  37.8907, val_wt_loss: 36.7551, train_grp_loss: [11.46740108 13.75181759 12.97730153], val_grp_loss: [12.62926768 12.87949113 11.24447786], train_hist_grp_loss: [14.62432375 19.04602941 42.16119518], cur_train_grp_loss: [0.08821824 0.11554942 0.25446687], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6835, max_kl_dist_index: 2, max_train_grp_loss:  13.7518, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8795, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2545, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:09:38,505 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  165, train_loss:  12.6303, val_loss:  12.2520, grad_norm: 0.0170, live_grad: 0.0000, reward_err: 0.0102, 0.0189, 0.0017, KL_dist: 0.6831, 0.3285, 0.6836, param: [ 4.77479634  6.75049734  5.83532841 10.46626208], weights: [0.19144422 0.22873377 0.57982201], train_wt_loss:  37.8909, val_wt_loss: 36.7561, train_grp_loss: [11.4664171  13.75327391 12.9767882 ], val_grp_loss: [12.62845075 12.88160092 11.24412955], train_hist_grp_loss: [14.71253453 19.16159091 42.41565208], cur_train_grp_loss: [0.08821078 0.11556149 0.25445689], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6836, max_kl_dist_index: 2, max_train_grp_loss:  13.7533, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8816, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2545, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:09:39,513 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  166, train_loss:  12.6304, val_loss:  12.2523, grad_norm: 0.0172, live_grad: 0.0000, reward_err: 0.0102, 0.0189, 0.0017, KL_dist: 0.6833, 0.3286, 0.6838, param: [ 4.77341535  6.74940114  5.83603934 10.46968317], weights: [0.19065888 0.22804499 0.58129613], train_wt_loss:  37.8911, val_wt_loss: 36.7570, train_grp_loss: [11.46541909 13.7547499  12.97627053], val_grp_loss: [12.62762075 12.8837352  11.24377575], train_hist_grp_loss: [14.80073774 19.27716464 42.6700989 ], cur_train_grp_loss: [0.08820321 0.11557373 0.25444683], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6838, max_kl_dist_index: 2, max_train_grp_loss:  13.7547, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8837, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2544, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:09:40,566 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  167, train_loss:  12.6304, val_loss:  12.2527, grad_norm: 0.0173, live_grad: 0.0000, reward_err: 0.0102, 0.0189, 0.0017, KL_dist: 0.6834, 0.3287, 0.6840, param: [ 4.77202608  6.74830667  5.83674637 10.47313118], weights: [0.18987502 0.22735639 0.58276859], train_wt_loss:  37.8913, val_wt_loss: 36.7580, train_grp_loss: [11.46440706 13.75624557 12.97574852], val_grp_loss: [12.62677767 12.88589401 11.24341649], train_hist_grp_loss: [14.88893327 19.39275077 42.92453558], cur_train_grp_loss: [0.08819553 0.11558613 0.25443668], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6840, max_kl_dist_index: 2, max_train_grp_loss:  13.7562, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8859, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2544, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:09:41,594 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  168, train_loss:  12.6305, val_loss:  12.2530, grad_norm: 0.0175, live_grad: 0.0000, reward_err: 0.0102, 0.0189, 0.0017, KL_dist: 0.6835, 0.3288, 0.6841, param: [ 4.77062852  6.7472139   5.83744948 10.47660614], weights: [0.18909266 0.22666797 0.58423937], train_wt_loss:  37.8915, val_wt_loss: 36.7590, train_grp_loss: [11.46338103 13.75776097 12.97522217], val_grp_loss: [12.62592154 12.8880774  11.24305177], train_hist_grp_loss: [14.97712101 19.50834947 43.17896202], cur_train_grp_loss: [0.08818775 0.1155987  0.25442644], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6841, max_kl_dist_index: 2, max_train_grp_loss:  13.7578, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8881, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2544, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:09:42,625 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  169, train_loss:  12.6306, val_loss:  12.2533, grad_norm: 0.0176, live_grad: 0.0000, reward_err: 0.0103, 0.0189, 0.0018, KL_dist: 0.6836, 0.3289, 0.6843, param: [ 4.76922265  6.74612279  5.83814867 10.48010808], weights: [0.18831179 0.22597976 0.58570845], train_wt_loss:  37.8917, val_wt_loss: 36.7599, train_grp_loss: [11.462341   13.75929612 12.97469148], val_grp_loss: [12.62505234 12.89028541 11.24268162], train_hist_grp_loss: [15.06530087 19.62396091 43.43337814], cur_train_grp_loss: [0.08817985 0.11561144 0.25441612], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6843, max_kl_dist_index: 2, max_train_grp_loss:  13.7593, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8903, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2544, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:09:43,672 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  170, train_loss:  12.6306, val_loss:  12.2536, grad_norm: 0.0178, live_grad: 0.0000, reward_err: 0.0103, 0.0189, 0.0018, KL_dist: 0.6838, 0.3290, 0.6845, param: [ 4.76780848  6.74503329  5.83884391 10.48363703], weights: [0.18753243 0.22529177 0.5871758 ], train_wt_loss:  37.8919, val_wt_loss: 36.7609, train_grp_loss: [11.46128697 13.76085107 12.97415647], val_grp_loss: [12.62417009 12.89251809 11.24230605], train_hist_grp_loss: [15.15347272 19.73958525 43.68778386], cur_train_grp_loss: [0.08817185 0.11562434 0.25440572], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6845, max_kl_dist_index: 2, max_train_grp_loss:  13.7609, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8925, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2544, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:09:44,689 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  171, train_loss:  12.6307, val_loss:  12.2540, grad_norm: 0.0180, live_grad: 0.0000, reward_err: 0.0103, 0.0189, 0.0018, KL_dist: 0.6839, 0.3290, 0.6846, param: [ 4.76638599  6.74394535  5.8395352  10.48719303], weights: [0.1867546  0.22460401 0.58864139], train_wt_loss:  37.8921, val_wt_loss: 36.7619, train_grp_loss: [11.46021895 13.76242585 12.97361712], val_grp_loss: [12.62327478 12.89477548 11.24192508], train_hist_grp_loss: [15.24163647 19.85522265 43.94217908], cur_train_grp_loss: [0.08816375 0.1156374  0.25439522], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6846, max_kl_dist_index: 2, max_train_grp_loss:  13.7624, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8948, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2544, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:09:45,713 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  172, train_loss:  12.6308, val_loss:  12.2543, grad_norm: 0.0181, live_grad: 0.0000, reward_err: 0.0103, 0.0189, 0.0018, KL_dist: 0.6840, 0.3291, 0.6848, param: [ 4.76495517  6.74285893  5.84022251 10.4907761 ], weights: [0.18597829 0.2239165  0.59010521], train_wt_loss:  37.8923, val_wt_loss: 36.7629, train_grp_loss: [11.45913695 13.76402048 12.97307345], val_grp_loss: [12.62236643 12.89705763 11.24153872], train_hist_grp_loss: [15.329792   19.97087329 44.19656373], cur_train_grp_loss: [0.08815553 0.11565064 0.25438465], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6848, max_kl_dist_index: 2, max_train_grp_loss:  13.7640, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8971, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2544, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:09:46,756 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  173, train_loss:  12.6308, val_loss:  12.2546, grad_norm: 0.0183, live_grad: 0.0000, reward_err: 0.0103, 0.0189, 0.0018, KL_dist: 0.6841, 0.3292, 0.6850, param: [ 4.763516    6.741774    5.84090583 10.49438626], weights: [0.18520353 0.22322926 0.59156722], train_wt_loss:  37.8925, val_wt_loss: 36.7639, train_grp_loss: [11.45804099 13.76563501 12.97252546], val_grp_loss: [12.62144504 12.89936458 11.241147  ], train_hist_grp_loss: [15.41793921 20.08653733 44.45093772], cur_train_grp_loss: [0.08814721 0.11566404 0.25437399], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6850, max_kl_dist_index: 2, max_train_grp_loss:  13.7656, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8994, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2544, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:09:47,786 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  174, train_loss:  12.6309, val_loss:  12.2550, grad_norm: 0.0184, live_grad: 0.0000, reward_err: 0.0103, 0.0189, 0.0018, KL_dist: 0.6843, 0.3293, 0.6852, param: [ 4.76206849  6.7406905   5.84158516 10.49802356], weights: [0.18443031 0.22254229 0.5930274 ], train_wt_loss:  37.8928, val_wt_loss: 36.7649, train_grp_loss: [11.45693106 13.76726946 12.97197314], val_grp_loss: [12.62051062 12.90169638 11.24074993], train_hist_grp_loss: [15.50607798 20.20221493 44.70530097], cur_train_grp_loss: [0.08813878 0.11567761 0.25436324], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6852, max_kl_dist_index: 2, max_train_grp_loss:  13.7673, max_train_grp_loss_index: 1, max_val_grp_loss:  12.9017, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2544, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:09:48,796 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  175, train_loss:  12.6310, val_loss:  12.2553, grad_norm: 0.0186, live_grad: 0.0000, reward_err: 0.0105, 0.0189, 0.0019, KL_dist: 0.6844, 0.3294, 0.6853, param: [ 4.76061263  6.73960839  5.84226046 10.50168801], weights: [0.18365865 0.22185562 0.59448572], train_wt_loss:  37.8930, val_wt_loss: 36.7659, train_grp_loss: [11.45580718 13.76892386 12.97141652], val_grp_loss: [12.61956317 12.90405308 11.24034754], train_hist_grp_loss: [15.59420822 20.31790627 44.95965338], cur_train_grp_loss: [0.08813024 0.11569134 0.25435241], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6853, max_kl_dist_index: 2, max_train_grp_loss:  13.7689, max_train_grp_loss_index: 1, max_val_grp_loss:  12.9041, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2544, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:09:49,796 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  176, train_loss:  12.6311, val_loss:  12.2556, grad_norm: 0.0188, live_grad: 0.0000, reward_err: 0.0105, 0.0189, 0.0019, KL_dist: 0.6845, 0.3295, 0.6855, param: [ 4.75914839  6.73852763  5.84293174 10.50537965], weights: [0.18288857 0.22116926 0.59594217], train_wt_loss:  37.8932, val_wt_loss: 36.7669, train_grp_loss: [11.45466936 13.77059826 12.97085558], val_grp_loss: [12.6186027  12.90643471 11.23993983], train_hist_grp_loss: [15.68232981 20.43361151 45.21399488], cur_train_grp_loss: [0.08812159 0.11570524 0.2543415 ], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6855, max_kl_dist_index: 2, max_train_grp_loss:  13.7706, max_train_grp_loss_index: 1, max_val_grp_loss:  12.9064, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2543, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:09:50,810 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  177, train_loss:  12.6311, val_loss:  12.2560, grad_norm: 0.0189, live_grad: 0.0000, reward_err: 0.0105, 0.0189, 0.0019, KL_dist: 0.6847, 0.3296, 0.6857, param: [ 4.75767578  6.73744817  5.84359897 10.50909849], weights: [0.18212005 0.22048323 0.59739672], train_wt_loss:  37.8934, val_wt_loss: 36.7680, train_grp_loss: [11.45351761 13.77229268 12.97029033], val_grp_loss: [12.61762922 12.90884132 11.23952683], train_hist_grp_loss: [15.77044266 20.54933083 45.46832538], cur_train_grp_loss: [0.08811284 0.11571931 0.2543305 ], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6857, max_kl_dist_index: 2, max_train_grp_loss:  13.7723, max_train_grp_loss_index: 1, max_val_grp_loss:  12.9088, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2543, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:09:51,821 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  178, train_loss:  12.6312, val_loss:  12.2563, grad_norm: 0.0191, live_grad: 0.0000, reward_err: 0.0105, 0.0189, 0.0019, KL_dist: 0.6848, 0.3297, 0.6859, param: [ 4.75619479  6.73636997  5.84426214 10.51284458], weights: [0.18135313 0.21979753 0.59884934], train_wt_loss:  37.8937, val_wt_loss: 36.7690, train_grp_loss: [11.45235194 13.77400716 12.96972078], val_grp_loss: [12.61664273 12.91127296 11.23910856], train_hist_grp_loss: [15.85854664 20.66506438 45.7226448 ], cur_train_grp_loss: [0.08810398 0.11573355 0.25431942], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6859, max_kl_dist_index: 2, max_train_grp_loss:  13.7740, max_train_grp_loss_index: 1, max_val_grp_loss:  12.9113, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2543, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:09:52,837 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  179, train_loss:  12.6313, val_loss:  12.2567, grad_norm: 0.0193, live_grad: 0.0000, reward_err: 0.0105, 0.0189, 0.0019, KL_dist: 0.6849, 0.3298, 0.6861, param: [ 4.7547054   6.73529298  5.84492124 10.51661792], weights: [0.1805878 0.2191122 0.6003   ], train_wt_loss:  37.8939, val_wt_loss: 36.7700, train_grp_loss: [11.45117237 13.77574172 12.96914692], val_grp_loss: [12.61564325 12.91372966 11.23868504], train_hist_grp_loss: [15.94664165 20.78081234 45.97695305], cur_train_grp_loss: [0.08809501 0.11574796 0.25430825], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6861, max_kl_dist_index: 2, max_train_grp_loss:  13.7757, max_train_grp_loss_index: 1, max_val_grp_loss:  12.9137, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2543, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:09:53,874 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  180, train_loss:  12.6314, val_loss:  12.2570, grad_norm: 0.0195, live_grad: 0.0000, reward_err: 0.0105, 0.0189, 0.0019, KL_dist: 0.6851, 0.3299, 0.6863, param: [ 4.75320761  6.73421716  5.84557624 10.52041856], weights: [0.17982408 0.21842723 0.6017487 ], train_wt_loss:  37.8942, val_wt_loss: 36.7711, train_grp_loss: [11.44997889 13.7774964  12.96856878], val_grp_loss: [12.61463078 12.91621148 11.23825629], train_hist_grp_loss: [16.03472759 20.89657487 46.23125005], cur_train_grp_loss: [0.08808594 0.11576254 0.254297  ], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6863, max_kl_dist_index: 2, max_train_grp_loss:  13.7775, max_train_grp_loss_index: 1, max_val_grp_loss:  12.9162, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2543, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:09:54,889 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  181, train_loss:  12.6315, val_loss:  12.2574, grad_norm: 0.0196, live_grad: 0.0000, reward_err: 0.0105, 0.0189, 0.0019, KL_dist: 0.6852, 0.3300, 0.6864, param: [ 4.75170141  6.73314245  5.84622714 10.5242465 ], weights: [0.17906197 0.21774264 0.60319539], train_wt_loss:  37.8944, val_wt_loss: 36.7721, train_grp_loss: [11.44877154 13.77927124 12.96798634], val_grp_loss: [12.61360534 12.91871846 11.23782233], train_hist_grp_loss: [16.12280435 21.01235215 46.48553571], cur_train_grp_loss: [0.08807676 0.11577728 0.25428566], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6864, max_kl_dist_index: 2, max_train_grp_loss:  13.7793, max_train_grp_loss_index: 1, max_val_grp_loss:  12.9187, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2543, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:09:55,911 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  182, train_loss:  12.6316, val_loss:  12.2577, grad_norm: 0.0198, live_grad: 0.0000, reward_err: 0.0104, 0.0189, 0.0020, KL_dist: 0.6854, 0.3301, 0.6866, param: [ 4.75018679  6.73206883  5.84687393 10.52810178], weights: [0.17830148 0.21705846 0.60464006], train_wt_loss:  37.8947, val_wt_loss: 36.7732, train_grp_loss: [11.44755032 13.78106626 12.96739962], val_grp_loss: [12.61256693 12.92125063 11.23738318], train_hist_grp_loss: [16.21087183 21.12814435 46.73980996], cur_train_grp_loss: [0.08806747 0.1157922  0.25427424], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6866, max_kl_dist_index: 2, max_train_grp_loss:  13.7811, max_train_grp_loss_index: 1, max_val_grp_loss:  12.9213, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2543, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:09:56,932 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  183, train_loss:  12.6316, val_loss:  12.2581, grad_norm: 0.0200, live_grad: 0.0000, reward_err: 0.0104, 0.0189, 0.0020, KL_dist: 0.6855, 0.3302, 0.6868, param: [ 4.74866375  6.73099623  5.84751658 10.53198442], weights: [0.17754262 0.21637469 0.60608269], train_wt_loss:  37.8949, val_wt_loss: 36.7743, train_grp_loss: [11.44631524 13.78288149 12.96680862], val_grp_loss: [12.61151556 12.92380805 11.23693886], train_hist_grp_loss: [16.29892991 21.24395163 46.99407269], cur_train_grp_loss: [0.08805808 0.11580728 0.25426274], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6868, max_kl_dist_index: 2, max_train_grp_loss:  13.7829, max_train_grp_loss_index: 1, max_val_grp_loss:  12.9238, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2543, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:09:57,965 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  184, train_loss:  12.6317, val_loss:  12.2584, grad_norm: 0.0202, live_grad: 0.0000, reward_err: 0.0104, 0.0189, 0.0020, KL_dist: 0.6856, 0.3303, 0.6870, param: [ 4.74713227  6.72992461  5.84815509 10.53589444], weights: [0.17678541 0.21569135 0.60752324], train_wt_loss:  37.8952, val_wt_loss: 36.7753, train_grp_loss: [11.44506632 13.78471696 12.96621334], val_grp_loss: [12.61045125 12.92639075 11.2364894 ], train_hist_grp_loss: [16.38697849 21.35977416 47.24832384], cur_train_grp_loss: [0.08804858 0.11582253 0.25425115], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6870, max_kl_dist_index: 2, max_train_grp_loss:  13.7847, max_train_grp_loss_index: 1, max_val_grp_loss:  12.9264, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2543, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:09:58,980 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  185, train_loss:  12.6318, val_loss:  12.2588, grad_norm: 0.0203, live_grad: 0.0000, reward_err: 0.0104, 0.0189, 0.0020, KL_dist: 0.6858, 0.3304, 0.6872, param: [ 4.74559235  6.72885393  5.84878943 10.53983186], weights: [0.17602984 0.21500845 0.6089617 ], train_wt_loss:  37.8954, val_wt_loss: 36.7764, train_grp_loss: [11.44380358 13.78657272 12.96561379], val_grp_loss: [12.609374   12.92899877 11.23603481], train_hist_grp_loss: [16.47501746 21.47561212 47.50256332], cur_train_grp_loss: [0.08803897 0.11583796 0.25423948], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6872, max_kl_dist_index: 2, max_train_grp_loss:  13.7866, max_train_grp_loss_index: 1, max_val_grp_loss:  12.9290, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2542, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:09:59,991 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  186, train_loss:  12.6319, val_loss:  12.2592, grad_norm: 0.0205, live_grad: 0.0000, reward_err: 0.0103, 0.0189, 0.0021, KL_dist: 0.6859, 0.3305, 0.6874, param: [ 4.74404399  6.72778414  5.8494196  10.54379671], weights: [0.17527594 0.21432601 0.61039805], train_wt_loss:  37.8957, val_wt_loss: 36.7775, train_grp_loss: [11.44252702 13.78844878 12.96500998], val_grp_loss: [12.60828383 12.93163217 11.23557512], train_hist_grp_loss: [16.56304672 21.59146567 47.75679104], cur_train_grp_loss: [0.08802926 0.11585355 0.25422772], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6874, max_kl_dist_index: 2, max_train_grp_loss:  13.7884, max_train_grp_loss_index: 1, max_val_grp_loss:  12.9316, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2542, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:10:00,999 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  187, train_loss:  12.6320, val_loss:  12.2595, grad_norm: 0.0207, live_grad: 0.0000, reward_err: 0.0103, 0.0189, 0.0021, KL_dist: 0.6861, 0.3306, 0.6876, param: [ 4.74248717  6.72671519  5.85004558 10.547789  ], weights: [0.1745237  0.21364404 0.61183226], train_wt_loss:  37.8960, val_wt_loss: 36.7786, train_grp_loss: [11.44123667 13.79034518 12.96440191], val_grp_loss: [12.60718074 12.93429097 11.23511035], train_hist_grp_loss: [16.65106615 21.70733499 48.01100692], cur_train_grp_loss: [0.08801944 0.11586932 0.25421588], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6876, max_kl_dist_index: 2, max_train_grp_loss:  13.7903, max_train_grp_loss_index: 1, max_val_grp_loss:  12.9343, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2542, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:10:02,041 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  188, train_loss:  12.6321, val_loss:  12.2599, grad_norm: 0.0209, live_grad: 0.0000, reward_err: 0.0103, 0.0189, 0.0021, KL_dist: 0.6862, 0.3307, 0.6878, param: [ 4.74092188  6.72564704  5.85066736 10.55180876], weights: [0.17377313 0.21296256 0.61326431], train_wt_loss:  37.8962, val_wt_loss: 36.7797, train_grp_loss: [11.43993254 13.79226195 12.96378959], val_grp_loss: [12.60606477 12.93697522 11.23464052], train_hist_grp_loss: [16.73907567 21.82322024 48.26521088], cur_train_grp_loss: [0.08800951 0.11588525 0.25420396], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6878, max_kl_dist_index: 2, max_train_grp_loss:  13.7923, max_train_grp_loss_index: 1, max_val_grp_loss:  12.9370, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2542, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:10:03,065 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  189, train_loss:  12.6322, val_loss:  12.2603, grad_norm: 0.0211, live_grad: 0.0000, reward_err: 0.0103, 0.0193, 0.0021, KL_dist: 0.6864, 0.3308, 0.6880, param: [ 4.73934813  6.72457963  5.85128492 10.55585601], weights: [0.17302425 0.21228158 0.61469417], train_wt_loss:  37.8965, val_wt_loss: 36.7808, train_grp_loss: [11.43861465 13.79419912 12.96317302], val_grp_loss: [12.6049359  12.93968497 11.23416566], train_hist_grp_loss: [16.82707515 21.9391216  48.51940283], cur_train_grp_loss: [0.08799948 0.11590136 0.25419195], max_reward_err:  0.0193, max_reward_err_index: 1, max_kl_dist:  0.6880, max_kl_dist_index: 2, max_train_grp_loss:  13.7942, max_train_grp_loss_index: 1, max_val_grp_loss:  12.9397, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2542, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:10:04,123 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  190, train_loss:  12.6323, val_loss:  12.2606, grad_norm: 0.0213, live_grad: 0.0000, reward_err: 0.0103, 0.0193, 0.0021, KL_dist: 0.6865, 0.3309, 0.6882, param: [ 4.73776589  6.72351293  5.85189825 10.55993076], weights: [0.17227706 0.21160112 0.61612183], train_wt_loss:  37.8968, val_wt_loss: 36.7819, train_grp_loss: [11.43728302 13.79615672 12.96255221], val_grp_loss: [12.60379417 12.94242025 11.2336858 ], train_hist_grp_loss: [16.91506449 22.05503924 48.7735827 ], cur_train_grp_loss: [0.08798934 0.11591764 0.25417986], max_reward_err:  0.0193, max_reward_err_index: 1, max_kl_dist:  0.6882, max_kl_dist_index: 2, max_train_grp_loss:  13.7962, max_train_grp_loss_index: 1, max_val_grp_loss:  12.9424, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2542, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:10:05,127 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  191, train_loss:  12.6324, val_loss:  12.2610, grad_norm: 0.0215, live_grad: 0.0000, reward_err: 0.0103, 0.0193, 0.0021, KL_dist: 0.6867, 0.3310, 0.6884, param: [ 4.73617518  6.72244688  5.85250734 10.56403303], weights: [0.17153157 0.21092118 0.61754725], train_wt_loss:  37.8971, val_wt_loss: 36.7831, train_grp_loss: [11.43593766 13.79813477 12.96192717], val_grp_loss: [12.60263958 12.94518111 11.23320094], train_hist_grp_loss: [17.00304359 22.17097333 49.02775039], cur_train_grp_loss: [0.0879791  0.11593409 0.25416769], max_reward_err:  0.0193, max_reward_err_index: 1, max_kl_dist:  0.6884, max_kl_dist_index: 2, max_train_grp_loss:  13.7981, max_train_grp_loss_index: 1, max_val_grp_loss:  12.9452, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2542, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:10:06,138 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  192, train_loss:  12.6325, val_loss:  12.2614, grad_norm: 0.0217, live_grad: 0.0000, reward_err: 0.0103, 0.0194, 0.0021, KL_dist: 0.6868, 0.3311, 0.6886, param: [ 4.73457597  6.72138144  5.85311217 10.56816284], weights: [0.17078778 0.21024179 0.61897043], train_wt_loss:  37.8974, val_wt_loss: 36.7842, train_grp_loss: [11.43457859 13.80013332 12.9612979 ], val_grp_loss: [12.60147215 12.94796758 11.23271113], train_hist_grp_loss: [17.09101234 22.28692405 49.28190582], cur_train_grp_loss: [0.08796875 0.11595071 0.25415543], max_reward_err:  0.0194, max_reward_err_index: 1, max_kl_dist:  0.6886, max_kl_dist_index: 2, max_train_grp_loss:  13.8001, max_train_grp_loss_index: 1, max_val_grp_loss:  12.9480, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2542, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:10:07,133 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  193, train_loss:  12.6326, val_loss:  12.2618, grad_norm: 0.0219, live_grad: 0.0000, reward_err: 0.0103, 0.0194, 0.0021, KL_dist: 0.6870, 0.3312, 0.6888, param: [ 4.73296827  6.72031655  5.85371272 10.57232021], weights: [0.17004572 0.20956295 0.62039133], train_wt_loss:  37.8977, val_wt_loss: 36.7854, train_grp_loss: [11.43320583 13.80215239 12.96066441], val_grp_loss: [12.60029189 12.95077971 11.23221638], train_hist_grp_loss: [17.17897064 22.40289155 49.53604892], cur_train_grp_loss: [0.0879583  0.11596751 0.2541431 ], max_reward_err:  0.0194, max_reward_err_index: 1, max_kl_dist:  0.6888, max_kl_dist_index: 2, max_train_grp_loss:  13.8022, max_train_grp_loss_index: 1, max_val_grp_loss:  12.9508, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2541, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:10:08,175 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  194, train_loss:  12.6327, val_loss:  12.2622, grad_norm: 0.0221, live_grad: 0.0000, reward_err: 0.0103, 0.0194, 0.0021, KL_dist: 0.6871, 0.3313, 0.6890, param: [ 4.73135207  6.71925217  5.85430899 10.57650516], weights: [0.16930538 0.20888468 0.62180994], train_wt_loss:  37.8980, val_wt_loss: 36.7865, train_grp_loss: [11.43181941 13.804192   12.9600267 ], val_grp_loss: [12.59909882 12.95361753 11.23171672], train_hist_grp_loss: [17.26691838 22.51887603 49.79017959], cur_train_grp_loss: [0.08794774 0.11598447 0.25413067], max_reward_err:  0.0194, max_reward_err_index: 1, max_kl_dist:  0.6890, max_kl_dist_index: 2, max_train_grp_loss:  13.8042, max_train_grp_loss_index: 1, max_val_grp_loss:  12.9536, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2541, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:10:09,227 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  195, train_loss:  12.6328, val_loss:  12.2626, grad_norm: 0.0223, live_grad: 0.0000, reward_err: 0.0103, 0.0194, 0.0021, KL_dist: 0.6873, 0.3314, 0.6892, param: [ 4.72972736  6.71818826  5.85490095 10.58071769], weights: [0.16856676 0.208207   0.62322623], train_wt_loss:  37.8983, val_wt_loss: 36.7877, train_grp_loss: [11.43041933 13.80625219 12.95938479], val_grp_loss: [12.59789296 12.95648109 11.23121217], train_hist_grp_loss: [17.35485545 22.63487764 50.04429776], cur_train_grp_loss: [0.08793707 0.11600161 0.25411817], max_reward_err:  0.0194, max_reward_err_index: 1, max_kl_dist:  0.6892, max_kl_dist_index: 2, max_train_grp_loss:  13.8063, max_train_grp_loss_index: 1, max_val_grp_loss:  12.9565, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2541, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:10:10,276 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  196, train_loss:  12.6329, val_loss:  12.2629, grad_norm: 0.0225, live_grad: 0.0000, reward_err: 0.0103, 0.0194, 0.0021, KL_dist: 0.6874, 0.3315, 0.6894, param: [ 4.72809413  6.71712476  5.85548861 10.58495783], weights: [0.16782989 0.20752992 0.62464019], train_wt_loss:  37.8986, val_wt_loss: 36.7888, train_grp_loss: [11.42900563 13.80833299 12.95873868], val_grp_loss: [12.59667432 12.95937042 11.23070276], train_hist_grp_loss: [17.44278175 22.75089657 50.29840335], cur_train_grp_loss: [0.0879263  0.11601893 0.25410558], max_reward_err:  0.0194, max_reward_err_index: 1, max_kl_dist:  0.6894, max_kl_dist_index: 2, max_train_grp_loss:  13.8083, max_train_grp_loss_index: 1, max_val_grp_loss:  12.9594, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2541, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:10:11,313 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  197, train_loss:  12.6330, val_loss:  12.2633, grad_norm: 0.0227, live_grad: 0.0000, reward_err: 0.0103, 0.0194, 0.0021, KL_dist: 0.6876, 0.3316, 0.6896, param: [ 4.72645239  6.71606162  5.85607193 10.58922559], weights: [0.16709477 0.20685345 0.62605178], train_wt_loss:  37.8989, val_wt_loss: 36.7900, train_grp_loss: [11.42757832 13.81043442 12.95808839], val_grp_loss: [12.59544292 12.96228556 11.23018852], train_hist_grp_loss: [17.53069718 22.86693298 50.55249626], cur_train_grp_loss: [0.08791543 0.11603641 0.25409292], max_reward_err:  0.0194, max_reward_err_index: 1, max_kl_dist:  0.6896, max_kl_dist_index: 2, max_train_grp_loss:  13.8104, max_train_grp_loss_index: 1, max_val_grp_loss:  12.9623, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2541, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:10:12,306 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  198, train_loss:  12.6331, val_loss:  12.2637, grad_norm: 0.0229, live_grad: 0.0000, reward_err: 0.0103, 0.0194, 0.0021, KL_dist: 0.6877, 0.3317, 0.6899, param: [ 4.72480212  6.7149988   5.85665092 10.59352098], weights: [0.1663614 0.2061776 0.627461 ], train_wt_loss:  37.8992, val_wt_loss: 36.7912, train_grp_loss: [11.42613742 13.81255652 12.9574339 ], val_grp_loss: [12.59419877 12.96522655 11.22966947], train_hist_grp_loss: [17.61860163 22.98298705 50.80657643], cur_train_grp_loss: [0.08790445 0.11605407 0.25408016], max_reward_err:  0.0194, max_reward_err_index: 1, max_kl_dist:  0.6899, max_kl_dist_index: 2, max_train_grp_loss:  13.8126, max_train_grp_loss_index: 1, max_val_grp_loss:  12.9652, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2541, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:10:13,317 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  199, train_loss:  12.6332, val_loss:  12.2641, grad_norm: 0.0231, live_grad: 0.0000, reward_err: 0.0103, 0.0194, 0.0021, KL_dist: 0.6879, 0.3319, 0.6901, param: [ 4.72314332  6.71393624  5.85722555 10.59784402], weights: [0.16562979 0.20550239 0.62886781], train_wt_loss:  37.8995, val_wt_loss: 36.7924, train_grp_loss: [11.42468296 13.81469931 12.95677524], val_grp_loss: [12.59294191 12.96819344 11.22914564], train_hist_grp_loss: [17.70649499 23.09905895 51.06064376], cur_train_grp_loss: [0.08789336 0.1160719  0.25406733], max_reward_err:  0.0194, max_reward_err_index: 1, max_kl_dist:  0.6901, max_kl_dist_index: 2, max_train_grp_loss:  13.8147, max_train_grp_loss_index: 1, max_val_grp_loss:  12.9682, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2541, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:10:14,276 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1654] - INFO: Iteration:  199, train_loss:  12.6332, val_loss:  12.2641, grad_norm: 0.0231,  live_grad: 0.0000, reward_err: 0.0103, 0.0194, 0.0021, KL_dist: 0.6879, 0.3319, 0.6901, param: [ 4.72314332  6.71393624  5.85722555 10.59784402], weights: [0.16562979 0.20550239 0.62886781], train_wt_loss:  37.8995, val_wt_loss: 36.7924, train_grp_loss: [11.42468296 13.81469931 12.95677524], val_grp_loss: [12.59294191 12.96819344 11.22914564], train_hist_grp_loss: [17.70649499 23.09905895 51.06064376], cur_train_grp_loss: [0.08789336 0.1160719  0.25406733], max_reward_err:  0.0194, max_reward_err_index: 1, max_kl_dist:  0.6901, max_kl_dist_index: 2, max_train_grp_loss:  13.8147, max_train_grp_loss_index: 1, max_val_grp_loss:  12.9682, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2541, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:10:14,504 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:388] - INFO: Policy parameter learned solely on the preference data rdpo: [ 4.72314332  6.71393624  5.85722555 10.59784402].
2024-10-07 01:10:14,857 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Uniform reward: 3.8511, 3.8511, 3.1970
2024-10-07 01:10:14,857 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Optimal reward: 3.8856, 7.2460, 3.3201
2024-10-07 01:10:14,858 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Policy reward: 3.8457, 7.1053, 3.3131
2024-10-07 01:10:14,858 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:402] - INFO: Reward Error: 0.0103, 0.0194, 0.0021
2024-10-07 01:10:15,560 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:417] - INFO: Optimal reward: 3.8856, 7.2460, 3.3201
Known param reward: [[3.885563232421875, 6.83889453125, 3.291370361328125], [3.493690185546875, 7.24602734375, 3.1155205078125], [3.850873046875, 7.10487548828125, 3.320061279296875]], Known param reward error: [[0.0, 0.05618703783269167, 0.008641683256769945], [0.10085360176489651, 0.0, 0.06160752898142066], [0.008927968346368324, 0.019479895503085456, 0.0]].
