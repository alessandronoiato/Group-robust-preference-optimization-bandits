2024-10-07 01:39:12,886 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log-hyperparam-search/2024_10_07_00_27_03/rdpo,0.2,0.1,0.03,2023
2024-10-07 01:39:12,888 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2023
2024-10-07 01:39:12,888 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-10-07 01:39:12,979 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.2729, l2 distance: 29.4548, acc: 0.92.
2024-10-07 01:39:12,980 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-10-07 01:39:12,981 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [ 6.99981245 12.85202501  8.22225193 12.39503134]
2024-10-07 01:39:13,196 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.8503, 7.1054, 3.3198
2024-10-07 01:39:13,426 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1314] - INFO: unique_group_ids: {0, 1, 2}
2024-10-07 01:39:14,692 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  0, train_loss:  12.6261, val_loss:  12.2165, grad_norm: 0.4066, live_grad: 0.0000, reward_err: 0.0095, 0.0189, 0.0009, KL_dist: 0.6768, 0.3238, 0.6776, param: [ 4.89977817  6.97905177  5.6749584  10.23406352], weights: [0.33255593 0.33266631 0.33477776], train_wt_loss:  37.8784, val_wt_loss: 36.6496, train_grp_loss: [11.4469374  13.75171834 13.00553536], val_grp_loss: [12.59509381 12.82781215 11.22483468], train_hist_grp_loss: [0.1342519  0.14531453 0.3562142 ], cur_train_grp_loss: [0.1342519  0.14531453 0.3562142 ], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6776, max_kl_dist_index: 2, max_train_grp_loss:  13.7517, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8278, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.3562, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:39:15,795 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  1, train_loss:  12.6261, val_loss:  12.2166, grad_norm: 0.0001, live_grad: 0.0000, reward_err: 0.0095, 0.0189, 0.0009, KL_dist: 0.6768, 0.3238, 0.6776, param: [ 4.89962624  6.9777323   5.67584095 10.23380585], weights: [0.33190683 0.3322911  0.33580206], train_wt_loss:  37.8784, val_wt_loss: 36.6499, train_grp_loss: [11.44778361 13.75075199 13.00563393], val_grp_loss: [12.59594072 12.82687088 11.22525123], train_hist_grp_loss: [0.22230527 0.26087519 0.61122469], cur_train_grp_loss: [0.08805336 0.11556066 0.2550105 ], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6776, max_kl_dist_index: 2, max_train_grp_loss:  13.7508, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8269, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:39:16,873 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  2, train_loss:  12.6261, val_loss:  12.2167, grad_norm: 0.0001, live_grad: 0.0000, reward_err: 0.0095, 0.0189, 0.0009, KL_dist: 0.6768, 0.3238, 0.6775, param: [ 4.89947098  6.9764157   5.67672236 10.23355827], weights: [0.33125747 0.33191464 0.33682789], train_wt_loss:  37.8784, val_wt_loss: 36.6502, train_grp_loss: [11.44862384 13.7497935  13.00573076], val_grp_loss: [12.59678219 12.82593903 11.22566523], train_hist_grp_loss: [0.31036514 0.37642773 0.86623712], cur_train_grp_loss: [0.08805987 0.11555254 0.25501243], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6775, max_kl_dist_index: 2, max_train_grp_loss:  13.7498, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8259, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:39:17,947 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  3, train_loss:  12.6261, val_loss:  12.2168, grad_norm: 0.0001, live_grad: 0.0000, reward_err: 0.0095, 0.0189, 0.0009, KL_dist: 0.6767, 0.3238, 0.6775, param: [ 4.8993124   6.97510196  5.6776026  10.23332079], weights: [0.33060785 0.33153691 0.33785524], train_wt_loss:  37.8784, val_wt_loss: 36.6505, train_grp_loss: [11.44945807 13.74884289 13.00582585], val_grp_loss: [12.59761819 12.82501662 11.22607666], train_hist_grp_loss: [0.39843148 0.49197221 1.12125145], cur_train_grp_loss: [0.08806634 0.11554448 0.25501433], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6775, max_kl_dist_index: 2, max_train_grp_loss:  13.7488, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8250, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:39:19,068 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  4, train_loss:  12.6261, val_loss:  12.2170, grad_norm: 0.0002, live_grad: 0.0000, reward_err: 0.0095, 0.0189, 0.0009, KL_dist: 0.6767, 0.3238, 0.6774, param: [ 4.89915049  6.97379109  5.67848169 10.23309345], weights: [0.32995796 0.33115793 0.3388841 ], train_wt_loss:  37.8784, val_wt_loss: 36.6509, train_grp_loss: [11.4502863  13.74790016 13.00591919], val_grp_loss: [12.59844872 12.82410368 11.22648553], train_hist_grp_loss: [0.48650423 0.6075087  1.37626765], cur_train_grp_loss: [0.08807275 0.11553649 0.25501619], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6774, max_kl_dist_index: 2, max_train_grp_loss:  13.7479, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8241, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:39:20,156 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  5, train_loss:  12.6261, val_loss:  12.2171, grad_norm: 0.0003, live_grad: 0.0000, reward_err: 0.0095, 0.0189, 0.0009, KL_dist: 0.6767, 0.3237, 0.6773, param: [ 4.89898523  6.97248309  5.67935963 10.23287626], weights: [0.32930783 0.33077771 0.33991447], train_wt_loss:  37.8784, val_wt_loss: 36.6512, train_grp_loss: [11.45110851 13.74696532 13.00601078], val_grp_loss: [12.59927376 12.8232002  11.22689181], train_hist_grp_loss: [0.57458336 0.72303728 1.63128567], cur_train_grp_loss: [0.08807913 0.11552857 0.25501802], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6773, max_kl_dist_index: 2, max_train_grp_loss:  13.7470, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8232, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:39:21,234 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  6, train_loss:  12.6261, val_loss:  12.2172, grad_norm: 0.0003, live_grad: 0.0000, reward_err: 0.0095, 0.0189, 0.0009, KL_dist: 0.6766, 0.3237, 0.6773, param: [ 4.89881664  6.97117795  5.6802364  10.23266926], weights: [0.32865743 0.33039624 0.34094633], train_wt_loss:  37.8784, val_wt_loss: 36.6515, train_grp_loss: [11.45192468 13.74603839 13.00610061], val_grp_loss: [12.6000933  12.82230622 11.22729551], train_hist_grp_loss: [0.66266881 0.83855799 1.88630549], cur_train_grp_loss: [0.08808545 0.11552072 0.25501982], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6773, max_kl_dist_index: 2, max_train_grp_loss:  13.7460, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8223, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:39:22,258 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  7, train_loss:  12.6261, val_loss:  12.2173, grad_norm: 0.0004, live_grad: 0.0000, reward_err: 0.0095, 0.0189, 0.0009, KL_dist: 0.6766, 0.3237, 0.6772, param: [ 4.89864469  6.96987568  5.68111201 10.23247246], weights: [0.3280068  0.33001352 0.34197968], train_wt_loss:  37.8784, val_wt_loss: 36.6518, train_grp_loss: [11.4527348  13.74511938 13.00618867], val_grp_loss: [12.60090732 12.82142175 11.22769662], train_hist_grp_loss: [0.75076053 0.95407092 2.14132707], cur_train_grp_loss: [0.08809173 0.11551293 0.25502158], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6772, max_kl_dist_index: 2, max_train_grp_loss:  13.7451, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8214, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:39:23,317 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  8, train_loss:  12.6261, val_loss:  12.2174, grad_norm: 0.0004, live_grad: 0.0000, reward_err: 0.0095, 0.0189, 0.0009, KL_dist: 0.6766, 0.3237, 0.6772, param: [ 4.89846938  6.96857627  5.68198645 10.2322859 ], weights: [0.32735591 0.32962958 0.34301451], train_wt_loss:  37.8784, val_wt_loss: 36.6522, train_grp_loss: [11.45353885 13.7442083  13.00627496], val_grp_loss: [12.60171582 12.8205468  11.22809512], train_hist_grp_loss: [0.83885849 1.06957613 2.39635038], cur_train_grp_loss: [0.08809796 0.1155052  0.25502331], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6772, max_kl_dist_index: 2, max_train_grp_loss:  13.7442, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8205, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:39:24,322 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  9, train_loss:  12.6261, val_loss:  12.2175, grad_norm: 0.0005, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6766, 0.3237, 0.6771, param: [ 4.89829072  6.96727972  5.68285973 10.23210959], weights: [0.32670479 0.32924439 0.34405082], train_wt_loss:  37.8784, val_wt_loss: 36.6525, train_grp_loss: [11.45433682 13.74330517 13.00635947], val_grp_loss: [12.60251877 12.81968139 11.22849101], train_hist_grp_loss: [0.92696264 1.18507368 2.65137538], cur_train_grp_loss: [0.08810414 0.11549755 0.255025  ], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6771, max_kl_dist_index: 2, max_train_grp_loss:  13.7433, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8197, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:39:25,336 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  10, train_loss:  12.6261, val_loss:  12.2176, grad_norm: 0.0006, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6765, 0.3237, 0.6771, param: [ 4.89810868  6.96598603  5.68373184 10.23194358], weights: [0.32605343 0.32885798 0.34508858], train_wt_loss:  37.8784, val_wt_loss: 36.6528, train_grp_loss: [11.4551287  13.74240998 13.0064422 ], val_grp_loss: [12.60331617 12.81882554 11.22888428], train_hist_grp_loss: [1.01507292 1.30056364 2.90640203], cur_train_grp_loss: [0.08811028 0.11548996 0.25502666], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6771, max_kl_dist_index: 2, max_train_grp_loss:  13.7424, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8188, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:39:26,353 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  11, train_loss:  12.6261, val_loss:  12.2177, grad_norm: 0.0006, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6765, 0.3237, 0.6770, param: [ 4.89792328  6.96469521  5.68460277 10.23178787], weights: [0.32540184 0.32847035 0.34612781], train_wt_loss:  37.8784, val_wt_loss: 36.6532, train_grp_loss: [11.45591447 13.74152277 13.00652315], val_grp_loss: [12.604108   12.81797926 11.22927492], train_hist_grp_loss: [1.1031893  1.41604607 3.16143031], cur_train_grp_loss: [0.08811637 0.11548244 0.25502828], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6770, max_kl_dist_index: 2, max_train_grp_loss:  13.7415, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8180, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:39:27,386 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  12, train_loss:  12.6261, val_loss:  12.2178, grad_norm: 0.0007, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6765, 0.3236, 0.6770, param: [ 4.89773449  6.96340724  5.68547253 10.23164249], weights: [0.32475003 0.32808149 0.34716848], train_wt_loss:  37.8784, val_wt_loss: 36.6535, train_grp_loss: [11.45669412 13.74064353 13.0066023 ], val_grp_loss: [12.60489425 12.81714257 11.22966293], train_hist_grp_loss: [1.19131172 1.53152105 3.41646018], cur_train_grp_loss: [0.08812242 0.11547498 0.25502987], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6770, max_kl_dist_index: 2, max_train_grp_loss:  13.7406, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8171, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:39:28,431 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  13, train_loss:  12.6261, val_loss:  12.2179, grad_norm: 0.0007, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6765, 0.3236, 0.6769, param: [ 4.89754232  6.96212213  5.68634112 10.23150747], weights: [0.32409799 0.32769142 0.34821059], train_wt_loss:  37.8784, val_wt_loss: 36.6538, train_grp_loss: [11.45746764 13.73977229 13.00667965], val_grp_loss: [12.60567491 12.81631549 11.2300483 ], train_hist_grp_loss: [1.27944013 1.64698865 3.67149159], cur_train_grp_loss: [0.08812842 0.11546759 0.25503142], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6769, max_kl_dist_index: 2, max_train_grp_loss:  13.7398, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8163, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:39:29,460 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  14, train_loss:  12.6262, val_loss:  12.2181, grad_norm: 0.0008, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6764, 0.3236, 0.6769, param: [ 4.89734675  6.96083987  5.68720853 10.23138285], weights: [0.32344573 0.32730013 0.34925414], train_wt_loss:  37.8785, val_wt_loss: 36.6542, train_grp_loss: [11.458235   13.73890905 13.0067552 ], val_grp_loss: [12.60644996 12.81549803 11.23043102], train_hist_grp_loss: [1.3675745  1.76244892 3.92652453], cur_train_grp_loss: [0.08813437 0.11546027 0.25503293], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6769, max_kl_dist_index: 2, max_train_grp_loss:  13.7389, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8155, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:39:30,504 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  15, train_loss:  12.6262, val_loss:  12.2182, grad_norm: 0.0009, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6764, 0.3236, 0.6768, param: [ 4.89714779  6.95956047  5.68807475 10.23126863], weights: [0.32279326 0.32690763 0.35029911], train_wt_loss:  37.8785, val_wt_loss: 36.6545, train_grp_loss: [11.4589962  13.73805382 13.00682894], val_grp_loss: [12.60721938 12.81469021 11.23081107], train_hist_grp_loss: [1.45571477 1.87790193 4.18155894], cur_train_grp_loss: [0.08814027 0.11545302 0.25503442], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6768, max_kl_dist_index: 2, max_train_grp_loss:  13.7381, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8147, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:39:31,529 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  16, train_loss:  12.6262, val_loss:  12.2183, grad_norm: 0.0009, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6764, 0.3236, 0.6768, param: [ 4.89694543  6.95828393  5.68893979 10.23116484], weights: [0.32214058 0.32651393 0.35134549], train_wt_loss:  37.8785, val_wt_loss: 36.6549, train_grp_loss: [11.45975122 13.73720662 13.00690086], val_grp_loss: [12.60798317 12.81389204 11.23118846], train_hist_grp_loss: [1.54386089 1.99334776 4.4365948 ], cur_train_grp_loss: [0.08814612 0.11544583 0.25503586], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6768, max_kl_dist_index: 2, max_train_grp_loss:  13.7372, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8139, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:39:32,550 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  17, train_loss:  12.6262, val_loss:  12.2184, grad_norm: 0.0010, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6764, 0.3236, 0.6767, param: [ 4.89673965  6.95701023  5.68980365 10.23107152], weights: [0.32148769 0.32611903 0.35239328], train_wt_loss:  37.8785, val_wt_loss: 36.6552, train_grp_loss: [11.46050005 13.73636746 13.00697096], val_grp_loss: [12.60874131 12.81310355 11.23156318], train_hist_grp_loss: [1.63201283 2.10878648 4.69163208], cur_train_grp_loss: [0.08815193 0.11543871 0.25503727], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6767, max_kl_dist_index: 2, max_train_grp_loss:  13.7364, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8131, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:39:33,571 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  18, train_loss:  12.6262, val_loss:  12.2185, grad_norm: 0.0011, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6764, 0.3236, 0.6767, param: [ 4.89653046  6.95573939  5.69066632 10.23098869], weights: [0.3208346  0.32572294 0.35344247], train_wt_loss:  37.8785, val_wt_loss: 36.6555, train_grp_loss: [11.46124268 13.73553635 13.00703924], val_grp_loss: [12.60949379 12.81232475 11.23193521], train_hist_grp_loss: [1.72017052 2.22421814 4.94667072], cur_train_grp_loss: [0.08815769 0.11543166 0.25503865], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6767, max_kl_dist_index: 2, max_train_grp_loss:  13.7355, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8123, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:39:34,636 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  19, train_loss:  12.6262, val_loss:  12.2186, grad_norm: 0.0011, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6763, 0.3236, 0.6766, param: [ 4.89631785  6.95447139  5.69152779 10.23091637], weights: [0.32018131 0.32532565 0.35449304], train_wt_loss:  37.8785, val_wt_loss: 36.6559, train_grp_loss: [11.46197908 13.73471331 13.00710569], val_grp_loss: [12.6102406  12.81155566 11.23230456], train_hist_grp_loss: [1.80833392 2.33964281 5.20171071], cur_train_grp_loss: [0.08816341 0.11542468 0.25503999], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6766, max_kl_dist_index: 2, max_train_grp_loss:  13.7347, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8116, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:39:35,681 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  20, train_loss:  12.6262, val_loss:  12.2187, grad_norm: 0.0012, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6763, 0.3235, 0.6766, param: [ 4.89610181  6.95320624  5.69238808 10.23085459], weights: [0.31952782 0.32492718 0.355545  ], train_wt_loss:  37.8785, val_wt_loss: 36.6562, train_grp_loss: [11.46270925 13.73389834 13.0071703 ], val_grp_loss: [12.61098171 12.8107963  11.2326712 ], train_hist_grp_loss: [1.89650299 2.45506057 5.456752  ], cur_train_grp_loss: [0.08816907 0.11541776 0.25504129], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6766, max_kl_dist_index: 2, max_train_grp_loss:  13.7339, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8108, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:39:36,683 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  21, train_loss:  12.6262, val_loss:  12.2189, grad_norm: 0.0013, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6763, 0.3235, 0.6765, param: [ 4.89588234  6.95194394  5.69324717 10.23080337], weights: [0.31887415 0.32452752 0.35659833], train_wt_loss:  37.8785, val_wt_loss: 36.6566, train_grp_loss: [11.46343317 13.73309146 13.00723307], val_grp_loss: [12.61171713 12.81004667 11.23303514], train_hist_grp_loss: [1.98467768 2.57047148 5.71179455], cur_train_grp_loss: [0.08817469 0.11541091 0.25504255], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6765, max_kl_dist_index: 2, max_train_grp_loss:  13.7331, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8100, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:39:37,718 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  22, train_loss:  12.6262, val_loss:  12.2190, grad_norm: 0.0013, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6763, 0.3235, 0.6765, param: [ 4.89565943  6.95068448  5.69410506 10.23076275], weights: [0.3182203  0.32412668 0.35765302], train_wt_loss:  37.8785, val_wt_loss: 36.6569, train_grp_loss: [11.46415083 13.73229269 13.00729399], val_grp_loss: [12.61244683 12.8093068  11.23339637], train_hist_grp_loss: [2.07285793 2.68587561 5.96683834], cur_train_grp_loss: [0.08818026 0.11540413 0.25504379], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6765, max_kl_dist_index: 2, max_train_grp_loss:  13.7323, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8093, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:39:38,749 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  23, train_loss:  12.6262, val_loss:  12.2191, grad_norm: 0.0014, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6763, 0.3235, 0.6764, param: [ 4.89543307  6.94942786  5.69496174 10.23073274], weights: [0.31756626 0.32372467 0.35870907], train_wt_loss:  37.8786, val_wt_loss: 36.6573, train_grp_loss: [11.46486222 13.73150202 13.00735306], val_grp_loss: [12.6131708  12.80857671 11.23375488], train_hist_grp_loss: [2.16104371 2.80127303 6.22188332], cur_train_grp_loss: [0.08818578 0.11539742 0.25504498], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6764, max_kl_dist_index: 2, max_train_grp_loss:  13.7315, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8086, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:39:39,754 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  24, train_loss:  12.6262, val_loss:  12.2192, grad_norm: 0.0014, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6762, 0.3235, 0.6764, param: [ 4.89520326  6.94817409  5.69581723 10.23071337], weights: [0.31691205 0.32332149 0.35976647], train_wt_loss:  37.8786, val_wt_loss: 36.6576, train_grp_loss: [11.46556731 13.73071949 13.00741027], val_grp_loss: [12.61388903 12.80785641 11.23411065], train_hist_grp_loss: [2.24923496 2.9166638  6.47692945], cur_train_grp_loss: [0.08819125 0.11539077 0.25504614], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6764, max_kl_dist_index: 2, max_train_grp_loss:  13.7307, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8079, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:39:40,795 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  25, train_loss:  12.6262, val_loss:  12.2193, grad_norm: 0.0015, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6762, 0.3235, 0.6764, param: [ 4.89496999  6.94692315  5.69667151 10.23070466], weights: [0.31625766 0.32291714 0.3608252 ], train_wt_loss:  37.8786, val_wt_loss: 36.6580, train_grp_loss: [11.4662661  13.7299451  13.00746562], val_grp_loss: [12.61460151 12.80714592 11.2344637 ], train_hist_grp_loss: [2.33743163 3.032048   6.73197672], cur_train_grp_loss: [0.08819667 0.1153842  0.25504726], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6764, max_kl_dist_index: 2, max_train_grp_loss:  13.7299, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8071, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:39:41,792 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  26, train_loss:  12.6262, val_loss:  12.2194, grad_norm: 0.0016, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6762, 0.3235, 0.6763, param: [ 4.89473326  6.94567505  5.69752458 10.23070665], weights: [0.31560311 0.32251163 0.36188526], train_wt_loss:  37.8786, val_wt_loss: 36.6583, train_grp_loss: [11.46695857 13.72917885 13.0075191 ], val_grp_loss: [12.61530822 12.80644526 11.23481399], train_hist_grp_loss: [2.42563368 3.14742569 6.98702506], cur_train_grp_loss: [0.08820205 0.11537769 0.25504835], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6763, max_kl_dist_index: 2, max_train_grp_loss:  13.7292, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8064, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:39:42,821 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  27, train_loss:  12.6262, val_loss:  12.2196, grad_norm: 0.0016, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6762, 0.3235, 0.6763, param: [ 4.89449306  6.94442978  5.69837644 10.23071936], weights: [0.3149484  0.32210497 0.36294663], train_wt_loss:  37.8786, val_wt_loss: 36.6587, train_grp_loss: [11.46764471 13.72842077 13.0075707 ], val_grp_loss: [12.61600914 12.80575445 11.23516154], train_hist_grp_loss: [2.51384105 3.26279694 7.24207445], cur_train_grp_loss: [0.08820737 0.11537125 0.25504939], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6763, max_kl_dist_index: 2, max_train_grp_loss:  13.7284, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8058, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:39:43,877 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  28, train_loss:  12.6262, val_loss:  12.2197, grad_norm: 0.0017, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6762, 0.3235, 0.6762, param: [ 4.89424938  6.94318734  5.69922708 10.23074281], weights: [0.31429352 0.32169715 0.36400932], train_wt_loss:  37.8786, val_wt_loss: 36.6590, train_grp_loss: [11.46832451 13.72767087 13.00762043], val_grp_loss: [12.61670428 12.80507349 11.23550633], train_hist_grp_loss: [2.6020537  3.37816182 7.49712486], cur_train_grp_loss: [0.08821265 0.11536488 0.25505041], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6762, max_kl_dist_index: 2, max_train_grp_loss:  13.7277, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8051, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:39:44,915 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  29, train_loss:  12.6262, val_loss:  12.2198, grad_norm: 0.0018, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6762, 0.3235, 0.6762, param: [ 4.89400222  6.94194774  5.70007651 10.23077703], weights: [0.3136385  0.32128819 0.36507331], train_wt_loss:  37.8787, val_wt_loss: 36.6594, train_grp_loss: [11.46899794 13.72692916 13.00766827], val_grp_loss: [12.6173936  12.80440242 11.23584835], train_hist_grp_loss: [2.69027158 3.4935204  7.75217624], cur_train_grp_loss: [0.08821788 0.11535858 0.25505138], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6762, max_kl_dist_index: 2, max_train_grp_loss:  13.7269, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8044, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:39:45,935 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  30, train_loss:  12.6262, val_loss:  12.2199, grad_norm: 0.0018, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6761, 0.3235, 0.6762, param: [ 4.89375158  6.94071096  5.70092471 10.23082204], weights: [0.31298332 0.32087808 0.36613859], train_wt_loss:  37.8787, val_wt_loss: 36.6598, train_grp_loss: [11.469665   13.72619565 13.00771422], val_grp_loss: [12.6180771  12.80374124 11.2361876 ], train_hist_grp_loss: [2.77849464 3.60887274 8.00722856], cur_train_grp_loss: [0.08822306 0.11535235 0.25505232], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6762, max_kl_dist_index: 2, max_train_grp_loss:  13.7262, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8037, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:39:46,942 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  31, train_loss:  12.6262, val_loss:  12.2200, grad_norm: 0.0019, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6761, 0.3235, 0.6761, param: [ 4.89349744  6.93947701  5.7017717  10.23087788], weights: [0.312328   0.32046684 0.36720516], train_wt_loss:  37.8787, val_wt_loss: 36.6601, train_grp_loss: [11.47032568 13.72547036 13.00775828], val_grp_loss: [12.61875477 12.80308998 11.23652406], train_hist_grp_loss: [2.86672284 3.72421893 8.26228178], cur_train_grp_loss: [0.08822819 0.11534618 0.25505322], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6761, max_kl_dist_index: 0, max_train_grp_loss:  13.7255, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8031, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:39:47,965 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  32, train_loss:  12.6262, val_loss:  12.2202, grad_norm: 0.0020, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6761, 0.3234, 0.6761, param: [ 4.89323979  6.93824588  5.70261745 10.23094456], weights: [0.31167254 0.32005446 0.36827299], train_wt_loss:  37.8787, val_wt_loss: 36.6605, train_grp_loss: [11.47097995 13.7247533  13.00780043], val_grp_loss: [12.6194266  12.80244865 11.23685774], train_hist_grp_loss: [2.95495611 3.83955901 8.51733586], cur_train_grp_loss: [0.08823327 0.11534009 0.25505408], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6761, max_kl_dist_index: 0, max_train_grp_loss:  13.7248, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8024, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:39:48,984 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  33, train_loss:  12.6262, val_loss:  12.2203, grad_norm: 0.0020, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6761, 0.3234, 0.6760, param: [ 4.89297864  6.93701757  5.70346198 10.23102212], weights: [0.31101695 0.31964096 0.36934209], train_wt_loss:  37.8787, val_wt_loss: 36.6608, train_grp_loss: [11.47162781 13.72404448 13.00784068], val_grp_loss: [12.62009256 12.80181728 11.23718862], train_hist_grp_loss: [3.04319442 3.95489307 8.77239077], cur_train_grp_loss: [0.08823831 0.11533406 0.25505491], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6761, max_kl_dist_index: 0, max_train_grp_loss:  13.7240, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8018, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:39:50,025 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  34, train_loss:  12.6262, val_loss:  12.2204, grad_norm: 0.0021, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6761, 0.3234, 0.6760, param: [ 4.89271398  6.93579209  5.70430528 10.23111057], weights: [0.31036122 0.31922633 0.37041245], train_wt_loss:  37.8787, val_wt_loss: 36.6612, train_grp_loss: [11.47226924 13.72334391 13.00787902], val_grp_loss: [12.62075265 12.80119587 11.2375167 ], train_hist_grp_loss: [3.13143771 4.07022118 9.02744647], cur_train_grp_loss: [0.08824329 0.1153281  0.2550557 ], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6761, max_kl_dist_index: 0, max_train_grp_loss:  13.7233, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8012, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:39:51,064 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  35, train_loss:  12.6263, val_loss:  12.2205, grad_norm: 0.0022, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6761, 0.3234, 0.6760, param: [ 4.8924458   6.93456942  5.70514735 10.23120995], weights: [0.30970537 0.31881058 0.37148405], train_wt_loss:  37.8788, val_wt_loss: 36.6616, train_grp_loss: [11.47290423 13.72265162 13.00791545], val_grp_loss: [12.62140685 12.80058444 11.23784197], train_hist_grp_loss: [3.21968593 4.1855434  9.28250293], cur_train_grp_loss: [0.08824822 0.11532222 0.25505645], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6761, max_kl_dist_index: 0, max_train_grp_loss:  13.7227, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8006, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:39:52,091 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  36, train_loss:  12.6263, val_loss:  12.2206, grad_norm: 0.0022, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6761, 0.3234, 0.6759, param: [ 4.8921741   6.93334956  5.70598817 10.23132027], weights: [0.30904939 0.31839372 0.37255689], train_wt_loss:  37.8788, val_wt_loss: 36.6619, train_grp_loss: [11.47353276 13.7219676  13.00794995], val_grp_loss: [12.62205516 12.79998302 11.23816442], train_hist_grp_loss: [3.30793904 4.3008598  9.53756009], cur_train_grp_loss: [0.08825311 0.1153164  0.25505717], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6761, max_kl_dist_index: 0, max_train_grp_loss:  13.7220, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8000, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:39:53,163 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  37, train_loss:  12.6263, val_loss:  12.2208, grad_norm: 0.0023, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6760, 0.3234, 0.6759, param: [ 4.89189886  6.93213251  5.70682776 10.23144158], weights: [0.3083933  0.31797575 0.37363095], train_wt_loss:  37.8788, val_wt_loss: 36.6623, train_grp_loss: [11.47415483 13.72129188 13.00798252], val_grp_loss: [12.62269755 12.79939162 11.23848404], train_hist_grp_loss: [3.39619699 4.41617045 9.79261793], cur_train_grp_loss: [0.08825794 0.11531065 0.25505784], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6760, max_kl_dist_index: 0, max_train_grp_loss:  13.7213, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7994, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:39:54,180 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  38, train_loss:  12.6263, val_loss:  12.2209, grad_norm: 0.0024, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6760, 0.3234, 0.6759, param: [ 4.89162008  6.93091828  5.7076661  10.23157388], weights: [0.3077371  0.31755667 0.37470623], train_wt_loss:  37.8788, val_wt_loss: 36.6627, train_grp_loss: [11.47477041 13.72062446 13.00801316], val_grp_loss: [12.62333402 12.79881026 11.23880084], train_hist_grp_loss: [ 3.48445972  4.53147542 10.04767641], cur_train_grp_loss: [0.08826273 0.11530497 0.25505848], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6760, max_kl_dist_index: 0, max_train_grp_loss:  13.7206, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7988, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:39:55,189 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  39, train_loss:  12.6263, val_loss:  12.2210, grad_norm: 0.0024, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6760, 0.3234, 0.6758, param: [ 4.89133776  6.92970685  5.7085032  10.23171722], weights: [0.30708078 0.3171365  0.37578272], train_wt_loss:  37.8789, val_wt_loss: 36.6631, train_grp_loss: [11.47537949 13.71996536 13.00804187], val_grp_loss: [12.62396455 12.79823896 11.23911479], train_hist_grp_loss: [ 3.57272718  4.64677479 10.3027355 ], cur_train_grp_loss: [0.08826746 0.11529937 0.25505908], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6760, max_kl_dist_index: 0, max_train_grp_loss:  13.7200, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7982, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:39:56,213 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  40, train_loss:  12.6263, val_loss:  12.2211, grad_norm: 0.0025, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6760, 0.3234, 0.6758, param: [ 4.89105189  6.92849822  5.70933905 10.2318716 ], weights: [0.30642437 0.31671523 0.3768604 ], train_wt_loss:  37.8789, val_wt_loss: 36.6634, train_grp_loss: [11.47598207 13.7193146  13.00806863], val_grp_loss: [12.62458912 12.79767774 11.2394259 ], train_hist_grp_loss: [ 3.66099933  4.76206861 10.55779514], cur_train_grp_loss: [0.08827215 0.11529383 0.25505964], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6760, max_kl_dist_index: 0, max_train_grp_loss:  13.7193, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7977, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:39:57,237 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  41, train_loss:  12.6263, val_loss:  12.2213, grad_norm: 0.0026, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6760, 0.3234, 0.6758, param: [ 4.89076247  6.9272924   5.71017364 10.23203707], weights: [0.30576785 0.31629287 0.37793928], train_wt_loss:  37.8789, val_wt_loss: 36.6638, train_grp_loss: [11.47657811 13.71867218 13.00809345], val_grp_loss: [12.62520773 12.79712661 11.23973415], train_hist_grp_loss: [ 3.74927612  4.87735697 10.81285531], cur_train_grp_loss: [0.08827679 0.11528836 0.25506017], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6760, max_kl_dist_index: 0, max_train_grp_loss:  13.7187, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7971, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:39:58,246 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  42, train_loss:  12.6263, val_loss:  12.2214, grad_norm: 0.0026, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6760, 0.3234, 0.6757, param: [ 4.89046948  6.92608937  5.71100698 10.23221364], weights: [0.30511125 0.31586943 0.37901933], train_wt_loss:  37.8789, val_wt_loss: 36.6642, train_grp_loss: [11.47716763 13.71803813 13.00811631], val_grp_loss: [12.62582037 12.79658559 11.24003954], train_hist_grp_loss: [ 3.83755749  4.99263993 11.06791597], cur_train_grp_loss: [0.08828137 0.11528296 0.25506066], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6760, max_kl_dist_index: 0, max_train_grp_loss:  13.7180, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7966, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:39:59,288 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  43, train_loss:  12.6263, val_loss:  12.2215, grad_norm: 0.0027, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6760, 0.3234, 0.6757, param: [ 4.89017292  6.92488913  5.71183907 10.23240134], weights: [0.30445455 0.3154449  0.38010055], train_wt_loss:  37.8789, val_wt_loss: 36.6645, train_grp_loss: [11.47775059 13.71741245 13.00813722], val_grp_loss: [12.62642701 12.7960547  11.24034207], train_hist_grp_loss: [ 3.92584339  5.10791756 11.32297707], cur_train_grp_loss: [0.0882859  0.11527763 0.2550611 ], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6760, max_kl_dist_index: 0, max_train_grp_loss:  13.7174, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7961, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:40:00,305 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  44, train_loss:  12.6263, val_loss:  12.2216, grad_norm: 0.0028, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6760, 0.3234, 0.6757, param: [ 4.88987279  6.92369169  5.71266989 10.2326002 ], weights: [0.30379777 0.31501931 0.38118293], train_wt_loss:  37.8790, val_wt_loss: 36.6649, train_grp_loss: [11.47832699 13.71679515 13.00815616], val_grp_loss: [12.62702765 12.79553395 11.24064172], train_hist_grp_loss: [ 4.01413378  5.22318994 11.57803858], cur_train_grp_loss: [0.08829039 0.11527237 0.25506151], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6760, max_kl_dist_index: 0, max_train_grp_loss:  13.7168, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7955, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:40:01,317 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  45, train_loss:  12.6263, val_loss:  12.2218, grad_norm: 0.0028, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6760, 0.3234, 0.6757, param: [ 4.88956908  6.92249704  5.71349944 10.23281024], weights: [0.30314091 0.31459264 0.38226645], train_wt_loss:  37.8790, val_wt_loss: 36.6653, train_grp_loss: [11.4788968  13.71618625 13.00817314], val_grp_loss: [12.62762228 12.79502338 11.24093849], train_hist_grp_loss: [ 4.1024286   5.33845712 11.83310047], cur_train_grp_loss: [0.08829482 0.11526719 0.25506189], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6760, max_kl_dist_index: 0, max_train_grp_loss:  13.7162, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7950, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:40:02,348 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  46, train_loss:  12.6263, val_loss:  12.2219, grad_norm: 0.0029, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6760, 0.3234, 0.6756, param: [ 4.88926178  6.92130518  5.71432773 10.23303149], weights: [0.30248397 0.31416491 0.38335112], train_wt_loss:  37.8790, val_wt_loss: 36.6657, train_grp_loss: [11.47946003 13.71558577 13.00818814], val_grp_loss: [12.62821088 12.79452299 11.24123237], train_hist_grp_loss: [ 4.19072781  5.45371919 12.08816269], cur_train_grp_loss: [0.08829921 0.11526207 0.25506222], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6760, max_kl_dist_index: 0, max_train_grp_loss:  13.7156, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7945, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:40:03,397 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  47, train_loss:  12.6263, val_loss:  12.2220, grad_norm: 0.0030, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6760, 0.3234, 0.6756, param: [ 4.88895088  6.92011609  5.71515474 10.23326398], weights: [0.30182697 0.31373612 0.38443692], train_wt_loss:  37.8790, val_wt_loss: 36.6661, train_grp_loss: [11.48001665 13.71499372 13.00820117], val_grp_loss: [12.62879343 12.7940328  11.24152336], train_hist_grp_loss: [ 4.27903135  5.56897622 12.3432252 ], cur_train_grp_loss: [0.08830354 0.11525702 0.25506251], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6760, max_kl_dist_index: 0, max_train_grp_loss:  13.7150, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7940, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:40:04,448 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  48, train_loss:  12.6264, val_loss:  12.2222, grad_norm: 0.0030, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6759, 0.3234, 0.6756, param: [ 4.88863638  6.91892979  5.71598049 10.23350772], weights: [0.3011699  0.31330627 0.38552383], train_wt_loss:  37.8791, val_wt_loss: 36.6665, train_grp_loss: [11.48056666 13.7144101  13.00821221], val_grp_loss: [12.62936993 12.79355284 11.24181145], train_hist_grp_loss: [ 4.36733917  5.68422826 12.59828797], cur_train_grp_loss: [0.08830782 0.11525205 0.25506277], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6759, max_kl_dist_index: 0, max_train_grp_loss:  13.7144, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7936, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:40:05,464 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  49, train_loss:  12.6264, val_loss:  12.2223, grad_norm: 0.0031, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6759, 0.3234, 0.6756, param: [ 4.88831828  6.91774626  5.71680495 10.23376276], weights: [0.30051277 0.31287538 0.38661185], train_wt_loss:  37.8791, val_wt_loss: 36.6668, train_grp_loss: [11.48111003 13.71383494 13.00822126], val_grp_loss: [12.62994036 12.79308311 11.24209662], train_hist_grp_loss: [ 4.45565122  5.79947541 12.85335095], cur_train_grp_loss: [0.08831205 0.11524714 0.25506298], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6759, max_kl_dist_index: 0, max_train_grp_loss:  13.7138, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7931, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:40:06,483 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  50, train_loss:  12.6264, val_loss:  12.2224, grad_norm: 0.0032, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6759, 0.3234, 0.6755, param: [ 4.88799657  6.91656551  5.71762813 10.2340291 ], weights: [0.29985558 0.31244344 0.38770098], train_wt_loss:  37.8791, val_wt_loss: 36.6672, train_grp_loss: [11.48164676 13.71326825 13.00822832], val_grp_loss: [12.63050472 12.79262365 11.24237889], train_hist_grp_loss: [ 4.54396745  5.91471772 13.10841411], cur_train_grp_loss: [0.08831623 0.11524231 0.25506316], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6759, max_kl_dist_index: 0, max_train_grp_loss:  13.7133, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7926, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:40:07,547 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  51, train_loss:  12.6264, val_loss:  12.2225, grad_norm: 0.0032, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6759, 0.3234, 0.6755, param: [ 4.88767123  6.91538752  5.71845003 10.23430679], weights: [0.29919835 0.31201047 0.38879119], train_wt_loss:  37.8792, val_wt_loss: 36.6676, train_grp_loss: [11.48217683 13.71271003 13.00823338], val_grp_loss: [12.63106298 12.79217446 11.24265822], train_hist_grp_loss: [ 4.63228781  6.02995527 13.36347742], cur_train_grp_loss: [0.08832036 0.11523755 0.2550633 ], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6759, max_kl_dist_index: 0, max_train_grp_loss:  13.7127, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7922, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:40:08,554 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  52, train_loss:  12.6264, val_loss:  12.2227, grad_norm: 0.0033, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6759, 0.3234, 0.6755, param: [ 4.88734227  6.9142123   5.71927064 10.23459584], weights: [0.29854106 0.31157646 0.38988248], train_wt_loss:  37.8792, val_wt_loss: 36.6680, train_grp_loss: [11.48270023 13.71216032 13.00823644], val_grp_loss: [12.63161513 12.79173557 11.24293464], train_hist_grp_loss: [ 4.72061225  6.14518812 13.61854081], cur_train_grp_loss: [0.08832444 0.11523286 0.2550634 ], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6759, max_kl_dist_index: 0, max_train_grp_loss:  13.7122, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7917, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:40:09,560 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  53, train_loss:  12.6264, val_loss:  12.2228, grad_norm: 0.0034, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6759, 0.3234, 0.6755, param: [ 4.88700968  6.91303984  5.72008995 10.23489628], weights: [0.29788374 0.31114143 0.39097483], train_wt_loss:  37.8792, val_wt_loss: 36.6684, train_grp_loss: [11.48321695 13.71161911 13.00823749], val_grp_loss: [12.63216116 12.79130699 11.24320811], train_hist_grp_loss: [ 4.80894071  6.26041636 13.87360427], cur_train_grp_loss: [0.08832846 0.11522824 0.25506346], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6759, max_kl_dist_index: 0, max_train_grp_loss:  13.7116, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7913, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:40:10,561 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  54, train_loss:  12.6264, val_loss:  12.2229, grad_norm: 0.0034, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6759, 0.3234, 0.6754, param: [ 4.88667345  6.91187015  5.72090798 10.23520813], weights: [0.29722638 0.31070537 0.39206825], train_wt_loss:  37.8792, val_wt_loss: 36.6688, train_grp_loss: [11.48372696 13.71108642 13.00823653], val_grp_loss: [12.63270107 12.79088875 11.24347865], train_hist_grp_loss: [ 4.89727315  6.37564005 14.12866775], cur_train_grp_loss: [0.08833244 0.11522369 0.25506348], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6759, max_kl_dist_index: 0, max_train_grp_loss:  13.7111, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7909, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:40:11,605 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  55, train_loss:  12.6264, val_loss:  12.2231, grad_norm: 0.0035, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6759, 0.3234, 0.6754, param: [ 4.88633357  6.9107032   5.7217247  10.23553143], weights: [0.296569   0.31026829 0.39316271], train_wt_loss:  37.8793, val_wt_loss: 36.6692, train_grp_loss: [11.48423027 13.71056227 13.00823354], val_grp_loss: [12.63323483 12.79048085 11.24374623], train_hist_grp_loss: [ 4.98560951  6.49085927 14.38373122], cur_train_grp_loss: [0.08833636 0.11521921 0.25506346], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6759, max_kl_dist_index: 0, max_train_grp_loss:  13.7106, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7905, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:40:12,615 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  56, train_loss:  12.6264, val_loss:  12.2232, grad_norm: 0.0036, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6759, 0.3234, 0.6754, param: [ 4.88599005  6.90953901  5.72254012 10.23586619], weights: [0.29591158 0.30983021 0.39425821], train_wt_loss:  37.8793, val_wt_loss: 36.6696, train_grp_loss: [11.48472685 13.71004667 13.00822854], val_grp_loss: [12.63376244 12.79008333 11.24401086], train_hist_grp_loss: [ 5.07394974  6.60607407 14.63879462], cur_train_grp_loss: [0.08834023 0.11521481 0.2550634 ], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6759, max_kl_dist_index: 0, max_train_grp_loss:  13.7100, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7901, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:40:13,670 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  57, train_loss:  12.6264, val_loss:  12.2233, grad_norm: 0.0036, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6759, 0.3234, 0.6754, param: [ 4.88564286  6.90837757  5.72335424 10.23621246], weights: [0.29525415 0.30939112 0.39535474], train_wt_loss:  37.8793, val_wt_loss: 36.6700, train_grp_loss: [11.4852167  13.70953964 13.00822151], val_grp_loss: [12.63428387 12.7896962  11.24427253], train_hist_grp_loss: [ 5.1622938   6.72128455 14.89385792], cur_train_grp_loss: [0.08834405 0.11521048 0.2550633 ], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6759, max_kl_dist_index: 0, max_train_grp_loss:  13.7095, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7897, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:40:14,676 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  58, train_loss:  12.6265, val_loss:  12.2234, grad_norm: 0.0037, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6759, 0.3234, 0.6754, param: [ 4.88529202  6.90721887  5.72416705 10.23657024], weights: [0.2945967  0.30895102 0.39645228], train_wt_loss:  37.8794, val_wt_loss: 36.6703, train_grp_loss: [11.48569979 13.70904118 13.00821244], val_grp_loss: [12.63479913 12.78931948 11.24453124], train_hist_grp_loss: [ 5.25064162  6.83649077 15.14892109], cur_train_grp_loss: [0.08834782 0.11520622 0.25506317], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6759, max_kl_dist_index: 0, max_train_grp_loss:  13.7090, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7893, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:40:15,697 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  59, train_loss:  12.6265, val_loss:  12.2236, grad_norm: 0.0038, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6759, 0.3234, 0.6754, param: [ 4.8849375   6.90606291  5.72497854 10.23693956], weights: [0.29393924 0.30850994 0.39755083], train_wt_loss:  37.8794, val_wt_loss: 36.6707, train_grp_loss: [11.48617613 13.70855131 13.00820134], val_grp_loss: [12.63530819 12.78895318 11.24478697], train_hist_grp_loss: [ 5.33899315  6.95169279 15.40398408], cur_train_grp_loss: [0.08835154 0.11520203 0.25506299], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6759, max_kl_dist_index: 0, max_train_grp_loss:  13.7086, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7890, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:40:16,725 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  60, train_loss:  12.6265, val_loss:  12.2237, grad_norm: 0.0038, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6759, 0.3234, 0.6753, param: [ 4.8845793   6.90490969  5.72578872 10.23732046], weights: [0.29328177 0.30806786 0.39865037], train_wt_loss:  37.8794, val_wt_loss: 36.6711, train_grp_loss: [11.48664568 13.70807005 13.00818819], val_grp_loss: [12.63581104 12.78859734 11.24503972], train_hist_grp_loss: [ 5.42734836  7.0668907  15.65904685], cur_train_grp_loss: [0.0883552  0.11519791 0.25506277], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6759, max_kl_dist_index: 0, max_train_grp_loss:  13.7081, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7886, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:40:17,751 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  61, train_loss:  12.6265, val_loss:  12.2238, grad_norm: 0.0039, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6759, 0.3234, 0.6753, param: [ 4.88421743  6.90375919  5.72659758 10.23771296], weights: [0.2926243 0.3076248 0.3997509], train_wt_loss:  37.8795, val_wt_loss: 36.6715, train_grp_loss: [11.48710845 13.70759741 13.008173  ], val_grp_loss: [12.63630768 12.78825195 11.24528948], train_hist_grp_loss: [ 5.51570717  7.18208457 15.91410936], cur_train_grp_loss: [0.08835881 0.11519387 0.25506251], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6759, max_kl_dist_index: 0, max_train_grp_loss:  13.7076, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7883, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:40:18,725 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  62, train_loss:  12.6265, val_loss:  12.2240, grad_norm: 0.0040, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6759, 0.3234, 0.6753, param: [ 4.88385186  6.90261143  5.72740512 10.23811708], weights: [0.29196684 0.30718076 0.4008524 ], train_wt_loss:  37.8795, val_wt_loss: 36.6719, train_grp_loss: [11.48756441 13.7071334  13.00815575], val_grp_loss: [12.63679809 12.78791705 11.24553625], train_hist_grp_loss: [ 5.60406954  7.29727446 16.16917158], cur_train_grp_loss: [0.08836237 0.11518989 0.25506222], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6759, max_kl_dist_index: 0, max_train_grp_loss:  13.7071, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7879, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:40:19,758 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  63, train_loss:  12.6265, val_loss:  12.2241, grad_norm: 0.0040, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6759, 0.3234, 0.6753, param: [ 4.8834826   6.90146639  5.72821133 10.23853285], weights: [0.29130938 0.30673575 0.40195487], train_wt_loss:  37.8795, val_wt_loss: 36.6723, train_grp_loss: [11.48801357 13.70667804 13.00813645], val_grp_loss: [12.63728225 12.78759266 11.24578002], train_hist_grp_loss: [ 5.69243542  7.41246046 16.42423346], cur_train_grp_loss: [0.08836588 0.11518599 0.25506188], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6759, max_kl_dist_index: 0, max_train_grp_loss:  13.7067, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7876, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:40:20,769 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  64, train_loss:  12.6265, val_loss:  12.2243, grad_norm: 0.0041, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6759, 0.3234, 0.6753, param: [ 4.88310963  6.90032407  5.72901621 10.2389603 ], weights: [0.29065194 0.30628977 0.40305829], train_wt_loss:  37.8795, val_wt_loss: 36.6728, train_grp_loss: [11.48845589 13.70623134 13.00811508], val_grp_loss: [12.63776016 12.78727879 11.24602079], train_hist_grp_loss: [ 5.78080476  7.52764263 16.67929496], cur_train_grp_loss: [0.08836934 0.11518217 0.2550615 ], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6759, max_kl_dist_index: 0, max_train_grp_loss:  13.7062, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7873, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:40:21,824 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  65, train_loss:  12.6265, val_loss:  12.2244, grad_norm: 0.0042, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6759, 0.3234, 0.6753, param: [ 4.88273296  6.89918446  5.72981975 10.23939945], weights: [0.28999452 0.30584283 0.40416265], train_wt_loss:  37.8796, val_wt_loss: 36.6732, train_grp_loss: [11.48889137 13.70579331 13.00809165], val_grp_loss: [12.63823179 12.78697546 11.24625855], train_hist_grp_loss: [ 5.86917749  7.64282104 16.93435604], cur_train_grp_loss: [0.08837274 0.11517841 0.25506108], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6759, max_kl_dist_index: 0, max_train_grp_loss:  13.7058, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7870, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:40:22,840 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  66, train_loss:  12.6265, val_loss:  12.2245, grad_norm: 0.0042, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6759, 0.3234, 0.6753, param: [ 4.88235257  6.89804757  5.73062196 10.23985033], weights: [0.28933713 0.30539493 0.40526794], train_wt_loss:  37.8796, val_wt_loss: 36.6736, train_grp_loss: [11.48932    13.70536398 13.00806615], val_grp_loss: [12.63869715 12.78668269 11.24649329], train_hist_grp_loss: [ 5.95755358  7.75799577 17.18941666], cur_train_grp_loss: [0.08837609 0.11517473 0.25506062], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6759, max_kl_dist_index: 0, max_train_grp_loss:  13.7054, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7867, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:40:23,880 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  67, train_loss:  12.6265, val_loss:  12.2247, grad_norm: 0.0043, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6759, 0.3234, 0.6753, param: [ 4.88196846  6.89691338  5.73142282 10.24031296], weights: [0.28867976 0.30494609 0.40637415], train_wt_loss:  37.8796, val_wt_loss: 36.6740, train_grp_loss: [11.48974177 13.70494335 13.00803856], val_grp_loss: [12.63915622 12.78640051 11.24672501], train_hist_grp_loss: [ 6.04593297  7.8731669  17.44447678], cur_train_grp_loss: [0.08837938 0.11517113 0.25506012], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6759, max_kl_dist_index: 0, max_train_grp_loss:  13.7049, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7864, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:40:24,920 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  68, train_loss:  12.6266, val_loss:  12.2248, grad_norm: 0.0044, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6759, 0.3234, 0.6752, param: [ 4.88158062  6.89578189  5.73222234 10.24078737], weights: [0.28802243 0.3044963  0.40748127], train_wt_loss:  37.8797, val_wt_loss: 36.6744, train_grp_loss: [11.49015665 13.70453143 13.0080089 ], val_grp_loss: [12.63960898 12.78612892 11.24695369], train_hist_grp_loss: [ 6.13431559  7.98833449 17.69953636], cur_train_grp_loss: [0.08838263 0.11516759 0.25505958], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6759, max_kl_dist_index: 0, max_train_grp_loss:  13.7045, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7861, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:40:25,935 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  69, train_loss:  12.6266, val_loss:  12.2249, grad_norm: 0.0044, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6759, 0.3234, 0.6752, param: [ 4.88118905  6.8946531   5.7330205  10.24127359], weights: [0.28736514 0.30404557 0.4085893 ], train_wt_loss:  37.8797, val_wt_loss: 36.6748, train_grp_loss: [11.49056465 13.70412825 13.00797716], val_grp_loss: [12.64005542 12.78586795 11.24717935], train_hist_grp_loss: [ 6.22270142  8.10349862 17.95459535], cur_train_grp_loss: [0.08838582 0.11516413 0.255059  ], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6759, max_kl_dist_index: 0, max_train_grp_loss:  13.7041, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7859, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:40:26,949 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  70, train_loss:  12.6266, val_loss:  12.2251, grad_norm: 0.0045, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6759, 0.3234, 0.6752, param: [ 4.88079373  6.893527    5.73381732 10.24177163], weights: [0.28670789 0.3035939  0.4096982 ], train_wt_loss:  37.8797, val_wt_loss: 36.6752, train_grp_loss: [11.49096574 13.70373382 13.00794332], val_grp_loss: [12.64049554 12.78561762 11.24740196], train_hist_grp_loss: [ 6.31109037  8.21865936 18.20965373], cur_train_grp_loss: [0.08838896 0.11516074 0.25505838], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6759, max_kl_dist_index: 0, max_train_grp_loss:  13.7037, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7856, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:40:28,017 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  71, train_loss:  12.6266, val_loss:  12.2252, grad_norm: 0.0046, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6759, 0.3234, 0.6752, param: [ 4.88039467  6.89240358  5.73461277 10.24228154], weights: [0.2860507  0.30314132 0.41080799], train_wt_loss:  37.8798, val_wt_loss: 36.6756, train_grp_loss: [11.49135992 13.70334815 13.00790739], val_grp_loss: [12.64092931 12.78537795 11.24762153], train_hist_grp_loss: [ 6.39948242  8.33381679 18.46471144], cur_train_grp_loss: [0.08839204 0.11515743 0.25505771], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6759, max_kl_dist_index: 0, max_train_grp_loss:  13.7033, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7854, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:40:29,060 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  72, train_loss:  12.6266, val_loss:  12.2253, grad_norm: 0.0047, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6760, 0.3234, 0.6752, param: [ 4.87999186  6.89128285  5.73540687 10.24280333], weights: [0.28539356 0.30268781 0.41191864], train_wt_loss:  37.8798, val_wt_loss: 36.6760, train_grp_loss: [11.49174716 13.70297125 13.00786935], val_grp_loss: [12.64135673 12.78514896 11.24783805], train_hist_grp_loss: [ 6.48787749  8.44897098 18.71976845], cur_train_grp_loss: [0.08839508 0.11515419 0.25505701], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6760, max_kl_dist_index: 0, max_train_grp_loss:  13.7030, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7851, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:40:30,081 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  73, train_loss:  12.6266, val_loss:  12.2255, grad_norm: 0.0047, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6760, 0.3234, 0.6752, param: [ 4.87958528  6.8901648   5.7361996  10.24333702], weights: [0.28473648 0.30223338 0.41303014], train_wt_loss:  37.8799, val_wt_loss: 36.6764, train_grp_loss: [11.49212747 13.70260314 13.00782922], val_grp_loss: [12.64177778 12.78493066 11.24805151], train_hist_grp_loss: [ 6.57627555  8.56412199 18.97482471], cur_train_grp_loss: [0.08839806 0.11515102 0.25505626], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6760, max_kl_dist_index: 0, max_train_grp_loss:  13.7026, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7849, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:40:31,091 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  74, train_loss:  12.6266, val_loss:  12.2256, grad_norm: 0.0048, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6760, 0.3235, 0.6752, param: [ 4.87917494  6.88904942  5.73699096 10.24388266], weights: [0.28407946 0.30177804 0.41414249], train_wt_loss:  37.8799, val_wt_loss: 36.6769, train_grp_loss: [11.49250082 13.70224384 13.00778697], val_grp_loss: [12.64219246 12.78472309 11.24826191], train_hist_grp_loss: [ 6.66467653  8.67926992 19.22988019], cur_train_grp_loss: [0.08840098 0.11514793 0.25505547], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6760, max_kl_dist_index: 0, max_train_grp_loss:  13.7022, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7847, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:40:32,082 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  75, train_loss:  12.6266, val_loss:  12.2258, grad_norm: 0.0049, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6760, 0.3235, 0.6752, param: [ 4.87876082  6.88793671  5.73778094 10.24444025], weights: [0.28342252 0.30132181 0.41525568], train_wt_loss:  37.8799, val_wt_loss: 36.6773, train_grp_loss: [11.49286721 13.70189335 13.00774261], val_grp_loss: [12.64260075 12.78452624 11.24846924], train_hist_grp_loss: [ 6.75308038  8.79441483 19.48493483], cur_train_grp_loss: [0.08840385 0.11514491 0.25505465], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6760, max_kl_dist_index: 0, max_train_grp_loss:  13.7019, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7845, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:40:33,126 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  76, train_loss:  12.6267, val_loss:  12.2259, grad_norm: 0.0049, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6760, 0.3235, 0.6752, param: [ 4.87834293  6.88682666  5.73856955 10.24500983], weights: [0.28276565 0.30086467 0.41636968], train_wt_loss:  37.8800, val_wt_loss: 36.6777, train_grp_loss: [11.49322662 13.7015517  13.00769613], val_grp_loss: [12.64300264 12.78434016 11.24867349], train_hist_grp_loss: [ 6.84148705  8.90955679 19.73998861], cur_train_grp_loss: [0.08840667 0.11514196 0.25505378], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6760, max_kl_dist_index: 0, max_train_grp_loss:  13.7016, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7843, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:40:34,149 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  77, train_loss:  12.6267, val_loss:  12.2260, grad_norm: 0.0050, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6760, 0.3235, 0.6752, param: [ 4.87792125  6.88571927  5.73935678 10.24559142], weights: [0.28210887 0.30040664 0.41748449], train_wt_loss:  37.8800, val_wt_loss: 36.6781, train_grp_loss: [11.49357904 13.7012189  13.00764753], val_grp_loss: [12.64339811 12.78416485 11.24887467], train_hist_grp_loss: [ 6.92989649  9.02469588 19.99504148], cur_train_grp_loss: [0.08840944 0.11513909 0.25505287], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6760, max_kl_dist_index: 0, max_train_grp_loss:  13.7012, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7842, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:40:35,202 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  78, train_loss:  12.6267, val_loss:  12.2262, grad_norm: 0.0051, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6760, 0.3235, 0.6752, param: [ 4.87749577  6.88461453  5.74014262 10.24618505], weights: [0.28145217 0.29994773 0.4186001 ], train_wt_loss:  37.8800, val_wt_loss: 36.6785, train_grp_loss: [11.49392446 13.70089495 13.0075968 ], val_grp_loss: [12.64378716 12.78400033 11.24907276], train_hist_grp_loss: [ 7.01830864  9.13983217 20.25009339], cur_train_grp_loss: [0.08841215 0.11513629 0.25505191], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6760, max_kl_dist_index: 0, max_train_grp_loss:  13.7009, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7840, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:40:36,224 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  79, train_loss:  12.6267, val_loss:  12.2263, grad_norm: 0.0051, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6760, 0.3235, 0.6752, param: [ 4.8770665   6.88351243  5.74092707 10.24679074], weights: [0.28079556 0.29948794 0.4197165 ], train_wt_loss:  37.8801, val_wt_loss: 36.6790, train_grp_loss: [11.49426286 13.70057989 13.00754394], val_grp_loss: [12.64416977 12.78384663 11.24926776], train_hist_grp_loss: [ 7.10672344  9.25496574 20.50514431], cur_train_grp_loss: [0.0884148  0.11513357 0.25505092], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6760, max_kl_dist_index: 0, max_train_grp_loss:  13.7006, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7838, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:40:37,248 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  80, train_loss:  12.6267, val_loss:  12.2265, grad_norm: 0.0052, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6760, 0.3235, 0.6752, param: [ 4.87663342  6.88241298  5.74171013 10.24740853], weights: [0.28013905 0.29902727 0.42083368], train_wt_loss:  37.8801, val_wt_loss: 36.6794, train_grp_loss: [11.49459423 13.70027371 13.00748894], val_grp_loss: [12.64454594 12.78370377 11.24945966], train_hist_grp_loss: [ 7.19514085  9.37009667 20.76019419], cur_train_grp_loss: [0.08841741 0.11513092 0.25504988], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6760, max_kl_dist_index: 0, max_train_grp_loss:  13.7003, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7837, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:40:38,261 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  81, train_loss:  12.6267, val_loss:  12.2266, grad_norm: 0.0053, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6760, 0.3235, 0.6752, param: [ 4.87619652  6.88131616  5.74249179 10.24803843], weights: [0.27948265 0.29856573 0.42195162], train_wt_loss:  37.8802, val_wt_loss: 36.6798, train_grp_loss: [11.49491857 13.69997644 13.00743181], val_grp_loss: [12.64491564 12.78357176 11.24964847], train_hist_grp_loss: [ 7.2835608   9.48522502 21.01524299], cur_train_grp_loss: [0.08841996 0.11512835 0.2550488 ], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6760, max_kl_dist_index: 0, max_train_grp_loss:  13.7000, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7836, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:40:39,285 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  82, train_loss:  12.6267, val_loss:  12.2267, grad_norm: 0.0053, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6760, 0.3235, 0.6752, param: [ 4.87575581  6.88022198  5.74327205 10.24868047], weights: [0.27882635 0.29810334 0.42307032], train_wt_loss:  37.8802, val_wt_loss: 36.6802, train_grp_loss: [11.49523586 13.69968809 13.00737252], val_grp_loss: [12.64527887 12.78345063 11.24983417], train_hist_grp_loss: [ 7.37198325  9.60035087 21.27029067], cur_train_grp_loss: [0.08842245 0.11512585 0.25504768], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6760, max_kl_dist_index: 0, max_train_grp_loss:  13.6997, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7835, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:40:40,294 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  83, train_loss:  12.6267, val_loss:  12.2269, grad_norm: 0.0054, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6761, 0.3235, 0.6752, param: [ 4.87531127  6.87913042  5.7440509  10.24933468], weights: [0.27817016 0.29764009 0.42418975], train_wt_loss:  37.8802, val_wt_loss: 36.6807, train_grp_loss: [11.49554608 13.69940868 13.00731109], val_grp_loss: [12.64563562 12.78334039 11.25001676], train_hist_grp_loss: [ 7.46040814  9.7154743  21.52533719], cur_train_grp_loss: [0.08842489 0.11512343 0.25504652], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6761, max_kl_dist_index: 0, max_train_grp_loss:  13.6994, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7833, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:40:41,288 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  84, train_loss:  12.6268, val_loss:  12.2270, grad_norm: 0.0055, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6761, 0.3235, 0.6752, param: [ 4.8748629   6.87804147  5.74482834 10.25000108], weights: [0.27751409 0.29717599 0.42530992], train_wt_loss:  37.8803, val_wt_loss: 36.6811, train_grp_loss: [11.49584923 13.69913821 13.0072475 ], val_grp_loss: [12.64598588 12.78324106 11.25019623], train_hist_grp_loss: [ 7.54883542  9.83059538 21.78038251], cur_train_grp_loss: [0.08842728 0.11512108 0.25504532], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6761, max_kl_dist_index: 0, max_train_grp_loss:  13.6991, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7832, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:40:42,317 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  85, train_loss:  12.6268, val_loss:  12.2272, grad_norm: 0.0056, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6761, 0.3236, 0.6752, param: [ 4.8744107   6.87695514  5.74560436 10.25067969], weights: [0.27685815 0.29671104 0.42643081], train_wt_loss:  37.8803, val_wt_loss: 36.6815, train_grp_loss: [11.49614529 13.69887671 13.00718176], val_grp_loss: [12.64632963 12.78315267 11.25037258], train_hist_grp_loss: [ 7.63726503  9.94571419 22.03542658], cur_train_grp_loss: [0.08842961 0.11511881 0.25504407], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6761, max_kl_dist_index: 0, max_train_grp_loss:  13.6989, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7832, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:40:43,346 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  86, train_loss:  12.6268, val_loss:  12.2273, grad_norm: 0.0056, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6761, 0.3236, 0.6752, param: [ 4.87395464  6.87587142  5.74637896 10.25137056], weights: [0.27620233 0.29624526 0.4275524 ], train_wt_loss:  37.8804, val_wt_loss: 36.6820, train_grp_loss: [11.49643426 13.69862419 13.00711385], val_grp_loss: [12.64666686 12.78307524 11.25054581], train_hist_grp_loss: [ 7.72569692 10.0608308  22.29046936], cur_train_grp_loss: [0.08843189 0.11511661 0.25504278], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6761, max_kl_dist_index: 0, max_train_grp_loss:  13.6986, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7831, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:40:44,360 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  87, train_loss:  12.6268, val_loss:  12.2275, grad_norm: 0.0057, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6761, 0.3236, 0.6752, param: [ 4.87349474  6.87479029  5.74715215 10.25207369], weights: [0.27554665 0.29577865 0.4286747 ], train_wt_loss:  37.8804, val_wt_loss: 36.6824, train_grp_loss: [11.49671612 13.69838066 13.00704378], val_grp_loss: [12.64699756 12.78300878 11.2507159 ], train_hist_grp_loss: [ 7.81413103 10.17594529 22.5455108 ], cur_train_grp_loss: [0.08843411 0.11511449 0.25504145], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6761, max_kl_dist_index: 0, max_train_grp_loss:  13.6984, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7830, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:40:45,379 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  88, train_loss:  12.6268, val_loss:  12.2276, grad_norm: 0.0058, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6761, 0.3236, 0.6752, param: [ 4.87303098  6.87371176  5.7479239  10.25278911], weights: [0.27489111 0.29531122 0.42979767], train_wt_loss:  37.8804, val_wt_loss: 36.6828, train_grp_loss: [11.49699085 13.69814614 13.00697153], val_grp_loss: [12.64732172 12.78295331 11.25088286], train_hist_grp_loss: [ 7.9025673  10.29105773 22.80055088], cur_train_grp_loss: [0.08843628 0.11511244 0.25504007], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6761, max_kl_dist_index: 0, max_train_grp_loss:  13.6981, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7830, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:40:46,412 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  89, train_loss:  12.6268, val_loss:  12.2278, grad_norm: 0.0058, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6761, 0.3236, 0.6752, param: [ 4.87256335  6.87263582  5.74869422 10.25351686], weights: [0.27423572 0.29484296 0.43092132], train_wt_loss:  37.8805, val_wt_loss: 36.6833, train_grp_loss: [11.49725845 13.69792065 13.00689711], val_grp_loss: [12.64763933 12.78290886 11.25104668], train_hist_grp_loss: [ 7.9910057  10.4061682  23.05558954], cur_train_grp_loss: [0.08843839 0.11511047 0.25503866], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6761, max_kl_dist_index: 0, max_train_grp_loss:  13.6979, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7829, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:40:47,422 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  90, train_loss:  12.6268, val_loss:  12.2279, grad_norm: 0.0059, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6762, 0.3236, 0.6752, param: [ 4.87209185  6.87156247  5.7494631  10.25425696], weights: [0.27358047 0.2943739  0.43204563], train_wt_loss:  37.8805, val_wt_loss: 36.6837, train_grp_loss: [11.49751891 13.69770419 13.00682051], val_grp_loss: [12.64795038 12.78287544 11.25120735], train_hist_grp_loss: [ 8.07944615 10.52127678 23.31062673], cur_train_grp_loss: [0.08844045 0.11510858 0.2550372 ], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6762, max_kl_dist_index: 0, max_train_grp_loss:  13.6977, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7829, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:40:48,444 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  91, train_loss:  12.6269, val_loss:  12.2280, grad_norm: 0.0060, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6762, 0.3236, 0.6753, param: [ 4.87161647  6.87049169  5.75023055 10.25500942], weights: [0.27292538 0.29390403 0.4331706 ], train_wt_loss:  37.8806, val_wt_loss: 36.6841, train_grp_loss: [11.49777221 13.69749679 13.00674172], val_grp_loss: [12.64825485 12.78285308 11.25136488], train_hist_grp_loss: [ 8.1678886  10.63638354 23.56566243], cur_train_grp_loss: [0.08844245 0.11510676 0.2550357 ], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6762, max_kl_dist_index: 0, max_train_grp_loss:  13.6975, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7829, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:40:49,483 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  92, train_loss:  12.6269, val_loss:  12.2282, grad_norm: 0.0061, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6762, 0.3236, 0.6753, param: [ 4.87113721  6.86942348  5.75099654 10.25577428], weights: [0.27227045 0.29343335 0.4342962 ], train_wt_loss:  37.8806, val_wt_loss: 36.6846, train_grp_loss: [11.49801834 13.69729845 13.00666075], val_grp_loss: [12.64855274 12.7828418  11.25151925], train_hist_grp_loss: [ 8.256333   10.75148855 23.82069658], cur_train_grp_loss: [0.0884444  0.11510502 0.25503415], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6762, max_kl_dist_index: 0, max_train_grp_loss:  13.6973, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7828, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:40:50,510 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  93, train_loss:  12.6269, val_loss:  12.2283, grad_norm: 0.0061, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6762, 0.3237, 0.6753, param: [ 4.87065406  6.86835783  5.75176109 10.25655157], weights: [0.27161569 0.29296189 0.43542242], train_wt_loss:  37.8806, val_wt_loss: 36.6850, train_grp_loss: [11.49825729 13.6971092  13.00657758], val_grp_loss: [12.64884403 12.78284161 11.25167046], train_hist_grp_loss: [ 8.34477929 10.8665919  24.07572914], cur_train_grp_loss: [0.08844629 0.11510335 0.25503256], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6762, max_kl_dist_index: 0, max_train_grp_loss:  13.6971, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7828, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:40:51,523 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  94, train_loss:  12.6269, val_loss:  12.2285, grad_norm: 0.0062, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6762, 0.3237, 0.6753, param: [ 4.87016701  6.86729474  5.75252418 10.2573413 ], weights: [0.2709611  0.29248964 0.43654927], train_wt_loss:  37.8807, val_wt_loss: 36.6855, train_grp_loss: [11.49848906 13.69692904 13.00649221], val_grp_loss: [12.64912871 12.78285253 11.25181851], train_hist_grp_loss: [ 8.43322743 10.98169366 24.33076008], cur_train_grp_loss: [0.08844813 0.11510176 0.25503093], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6762, max_kl_dist_index: 0, max_train_grp_loss:  13.6969, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7829, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:40:52,539 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  95, train_loss:  12.6269, val_loss:  12.2286, grad_norm: 0.0063, live_grad: 0.0000, reward_err: 0.0103, 0.0186, 0.0011, KL_dist: 0.6763, 0.3237, 0.6753, param: [ 4.86967606  6.8662342   5.75328581 10.25814351], weights: [0.27030668 0.29201661 0.43767671], train_wt_loss:  37.8807, val_wt_loss: 36.6859, train_grp_loss: [11.49871362 13.696758   13.00640465], val_grp_loss: [12.64940677 12.7828746  11.25196339], train_hist_grp_loss: [ 8.52167734 11.0967939  24.58578934], cur_train_grp_loss: [0.08844992 0.11510024 0.25502926], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6763, max_kl_dist_index: 0, max_train_grp_loss:  13.6968, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7829, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:40:53,591 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  96, train_loss:  12.6269, val_loss:  12.2288, grad_norm: 0.0063, live_grad: 0.0000, reward_err: 0.0103, 0.0186, 0.0011, KL_dist: 0.6763, 0.3237, 0.6753, param: [ 4.8691812   6.8651762   5.75404598 10.25895822], weights: [0.26965245 0.2915428  0.43880475], train_wt_loss:  37.8808, val_wt_loss: 36.6864, train_grp_loss: [11.49893097 13.69659608 13.00631488], val_grp_loss: [12.64967821 12.78290782 11.2521051 ], train_hist_grp_loss: [ 8.61012899 11.21189271 24.84081688], cur_train_grp_loss: [0.08845164 0.11509881 0.25502754], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6763, max_kl_dist_index: 0, max_train_grp_loss:  13.6966, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7829, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:40:54,616 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  97, train_loss:  12.6269, val_loss:  12.2289, grad_norm: 0.0064, live_grad: 0.0000, reward_err: 0.0103, 0.0186, 0.0011, KL_dist: 0.6763, 0.3237, 0.6753, param: [ 4.86868242  6.86412074  5.75480468 10.25978545], weights: [0.26899841 0.29106823 0.43993336], train_wt_loss:  37.8808, val_wt_loss: 36.6868, train_grp_loss: [11.49914109 13.69644331 13.0062229 ], val_grp_loss: [12.649943   12.78295221 11.25224363], train_hist_grp_loss: [ 8.6985823  11.32699015 25.09584266], cur_train_grp_loss: [0.08845332 0.11509745 0.25502578], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6763, max_kl_dist_index: 0, max_train_grp_loss:  13.6964, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7830, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:40:55,631 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  98, train_loss:  12.6270, val_loss:  12.2291, grad_norm: 0.0065, live_grad: 0.0000, reward_err: 0.0103, 0.0186, 0.0011, KL_dist: 0.6763, 0.3237, 0.6753, param: [ 4.86817971  6.86306781  5.7555619  10.26062523], weights: [0.26834456 0.29059289 0.44106255], train_wt_loss:  37.8809, val_wt_loss: 36.6873, train_grp_loss: [11.49934398 13.69629969 13.00612871], val_grp_loss: [12.65020114 12.78300781 11.25237899], train_hist_grp_loss: [ 8.78703723 11.44208632 25.35086664], cur_train_grp_loss: [0.08845493 0.11509616 0.25502398], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6763, max_kl_dist_index: 0, max_train_grp_loss:  13.6963, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7830, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:40:56,651 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  99, train_loss:  12.6270, val_loss:  12.2292, grad_norm: 0.0066, live_grad: 0.0000, reward_err: 0.0103, 0.0186, 0.0011, KL_dist: 0.6763, 0.3237, 0.6754, param: [ 4.86767308  6.86201741  5.75631765 10.26147758], weights: [0.26769091 0.2901168  0.44219229], train_wt_loss:  37.8809, val_wt_loss: 36.6877, train_grp_loss: [11.49953963 13.69616525 13.0060323 ], val_grp_loss: [12.65045262 12.78307462 11.25251115], train_hist_grp_loss: [ 8.87549373 11.55718127 25.60588877], cur_train_grp_loss: [0.08845649 0.11509496 0.25502213], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6763, max_kl_dist_index: 0, max_train_grp_loss:  13.6962, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7831, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:40:57,662 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  100, train_loss:  12.6270, val_loss:  12.2294, grad_norm: 0.0066, live_grad: 0.0000, reward_err: 0.0103, 0.0186, 0.0011, KL_dist: 0.6764, 0.3238, 0.6754, param: [ 4.86716251  6.86096952  5.75707192 10.26234254], weights: [0.26703746 0.28963996 0.44332258], train_wt_loss:  37.8810, val_wt_loss: 36.6882, train_grp_loss: [11.49972802 13.69604    13.00593367], val_grp_loss: [12.65069743 12.78315267 11.25264013], train_hist_grp_loss: [ 8.96395172 11.6722751  25.86090901], cur_train_grp_loss: [0.088458   0.11509383 0.25502024], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6764, max_kl_dist_index: 0, max_train_grp_loss:  13.6960, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7832, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:40:58,709 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  101, train_loss:  12.6270, val_loss:  12.2295, grad_norm: 0.0067, live_grad: 0.0000, reward_err: 0.0103, 0.0186, 0.0011, KL_dist: 0.6764, 0.3238, 0.6754, param: [ 4.86664799  6.85992413  5.7578247  10.26322012], weights: [0.26638422 0.28916238 0.44445339], train_wt_loss:  37.8810, val_wt_loss: 36.6886, train_grp_loss: [11.49990914 13.69592395 13.00583281], val_grp_loss: [12.65093555 12.78324198 11.25276592], train_hist_grp_loss: [ 9.05241117 11.78736787 26.11592732], cur_train_grp_loss: [0.08845945 0.11509277 0.25501831], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6764, max_kl_dist_index: 0, max_train_grp_loss:  13.6959, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7832, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:40:59,716 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  102, train_loss:  12.6270, val_loss:  12.2297, grad_norm: 0.0068, live_grad: 0.0000, reward_err: 0.0103, 0.0186, 0.0011, KL_dist: 0.6764, 0.3238, 0.6754, param: [ 4.86612953  6.85888126  5.75857598 10.26411035], weights: [0.2657312  0.28868407 0.44558473], train_wt_loss:  37.8811, val_wt_loss: 36.6891, train_grp_loss: [11.50008298 13.69581711 13.00572972], val_grp_loss: [12.65116698 12.78334257 11.25288851], train_hist_grp_loss: [ 9.14087201 11.90245967 26.37094365], cur_train_grp_loss: [0.08846084 0.1150918  0.25501633], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6764, max_kl_dist_index: 0, max_train_grp_loss:  13.6958, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7833, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:41:00,727 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  103, train_loss:  12.6270, val_loss:  12.2298, grad_norm: 0.0068, live_grad: 0.0000, reward_err: 0.0103, 0.0186, 0.0011, KL_dist: 0.6764, 0.3238, 0.6754, param: [ 4.86560711  6.85784087  5.75932577 10.26501326], weights: [0.2650784  0.28820502 0.44671658], train_wt_loss:  37.8811, val_wt_loss: 36.6895, train_grp_loss: [11.50024953 13.69571952 13.0056244 ], val_grp_loss: [12.6513917  12.78345445 11.2530079 ], train_hist_grp_loss: [ 9.22933419 12.01755057 26.62595796], cur_train_grp_loss: [0.08846218 0.1150909  0.25501431], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6764, max_kl_dist_index: 0, max_train_grp_loss:  13.6957, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7835, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:41:01,777 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  104, train_loss:  12.6270, val_loss:  12.2300, grad_norm: 0.0069, live_grad: 0.0000, reward_err: 0.0103, 0.0186, 0.0011, KL_dist: 0.6764, 0.3238, 0.6754, param: [ 4.86508072  6.85680297  5.76007406 10.26592887], weights: [0.26442582 0.28772526 0.44784892], train_wt_loss:  37.8811, val_wt_loss: 36.6900, train_grp_loss: [11.50040878 13.69563116 13.00551685], val_grp_loss: [12.65160971 12.78357766 11.25312408], train_hist_grp_loss: [ 9.31779764 12.13264065 26.8809702 ], cur_train_grp_loss: [0.08846346 0.11509008 0.25501224], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6764, max_kl_dist_index: 0, max_train_grp_loss:  13.6956, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7836, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:41:02,794 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  105, train_loss:  12.6271, val_loss:  12.2301, grad_norm: 0.0070, live_grad: 0.0000, reward_err: 0.0103, 0.0186, 0.0011, KL_dist: 0.6765, 0.3239, 0.6755, param: [ 4.86455037  6.85576755  5.76082085 10.2668572 ], weights: [0.26377348 0.28724477 0.44898175], train_wt_loss:  37.8812, val_wt_loss: 36.6904, train_grp_loss: [11.50056072 13.69555208 13.00540705], val_grp_loss: [12.65182099 12.78371221 11.25323706], train_hist_grp_loss: [ 9.40626233 12.24772999 27.13598033], cur_train_grp_loss: [0.08846468 0.11508934 0.25501013], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6765, max_kl_dist_index: 0, max_train_grp_loss:  13.6956, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7837, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:41:03,855 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  106, train_loss:  12.6271, val_loss:  12.2303, grad_norm: 0.0071, live_grad: 0.0000, reward_err: 0.0103, 0.0186, 0.0011, KL_dist: 0.6765, 0.3239, 0.6755, param: [ 4.86401604  6.85473461  5.76156612 10.26779828], weights: [0.26312137 0.28676358 0.45011505], train_wt_loss:  37.8812, val_wt_loss: 36.6909, train_grp_loss: [11.50070534 13.69548227 13.00529501], val_grp_loss: [12.65202554 12.78385813 11.25334682], train_hist_grp_loss: [ 9.49472818 12.36281866 27.39098832], cur_train_grp_loss: [0.08846585 0.11508867 0.25500798], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6765, max_kl_dist_index: 0, max_train_grp_loss:  13.6955, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7839, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:41:04,872 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  107, train_loss:  12.6271, val_loss:  12.2305, grad_norm: 0.0071, live_grad: 0.0000, reward_err: 0.0103, 0.0186, 0.0011, KL_dist: 0.6765, 0.3239, 0.6755, param: [ 4.86347773  6.85370413  5.76230987 10.26875214], weights: [0.2624695  0.28628169 0.45124881], train_wt_loss:  37.8813, val_wt_loss: 36.6914, train_grp_loss: [11.50084263 13.69542176 13.00518072], val_grp_loss: [12.65222334 12.78401542 11.25345337], train_hist_grp_loss: [ 9.58319514 12.47790675 27.6459941 ], cur_train_grp_loss: [0.08846696 0.11508809 0.25500578], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6765, max_kl_dist_index: 0, max_train_grp_loss:  13.6954, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7840, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:41:05,901 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  108, train_loss:  12.6271, val_loss:  12.2306, grad_norm: 0.0072, live_grad: 0.0000, reward_err: 0.0103, 0.0186, 0.0011, KL_dist: 0.6766, 0.3239, 0.6755, param: [ 4.86293543  6.8526761   5.76305211 10.26971881], weights: [0.26181789 0.2857991  0.45238302], train_wt_loss:  37.8813, val_wt_loss: 36.6918, train_grp_loss: [11.50097258 13.69537055 13.00506418], val_grp_loss: [12.65241438 12.78418412 11.2535567 ], train_hist_grp_loss: [ 9.67166316 12.59299432 27.90099764], cur_train_grp_loss: [0.08846802 0.11508758 0.25500354], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6766, max_kl_dist_index: 0, max_train_grp_loss:  13.6954, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7842, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:41:06,908 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  109, train_loss:  12.6271, val_loss:  12.2308, grad_norm: 0.0073, live_grad: 0.0000, reward_err: 0.0103, 0.0186, 0.0011, KL_dist: 0.6766, 0.3239, 0.6756, param: [ 4.86238913  6.85165053  5.76379282 10.27069829], weights: [0.26116652 0.28531582 0.45351766], train_wt_loss:  37.8814, val_wt_loss: 36.6923, train_grp_loss: [11.50109517 13.69532867 13.00494538], val_grp_loss: [12.65259866 12.78436424 11.25365681], train_hist_grp_loss: [ 9.76013218 12.70808147 28.1559989 ], cur_train_grp_loss: [0.08846902 0.11508715 0.25500126], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6766, max_kl_dist_index: 0, max_train_grp_loss:  13.6953, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7844, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:41:07,934 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  110, train_loss:  12.6271, val_loss:  12.2309, grad_norm: 0.0074, live_grad: 0.0000, reward_err: 0.0103, 0.0186, 0.0011, KL_dist: 0.6766, 0.3239, 0.6756, param: [ 4.86183883  6.8506274   5.76453199 10.27169063], weights: [0.26051541 0.28483185 0.45465273], train_wt_loss:  37.8814, val_wt_loss: 36.6927, train_grp_loss: [11.5012104  13.69529613 13.00482432], val_grp_loss: [12.65277616 12.78455581 11.25375369], train_hist_grp_loss: [ 9.84860215 12.82316827 28.41099783], cur_train_grp_loss: [0.08846996 0.1150868  0.25499893], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6766, max_kl_dist_index: 0, max_train_grp_loss:  13.6953, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7846, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:41:08,984 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  111, train_loss:  12.6272, val_loss:  12.2311, grad_norm: 0.0074, live_grad: 0.0000, reward_err: 0.0103, 0.0186, 0.0011, KL_dist: 0.6766, 0.3240, 0.6756, param: [ 4.86128452  6.8496067   5.76526964 10.27269585], weights: [0.25986457 0.28434721 0.45578821], train_wt_loss:  37.8815, val_wt_loss: 36.6932, train_grp_loss: [11.50131826 13.69527295 13.004701  ], val_grp_loss: [12.65294687 12.78475884 11.25384734], train_hist_grp_loss: [ 9.93707299 12.93825479 28.66599439], cur_train_grp_loss: [0.08847085 0.11508652 0.25499656], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6766, max_kl_dist_index: 0, max_train_grp_loss:  13.6953, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7848, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:41:10,005 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  112, train_loss:  12.6272, val_loss:  12.2312, grad_norm: 0.0075, live_grad: 0.0000, reward_err: 0.0105, 0.0186, 0.0012, KL_dist: 0.6767, 0.3240, 0.6756, param: [ 4.8607262   6.84858842  5.76600574 10.27371396], weights: [0.259214  0.2838619 0.4569241], train_wt_loss:  37.8815, val_wt_loss: 36.6937, train_grp_loss: [11.50141873 13.69525913 13.00457541], val_grp_loss: [12.65311078 12.78497335 11.25393776], train_hist_grp_loss: [10.02554467 13.05334112 28.92098852], cur_train_grp_loss: [0.08847168 0.11508633 0.25499414], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6767, max_kl_dist_index: 0, max_train_grp_loss:  13.6953, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7850, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:41:11,017 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  113, train_loss:  12.6272, val_loss:  12.2314, grad_norm: 0.0076, live_grad: 0.0000, reward_err: 0.0105, 0.0186, 0.0012, KL_dist: 0.6767, 0.3240, 0.6757, param: [ 4.86016385  6.84757256  5.7667403  10.274745  ], weights: [0.2585637  0.28337593 0.45806037], train_wt_loss:  37.8816, val_wt_loss: 36.6942, train_grp_loss: [11.50151182 13.6952547  13.00444755], val_grp_loss: [12.65326789 12.78519938 11.25402494], train_hist_grp_loss: [10.11401713 13.16842733 29.1759802 ], cur_train_grp_loss: [0.08847245 0.11508621 0.25499167], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6767, max_kl_dist_index: 0, max_train_grp_loss:  13.6953, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7852, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:41:12,049 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  114, train_loss:  12.6272, val_loss:  12.2315, grad_norm: 0.0076, live_grad: 0.0000, reward_err: 0.0107, 0.0186, 0.0013, KL_dist: 0.6767, 0.3240, 0.6757, param: [ 4.85959748  6.84655911  5.7674733  10.27578899], weights: [0.25791368 0.2828893  0.45919701], train_wt_loss:  37.8816, val_wt_loss: 36.6946, train_grp_loss: [11.5015975  13.69525968 13.00431741], val_grp_loss: [12.65341818 12.78543693 11.25410888], train_hist_grp_loss: [10.20249029 13.2835135  29.43096937], cur_train_grp_loss: [0.08847317 0.11508617 0.25498917], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6767, max_kl_dist_index: 0, max_train_grp_loss:  13.6953, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7854, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:41:13,130 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  115, train_loss:  12.6272, val_loss:  12.2317, grad_norm: 0.0077, live_grad: 0.0000, reward_err: 0.0107, 0.0186, 0.0013, KL_dist: 0.6767, 0.3241, 0.6757, param: [ 4.85902707  6.84554807  5.76820476 10.27684595], weights: [0.25726395 0.28240202 0.46033402], train_wt_loss:  37.8817, val_wt_loss: 36.6951, train_grp_loss: [11.50167576 13.69527407 13.004185  ], val_grp_loss: [12.65356164 12.78568603 11.25418958], train_hist_grp_loss: [10.29096412 13.39859972 29.68595598], cur_train_grp_loss: [0.08847383 0.11508622 0.25498662], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6767, max_kl_dist_index: 0, max_train_grp_loss:  13.6953, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7857, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:41:14,132 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  116, train_loss:  12.6272, val_loss:  12.2319, grad_norm: 0.0078, live_grad: 0.0000, reward_err: 0.0107, 0.0186, 0.0013, KL_dist: 0.6768, 0.3241, 0.6757, param: [ 4.85845262  6.84453941  5.76893465 10.27791592], weights: [0.25661451 0.2819141  0.46147138], train_wt_loss:  37.8817, val_wt_loss: 36.6956, train_grp_loss: [11.5017466  13.69529789 13.0040503 ], val_grp_loss: [12.65369827 12.7859467  11.25426704], train_hist_grp_loss: [10.37943855 13.51368605 29.94094   ], cur_train_grp_loss: [0.08847443 0.11508634 0.25498402], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6768, max_kl_dist_index: 0, max_train_grp_loss:  13.6953, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7859, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:41:15,160 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  117, train_loss:  12.6273, val_loss:  12.2320, grad_norm: 0.0079, live_grad: 0.0000, reward_err: 0.0105, 0.0186, 0.0013, KL_dist: 0.6768, 0.3241, 0.6758, param: [ 4.85787412  6.84353314  5.76966297 10.2789989 ], weights: [0.25596537 0.28142555 0.46260909], train_wt_loss:  37.8818, val_wt_loss: 36.6961, train_grp_loss: [11.50181001 13.69533116 13.00391332], val_grp_loss: [12.65382805 12.78621896 11.25434124], train_hist_grp_loss: [10.46791352 13.62877259 30.19592138], cur_train_grp_loss: [0.08847497 0.11508654 0.25498138], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6768, max_kl_dist_index: 0, max_train_grp_loss:  13.6953, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7862, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:41:16,170 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  118, train_loss:  12.6273, val_loss:  12.2322, grad_norm: 0.0079, live_grad: 0.0000, reward_err: 0.0105, 0.0186, 0.0013, KL_dist: 0.6768, 0.3241, 0.6758, param: [ 4.85729157  6.84252924  5.77038973 10.28009494], weights: [0.25531653 0.28093636 0.46374711], train_wt_loss:  37.8818, val_wt_loss: 36.6965, train_grp_loss: [11.50186598 13.69537389 13.00377405], val_grp_loss: [12.65395097 12.78650283 11.2544122 ], train_hist_grp_loss: [10.55638898 13.74385941 30.45090007], cur_train_grp_loss: [0.08847546 0.11508682 0.25497869], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6768, max_kl_dist_index: 0, max_train_grp_loss:  13.6954, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7865, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:41:17,187 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  119, train_loss:  12.6273, val_loss:  12.2323, grad_norm: 0.0080, live_grad: 0.0000, reward_err: 0.0105, 0.0186, 0.0013, KL_dist: 0.6769, 0.3241, 0.6758, param: [ 4.85670495  6.84152772  5.7711149  10.28120404], weights: [0.25466799 0.28044655 0.46488546], train_wt_loss:  37.8819, val_wt_loss: 36.6970, train_grp_loss: [11.5019145  13.6954261  13.00363249], val_grp_loss: [12.65406703 12.78679834 11.2544799 ], train_hist_grp_loss: [10.64486488 13.85894658 30.70587603], cur_train_grp_loss: [0.08847589 0.11508718 0.25497596], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6769, max_kl_dist_index: 0, max_train_grp_loss:  13.6954, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7868, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:41:18,222 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  120, train_loss:  12.6273, val_loss:  12.2325, grad_norm: 0.0081, live_grad: 0.0000, reward_err: 0.0105, 0.0186, 0.0013, KL_dist: 0.6769, 0.3242, 0.6759, param: [ 4.85611427  6.84052854  5.7718385  10.28232625], weights: [0.25401977 0.27995613 0.4660241 ], train_wt_loss:  37.8820, val_wt_loss: 36.6975, train_grp_loss: [11.50195555 13.6954878  13.00348864], val_grp_loss: [12.65417622 12.78710549 11.25454435], train_hist_grp_loss: [10.73334114 13.9740342  30.96084922], cur_train_grp_loss: [0.08847627 0.11508761 0.25497319], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6769, max_kl_dist_index: 0, max_train_grp_loss:  13.6955, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7871, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:41:19,273 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  121, train_loss:  12.6273, val_loss:  12.2327, grad_norm: 0.0082, live_grad: 0.0000, reward_err: 0.0105, 0.0186, 0.0013, KL_dist: 0.6769, 0.3242, 0.6759, param: [ 4.85551952  6.83953172  5.77256051 10.28346157], weights: [0.25337187 0.27946509 0.46716304], train_wt_loss:  37.8820, val_wt_loss: 36.6980, train_grp_loss: [11.50198914 13.69555902 13.00334248], val_grp_loss: [12.65427852 12.78742432 11.25460553], train_hist_grp_loss: [10.82181772 14.08912233 31.21581959], cur_train_grp_loss: [0.08847658 0.11508813 0.25497037], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6769, max_kl_dist_index: 0, max_train_grp_loss:  13.6956, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7874, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:41:20,288 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  122, train_loss:  12.6274, val_loss:  12.2328, grad_norm: 0.0082, live_grad: 0.0000, reward_err: 0.0105, 0.0186, 0.0013, KL_dist: 0.6770, 0.3242, 0.6759, param: [ 4.85492068  6.83853724  5.77328093 10.28461004], weights: [0.25272429 0.27897346 0.46830225], train_wt_loss:  37.8821, val_wt_loss: 36.6985, train_grp_loss: [11.50201524 13.69563976 13.00319402], val_grp_loss: [12.65437392 12.78775485 11.25466346], train_hist_grp_loss: [10.91029456 14.20421106 31.47078709], cur_train_grp_loss: [0.08847684 0.11508873 0.2549675 ], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6770, max_kl_dist_index: 0, max_train_grp_loss:  13.6956, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7878, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:41:21,307 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  123, train_loss:  12.6274, val_loss:  12.2330, grad_norm: 0.0083, live_grad: 0.0000, reward_err: 0.0105, 0.0186, 0.0013, KL_dist: 0.6770, 0.3242, 0.6760, param: [ 4.85431776  6.83754509  5.77399976 10.28577168], weights: [0.25207705 0.27848123 0.46944173], train_wt_loss:  37.8821, val_wt_loss: 36.6989, train_grp_loss: [11.50203385 13.69573003 13.00304326], val_grp_loss: [12.65446242 12.78809709 11.25471812], train_hist_grp_loss: [10.9987716  14.31930047 31.72575167], cur_train_grp_loss: [0.08847704 0.11508941 0.25496459], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6770, max_kl_dist_index: 0, max_train_grp_loss:  13.6957, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7881, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:41:22,345 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  124, train_loss:  12.6274, val_loss:  12.2331, grad_norm: 0.0084, live_grad: 0.0000, reward_err: 0.0105, 0.0186, 0.0013, KL_dist: 0.6770, 0.3243, 0.6760, param: [ 4.85371074  6.83655526  5.77471698 10.28694652], weights: [0.25143013 0.2779884  0.47058146], train_wt_loss:  37.8822, val_wt_loss: 36.6994, train_grp_loss: [11.50204497 13.69582987 13.00289018], val_grp_loss: [12.65454401 12.78845107 11.25476951], train_hist_grp_loss: [11.08724879 14.43439064 31.98071331], cur_train_grp_loss: [0.08847718 0.11509017 0.25496163], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6770, max_kl_dist_index: 0, max_train_grp_loss:  13.6958, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7885, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:41:23,368 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  125, train_loss:  12.6274, val_loss:  12.2333, grad_norm: 0.0085, live_grad: 0.0000, reward_err: 0.0105, 0.0186, 0.0013, KL_dist: 0.6771, 0.3243, 0.6761, param: [ 4.85309962  6.83556775  5.77543259 10.28813457], weights: [0.25078356 0.277495   0.47172144], train_wt_loss:  37.8822, val_wt_loss: 36.6999, train_grp_loss: [11.50204858 13.69593927 13.0027348 ], val_grp_loss: [12.65461868 12.78881681 11.25481764], train_hist_grp_loss: [11.17572606 14.54948165 32.23567194], cur_train_grp_loss: [0.08847727 0.11509101 0.25495863], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6771, max_kl_dist_index: 0, max_train_grp_loss:  13.6959, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7888, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:41:24,394 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  126, train_loss:  12.6274, val_loss:  12.2335, grad_norm: 0.0085, live_grad: 0.0000, reward_err: 0.0105, 0.0186, 0.0013, KL_dist: 0.6771, 0.3243, 0.6761, param: [ 4.8524844   6.83458254  5.77614659 10.28933587], weights: [0.25013733 0.27700103 0.47286164], train_wt_loss:  37.8823, val_wt_loss: 36.7004, train_grp_loss: [11.50204467 13.69605826 13.00257709], val_grp_loss: [12.65468642 12.78919433 11.25486249], train_hist_grp_loss: [11.26420335 14.66457357 32.49062752], cur_train_grp_loss: [0.0884773  0.11509193 0.25495558], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6771, max_kl_dist_index: 0, max_train_grp_loss:  13.6961, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7892, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:41:25,399 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  127, train_loss:  12.6274, val_loss:  12.2336, grad_norm: 0.0086, live_grad: 0.0000, reward_err: 0.0105, 0.0186, 0.0013, KL_dist: 0.6772, 0.3243, 0.6761, param: [ 4.85186506  6.83359962  5.77685898 10.29055043], weights: [0.24949146 0.27650648 0.47400206], train_wt_loss:  37.8823, val_wt_loss: 36.7009, train_grp_loss: [11.50203323 13.69618686 13.00241707], val_grp_loss: [12.65474722 12.78958364 11.25490407], train_hist_grp_loss: [11.35268062 14.7796665  32.74558001], cur_train_grp_loss: [0.08847727 0.11509293 0.25495249], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6772, max_kl_dist_index: 0, max_train_grp_loss:  13.6962, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7896, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:41:26,420 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  128, train_loss:  12.6275, val_loss:  12.2338, grad_norm: 0.0087, live_grad: 0.0000, reward_err: 0.0105, 0.0186, 0.0013, KL_dist: 0.6772, 0.3244, 0.6762, param: [ 4.8512416   6.83261899  5.77756974 10.29177828], weights: [0.24884594 0.27601138 0.47514268], train_wt_loss:  37.8824, val_wt_loss: 36.7014, train_grp_loss: [11.50201426 13.69632507 13.00225473], val_grp_loss: [12.65480107 12.78998478 11.25494237], train_hist_grp_loss: [11.4411578  14.89476051 33.00052937], cur_train_grp_loss: [0.08847718 0.11509401 0.25494935], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6772, max_kl_dist_index: 0, max_train_grp_loss:  13.6963, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7900, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2549, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:41:27,448 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  129, train_loss:  12.6275, val_loss:  12.2340, grad_norm: 0.0088, live_grad: 0.0000, reward_err: 0.0105, 0.0186, 0.0013, KL_dist: 0.6772, 0.3244, 0.6762, param: [ 4.85061402  6.83164064  5.77827887 10.29301945], weights: [0.24820079 0.27551571 0.4762835 ], train_wt_loss:  37.8825, val_wt_loss: 36.7019, train_grp_loss: [11.50198775 13.69647291 13.00209006], val_grp_loss: [12.65484796 12.79039776 11.2549774 ], train_hist_grp_loss: [11.52963483 15.00985568 33.25547554], cur_train_grp_loss: [0.08847703 0.11509517 0.25494617], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6772, max_kl_dist_index: 0, max_train_grp_loss:  13.6965, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7904, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2549, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:41:28,502 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  130, train_loss:  12.6275, val_loss:  12.2341, grad_norm: 0.0088, live_grad: 0.0000, reward_err: 0.0105, 0.0186, 0.0013, KL_dist: 0.6773, 0.3244, 0.6763, param: [ 4.84998231  6.83066455  5.77898637 10.29427395], weights: [0.247556   0.27501951 0.47742449], train_wt_loss:  37.8825, val_wt_loss: 36.7024, train_grp_loss: [11.50195368 13.69663041 13.00192307], val_grp_loss: [12.65488789 12.79082261 11.25500914], train_hist_grp_loss: [11.61811166 15.12495209 33.51041848], cur_train_grp_loss: [0.08847683 0.11509641 0.25494294], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6773, max_kl_dist_index: 0, max_train_grp_loss:  13.6966, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7908, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2549, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:41:29,542 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  131, train_loss:  12.6275, val_loss:  12.2343, grad_norm: 0.0089, live_grad: 0.0000, reward_err: 0.0105, 0.0186, 0.0013, KL_dist: 0.6773, 0.3244, 0.6763, param: [ 4.84934645  6.82969071  5.77969223 10.29554181], weights: [0.24691159 0.27452276 0.47856566], train_wt_loss:  37.8826, val_wt_loss: 36.7029, train_grp_loss: [11.50191206 13.69679757 13.00175374], val_grp_loss: [12.65492084 12.79125934 11.2550376 ], train_hist_grp_loss: [11.70658823 15.24004982 33.76535815], cur_train_grp_loss: [0.08847657 0.11509773 0.25493967], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6773, max_kl_dist_index: 0, max_train_grp_loss:  13.6968, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7913, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2549, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:41:30,569 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  132, train_loss:  12.6275, val_loss:  12.2345, grad_norm: 0.0090, live_grad: 0.0000, reward_err: 0.0105, 0.0186, 0.0013, KL_dist: 0.6773, 0.3245, 0.6763, param: [ 4.84870646  6.82871913  5.78039644 10.29682307], weights: [0.24626755 0.27402548 0.47970697], train_wt_loss:  37.8826, val_wt_loss: 36.7034, train_grp_loss: [11.50186286 13.69697441 13.00158208], val_grp_loss: [12.65494681 12.79170797 11.25506278], train_hist_grp_loss: [11.79506447 15.35514896 34.0202945 ], cur_train_grp_loss: [0.08847625 0.11509914 0.25493635], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6773, max_kl_dist_index: 0, max_train_grp_loss:  13.6970, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7917, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2549, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:41:31,603 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  133, train_loss:  12.6276, val_loss:  12.2346, grad_norm: 0.0091, live_grad: 0.0000, reward_err: 0.0105, 0.0186, 0.0013, KL_dist: 0.6774, 0.3245, 0.6764, param: [ 4.8480623   6.82774978  5.78109901 10.29811773], weights: [0.2456239  0.27352767 0.48084843], train_wt_loss:  37.8827, val_wt_loss: 36.7039, train_grp_loss: [11.50180609 13.69716094 13.00140808], val_grp_loss: [12.65496578 12.79216854 11.25508468], train_hist_grp_loss: [11.88354034 15.47024959 34.27522748], cur_train_grp_loss: [0.08847587 0.11510063 0.25493298], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6774, max_kl_dist_index: 0, max_train_grp_loss:  13.6972, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7922, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2549, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:41:32,627 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  134, train_loss:  12.6276, val_loss:  12.2348, grad_norm: 0.0092, live_grad: 0.0000, reward_err: 0.0105, 0.0186, 0.0013, KL_dist: 0.6774, 0.3245, 0.6764, param: [ 4.847414    6.82678265  5.78179992 10.29942582], weights: [0.24498064 0.27302934 0.48199002], train_wt_loss:  37.8827, val_wt_loss: 36.7044, train_grp_loss: [11.50174173 13.69735719 13.00123174], val_grp_loss: [12.65497776 12.79264105 11.25510329], train_hist_grp_loss: [11.97201577 15.58535178 34.53015705], cur_train_grp_loss: [0.08847543 0.11510219 0.25492957], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6774, max_kl_dist_index: 0, max_train_grp_loss:  13.6974, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7926, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2549, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:41:33,655 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  135, train_loss:  12.6276, val_loss:  12.2350, grad_norm: 0.0092, live_grad: 0.0000, reward_err: 0.0105, 0.0186, 0.0013, KL_dist: 0.6775, 0.3246, 0.6765, param: [ 4.84676152  6.82581775  5.78249917 10.30074737], weights: [0.24433777 0.2725305  0.48313173], train_wt_loss:  37.8828, val_wt_loss: 36.7049, train_grp_loss: [11.50166978 13.69756316 13.00105305], val_grp_loss: [12.65498273 12.79312553 11.2551186 ], train_hist_grp_loss: [12.06049071 15.70045562 34.78508316], cur_train_grp_loss: [0.08847494 0.11510384 0.25492611], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6775, max_kl_dist_index: 0, max_train_grp_loss:  13.6976, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7931, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2549, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:41:34,697 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  136, train_loss:  12.6276, val_loss:  12.2351, grad_norm: 0.0093, live_grad: 0.0000, reward_err: 0.0105, 0.0186, 0.0013, KL_dist: 0.6775, 0.3246, 0.6765, param: [ 4.84610488  6.82485505  5.78319675 10.3020824 ], weights: [0.24369531 0.27203115 0.48427354], train_wt_loss:  37.8829, val_wt_loss: 36.7054, train_grp_loss: [11.50159022 13.69777888 13.00087202], val_grp_loss: [12.65498068 12.793622   11.25513063], train_hist_grp_loss: [12.14896509 15.81556119 35.04000577], cur_train_grp_loss: [0.08847438 0.11510557 0.25492261], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6775, max_kl_dist_index: 0, max_train_grp_loss:  13.6978, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7936, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2549, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:41:35,728 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  137, train_loss:  12.6276, val_loss:  12.2353, grad_norm: 0.0094, live_grad: 0.0000, reward_err: 0.0105, 0.0186, 0.0013, KL_dist: 0.6776, 0.3246, 0.6766, param: [ 4.84544405  6.82389454  5.78389266 10.30343093], weights: [0.24305325 0.2715313  0.48541545], train_wt_loss:  37.8829, val_wt_loss: 36.7059, train_grp_loss: [11.50150305 13.69800435 13.00068864], val_grp_loss: [12.65497161 12.79413048 11.25513937], train_hist_grp_loss: [12.23743886 15.93066858 35.29492483], cur_train_grp_loss: [0.08847377 0.11510739 0.25491906], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6776, max_kl_dist_index: 0, max_train_grp_loss:  13.6980, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7941, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2549, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:41:36,756 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  138, train_loss:  12.6277, val_loss:  12.2355, grad_norm: 0.0095, live_grad: 0.0000, reward_err: 0.0105, 0.0186, 0.0013, KL_dist: 0.6776, 0.3247, 0.6766, param: [ 4.84477905  6.82293622  5.7845869  10.30479298], weights: [0.2424116  0.27103097 0.48655744], train_wt_loss:  37.8830, val_wt_loss: 36.7064, train_grp_loss: [11.50140827 13.6982396  13.00050291], val_grp_loss: [12.6549555  12.794651   11.25514481], train_hist_grp_loss: [12.32591196 16.04577786 35.54984029], cur_train_grp_loss: [0.0884731  0.11510928 0.25491546], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6776, max_kl_dist_index: 0, max_train_grp_loss:  13.6982, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7947, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2549, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:41:37,747 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  139, train_loss:  12.6277, val_loss:  12.2356, grad_norm: 0.0095, live_grad: 0.0000, reward_err: 0.0105, 0.0186, 0.0013, KL_dist: 0.6776, 0.3247, 0.6767, param: [ 4.84410985  6.82198008  5.78527945 10.30616859], weights: [0.24177037 0.27053014 0.48769949], train_wt_loss:  37.8831, val_wt_loss: 36.7069, train_grp_loss: [11.50130586 13.69848464 13.00031482], val_grp_loss: [12.65493235 12.79518357 11.25514696], train_hist_grp_loss: [12.41438433 16.16088912 35.80475212], cur_train_grp_loss: [0.08847237 0.11511126 0.25491182], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6776, max_kl_dist_index: 0, max_train_grp_loss:  13.6985, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7952, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2549, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:41:38,772 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  140, train_loss:  12.6277, val_loss:  12.2358, grad_norm: 0.0096, live_grad: 0.0000, reward_err: 0.0105, 0.0186, 0.0013, KL_dist: 0.6777, 0.3247, 0.6767, param: [ 4.84343646  6.8210261   5.78597031 10.30755777], weights: [0.24112956 0.27002884 0.4888416 ], train_wt_loss:  37.8831, val_wt_loss: 36.7075, train_grp_loss: [11.50119581 13.69873948 13.00012438], val_grp_loss: [12.65490216 12.79572821 11.25514582], train_hist_grp_loss: [12.50285592 16.27600243 36.05966025], cur_train_grp_loss: [0.08847158 0.11511332 0.25490813], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6777, max_kl_dist_index: 0, max_train_grp_loss:  13.6987, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7957, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2549, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:41:39,814 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  141, train_loss:  12.6277, val_loss:  12.2360, grad_norm: 0.0097, live_grad: 0.0000, reward_err: 0.0105, 0.0186, 0.0013, KL_dist: 0.6777, 0.3247, 0.6768, param: [ 4.84275886  6.82007428  5.78665947 10.30896055], weights: [0.24048918 0.26952707 0.48998375], train_wt_loss:  37.8832, val_wt_loss: 36.7080, train_grp_loss: [11.50107812 13.69900414 12.99993157], val_grp_loss: [12.6548649  12.79628496 11.25514138], train_hist_grp_loss: [12.59132665 16.39111789 36.31456465], cur_train_grp_loss: [0.08847074 0.11511546 0.2549044 ], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6777, max_kl_dist_index: 0, max_train_grp_loss:  13.6990, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7963, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2549, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:41:40,819 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  142, train_loss:  12.6277, val_loss:  12.2362, grad_norm: 0.0098, live_grad: 0.0000, reward_err: 0.0105, 0.0186, 0.0013, KL_dist: 0.6778, 0.3248, 0.6768, param: [ 4.84207706  6.8191246   5.78734694 10.31037694], weights: [0.23984923 0.26902483 0.49112594], train_wt_loss:  37.8832, val_wt_loss: 36.7085, train_grp_loss: [11.50095279 13.69927864 12.99973641], val_grp_loss: [12.65482058 12.79685382 11.25513364], train_hist_grp_loss: [12.67979649 16.50623557 36.56946527], cur_train_grp_loss: [0.08846983 0.11511768 0.25490062], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6778, max_kl_dist_index: 0, max_train_grp_loss:  13.6993, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7969, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2549, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:41:41,839 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  143, train_loss:  12.6278, val_loss:  12.2363, grad_norm: 0.0099, live_grad: 0.0000, reward_err: 0.0105, 0.0186, 0.0013, KL_dist: 0.6778, 0.3248, 0.6769, param: [ 4.84139104  6.81817705  5.7880327  10.31180698], weights: [0.23920972 0.26852214 0.49226814], train_wt_loss:  37.8833, val_wt_loss: 36.7090, train_grp_loss: [11.50081979 13.699563   12.99953887], val_grp_loss: [12.65476919 12.79743482 11.2551226 ], train_hist_grp_loss: [12.76826535 16.62135556 36.82436206], cur_train_grp_loss: [0.08846887 0.11511999 0.25489679], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6778, max_kl_dist_index: 0, max_train_grp_loss:  13.6996, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7974, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2549, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:41:42,874 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  144, train_loss:  12.6278, val_loss:  12.2365, grad_norm: 0.0099, live_grad: 0.0000, reward_err: 0.0105, 0.0186, 0.0013, KL_dist: 0.6779, 0.3248, 0.6769, param: [ 4.8407008   6.81723163  5.78871676 10.31325068], weights: [0.23857066 0.268019   0.49341035], train_wt_loss:  37.8834, val_wt_loss: 36.7095, train_grp_loss: [11.50067913 13.69985722 12.99933897], val_grp_loss: [12.65471072 12.79802798 11.25510826], train_hist_grp_loss: [12.8567332  16.73647794 37.07925498], cur_train_grp_loss: [0.08846784 0.11512238 0.25489292], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6779, max_kl_dist_index: 0, max_train_grp_loss:  13.6999, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7980, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2549, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:41:43,929 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  145, train_loss:  12.6278, val_loss:  12.2367, grad_norm: 0.0100, live_grad: 0.0000, reward_err: 0.0105, 0.0186, 0.0013, KL_dist: 0.6779, 0.3249, 0.6770, param: [ 4.84000633  6.81628831  5.78939909 10.31470807], weights: [0.23793204 0.26751541 0.49455255], train_wt_loss:  37.8834, val_wt_loss: 36.7101, train_grp_loss: [11.5005308  13.70016132 12.9991367 ], val_grp_loss: [12.65464516 12.79863332 11.25509063], train_hist_grp_loss: [12.94519996 16.85160279 37.33414398], cur_train_grp_loss: [0.08846676 0.11512485 0.254889  ], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6779, max_kl_dist_index: 0, max_train_grp_loss:  13.7002, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7986, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2549, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:41:44,961 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  146, train_loss:  12.6278, val_loss:  12.2369, grad_norm: 0.0101, live_grad: 0.0000, reward_err: 0.0105, 0.0186, 0.0013, KL_dist: 0.6780, 0.3249, 0.6770, param: [ 4.83930762  6.8153471   5.7900797  10.31617917], weights: [0.23729388 0.26701139 0.49569473], train_wt_loss:  37.8835, val_wt_loss: 36.7106, train_grp_loss: [11.50037479 13.70047532 12.99893205], val_grp_loss: [12.65457251 12.79925086 11.25506969], train_hist_grp_loss: [13.03366558 16.96673019 37.58902901], cur_train_grp_loss: [0.08846562 0.11512741 0.25488503], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6780, max_kl_dist_index: 0, max_train_grp_loss:  13.7005, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7993, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2549, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:41:45,977 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  147, train_loss:  12.6279, val_loss:  12.2370, grad_norm: 0.0102, live_grad: 0.0000, reward_err: 0.0105, 0.0186, 0.0013, KL_dist: 0.6780, 0.3249, 0.6771, param: [ 4.83860467  6.81440797  5.79075859 10.317664  ], weights: [0.23665618 0.26650694 0.49683688], train_wt_loss:  37.8836, val_wt_loss: 36.7111, train_grp_loss: [11.5002111  13.70079924 12.99872503], val_grp_loss: [12.65449275 12.79988063 11.25504545], train_hist_grp_loss: [13.12213    17.08186024 37.84391003], cur_train_grp_loss: [0.08846442 0.11513004 0.25488102], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6780, max_kl_dist_index: 0, max_train_grp_loss:  13.7008, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7999, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2549, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:41:47,027 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  148, train_loss:  12.6279, val_loss:  12.2372, grad_norm: 0.0103, live_grad: 0.0000, reward_err: 0.0105, 0.0186, 0.0013, KL_dist: 0.6781, 0.3250, 0.6771, param: [ 4.83789748  6.81347092  5.79143574 10.31916259], weights: [0.23601894 0.26600206 0.49797899], train_wt_loss:  37.8836, val_wt_loss: 36.7116, train_grp_loss: [11.50003971 13.70113309 12.99851563], val_grp_loss: [12.65440589 12.80052265 11.25501791], train_hist_grp_loss: [13.21059317 17.19699301 38.09878699], cur_train_grp_loss: [0.08846316 0.11513277 0.25487696], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6781, max_kl_dist_index: 0, max_train_grp_loss:  13.7011, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8005, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2549, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:41:48,056 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  149, train_loss:  12.6279, val_loss:  12.2374, grad_norm: 0.0103, live_grad: 0.0000, reward_err: 0.0105, 0.0186, 0.0013, KL_dist: 0.6781, 0.3250, 0.6772, param: [ 4.83718603  6.81253594  5.79211115 10.32067495], weights: [0.23538218 0.26549678 0.49912104], train_wt_loss:  37.8837, val_wt_loss: 36.7122, train_grp_loss: [11.49986062 13.70147689 12.99830385], val_grp_loss: [12.6543119  12.80117693 11.25498706], train_hist_grp_loss: [13.29905501 17.31212858 38.35365985], cur_train_grp_loss: [0.08846184 0.11513557 0.25487286], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6781, max_kl_dist_index: 0, max_train_grp_loss:  13.7015, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8012, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2549, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:41:49,102 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  150, train_loss:  12.6279, val_loss:  12.2376, grad_norm: 0.0104, live_grad: 0.0000, reward_err: 0.0105, 0.0186, 0.0013, KL_dist: 0.6782, 0.3250, 0.6773, param: [ 4.83647033  6.81160301  5.79278481 10.32220112], weights: [0.23474589 0.26499108 0.50026303], train_wt_loss:  37.8838, val_wt_loss: 36.7127, train_grp_loss: [11.49967383 13.70183065 12.99808968], val_grp_loss: [12.6542108  12.8018435  11.25495292], train_hist_grp_loss: [13.38751548 17.42726704 38.60852855], cur_train_grp_loss: [0.08846047 0.11513846 0.2548687 ], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6782, max_kl_dist_index: 0, max_train_grp_loss:  13.7018, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8018, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2549, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:41:50,110 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  151, train_loss:  12.6279, val_loss:  12.2377, grad_norm: 0.0105, live_grad: 0.0000, reward_err: 0.0105, 0.0186, 0.0013, KL_dist: 0.6782, 0.3251, 0.6773, param: [ 4.83575036  6.81067213  5.79345673 10.32374111], weights: [0.23411009 0.26448498 0.50140493], train_wt_loss:  37.8838, val_wt_loss: 36.7132, train_grp_loss: [11.49947932 13.70219438 12.99787313], val_grp_loss: [12.65410256 12.80252238 11.25491547], train_hist_grp_loss: [13.47597451 17.54240847 38.86339306], cur_train_grp_loss: [0.08845903 0.11514143 0.2548645 ], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6782, max_kl_dist_index: 0, max_train_grp_loss:  13.7022, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8025, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2549, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:41:51,115 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  152, train_loss:  12.6280, val_loss:  12.2379, grad_norm: 0.0106, live_grad: 0.0000, reward_err: 0.0105, 0.0186, 0.0013, KL_dist: 0.6783, 0.3251, 0.6774, param: [ 4.83502611  6.80974327  5.79412689 10.32529494], weights: [0.23347477 0.26397849 0.50254674], train_wt_loss:  37.8839, val_wt_loss: 36.7138, train_grp_loss: [11.49927709 13.70256811 12.99765419], val_grp_loss: [12.65398718 12.80321359 11.25487471], train_hist_grp_loss: [13.56443204 17.65755296 39.11825331], cur_train_grp_loss: [0.08845753 0.11514449 0.25486026], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6783, max_kl_dist_index: 0, max_train_grp_loss:  13.7026, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8032, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2549, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:41:52,131 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  153, train_loss:  12.6280, val_loss:  12.2381, grad_norm: 0.0107, live_grad: 0.0000, reward_err: 0.0105, 0.0186, 0.0013, KL_dist: 0.6783, 0.3252, 0.6774, param: [ 4.83429759  6.80881644  5.79479528 10.32686264], weights: [0.23283994 0.26347162 0.50368844], train_wt_loss:  37.8840, val_wt_loss: 36.7143, train_grp_loss: [11.49906713 13.70295185 12.99743286], val_grp_loss: [12.65386466 12.80391715 11.25483066], train_hist_grp_loss: [13.65288802 17.7727006  39.37310928], cur_train_grp_loss: [0.08845598 0.11514763 0.25485596], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6783, max_kl_dist_index: 0, max_train_grp_loss:  13.7030, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8039, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2549, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:41:53,175 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  154, train_loss:  12.6280, val_loss:  12.2383, grad_norm: 0.0107, live_grad: 0.0000, reward_err: 0.0108, 0.0186, 0.0014, KL_dist: 0.6784, 0.3252, 0.6775, param: [ 4.83356478  6.80789161  5.79546191 10.32844423], weights: [0.23220561 0.26296436 0.50483003], train_wt_loss:  37.8841, val_wt_loss: 36.7149, train_grp_loss: [11.49884944 13.70334561 12.99720914], val_grp_loss: [12.65373499 12.80463309 11.2547833 ], train_hist_grp_loss: [13.74134238 17.88785145 39.6279609 ], cur_train_grp_loss: [0.08845436 0.11515086 0.25485162], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6784, max_kl_dist_index: 0, max_train_grp_loss:  13.7033, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8046, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2549, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:41:54,196 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  155, train_loss:  12.6280, val_loss:  12.2385, grad_norm: 0.0108, live_grad: 0.0000, reward_err: 0.0106, 0.0186, 0.0015, KL_dist: 0.6784, 0.3252, 0.6776, param: [ 4.83282768  6.80696878  5.79612676 10.33003973], weights: [0.23157179 0.26245673 0.50597148], train_wt_loss:  37.8841, val_wt_loss: 36.7154, train_grp_loss: [11.49862401 13.70374942 12.99698302], val_grp_loss: [12.65359816 12.80536142 11.25473264], train_hist_grp_loss: [13.82979507 18.00300562 39.88280814], cur_train_grp_loss: [0.08845269 0.11515416 0.25484724], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6784, max_kl_dist_index: 0, max_train_grp_loss:  13.7037, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8054, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2548, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:41:55,225 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  156, train_loss:  12.6281, val_loss:  12.2386, grad_norm: 0.0109, live_grad: 0.0000, reward_err: 0.0106, 0.0186, 0.0015, KL_dist: 0.6785, 0.3253, 0.6776, param: [ 4.83208629  6.80604794  5.79678983 10.33164916], weights: [0.23093847 0.26194874 0.50711279], train_wt_loss:  37.8842, val_wt_loss: 36.7159, train_grp_loss: [11.49839084 13.70416328 12.99675451], val_grp_loss: [12.65345417 12.80610216 11.25467867], train_hist_grp_loss: [13.91824602 18.11816317 40.13765095], cur_train_grp_loss: [0.08845095 0.11515756 0.2548428 ], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6785, max_kl_dist_index: 0, max_train_grp_loss:  13.7042, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8061, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2548, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:41:56,235 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  157, train_loss:  12.6281, val_loss:  12.2388, grad_norm: 0.0110, live_grad: 0.0000, reward_err: 0.0106, 0.0186, 0.0015, KL_dist: 0.6785, 0.3253, 0.6777, param: [ 4.83134059  6.80512906  5.79745112 10.33327255], weights: [0.23030567 0.26144038 0.50825395], train_wt_loss:  37.8843, val_wt_loss: 36.7165, train_grp_loss: [11.49814991 13.70458721 12.99652359], val_grp_loss: [12.653303   12.80685535 11.2546214 ], train_hist_grp_loss: [14.00669518 18.23332421 40.39248927], cur_train_grp_loss: [0.08844916 0.11516104 0.25483832], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6785, max_kl_dist_index: 0, max_train_grp_loss:  13.7046, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8069, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2548, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:41:57,248 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  158, train_loss:  12.6281, val_loss:  12.2390, grad_norm: 0.0111, live_grad: 0.0000, reward_err: 0.0104, 0.0186, 0.0015, KL_dist: 0.6786, 0.3253, 0.6778, param: [ 4.83059058  6.80421215  5.79811061 10.33490991], weights: [0.22967338 0.26093168 0.50939494], train_wt_loss:  37.8844, val_wt_loss: 36.7170, train_grp_loss: [11.49790123 13.70502123 12.99629028], val_grp_loss: [12.65314466 12.80762099 11.25456083], train_hist_grp_loss: [14.09514249 18.34848881 40.64732306], cur_train_grp_loss: [0.08844731 0.1151646  0.2548338 ], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6786, max_kl_dist_index: 0, max_train_grp_loss:  13.7050, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8076, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2548, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:41:58,258 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  159, train_loss:  12.6281, val_loss:  12.2392, grad_norm: 0.0112, live_grad: 0.0000, reward_err: 0.0104, 0.0186, 0.0015, KL_dist: 0.6786, 0.3254, 0.6778, param: [ 4.82983626  6.80329718  5.79876831 10.33656127], weights: [0.22904162 0.26042263 0.51053575], train_wt_loss:  37.8844, val_wt_loss: 36.7176, train_grp_loss: [11.49764478 13.70546535 12.99605456], val_grp_loss: [12.65297914 12.80839911 11.25449696], train_hist_grp_loss: [14.18358788 18.46365705 40.90215229], cur_train_grp_loss: [0.08844539 0.11516825 0.25482922], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6786, max_kl_dist_index: 0, max_train_grp_loss:  13.7055, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8084, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2548, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:41:59,292 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  160, train_loss:  12.6282, val_loss:  12.2394, grad_norm: 0.0112, live_grad: 0.0000, reward_err: 0.0104, 0.0186, 0.0015, KL_dist: 0.6787, 0.3254, 0.6779, param: [ 4.82907761  6.80238415  5.7994242  10.33822666], weights: [0.22841039 0.25991324 0.51167637], train_wt_loss:  37.8845, val_wt_loss: 36.7181, train_grp_loss: [11.49738056 13.70591959 12.99581644], val_grp_loss: [12.65280642 12.80918973 11.25442979], train_hist_grp_loss: [14.2720313  18.57882903 41.15697689], cur_train_grp_loss: [0.08844342 0.11517198 0.2548246 ], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6787, max_kl_dist_index: 0, max_train_grp_loss:  13.7059, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8092, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2548, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:42:00,288 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  161, train_loss:  12.6282, val_loss:  12.2396, grad_norm: 0.0113, live_grad: 0.0000, reward_err: 0.0104, 0.0186, 0.0015, KL_dist: 0.6787, 0.3255, 0.6780, param: [ 4.82831464  6.80147305  5.80007828 10.33990608], weights: [0.22777969 0.25940353 0.51281678], train_wt_loss:  37.8846, val_wt_loss: 36.7187, train_grp_loss: [11.49710857 13.70638397 12.99557591], val_grp_loss: [12.65262651 12.80999287 11.25435931], train_hist_grp_loss: [14.36047269 18.69400483 41.41179682], cur_train_grp_loss: [0.08844139 0.11517579 0.25481993], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6787, max_kl_dist_index: 0, max_train_grp_loss:  13.7064, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8100, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2548, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:42:01,326 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  162, train_loss:  12.6282, val_loss:  12.2397, grad_norm: 0.0114, live_grad: 0.0000, reward_err: 0.0104, 0.0186, 0.0015, KL_dist: 0.6788, 0.3255, 0.6780, param: [ 4.82754734  6.80056385  5.80073055 10.34159957], weights: [0.22714954 0.25889349 0.51395698], train_wt_loss:  37.8847, val_wt_loss: 36.7192, train_grp_loss: [11.4968288  13.7068585  12.99533297], val_grp_loss: [12.6524394  12.81080856 11.25428554], train_hist_grp_loss: [14.44891199 18.80918452 41.66661203], cur_train_grp_loss: [0.0884393  0.1151797  0.25481521], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6788, max_kl_dist_index: 0, max_train_grp_loss:  13.7069, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8108, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2548, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:42:02,355 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  163, train_loss:  12.6282, val_loss:  12.2399, grad_norm: 0.0115, live_grad: 0.0000, reward_err: 0.0104, 0.0186, 0.0015, KL_dist: 0.6789, 0.3255, 0.6781, param: [ 4.82677569  6.79965655  5.801381   10.34330713], weights: [0.22651993 0.25838313 0.51509694], train_wt_loss:  37.8847, val_wt_loss: 36.7198, train_grp_loss: [11.49654124 13.70734319 12.99508762], val_grp_loss: [12.65224508 12.81163681 11.25420846], train_hist_grp_loss: [14.53734913 18.92436821 41.92142248], cur_train_grp_loss: [0.08843714 0.11518368 0.25481045], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6789, max_kl_dist_index: 0, max_train_grp_loss:  13.7073, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8116, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2548, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:42:03,418 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  164, train_loss:  12.6283, val_loss:  12.2401, grad_norm: 0.0116, live_grad: 0.0000, reward_err: 0.0104, 0.0186, 0.0015, KL_dist: 0.6789, 0.3256, 0.6782, param: [ 4.8259997   6.79875113  5.80202962 10.34502881], weights: [0.22589087 0.25787247 0.51623667], train_wt_loss:  37.8848, val_wt_loss: 36.7204, train_grp_loss: [11.49624589 13.70783807 12.99483986], val_grp_loss: [12.65204355 12.81247765 11.25412809], train_hist_grp_loss: [14.62578407 19.03955597 42.17622812], cur_train_grp_loss: [0.08843493 0.11518776 0.25480564], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6789, max_kl_dist_index: 0, max_train_grp_loss:  13.7078, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8125, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2548, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:42:04,431 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  165, train_loss:  12.6283, val_loss:  12.2403, grad_norm: 0.0117, live_grad: 0.0000, reward_err: 0.0104, 0.0186, 0.0015, KL_dist: 0.6790, 0.3256, 0.6783, param: [ 4.82521936  6.79784759  5.8026764  10.34676461], weights: [0.22526236 0.2573615  0.51737614], train_wt_loss:  37.8849, val_wt_loss: 36.7209, train_grp_loss: [11.49594275 13.70834314 12.99458968], val_grp_loss: [12.6518348  12.8133311  11.25404442], train_hist_grp_loss: [14.71421673 19.15474788 42.4310289 ], cur_train_grp_loss: [0.08843266 0.11519192 0.25480078], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6790, max_kl_dist_index: 0, max_train_grp_loss:  13.7083, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8133, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2548, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:42:05,473 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  166, train_loss:  12.6283, val_loss:  12.2405, grad_norm: 0.0117, live_grad: 0.0000, reward_err: 0.0104, 0.0186, 0.0015, KL_dist: 0.6790, 0.3257, 0.6783, param: [ 4.82443466  6.7969459   5.80332135 10.34851455], weights: [0.22463442 0.25685024 0.51851534], train_wt_loss:  37.8850, val_wt_loss: 36.7215, train_grp_loss: [11.4956318  13.70885843 12.99433708], val_grp_loss: [12.65161882 12.81419717 11.25395745], train_hist_grp_loss: [14.80264706 19.26994404 42.68582478], cur_train_grp_loss: [0.08843033 0.11519616 0.25479588], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6790, max_kl_dist_index: 0, max_train_grp_loss:  13.7089, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8142, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2548, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:42:06,488 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  167, train_loss:  12.6284, val_loss:  12.2407, grad_norm: 0.0118, live_grad: 0.0000, reward_err: 0.0104, 0.0186, 0.0015, KL_dist: 0.6791, 0.3257, 0.6784, param: [ 4.82364559  6.79604606  5.80396445 10.35027867], weights: [0.22400704 0.25633869 0.51965427], train_wt_loss:  37.8851, val_wt_loss: 36.7221, train_grp_loss: [11.49531304 13.70938394 12.99408207], val_grp_loss: [12.65139562 12.81507589 11.25386719], train_hist_grp_loss: [14.89107499 19.38514454 42.9406157 ], cur_train_grp_loss: [0.08842794 0.11520049 0.25479092], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6791, max_kl_dist_index: 0, max_train_grp_loss:  13.7094, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8151, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2548, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:42:07,506 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  168, train_loss:  12.6284, val_loss:  12.2409, grad_norm: 0.0119, live_grad: 0.0000, reward_err: 0.0104, 0.0186, 0.0015, KL_dist: 0.6792, 0.3257, 0.6785, param: [ 4.82285216  6.79514805  5.80460569 10.35205697], weights: [0.22338024 0.25582686 0.5207929 ], train_wt_loss:  37.8851, val_wt_loss: 36.7226, train_grp_loss: [11.49498648 13.7099197  12.99382464], val_grp_loss: [12.65116518 12.81596729 11.25377364], train_hist_grp_loss: [14.97950048 19.50034944 43.19540162], cur_train_grp_loss: [0.08842548 0.11520491 0.25478592], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6792, max_kl_dist_index: 0, max_train_grp_loss:  13.7099, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8160, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2548, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:42:08,525 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  169, train_loss:  12.6284, val_loss:  12.2411, grad_norm: 0.0120, live_grad: 0.0000, reward_err: 0.0104, 0.0186, 0.0015, KL_dist: 0.6792, 0.3258, 0.6785, param: [ 4.82205435  6.79425187  5.80524509 10.35384948], weights: [0.22275401 0.25531476 0.52193123], train_wt_loss:  37.8852, val_wt_loss: 36.7232, train_grp_loss: [11.4946521  13.71046572 12.99356478], val_grp_loss: [12.6509275  12.81687138 11.25367679], train_hist_grp_loss: [15.06792345 19.61555885 43.4501825 ], cur_train_grp_loss: [0.08842297 0.11520941 0.25478088], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6792, max_kl_dist_index: 0, max_train_grp_loss:  13.7105, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8169, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2548, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:42:09,539 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  170, train_loss:  12.6284, val_loss:  12.2413, grad_norm: 0.0121, live_grad: 0.0000, reward_err: 0.0104, 0.0186, 0.0015, KL_dist: 0.6793, 0.3258, 0.6786, param: [ 4.82125216  6.79335749  5.80588261 10.35565622], weights: [0.22212836 0.25480239 0.52306925], train_wt_loss:  37.8853, val_wt_loss: 36.7238, train_grp_loss: [11.49430989 13.71102202 12.99330251], val_grp_loss: [12.65068257 12.81778817 11.25357665], train_hist_grp_loss: [15.15634385 19.73077285 43.70495828], cur_train_grp_loss: [0.0884204  0.115214   0.25477578], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6793, max_kl_dist_index: 0, max_train_grp_loss:  13.7110, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8178, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2548, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:42:10,571 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  171, train_loss:  12.6285, val_loss:  12.2415, grad_norm: 0.0122, live_grad: 0.0000, reward_err: 0.0104, 0.0186, 0.0015, KL_dist: 0.6793, 0.3259, 0.6787, param: [ 4.82044558  6.7924649   5.80651827 10.35747722], weights: [0.2215033  0.25428976 0.52420694], train_wt_loss:  37.8854, val_wt_loss: 36.7244, train_grp_loss: [11.49395987 13.7115886  12.9930378 ], val_grp_loss: [12.65043039 12.81871771 11.25347322], train_hist_grp_loss: [15.24476162 19.84599152 43.95972892], cur_train_grp_loss: [0.08841777 0.11521867 0.25477064], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6793, max_kl_dist_index: 0, max_train_grp_loss:  13.7116, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8187, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2548, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:42:11,598 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  172, train_loss:  12.6285, val_loss:  12.2416, grad_norm: 0.0123, live_grad: 0.0000, reward_err: 0.0104, 0.0186, 0.0015, KL_dist: 0.6794, 0.3259, 0.6788, param: [ 4.8196346   6.79157409  5.80715205 10.35931248], weights: [0.22087884 0.25377688 0.52534429], train_wt_loss:  37.8855, val_wt_loss: 36.7249, train_grp_loss: [11.49360201 13.71216549 12.99277068], val_grp_loss: [12.65017096 12.81966    11.2533665 ], train_hist_grp_loss: [15.3331767  19.96121496 44.21449436], cur_train_grp_loss: [0.08841508 0.11522343 0.25476545], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6794, max_kl_dist_index: 0, max_train_grp_loss:  13.7122, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8197, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2548, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:42:12,638 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  173, train_loss:  12.6285, val_loss:  12.2418, grad_norm: 0.0123, live_grad: 0.0000, reward_err: 0.0104, 0.0186, 0.0015, KL_dist: 0.6795, 0.3260, 0.6789, param: [ 4.81881923  6.79068505  5.80778395 10.36116203], weights: [0.22025497 0.25326375 0.52648128], train_wt_loss:  37.8856, val_wt_loss: 36.7255, train_grp_loss: [11.49323632 13.71275271 12.99250112], val_grp_loss: [12.64990427 12.82061506 11.2532565 ], train_hist_grp_loss: [15.42158902 20.07644324 44.46925457], cur_train_grp_loss: [0.08841232 0.11522828 0.25476021], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6795, max_kl_dist_index: 0, max_train_grp_loss:  13.7128, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8206, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2548, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:42:13,682 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  174, train_loss:  12.6285, val_loss:  12.2420, grad_norm: 0.0124, live_grad: 0.0000, reward_err: 0.0104, 0.0186, 0.0015, KL_dist: 0.6795, 0.3260, 0.6789, param: [ 4.81799946  6.78979776  5.80841396 10.36302589], weights: [0.2196317  0.25275039 0.52761792], train_wt_loss:  37.8856, val_wt_loss: 36.7261, train_grp_loss: [11.49286279 13.71335026 12.99222914], val_grp_loss: [12.64963031 12.82158293 11.25314321], train_hist_grp_loss: [15.50999853 20.19167645 44.7240095 ], cur_train_grp_loss: [0.08840951 0.11523322 0.25475492], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6795, max_kl_dist_index: 0, max_train_grp_loss:  13.7134, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8216, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2548, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:42:14,686 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  175, train_loss:  12.6286, val_loss:  12.2422, grad_norm: 0.0125, live_grad: 0.0000, reward_err: 0.0104, 0.0186, 0.0015, KL_dist: 0.6796, 0.3260, 0.6790, param: [ 4.81717527  6.78891221  5.80904208 10.36490409], weights: [0.21900904 0.25223679 0.52875417], train_wt_loss:  37.8857, val_wt_loss: 36.7267, train_grp_loss: [11.49248141 13.71395817 12.99195472], val_grp_loss: [12.64934909 12.82256361 11.25302664], train_hist_grp_loss: [15.59840517 20.30691469 44.97875909], cur_train_grp_loss: [0.08840664 0.11523824 0.25474959], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6796, max_kl_dist_index: 0, max_train_grp_loss:  13.7140, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8226, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2547, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:42:15,709 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  176, train_loss:  12.6286, val_loss:  12.2424, grad_norm: 0.0126, live_grad: 0.0000, reward_err: 0.0104, 0.0186, 0.0015, KL_dist: 0.6797, 0.3261, 0.6791, param: [ 4.81634666  6.78802838  5.8096683  10.36679663], weights: [0.21838699 0.25172297 0.52989004], train_wt_loss:  37.8858, val_wt_loss: 36.7273, train_grp_loss: [11.49209219 13.71457645 12.99167787], val_grp_loss: [12.64906059 12.82355713 11.25290679], train_hist_grp_loss: [15.68680887 20.42215804 45.2335033 ], cur_train_grp_loss: [0.0884037  0.11524335 0.25474421], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6797, max_kl_dist_index: 0, max_train_grp_loss:  13.7146, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8236, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2547, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:42:16,743 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  177, train_loss:  12.6286, val_loss:  12.2426, grad_norm: 0.0127, live_grad: 0.0000, reward_err: 0.0104, 0.0186, 0.0015, KL_dist: 0.6797, 0.3261, 0.6792, param: [ 4.81551364  6.78714626  5.81029261 10.36870355], weights: [0.21776556 0.25120893 0.53102551], train_wt_loss:  37.8859, val_wt_loss: 36.7279, train_grp_loss: [11.49169513 13.71520511 12.99139859], val_grp_loss: [12.64876481 12.82456352 11.25278366], train_hist_grp_loss: [15.77520958 20.53740658 45.48824208], cur_train_grp_loss: [0.08840071 0.11524854 0.25473878], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6797, max_kl_dist_index: 0, max_train_grp_loss:  13.7152, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8246, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2547, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:42:17,775 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  178, train_loss:  12.6287, val_loss:  12.2428, grad_norm: 0.0128, live_grad: 0.0000, reward_err: 0.0104, 0.0186, 0.0015, KL_dist: 0.6798, 0.3262, 0.6793, param: [ 4.81467618  6.78626585  5.81091501 10.37062485], weights: [0.21714476 0.25069468 0.53216056], train_wt_loss:  37.8860, val_wt_loss: 36.7285, train_grp_loss: [11.4912902  13.71584417 12.99111688], val_grp_loss: [12.64846175 12.82558278 11.25265725], train_hist_grp_loss: [15.86360723 20.6526604  45.74297538], cur_train_grp_loss: [0.08839765 0.11525382 0.25473331], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6798, max_kl_dist_index: 0, max_train_grp_loss:  13.7158, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8256, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2547, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:42:18,798 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  179, train_loss:  12.6287, val_loss:  12.2430, grad_norm: 0.0129, live_grad: 0.0000, reward_err: 0.0104, 0.0186, 0.0015, KL_dist: 0.6798, 0.3262, 0.6793, param: [ 4.81383429  6.78538711  5.81153549 10.37256057], weights: [0.21652458 0.25018023 0.53329519], train_wt_loss:  37.8861, val_wt_loss: 36.7290, train_grp_loss: [11.49087742 13.71649365 12.99083273], val_grp_loss: [12.64815141 12.82661495 11.25252757], train_hist_grp_loss: [15.95200177 20.7679196  45.99770317], cur_train_grp_loss: [0.08839454 0.11525919 0.25472778], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6798, max_kl_dist_index: 0, max_train_grp_loss:  13.7165, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8266, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2547, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:42:19,813 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  180, train_loss:  12.6287, val_loss:  12.2432, grad_norm: 0.0130, live_grad: 0.0000, reward_err: 0.0104, 0.0186, 0.0015, KL_dist: 0.6799, 0.3263, 0.6794, param: [ 4.81298796  6.78451004  5.81215405 10.37451071], weights: [0.21590503 0.24966559 0.53442938], train_wt_loss:  37.8862, val_wt_loss: 36.7296, train_grp_loss: [11.49045678 13.71715355 12.99054614], val_grp_loss: [12.64783377 12.82766005 11.25239462], train_hist_grp_loss: [16.04039314 20.88318425 46.25242538], cur_train_grp_loss: [0.08839136 0.11526465 0.25472221], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6799, max_kl_dist_index: 0, max_train_grp_loss:  13.7172, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8277, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2547, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:42:20,858 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  181, train_loss:  12.6288, val_loss:  12.2434, grad_norm: 0.0131, live_grad: 0.0000, reward_err: 0.0104, 0.0186, 0.0015, KL_dist: 0.6800, 0.3263, 0.6795, param: [ 4.81213719  6.78363462  5.81277068 10.37647531], weights: [0.21528612 0.24915075 0.53556313], train_wt_loss:  37.8863, val_wt_loss: 36.7302, train_grp_loss: [11.49002828 13.71782391 12.99025712], val_grp_loss: [12.64750884 12.82871808 11.25225839], train_hist_grp_loss: [16.12878127 20.99845445 46.50714197], cur_train_grp_loss: [0.08838813 0.1152702  0.25471659], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6800, max_kl_dist_index: 0, max_train_grp_loss:  13.7178, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8287, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2547, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:42:21,880 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  182, train_loss:  12.6288, val_loss:  12.2436, grad_norm: 0.0132, live_grad: 0.0000, reward_err: 0.0104, 0.0186, 0.0015, KL_dist: 0.6801, 0.3264, 0.6796, param: [ 4.81128196  6.78276085  5.81338536 10.37845437], weights: [0.21466786 0.24863573 0.53669641], train_wt_loss:  37.8864, val_wt_loss: 36.7308, train_grp_loss: [11.48959191 13.71850473 12.98996566], val_grp_loss: [12.64717661 12.82978909 11.25211891], train_hist_grp_loss: [16.2171661  21.11373028 46.76185289], cur_train_grp_loss: [0.08838483 0.11527583 0.25471092], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6801, max_kl_dist_index: 0, max_train_grp_loss:  13.7185, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8298, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2547, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:42:22,902 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  183, train_loss:  12.6288, val_loss:  12.2438, grad_norm: 0.0132, live_grad: 0.0000, reward_err: 0.0104, 0.0186, 0.0015, KL_dist: 0.6801, 0.3264, 0.6797, param: [ 4.81042228  6.7818887   5.81399811 10.38044791], weights: [0.21405024 0.24812054 0.53782922], train_wt_loss:  37.8865, val_wt_loss: 36.7314, train_grp_loss: [11.48914766 13.71919602 12.98967175], val_grp_loss: [12.64683707 12.83087308 11.25197615], train_hist_grp_loss: [16.30554758 21.22901183 47.0165581 ], cur_train_grp_loss: [0.08838148 0.11528155 0.25470521], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6801, max_kl_dist_index: 0, max_train_grp_loss:  13.7192, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8309, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2547, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:42:23,961 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  184, train_loss:  12.6289, val_loss:  12.2440, grad_norm: 0.0133, live_grad: 0.0000, reward_err: 0.0104, 0.0186, 0.0015, KL_dist: 0.6802, 0.3265, 0.6798, param: [ 4.80955813  6.78101816  5.81460891 10.38245597], weights: [0.21343328 0.24760518 0.53896154], train_wt_loss:  37.8866, val_wt_loss: 36.7321, train_grp_loss: [11.48869555 13.71989781 12.98937541], val_grp_loss: [12.64649024 12.83197008 11.25183014], train_hist_grp_loss: [16.39392564 21.34429919 47.27125755], cur_train_grp_loss: [0.08837806 0.11528736 0.25469945], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6802, max_kl_dist_index: 0, max_train_grp_loss:  13.7199, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8320, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2547, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:42:24,989 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  185, train_loss:  12.6289, val_loss:  12.2442, grad_norm: 0.0134, live_grad: 0.0000, reward_err: 0.0104, 0.0186, 0.0015, KL_dist: 0.6803, 0.3265, 0.6799, param: [ 4.80868952  6.78014922  5.81521775 10.38447855], weights: [0.21281697 0.24708966 0.54009337], train_wt_loss:  37.8867, val_wt_loss: 36.7327, train_grp_loss: [11.48823556 13.72061011 12.98907663], val_grp_loss: [12.64613609 12.83308011 11.25168087], train_hist_grp_loss: [16.48230022 21.45959245 47.52595118], cur_train_grp_loss: [0.08837458 0.11529326 0.25469364], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6803, max_kl_dist_index: 0, max_train_grp_loss:  13.7206, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8331, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2547, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:42:26,000 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  186, train_loss:  12.6289, val_loss:  12.2444, grad_norm: 0.0135, live_grad: 0.0000, reward_err: 0.0104, 0.0186, 0.0015, KL_dist: 0.6803, 0.3266, 0.6800, param: [ 4.80781643  6.77928185  5.81582462 10.38651567], weights: [0.21220133 0.24657399 0.54122469], train_wt_loss:  37.8868, val_wt_loss: 36.7333, train_grp_loss: [11.48776769 13.72133293 12.9887754 ], val_grp_loss: [12.64577463 12.83420319 11.25152834], train_hist_grp_loss: [16.57067126 21.5748917  47.78063896], cur_train_grp_loss: [0.08837104 0.11529924 0.25468778], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6803, max_kl_dist_index: 0, max_train_grp_loss:  13.7213, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8342, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2547, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:42:27,037 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  187, train_loss:  12.6290, val_loss:  12.2446, grad_norm: 0.0136, live_grad: 0.0000, reward_err: 0.0104, 0.0189, 0.0015, KL_dist: 0.6804, 0.3266, 0.6801, param: [ 4.80693887  6.77841606  5.81642954 10.38856735], weights: [0.21158635 0.24605816 0.54235548], train_wt_loss:  37.8869, val_wt_loss: 36.7339, train_grp_loss: [11.48729194 13.72206629 12.98847173], val_grp_loss: [12.64540585 12.83533934 11.25137256], train_hist_grp_loss: [16.6590387  21.69019701 48.03532083], cur_train_grp_loss: [0.08836744 0.11530532 0.25468187], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6804, max_kl_dist_index: 0, max_train_grp_loss:  13.7221, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8353, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2547, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:42:28,085 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  188, train_loss:  12.6290, val_loss:  12.2448, grad_norm: 0.0137, live_grad: 0.0000, reward_err: 0.0104, 0.0189, 0.0015, KL_dist: 0.6805, 0.3267, 0.6801, param: [ 4.80605682  6.77755181  5.81703247 10.39063362], weights: [0.21097205 0.2455422  0.54348575], train_wt_loss:  37.8870, val_wt_loss: 36.7345, train_grp_loss: [11.4868083  13.7228102  12.98816561], val_grp_loss: [12.64502976 12.83648858 11.25121353], train_hist_grp_loss: [16.74740249 21.8055085  48.28999675], cur_train_grp_loss: [0.08836378 0.11531148 0.25467592], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6805, max_kl_dist_index: 0, max_train_grp_loss:  13.7228, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8365, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2547, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:42:29,109 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  189, train_loss:  12.6290, val_loss:  12.2450, grad_norm: 0.0138, live_grad: 0.0000, reward_err: 0.0104, 0.0189, 0.0015, KL_dist: 0.6805, 0.3267, 0.6802, param: [ 4.80517028  6.7766891   5.81763343 10.39271448], weights: [0.21035842 0.24502611 0.54461547], train_wt_loss:  37.8871, val_wt_loss: 36.7351, train_grp_loss: [11.48631678 13.72356469 12.98785705], val_grp_loss: [12.64464634 12.83765094 11.25105126], train_hist_grp_loss: [16.83576255 21.92082623 48.54466666], cur_train_grp_loss: [0.08836006 0.11531773 0.25466991], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6805, max_kl_dist_index: 0, max_train_grp_loss:  13.7236, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8377, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2547, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:42:30,121 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  190, train_loss:  12.6291, val_loss:  12.2453, grad_norm: 0.0139, live_grad: 0.0000, reward_err: 0.0104, 0.0189, 0.0015, KL_dist: 0.6806, 0.3268, 0.6803, param: [ 4.80427924  6.77582791  5.8182324  10.39480996], weights: [0.20974548 0.24450989 0.54574463], train_wt_loss:  37.8872, val_wt_loss: 36.7358, train_grp_loss: [11.48581737 13.72432976 12.98754605], val_grp_loss: [12.6442556  12.83882642 11.25088574], train_hist_grp_loss: [16.92411883 22.0361503  48.79933052], cur_train_grp_loss: [0.08835628 0.11532407 0.25466386], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6806, max_kl_dist_index: 0, max_train_grp_loss:  13.7243, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8388, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2547, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:42:31,139 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  191, train_loss:  12.6291, val_loss:  12.2455, grad_norm: 0.0140, live_grad: 0.0000, reward_err: 0.0103, 0.0189, 0.0016, KL_dist: 0.6807, 0.3268, 0.6804, param: [ 4.8033837   6.77496823  5.81882937 10.39692008], weights: [0.20913323 0.24399355 0.54687322], train_wt_loss:  37.8873, val_wt_loss: 36.7364, train_grp_loss: [11.48531008 13.72510543 12.98723259], val_grp_loss: [12.64385754 12.84001507 11.25071699], train_hist_grp_loss: [17.01247128 22.1514808  49.05398829], cur_train_grp_loss: [0.08835244 0.1153305  0.25465777], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6807, max_kl_dist_index: 0, max_train_grp_loss:  13.7251, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8400, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2547, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:42:32,175 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  192, train_loss:  12.6291, val_loss:  12.2457, grad_norm: 0.0141, live_grad: 0.0000, reward_err: 0.0103, 0.0189, 0.0016, KL_dist: 0.6808, 0.3269, 0.6805, param: [ 4.80248366  6.77411004  5.81942435 10.39904485], weights: [0.20852166 0.2434771  0.54800124], train_wt_loss:  37.8874, val_wt_loss: 36.7370, train_grp_loss: [11.48479488 13.72589171 12.9869167 ], val_grp_loss: [12.64345214 12.84121688 11.25054499], train_hist_grp_loss: [17.10081981 22.26681782 49.30863991], cur_train_grp_loss: [0.08834854 0.11533702 0.25465162], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6808, max_kl_dist_index: 0, max_train_grp_loss:  13.7259, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8412, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2547, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:42:33,198 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  193, train_loss:  12.6292, val_loss:  12.2459, grad_norm: 0.0142, live_grad: 0.0000, reward_err: 0.0103, 0.0189, 0.0016, KL_dist: 0.6808, 0.3269, 0.6806, param: [ 4.8015791   6.77325332  5.82001732 10.40118429], weights: [0.2079108  0.24296054 0.54912866], train_wt_loss:  37.8875, val_wt_loss: 36.7376, train_grp_loss: [11.4842718  13.72668863 12.98659835], val_grp_loss: [12.64303941 12.84243189 11.25036977], train_hist_grp_loss: [17.18916439 22.38216145 49.56328533], cur_train_grp_loss: [0.08834458 0.11534363 0.25464543], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6808, max_kl_dist_index: 0, max_train_grp_loss:  13.7267, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8424, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2546, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:42:34,234 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  194, train_loss:  12.6292, val_loss:  12.2461, grad_norm: 0.0143, live_grad: 0.0000, reward_err: 0.0103, 0.0189, 0.0016, KL_dist: 0.6809, 0.3270, 0.6807, param: [ 4.80067003  6.77239807  5.82060829 10.40333842], weights: [0.20730064 0.24244389 0.55025548], train_wt_loss:  37.8876, val_wt_loss: 36.7383, train_grp_loss: [11.48374082 13.7274962  12.98627755], val_grp_loss: [12.64261934 12.84366012 11.25019132], train_hist_grp_loss: [17.27750494 22.49751178 49.81792452], cur_train_grp_loss: [0.08834055 0.11535032 0.25463918], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6809, max_kl_dist_index: 0, max_train_grp_loss:  13.7275, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8437, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2546, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:42:35,287 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  195, train_loss:  12.6292, val_loss:  12.2463, grad_norm: 0.0144, live_grad: 0.0000, reward_err: 0.0103, 0.0189, 0.0016, KL_dist: 0.6810, 0.3270, 0.6808, param: [ 4.79975644  6.77154425  5.82119723 10.40550725], weights: [0.20669118 0.24192714 0.55138168], train_wt_loss:  37.8877, val_wt_loss: 36.7389, train_grp_loss: [11.48320194 13.72831442 12.98595431], val_grp_loss: [12.64219194 12.84490159 11.25000964], train_hist_grp_loss: [17.36584141 22.61286889 50.07255741], cur_train_grp_loss: [0.08833647 0.11535711 0.25463289], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6810, max_kl_dist_index: 0, max_train_grp_loss:  13.7283, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8449, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2546, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:42:36,324 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  196, train_loss:  12.6293, val_loss:  12.2465, grad_norm: 0.0145, live_grad: 0.0000, reward_err: 0.0103, 0.0189, 0.0016, KL_dist: 0.6811, 0.3271, 0.6809, param: [ 4.79883831  6.77069187  5.82178415 10.40769081], weights: [0.20608243 0.24141031 0.55250725], train_wt_loss:  37.8878, val_wt_loss: 36.7395, train_grp_loss: [11.48265517 13.72914333 12.98562862], val_grp_loss: [12.6417572  12.84615631 11.24982475], train_hist_grp_loss: [17.45417373 22.72823287 50.32718397], cur_train_grp_loss: [0.08833232 0.11536399 0.25462656], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6811, max_kl_dist_index: 0, max_train_grp_loss:  13.7291, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8462, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2546, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:42:37,344 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  197, train_loss:  12.6293, val_loss:  12.2467, grad_norm: 0.0146, live_grad: 0.0000, reward_err: 0.0103, 0.0189, 0.0016, KL_dist: 0.6811, 0.3271, 0.6810, param: [ 4.79791566  6.7698409   5.82236903 10.40988911], weights: [0.20547441 0.24089341 0.55363219], train_wt_loss:  37.8879, val_wt_loss: 36.7402, train_grp_loss: [11.48210049 13.72998292 12.98530048], val_grp_loss: [12.64131511 12.84742431 11.24963664], train_hist_grp_loss: [17.54250185 22.84360383 50.58180414], cur_train_grp_loss: [0.08832812 0.11537095 0.25462017], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6811, max_kl_dist_index: 0, max_train_grp_loss:  13.7300, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8474, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2546, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:42:38,349 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  198, train_loss:  12.6293, val_loss:  12.2469, grad_norm: 0.0147, live_grad: 0.0000, reward_err: 0.0103, 0.0189, 0.0016, KL_dist: 0.6812, 0.3272, 0.6811, param: [ 4.79698847  6.76899132  5.82295189 10.41210218], weights: [0.2048671  0.24037643 0.55475647], train_wt_loss:  37.8880, val_wt_loss: 36.7408, train_grp_loss: [11.48153792 13.73083323 12.98496989], val_grp_loss: [12.64086569 12.84870561 11.24944531], train_hist_grp_loss: [17.6308257  22.95898183 50.83641787], cur_train_grp_loss: [0.08832385 0.11537801 0.25461373], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6812, max_kl_dist_index: 0, max_train_grp_loss:  13.7308, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8487, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2546, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:42:39,351 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  199, train_loss:  12.6294, val_loss:  12.2472, grad_norm: 0.0148, live_grad: 0.0000, reward_err: 0.0103, 0.0189, 0.0016, KL_dist: 0.6813, 0.3272, 0.6812, param: [ 4.79605673  6.76814313  5.82353269 10.41433001], weights: [0.20426052 0.23985939 0.5558801 ], train_wt_loss:  37.8881, val_wt_loss: 36.7415, train_grp_loss: [11.48096744 13.73169425 12.98463685], val_grp_loss: [12.64040891 12.85000023 11.24925078], train_hist_grp_loss: [17.71914522 23.07436699 51.09102512], cur_train_grp_loss: [0.08831952 0.11538515 0.25460725], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6813, max_kl_dist_index: 0, max_train_grp_loss:  13.7317, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8500, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2546, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:42:40,282 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1654] - INFO: Iteration:  199, train_loss:  12.6294, val_loss:  12.2472, grad_norm: 0.0148,  live_grad: 0.0000, reward_err: 0.0103, 0.0189, 0.0016, KL_dist: 0.6813, 0.3272, 0.6812, param: [ 4.79605673  6.76814313  5.82353269 10.41433001], weights: [0.20426052 0.23985939 0.5558801 ], train_wt_loss:  37.8881, val_wt_loss: 36.7415, train_grp_loss: [11.48096744 13.73169425 12.98463685], val_grp_loss: [12.64040891 12.85000023 11.24925078], train_hist_grp_loss: [17.71914522 23.07436699 51.09102512], cur_train_grp_loss: [0.08831952 0.11538515 0.25460725], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6813, max_kl_dist_index: 0, max_train_grp_loss:  13.7317, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8500, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2546, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:42:40,510 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:388] - INFO: Policy parameter learned solely on the preference data rdpo: [ 4.79605673  6.76814313  5.82353269 10.41433001].
2024-10-07 01:42:40,861 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Uniform reward: 3.8511, 3.8511, 3.1970
2024-10-07 01:42:40,861 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Optimal reward: 3.8856, 7.2460, 3.3201
2024-10-07 01:42:40,862 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Policy reward: 3.8455, 7.1089, 3.3147
2024-10-07 01:42:40,862 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:402] - INFO: Reward Error: 0.0103, 0.0189, 0.0016
2024-10-07 01:42:41,557 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:417] - INFO: Optimal reward: 3.8856, 7.2460, 3.3201
Known param reward: [[3.885563232421875, 6.83889453125, 3.291370361328125], [3.493690185546875, 7.24602734375, 3.1155205078125], [3.850873046875, 7.10487548828125, 3.320061279296875]], Known param reward error: [[0.0, 0.05618703783269167, 0.008641683256769945], [0.10085360176489651, 0.0, 0.06160752898142066], [0.008927968346368324, 0.019479895503085456, 0.0]].
