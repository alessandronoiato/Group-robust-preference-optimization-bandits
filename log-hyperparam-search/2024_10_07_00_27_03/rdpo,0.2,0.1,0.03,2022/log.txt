2024-10-07 01:35:31,777 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log-hyperparam-search/2024_10_07_00_27_03/rdpo,0.2,0.1,0.03,2022
2024-10-07 01:35:31,779 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2022
2024-10-07 01:35:31,779 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-10-07 01:35:31,871 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.3214, l2 distance: 25.6155, acc: 0.89.
2024-10-07 01:35:31,872 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-10-07 01:35:31,873 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [ 4.91492317 13.51244723  6.71533233  9.49961375]
2024-10-07 01:35:32,094 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.8530, 6.9304, 3.3326
2024-10-07 01:35:32,328 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1314] - INFO: unique_group_ids: {0, 1, 2}
2024-10-07 01:35:33,609 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  0, train_loss:  13.4334, val_loss:  12.2620, grad_norm: 0.5704, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6506, 0.3479, 0.6808, param: [4.15053021 9.5246301  4.95544154 8.85723397], weights: [0.33234513 0.33246408 0.33519079], train_wt_loss:  40.3003, val_wt_loss: 36.7860, train_grp_loss: [11.73490857 15.89686997 11.15320157], val_grp_loss: [10.62009669 14.91176746 11.2699811 ], train_hist_grp_loss: [0.17243466 0.18436246 0.45663202], cur_train_grp_loss: [0.17243466 0.18436246 0.45663202], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6808, max_kl_dist_index: 2, max_train_grp_loss:  15.8969, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9118, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.4566, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:35:34,676 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  1, train_loss:  13.4334, val_loss:  12.2619, grad_norm: 0.0001, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6506, 0.3479, 0.6808, param: [4.15059431 9.5237568  4.95591604 8.85749304], weights: [0.33177348 0.33217706 0.33604946], train_wt_loss:  40.3003, val_wt_loss: 36.7858, train_grp_loss: [11.73543613 15.89630073 11.15337147], val_grp_loss: [10.62049744 14.91100435 11.27019054], train_hist_grp_loss: [0.26707102 0.30759401 0.69393419], cur_train_grp_loss: [0.09463636 0.12323155 0.23730216], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6808, max_kl_dist_index: 2, max_train_grp_loss:  15.8963, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9110, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2373, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:35:35,765 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  2, train_loss:  13.4334, val_loss:  12.2619, grad_norm: 0.0001, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6506, 0.3478, 0.6807, param: [4.15065634 9.52288799 4.95638902 8.85775685], weights: [0.33120171 0.3318891  0.33690919], train_wt_loss:  40.3003, val_wt_loss: 36.7857, train_grp_loss: [11.73595915 15.8957368  11.15353944], val_grp_loss: [10.62089416 14.91024915 11.27039851], train_hist_grp_loss: [0.36171163 0.43082115 0.93123996], cur_train_grp_loss: [0.09464061 0.12322714 0.23730578], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6807, max_kl_dist_index: 2, max_train_grp_loss:  15.8957, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9102, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2373, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:35:36,853 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  3, train_loss:  13.4334, val_loss:  12.2618, grad_norm: 0.0001, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6506, 0.3478, 0.6807, param: [4.15071627 9.52202366 4.95686049 8.85802541], weights: [0.33062982 0.33160019 0.33776999], train_wt_loss:  40.3003, val_wt_loss: 36.7855, train_grp_loss: [11.73647762 15.89517816 11.15370546], val_grp_loss: [10.62128686 14.90950185 11.27060499], train_hist_grp_loss: [0.45635647 0.55404391 1.16854931], cur_train_grp_loss: [0.09464483 0.12322277 0.23730935], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6807, max_kl_dist_index: 2, max_train_grp_loss:  15.8952, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9095, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2373, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:35:37,995 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  4, train_loss:  13.4334, val_loss:  12.2618, grad_norm: 0.0001, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6506, 0.3478, 0.6807, param: [4.15077412 9.52116383 4.95733044 8.85829872], weights: [0.33005781 0.33131034 0.33863185], train_wt_loss:  40.3003, val_wt_loss: 36.7854, train_grp_loss: [11.73699154 15.89462482 11.15386954], val_grp_loss: [10.62167553 14.90876246 11.27080998], train_hist_grp_loss: [0.55100548 0.67726235 1.40586219], cur_train_grp_loss: [0.09464901 0.12321844 0.23731288], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6807, max_kl_dist_index: 2, max_train_grp_loss:  15.8946, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9088, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2373, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:35:39,101 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  5, train_loss:  13.4334, val_loss:  12.2618, grad_norm: 0.0001, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6506, 0.3478, 0.6807, param: [4.15082987 9.52030849 4.95779887 8.85857681], weights: [0.32948569 0.33101955 0.33949476], train_wt_loss:  40.3003, val_wt_loss: 36.7853, train_grp_loss: [11.73750089 15.8940768  11.15403167], val_grp_loss: [10.62206016 14.908031   11.27101348], train_hist_grp_loss: [0.64565864 0.8004765  1.64317857], cur_train_grp_loss: [0.09465316 0.12321415 0.23731637], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6807, max_kl_dist_index: 2, max_train_grp_loss:  15.8941, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9080, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2373, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:35:40,173 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  6, train_loss:  13.4334, val_loss:  12.2617, grad_norm: 0.0002, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6505, 0.3477, 0.6806, param: [4.15088354 9.51945765 4.95826577 8.85885966], weights: [0.32891345 0.33072783 0.34035872], train_wt_loss:  40.3003, val_wt_loss: 36.7851, train_grp_loss: [11.73800566 15.89353408 11.15419185], val_grp_loss: [10.62244075 14.90730747 11.27121549], train_hist_grp_loss: [0.7403159  0.92368639 1.88049839], cur_train_grp_loss: [0.09465727 0.1232099  0.23731982], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6806, max_kl_dist_index: 2, max_train_grp_loss:  15.8935, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9073, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2373, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:35:41,203 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  7, train_loss:  13.4334, val_loss:  12.2617, grad_norm: 0.0002, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6505, 0.3477, 0.6806, param: [4.15093511 9.51861132 4.95873115 8.85914729], weights: [0.32834111 0.33043517 0.34122373], train_wt_loss:  40.3003, val_wt_loss: 36.7850, train_grp_loss: [11.73850586 15.89299668 11.15435008], val_grp_loss: [10.62281728 14.90659187 11.271416  ], train_hist_grp_loss: [0.83497724 1.04689208 2.11782162], cur_train_grp_loss: [0.09466134 0.12320569 0.23732323], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6806, max_kl_dist_index: 2, max_train_grp_loss:  15.8930, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9066, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2373, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:35:42,247 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  8, train_loss:  13.4334, val_loss:  12.2616, grad_norm: 0.0002, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6505, 0.3477, 0.6806, param: [4.15098459 9.51776949 4.95919499 8.85943971], weights: [0.32776865 0.33014157 0.34208978], train_wt_loss:  40.3003, val_wt_loss: 36.7849, train_grp_loss: [11.73900148 15.8924646  11.15450634], val_grp_loss: [10.62318976 14.90588423 11.27161501], train_hist_grp_loss: [0.92964261 1.17009361 2.35514822], cur_train_grp_loss: [0.09466537 0.12320152 0.2373266 ], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6806, max_kl_dist_index: 2, max_train_grp_loss:  15.8925, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9059, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2373, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:35:43,305 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  9, train_loss:  13.4334, val_loss:  12.2616, grad_norm: 0.0003, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6505, 0.3477, 0.6806, param: [4.15103198 9.51693218 4.95965731 8.85973692], weights: [0.3271961  0.32984705 0.34295686], train_wt_loss:  40.3003, val_wt_loss: 36.7847, train_grp_loss: [11.7394925  15.89193785 11.15466065], val_grp_loss: [10.62355817 14.90518453 11.27181252], train_hist_grp_loss: [1.02431198 1.29329101 2.59247814], cur_train_grp_loss: [0.09466937 0.1231974  0.23732992], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6806, max_kl_dist_index: 2, max_train_grp_loss:  15.8919, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9052, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2373, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:35:44,345 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  10, train_loss:  13.4334, val_loss:  12.2615, grad_norm: 0.0003, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6505, 0.3477, 0.6805, param: [4.15107726 9.51609938 4.96011808 8.86003893], weights: [0.32662344 0.32955159 0.34382497], train_wt_loss:  40.3003, val_wt_loss: 36.7846, train_grp_loss: [11.73997892 15.89141643 11.15481299], val_grp_loss: [10.62392252 14.9044928  11.27200853], train_hist_grp_loss: [1.1189853  1.41648432 2.82981134], cur_train_grp_loss: [0.09467333 0.12319332 0.23733321], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6805, max_kl_dist_index: 2, max_train_grp_loss:  15.8914, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9045, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2373, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:35:45,358 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  11, train_loss:  13.4334, val_loss:  12.2615, grad_norm: 0.0004, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6505, 0.3476, 0.6805, param: [4.15112045 9.51527109 4.96057732 8.86034575], weights: [0.32605068 0.32925521 0.34469411], train_wt_loss:  40.3003, val_wt_loss: 36.7845, train_grp_loss: [11.74046074 15.89090035 11.15496336], val_grp_loss: [10.6242828  14.90380904 11.27220302], train_hist_grp_loss: [1.21366255 1.5396736  3.06714779], cur_train_grp_loss: [0.09467725 0.12318927 0.23733645], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6805, max_kl_dist_index: 2, max_train_grp_loss:  15.8909, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9038, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2373, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:35:46,395 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  12, train_loss:  13.4334, val_loss:  12.2614, grad_norm: 0.0004, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6505, 0.3476, 0.6805, param: [4.15116154 9.51444732 4.96103502 8.86065738], weights: [0.32547783 0.3289579  0.34556427], train_wt_loss:  40.3003, val_wt_loss: 36.7843, train_grp_loss: [11.74093794 15.8903896  11.15511175], val_grp_loss: [10.62463899 14.90313325 11.272396  ], train_hist_grp_loss: [1.30834369 1.66285887 3.30448744], cur_train_grp_loss: [0.09468113 0.12318527 0.23733965], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6805, max_kl_dist_index: 2, max_train_grp_loss:  15.8904, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9031, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2373, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:35:47,402 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  13, train_loss:  13.4334, val_loss:  12.2614, grad_norm: 0.0005, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6505, 0.3476, 0.6805, param: [4.15120052 9.51362808 4.96149118 8.86097384], weights: [0.32490488 0.32865968 0.34643545], train_wt_loss:  40.3003, val_wt_loss: 36.7842, train_grp_loss: [11.74141052 15.8898842  11.15525817], val_grp_loss: [10.6249911  14.90246545 11.27258746], train_hist_grp_loss: [1.40302867 1.78604019 3.54183024], cur_train_grp_loss: [0.09468498 0.12318131 0.2373428 ], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6805, max_kl_dist_index: 2, max_train_grp_loss:  15.8899, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9025, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2373, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:35:48,422 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  14, train_loss:  13.4334, val_loss:  12.2614, grad_norm: 0.0005, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6505, 0.3476, 0.6804, param: [4.1512374  9.51281336 4.96194578 8.86129513], weights: [0.32433184 0.32836053 0.34730763], train_wt_loss:  40.3003, val_wt_loss: 36.7841, train_grp_loss: [11.74187848 15.88938414 11.15540261], val_grp_loss: [10.62533912 14.90180564 11.27277741], train_hist_grp_loss: [1.49771746 1.90921758 3.77917616], cur_train_grp_loss: [0.09468879 0.1231774  0.23734592], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6804, max_kl_dist_index: 2, max_train_grp_loss:  15.8894, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9018, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2373, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:35:49,461 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  15, train_loss:  13.4334, val_loss:  12.2613, grad_norm: 0.0005, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6505, 0.3476, 0.6804, param: [4.15127218 9.51200317 4.96239884 8.86162125], weights: [0.32375871 0.32806047 0.34818083], train_wt_loss:  40.3003, val_wt_loss: 36.7840, train_grp_loss: [11.7423418  15.88888944 11.15554506], val_grp_loss: [10.62568304 14.90115383 11.27296583], train_hist_grp_loss: [1.59241003 2.03239111 4.01652515], cur_train_grp_loss: [0.09469257 0.12317352 0.23734899], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6804, max_kl_dist_index: 2, max_train_grp_loss:  15.8889, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9012, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2373, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:35:50,484 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  16, train_loss:  13.4334, val_loss:  12.2613, grad_norm: 0.0006, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6505, 0.3475, 0.6804, param: [4.15130485 9.51119752 4.96285035 8.86195221], weights: [0.32318549 0.32775949 0.34905502], train_wt_loss:  40.3003, val_wt_loss: 36.7839, train_grp_loss: [11.74280048 15.8884001  11.15568553], val_grp_loss: [10.62602286 14.90051003 11.27315273], train_hist_grp_loss: [1.68710634 2.15556079 4.25387717], cur_train_grp_loss: [0.0946963  0.12316969 0.23735202], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6804, max_kl_dist_index: 2, max_train_grp_loss:  15.8884, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9005, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:35:51,507 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  17, train_loss:  13.4334, val_loss:  12.2613, grad_norm: 0.0006, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6505, 0.3475, 0.6804, param: [4.15133542 9.5103964  4.9633003  8.86228802], weights: [0.32261219 0.3274576  0.34993021], train_wt_loss:  40.3003, val_wt_loss: 36.7838, train_grp_loss: [11.74325451 15.88791611 11.155824  ], val_grp_loss: [10.62635857 14.89987425 11.2733381 ], train_hist_grp_loss: [1.78180634 2.27872668 4.49123218], cur_train_grp_loss: [0.0947     0.12316589 0.23735501], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6804, max_kl_dist_index: 2, max_train_grp_loss:  15.8879, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8999, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:35:52,545 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  18, train_loss:  13.4334, val_loss:  12.2612, grad_norm: 0.0007, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6505, 0.3475, 0.6804, param: [4.15136387 9.50959981 4.96374869 8.86262869], weights: [0.32203881 0.3271548  0.35080639], train_wt_loss:  40.3003, val_wt_loss: 36.7837, train_grp_loss: [11.74370389 15.8874375  11.15596049], val_grp_loss: [10.62669017 14.89924648 11.27352193], train_hist_grp_loss: [1.87651001 2.40188882 4.72859014], cur_train_grp_loss: [0.09470367 0.12316214 0.23735796], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6804, max_kl_dist_index: 2, max_train_grp_loss:  15.8874, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8992, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:35:53,608 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  19, train_loss:  13.4334, val_loss:  12.2612, grad_norm: 0.0007, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6505, 0.3475, 0.6804, param: [4.15139021 9.50880777 4.96419552 8.86297422], weights: [0.32146535 0.32685109 0.35168356], train_wt_loss:  40.3003, val_wt_loss: 36.7836, train_grp_loss: [11.74414861 15.88696425 11.15609497], val_grp_loss: [10.62701765 14.89862675 11.27370424], train_hist_grp_loss: [1.9712173  2.52504725 4.965951  ], cur_train_grp_loss: [0.09470729 0.12315843 0.23736086], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6804, max_kl_dist_index: 2, max_train_grp_loss:  15.8870, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8986, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:35:54,672 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  20, train_loss:  13.4334, val_loss:  12.2612, grad_norm: 0.0008, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6505, 0.3475, 0.6803, param: [4.15141444 9.50802027 4.96464079 8.86332462], weights: [0.32089182 0.32654647 0.35256171], train_wt_loss:  40.3003, val_wt_loss: 36.7835, train_grp_loss: [11.74458866 15.88649638 11.15622745], val_grp_loss: [10.627341   14.89801505 11.273885  ], train_hist_grp_loss: [2.06592817 2.64820202 5.20331473], cur_train_grp_loss: [0.09471088 0.12315476 0.23736372], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6803, max_kl_dist_index: 2, max_train_grp_loss:  15.8865, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8980, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:35:55,704 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  21, train_loss:  13.4334, val_loss:  12.2611, grad_norm: 0.0008, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6505, 0.3475, 0.6803, param: [4.15143656 9.50723732 4.96508449 8.8636799 ], weights: [0.32031821 0.32624096 0.35344083], train_wt_loss:  40.3003, val_wt_loss: 36.7833, train_grp_loss: [11.74502404 15.88603388 11.15635793], val_grp_loss: [10.62766023 14.8974114  11.27406423], train_hist_grp_loss: [2.1606426  2.77135315 5.44068127], cur_train_grp_loss: [0.09471442 0.12315113 0.23736654], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6803, max_kl_dist_index: 2, max_train_grp_loss:  15.8860, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8974, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:35:56,746 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  22, train_loss:  13.4334, val_loss:  12.2611, grad_norm: 0.0008, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6505, 0.3474, 0.6803, param: [4.15145656 9.50645892 4.96552662 8.86404006], weights: [0.31974454 0.32593454 0.35432092], train_wt_loss:  40.3003, val_wt_loss: 36.7833, train_grp_loss: [11.74545473 15.88557677 11.1564864 ], val_grp_loss: [10.62797532 14.8968158  11.27424191], train_hist_grp_loss: [2.25536053 2.8945007  5.67805059], cur_train_grp_loss: [0.09471794 0.12314755 0.23736932], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6803, max_kl_dist_index: 2, max_train_grp_loss:  15.8856, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8968, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:35:57,781 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  23, train_loss:  13.4334, val_loss:  12.2611, grad_norm: 0.0009, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6505, 0.3474, 0.6803, param: [4.15147445 9.50568506 4.96596718 8.8644051 ], weights: [0.31917079 0.32562723 0.35520198], train_wt_loss:  40.3003, val_wt_loss: 36.7832, train_grp_loss: [11.74588074 15.88512505 11.15661286], val_grp_loss: [10.62828627 14.89622826 11.27441804], train_hist_grp_loss: [2.35008194 3.01764471 5.91542264], cur_train_grp_loss: [0.09472141 0.12314401 0.23737205], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6803, max_kl_dist_index: 2, max_train_grp_loss:  15.8851, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8962, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:35:58,832 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  24, train_loss:  13.4334, val_loss:  12.2610, grad_norm: 0.0009, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6505, 0.3474, 0.6803, param: [4.15149022 9.50491577 4.96640617 8.86477505], weights: [0.31859699 0.32531902 0.356084  ], train_wt_loss:  40.3003, val_wt_loss: 36.7831, train_grp_loss: [11.74630206 15.88467872 11.1567373 ], val_grp_loss: [10.62859308 14.89564878 11.27459263], train_hist_grp_loss: [2.44480679 3.14078521 6.15279738], cur_train_grp_loss: [0.09472484 0.1231405  0.23737474], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6803, max_kl_dist_index: 2, max_train_grp_loss:  15.8847, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8956, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:35:59,872 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  25, train_loss:  13.4334, val_loss:  12.2610, grad_norm: 0.0010, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6505, 0.3474, 0.6803, param: [4.15150386 9.50415103 4.96684357 8.86514989], weights: [0.31802311 0.32500991 0.35696697], train_wt_loss:  40.3003, val_wt_loss: 36.7830, train_grp_loss: [11.74671868 15.88423778 11.15685973], val_grp_loss: [10.62889573 14.89507738 11.27476566], train_hist_grp_loss: [2.53953503 3.26392225 6.39017477], cur_train_grp_loss: [0.09472824 0.12313704 0.23737739], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6803, max_kl_dist_index: 2, max_train_grp_loss:  15.8842, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8951, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:36:00,901 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  26, train_loss:  13.4334, val_loss:  12.2610, grad_norm: 0.0010, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6504, 0.3474, 0.6802, param: [4.15151539 9.50339085 4.9672794  8.86552964], weights: [0.31744919 0.32469992 0.35785089], train_wt_loss:  40.3003, val_wt_loss: 36.7829, train_grp_loss: [11.74713059 15.88380225 11.15698013], val_grp_loss: [10.62919423 14.89451406 11.27493714], train_hist_grp_loss: [2.63426663 3.38705588 6.62755476], cur_train_grp_loss: [0.0947316  0.12313363 0.23737999], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6802, max_kl_dist_index: 2, max_train_grp_loss:  15.8838, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8945, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:36:01,969 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  27, train_loss:  13.4334, val_loss:  12.2609, grad_norm: 0.0010, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6504, 0.3474, 0.6802, param: [4.1515248  9.50263523 4.96771364 8.86591431], weights: [0.3168752  0.32438904 0.35873576], train_wt_loss:  40.3003, val_wt_loss: 36.7828, train_grp_loss: [11.74753779 15.88337212 11.15709852], val_grp_loss: [10.62948857 14.89395883 11.27510706], train_hist_grp_loss: [2.72900156 3.51018613 6.86493732], cur_train_grp_loss: [0.09473492 0.12313025 0.23738256], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6802, max_kl_dist_index: 2, max_train_grp_loss:  15.8834, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8940, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:36:02,985 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  28, train_loss:  13.4334, val_loss:  12.2609, grad_norm: 0.0011, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6504, 0.3473, 0.6802, param: [4.15153208 9.50188418 4.96814629 8.8663039 ], weights: [0.31630116 0.32407728 0.35962157], train_wt_loss:  40.3003, val_wt_loss: 36.7827, train_grp_loss: [11.74794028 15.8829474  11.15721487], val_grp_loss: [10.62977874 14.89341169 11.27527542], train_hist_grp_loss: [2.82373976 3.63331305 7.10232239], cur_train_grp_loss: [0.09473821 0.12312692 0.23738507], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6802, max_kl_dist_index: 2, max_train_grp_loss:  15.8829, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8934, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:36:04,034 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  29, train_loss:  13.4334, val_loss:  12.2609, grad_norm: 0.0011, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6504, 0.3473, 0.6802, param: [4.15153723 9.50113769 4.96857735 8.86669841], weights: [0.31572707 0.32376463 0.3605083 ], train_wt_loss:  40.3003, val_wt_loss: 36.7826, train_grp_loss: [11.74833803 15.88252809 11.1573292 ], val_grp_loss: [10.63006474 14.89287265 11.27544222], train_hist_grp_loss: [2.91848122 3.75643667 7.33970994], cur_train_grp_loss: [0.09474145 0.12312362 0.23738755], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6802, max_kl_dist_index: 2, max_train_grp_loss:  15.8825, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8929, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:36:05,066 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  30, train_loss:  13.4335, val_loss:  12.2608, grad_norm: 0.0012, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6504, 0.3473, 0.6802, param: [4.15154026 9.50039578 4.96900682 8.86709786], weights: [0.31515293 0.3234511  0.36139597], train_wt_loss:  40.3004, val_wt_loss: 36.7825, train_grp_loss: [11.74873106 15.88211419 11.15744149], val_grp_loss: [10.63034657 14.89234173 11.27560745], train_hist_grp_loss: [3.01322588 3.87955704 7.57709993], cur_train_grp_loss: [0.09474466 0.12312037 0.23738998], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6802, max_kl_dist_index: 2, max_train_grp_loss:  15.8821, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8923, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:36:06,109 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  31, train_loss:  13.4335, val_loss:  12.2608, grad_norm: 0.0012, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6504, 0.3473, 0.6802, param: [4.15154116 9.49965843 4.9694347  8.86750224], weights: [0.31457874 0.3231367  0.36228456], train_wt_loss:  40.3004, val_wt_loss: 36.7825, train_grp_loss: [11.74911935 15.88170572 11.15755174], val_grp_loss: [10.63062421 14.89181892 11.27577111], train_hist_grp_loss: [3.10797371 4.00267421 7.8144923 ], cur_train_grp_loss: [0.09474783 0.12311716 0.23739237], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6802, max_kl_dist_index: 2, max_train_grp_loss:  15.8817, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8918, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:36:07,134 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  32, train_loss:  13.4335, val_loss:  12.2608, grad_norm: 0.0013, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6505, 0.3473, 0.6802, param: [4.15153993 9.49892566 4.96986097 8.86791157], weights: [0.31400452 0.32282142 0.36317407], train_wt_loss:  40.3004, val_wt_loss: 36.7824, train_grp_loss: [11.7495029  15.88130267 11.15765996], val_grp_loss: [10.63089767 14.89130423 11.2759332 ], train_hist_grp_loss: [3.20272467 4.1257882  8.05188702], cur_train_grp_loss: [0.09475096 0.123114   0.23739472], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6802, max_kl_dist_index: 2, max_train_grp_loss:  15.8813, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8913, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:36:08,153 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  33, train_loss:  13.4335, val_loss:  12.2608, grad_norm: 0.0013, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6505, 0.3473, 0.6802, param: [4.15153657 9.49819747 4.97028565 8.86832585], weights: [0.31343025 0.32250526 0.36406448], train_wt_loss:  40.3004, val_wt_loss: 36.7823, train_grp_loss: [11.74988171 15.88090506 11.15776613], val_grp_loss: [10.63116694 14.89079768 11.27609372], train_hist_grp_loss: [3.29747873 4.24889908 8.28928404], cur_train_grp_loss: [0.09475406 0.12311087 0.23739702], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6802, max_kl_dist_index: 2, max_train_grp_loss:  15.8809, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8908, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:36:09,175 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  34, train_loss:  13.4335, val_loss:  12.2607, grad_norm: 0.0013, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6505, 0.3473, 0.6801, param: [4.15153108 9.49747385 4.97070871 8.86874509], weights: [0.31285595 0.32218824 0.36495581], train_wt_loss:  40.3004, val_wt_loss: 36.7822, train_grp_loss: [11.75025575 15.88051287 11.15787026], val_grp_loss: [10.63143201 14.89029926 11.27625266], train_hist_grp_loss: [3.39223584 4.37200687 8.52668332], cur_train_grp_loss: [0.09475711 0.12310779 0.23739928], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6801, max_kl_dist_index: 2, max_train_grp_loss:  15.8805, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8903, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:36:10,192 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  35, train_loss:  13.4335, val_loss:  12.2607, grad_norm: 0.0014, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6505, 0.3473, 0.6801, param: [4.15152345 9.49675482 4.97113017 8.86916928], weights: [0.31228161 0.32187036 0.36584803], train_wt_loss:  40.3004, val_wt_loss: 36.7822, train_grp_loss: [11.75062504 15.88012612 11.15797234], val_grp_loss: [10.63169289 14.88980898 11.27641003], train_hist_grp_loss: [3.48699597 4.49511162 8.76408481], cur_train_grp_loss: [0.09476013 0.12310475 0.23740149], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6801, max_kl_dist_index: 2, max_train_grp_loss:  15.8801, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8898, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:36:11,219 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  36, train_loss:  13.4335, val_loss:  12.2607, grad_norm: 0.0014, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6505, 0.3472, 0.6801, param: [4.15151369 9.49604037 4.97155002 8.86959845], weights: [0.31170724 0.32155161 0.36674115], train_wt_loss:  40.3004, val_wt_loss: 36.7821, train_grp_loss: [11.75098956 15.87974482 11.15807238], val_grp_loss: [10.63194956 14.88932686 11.27656581], train_hist_grp_loss: [3.58175907 4.61821337 9.00148848], cur_train_grp_loss: [0.09476311 0.12310175 0.23740367], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6801, max_kl_dist_index: 2, max_train_grp_loss:  15.8797, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8893, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:36:12,261 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  37, train_loss:  13.4335, val_loss:  12.2607, grad_norm: 0.0015, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6505, 0.3472, 0.6801, param: [4.15150179 9.4953305  4.97196826 8.87003259], weights: [0.31113284 0.32123199 0.36763516], train_wt_loss:  40.3004, val_wt_loss: 36.7820, train_grp_loss: [11.75134931 15.87936896 11.15817035], val_grp_loss: [10.63220202 14.88885289 11.27672   ], train_hist_grp_loss: [3.67652512 4.74131217 9.23889427], cur_train_grp_loss: [0.09476604 0.1230988  0.2374058 ], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6801, max_kl_dist_index: 2, max_train_grp_loss:  15.8794, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8889, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:36:13,305 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  38, train_loss:  13.4335, val_loss:  12.2607, grad_norm: 0.0015, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6505, 0.3472, 0.6801, param: [4.15148775 9.49462522 4.97238487 8.87047171], weights: [0.31055842 0.32091152 0.36853006], train_wt_loss:  40.3004, val_wt_loss: 36.7820, train_grp_loss: [11.75170429 15.87899855 11.15826627], val_grp_loss: [10.63245026 14.88838709 11.27687261], train_hist_grp_loss: [3.77129406 4.86440805 9.47630215], cur_train_grp_loss: [0.09476895 0.12309588 0.23740788], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6801, max_kl_dist_index: 2, max_train_grp_loss:  15.8790, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8884, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:36:14,307 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  39, train_loss:  13.4335, val_loss:  12.2606, grad_norm: 0.0015, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6505, 0.3472, 0.6801, param: [4.15147158 9.49392453 4.97279987 8.87091581], weights: [0.30998397 0.3205902  0.36942583], train_wt_loss:  40.3004, val_wt_loss: 36.7819, train_grp_loss: [11.75205448 15.87863359 11.15836014], val_grp_loss: [10.63269429 14.88792945 11.27702364], train_hist_grp_loss: [3.86606587 4.98750107 9.71371207], cur_train_grp_loss: [0.09477181 0.12309301 0.23740992], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6801, max_kl_dist_index: 2, max_train_grp_loss:  15.8786, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8879, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:36:15,369 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  40, train_loss:  13.4335, val_loss:  12.2606, grad_norm: 0.0016, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6505, 0.3472, 0.6801, param: [4.15145326 9.49322843 4.97321325 8.8713649 ], weights: [0.30940951 0.32026802 0.37032247], train_wt_loss:  40.3004, val_wt_loss: 36.7819, train_grp_loss: [11.75239988 15.87827409 11.15845194], val_grp_loss: [10.6329341  14.88748    11.27717307], train_hist_grp_loss: [3.9608405  5.11059125 9.95112399], cur_train_grp_loss: [0.09477463 0.12309018 0.23741192], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6801, max_kl_dist_index: 2, max_train_grp_loss:  15.8783, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8875, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:36:16,414 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  41, train_loss:  13.4335, val_loss:  12.2606, grad_norm: 0.0016, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6505, 0.3472, 0.6801, param: [4.1514328  9.49253692 4.97362499 8.87181899], weights: [0.30883503 0.31994499 0.37121999], train_wt_loss:  40.3004, val_wt_loss: 36.7818, train_grp_loss: [11.75274049 15.87792005 11.15854167], val_grp_loss: [10.63316967 14.88703873 11.2773209 ], train_hist_grp_loss: [ 4.05561792  5.23367864 10.18853786], cur_train_grp_loss: [0.09477742 0.1230874  0.23741387], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6801, max_kl_dist_index: 2, max_train_grp_loss:  15.8779, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8870, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:36:17,469 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  42, train_loss:  13.4335, val_loss:  12.2606, grad_norm: 0.0017, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6505, 0.3472, 0.6801, param: [4.1514102  9.49185    4.97403511 8.87227808], weights: [0.30826053 0.31962111 0.37211836], train_wt_loss:  40.3004, val_wt_loss: 36.7817, train_grp_loss: [11.7530763  15.87757147 11.15862934], val_grp_loss: [10.63340102 14.88660565 11.27746714], train_hist_grp_loss: [ 4.15039809  5.3567633  10.42595364], cur_train_grp_loss: [0.09478017 0.12308465 0.23741578], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6801, max_kl_dist_index: 2, max_train_grp_loss:  15.8776, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8866, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:36:18,496 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  43, train_loss:  13.4335, val_loss:  12.2606, grad_norm: 0.0017, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6505, 0.3472, 0.6801, param: [4.15138545 9.49116769 4.9744436  8.87274217], weights: [0.30768602 0.31929639 0.37301759], train_wt_loss:  40.3004, val_wt_loss: 36.7817, train_grp_loss: [11.7534073  15.87722836 11.15871494], val_grp_loss: [10.63362813 14.88618077 11.27761179], train_hist_grp_loss: [ 4.24518096  5.47984524 10.66337129], cur_train_grp_loss: [0.09478287 0.12308195 0.23741765], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6801, max_kl_dist_index: 2, max_train_grp_loss:  15.8772, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8862, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:36:19,542 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  44, train_loss:  13.4335, val_loss:  12.2606, grad_norm: 0.0017, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6505, 0.3472, 0.6801, param: [4.15135855 9.49048997 4.97485044 8.87321128], weights: [0.30711151 0.31897083 0.37391767], train_wt_loss:  40.3005, val_wt_loss: 36.7817, train_grp_loss: [11.75373349 15.87689073 11.15879846], val_grp_loss: [10.633851   14.88576409 11.27775483], train_hist_grp_loss: [ 4.3399665   5.60292453 10.90079075], cur_train_grp_loss: [0.09478554 0.12307929 0.23741947], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6801, max_kl_dist_index: 2, max_train_grp_loss:  15.8769, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8858, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:36:20,572 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  45, train_loss:  13.4335, val_loss:  12.2605, grad_norm: 0.0018, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6505, 0.3472, 0.6801, param: [4.15132951 9.48981684 4.97525566 8.8736854 ], weights: [0.30653699 0.31864442 0.37481859], train_wt_loss:  40.3005, val_wt_loss: 36.7816, train_grp_loss: [11.75405487 15.87655857 11.15887991], val_grp_loss: [10.63406963 14.88535562 11.27789626], train_hist_grp_loss: [ 4.43475468  5.72600121 11.138212  ], cur_train_grp_loss: [0.09478817 0.12307667 0.23742124], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6801, max_kl_dist_index: 2, max_train_grp_loss:  15.8766, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8854, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:36:21,610 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  46, train_loss:  13.4335, val_loss:  12.2605, grad_norm: 0.0018, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6505, 0.3472, 0.6801, param: [4.15129832 9.48914833 4.97565922 8.87416454], weights: [0.30596246 0.31831719 0.37572035], train_wt_loss:  40.3005, val_wt_loss: 36.7816, train_grp_loss: [11.75437143 15.87623189 11.15895929], val_grp_loss: [10.63428401 14.88495537 11.2780361 ], train_hist_grp_loss: [ 4.52954544  5.8490753  11.37563497], cur_train_grp_loss: [0.09479077 0.1230741  0.23742298], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6801, max_kl_dist_index: 2, max_train_grp_loss:  15.8762, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8850, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:36:22,659 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  47, train_loss:  13.4335, val_loss:  12.2605, grad_norm: 0.0019, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6505, 0.3471, 0.6801, param: [4.15126498 9.48848441 4.97606115 8.87464871], weights: [0.30538794 0.31798912 0.37662294], train_wt_loss:  40.3005, val_wt_loss: 36.7815, train_grp_loss: [11.75468316 15.8759107  11.15903658], val_grp_loss: [10.63449413 14.88456334 11.27817432], train_hist_grp_loss: [ 4.62433876  5.97214687 11.61305964], cur_train_grp_loss: [0.09479332 0.12307157 0.23742467], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6801, max_kl_dist_index: 2, max_train_grp_loss:  15.8759, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8846, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:36:23,710 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  48, train_loss:  13.4335, val_loss:  12.2605, grad_norm: 0.0019, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6505, 0.3471, 0.6801, param: [4.15122949 9.48782509 4.97646142 8.87513791], weights: [0.30481342 0.31766021 0.37752636], train_wt_loss:  40.3005, val_wt_loss: 36.7815, train_grp_loss: [11.75499006 15.87559499 11.15911179], val_grp_loss: [10.6347     14.88417954 11.27831094], train_hist_grp_loss: [ 4.71913459  6.09521594 11.85048595], cur_train_grp_loss: [0.09479583 0.12306908 0.23742631], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6801, max_kl_dist_index: 2, max_train_grp_loss:  15.8756, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8842, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:36:24,739 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  49, train_loss:  13.4335, val_loss:  12.2605, grad_norm: 0.0019, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6505, 0.3471, 0.6801, param: [4.15119184 9.48717039 4.97686005 8.87563215], weights: [0.30423891 0.31733049 0.3784306 ], train_wt_loss:  40.3005, val_wt_loss: 36.7814, train_grp_loss: [11.75529213 15.87528478 11.15918492], val_grp_loss: [10.63490161 14.88380397 11.27844594], train_hist_grp_loss: [ 4.8139329   6.21828257 12.08791386], cur_train_grp_loss: [0.09479831 0.12306663 0.23742791], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6801, max_kl_dist_index: 2, max_train_grp_loss:  15.8753, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8838, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:36:25,794 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  50, train_loss:  13.4335, val_loss:  12.2605, grad_norm: 0.0020, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6505, 0.3471, 0.6801, param: [4.15115204 9.48652029 4.97725702 8.87613143], weights: [0.30366441 0.31699993 0.37933566], train_wt_loss:  40.3005, val_wt_loss: 36.7814, train_grp_loss: [11.75558935 15.87498006 11.15925596], val_grp_loss: [10.63509896 14.88343665 11.27857933], train_hist_grp_loss: [ 4.90873364  6.3413468  12.32534333], cur_train_grp_loss: [0.09480074 0.12306422 0.23742947], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6801, max_kl_dist_index: 2, max_train_grp_loss:  15.8750, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8834, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:36:26,821 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  51, train_loss:  13.4335, val_loss:  12.2605, grad_norm: 0.0020, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6506, 0.3471, 0.6801, param: [4.15111008 9.48587479 4.97765233 8.87663575], weights: [0.30308992 0.31666856 0.38024152], train_wt_loss:  40.3005, val_wt_loss: 36.7814, train_grp_loss: [11.75588173 15.87468084 11.15932491], val_grp_loss: [10.63529203 14.88307758 11.27871111], train_hist_grp_loss: [ 5.00353678  6.46440866 12.56277431], cur_train_grp_loss: [0.09480314 0.12306186 0.23743098], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6801, max_kl_dist_index: 2, max_train_grp_loss:  15.8747, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8831, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:36:27,811 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  52, train_loss:  13.4335, val_loss:  12.2604, grad_norm: 0.0021, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6506, 0.3471, 0.6801, param: [4.15106597 9.48523391 4.97804598 8.87714512], weights: [0.30251544 0.31633637 0.38114819], train_wt_loss:  40.3005, val_wt_loss: 36.7813, train_grp_loss: [11.75616925 15.87438712 11.15939177], val_grp_loss: [10.63548084 14.88272676 11.27884127], train_hist_grp_loss: [ 5.09834228  6.5874682  12.80020675], cur_train_grp_loss: [0.0948055  0.12305954 0.23743244], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6801, max_kl_dist_index: 2, max_train_grp_loss:  15.8744, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8827, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:36:28,835 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  53, train_loss:  13.4335, val_loss:  12.2604, grad_norm: 0.0021, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6506, 0.3471, 0.6801, param: [4.1510197  9.48459764 4.97843797 8.87765955], weights: [0.30194098 0.31600336 0.38205566], train_wt_loss:  40.3005, val_wt_loss: 36.7813, train_grp_loss: [11.75645192 15.87409891 11.15945653], val_grp_loss: [10.63566536 14.8823842  11.2789698 ], train_hist_grp_loss: [ 5.1931501   6.71052546 13.03764062], cur_train_grp_loss: [0.09480782 0.12305726 0.23743387], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6801, max_kl_dist_index: 2, max_train_grp_loss:  15.8741, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8824, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:36:29,857 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  54, train_loss:  13.4335, val_loss:  12.2604, grad_norm: 0.0021, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6506, 0.3471, 0.6801, param: [4.15097126 9.48396598 4.97882829 8.87817904], weights: [0.30136655 0.31566954 0.38296391], train_wt_loss:  40.3005, val_wt_loss: 36.7813, train_grp_loss: [11.75672973 15.87381621 11.1595192 ], val_grp_loss: [10.63584561 14.8820499  11.27909672], train_hist_grp_loss: [ 5.28796019  6.83358049 13.27507586], cur_train_grp_loss: [0.0948101  0.12305503 0.23743525], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6801, max_kl_dist_index: 2, max_train_grp_loss:  15.8738, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8820, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:36:30,869 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  55, train_loss:  13.4335, val_loss:  12.2604, grad_norm: 0.0022, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6506, 0.3471, 0.6801, param: [4.15092067 9.48333893 4.97921693 8.8787036 ], weights: [0.30079214 0.31533491 0.38387295], train_wt_loss:  40.3006, val_wt_loss: 36.7813, train_grp_loss: [11.75700267 15.87353902 11.15957977], val_grp_loss: [10.63602158 14.88172388 11.27922201], train_hist_grp_loss: [ 5.38277253  6.95663333 13.51251244], cur_train_grp_loss: [0.09481234 0.12305284 0.23743658], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6801, max_kl_dist_index: 2, max_train_grp_loss:  15.8735, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8817, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:36:31,906 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  56, train_loss:  13.4335, val_loss:  12.2604, grad_norm: 0.0022, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6506, 0.3471, 0.6801, param: [4.15086792 9.4827165  4.97960391 8.87923322], weights: [0.30021775 0.31499947 0.38478277], train_wt_loss:  40.3006, val_wt_loss: 36.7813, train_grp_loss: [11.75727075 15.87326735 11.15963824], val_grp_loss: [10.63619326 14.88140614 11.27934567], train_hist_grp_loss: [ 5.47758707  7.07968402 13.74995031], cur_train_grp_loss: [0.09481454 0.12305069 0.23743787], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6801, max_kl_dist_index: 2, max_train_grp_loss:  15.8733, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8814, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:36:32,947 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  57, train_loss:  13.4335, val_loss:  12.2604, grad_norm: 0.0023, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6506, 0.3471, 0.6801, param: [4.150813   9.48209868 4.97998921 8.87976791], weights: [0.2996434  0.31466323 0.38569337], train_wt_loss:  40.3006, val_wt_loss: 36.7812, train_grp_loss: [11.75753394 15.8730012  11.1596946 ], val_grp_loss: [10.63636064 14.88109668 11.27946771], train_hist_grp_loss: [ 5.57240377  7.20273261 13.98738942], cur_train_grp_loss: [0.0948167  0.12304858 0.23743911], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6801, max_kl_dist_index: 2, max_train_grp_loss:  15.8730, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8811, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:36:33,968 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  58, train_loss:  13.4335, val_loss:  12.2604, grad_norm: 0.0023, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6506, 0.3471, 0.6801, param: [4.15075591 9.48148548 4.98037283 8.88030769], weights: [0.29906908 0.31432619 0.38660473], train_wt_loss:  40.3006, val_wt_loss: 36.7812, train_grp_loss: [11.75779226 15.87274057 11.15974886], val_grp_loss: [10.63652374 14.88079551 11.27958812], train_hist_grp_loss: [ 5.66722259  7.32577913 14.22482973], cur_train_grp_loss: [0.09481882 0.12304652 0.23744031], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6801, max_kl_dist_index: 2, max_train_grp_loss:  15.8727, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8808, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:36:35,002 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  59, train_loss:  13.4335, val_loss:  12.2604, grad_norm: 0.0023, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6506, 0.3471, 0.6801, param: [4.15069666 9.4808769  4.98075476 8.88085254], weights: [0.2984948  0.31398836 0.38751685], train_wt_loss:  40.3006, val_wt_loss: 36.7812, train_grp_loss: [11.7580457  15.87248547 11.15980102], val_grp_loss: [10.63668253 14.88050263 11.27970689], train_hist_grp_loss: [ 5.76204349  7.44882363 14.4622712 ], cur_train_grp_loss: [0.09482091 0.1230445  0.23744147], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6801, max_kl_dist_index: 2, max_train_grp_loss:  15.8725, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8805, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:36:36,050 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  60, train_loss:  13.4335, val_loss:  12.2604, grad_norm: 0.0024, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6506, 0.3471, 0.6801, param: [4.15063525 9.48027293 4.98113501 8.88140248], weights: [0.29792055 0.31364972 0.38842972], train_wt_loss:  40.3006, val_wt_loss: 36.7812, train_grp_loss: [11.75829424 15.8722359  11.15985107], val_grp_loss: [10.63683703 14.88021806 11.27982404], train_hist_grp_loss: [ 5.85686644  7.57186615 14.69971377], cur_train_grp_loss: [0.09482295 0.12304252 0.23744257], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6801, max_kl_dist_index: 2, max_train_grp_loss:  15.8722, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8802, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:36:37,068 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  61, train_loss:  13.4335, val_loss:  12.2604, grad_norm: 0.0024, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6507, 0.3471, 0.6801, param: [4.15057166 9.47967358 4.98151357 8.88195751], weights: [0.29734635 0.3133103  0.38934335], train_wt_loss:  40.3006, val_wt_loss: 36.7812, train_grp_loss: [11.7585379  15.87199186 11.159899  ], val_grp_loss: [10.63698722 14.8799418  11.27993955], train_hist_grp_loss: [ 5.9516914   7.69490674 14.93715741], cur_train_grp_loss: [0.09482495 0.12304059 0.23744364], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6801, max_kl_dist_index: 2, max_train_grp_loss:  15.8720, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8799, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:36:38,081 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  62, train_loss:  13.4335, val_loss:  12.2604, grad_norm: 0.0024, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6507, 0.3471, 0.6801, param: [4.1505059  9.47907886 4.98189043 8.88251763], weights: [0.29677219 0.31297009 0.39025772], train_wt_loss:  40.3006, val_wt_loss: 36.7812, train_grp_loss: [11.75877665 15.87175337 11.15994482], val_grp_loss: [10.6371331  14.87967384 11.28005342], train_hist_grp_loss: [ 6.04651831  7.81794544 15.17460207], cur_train_grp_loss: [0.09482692 0.1230387  0.23744466], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6801, max_kl_dist_index: 2, max_train_grp_loss:  15.8718, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8797, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:36:39,111 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  63, train_loss:  13.4335, val_loss:  12.2604, grad_norm: 0.0025, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6507, 0.3471, 0.6801, param: [4.15043798 9.47848875 4.9822656  8.88308285], weights: [0.29619809 0.3126291  0.39117282], train_wt_loss:  40.3006, val_wt_loss: 36.7812, train_grp_loss: [11.7590105  15.87152041 11.15998853], val_grp_loss: [10.63727467 14.87941421 11.28016565], train_hist_grp_loss: [ 6.14134716  7.94098228 15.41204771], cur_train_grp_loss: [0.09482884 0.12303685 0.23744563], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6801, max_kl_dist_index: 2, max_train_grp_loss:  15.8715, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8794, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:36:40,135 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  64, train_loss:  13.4335, val_loss:  12.2604, grad_norm: 0.0025, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6507, 0.3471, 0.6801, param: [4.15036788 9.47790326 4.98263907 8.88365318], weights: [0.29562403 0.31228732 0.39208865], train_wt_loss:  40.3006, val_wt_loss: 36.7812, train_grp_loss: [11.75923945 15.871293   11.16003012], val_grp_loss: [10.63741193 14.8791629  11.28027624], train_hist_grp_loss: [ 6.23617789  8.06401732 15.64949427], cur_train_grp_loss: [0.09483073 0.12303504 0.23744656], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6801, max_kl_dist_index: 2, max_train_grp_loss:  15.8713, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8792, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:36:41,160 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  65, train_loss:  13.4335, val_loss:  12.2604, grad_norm: 0.0026, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6507, 0.3471, 0.6801, param: [4.1502956  9.4773224  4.98301084 8.8842286 ], weights: [0.29505003 0.31194476 0.39300521], train_wt_loss:  40.3006, val_wt_loss: 36.7812, train_grp_loss: [11.75946349 15.87107113 11.16006959], val_grp_loss: [10.63754487 14.87891992 11.2803852 ], train_hist_grp_loss: [ 6.33101046  8.1870506  15.88694172], cur_train_grp_loss: [0.09483258 0.12303328 0.23744745], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6801, max_kl_dist_index: 2, max_train_grp_loss:  15.8711, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8789, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:36:42,202 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  66, train_loss:  13.4336, val_loss:  12.2604, grad_norm: 0.0026, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6507, 0.3471, 0.6802, param: [4.15022115 9.47674616 4.9833809  8.88480914], weights: [0.29447608 0.31160143 0.39392248], train_wt_loss:  40.3007, val_wt_loss: 36.7812, train_grp_loss: [11.75968261 15.87085482 11.16010695], val_grp_loss: [10.63767349 14.87868528 11.2804925 ], train_hist_grp_loss: [ 6.42584485  8.31008216 16.12439001], cur_train_grp_loss: [0.09483438 0.12303156 0.23744829], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6802, max_kl_dist_index: 2, max_train_grp_loss:  15.8709, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8787, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:36:43,269 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  67, train_loss:  13.4336, val_loss:  12.2604, grad_norm: 0.0026, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6507, 0.3471, 0.6802, param: [4.15014453 9.47617454 4.98374925 8.88539479], weights: [0.2939022  0.31125733 0.39484047], train_wt_loss:  40.3007, val_wt_loss: 36.7812, train_grp_loss: [11.75989682 15.87064406 11.16014218], val_grp_loss: [10.63779779 14.87845897 11.28059817], train_hist_grp_loss: [ 6.520681    8.43311205 16.36183909], cur_train_grp_loss: [0.09483615 0.12302988 0.23744908], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6802, max_kl_dist_index: 2, max_train_grp_loss:  15.8706, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8785, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:36:44,290 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  68, train_loss:  13.4336, val_loss:  12.2604, grad_norm: 0.0027, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6508, 0.3471, 0.6802, param: [4.15006573 9.47560754 4.98411589 8.88598556], weights: [0.29332838 0.31091246 0.39575916], train_wt_loss:  40.3007, val_wt_loss: 36.7812, train_grp_loss: [11.7601061  15.87043886 11.16017529], val_grp_loss: [10.63791776 14.87824101 11.28070219], train_hist_grp_loss: [ 6.61551887  8.55614029 16.59928893], cur_train_grp_loss: [0.09483788 0.12302825 0.23744983], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6802, max_kl_dist_index: 2, max_train_grp_loss:  15.8704, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8782, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:36:45,320 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  69, train_loss:  13.4336, val_loss:  12.2604, grad_norm: 0.0027, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6508, 0.3471, 0.6802, param: [4.14998475 9.47504517 4.98448081 8.88658144], weights: [0.29275463 0.31056682 0.39667855], train_wt_loss:  40.3007, val_wt_loss: 36.7812, train_grp_loss: [11.76031046 15.87023922 11.16020627], val_grp_loss: [10.6380334  14.8780314  11.28080456], train_hist_grp_loss: [ 6.71035844  8.67916695 16.83673946], cur_train_grp_loss: [0.09483957 0.12302666 0.23745054], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6802, max_kl_dist_index: 2, max_train_grp_loss:  15.8702, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8780, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2375, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:36:46,372 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  70, train_loss:  13.4336, val_loss:  12.2604, grad_norm: 0.0027, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6508, 0.3471, 0.6802, param: [4.14990159 9.47448742 4.98484401 8.88718245], weights: [0.29218095 0.31022042 0.39759863], train_wt_loss:  40.3007, val_wt_loss: 36.7812, train_grp_loss: [11.76050989 15.87004514 11.16023512], val_grp_loss: [10.63814472 14.87783015 11.28090528], train_hist_grp_loss: [ 6.80519965  8.80219206 17.07419066], cur_train_grp_loss: [0.09484121 0.12302511 0.2374512 ], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6802, max_kl_dist_index: 2, max_train_grp_loss:  15.8700, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8778, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2375, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:36:47,414 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  71, train_loss:  13.4336, val_loss:  12.2604, grad_norm: 0.0028, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6508, 0.3471, 0.6802, param: [4.14981625 9.4739343  4.98520549 8.88778859], weights: [0.29160734 0.30987326 0.3985194 ], train_wt_loss:  40.3007, val_wt_loss: 36.7812, train_grp_loss: [11.76070438 15.86985663 11.16026185], val_grp_loss: [10.63825169 14.87763726 11.28100435], train_hist_grp_loss: [ 6.90004248  8.92521567 17.31164247], cur_train_grp_loss: [0.09484282 0.12302361 0.23745181], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6802, max_kl_dist_index: 2, max_train_grp_loss:  15.8699, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8776, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2375, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:36:48,441 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  72, train_loss:  13.4336, val_loss:  12.2604, grad_norm: 0.0028, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6508, 0.3471, 0.6802, param: [4.14972872 9.47338579 4.98556524 8.88839985], weights: [0.29103381 0.30952534 0.39944085], train_wt_loss:  40.3007, val_wt_loss: 36.7812, train_grp_loss: [11.76089393 15.86967369 11.16028645], val_grp_loss: [10.63835433 14.87745274 11.28110177], train_hist_grp_loss: [ 6.99488687  9.04823781 17.54909485], cur_train_grp_loss: [0.09484439 0.12302214 0.23745238], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6802, max_kl_dist_index: 2, max_train_grp_loss:  15.8697, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8775, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2375, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:36:49,481 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  73, train_loss:  13.4336, val_loss:  12.2604, grad_norm: 0.0028, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6508, 0.3471, 0.6802, param: [4.14963902 9.47284192 4.98592327 8.88901625], weights: [0.29046036 0.30917668 0.40036297], train_wt_loss:  40.3007, val_wt_loss: 36.7813, train_grp_loss: [11.76107855 15.86949632 11.16030892], val_grp_loss: [10.63845263 14.87727659 11.28119753], train_hist_grp_loss: [ 7.08973278  9.17125854 17.78654776], cur_train_grp_loss: [0.09484592 0.12302073 0.2374529 ], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6802, max_kl_dist_index: 2, max_train_grp_loss:  15.8695, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8773, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2375, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:36:50,516 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  74, train_loss:  13.4336, val_loss:  12.2604, grad_norm: 0.0029, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6509, 0.3471, 0.6803, param: [4.14954713 9.47230267 4.98627956 8.88963779], weights: [0.28988699 0.30882726 0.40128575], train_wt_loss:  40.3007, val_wt_loss: 36.7813, train_grp_loss: [11.76125822 15.86932453 11.16032925], val_grp_loss: [10.63854659 14.87710882 11.28129164], train_hist_grp_loss: [ 7.18458019  9.29427789 18.02400114], cur_train_grp_loss: [0.09484741 0.12301935 0.23745338], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6803, max_kl_dist_index: 2, max_train_grp_loss:  15.8693, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8771, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2375, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:36:51,539 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  75, train_loss:  13.4336, val_loss:  12.2604, grad_norm: 0.0029, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6509, 0.3471, 0.6803, param: [4.14945305 9.47176804 4.98663411 8.89026446], weights: [0.2893137  0.30847709 0.4022092 ], train_wt_loss:  40.3008, val_wt_loss: 36.7813, train_grp_loss: [11.76143294 15.86915832 11.16034745], val_grp_loss: [10.6386362  14.87694943 11.28138409], train_hist_grp_loss: [ 7.27942905  9.41729591 18.26145495], cur_train_grp_loss: [0.09484886 0.12301802 0.23745381], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6803, max_kl_dist_index: 2, max_train_grp_loss:  15.8692, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8769, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2375, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:36:52,594 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  76, train_loss:  13.4336, val_loss:  12.2604, grad_norm: 0.0029, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6509, 0.3471, 0.6803, param: [4.14935679 9.47123804 4.98698693 8.89089628], weights: [0.28874051 0.30812619 0.4031333 ], train_wt_loss:  40.3008, val_wt_loss: 36.7813, train_grp_loss: [11.7616027  15.86899769 11.16036351], val_grp_loss: [10.63872146 14.87679842 11.28147489], train_hist_grp_loss: [ 7.37427931  9.54031264 18.49890915], cur_train_grp_loss: [0.09485027 0.12301673 0.2374542 ], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6803, max_kl_dist_index: 2, max_train_grp_loss:  15.8690, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8768, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2375, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:36:53,632 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  77, train_loss:  13.4336, val_loss:  12.2605, grad_norm: 0.0030, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6509, 0.3471, 0.6803, param: [4.14925833 9.47071266 4.987338   8.89153324], weights: [0.28816741 0.30777454 0.40405805], train_wt_loss:  40.3008, val_wt_loss: 36.7814, train_grp_loss: [11.76176752 15.86884264 11.16037744], val_grp_loss: [10.63880238 14.87665581 11.28156403], train_hist_grp_loss: [ 7.46913095  9.66332813 18.73636369], cur_train_grp_loss: [0.09485163 0.12301549 0.23745454], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6803, max_kl_dist_index: 2, max_train_grp_loss:  15.8688, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8767, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2375, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:36:54,663 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  78, train_loss:  13.4336, val_loss:  12.2605, grad_norm: 0.0030, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6509, 0.3471, 0.6803, param: [4.14915769 9.47019191 4.98768733 8.89217536], weights: [0.2875944  0.30742216 0.40498344], train_wt_loss:  40.3008, val_wt_loss: 36.7814, train_grp_loss: [11.76192737 15.86869319 11.16038923], val_grp_loss: [10.63887894 14.87652159 11.28165151], train_hist_grp_loss: [ 7.56398391  9.78634241 18.97381853], cur_train_grp_loss: [0.09485296 0.12301428 0.23745484], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6803, max_kl_dist_index: 2, max_train_grp_loss:  15.8687, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8765, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2375, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:36:55,716 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  79, train_loss:  13.4336, val_loss:  12.2605, grad_norm: 0.0031, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6510, 0.3471, 0.6803, param: [4.14905486 9.46967578 4.9880349  8.89282262], weights: [0.28702149 0.30706904 0.40590947], train_wt_loss:  40.3008, val_wt_loss: 36.7814, train_grp_loss: [11.76208226 15.86854932 11.16039887], val_grp_loss: [10.63895115 14.87639578 11.28173733], train_hist_grp_loss: [ 7.65883817  9.90935554 19.21127362], cur_train_grp_loss: [0.09485425 0.12301313 0.23745509], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6803, max_kl_dist_index: 2, max_train_grp_loss:  15.8685, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8764, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2375, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:36:56,747 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  80, train_loss:  13.4336, val_loss:  12.2605, grad_norm: 0.0031, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6510, 0.3471, 0.6803, param: [4.14894984 9.46916428 4.98838073 8.89347503], weights: [0.28644868 0.3067152  0.40683612], train_wt_loss:  40.3008, val_wt_loss: 36.7815, train_grp_loss: [11.76223219 15.86841105 11.16040638], val_grp_loss: [10.639019   14.87627837 11.28182148], train_hist_grp_loss: [ 7.75369367 10.03236755 19.44872892], cur_train_grp_loss: [0.0948555  0.12301201 0.2374553 ], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6803, max_kl_dist_index: 2, max_train_grp_loss:  15.8684, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8763, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2375, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:36:57,765 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  81, train_loss:  13.4336, val_loss:  12.2605, grad_norm: 0.0031, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6510, 0.3471, 0.6804, param: [4.14884262 9.4686574  4.98872479 8.89413261], weights: [0.28587598 0.30636062 0.4077634 ], train_wt_loss:  40.3008, val_wt_loss: 36.7815, train_grp_loss: [11.76237715 15.86827838 11.16041175], val_grp_loss: [10.63908249 14.87616937 11.28190398], train_hist_grp_loss: [ 7.84855038 10.15537848 19.68618437], cur_train_grp_loss: [0.09485671 0.12301094 0.23745545], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6804, max_kl_dist_index: 2, max_train_grp_loss:  15.8683, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8762, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2375, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:36:58,795 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  82, train_loss:  13.4336, val_loss:  12.2605, grad_norm: 0.0032, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6510, 0.3471, 0.6804, param: [4.14873322 9.46815514 4.9890671  8.89479534], weights: [0.28530338 0.30600533 0.40869129], train_wt_loss:  40.3008, val_wt_loss: 36.7815, train_grp_loss: [11.76251713 15.8681513  11.16041497], val_grp_loss: [10.63914162 14.87606879 11.28198481], train_hist_grp_loss: [ 7.94340826 10.27838839 19.92363994], cur_train_grp_loss: [0.09485788 0.12300991 0.23745557], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6804, max_kl_dist_index: 2, max_train_grp_loss:  15.8682, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8761, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2375, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:36:59,840 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  83, train_loss:  13.4336, val_loss:  12.2605, grad_norm: 0.0032, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6510, 0.3471, 0.6804, param: [4.14862161 9.46765751 4.98940764 8.89546323], weights: [0.2847309  0.30564932 0.40961978], train_wt_loss:  40.3008, val_wt_loss: 36.7816, train_grp_loss: [11.76265214 15.86802983 11.16041605], val_grp_loss: [10.63919639 14.87597663 11.28206397], train_hist_grp_loss: [ 8.03826727 10.40139732 20.16109558], cur_train_grp_loss: [0.09485901 0.12300892 0.23745564], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6804, max_kl_dist_index: 2, max_train_grp_loss:  15.8680, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8760, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2375, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:37:00,879 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  84, train_loss:  13.4336, val_loss:  12.2605, grad_norm: 0.0032, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6511, 0.3471, 0.6804, param: [4.14850781 9.46716449 4.98974642 8.89613629], weights: [0.28415853 0.30529259 0.41054888], train_wt_loss:  40.3009, val_wt_loss: 36.7816, train_grp_loss: [11.76278217 15.86791396 11.16041498], val_grp_loss: [10.63924679 14.87589289 11.28214147], train_hist_grp_loss: [ 8.13312737 10.5244053  20.39855124], cur_train_grp_loss: [0.0948601  0.12300798 0.23745566], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6804, max_kl_dist_index: 2, max_train_grp_loss:  15.8679, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8759, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2375, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:37:01,929 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  85, train_loss:  13.4336, val_loss:  12.2606, grad_norm: 0.0033, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6511, 0.3471, 0.6804, param: [4.14839182 9.46667611 4.99008343 8.89681451], weights: [0.28358628 0.30493515 0.41147858], train_wt_loss:  40.3009, val_wt_loss: 36.7817, train_grp_loss: [11.76290723 15.8678037  11.16041177], val_grp_loss: [10.63929283 14.87581758 11.2822173 ], train_hist_grp_loss: [ 8.22798851 10.64741239 20.63600688], cur_train_grp_loss: [0.09486115 0.12300708 0.23745564], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6804, max_kl_dist_index: 2, max_train_grp_loss:  15.8678, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8758, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2375, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:37:02,961 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  86, train_loss:  13.4336, val_loss:  12.2606, grad_norm: 0.0033, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6511, 0.3471, 0.6805, param: [4.14827362 9.46619234 4.99041866 8.8974979 ], weights: [0.28301415 0.304577   0.41240886], train_wt_loss:  40.3009, val_wt_loss: 36.7817, train_grp_loss: [11.76302729 15.86769906 11.1604064 ], val_grp_loss: [10.6393345  14.87575071 11.28229147], train_hist_grp_loss: [ 8.32285067 10.77041862 20.87346245], cur_train_grp_loss: [0.09486216 0.12300623 0.23745557], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6805, max_kl_dist_index: 2, max_train_grp_loss:  15.8677, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8758, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2375, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:37:04,023 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  87, train_loss:  13.4336, val_loss:  12.2606, grad_norm: 0.0033, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6511, 0.3471, 0.6805, param: [4.14815323 9.46571319 4.99075212 8.89818646], weights: [0.28244214 0.30421814 0.41333972], train_wt_loss:  40.3009, val_wt_loss: 36.7818, train_grp_loss: [11.76314237 15.86760002 11.1603989 ], val_grp_loss: [10.63937179 14.87569227 11.28236396], train_hist_grp_loss: [ 8.41771379 10.89342404 21.1109179 ], cur_train_grp_loss: [0.09486312 0.12300542 0.23745546], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6805, max_kl_dist_index: 2, max_train_grp_loss:  15.8676, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8757, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2375, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:37:05,050 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  88, train_loss:  13.4336, val_loss:  12.2606, grad_norm: 0.0034, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6512, 0.3472, 0.6805, param: [4.14803063 9.46523867 4.99108379 8.8988802 ], weights: [0.28187026 0.30385858 0.41427116], train_wt_loss:  40.3009, val_wt_loss: 36.7818, train_grp_loss: [11.76325247 15.8675066  11.16038924], val_grp_loss: [10.63940472 14.87564228 11.28243479], train_hist_grp_loss: [ 8.51257784 11.01642869 21.3483732 ], cur_train_grp_loss: [0.09486405 0.12300465 0.2374553 ], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6805, max_kl_dist_index: 2, max_train_grp_loss:  15.8675, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8756, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2375, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:37:06,096 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  89, train_loss:  13.4336, val_loss:  12.2606, grad_norm: 0.0034, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6512, 0.3472, 0.6805, param: [4.14790584 9.46476876 4.99141369 8.89957911], weights: [0.2812985  0.30349833 0.41520317], train_wt_loss:  40.3009, val_wt_loss: 36.7819, train_grp_loss: [11.76335757 15.8674188  11.16037743], val_grp_loss: [10.63943327 14.87560073 11.28250395], train_hist_grp_loss: [ 8.60744278 11.13943262 21.58582829], cur_train_grp_loss: [0.09486494 0.12300393 0.23745509], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6805, max_kl_dist_index: 2, max_train_grp_loss:  15.8674, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8756, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2375, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:37:07,103 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  90, train_loss:  13.4336, val_loss:  12.2606, grad_norm: 0.0034, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6512, 0.3472, 0.6806, param: [4.14777884 9.46430347 4.99174179 8.90028319], weights: [0.28072689 0.30313737 0.41613574], train_wt_loss:  40.3009, val_wt_loss: 36.7819, train_grp_loss: [11.76345767 15.86733662 11.16036347], val_grp_loss: [10.63945744 14.87556763 11.28257143], train_hist_grp_loss: [ 8.70230857 11.26243586 21.82328313], cur_train_grp_loss: [0.09486579 0.12300325 0.23745484], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6806, max_kl_dist_index: 2, max_train_grp_loss:  15.8673, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8756, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2375, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:37:08,130 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  91, train_loss:  13.4336, val_loss:  12.2607, grad_norm: 0.0035, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6512, 0.3472, 0.6806, param: [4.14764964 9.46384281 4.9920681  8.90099246], weights: [0.28015541 0.30277573 0.41706886], train_wt_loss:  40.3009, val_wt_loss: 36.7820, train_grp_loss: [11.76355278 15.86726007 11.16034736], val_grp_loss: [10.63947724 14.87554299 11.28263725], train_hist_grp_loss: [ 8.79717516 11.38543847 22.06073767], cur_train_grp_loss: [0.09486659 0.12300261 0.23745454], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6806, max_kl_dist_index: 2, max_train_grp_loss:  15.8673, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8755, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2375, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:37:09,188 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  92, train_loss:  13.4336, val_loss:  12.2607, grad_norm: 0.0035, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6513, 0.3472, 0.6806, param: [4.14751823 9.46338675 4.99239262 8.9017069 ], weights: [0.27958407 0.3024134  0.41800253], train_wt_loss:  40.3009, val_wt_loss: 36.7821, train_grp_loss: [11.76364289 15.86718914 11.16032909], val_grp_loss: [10.63949266 14.8755268  11.28270139], train_hist_grp_loss: [ 8.89204252 11.50844049 22.29819187], cur_train_grp_loss: [0.09486736 0.12300202 0.2374542 ], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6806, max_kl_dist_index: 2, max_train_grp_loss:  15.8672, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8755, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2375, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:37:10,228 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  93, train_loss:  13.4337, val_loss:  12.2607, grad_norm: 0.0035, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6513, 0.3472, 0.6806, param: [4.14738462 9.46293532 4.99271535 8.90242653], weights: [0.27901287 0.30205038 0.41893675], train_wt_loss:  40.3010, val_wt_loss: 36.7821, train_grp_loss: [11.763728   15.86712383 11.16030868], val_grp_loss: [10.63950369 14.87551908 11.28276386], train_hist_grp_loss: [ 8.98691061 11.63144195 22.53564568], cur_train_grp_loss: [0.09486809 0.12300147 0.23745381], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6806, max_kl_dist_index: 2, max_train_grp_loss:  15.8671, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8755, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2375, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:37:11,244 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  94, train_loss:  13.4337, val_loss:  12.2607, grad_norm: 0.0036, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6513, 0.3472, 0.6807, param: [4.14724881 9.4624885  4.99303627 8.90315133], weights: [0.27844182 0.30168669 0.4198715 ], train_wt_loss:  40.3010, val_wt_loss: 36.7822, train_grp_loss: [11.7638081  15.86706416 11.16028611], val_grp_loss: [10.63951035 14.87551982 11.28282465], train_hist_grp_loss: [ 9.08177939 11.75444291 22.77309906], cur_train_grp_loss: [0.09486877 0.12300096 0.23745338], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6807, max_kl_dist_index: 2, max_train_grp_loss:  15.8671, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8755, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2375, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:37:12,286 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  95, train_loss:  13.4337, val_loss:  12.2608, grad_norm: 0.0036, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6513, 0.3472, 0.6807, param: [4.14711078 9.46204629 4.99335538 8.90388133], weights: [0.27787091 0.30132231 0.42080677], train_wt_loss:  40.3010, val_wt_loss: 36.7823, train_grp_loss: [11.7638832  15.86701013 11.16026138], val_grp_loss: [10.63951263 14.87552904 11.28288377], train_hist_grp_loss: [ 9.17664881 11.87744341 23.01055195], cur_train_grp_loss: [0.09486942 0.1230005  0.2374529 ], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6807, max_kl_dist_index: 2, max_train_grp_loss:  15.8670, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8755, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2375, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:37:13,313 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  96, train_loss:  13.4337, val_loss:  12.2608, grad_norm: 0.0036, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6514, 0.3472, 0.6807, param: [4.14697055 9.46160869 4.99367269 8.90461651], weights: [0.27730016 0.30095727 0.42174257], train_wt_loss:  40.3010, val_wt_loss: 36.7823, train_grp_loss: [11.76395328 15.86696173 11.1602345 ], val_grp_loss: [10.63951051 14.87554673 11.28294122], train_hist_grp_loss: [ 9.27151883 12.00044349 23.24800432], cur_train_grp_loss: [0.09487003 0.12300008 0.23745237], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6807, max_kl_dist_index: 2, max_train_grp_loss:  15.8670, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8755, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2375, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:37:14,348 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  97, train_loss:  13.4337, val_loss:  12.2608, grad_norm: 0.0036, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6514, 0.3472, 0.6807, param: [4.14682811 9.46117571 4.99398819 8.90535688], weights: [0.27672957 0.30059155 0.42267888], train_wt_loss:  40.3010, val_wt_loss: 36.7824, train_grp_loss: [11.76401836 15.86691896 11.16020547], val_grp_loss: [10.63950402 14.8755729  11.28299699], train_hist_grp_loss: [ 9.36638942 12.12344319 23.48545612], cur_train_grp_loss: [0.09487059 0.1229997  0.2374518 ], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6807, max_kl_dist_index: 2, max_train_grp_loss:  15.8669, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8756, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2375, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:37:15,379 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  98, train_loss:  13.4337, val_loss:  12.2608, grad_norm: 0.0037, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6514, 0.3473, 0.6808, param: [4.14668345 9.46074734 4.99430187 8.90610244], weights: [0.27615914 0.30022516 0.4236157 ], train_wt_loss:  40.3010, val_wt_loss: 36.7825, train_grp_loss: [11.76407842 15.86688184 11.16017428], val_grp_loss: [10.63949314 14.87560754 11.28305108], train_hist_grp_loss: [ 9.46126054 12.24644256 23.7229073 ], cur_train_grp_loss: [0.09487112 0.12299937 0.23745118], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6808, max_kl_dist_index: 2, max_train_grp_loss:  15.8669, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8756, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2375, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:37:16,405 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  99, train_loss:  13.4337, val_loss:  12.2609, grad_norm: 0.0037, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6515, 0.3473, 0.6808, param: [4.14653659 9.46032358 4.99461373 8.90685318], weights: [0.27558886 0.29985812 0.42455302], train_wt_loss:  40.3010, val_wt_loss: 36.7826, train_grp_loss: [11.76413347 15.86685036 11.16014093], val_grp_loss: [10.63947787 14.87565068 11.2831035 ], train_hist_grp_loss: [ 9.55613214 12.36944165 23.96035782], cur_train_grp_loss: [0.0948716  0.12299908 0.23745052], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6808, max_kl_dist_index: 2, max_train_grp_loss:  15.8669, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8757, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2375, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:37:17,426 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  100, train_loss:  13.4337, val_loss:  12.2609, grad_norm: 0.0037, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6515, 0.3473, 0.6808, param: [4.14638751 9.45990442 4.99492377 8.90760912], weights: [0.27501876 0.29949041 0.42549083], train_wt_loss:  40.3010, val_wt_loss: 36.7827, train_grp_loss: [11.7641835  15.86682453 11.16010543], val_grp_loss: [10.63945821 14.8757023  11.28315425], train_hist_grp_loss: [ 9.65100418 12.49244049 24.19780762], cur_train_grp_loss: [0.09487204 0.12299884 0.23744981], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6808, max_kl_dist_index: 2, max_train_grp_loss:  15.8668, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8757, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:37:18,458 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  101, train_loss:  13.4337, val_loss:  12.2609, grad_norm: 0.0038, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6515, 0.3473, 0.6809, param: [4.14623622 9.45948987 4.99523199 8.90837026], weights: [0.27444882 0.29912205 0.42642913], train_wt_loss:  40.3011, val_wt_loss: 36.7827, train_grp_loss: [11.76422851 15.86680434 11.16006777], val_grp_loss: [10.63943416 14.87576242 11.28320331], train_hist_grp_loss: [ 9.74587663 12.61543913 24.43525667], cur_train_grp_loss: [0.09487245 0.12299864 0.23744905], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6809, max_kl_dist_index: 2, max_train_grp_loss:  15.8668, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8758, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:37:19,482 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  102, train_loss:  13.4337, val_loss:  12.2609, grad_norm: 0.0038, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6515, 0.3473, 0.6809, param: [4.14608272 9.45907993 4.99553837 8.90913658], weights: [0.27387905 0.29875303 0.42736791], train_wt_loss:  40.3011, val_wt_loss: 36.7828, train_grp_loss: [11.7642685  15.8667898  11.16002795], val_grp_loss: [10.63940573 14.87583103 11.2832507 ], train_hist_grp_loss: [ 9.84074944 12.73843761 24.67270493], cur_train_grp_loss: [0.09487281 0.12299848 0.23744825], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6809, max_kl_dist_index: 2, max_train_grp_loss:  15.8668, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8758, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:37:20,525 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  103, train_loss:  13.4337, val_loss:  12.2610, grad_norm: 0.0038, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6516, 0.3473, 0.6809, param: [4.145927   9.45867458 4.99584293 8.9099081 ], weights: [0.27330947 0.29838337 0.42830717], train_wt_loss:  40.3011, val_wt_loss: 36.7829, train_grp_loss: [11.76430347 15.86678092 11.15998597], val_grp_loss: [10.6393729  14.87590814 11.28329641], train_hist_grp_loss: [ 9.93562257 12.86143598 24.91015233], cur_train_grp_loss: [0.09487313 0.12299837 0.2374474 ], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6809, max_kl_dist_index: 2, max_train_grp_loss:  15.8668, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8759, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:37:21,552 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  104, train_loss:  13.4337, val_loss:  12.2610, grad_norm: 0.0039, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6516, 0.3473, 0.6809, param: [4.14576906 9.45827384 4.99614565 8.91068482], weights: [0.27274005 0.29801306 0.42924689], train_wt_loss:  40.3011, val_wt_loss: 36.7830, train_grp_loss: [11.76433342 15.86677768 11.15994184], val_grp_loss: [10.63933568 14.87599375 11.28334045], train_hist_grp_loss: [10.03049599 12.98443428 25.14759884], cur_train_grp_loss: [0.09487342 0.1229983  0.23744651], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6809, max_kl_dist_index: 2, max_train_grp_loss:  15.8668, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8760, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:37:22,594 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  105, train_loss:  13.4337, val_loss:  12.2610, grad_norm: 0.0039, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6516, 0.3473, 0.6810, param: [4.14560891 9.4578777  4.99644652 8.91146673], weights: [0.27217083 0.29764211 0.43018706], train_wt_loss:  40.3011, val_wt_loss: 36.7831, train_grp_loss: [11.76435834 15.86678011 11.15989554], val_grp_loss: [10.63929407 14.87608787 11.28338281], train_hist_grp_loss: [10.12536965 13.10743256 25.38504441], cur_train_grp_loss: [0.09487366 0.12299828 0.23744557], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6810, max_kl_dist_index: 2, max_train_grp_loss:  15.8668, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8761, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:37:23,633 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  106, train_loss:  13.4337, val_loss:  12.2611, grad_norm: 0.0039, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6517, 0.3474, 0.6810, param: [4.14544654 9.45748616 4.99674556 8.91225384], weights: [0.27160178 0.29727052 0.43112769], train_wt_loss:  40.3011, val_wt_loss: 36.7832, train_grp_loss: [11.76437823 15.86678819 11.15984709], val_grp_loss: [10.63924806 14.8761905  11.28342348], train_hist_grp_loss: [10.2202435  13.23043086 25.622489  ], cur_train_grp_loss: [0.09487386 0.1229983  0.23744459], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6810, max_kl_dist_index: 2, max_train_grp_loss:  15.8668, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8762, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:37:24,668 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  107, train_loss:  13.4337, val_loss:  12.2611, grad_norm: 0.0040, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6517, 0.3474, 0.6810, param: [4.14528195 9.45709921 4.99704275 8.91304614], weights: [0.27103293 0.2968983  0.43206877], train_wt_loss:  40.3011, val_wt_loss: 36.7833, train_grp_loss: [11.76439309 15.86680193 11.15979648], val_grp_loss: [10.63919766 14.87630164 11.28346249], train_hist_grp_loss: [10.31511752 13.35342921 25.85993255], cur_train_grp_loss: [0.09487402 0.12299836 0.23744356], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6810, max_kl_dist_index: 2, max_train_grp_loss:  15.8668, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8763, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:37:25,721 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  108, train_loss:  13.4337, val_loss:  12.2611, grad_norm: 0.0040, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6517, 0.3474, 0.6811, param: [4.14511514 9.45671686 4.99733808 8.91384364], weights: [0.27046426 0.29652545 0.43301028], train_wt_loss:  40.3011, val_wt_loss: 36.7834, train_grp_loss: [11.76440292 15.86682133 11.15974371], val_grp_loss: [10.63914287 14.8764213  11.28349981], train_hist_grp_loss: [10.40999166 13.47642768 26.09737503], cur_train_grp_loss: [0.09487414 0.12299846 0.23744248], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6811, max_kl_dist_index: 2, max_train_grp_loss:  15.8668, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8764, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:37:26,756 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  109, train_loss:  13.4337, val_loss:  12.2612, grad_norm: 0.0040, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6518, 0.3474, 0.6811, param: [4.14494611 9.4563391  4.99763157 8.91464634], weights: [0.2698958  0.29615198 0.43395223], train_wt_loss:  40.3012, val_wt_loss: 36.7835, train_grp_loss: [11.76440773 15.8668464  11.15968879], val_grp_loss: [10.63908369 14.87654947 11.28353545], train_hist_grp_loss: [10.50486588 13.59942629 26.33481638], cur_train_grp_loss: [0.09487422 0.12299861 0.23744136], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6811, max_kl_dist_index: 2, max_train_grp_loss:  15.8668, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8765, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:37:27,779 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  110, train_loss:  13.4337, val_loss:  12.2612, grad_norm: 0.0040, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6518, 0.3474, 0.6812, param: [4.14477486 9.45596593 4.9979232  8.91545424], weights: [0.26932753 0.29577788 0.4348946 ], train_wt_loss:  40.3012, val_wt_loss: 36.7836, train_grp_loss: [11.76440749 15.86687713 11.1596317 ], val_grp_loss: [10.6390201  14.87668617 11.28356942], train_hist_grp_loss: [10.59974013 13.7224251  26.57225657], cur_train_grp_loss: [0.09487426 0.12299881 0.23744019], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6812, max_kl_dist_index: 2, max_train_grp_loss:  15.8669, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8767, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:37:28,827 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  111, train_loss:  13.4337, val_loss:  12.2612, grad_norm: 0.0041, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6518, 0.3474, 0.6812, param: [4.14460138 9.45559735 4.99821296 8.91626734], weights: [0.26875946 0.29540316 0.43583738], train_wt_loss:  40.3012, val_wt_loss: 36.7837, train_grp_loss: [11.76440223 15.86691352 11.15957246], val_grp_loss: [10.63895213 14.87683139 11.28360171], train_hist_grp_loss: [10.69461439 13.84542415 26.80969554], cur_train_grp_loss: [0.09487425 0.12299905 0.23743897], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6812, max_kl_dist_index: 2, max_train_grp_loss:  15.8669, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8768, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:37:29,897 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  112, train_loss:  13.4337, val_loss:  12.2613, grad_norm: 0.0041, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6519, 0.3474, 0.6812, param: [4.14442569 9.45523336 4.99850086 8.91708564], weights: [0.26819159 0.29502782 0.43678058], train_wt_loss:  40.3012, val_wt_loss: 36.7838, train_grp_loss: [11.76439193 15.86695559 11.15951106], val_grp_loss: [10.63887976 14.87698514 11.28363232], train_hist_grp_loss: [10.7894886  13.96842348 27.04713326], cur_train_grp_loss: [0.09487421 0.12299933 0.23743771], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6812, max_kl_dist_index: 2, max_train_grp_loss:  15.8670, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8770, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:37:30,925 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  113, train_loss:  13.4337, val_loss:  12.2613, grad_norm: 0.0041, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6519, 0.3475, 0.6813, param: [4.14424776 9.45487395 4.9987869  8.91790913], weights: [0.26762394 0.29465188 0.43772418], train_wt_loss:  40.3012, val_wt_loss: 36.7839, train_grp_loss: [11.76437659 15.86700333 11.1594475 ], val_grp_loss: [10.63880299 14.87714741 11.28366125], train_hist_grp_loss: [10.88436273 14.09142314 27.28456966], cur_train_grp_loss: [0.09487413 0.12299966 0.23743641], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6813, max_kl_dist_index: 2, max_train_grp_loss:  15.8670, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8771, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:37:32,008 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  114, train_loss:  13.4337, val_loss:  12.2614, grad_norm: 0.0042, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6519, 0.3475, 0.6813, param: [4.14406762 9.45451912 4.99907106 8.91873782], weights: [0.26705649 0.29427533 0.43866818], train_wt_loss:  40.3012, val_wt_loss: 36.7841, train_grp_loss: [11.76435622 15.86705674 11.15938178], val_grp_loss: [10.63872183 14.87731822 11.2836885 ], train_hist_grp_loss: [10.97923673 14.21442316 27.52200471], cur_train_grp_loss: [0.094874   0.12300003 0.23743505], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6813, max_kl_dist_index: 2, max_train_grp_loss:  15.8671, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8773, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:37:33,088 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  115, train_loss:  13.4337, val_loss:  12.2614, grad_norm: 0.0042, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6520, 0.3475, 0.6813, param: [4.14388524 9.45416888 4.99935335 8.91957171], weights: [0.26648927 0.29389817 0.43961256], train_wt_loss:  40.3012, val_wt_loss: 36.7842, train_grp_loss: [11.76433081 15.86711582 11.15931391], val_grp_loss: [10.63863628 14.87749756 11.28371408], train_hist_grp_loss: [11.07411057 14.3374236  27.75943837], cur_train_grp_loss: [0.09487384 0.12300044 0.23743365], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6813, max_kl_dist_index: 2, max_train_grp_loss:  15.8671, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8775, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:37:34,122 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  116, train_loss:  13.4337, val_loss:  12.2614, grad_norm: 0.0042, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6520, 0.3475, 0.6814, param: [4.14370065 9.45382321 4.99963376 8.9204108 ], weights: [0.26592225 0.29352042 0.44055733], train_wt_loss:  40.3012, val_wt_loss: 36.7843, train_grp_loss: [11.76430036 15.86718058 11.15924387], val_grp_loss: [10.63854632 14.87768545 11.28373798], train_hist_grp_loss: [11.16898421 14.4604245  27.99687058], cur_train_grp_loss: [0.09487364 0.1230009  0.23743221], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6814, max_kl_dist_index: 2, max_train_grp_loss:  15.8672, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8777, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:37:35,160 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  117, train_loss:  13.4338, val_loss:  12.2615, grad_norm: 0.0042, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6520, 0.3475, 0.6814, param: [4.14351382 9.45348211 4.99991228 8.92125509], weights: [0.26535546 0.29314206 0.44150247], train_wt_loss:  40.3013, val_wt_loss: 36.7844, train_grp_loss: [11.76426487 15.86725102 11.15917168], val_grp_loss: [10.63845198 14.87788187 11.2837602 ], train_hist_grp_loss: [11.2638576 14.5834259 28.2343013], cur_train_grp_loss: [0.09487339 0.1230014  0.23743072], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6814, max_kl_dist_index: 2, max_train_grp_loss:  15.8673, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8779, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:37:36,184 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  118, train_loss:  13.4338, val_loss:  12.2615, grad_norm: 0.0043, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6521, 0.3476, 0.6815, param: [4.14332476 9.45314559 5.00018893 8.92210458], weights: [0.2647889  0.29276312 0.44244798], train_wt_loss:  40.3013, val_wt_loss: 36.7846, train_grp_loss: [11.76422434 15.86732714 11.15909734], val_grp_loss: [10.63835324 14.87808683 11.28378075], train_hist_grp_loss: [11.3587307  14.70642784 28.47173049], cur_train_grp_loss: [0.0948731  0.12300195 0.23742918], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6815, max_kl_dist_index: 2, max_train_grp_loss:  15.8673, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8781, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:37:37,213 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  119, train_loss:  13.4338, val_loss:  12.2616, grad_norm: 0.0043, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6521, 0.3476, 0.6815, param: [4.14313348 9.45281363 5.00046368 8.92295926], weights: [0.26422256 0.29238359 0.44339385], train_wt_loss:  40.3013, val_wt_loss: 36.7847, train_grp_loss: [11.76417877 15.86740894 11.15902083], val_grp_loss: [10.6382501  14.87830034 11.28379961], train_hist_grp_loss: [11.45360348 14.82943038 28.70915809], cur_train_grp_loss: [0.09487278 0.12300254 0.2374276 ], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6815, max_kl_dist_index: 2, max_train_grp_loss:  15.8674, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8783, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:37:38,258 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  120, train_loss:  13.4338, val_loss:  12.2616, grad_norm: 0.0043, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6521, 0.3476, 0.6815, param: [4.14293997 9.45248625 5.00073654 8.92381914], weights: [0.26365646 0.29200347 0.44434007], train_wt_loss:  40.3013, val_wt_loss: 36.7848, train_grp_loss: [11.76412816 15.86749642 11.15894217], val_grp_loss: [10.63814257 14.87852239 11.28381681], train_hist_grp_loss: [11.54847589 14.95243355 28.94658406], cur_train_grp_loss: [0.09487241 0.12300317 0.23742598], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6815, max_kl_dist_index: 2, max_train_grp_loss:  15.8675, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8785, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:37:39,291 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  121, train_loss:  13.4338, val_loss:  12.2616, grad_norm: 0.0043, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6522, 0.3476, 0.6816, param: [4.14274422 9.45216343 5.0010075  8.92468421], weights: [0.26309059 0.29162277 0.44528664], train_wt_loss:  40.3013, val_wt_loss: 36.7849, train_grp_loss: [11.76407251 15.86758958 11.15886136], val_grp_loss: [10.63803065 14.878753   11.28383232], train_hist_grp_loss: [11.64334789 15.0754374  29.18400837], cur_train_grp_loss: [0.094872   0.12300385 0.2374243 ], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6816, max_kl_dist_index: 2, max_train_grp_loss:  15.8676, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8788, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:37:40,321 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  122, train_loss:  13.4338, val_loss:  12.2617, grad_norm: 0.0044, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6522, 0.3476, 0.6816, param: [4.14254625 9.45184517 5.00127656 8.92555448], weights: [0.26252495 0.2912415  0.44623355], train_wt_loss:  40.3013, val_wt_loss: 36.7851, train_grp_loss: [11.76401181 15.86768843 11.15877839], val_grp_loss: [10.63791433 14.87899215 11.28384617], train_hist_grp_loss: [11.73821944 15.19844197 29.42143095], cur_train_grp_loss: [0.09487155 0.12300457 0.23742258], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6816, max_kl_dist_index: 2, max_train_grp_loss:  15.8677, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8790, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:37:41,349 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  123, train_loss:  13.4338, val_loss:  12.2617, grad_norm: 0.0044, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6523, 0.3476, 0.6817, param: [4.14234604 9.45153147 5.00154372 8.92642995], weights: [0.26195956 0.29085965 0.44718079], train_wt_loss:  40.3013, val_wt_loss: 36.7852, train_grp_loss: [11.76394608 15.86779297 11.15869327], val_grp_loss: [10.63779362 14.87923986 11.28385833], train_hist_grp_loss: [11.8330905  15.32144731 29.65885176], cur_train_grp_loss: [0.09487106 0.12300534 0.23742082], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6817, max_kl_dist_index: 2, max_train_grp_loss:  15.8678, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8792, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:37:42,380 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  124, train_loss:  13.4338, val_loss:  12.2618, grad_norm: 0.0044, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6523, 0.3477, 0.6817, param: [4.1421436  9.45122233 5.00180898 8.9273106 ], weights: [0.26139441 0.29047723 0.44812836], train_wt_loss:  40.3013, val_wt_loss: 36.7854, train_grp_loss: [11.76387529 15.86790319 11.15860599], val_grp_loss: [10.63766852 14.87949612 11.28386882], train_hist_grp_loss: [11.92796104 15.44445345 29.89627077], cur_train_grp_loss: [0.09487053 0.12300615 0.23741901], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6817, max_kl_dist_index: 2, max_train_grp_loss:  15.8679, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8795, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:37:43,386 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  125, train_loss:  13.4338, val_loss:  12.2618, grad_norm: 0.0045, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6523, 0.3477, 0.6818, param: [4.14193892 9.45091774 5.00207232 8.92819645], weights: [0.26082951 0.29009425 0.44907624], train_wt_loss:  40.3014, val_wt_loss: 36.7855, train_grp_loss: [11.76379947 15.8680191  11.15851656], val_grp_loss: [10.63753903 14.87976095 11.28387764], train_hist_grp_loss: [12.022831   15.56746045 30.13368792], cur_train_grp_loss: [0.09486996 0.123007   0.23741715], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6818, max_kl_dist_index: 2, max_train_grp_loss:  15.8680, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8798, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:37:44,416 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  126, train_loss:  13.4338, val_loss:  12.2619, grad_norm: 0.0045, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6524, 0.3477, 0.6818, param: [4.14173201 9.4506177  5.00233375 8.92908749], weights: [0.26026486 0.2897107  0.45002444], train_wt_loss:  40.3014, val_wt_loss: 36.7856, train_grp_loss: [11.76371861 15.86814071 11.15842498], val_grp_loss: [10.63740514 14.88003433 11.28388479], train_hist_grp_loss: [12.11770035 15.69046835 30.37110316], cur_train_grp_loss: [0.09486935 0.1230079  0.23741525], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6818, max_kl_dist_index: 2, max_train_grp_loss:  15.8681, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8800, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:37:45,459 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  127, train_loss:  13.4338, val_loss:  12.2619, grad_norm: 0.0045, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6524, 0.3477, 0.6818, param: [4.14152287 9.45032221 5.00259326 8.92998373], weights: [0.25970046 0.2893266  0.45097294], train_wt_loss:  40.3014, val_wt_loss: 36.7858, train_grp_loss: [11.7636327  15.868268   11.15833125], val_grp_loss: [10.63726687 14.88031627 11.28389026], train_hist_grp_loss: [12.21256905 15.8134772  30.60851646], cur_train_grp_loss: [0.0948687  0.12300884 0.2374133 ], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6818, max_kl_dist_index: 2, max_train_grp_loss:  15.8683, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8803, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:37:46,502 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  128, train_loss:  13.4338, val_loss:  12.2620, grad_norm: 0.0045, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6524, 0.3478, 0.6819, param: [4.14131149 9.45003126 5.00285084 8.93088515], weights: [0.25913633 0.28894194 0.45192173], train_wt_loss:  40.3014, val_wt_loss: 36.7859, train_grp_loss: [11.76354174 15.86840099 11.15823536], val_grp_loss: [10.63712421 14.88060677 11.28389406], train_hist_grp_loss: [12.30743705 15.93648703 30.84592777], cur_train_grp_loss: [0.09486801 0.12300983 0.2374113 ], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6819, max_kl_dist_index: 2, max_train_grp_loss:  15.8684, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8806, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:37:47,535 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  129, train_loss:  13.4338, val_loss:  12.2620, grad_norm: 0.0046, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6525, 0.3478, 0.6819, param: [4.14109788 9.44974485 5.00310651 8.93179176], weights: [0.25857245 0.28855674 0.45287081], train_wt_loss:  40.3014, val_wt_loss: 36.7861, train_grp_loss: [11.76344575 15.86853967 11.15813733], val_grp_loss: [10.63697716 14.88090584 11.28389619], train_hist_grp_loss: [12.40230433 16.05949789 31.08333703], cur_train_grp_loss: [0.09486727 0.12301086 0.23740926], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6819, max_kl_dist_index: 2, max_train_grp_loss:  15.8685, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8809, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:37:48,559 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  130, train_loss:  13.4338, val_loss:  12.2621, grad_norm: 0.0046, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6525, 0.3478, 0.6820, param: [4.14088202 9.44946299 5.00336024 8.93270355], weights: [0.25800884 0.28817099 0.45382018], train_wt_loss:  40.3014, val_wt_loss: 36.7863, train_grp_loss: [11.76334471 15.86868405 11.15803714], val_grp_loss: [10.63682572 14.88121348 11.28389665], train_hist_grp_loss: [12.49717082 16.18250982 31.32074421], cur_train_grp_loss: [0.0948665  0.12301194 0.23740718], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6820, max_kl_dist_index: 2, max_train_grp_loss:  15.8687, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8812, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:37:49,584 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  131, train_loss:  13.4338, val_loss:  12.2621, grad_norm: 0.0046, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6526, 0.3478, 0.6820, param: [4.14066393 9.44918565 5.00361205 8.93362053], weights: [0.25744549 0.28778469 0.45476982], train_wt_loss:  40.3014, val_wt_loss: 36.7864, train_grp_loss: [11.76323863 15.86883412 11.15793481], val_grp_loss: [10.6366699  14.88152968 11.28389544], train_hist_grp_loss: [12.59203651 16.30552288 31.55814925], cur_train_grp_loss: [0.09486568 0.12301305 0.23740505], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6820, max_kl_dist_index: 2, max_train_grp_loss:  15.8688, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8815, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:37:50,628 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  132, train_loss:  13.4338, val_loss:  12.2622, grad_norm: 0.0046, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6526, 0.3478, 0.6821, param: [4.1404436  9.44891285 5.00386191 8.93454269], weights: [0.25688242 0.28739786 0.45571972], train_wt_loss:  40.3015, val_wt_loss: 36.7866, train_grp_loss: [11.76312751 15.86898989 11.15783034], val_grp_loss: [10.63650969 14.88185445 11.28389256], train_hist_grp_loss: [12.68690133 16.4285371  31.79555212], cur_train_grp_loss: [0.09486483 0.12301422 0.23740287], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6821, max_kl_dist_index: 2, max_train_grp_loss:  15.8690, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8819, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:37:51,655 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  133, train_loss:  13.4338, val_loss:  12.2622, grad_norm: 0.0047, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6527, 0.3479, 0.6821, param: [4.14022104 9.44864458 5.00410984 8.93547003], weights: [0.25631962 0.28701049 0.45666989], train_wt_loss:  40.3015, val_wt_loss: 36.7867, train_grp_loss: [11.76301134 15.86915136 11.15772371], val_grp_loss: [10.6363451  14.88218779 11.28388802], train_hist_grp_loss: [12.78176527 16.55155252 32.03295276], cur_train_grp_loss: [0.09486393 0.12301543 0.23740065], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6821, max_kl_dist_index: 2, max_train_grp_loss:  15.8692, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8822, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:37:52,703 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  134, train_loss:  13.4338, val_loss:  12.2623, grad_norm: 0.0047, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6527, 0.3479, 0.6822, param: [4.13999623 9.44838083 5.00435583 8.93640256], weights: [0.25575709 0.2866226  0.45762031], train_wt_loss:  40.3015, val_wt_loss: 36.7869, train_grp_loss: [11.76289014 15.86931853 11.15761494], val_grp_loss: [10.63617612 14.8825297  11.28388181], train_hist_grp_loss: [12.87662826 16.6745692  32.27035114], cur_train_grp_loss: [0.09486299 0.12301668 0.23739838], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6822, max_kl_dist_index: 2, max_train_grp_loss:  15.8693, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8825, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:37:53,730 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  135, train_loss:  13.4338, val_loss:  12.2624, grad_norm: 0.0047, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6527, 0.3479, 0.6822, param: [4.13976918 9.44812161 5.00459987 8.93734026], weights: [0.25519485 0.28623418 0.45857097], train_wt_loss:  40.3015, val_wt_loss: 36.7871, train_grp_loss: [11.76276389 15.86949139 11.15750403], val_grp_loss: [10.63600277 14.88288019 11.28387393], train_hist_grp_loss: [12.97149028 16.79758717 32.5077472 ], cur_train_grp_loss: [0.09486202 0.12301797 0.23739606], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6822, max_kl_dist_index: 2, max_train_grp_loss:  15.8695, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8829, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:37:54,741 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  136, train_loss:  13.4338, val_loss:  12.2624, grad_norm: 0.0047, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6528, 0.3479, 0.6823, param: [4.13953989 9.4478669  5.00484196 8.93828313], weights: [0.25463289 0.28584523 0.45952188], train_wt_loss:  40.3015, val_wt_loss: 36.7872, train_grp_loss: [11.76263261 15.86966996 11.15739098], val_grp_loss: [10.63582504 14.88323925 11.28386438], train_hist_grp_loss: [13.06635128 16.92060648 32.74514091], cur_train_grp_loss: [0.094861   0.12301931 0.2373937 ], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6823, max_kl_dist_index: 2, max_train_grp_loss:  15.8697, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8832, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:37:55,754 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  137, train_loss:  13.4338, val_loss:  12.2625, grad_norm: 0.0048, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6528, 0.3480, 0.6823, param: [4.13930836 9.4476167  5.00508209 8.93923118], weights: [0.25407122 0.28545577 0.46047301], train_wt_loss:  40.3015, val_wt_loss: 36.7874, train_grp_loss: [11.76249628 15.86985423 11.15727578], val_grp_loss: [10.63564293 14.88360688 11.28385317], train_hist_grp_loss: [13.16121122 17.04362718 32.9825322 ], cur_train_grp_loss: [0.09485994 0.1230207  0.2373913 ], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6823, max_kl_dist_index: 2, max_train_grp_loss:  15.8699, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8836, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:37:56,744 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  138, train_loss:  13.4338, val_loss:  12.2625, grad_norm: 0.0048, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6529, 0.3480, 0.6824, param: [4.13907459 9.44737102 5.00532027 8.94018441], weights: [0.25350984 0.28506579 0.46142437], train_wt_loss:  40.3015, val_wt_loss: 36.7876, train_grp_loss: [11.76235492 15.87004421 11.15715844], val_grp_loss: [10.63545644 14.88398309 11.2838403 ], train_hist_grp_loss: [13.25607006 17.16664931 33.21992105], cur_train_grp_loss: [0.09485884 0.12302213 0.23738885], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6824, max_kl_dist_index: 2, max_train_grp_loss:  15.8700, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8840, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:37:57,783 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  139, train_loss:  13.4339, val_loss:  12.2626, grad_norm: 0.0048, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6529, 0.3480, 0.6824, param: [4.13883858 9.44712984 5.00555649 8.9411428 ], weights: [0.25294875 0.28467531 0.46237594], train_wt_loss:  40.3016, val_wt_loss: 36.7878, train_grp_loss: [11.76220851 15.87023989 11.15703897], val_grp_loss: [10.63526558 14.88436788 11.28382577], train_hist_grp_loss: [13.35092776 17.28967291 33.4573074 ], cur_train_grp_loss: [0.0948577  0.1230236  0.23738635], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6824, max_kl_dist_index: 2, max_train_grp_loss:  15.8702, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8844, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:37:58,845 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  140, train_loss:  13.4339, val_loss:  12.2626, grad_norm: 0.0048, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6530, 0.3480, 0.6825, param: [4.13860032 9.44689316 5.00579075 8.94210635], weights: [0.25238796 0.28428431 0.46332773], train_wt_loss:  40.3016, val_wt_loss: 36.7879, train_grp_loss: [11.76205708 15.87044127 11.15691736], val_grp_loss: [10.63507034 14.88476125 11.28380958], train_hist_grp_loss: [13.44578428 17.41269802 33.69469121], cur_train_grp_loss: [0.09485652 0.12302512 0.23738381], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6825, max_kl_dist_index: 2, max_train_grp_loss:  15.8704, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8848, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:37:59,892 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  141, train_loss:  13.4339, val_loss:  12.2627, grad_norm: 0.0049, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6530, 0.3481, 0.6825, param: [4.13835982 9.44666099 5.00602303 8.94307508], weights: [0.25182747 0.28389282 0.46427971], train_wt_loss:  40.3016, val_wt_loss: 36.7881, train_grp_loss: [11.7619006  15.87064835 11.15679361], val_grp_loss: [10.63487073 14.88516319 11.28379172], train_hist_grp_loss: [13.54063958 17.5357247  33.93207243], cur_train_grp_loss: [0.0948553  0.12302668 0.23738122], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6825, max_kl_dist_index: 2, max_train_grp_loss:  15.8706, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8852, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:38:00,954 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  142, train_loss:  13.4339, val_loss:  12.2628, grad_norm: 0.0049, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6530, 0.3481, 0.6826, param: [4.13811707 9.44643331 5.00625335 8.94404896], weights: [0.25126728 0.28350082 0.46523189], train_wt_loss:  40.3016, val_wt_loss: 36.7883, train_grp_loss: [11.76173909 15.87086114 11.15666773], val_grp_loss: [10.63466676 14.88557372 11.28377221], train_hist_grp_loss: [13.63549362 17.65875298 34.16945102], cur_train_grp_loss: [0.09485404 0.12302828 0.23737859], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6826, max_kl_dist_index: 2, max_train_grp_loss:  15.8709, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8856, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:38:02,006 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  143, train_loss:  13.4339, val_loss:  12.2628, grad_norm: 0.0049, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6531, 0.3481, 0.6827, param: [4.13787208 9.44621012 5.00648169 8.945028  ], weights: [0.25070741 0.28310834 0.46618426], train_wt_loss:  40.3016, val_wt_loss: 36.7885, train_grp_loss: [11.76157255 15.87107964 11.15653971], val_grp_loss: [10.63445841 14.88599282 11.28375105], train_hist_grp_loss: [13.73034635 17.78178291 34.40682693], cur_train_grp_loss: [0.09485273 0.12302993 0.23737591], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6827, max_kl_dist_index: 2, max_train_grp_loss:  15.8711, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8860, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:38:03,023 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  144, train_loss:  13.4339, val_loss:  12.2629, grad_norm: 0.0049, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6531, 0.3482, 0.6827, param: [4.13762485 9.44599141 5.00670805 8.9460122 ], weights: [0.25014784 0.28271536 0.46713681], train_wt_loss:  40.3016, val_wt_loss: 36.7887, train_grp_loss: [11.76140097 15.87130385 11.15640956], val_grp_loss: [10.63424571 14.8864205  11.28372822], train_hist_grp_loss: [13.82519774 17.90481454 34.64420011], cur_train_grp_loss: [0.09485139 0.12303163 0.23737319], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6827, max_kl_dist_index: 2, max_train_grp_loss:  15.8713, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8864, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:38:04,074 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  145, train_loss:  13.4339, val_loss:  12.2630, grad_norm: 0.0050, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6532, 0.3482, 0.6828, param: [4.13737536 9.44577719 5.00693243 8.94700156], weights: [0.24958858 0.28232189 0.46808952], train_wt_loss:  40.3016, val_wt_loss: 36.7889, train_grp_loss: [11.76122437 15.87153376 11.15627728], val_grp_loss: [10.63402863 14.88685677 11.28370375], train_hist_grp_loss: [13.92004775 18.0278479  34.88157053], cur_train_grp_loss: [0.09485001 0.12303336 0.23737042], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6828, max_kl_dist_index: 2, max_train_grp_loss:  15.8715, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8869, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:38:05,098 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  146, train_loss:  13.4339, val_loss:  12.2630, grad_norm: 0.0050, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6532, 0.3482, 0.6828, param: [4.13712364 9.44556745 5.00715482 8.94799606], weights: [0.24902964 0.28192795 0.46904241], train_wt_loss:  40.3017, val_wt_loss: 36.7891, train_grp_loss: [11.76104273 15.87176938 11.15614288], val_grp_loss: [10.6338072  14.88730161 11.28367761], train_hist_grp_loss: [14.01489633 18.15088304 35.11893813], cur_train_grp_loss: [0.09484858 0.12303515 0.2373676 ], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6828, max_kl_dist_index: 2, max_train_grp_loss:  15.8718, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8873, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:38:06,159 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  147, train_loss:  13.4339, val_loss:  12.2631, grad_norm: 0.0050, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6533, 0.3482, 0.6829, param: [4.13686966 9.44536218 5.00737523 8.94899572], weights: [0.24847102 0.28153352 0.46999545], train_wt_loss:  40.3017, val_wt_loss: 36.7893, train_grp_loss: [11.76085607 15.8720107  11.15600634], val_grp_loss: [10.63358141 14.88775504 11.28364983], train_hist_grp_loss: [14.10974345 18.27392002 35.35630287], cur_train_grp_loss: [0.09484712 0.12303697 0.23736474], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6829, max_kl_dist_index: 2, max_train_grp_loss:  15.8720, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8878, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:38:07,203 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  148, train_loss:  13.4339, val_loss:  12.2632, grad_norm: 0.0050, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6533, 0.3483, 0.6829, param: [4.13661344 9.44516138 5.00759364 8.95000051], weights: [0.24791273 0.28113863 0.47094865], train_wt_loss:  40.3017, val_wt_loss: 36.7895, train_grp_loss: [11.76066438 15.87225774 11.15586768], val_grp_loss: [10.63335126 14.88821705 11.2836204 ], train_hist_grp_loss: [14.20458907 18.39695886 35.59366471], cur_train_grp_loss: [0.09484561 0.12303884 0.23736184], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6829, max_kl_dist_index: 2, max_train_grp_loss:  15.8723, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8882, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:38:08,262 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  149, train_loss:  13.4339, val_loss:  12.2632, grad_norm: 0.0051, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6534, 0.3483, 0.6830, param: [4.13635497 9.44496505 5.00781005 8.95101045], weights: [0.24735476 0.28074326 0.47190198], train_wt_loss:  40.3017, val_wt_loss: 36.7897, train_grp_loss: [11.76046766 15.87251048 11.1557269 ], val_grp_loss: [10.63311676 14.88868765 11.28358932], train_hist_grp_loss: [14.29943313 18.51999962 35.83102359], cur_train_grp_loss: [0.09484407 0.12304076 0.23735889], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6830, max_kl_dist_index: 2, max_train_grp_loss:  15.8725, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8887, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:38:09,283 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  150, train_loss:  13.4339, val_loss:  12.2633, grad_norm: 0.0051, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6534, 0.3483, 0.6831, param: [4.13609425 9.44477318 5.00802447 8.95202553], weights: [0.24679712 0.28034742 0.47285545], train_wt_loss:  40.3017, val_wt_loss: 36.7899, train_grp_loss: [11.76026592 15.87276894 11.155584  ], val_grp_loss: [10.6328779  14.88916682 11.28355659], train_hist_grp_loss: [14.39427561 18.64304233 36.06837949], cur_train_grp_loss: [0.09484248 0.12304272 0.23735589], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6831, max_kl_dist_index: 2, max_train_grp_loss:  15.8728, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8892, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:38:10,359 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  151, train_loss:  13.4339, val_loss:  12.2634, grad_norm: 0.0051, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6535, 0.3484, 0.6831, param: [4.13583128 9.44458577 5.00823688 8.95304575], weights: [0.24623982 0.27995113 0.47380906], train_wt_loss:  40.3017, val_wt_loss: 36.7901, train_grp_loss: [11.76005916 15.8730331  11.15543897], val_grp_loss: [10.6326347  14.88965458 11.28352222], train_hist_grp_loss: [14.48911647 18.76608705 36.30573234], cur_train_grp_loss: [0.09484085 0.12304472 0.23735285], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6831, max_kl_dist_index: 2, max_train_grp_loss:  15.8730, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8897, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:38:11,396 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  152, train_loss:  13.4339, val_loss:  12.2634, grad_norm: 0.0051, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6535, 0.3484, 0.6832, param: [4.13556607 9.4444028  5.00844729 8.95407109], weights: [0.24568285 0.27955437 0.47476278], train_wt_loss:  40.3018, val_wt_loss: 36.7903, train_grp_loss: [11.75984738 15.87330297 11.15529183], val_grp_loss: [10.63238715 14.89015092 11.2834862 ], train_hist_grp_loss: [14.58395566 18.88913382 36.5430821 ], cur_train_grp_loss: [0.09483919 0.12304677 0.23734977], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6832, max_kl_dist_index: 2, max_train_grp_loss:  15.8733, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8902, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2373, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:38:12,434 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  153, train_loss:  13.4339, val_loss:  12.2635, grad_norm: 0.0052, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6536, 0.3484, 0.6832, param: [4.1352986  9.44422429 5.00865568 8.95510157], weights: [0.24512622 0.27915717 0.47571661], train_wt_loss:  40.3018, val_wt_loss: 36.7905, train_grp_loss: [11.75963058 15.87357855 11.15514257], val_grp_loss: [10.63213526 14.89065584 11.28344854], train_hist_grp_loss: [14.67879313 19.01218268 36.78042874], cur_train_grp_loss: [0.09483748 0.12304886 0.23734663], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6832, max_kl_dist_index: 2, max_train_grp_loss:  15.8736, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8907, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2373, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:38:13,452 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  154, train_loss:  13.4339, val_loss:  12.2636, grad_norm: 0.0052, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6536, 0.3485, 0.6833, param: [4.13502889 9.44405022 5.00886206 8.95613716], weights: [0.24456993 0.27875951 0.47667056], train_wt_loss:  40.3018, val_wt_loss: 36.7907, train_grp_loss: [11.75940877 15.87385984 11.1549912 ], val_grp_loss: [10.63187902 14.89116934 11.28340924], train_hist_grp_loss: [14.77362886 19.13523368 37.0177722 ], cur_train_grp_loss: [0.09483573 0.123051   0.23734346], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6833, max_kl_dist_index: 2, max_train_grp_loss:  15.8739, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8912, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2373, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:38:14,521 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  155, train_loss:  13.4339, val_loss:  12.2636, grad_norm: 0.0052, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6537, 0.3485, 0.6834, param: [4.13475692 9.44388058 5.00906642 8.95717788], weights: [0.24401399 0.27836141 0.4776246 ], train_wt_loss:  40.3018, val_wt_loss: 36.7909, train_grp_loss: [11.75918194 15.87414684 11.15483772], val_grp_loss: [10.63161844 14.89169143 11.2833683 ], train_hist_grp_loss: [14.86846281 19.25828686 37.25511243], cur_train_grp_loss: [0.09483394 0.12305318 0.23734024], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6834, max_kl_dist_index: 2, max_train_grp_loss:  15.8741, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8917, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2373, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:38:15,553 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  156, train_loss:  13.4339, val_loss:  12.2637, grad_norm: 0.0052, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6537, 0.3485, 0.6834, param: [4.1344827  9.44371538 5.00926877 8.95822372], weights: [0.2434584  0.27796286 0.47857873], train_wt_loss:  40.3018, val_wt_loss: 36.7912, train_grp_loss: [11.7589501  15.87443955 11.15468212], val_grp_loss: [10.63135353 14.89222209 11.28332573], train_hist_grp_loss: [14.96329492 19.38134226 37.49244941], cur_train_grp_loss: [0.09483211 0.1230554  0.23733697], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6834, max_kl_dist_index: 2, max_train_grp_loss:  15.8744, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8922, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2373, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:38:16,597 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  157, train_loss:  13.4339, val_loss:  12.2638, grad_norm: 0.0053, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6538, 0.3486, 0.6835, param: [4.13420624 9.44355461 5.00946908 8.95927467], weights: [0.24290317 0.27756388 0.47953295], train_wt_loss:  40.3018, val_wt_loss: 36.7914, train_grp_loss: [11.75871325 15.87473797 11.15452442], val_grp_loss: [10.63108429 14.89276134 11.28328152], train_hist_grp_loss: [15.05812516 19.50439993 37.72978307], cur_train_grp_loss: [0.09483024 0.12305767 0.23733366], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6835, max_kl_dist_index: 2, max_train_grp_loss:  15.8747, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8928, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2373, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:38:17,647 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  158, train_loss:  13.4340, val_loss:  12.2639, grad_norm: 0.0053, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6538, 0.3486, 0.6835, param: [4.13392752 9.44339826 5.00966737 8.96033073], weights: [0.24234829 0.27716447 0.48048725], train_wt_loss:  40.3019, val_wt_loss: 36.7916, train_grp_loss: [11.75847139 15.8750421  11.15436462], val_grp_loss: [10.63081071 14.89330917 11.28323567], train_hist_grp_loss: [15.15295349 19.62745991 37.96711338], cur_train_grp_loss: [0.09482833 0.12305998 0.23733031], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6835, max_kl_dist_index: 2, max_train_grp_loss:  15.8750, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8933, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2373, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:38:18,718 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  159, train_loss:  13.4340, val_loss:  12.2639, grad_norm: 0.0053, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6539, 0.3486, 0.6836, param: [4.13364655 9.44324633 5.00986363 8.96139189], weights: [0.24179376 0.27676463 0.48144161], train_wt_loss:  40.3019, val_wt_loss: 36.7918, train_grp_loss: [11.75822453 15.87535194 11.1542027 ], val_grp_loss: [10.63053281 14.89386558 11.2831882 ], train_hist_grp_loss: [15.24777988 19.75052225 38.20444028], cur_train_grp_loss: [0.09482638 0.12306234 0.23732691], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6836, max_kl_dist_index: 2, max_train_grp_loss:  15.8754, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8939, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2373, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:38:19,771 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  160, train_loss:  13.4340, val_loss:  12.2640, grad_norm: 0.0053, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6539, 0.3487, 0.6837, param: [4.13336332 9.44309882 5.01005785 8.96245816], weights: [0.2412396  0.27636436 0.48239604], train_wt_loss:  40.3019, val_wt_loss: 36.7921, train_grp_loss: [11.75797266 15.87566749 11.15403869], val_grp_loss: [10.63025059 14.89443057 11.28313909], train_hist_grp_loss: [15.34260427 19.873587   38.44176374], cur_train_grp_loss: [0.09482439 0.12306474 0.23732346], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6837, max_kl_dist_index: 2, max_train_grp_loss:  15.8757, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8944, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2373, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:38:20,799 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  161, train_loss:  13.4340, val_loss:  12.2641, grad_norm: 0.0054, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6540, 0.3487, 0.6837, param: [4.13307785 9.44295571 5.01025003 8.96352952], weights: [0.24068581 0.27596367 0.48335052], train_wt_loss:  40.3019, val_wt_loss: 36.7923, train_grp_loss: [11.7577158  15.87598875 11.15387258], val_grp_loss: [10.62996404 14.89500413 11.28308836], train_hist_grp_loss: [15.43742663 19.99665419 38.67908372], cur_train_grp_loss: [0.09482236 0.12306719 0.23731997], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6837, max_kl_dist_index: 2, max_train_grp_loss:  15.8760, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8950, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2373, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:38:21,838 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  162, train_loss:  13.4340, val_loss:  12.2642, grad_norm: 0.0054, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6540, 0.3487, 0.6838, param: [4.13279012 9.44281701 5.01044017 8.96460597], weights: [0.24013239 0.27556256 0.48430505], train_wt_loss:  40.3019, val_wt_loss: 36.7925, train_grp_loss: [11.75745394 15.87631571 11.15370437], val_grp_loss: [10.62967318 14.89558627 11.283036  ], train_hist_grp_loss: [15.53224692 20.11972387 38.91640015], cur_train_grp_loss: [0.09482029 0.12306968 0.23731644], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6838, max_kl_dist_index: 2, max_train_grp_loss:  15.8763, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8956, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2373, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:38:22,892 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  163, train_loss:  13.4340, val_loss:  12.2643, grad_norm: 0.0054, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6541, 0.3488, 0.6839, param: [4.13250014 9.4426827  5.01062827 8.96568751], weights: [0.23957933 0.27516104 0.48525962], train_wt_loss:  40.3019, val_wt_loss: 36.7928, train_grp_loss: [11.75718708 15.87664839 11.15353407], val_grp_loss: [10.629378   14.89617699 11.28298202], train_hist_grp_loss: [15.62706509 20.24279608 39.15371301], cur_train_grp_loss: [0.09481818 0.12307221 0.23731286], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6839, max_kl_dist_index: 2, max_train_grp_loss:  15.8766, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8962, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2373, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:38:23,922 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  164, train_loss:  13.4340, val_loss:  12.2643, grad_norm: 0.0054, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6541, 0.3488, 0.6839, param: [4.13220791 9.44255279 5.01081431 8.96677414], weights: [0.23902666 0.27475912 0.48621422], train_wt_loss:  40.3020, val_wt_loss: 36.7930, train_grp_loss: [11.75691523 15.87698677 11.15336167], val_grp_loss: [10.62907851 14.89677629 11.28292642], train_hist_grp_loss: [15.72188112 20.36587088 39.39102225], cur_train_grp_loss: [0.09481602 0.12307479 0.23730924], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6839, max_kl_dist_index: 2, max_train_grp_loss:  15.8770, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8968, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2373, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:38:24,939 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  165, train_loss:  13.4340, val_loss:  12.2644, grad_norm: 0.0055, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6542, 0.3488, 0.6840, param: [4.13191342 9.44242726 5.0109983  8.96786584], weights: [0.23847436 0.27435679 0.48716885], train_wt_loss:  40.3020, val_wt_loss: 36.7933, train_grp_loss: [11.75663839 15.87733087 11.15318719], val_grp_loss: [10.62877472 14.89738416 11.2828692 ], train_hist_grp_loss: [15.81669495 20.48894829 39.62832782], cur_train_grp_loss: [0.09481383 0.12307742 0.23730557], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6840, max_kl_dist_index: 2, max_train_grp_loss:  15.8773, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8974, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2373, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:38:25,950 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  166, train_loss:  13.4340, val_loss:  12.2645, grad_norm: 0.0055, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6542, 0.3489, 0.6841, param: [4.13161668 9.44230612 5.01118024 8.96896262], weights: [0.23792244 0.27395406 0.4881235 ], train_wt_loss:  40.3020, val_wt_loss: 36.7935, train_grp_loss: [11.75635657 15.87768066 11.15301062], val_grp_loss: [10.62846662 14.8980006  11.28281036], train_hist_grp_loss: [15.91150655 20.61202838 39.86562967], cur_train_grp_loss: [0.0948116  0.12308008 0.23730186], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6841, max_kl_dist_index: 2, max_train_grp_loss:  15.8777, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8980, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2373, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:38:26,987 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  167, train_loss:  13.4340, val_loss:  12.2646, grad_norm: 0.0055, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6543, 0.3489, 0.6841, param: [4.13131768 9.44218935 5.01136012 8.97006447], weights: [0.23737091 0.27355093 0.48907816], train_wt_loss:  40.3020, val_wt_loss: 36.7938, train_grp_loss: [11.75606976 15.87803617 11.15283196], val_grp_loss: [10.62815422 14.89862562 11.2827499 ], train_hist_grp_loss: [16.00631588 20.73511117 40.10292777], cur_train_grp_loss: [0.09480933 0.1230828  0.2372981 ], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6841, max_kl_dist_index: 2, max_train_grp_loss:  15.8780, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8986, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2373, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:38:28,028 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  168, train_loss:  13.4340, val_loss:  12.2647, grad_norm: 0.0055, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6544, 0.3489, 0.6842, param: [4.13101644 9.44207695 5.01153793 8.97117138], weights: [0.23681977 0.27314741 0.49003282], train_wt_loss:  40.3020, val_wt_loss: 36.7940, train_grp_loss: [11.75577797 15.87839739 11.15265122], val_grp_loss: [10.62783753 14.89925921 11.28268784], train_hist_grp_loss: [16.10112289 20.85819673 40.34022207], cur_train_grp_loss: [0.09480701 0.12308555 0.2372943 ], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6842, max_kl_dist_index: 2, max_train_grp_loss:  15.8784, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8993, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2373, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:38:29,076 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  169, train_loss:  13.4340, val_loss:  12.2648, grad_norm: 0.0056, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6544, 0.3490, 0.6843, param: [4.13071293 9.44196892 5.01171367 8.97228335], weights: [0.23626902 0.2727435  0.49098748], train_wt_loss:  40.3021, val_wt_loss: 36.7943, train_grp_loss: [11.75548121 15.8787643  11.15246841], val_grp_loss: [10.62751654 14.89990137 11.28262416], train_hist_grp_loss: [16.19592755 20.98128508 40.57751252], cur_train_grp_loss: [0.09480466 0.12308835 0.23729045], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6843, max_kl_dist_index: 2, max_train_grp_loss:  15.8788, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8999, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2373, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:38:30,101 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  170, train_loss:  13.4340, val_loss:  12.2648, grad_norm: 0.0056, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6545, 0.3490, 0.6843, param: [4.13040717 9.44186525 5.01188735 8.97340038], weights: [0.23571867 0.27233921 0.49194212], train_wt_loss:  40.3021, val_wt_loss: 36.7945, train_grp_loss: [11.75517947 15.87913693 11.15228351], val_grp_loss: [10.62719126 14.90055209 11.28255887], train_hist_grp_loss: [16.29072982 21.10437627 40.81479908], cur_train_grp_loss: [0.09480227 0.1230912  0.23728656], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6843, max_kl_dist_index: 2, max_train_grp_loss:  15.8791, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9006, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2373, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:38:31,136 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  171, train_loss:  13.4340, val_loss:  12.2649, grad_norm: 0.0056, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6545, 0.3490, 0.6844, param: [4.13009916 9.44176593 5.01205895 8.97452245], weights: [0.23516871 0.27193454 0.49289675], train_wt_loss:  40.3021, val_wt_loss: 36.7948, train_grp_loss: [11.75487276 15.87951526 11.15209655], val_grp_loss: [10.6268617  14.90121138 11.28249198], train_hist_grp_loss: [16.38552966 21.22747036 41.05208171], cur_train_grp_loss: [0.09479983 0.12309408 0.23728263], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6844, max_kl_dist_index: 2, max_train_grp_loss:  15.8795, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9012, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2373, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:38:32,191 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  172, train_loss:  13.4340, val_loss:  12.2650, grad_norm: 0.0056, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6546, 0.3491, 0.6845, param: [4.12978889 9.44167096 5.01222848 8.97564957], weights: [0.23461915 0.2715295  0.49385135], train_wt_loss:  40.3021, val_wt_loss: 36.7950, train_grp_loss: [11.75456108 15.87989929 11.15190751], val_grp_loss: [10.62652786 14.90187924 11.28242348], train_hist_grp_loss: [16.48032702 21.35056738 41.28936036], cur_train_grp_loss: [0.09479736 0.12309702 0.23727865], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6845, max_kl_dist_index: 2, max_train_grp_loss:  15.8799, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9019, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2373, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:38:33,190 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  173, train_loss:  13.4340, val_loss:  12.2651, grad_norm: 0.0057, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6546, 0.3491, 0.6846, param: [4.12947637 9.44158034 5.01239592 8.97678172], weights: [0.23407    0.27112408 0.49480592], train_wt_loss:  40.3021, val_wt_loss: 36.7953, train_grp_loss: [11.75424444 15.88028903 11.1517164 ], val_grp_loss: [10.62618974 14.90255566 11.28235339], train_hist_grp_loss: [16.57512186 21.47366737 41.52663499], cur_train_grp_loss: [0.09479485 0.12309999 0.23727463], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6846, max_kl_dist_index: 2, max_train_grp_loss:  15.8803, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9026, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2373, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:38:34,254 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  174, train_loss:  13.4341, val_loss:  12.2652, grad_norm: 0.0057, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6547, 0.3492, 0.6846, param: [4.12916159 9.44149405 5.01256128 8.97791891], weights: [0.23352125 0.2707183  0.49576045], train_wt_loss:  40.3022, val_wt_loss: 36.7956, train_grp_loss: [11.75392284 15.88068447 11.15152323], val_grp_loss: [10.62584735 14.90324064 11.28228169], train_hist_grp_loss: [16.66991416 21.59677039 41.76390555], cur_train_grp_loss: [0.09479229 0.12310302 0.23727056], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6846, max_kl_dist_index: 2, max_train_grp_loss:  15.8807, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9032, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2373, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:38:35,281 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  175, train_loss:  13.4341, val_loss:  12.2653, grad_norm: 0.0057, live_grad: 0.0000, reward_err: 0.0035, 0.0310, 0.0013, KL_dist: 0.6548, 0.3492, 0.6847, param: [4.12884456 9.44141209 5.01272455 8.97906112], weights: [0.23297292 0.27031215 0.49671493], train_wt_loss:  40.3022, val_wt_loss: 36.7958, train_grp_loss: [11.75359628 15.88108561 11.15132799], val_grp_loss: [10.62550069 14.90393418 11.2822084 ], train_hist_grp_loss: [16.76470386 21.71987647 42.001172  ], cur_train_grp_loss: [0.0947897  0.12310608 0.23726645], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6847, max_kl_dist_index: 2, max_train_grp_loss:  15.8811, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9039, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2373, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:38:36,312 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  176, train_loss:  13.4341, val_loss:  12.2654, grad_norm: 0.0057, live_grad: 0.0000, reward_err: 0.0035, 0.0310, 0.0013, KL_dist: 0.6548, 0.3492, 0.6848, param: [4.12852527 9.44133445 5.01288573 8.98020836], weights: [0.232425   0.26990565 0.49766935], train_wt_loss:  40.3022, val_wt_loss: 36.7961, train_grp_loss: [11.75326477 15.88149246 11.1511307 ], val_grp_loss: [10.62514977 14.90463628 11.28213352], train_hist_grp_loss: [16.85949092 21.84298566 42.2384343 ], cur_train_grp_loss: [0.09478707 0.12310919 0.2372623 ], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6848, max_kl_dist_index: 2, max_train_grp_loss:  15.8815, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9046, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2373, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:38:37,363 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  177, train_loss:  13.4341, val_loss:  12.2655, grad_norm: 0.0058, live_grad: 0.0000, reward_err: 0.0035, 0.0310, 0.0013, KL_dist: 0.6549, 0.3493, 0.6849, param: [4.12820373 9.44126113 5.01304482 8.98136061], weights: [0.2318775  0.26949879 0.49862371], train_wt_loss:  40.3022, val_wt_loss: 36.7964, train_grp_loss: [11.75292831 15.881905   11.15093134], val_grp_loss: [10.62479458 14.90534694 11.28205704], train_hist_grp_loss: [16.95427532 21.966098   42.4756924 ], cur_train_grp_loss: [0.09478439 0.12311234 0.2372581 ], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6849, max_kl_dist_index: 2, max_train_grp_loss:  15.8819, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9053, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2373, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:38:38,425 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  178, train_loss:  13.4341, val_loss:  12.2656, grad_norm: 0.0058, live_grad: 0.0000, reward_err: 0.0035, 0.0310, 0.0013, KL_dist: 0.6549, 0.3493, 0.6849, param: [4.12787993 9.44119213 5.0132018  8.98251787], weights: [0.23133042 0.26909158 0.499578  ], train_wt_loss:  40.3022, val_wt_loss: 36.7967, train_grp_loss: [11.75258691 15.88232324 11.15072994], val_grp_loss: [10.62443514 14.90606615 11.28197898], train_hist_grp_loss: [17.049057   22.08921355 42.71294626], cur_train_grp_loss: [0.09478168 0.12311554 0.23725386], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6849, max_kl_dist_index: 2, max_train_grp_loss:  15.8823, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9061, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2373, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:38:39,456 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  179, train_loss:  13.4341, val_loss:  12.2656, grad_norm: 0.0058, live_grad: 0.0000, reward_err: 0.0035, 0.0310, 0.0013, KL_dist: 0.6550, 0.3494, 0.6850, param: [4.12755387 9.44112743 5.01335669 8.98368014], weights: [0.23078376 0.26868402 0.50053222], train_wt_loss:  40.3023, val_wt_loss: 36.7969, train_grp_loss: [11.75224056 15.88274718 11.15052648], val_grp_loss: [10.62407145 14.90679391 11.28189933], train_hist_grp_loss: [17.14383592 22.21233233 42.95019583], cur_train_grp_loss: [0.09477893 0.12311878 0.23724957], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6850, max_kl_dist_index: 2, max_train_grp_loss:  15.8827, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9068, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2372, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:38:40,504 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  180, train_loss:  13.4341, val_loss:  12.2657, grad_norm: 0.0058, live_grad: 0.0000, reward_err: 0.0035, 0.0310, 0.0013, KL_dist: 0.6550, 0.3494, 0.6851, param: [4.12722556 9.44106703 5.01350947 8.9848474 ], weights: [0.23023753 0.26827613 0.50148634], train_wt_loss:  40.3023, val_wt_loss: 36.7972, train_grp_loss: [11.75188927 15.88317682 11.15032098], val_grp_loss: [10.62370351 14.90753022 11.2818181 ], train_hist_grp_loss: [17.23861206 22.3354544  43.18744107], cur_train_grp_loss: [0.09477613 0.12312207 0.23724524], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6851, max_kl_dist_index: 2, max_train_grp_loss:  15.8832, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9075, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2372, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:38:41,520 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  181, train_loss:  13.4341, val_loss:  12.2658, grad_norm: 0.0059, live_grad: 0.0000, reward_err: 0.0035, 0.0310, 0.0013, KL_dist: 0.6551, 0.3494, 0.6852, param: [4.12689499 9.44101093 5.01366014 8.98601966], weights: [0.22969173 0.26786789 0.50244038], train_wt_loss:  40.3023, val_wt_loss: 36.7975, train_grp_loss: [11.75153305 15.88361215 11.15011343], val_grp_loss: [10.62333133 14.90827507 11.28173529], train_hist_grp_loss: [17.33338536 22.4585798  43.42468195], cur_train_grp_loss: [0.0947733  0.1231254  0.23724087], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6852, max_kl_dist_index: 2, max_train_grp_loss:  15.8836, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9083, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2372, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:38:42,600 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  182, train_loss:  13.4341, val_loss:  12.2659, grad_norm: 0.0059, live_grad: 0.0000, reward_err: 0.0035, 0.0314, 0.0013, KL_dist: 0.6552, 0.3495, 0.6852, param: [4.12656217 9.44095911 5.01380871 8.9871969 ], weights: [0.22914636 0.26745933 0.50339432], train_wt_loss:  40.3023, val_wt_loss: 36.7978, train_grp_loss: [11.7511719  15.88405318 11.14990384], val_grp_loss: [10.62295492 14.90902847 11.2816509 ], train_hist_grp_loss: [17.42815579 22.58170858 43.6619184 ], cur_train_grp_loss: [0.09477043 0.12312878 0.23723646], max_reward_err:  0.0314, max_reward_err_index: 1, max_kl_dist:  0.6852, max_kl_dist_index: 2, max_train_grp_loss:  15.8841, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9090, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2372, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:38:43,632 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  183, train_loss:  13.4341, val_loss:  12.2660, grad_norm: 0.0059, live_grad: 0.0000, reward_err: 0.0035, 0.0314, 0.0013, KL_dist: 0.6552, 0.3495, 0.6853, param: [4.12622709 9.44091158 5.01395515 8.98837912], weights: [0.22860142 0.26705043 0.50434815], train_wt_loss:  40.3024, val_wt_loss: 36.7981, train_grp_loss: [11.75080583 15.8844999  11.14969221], val_grp_loss: [10.62257427 14.90979041 11.28156493], train_hist_grp_loss: [17.5229233  22.70484077 43.8991504 ], cur_train_grp_loss: [0.09476752 0.1231322  0.237232  ], max_reward_err:  0.0314, max_reward_err_index: 1, max_kl_dist:  0.6853, max_kl_dist_index: 2, max_train_grp_loss:  15.8845, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9098, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2372, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:38:44,673 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  184, train_loss:  13.4341, val_loss:  12.2661, grad_norm: 0.0059, live_grad: 0.0000, reward_err: 0.0035, 0.0314, 0.0013, KL_dist: 0.6553, 0.3496, 0.6854, param: [4.12588975 9.44086831 5.01409948 8.98956631], weights: [0.22805693 0.26664121 0.50530186], train_wt_loss:  40.3024, val_wt_loss: 36.7984, train_grp_loss: [11.75043483 15.88495231 11.14947855], val_grp_loss: [10.62218939 14.9105609  11.28147739], train_hist_grp_loss: [17.61768787 22.82797643 44.13637789], cur_train_grp_loss: [0.09476456 0.12313566 0.23722749], max_reward_err:  0.0314, max_reward_err_index: 1, max_kl_dist:  0.6854, max_kl_dist_index: 2, max_train_grp_loss:  15.8850, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9106, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2372, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:38:45,709 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  185, train_loss:  13.4341, val_loss:  12.2662, grad_norm: 0.0060, live_grad: 0.0000, reward_err: 0.0035, 0.0314, 0.0013, KL_dist: 0.6553, 0.3496, 0.6855, param: [4.12555016 9.44082932 5.01424169 8.99075847], weights: [0.22751288 0.26623166 0.50625546], train_wt_loss:  40.3024, val_wt_loss: 36.7987, train_grp_loss: [11.75005892 15.88541041 11.14926286], val_grp_loss: [10.62180029 14.91133991 11.28138829], train_hist_grp_loss: [17.71244944 22.9511156  44.37360084], cur_train_grp_loss: [0.09476157 0.12313917 0.23722295], max_reward_err:  0.0314, max_reward_err_index: 1, max_kl_dist:  0.6855, max_kl_dist_index: 2, max_train_grp_loss:  15.8854, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9113, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2372, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:38:46,734 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  186, train_loss:  13.4341, val_loss:  12.2663, grad_norm: 0.0060, live_grad: 0.0000, reward_err: 0.0035, 0.0314, 0.0013, KL_dist: 0.6554, 0.3496, 0.6855, param: [4.12520832 9.44079459 5.01438177 8.99195558], weights: [0.22696928 0.2658218  0.50720892], train_wt_loss:  40.3024, val_wt_loss: 36.7990, train_grp_loss: [11.7496781  15.88587421 11.14904513], val_grp_loss: [10.62140697 14.91212747 11.28129762], train_hist_grp_loss: [17.80720798 23.07425831 44.6108192 ], cur_train_grp_loss: [0.09475854 0.12314272 0.23721836], max_reward_err:  0.0314, max_reward_err_index: 1, max_kl_dist:  0.6855, max_kl_dist_index: 2, max_train_grp_loss:  15.8859, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9121, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2372, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:38:47,785 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  187, train_loss:  13.4342, val_loss:  12.2664, grad_norm: 0.0060, live_grad: 0.0000, reward_err: 0.0035, 0.0314, 0.0013, KL_dist: 0.6555, 0.3497, 0.6856, param: [4.12486421 9.44076411 5.01451972 8.99315765], weights: [0.22642612 0.26541163 0.50816225], train_wt_loss:  40.3025, val_wt_loss: 36.7993, train_grp_loss: [11.74929236 15.88634369 11.14882539], val_grp_loss: [10.62100944 14.91292355 11.28120538], train_hist_grp_loss: [17.90196344 23.19740463 44.84803292], cur_train_grp_loss: [0.09475547 0.12314631 0.23721373], max_reward_err:  0.0314, max_reward_err_index: 1, max_kl_dist:  0.6856, max_kl_dist_index: 2, max_train_grp_loss:  15.8863, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9129, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2372, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:38:48,826 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  188, train_loss:  13.4342, val_loss:  12.2665, grad_norm: 0.0060, live_grad: 0.0000, reward_err: 0.0035, 0.0314, 0.0013, KL_dist: 0.6555, 0.3497, 0.6857, param: [4.12451786 9.44073788 5.01465554 8.99436467], weights: [0.22588341 0.26500115 0.50911544], train_wt_loss:  40.3025, val_wt_loss: 36.7996, train_grp_loss: [11.74890173 15.88681886 11.14860362], val_grp_loss: [10.6206077  14.91372816 11.28111159], train_hist_grp_loss: [17.9967158  23.32055458 45.08524197], cur_train_grp_loss: [0.09475236 0.12314995 0.23720905], max_reward_err:  0.0314, max_reward_err_index: 1, max_kl_dist:  0.6857, max_kl_dist_index: 2, max_train_grp_loss:  15.8868, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9137, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2372, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:38:49,848 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  189, train_loss:  13.4342, val_loss:  12.2666, grad_norm: 0.0061, live_grad: 0.0000, reward_err: 0.0035, 0.0314, 0.0013, KL_dist: 0.6556, 0.3498, 0.6858, param: [4.12416924 9.44071589 5.01478923 8.99557662], weights: [0.22534116 0.26459036 0.51006847], train_wt_loss:  40.3025, val_wt_loss: 36.7999, train_grp_loss: [11.74850619 15.88729971 11.14837983], val_grp_loss: [10.62020175 14.91454129 11.28101624], train_hist_grp_loss: [18.09146501 23.44370821 45.32244631], cur_train_grp_loss: [0.09474921 0.12315363 0.23720433], max_reward_err:  0.0314, max_reward_err_index: 1, max_kl_dist:  0.6858, max_kl_dist_index: 2, max_train_grp_loss:  15.8873, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9145, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2372, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:38:50,866 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  190, train_loss:  13.4342, val_loss:  12.2667, grad_norm: 0.0061, live_grad: 0.0000, reward_err: 0.0035, 0.0314, 0.0013, KL_dist: 0.6557, 0.3498, 0.6859, param: [4.12381837 9.44069813 5.01492077 8.99679351], weights: [0.22479937 0.26417928 0.51102135], train_wt_loss:  40.3025, val_wt_loss: 36.8002, train_grp_loss: [11.74810577 15.88778625 11.14815403], val_grp_loss: [10.61979161 14.91536295 11.28091933], train_hist_grp_loss: [18.18621103 23.56686557 45.55964588], cur_train_grp_loss: [0.09474602 0.12315736 0.23719957], max_reward_err:  0.0314, max_reward_err_index: 1, max_kl_dist:  0.6859, max_kl_dist_index: 2, max_train_grp_loss:  15.8878, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9154, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2372, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:38:51,881 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  191, train_loss:  13.4342, val_loss:  12.2668, grad_norm: 0.0061, live_grad: 0.0000, reward_err: 0.0035, 0.0314, 0.0013, KL_dist: 0.6557, 0.3499, 0.6860, param: [4.12346525 9.4406846  5.01505018 8.99801532], weights: [0.22425804 0.2637679  0.51197406], train_wt_loss:  40.3026, val_wt_loss: 36.8005, train_grp_loss: [11.74770045 15.88827846 11.14792622], val_grp_loss: [10.61937728 14.91619312 11.28082087], train_hist_grp_loss: [18.28095382 23.69002671 45.79684064], cur_train_grp_loss: [0.09474279 0.12316113 0.23719477], max_reward_err:  0.0314, max_reward_err_index: 1, max_kl_dist:  0.6860, max_kl_dist_index: 2, max_train_grp_loss:  15.8883, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9162, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2372, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:38:52,938 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  192, train_loss:  13.4342, val_loss:  12.2669, grad_norm: 0.0062, live_grad: 0.0000, reward_err: 0.0035, 0.0314, 0.0013, KL_dist: 0.6558, 0.3499, 0.6860, param: [4.12310987 9.4406753  5.01517744 8.99924205], weights: [0.22371717 0.26335623 0.5129266 ], train_wt_loss:  40.3026, val_wt_loss: 36.8008, train_grp_loss: [11.74729025 15.88877636 11.14769641], val_grp_loss: [10.61895876 14.91703182 11.28072087], train_hist_grp_loss: [18.37569334 23.81319166 46.03403056], cur_train_grp_loss: [0.09473952 0.12316495 0.23718992], max_reward_err:  0.0314, max_reward_err_index: 1, max_kl_dist:  0.6860, max_kl_dist_index: 2, max_train_grp_loss:  15.8888, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9170, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2372, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:38:53,959 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  193, train_loss:  13.4342, val_loss:  12.2671, grad_norm: 0.0062, live_grad: 0.0000, reward_err: 0.0035, 0.0314, 0.0013, KL_dist: 0.6559, 0.3500, 0.6861, param: [4.12275223 9.4406702  5.01530255 9.00047369], weights: [0.22317677 0.26294427 0.51387896], train_wt_loss:  40.3026, val_wt_loss: 36.8012, train_grp_loss: [11.74687517 15.88927994 11.14746459], val_grp_loss: [10.61853606 14.91787902 11.28061932], train_hist_grp_loss: [18.47042955 23.93636047 46.27121559], cur_train_grp_loss: [0.09473621 0.12316881 0.23718503], max_reward_err:  0.0314, max_reward_err_index: 1, max_kl_dist:  0.6861, max_kl_dist_index: 2, max_train_grp_loss:  15.8893, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9179, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2372, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:38:54,982 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  194, train_loss:  13.4342, val_loss:  12.2672, grad_norm: 0.0062, live_grad: 0.0000, reward_err: 0.0035, 0.0314, 0.0013, KL_dist: 0.6559, 0.3500, 0.6862, param: [4.12239234 9.44066932 5.01542551 9.00171023], weights: [0.22263685 0.26253202 0.51483113], train_wt_loss:  40.3026, val_wt_loss: 36.8015, train_grp_loss: [11.74645521 15.8897892  11.14723077], val_grp_loss: [10.61810919 14.91873473 11.28051623], train_hist_grp_loss: [18.56516241 24.05953318 46.50839569], cur_train_grp_loss: [0.09473286 0.12317271 0.2371801 ], max_reward_err:  0.0314, max_reward_err_index: 1, max_kl_dist:  0.6862, max_kl_dist_index: 2, max_train_grp_loss:  15.8898, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9187, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2372, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:38:56,000 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  195, train_loss:  13.4342, val_loss:  12.2673, grad_norm: 0.0063, live_grad: 0.0000, reward_err: 0.0035, 0.0314, 0.0013, KL_dist: 0.6560, 0.3500, 0.6863, param: [4.12203019 9.44067263 5.01554631 9.00295167], weights: [0.22209739 0.2621195  0.51578311], train_wt_loss:  40.3027, val_wt_loss: 36.8018, train_grp_loss: [11.74603038 15.89030413 11.14699495], val_grp_loss: [10.61767814 14.91959894 11.2804116 ], train_hist_grp_loss: [18.65989189 24.18270984 46.74557081], cur_train_grp_loss: [0.09472948 0.12317666 0.23717512], max_reward_err:  0.0314, max_reward_err_index: 1, max_kl_dist:  0.6863, max_kl_dist_index: 2, max_train_grp_loss:  15.8903, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9196, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2372, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:38:57,032 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  196, train_loss:  13.4342, val_loss:  12.2674, grad_norm: 0.0063, live_grad: 0.0000, reward_err: 0.0035, 0.0314, 0.0013, KL_dist: 0.6560, 0.3501, 0.6864, param: [4.12166579 9.44068013 5.01566496 9.00419799], weights: [0.22155841 0.26170671 0.51673488], train_wt_loss:  40.3027, val_wt_loss: 36.8021, train_grp_loss: [11.7456007  15.89082473 11.14675714], val_grp_loss: [10.61724293 14.92047166 11.28030544], train_hist_grp_loss: [18.75461794 24.30589049 46.98274092], cur_train_grp_loss: [0.09472605 0.12318065 0.23717011], max_reward_err:  0.0314, max_reward_err_index: 1, max_kl_dist:  0.6864, max_kl_dist_index: 2, max_train_grp_loss:  15.8908, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9205, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2372, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:38:58,079 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  197, train_loss:  13.4342, val_loss:  12.2675, grad_norm: 0.0063, live_grad: 0.0000, reward_err: 0.0035, 0.0314, 0.0013, KL_dist: 0.6561, 0.3501, 0.6865, param: [4.12129914 9.44069182 5.01578144 9.0054492 ], weights: [0.22101991 0.26129364 0.51768645], train_wt_loss:  40.3027, val_wt_loss: 36.8025, train_grp_loss: [11.74516615 15.891351   11.14651735], val_grp_loss: [10.61680356 14.92135288 11.28019774], train_hist_grp_loss: [18.84934053 24.42907518 47.21990597], cur_train_grp_loss: [0.09472259 0.12318469 0.23716505], max_reward_err:  0.0314, max_reward_err_index: 1, max_kl_dist:  0.6865, max_kl_dist_index: 2, max_train_grp_loss:  15.8914, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9214, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2372, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:38:59,105 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  198, train_loss:  13.4342, val_loss:  12.2676, grad_norm: 0.0063, live_grad: 0.0000, reward_err: 0.0035, 0.0314, 0.0013, KL_dist: 0.6562, 0.3502, 0.6865, param: [4.12093023 9.44070768 5.01589576 9.00670528], weights: [0.22048189 0.26088031 0.5186378 ], train_wt_loss:  40.3027, val_wt_loss: 36.8028, train_grp_loss: [11.74472675 15.89188295 11.14627557], val_grp_loss: [10.61636004 14.92224259 11.28008852], train_hist_grp_loss: [18.94405961 24.55226395 47.45706591], cur_train_grp_loss: [0.09471908 0.12318877 0.23715994], max_reward_err:  0.0314, max_reward_err_index: 1, max_kl_dist:  0.6865, max_kl_dist_index: 2, max_train_grp_loss:  15.8919, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9222, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2372, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:39:00,142 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  199, train_loss:  13.4343, val_loss:  12.2677, grad_norm: 0.0064, live_grad: 0.0000, reward_err: 0.0035, 0.0314, 0.0013, KL_dist: 0.6562, 0.3502, 0.6866, param: [4.12055906 9.44072772 5.01600791 9.00796622], weights: [0.21994436 0.26046671 0.51958893], train_wt_loss:  40.3028, val_wt_loss: 36.8031, train_grp_loss: [11.7442825  15.89242056 11.1460318 ], val_grp_loss: [10.61591237 14.92314078 11.27997777], train_hist_grp_loss: [19.03877515 24.67545684 47.69422071], cur_train_grp_loss: [0.09471554 0.12319289 0.2371548 ], max_reward_err:  0.0314, max_reward_err_index: 1, max_kl_dist:  0.6866, max_kl_dist_index: 2, max_train_grp_loss:  15.8924, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9231, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2372, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:39:01,087 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1654] - INFO: Iteration:  199, train_loss:  13.4343, val_loss:  12.2677, grad_norm: 0.0064,  live_grad: 0.0000, reward_err: 0.0035, 0.0314, 0.0013, KL_dist: 0.6562, 0.3502, 0.6866, param: [4.12055906 9.44072772 5.01600791 9.00796622], weights: [0.21994436 0.26046671 0.51958893], train_wt_loss:  40.3028, val_wt_loss: 36.8031, train_grp_loss: [11.7442825  15.89242056 11.1460318 ], val_grp_loss: [10.61591237 14.92314078 11.27997777], train_hist_grp_loss: [19.03877515 24.67545684 47.69422071], cur_train_grp_loss: [0.09471554 0.12319289 0.2371548 ], max_reward_err:  0.0314, max_reward_err_index: 1, max_kl_dist:  0.6866, max_kl_dist_index: 2, max_train_grp_loss:  15.8924, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9231, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2372, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:39:01,322 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:388] - INFO: Policy parameter learned solely on the preference data rdpo: [4.12055906 9.44072772 5.01600791 9.00796622].
2024-10-07 01:39:01,677 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Uniform reward: 3.8269, 3.8269, 3.1987
2024-10-07 01:39:01,678 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Optimal reward: 3.8681, 7.1581, 3.3364
2024-10-07 01:39:01,679 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Policy reward: 3.8545, 6.9331, 3.3322
2024-10-07 01:39:01,679 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:402] - INFO: Reward Error: 0.0035, 0.0314, 0.0013
2024-10-07 01:39:02,408 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:417] - INFO: Optimal reward: 3.8681, 7.1581, 3.3364
Known param reward: [[3.8680634765625, 6.699916015625, 3.30809521484375], [3.46072314453125, 7.1581357421875, 3.12821826171875], [3.83464501953125, 7.0068994140625, 3.336449462890625]], Known param reward error: [[0.0, 0.06401383587376193, 0.00849832984501714], [0.10530859550248342, 0.0, 0.06241101610796404], [0.008639583407495802, 0.02112789329121925, 0.0]].
