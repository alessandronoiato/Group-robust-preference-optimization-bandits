2024-10-07 01:03:09,729 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log-hyperparam-search/2024_10_07_00_27_03/rdpo,0.1,0.1,0.04,2022
2024-10-07 01:03:09,731 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2022
2024-10-07 01:03:09,732 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-10-07 01:03:09,821 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.3214, l2 distance: 25.6155, acc: 0.89.
2024-10-07 01:03:09,822 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-10-07 01:03:09,823 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [ 4.91492317 13.51244723  6.71533233  9.49961375]
2024-10-07 01:03:10,042 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.8530, 6.9304, 3.3326
2024-10-07 01:03:10,271 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1314] - INFO: unique_group_ids: {0, 1, 2}
2024-10-07 01:03:11,494 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  0, train_loss:  13.4334, val_loss:  12.2621, grad_norm: 0.5704, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6507, 0.3479, 0.6809, param: [4.15023342 9.52499961 4.95539468 8.85793795], weights: [0.33201524 0.33217368 0.33581108], train_wt_loss:  40.3003, val_wt_loss: 36.7862, train_grp_loss: [11.73442877 15.89741443 11.15297469], val_grp_loss: [10.61965735 14.91261496 11.26983888], train_hist_grp_loss: [0.17243466 0.18436246 0.45663202], cur_train_grp_loss: [0.17243466 0.18436246 0.45663202], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6809, max_kl_dist_index: 2, max_train_grp_loss:  15.8974, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9126, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.4566, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:03:12,551 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  1, train_loss:  13.4334, val_loss:  12.2620, grad_norm: 0.0001, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6506, 0.3479, 0.6808, param: [4.15031712 9.52383848 4.9560263  8.85828784], weights: [0.33125266 0.33179014 0.3369572 ], train_wt_loss:  40.3003, val_wt_loss: 36.7860, train_grp_loss: [11.73512841 15.89665962 11.15319952], val_grp_loss: [10.62018831 14.91160383 11.27011687], train_hist_grp_loss: [0.26706715 0.30759823 0.69392936], cur_train_grp_loss: [0.09463249 0.12323577 0.23729733], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6808, max_kl_dist_index: 2, max_train_grp_loss:  15.8967, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9116, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2373, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:03:13,703 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  2, train_loss:  13.4334, val_loss:  12.2620, grad_norm: 0.0001, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6506, 0.3479, 0.6808, param: [4.15039712 9.52268532 4.95665522 8.85864618], weights: [0.33048988 0.33140492 0.3381052 ], train_wt_loss:  40.3003, val_wt_loss: 36.7859, train_grp_loss: [11.73581995 15.89591423 11.1534209 ], val_grp_loss: [10.62071211 14.91060677 11.27039222], train_hist_grp_loss: [0.36170528 0.43082815 0.93123148], cur_train_grp_loss: [0.09463813 0.12322992 0.23730212], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6808, max_kl_dist_index: 2, max_train_grp_loss:  15.8959, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9106, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2373, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:03:14,818 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  3, train_loss:  13.4334, val_loss:  12.2619, grad_norm: 0.0001, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6506, 0.3478, 0.6808, param: [4.1504734  9.52154016 4.95728144 8.85901297], weights: [0.32972689 0.33101803 0.33925508], train_wt_loss:  40.3003, val_wt_loss: 36.7857, train_grp_loss: [11.73650339 15.89517827 11.15363883], val_grp_loss: [10.62122874 14.90962378 11.27066493], train_hist_grp_loss: [0.45634899 0.55405229 1.1685383 ], cur_train_grp_loss: [0.09464371 0.12322414 0.23730683], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6808, max_kl_dist_index: 2, max_train_grp_loss:  15.8952, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9096, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2373, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:03:15,931 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  4, train_loss:  13.4334, val_loss:  12.2618, grad_norm: 0.0001, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6506, 0.3478, 0.6807, param: [4.15054596 9.52040299 4.95790495 8.85938824], weights: [0.3289637  0.33062947 0.34040683], train_wt_loss:  40.3003, val_wt_loss: 36.7855, train_grp_loss: [11.73717871 15.89445177 11.15385329], val_grp_loss: [10.62173819 14.9086549  11.27093498], train_hist_grp_loss: [0.55099821 0.67727073 1.40584977], cur_train_grp_loss: [0.09464922 0.12321844 0.23731146], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6807, max_kl_dist_index: 2, max_train_grp_loss:  15.8945, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9087, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2373, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:03:17,000 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  5, train_loss:  13.4334, val_loss:  12.2618, grad_norm: 0.0002, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6506, 0.3478, 0.6807, param: [4.15061481 9.51927384 4.95852574 8.85977201], weights: [0.32820032 0.33023924 0.34156044], train_wt_loss:  40.3003, val_wt_loss: 36.7853, train_grp_loss: [11.73784589 15.89373471 11.15406428], val_grp_loss: [10.62224043 14.90770013 11.27120238], train_hist_grp_loss: [0.64565288 0.80048353 1.6431658 ], cur_train_grp_loss: [0.09465467 0.1232128  0.23731603], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6807, max_kl_dist_index: 2, max_train_grp_loss:  15.8937, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9077, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2373, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:03:18,079 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  6, train_loss:  13.4334, val_loss:  12.2617, grad_norm: 0.0002, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6506, 0.3477, 0.6807, param: [4.15067992 9.5181527  4.95914381 8.86016429], weights: [0.32743674 0.32984736 0.3427159 ], train_wt_loss:  40.3003, val_wt_loss: 36.7851, train_grp_loss: [11.73850492 15.89302713 11.15427178], val_grp_loss: [10.62273546 14.9067595  11.27146711], train_hist_grp_loss: [0.74031293 0.92369078 1.88048631], cur_train_grp_loss: [0.09466005 0.12320725 0.23732052], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6807, max_kl_dist_index: 2, max_train_grp_loss:  15.8930, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9068, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2373, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:03:19,152 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  7, train_loss:  13.4334, val_loss:  12.2617, grad_norm: 0.0003, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6506, 0.3477, 0.6806, param: [4.15074131 9.51703958 4.95975914 8.8605651 ], weights: [0.32667299 0.32945382 0.34387319], train_wt_loss:  40.3003, val_wt_loss: 36.7850, train_grp_loss: [11.73915578 15.89232902 11.1544758 ], val_grp_loss: [10.62322327 14.90583302 11.27172917], train_hist_grp_loss: [0.83497829 1.04689254 2.11781124], cur_train_grp_loss: [0.09466536 0.12320176 0.23732493], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6806, max_kl_dist_index: 2, max_train_grp_loss:  15.8923, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9058, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2373, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:03:20,190 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  8, train_loss:  13.4334, val_loss:  12.2616, grad_norm: 0.0003, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6506, 0.3477, 0.6806, param: [4.15079896 9.51593449 4.96037175 8.86097445], weights: [0.32590906 0.32905864 0.3450323 ], train_wt_loss:  40.3003, val_wt_loss: 36.7848, train_grp_loss: [11.73979844 15.8916404  11.15467631], val_grp_loss: [10.62370383 14.90492071 11.27198855], train_hist_grp_loss: [0.9296489  1.17008889 2.35514052], cur_train_grp_loss: [0.09467061 0.12319635 0.23732927], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6806, max_kl_dist_index: 2, max_train_grp_loss:  15.8916, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9049, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2373, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:03:21,212 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  9, train_loss:  13.4334, val_loss:  12.2615, grad_norm: 0.0004, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6506, 0.3477, 0.6806, param: [4.15085288 9.51483744 4.96098161 8.86139237], weights: [0.32514496 0.32866182 0.34619323], train_wt_loss:  40.3003, val_wt_loss: 36.7846, train_grp_loss: [11.7404329  15.89096128 11.15487332], val_grp_loss: [10.62417714 14.9040226  11.27224523], train_hist_grp_loss: [1.0243247  1.2932799  2.59247405], cur_train_grp_loss: [0.09467579 0.12319101 0.23733354], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6806, max_kl_dist_index: 2, max_train_grp_loss:  15.8910, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9040, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2373, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:03:22,222 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  10, train_loss:  13.4334, val_loss:  12.2615, grad_norm: 0.0004, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6505, 0.3476, 0.6805, param: [4.15090306 9.51374843 4.96158872 8.86181886], weights: [0.32438069 0.32826336 0.34735595], train_wt_loss:  40.3003, val_wt_loss: 36.7845, train_grp_loss: [11.74105914 15.89029167 11.1550668 ], val_grp_loss: [10.62464318 14.90313869 11.27249922], train_hist_grp_loss: [1.11900561 1.41646565 2.82981178], cur_train_grp_loss: [0.09468091 0.12318575 0.23733773], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6805, max_kl_dist_index: 2, max_train_grp_loss:  15.8903, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9031, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2373, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:03:23,238 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  11, train_loss:  13.4334, val_loss:  12.2614, grad_norm: 0.0005, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6505, 0.3476, 0.6805, param: [4.15094949 9.51266748 4.96219307 8.86225395], weights: [0.32361627 0.32786327 0.34852046], train_wt_loss:  40.3003, val_wt_loss: 36.7843, train_grp_loss: [11.74167715 15.88963157 11.15525676], val_grp_loss: [10.62510194 14.90226901 11.2727505 ], train_hist_grp_loss: [1.21369157 1.5396462  3.06715363], cur_train_grp_loss: [0.09468596 0.12318056 0.23734185], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6805, max_kl_dist_index: 2, max_train_grp_loss:  15.8896, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9023, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2373, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:03:24,266 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  12, train_loss:  13.4334, val_loss:  12.2614, grad_norm: 0.0005, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6505, 0.3476, 0.6805, param: [4.15099218 9.51159458 4.96279466 8.86269766], weights: [0.3228517  0.32746155 0.34968675], train_wt_loss:  40.3003, val_wt_loss: 36.7842, train_grp_loss: [11.7422869  15.88898101 11.15544319], val_grp_loss: [10.6255534  14.90141357 11.27299908], train_hist_grp_loss: [1.30838251 1.66282164 3.30449952], cur_train_grp_loss: [0.09469094 0.12317544 0.23734589], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6805, max_kl_dist_index: 2, max_train_grp_loss:  15.8890, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9014, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2373, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:03:25,287 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  13, train_loss:  13.4334, val_loss:  12.2613, grad_norm: 0.0006, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6505, 0.3476, 0.6805, param: [4.15103111 9.51052976 4.96339348 8.86314999], weights: [0.32208698 0.32705821 0.3508548 ], train_wt_loss:  40.3003, val_wt_loss: 36.7840, train_grp_loss: [11.74288838 15.88833999 11.15562608], val_grp_loss: [10.62599755 14.90057239 11.27324493], train_hist_grp_loss: [1.40307837 1.78599203 3.54184937], cur_train_grp_loss: [0.09469586 0.1231704  0.23734986], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6805, max_kl_dist_index: 2, max_train_grp_loss:  15.8883, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9006, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2373, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:03:26,329 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  14, train_loss:  13.4334, val_loss:  12.2613, grad_norm: 0.0007, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6505, 0.3475, 0.6804, param: [4.1510663  9.509473   4.96398952 8.86361096], weights: [0.32132212 0.32665327 0.35202461], train_wt_loss:  40.3003, val_wt_loss: 36.7839, train_grp_loss: [11.74348158 15.88770851 11.15580542], val_grp_loss: [10.62643439 14.8997455  11.27348805], train_hist_grp_loss: [1.49777909 1.90915746 3.77920312], cur_train_grp_loss: [0.09470071 0.12316543 0.23735375], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6804, max_kl_dist_index: 2, max_train_grp_loss:  15.8877, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8997, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:03:27,355 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  15, train_loss:  13.4334, val_loss:  12.2612, grad_norm: 0.0007, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6505, 0.3475, 0.6804, param: [4.15109772 9.50842433 4.96458278 8.8640806 ], weights: [0.32055714 0.32624671 0.35319615], train_wt_loss:  40.3003, val_wt_loss: 36.7837, train_grp_loss: [11.74406647 15.8870866  11.15598119], val_grp_loss: [10.62686388 14.8989329  11.27372845], train_hist_grp_loss: [1.59248458 2.03231799 4.01656068], cur_train_grp_loss: [0.0947055  0.12316053 0.23735756], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6804, max_kl_dist_index: 2, max_train_grp_loss:  15.8871, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8989, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:03:28,367 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  16, train_loss:  13.4334, val_loss:  12.2612, grad_norm: 0.0008, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6505, 0.3475, 0.6804, param: [4.15112539 9.50738374 4.96517325 8.8645589 ], weights: [0.31979202 0.32583855 0.35436943], train_wt_loss:  40.3003, val_wt_loss: 36.7836, train_grp_loss: [11.74464305 15.88647426 11.15615341], val_grp_loss: [10.62728604 14.89813461 11.2739661 ], train_hist_grp_loss: [1.6871948  2.1554737  4.25392199], cur_train_grp_loss: [0.09471021 0.12315571 0.2373613 ], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6804, max_kl_dist_index: 2, max_train_grp_loss:  15.8865, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8981, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:03:29,374 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  17, train_loss:  13.4334, val_loss:  12.2612, grad_norm: 0.0008, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6505, 0.3475, 0.6804, param: [4.15114928 9.50635125 4.96576093 8.8650459 ], weights: [0.31902679 0.3254288  0.35554441], train_wt_loss:  40.3003, val_wt_loss: 36.7835, train_grp_loss: [11.7452113  15.8858715  11.15632204], val_grp_loss: [10.62770083 14.89735066 11.274201  ], train_hist_grp_loss: [1.78190966 2.27862467 4.49128695], cur_train_grp_loss: [0.09471486 0.12315096 0.23736497], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6804, max_kl_dist_index: 2, max_train_grp_loss:  15.8859, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8974, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:03:30,400 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  18, train_loss:  13.4334, val_loss:  12.2611, grad_norm: 0.0009, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6505, 0.3474, 0.6803, param: [4.15116942 9.50532686 4.9663458  8.86554161], weights: [0.31826145 0.32501745 0.3567211 ], train_wt_loss:  40.3003, val_wt_loss: 36.7833, train_grp_loss: [11.74577121 15.88527834 11.1564871 ], val_grp_loss: [10.62810825 14.89658105 11.27443315], train_hist_grp_loss: [1.87662911 2.40177096 4.72865551], cur_train_grp_loss: [0.09471945 0.12314629 0.23736855], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6803, max_kl_dist_index: 2, max_train_grp_loss:  15.8853, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8966, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:03:31,420 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  19, train_loss:  13.4334, val_loss:  12.2611, grad_norm: 0.0009, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6505, 0.3474, 0.6803, param: [4.15118578 9.50431057 4.96692786 8.86604603], weights: [0.31749599 0.32460452 0.35789949], train_wt_loss:  40.3003, val_wt_loss: 36.7832, train_grp_loss: [11.74632275 15.88469477 11.15664857], val_grp_loss: [10.62850829 14.89582582 11.27466254], train_hist_grp_loss: [1.97135307 2.52491265 4.96602757], cur_train_grp_loss: [0.09472396 0.12314169 0.23737207], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6803, max_kl_dist_index: 2, max_train_grp_loss:  15.8847, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8958, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:03:32,483 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  20, train_loss:  13.4334, val_loss:  12.2610, grad_norm: 0.0010, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6505, 0.3474, 0.6803, param: [4.15119836 9.50330239 4.9675071  8.86655919], weights: [0.31673044 0.32419001 0.35907954], train_wt_loss:  40.3003, val_wt_loss: 36.7831, train_grp_loss: [11.74686592 15.88412082 11.15680644], val_grp_loss: [10.62890093 14.89508496 11.27488917], train_hist_grp_loss: [2.06608148 2.64804982 5.20340307], cur_train_grp_loss: [0.09472841 0.12313717 0.2373755 ], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6803, max_kl_dist_index: 2, max_train_grp_loss:  15.8841, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8951, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:03:33,528 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  21, train_loss:  13.4334, val_loss:  12.2610, grad_norm: 0.0011, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6505, 0.3474, 0.6803, param: [4.15120717 9.50230234 4.96808351 8.8670811 ], weights: [0.3159648  0.32377393 0.36026127], train_wt_loss:  40.3003, val_wt_loss: 36.7830, train_grp_loss: [11.74740069 15.88355648 11.15696071], val_grp_loss: [10.62928616 14.8943585  11.27511301], train_hist_grp_loss: [2.16081427 2.77118254 5.44078193], cur_train_grp_loss: [0.09473279 0.12313272 0.23737886], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6803, max_kl_dist_index: 2, max_train_grp_loss:  15.8836, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8944, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:03:34,581 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  22, train_loss:  13.4334, val_loss:  12.2610, grad_norm: 0.0011, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6505, 0.3474, 0.6803, param: [4.15121219 9.5013104  4.96865709 8.86761177], weights: [0.31519907 0.32335629 0.36144465], train_wt_loss:  40.3003, val_wt_loss: 36.7829, train_grp_loss: [11.74792707 15.88300178 11.15711137], val_grp_loss: [10.62966397 14.89364647 11.27533408], train_hist_grp_loss: [2.25555137 2.89431088 5.67816408], cur_train_grp_loss: [0.0947371  0.12312834 0.23738214], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6803, max_kl_dist_index: 2, max_train_grp_loss:  15.8830, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8936, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:03:35,617 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  23, train_loss:  13.4335, val_loss:  12.2609, grad_norm: 0.0012, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6505, 0.3474, 0.6803, param: [4.15121343 9.50032659 4.96922784 8.86815122], weights: [0.31443326 0.32293708 0.36262966], train_wt_loss:  40.3004, val_wt_loss: 36.7828, train_grp_loss: [11.74844502 15.88245672 11.15725841], val_grp_loss: [10.63003435 14.89294886 11.27555236], train_hist_grp_loss: [2.35029272 3.01743493 5.91554942], cur_train_grp_loss: [0.09474135 0.12312404 0.23738535], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6803, max_kl_dist_index: 2, max_train_grp_loss:  15.8825, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8929, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:03:36,648 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  24, train_loss:  13.4335, val_loss:  12.2609, grad_norm: 0.0012, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6505, 0.3473, 0.6802, param: [4.15121089 9.49935092 4.96979574 8.86869947], weights: [0.31366737 0.32251633 0.3638163 ], train_wt_loss:  40.3004, val_wt_loss: 36.7827, train_grp_loss: [11.74895454 15.88192131 11.15740182], val_grp_loss: [10.63039729 14.8922657  11.27576785], train_hist_grp_loss: [2.44503824 3.14055475 6.1529379 ], cur_train_grp_loss: [0.09474552 0.12311982 0.23738848], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6802, max_kl_dist_index: 2, max_train_grp_loss:  15.8819, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8923, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:03:37,657 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  25, train_loss:  13.4335, val_loss:  12.2609, grad_norm: 0.0013, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6505, 0.3473, 0.6802, param: [4.15120455 9.49838339 4.97036078 8.86925652], weights: [0.31290142 0.32209402 0.36500456], train_wt_loss:  40.3004, val_wt_loss: 36.7826, train_grp_loss: [11.74945561 15.88139556 11.1575416 ], val_grp_loss: [10.63075277 14.89159701 11.27598054], train_hist_grp_loss: [2.53978787 3.26367042 6.39032943], cur_train_grp_loss: [0.09474963 0.12311567 0.23739153], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6802, max_kl_dist_index: 2, max_train_grp_loss:  15.8814, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8916, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:03:38,673 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  26, train_loss:  13.4335, val_loss:  12.2608, grad_norm: 0.0013, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6505, 0.3473, 0.6802, param: [4.15119441 9.497424   4.97092297 8.86982239], weights: [0.31213541 0.32167017 0.36619442], train_wt_loss:  40.3004, val_wt_loss: 36.7825, train_grp_loss: [11.74994822 15.88087948 11.15767774], val_grp_loss: [10.63110079 14.89094281 11.27619042], train_hist_grp_loss: [2.63454155 3.38678201 6.62772393], cur_train_grp_loss: [0.09475367 0.12311159 0.2373945 ], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6802, max_kl_dist_index: 2, max_train_grp_loss:  15.8809, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8909, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:03:39,701 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  27, train_loss:  13.4335, val_loss:  12.2608, grad_norm: 0.0014, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6505, 0.3473, 0.6802, param: [4.15118048 9.49647276 4.97148228 8.8703971 ], weights: [0.31136934 0.32124479 0.36738586], train_wt_loss:  40.3004, val_wt_loss: 36.7824, train_grp_loss: [11.75043236 15.88037307 11.15781024], val_grp_loss: [10.63144133 14.8903031  11.27639749], train_hist_grp_loss: [2.7292992  3.5098896  6.86512133], cur_train_grp_loss: [0.09475765 0.12310759 0.2373974 ], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6802, max_kl_dist_index: 2, max_train_grp_loss:  15.8804, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8903, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:03:40,741 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  28, train_loss:  13.4335, val_loss:  12.2608, grad_norm: 0.0014, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6505, 0.3473, 0.6802, param: [4.15116274 9.49552968 4.97203873 8.87098065], weights: [0.31060323 0.32081788 0.36857888], train_wt_loss:  40.3004, val_wt_loss: 36.7823, train_grp_loss: [11.750908   15.87987636 11.15793908], val_grp_loss: [10.63177439 14.8896779  11.27660174], train_hist_grp_loss: [2.82406075 3.63299327 7.10252155], cur_train_grp_loss: [0.09476155 0.12310367 0.23740022], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6802, max_kl_dist_index: 2, max_train_grp_loss:  15.8799, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8897, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:03:41,776 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  29, train_loss:  13.4335, val_loss:  12.2607, grad_norm: 0.0015, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6505, 0.3473, 0.6802, param: [4.1511412  9.49459475 4.97259229 8.87157306], weights: [0.30983708 0.32038945 0.36977346], train_wt_loss:  40.3004, val_wt_loss: 36.7822, train_grp_loss: [11.75137515 15.87938935 11.15806426], val_grp_loss: [10.63209994 14.88906724 11.27680317], train_hist_grp_loss: [2.91882613 3.75609309 7.33992451], cur_train_grp_loss: [0.09476539 0.12309982 0.23740296], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6802, max_kl_dist_index: 2, max_train_grp_loss:  15.8794, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8891, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:03:42,816 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  30, train_loss:  13.4335, val_loss:  12.2607, grad_norm: 0.0015, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6505, 0.3472, 0.6802, param: [4.15111585 9.49366799 4.97314296 8.87217435], weights: [0.3090709  0.31995951 0.37096959], train_wt_loss:  40.3004, val_wt_loss: 36.7822, train_grp_loss: [11.75183378 15.87891204 11.15818578], val_grp_loss: [10.63241799 14.88847112 11.27700178], train_hist_grp_loss: [3.01359529 3.87918913 7.57733013], cur_train_grp_loss: [0.09476915 0.12309604 0.23740562], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6802, max_kl_dist_index: 2, max_train_grp_loss:  15.8789, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8885, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:03:43,865 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  31, train_loss:  13.4335, val_loss:  12.2607, grad_norm: 0.0016, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6505, 0.3472, 0.6802, param: [4.15108669 9.49274939 4.97369073 8.87278452], weights: [0.30830469 0.31952806 0.37216725], train_wt_loss:  40.3004, val_wt_loss: 36.7821, train_grp_loss: [11.75228388 15.87844445 11.15830363], val_grp_loss: [10.63272851 14.88788957 11.27719754], train_hist_grp_loss: [3.10836814 4.00228147 7.81473834], cur_train_grp_loss: [0.09477285 0.12309234 0.23740821], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6802, max_kl_dist_index: 2, max_train_grp_loss:  15.8784, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8879, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:03:44,903 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  32, train_loss:  13.4335, val_loss:  12.2607, grad_norm: 0.0017, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6505, 0.3472, 0.6802, param: [4.15105372 9.49183897 4.9742356  8.87340359], weights: [0.30753846 0.3190951  0.37336644], train_wt_loss:  40.3004, val_wt_loss: 36.7820, train_grp_loss: [11.75272544 15.87798658 11.1584178 ], val_grp_loss: [10.63303151 14.88732259 11.27739047], train_hist_grp_loss: [3.20314462 4.12537019 8.05214905], cur_train_grp_loss: [0.09477648 0.12308872 0.23741072], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6802, max_kl_dist_index: 2, max_train_grp_loss:  15.8780, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8873, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:03:45,924 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  33, train_loss:  13.4335, val_loss:  12.2607, grad_norm: 0.0017, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6506, 0.3472, 0.6802, param: [4.15101692 9.49093672 4.97477756 8.87403157], weights: [0.30677222 0.31866065 0.37456713], train_wt_loss:  40.3004, val_wt_loss: 36.7820, train_grp_loss: [11.75315844 15.87753845 11.15852828], val_grp_loss: [10.63332697 14.8867702  11.27758055], train_hist_grp_loss: [3.29792467 4.24845535 8.2895622 ], cur_train_grp_loss: [0.09478004 0.12308517 0.23741314], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6802, max_kl_dist_index: 2, max_train_grp_loss:  15.8775, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8868, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:03:46,980 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  34, train_loss:  13.4335, val_loss:  12.2606, grad_norm: 0.0018, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6506, 0.3472, 0.6802, param: [4.15097631 9.49004265 4.9753166  8.87466848], weights: [0.30600598 0.31822472 0.37576931], train_wt_loss:  40.3005, val_wt_loss: 36.7819, train_grp_loss: [11.75358288 15.87710007 11.15863507], val_grp_loss: [10.63361488 14.88623242 11.27776778], train_hist_grp_loss: [3.3927082  4.37153705 8.52697769], cur_train_grp_loss: [0.09478354 0.12308169 0.2374155 ], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6802, max_kl_dist_index: 2, max_train_grp_loss:  15.8771, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8862, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:03:48,015 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  35, train_loss:  13.4335, val_loss:  12.2606, grad_norm: 0.0018, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6506, 0.3472, 0.6802, param: [4.15093187 9.48915677 4.97585272 8.87531431], weights: [0.30523973 0.3177873  0.37697297], train_wt_loss:  40.3005, val_wt_loss: 36.7818, train_grp_loss: [11.75399875 15.87667144 11.15873817], val_grp_loss: [10.63389523 14.88570927 11.27795215], train_hist_grp_loss: [3.48749516 4.49461534 8.76439546], cur_train_grp_loss: [0.09478696 0.1230783  0.23741777], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6802, max_kl_dist_index: 2, max_train_grp_loss:  15.8767, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8857, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:03:49,059 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  36, train_loss:  13.4335, val_loss:  12.2606, grad_norm: 0.0019, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6506, 0.3472, 0.6802, param: [4.1508836  9.48827907 4.9763859  8.8759691 ], weights: [0.3044735 0.3173484 0.3781781], train_wt_loss:  40.3005, val_wt_loss: 36.7818, train_grp_loss: [11.75440602 15.87625257 11.15883757], val_grp_loss: [10.63416801 14.88520075 11.27813367], train_hist_grp_loss: [3.58228547 4.61769031 9.00181542], cur_train_grp_loss: [0.09479031 0.12307497 0.23741996], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6802, max_kl_dist_index: 2, max_train_grp_loss:  15.8763, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8852, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:03:50,123 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  37, train_loss:  13.4335, val_loss:  12.2606, grad_norm: 0.0019, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6506, 0.3472, 0.6802, param: [4.1508315  9.48740957 4.97691614 8.87663284], weights: [0.30370728 0.31690804 0.37938468], train_wt_loss:  40.3005, val_wt_loss: 36.7817, train_grp_loss: [11.75480468 15.87584346 11.15893325], val_grp_loss: [10.63443321 14.88470688 11.27831231], train_hist_grp_loss: [3.67707907 4.74076204 9.2392375 ], cur_train_grp_loss: [0.0947936  0.12307173 0.23742208], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6802, max_kl_dist_index: 2, max_train_grp_loss:  15.8758, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8847, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:03:51,148 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  38, train_loss:  13.4335, val_loss:  12.2606, grad_norm: 0.0020, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6506, 0.3472, 0.6802, param: [4.15077557 9.48654825 4.97744343 8.87730556], weights: [0.30294108 0.31646622 0.3805927 ], train_wt_loss:  40.3005, val_wt_loss: 36.7817, train_grp_loss: [11.75519473 15.87544414 11.15902523], val_grp_loss: [10.63469082 14.88422769 11.27848809], train_hist_grp_loss: [3.77187588 4.86383059 9.47666161], cur_train_grp_loss: [0.09479681 0.12306855 0.23742411], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6802, max_kl_dist_index: 2, max_train_grp_loss:  15.8754, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8842, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:03:52,172 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  39, train_loss:  13.4335, val_loss:  12.2606, grad_norm: 0.0020, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6506, 0.3472, 0.6802, param: [4.1507158  9.48569514 4.97796776 8.87798725], weights: [0.30217491 0.31602295 0.38180214], train_wt_loss:  40.3005, val_wt_loss: 36.7817, train_grp_loss: [11.75557616 15.87505461 11.15911348], val_grp_loss: [10.63494084 14.88376317 11.27866099], train_hist_grp_loss: [3.86667584 4.98689605 9.71408768], cur_train_grp_loss: [0.09479996 0.12306546 0.23742607], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6802, max_kl_dist_index: 2, max_train_grp_loss:  15.8751, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8838, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:03:53,228 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  40, train_loss:  13.4335, val_loss:  12.2605, grad_norm: 0.0021, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6506, 0.3472, 0.6802, param: [4.15065219 9.48485022 4.97848913 8.87867794], weights: [0.30140878 0.31557823 0.38301299], train_wt_loss:  40.3005, val_wt_loss: 36.7816, train_grp_loss: [11.75594895 15.87467487 11.15919801], val_grp_loss: [10.63518325 14.88331335 11.27883101], train_hist_grp_loss: [3.96147887 5.10995849 9.95151562], cur_train_grp_loss: [0.09480303 0.12306244 0.23742795], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6802, max_kl_dist_index: 2, max_train_grp_loss:  15.8747, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8833, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:03:54,241 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  41, train_loss:  13.4335, val_loss:  12.2605, grad_norm: 0.0021, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6506, 0.3471, 0.6802, param: [4.15058474 9.48401351 4.97900753 8.87937762], weights: [0.3006427  0.31513207 0.38422523], train_wt_loss:  40.3005, val_wt_loss: 36.7816, train_grp_loss: [11.75631308 15.87430494 11.15927882], val_grp_loss: [10.63541805 14.88287824 11.27899814], train_hist_grp_loss: [ 4.05628491  5.23301799 10.18894537], cur_train_grp_loss: [0.09480604 0.1230595  0.23742974], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6802, max_kl_dist_index: 2, max_train_grp_loss:  15.8743, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8829, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:03:55,254 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  42, train_loss:  13.4335, val_loss:  12.2605, grad_norm: 0.0022, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6507, 0.3471, 0.6802, param: [4.15051344 9.483185   4.97952295 8.88008632], weights: [0.29987666 0.31468448 0.38543886], train_wt_loss:  40.3006, val_wt_loss: 36.7816, train_grp_loss: [11.75666856 15.87394482 11.15935589], val_grp_loss: [10.63564523 14.88245786 11.27916238], train_hist_grp_loss: [ 4.15109389  5.35607461 10.42637683], cur_train_grp_loss: [0.09480898 0.12305663 0.23743146], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6802, max_kl_dist_index: 2, max_train_grp_loss:  15.8739, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8825, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:03:56,282 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  43, train_loss:  13.4335, val_loss:  12.2605, grad_norm: 0.0022, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6507, 0.3471, 0.6802, param: [4.15043829 9.48236469 4.98003539 8.88080405], weights: [0.29911068 0.31423546 0.38665385], train_wt_loss:  40.3006, val_wt_loss: 36.7815, train_grp_loss: [11.75701537 15.87359453 11.15942921], val_grp_loss: [10.63586477 14.88205221 11.27932373], train_hist_grp_loss: [ 4.24590573  5.47912845 10.66380994], cur_train_grp_loss: [0.09481184 0.12305384 0.2374331 ], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6802, max_kl_dist_index: 2, max_train_grp_loss:  15.8736, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8821, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:03:57,304 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  44, train_loss:  13.4335, val_loss:  12.2605, grad_norm: 0.0023, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6507, 0.3471, 0.6802, param: [4.15035929 9.4815526  4.98054483 8.8815308 ], weights: [0.29834477 0.31378503 0.3878702 ], train_wt_loss:  40.3006, val_wt_loss: 36.7815, train_grp_loss: [11.75735349 15.87325406 11.1594988 ], val_grp_loss: [10.63607668 14.88166132 11.27948218], train_hist_grp_loss: [ 4.34072037  5.60217957 10.9012446 ], cur_train_grp_loss: [0.09481464 0.12305112 0.23743466], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6802, max_kl_dist_index: 2, max_train_grp_loss:  15.8733, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8817, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:03:58,318 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  45, train_loss:  13.4335, val_loss:  12.2605, grad_norm: 0.0023, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6507, 0.3471, 0.6802, param: [4.15027643 9.48074872 4.98105126 8.8822666 ], weights: [0.29757893 0.31333319 0.38908788], train_wt_loss:  40.3006, val_wt_loss: 36.7815, train_grp_loss: [11.75768292 15.87292343 11.15956464], val_grp_loss: [10.63628093 14.88128519 11.27963773], train_hist_grp_loss: [ 4.43553774  5.72522805 11.13868075], cur_train_grp_loss: [0.09481737 0.12304848 0.23743614], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6802, max_kl_dist_index: 2, max_train_grp_loss:  15.8729, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8813, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:03:59,331 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  46, train_loss:  13.4335, val_loss:  12.2605, grad_norm: 0.0024, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6507, 0.3471, 0.6802, param: [4.15018972 9.47995305 4.98155469 8.88301145], weights: [0.29681317 0.31287994 0.39030689], train_wt_loss:  40.3006, val_wt_loss: 36.7815, train_grp_loss: [11.75800365 15.87260265 11.15962672], val_grp_loss: [10.63647753 14.88092384 11.27979036], train_hist_grp_loss: [ 4.53035776  5.84827397 11.37611829], cur_train_grp_loss: [0.09482002 0.12304592 0.23743755], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6802, max_kl_dist_index: 2, max_train_grp_loss:  15.8726, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8809, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:04:00,361 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  47, train_loss:  13.4335, val_loss:  12.2605, grad_norm: 0.0024, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6507, 0.3471, 0.6802, param: [4.15009914 9.4791656  4.9820551  8.88376537], weights: [0.2960475 0.3124253 0.3915272], train_wt_loss:  40.3006, val_wt_loss: 36.7815, train_grp_loss: [11.75831566 15.87229172 11.15968504], val_grp_loss: [10.63666647 14.88057729 11.27994009], train_hist_grp_loss: [ 4.62518037  5.9713174  11.61355716], cur_train_grp_loss: [0.09482261 0.12304343 0.23743887], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6802, max_kl_dist_index: 2, max_train_grp_loss:  15.8723, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8806, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:04:01,396 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  48, train_loss:  13.4335, val_loss:  12.2605, grad_norm: 0.0025, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6508, 0.3471, 0.6802, param: [4.1500047  9.47838636 4.98255249 8.88452835], weights: [0.29528192 0.31196927 0.39274881], train_wt_loss:  40.3006, val_wt_loss: 36.7815, train_grp_loss: [11.75861895 15.87199066 11.1597396 ], val_grp_loss: [10.63684774 14.88024554 11.28008691], train_hist_grp_loss: [ 4.7200055   6.09435842 11.85099727], cur_train_grp_loss: [0.09482513 0.12304102 0.23744011], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6802, max_kl_dist_index: 2, max_train_grp_loss:  15.8720, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8802, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:04:02,428 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  49, train_loss:  13.4335, val_loss:  12.2605, grad_norm: 0.0025, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6508, 0.3471, 0.6802, param: [4.14990639 9.47761535 4.98304684 8.88530042], weights: [0.29451645 0.31151186 0.39397169], train_wt_loss:  40.3006, val_wt_loss: 36.7815, train_grp_loss: [11.75891351 15.87169946 11.1597904 ], val_grp_loss: [10.63702133 14.87992861 11.2802308 ], train_hist_grp_loss: [ 4.81483307  6.21739711 12.08843853], cur_train_grp_loss: [0.09482757 0.12303869 0.23744127], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6802, max_kl_dist_index: 2, max_train_grp_loss:  15.8717, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8799, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:04:03,455 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  50, train_loss:  13.4336, val_loss:  12.2605, grad_norm: 0.0026, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6508, 0.3471, 0.6802, param: [4.14980421 9.47685255 4.98353815 8.88608157], weights: [0.29375108 0.31105308 0.39519585], train_wt_loss:  40.3007, val_wt_loss: 36.7815, train_grp_loss: [11.75919932 15.87141814 11.15983742], val_grp_loss: [10.63718724 14.87962651 11.28037177], train_hist_grp_loss: [ 4.90966302  6.34043354 12.32588088], cur_train_grp_loss: [0.09482995 0.12303643 0.23744235], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6802, max_kl_dist_index: 2, max_train_grp_loss:  15.8714, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8796, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:04:04,503 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  51, train_loss:  13.4336, val_loss:  12.2605, grad_norm: 0.0026, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6508, 0.3471, 0.6803, param: [4.14969816 9.47609797 4.98402642 8.88687182], weights: [0.29298583 0.31059293 0.39642125], train_wt_loss:  40.3007, val_wt_loss: 36.7815, train_grp_loss: [11.75947638 15.87114671 11.15988067], val_grp_loss: [10.63734545 14.87933926 11.28050982], train_hist_grp_loss: [ 5.00449527  6.46346779 12.56332423], cur_train_grp_loss: [0.09483225 0.12303425 0.23744335], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6803, max_kl_dist_index: 2, max_train_grp_loss:  15.8711, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8793, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:04:05,483 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  52, train_loss:  13.4336, val_loss:  12.2605, grad_norm: 0.0027, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6508, 0.3471, 0.6803, param: [4.14958823 9.47535161 4.98451163 8.88767117], weights: [0.2922207  0.31013142 0.39764788], train_wt_loss:  40.3007, val_wt_loss: 36.7815, train_grp_loss: [11.75974468 15.87088517 11.15992015], val_grp_loss: [10.63749596 14.87906686 11.28064493], train_hist_grp_loss: [ 5.09932976  6.58649993 12.8007685 ], cur_train_grp_loss: [0.09483449 0.12303215 0.23744427], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6803, max_kl_dist_index: 2, max_train_grp_loss:  15.8709, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8791, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:04:06,516 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  53, train_loss:  13.4336, val_loss:  12.2605, grad_norm: 0.0027, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6509, 0.3471, 0.6803, param: [4.14947443 9.47461348 4.98499377 8.88847964], weights: [0.2914557  0.30966856 0.39887573], train_wt_loss:  40.3007, val_wt_loss: 36.7815, train_grp_loss: [11.76000421 15.87063353 11.15995583], val_grp_loss: [10.63763877 14.87880933 11.28077711], train_hist_grp_loss: [ 5.19416641  6.70953005 13.03821361], cur_train_grp_loss: [0.09483665 0.12303012 0.23744511], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6803, max_kl_dist_index: 2, max_train_grp_loss:  15.8706, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8788, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:04:07,548 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  54, train_loss:  13.4336, val_loss:  12.2605, grad_norm: 0.0028, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6509, 0.3471, 0.6803, param: [4.14935674 9.47388357 4.98547284 8.88929723], weights: [0.29069084 0.30920437 0.40010479], train_wt_loss:  40.3007, val_wt_loss: 36.7816, train_grp_loss: [11.76025496 15.8703918  11.15998774], val_grp_loss: [10.63777387 14.87856669 11.28090636], train_hist_grp_loss: [ 5.28900515  6.83255822 13.27565948], cur_train_grp_loss: [0.09483874 0.12302817 0.23744587], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6803, max_kl_dist_index: 2, max_train_grp_loss:  15.8704, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8786, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:04:08,568 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  55, train_loss:  13.4336, val_loss:  12.2605, grad_norm: 0.0028, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6509, 0.3471, 0.6803, param: [4.14923517 9.47316188 4.98594883 8.89012395], weights: [0.28992613 0.30873883 0.40133504], train_wt_loss:  40.3007, val_wt_loss: 36.7816, train_grp_loss: [11.76049692 15.87015998 11.16001585], val_grp_loss: [10.63790125 14.87833894 11.28103267], train_hist_grp_loss: [ 5.38384592  6.95558451 13.51310603], cur_train_grp_loss: [0.09484077 0.12302629 0.23744655], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6803, max_kl_dist_index: 2, max_train_grp_loss:  15.8702, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8783, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:04:09,616 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  56, train_loss:  13.4336, val_loss:  12.2605, grad_norm: 0.0029, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6509, 0.3471, 0.6803, param: [4.14910971 9.47244841 4.98642173 8.8909598 ], weights: [0.28916157 0.30827197 0.40256645], train_wt_loss:  40.3007, val_wt_loss: 36.7816, train_grp_loss: [11.76073008 15.86993809 11.16004017], val_grp_loss: [10.6380209  14.87812609 11.28115603], train_hist_grp_loss: [ 5.47868864  7.07860901 13.75055317], cur_train_grp_loss: [0.09484272 0.1230245  0.23744715], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6803, max_kl_dist_index: 2, max_train_grp_loss:  15.8699, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8781, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:04:10,674 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  57, train_loss:  13.4336, val_loss:  12.2606, grad_norm: 0.0029, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6510, 0.3471, 0.6804, param: [4.14898036 9.47174317 4.98689154 8.8918048 ], weights: [0.28839717 0.30780379 0.40379903], train_wt_loss:  40.3008, val_wt_loss: 36.7817, train_grp_loss: [11.76095444 15.86972612 11.16006069], val_grp_loss: [10.63813283 14.87792816 11.28127645], train_hist_grp_loss: [ 5.57353324  7.20163178 13.98800084], cur_train_grp_loss: [0.0948446  0.12302278 0.23744766], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6804, max_kl_dist_index: 2, max_train_grp_loss:  15.8697, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8779, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:04:11,694 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  58, train_loss:  13.4336, val_loss:  12.2606, grad_norm: 0.0030, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6510, 0.3471, 0.6804, param: [4.14884712 9.47104615 4.98735824 8.89265895], weights: [0.28763294 0.3073343  0.40503275], train_wt_loss:  40.3008, val_wt_loss: 36.7817, train_grp_loss: [11.76116998 15.8695241  11.16007742], val_grp_loss: [10.63823702 14.87774516 11.28139392], train_hist_grp_loss: [ 5.66837964  7.32465291 14.22544894], cur_train_grp_loss: [0.09484641 0.12302113 0.2374481 ], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6804, max_kl_dist_index: 2, max_train_grp_loss:  15.8695, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8777, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:04:12,717 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  59, train_loss:  13.4336, val_loss:  12.2606, grad_norm: 0.0030, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6510, 0.3472, 0.6804, param: [4.14870998 9.47035735 4.98782183 8.89352225], weights: [0.28686889 0.30686351 0.4062676 ], train_wt_loss:  40.3008, val_wt_loss: 36.7817, train_grp_loss: [11.7613767  15.86933201 11.16009034], val_grp_loss: [10.63833347 14.8775771  11.28150844], train_hist_grp_loss: [ 5.76322779  7.44767248 14.46289739], cur_train_grp_loss: [0.09484815 0.12301957 0.23744846], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6804, max_kl_dist_index: 2, max_train_grp_loss:  15.8693, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8776, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:04:13,726 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  60, train_loss:  13.4336, val_loss:  12.2606, grad_norm: 0.0030, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6510, 0.3472, 0.6804, param: [4.14856894 9.46967677 4.9882823  8.89439472], weights: [0.28610502 0.30639142 0.40750356], train_wt_loss:  40.3008, val_wt_loss: 36.7818, train_grp_loss: [11.7615746  15.86914988 11.16009945], val_grp_loss: [10.63842217 14.877424   11.28162   ], train_hist_grp_loss: [ 5.8580776   7.57069056 14.70034612], cur_train_grp_loss: [0.09484981 0.12301808 0.23744873], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6804, max_kl_dist_index: 2, max_train_grp_loss:  15.8691, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8774, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:04:14,792 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  61, train_loss:  13.4336, val_loss:  12.2606, grad_norm: 0.0031, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6511, 0.3472, 0.6805, param: [4.14842401 9.46900442 4.98873964 8.89527636], weights: [0.28534133 0.30591805 0.40874062], train_wt_loss:  40.3008, val_wt_loss: 36.7818, train_grp_loss: [11.76176365 15.8689777  11.16010476], val_grp_loss: [10.63850312 14.87728585 11.28172861], train_hist_grp_loss: [ 5.95292901  7.69370722 14.93779505], cur_train_grp_loss: [0.09485141 0.12301667 0.23744892], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6805, max_kl_dist_index: 2, max_train_grp_loss:  15.8690, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8773, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:04:15,805 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  62, train_loss:  13.4336, val_loss:  12.2606, grad_norm: 0.0031, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6511, 0.3472, 0.6805, param: [4.14827517 9.46834028 4.98919385 8.89616717], weights: [0.28457785 0.3054434  0.40997875], train_wt_loss:  40.3008, val_wt_loss: 36.7819, train_grp_loss: [11.76194386 15.86881548 11.16010626], val_grp_loss: [10.63857632 14.87716268 11.28183426], train_hist_grp_loss: [ 6.04778194  7.81672256 15.17524408], cur_train_grp_loss: [0.09485293 0.12301533 0.23744904], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6805, max_kl_dist_index: 2, max_train_grp_loss:  15.8688, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8772, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:04:16,821 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  63, train_loss:  13.4336, val_loss:  12.2607, grad_norm: 0.0032, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6511, 0.3472, 0.6805, param: [4.14812242 9.46768437 4.98964491 8.89706716], weights: [0.28381457 0.30496747 0.41121796], train_wt_loss:  40.3008, val_wt_loss: 36.7820, train_grp_loss: [11.76211523 15.86866324 11.16010394], val_grp_loss: [10.63864175 14.87705449 11.28193695], train_hist_grp_loss: [ 6.14263633  7.93973663 15.41269315], cur_train_grp_loss: [0.09485439 0.12301407 0.23744907], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6805, max_kl_dist_index: 2, max_train_grp_loss:  15.8687, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8771, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:04:17,857 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  64, train_loss:  13.4336, val_loss:  12.2607, grad_norm: 0.0032, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6512, 0.3472, 0.6805, param: [4.14796577 9.46703667 4.99009282 8.89797634], weights: [0.28305151 0.30449028 0.41245821], train_wt_loss:  40.3009, val_wt_loss: 36.7820, train_grp_loss: [11.76227773 15.86852097 11.16009781], val_grp_loss: [10.63869942 14.8769613  11.28203668], train_hist_grp_loss: [ 6.23749209  8.06274952 15.65014217], cur_train_grp_loss: [0.09485577 0.12301289 0.23744902], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6805, max_kl_dist_index: 2, max_train_grp_loss:  15.8685, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8770, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:04:18,908 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  65, train_loss:  13.4336, val_loss:  12.2607, grad_norm: 0.0033, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6512, 0.3472, 0.6806, param: [4.1478052  9.46639719 4.99053757 8.89889471], weights: [0.28228866 0.30401184 0.41369949], train_wt_loss:  40.3009, val_wt_loss: 36.7821, train_grp_loss: [11.76243137 15.86838868 11.16008786], val_grp_loss: [10.63874932 14.87688311 11.28213344], train_hist_grp_loss: [ 6.33234917  8.18576131 15.88759106], cur_train_grp_loss: [0.09485708 0.12301179 0.23744889], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6806, max_kl_dist_index: 2, max_train_grp_loss:  15.8684, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8769, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:04:19,935 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  66, train_loss:  13.4336, val_loss:  12.2607, grad_norm: 0.0033, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6512, 0.3472, 0.6806, param: [4.14764072 9.46576592 4.99097914 8.89982228], weights: [0.28152605 0.30353216 0.4149418 ], train_wt_loss:  40.3009, val_wt_loss: 36.7822, train_grp_loss: [11.76257613 15.86826639 11.16007409], val_grp_loss: [10.63879145 14.87681994 11.28222723], train_hist_grp_loss: [ 6.42720749  8.30877208 16.12503974], cur_train_grp_loss: [0.09485832 0.12301076 0.23744868], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6806, max_kl_dist_index: 2, max_train_grp_loss:  15.8683, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8768, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:04:21,022 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  67, train_loss:  13.4336, val_loss:  12.2608, grad_norm: 0.0034, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6513, 0.3472, 0.6806, param: [4.14747233 9.46514287 4.99141755 8.90075905], weights: [0.28076367 0.30305123 0.4161851 ], train_wt_loss:  40.3009, val_wt_loss: 36.7823, train_grp_loss: [11.76271202 15.86815408 11.16005649], val_grp_loss: [10.63882579 14.87677179 11.28231806], train_hist_grp_loss: [ 6.52206697  8.43178189 16.36248813], cur_train_grp_loss: [0.09485948 0.12300982 0.23744838], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6806, max_kl_dist_index: 2, max_train_grp_loss:  15.8682, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8768, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:04:22,037 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  68, train_loss:  13.4336, val_loss:  12.2608, grad_norm: 0.0034, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6513, 0.3472, 0.6807, param: [4.14730002 9.46452802 4.99185276 8.90170502], weights: [0.28000153 0.30256908 0.41742939], train_wt_loss:  40.3009, val_wt_loss: 36.7823, train_grp_loss: [11.76283903 15.86805178 11.16003508], val_grp_loss: [10.63885236 14.87673867 11.28240591], train_hist_grp_loss: [ 6.61692756  8.55479084 16.59993614], cur_train_grp_loss: [0.09486058 0.12300895 0.23744801], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6807, max_kl_dist_index: 2, max_train_grp_loss:  15.8681, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8767, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:04:23,063 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  69, train_loss:  13.4336, val_loss:  12.2608, grad_norm: 0.0034, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6513, 0.3472, 0.6807, param: [4.14712378 9.46392139 4.99228479 8.9026602 ], weights: [0.27923965 0.3020857  0.41867465], train_wt_loss:  40.3009, val_wt_loss: 36.7824, train_grp_loss: [11.76295715 15.86795949 11.16000984], val_grp_loss: [10.63887114 14.87672061 11.28249079], train_hist_grp_loss: [ 6.71178916  8.67779899 16.83738369], cur_train_grp_loss: [0.09486161 0.12300815 0.23744755], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6807, max_kl_dist_index: 2, max_train_grp_loss:  15.8680, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8767, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:04:24,137 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  70, train_loss:  13.4337, val_loss:  12.2608, grad_norm: 0.0035, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6514, 0.3473, 0.6807, param: [4.14694362 9.46332296 4.99271361 8.9036246 ], weights: [0.27847802 0.30160111 0.41992087], train_wt_loss:  40.3010, val_wt_loss: 36.7825, train_grp_loss: [11.76306637 15.86787721 11.15998076], val_grp_loss: [10.63888213 14.87671759 11.2825727 ], train_hist_grp_loss: [ 6.80665172  8.80080643 17.07483071], cur_train_grp_loss: [0.09486256 0.12300744 0.23744702], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6807, max_kl_dist_index: 2, max_train_grp_loss:  15.8679, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8767, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:04:25,174 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  71, train_loss:  13.4337, val_loss:  12.2609, grad_norm: 0.0035, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6514, 0.3473, 0.6808, param: [4.14675954 9.46273274 4.99313922 8.90459821], weights: [0.27771666 0.30111532 0.42116802], train_wt_loss:  40.3010, val_wt_loss: 36.7826, train_grp_loss: [11.76316669 15.86780495 11.15994787], val_grp_loss: [10.63888534 14.87672964 11.28265163], train_hist_grp_loss: [ 6.90151516  8.92381323 17.31227711], cur_train_grp_loss: [0.09486344 0.1230068  0.2374464 ], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6808, max_kl_dist_index: 2, max_train_grp_loss:  15.8678, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8767, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:04:26,205 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  72, train_loss:  13.4337, val_loss:  12.2609, grad_norm: 0.0036, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6514, 0.3473, 0.6808, param: [4.14657153 9.46215072 4.99356162 8.90558105], weights: [0.27695557 0.30062833 0.4224161 ], train_wt_loss:  40.3010, val_wt_loss: 36.7827, train_grp_loss: [11.76325811 15.86774271 11.15991114], val_grp_loss: [10.63888074 14.87675676 11.28272759], train_hist_grp_loss: [ 6.9963794   9.04681947 17.54972281], cur_train_grp_loss: [0.09486425 0.12300624 0.2374457 ], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6808, max_kl_dist_index: 2, max_train_grp_loss:  15.8677, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8768, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:04:27,224 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  73, train_loss:  13.4337, val_loss:  12.2609, grad_norm: 0.0036, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6515, 0.3473, 0.6808, param: [4.14637959 9.46157689 4.99398079 8.9065731 ], weights: [0.27619477 0.30014015 0.42366508], train_wt_loss:  40.3010, val_wt_loss: 36.7828, train_grp_loss: [11.76334061 15.8676905  11.15987058], val_grp_loss: [10.63886835 14.87679896 11.28280057], train_hist_grp_loss: [ 7.09124439  9.16982523 17.78716773], cur_train_grp_loss: [0.09486498 0.12300576 0.23744492], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6808, max_kl_dist_index: 2, max_train_grp_loss:  15.8677, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8768, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:04:28,247 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  74, train_loss:  13.4337, val_loss:  12.2610, grad_norm: 0.0037, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6515, 0.3473, 0.6809, param: [4.14618371 9.46101127 4.99439672 8.90757439], weights: [0.27543425 0.2996508  0.42491495], train_wt_loss:  40.3010, val_wt_loss: 36.7829, train_grp_loss: [11.7634142  15.86764833 11.15982618], val_grp_loss: [10.63884816 14.87685625 11.28287057], train_hist_grp_loss: [ 7.18611004  9.29283058 18.02461178], cur_train_grp_loss: [0.09486565 0.12300535 0.23744405], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6809, max_kl_dist_index: 2, max_train_grp_loss:  15.8676, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8769, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:04:29,307 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  75, train_loss:  13.4337, val_loss:  12.2610, grad_norm: 0.0037, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6515, 0.3473, 0.6809, param: [4.1459839  9.46045383 4.99480941 8.9085849 ], weights: [0.27467404 0.29916027 0.42616569], train_wt_loss:  40.3010, val_wt_loss: 36.7830, train_grp_loss: [11.76347887 15.86761619 11.15977796], val_grp_loss: [10.63882017 14.87692863 11.28293759], train_hist_grp_loss: [ 7.28097628  9.41583561 18.26205489], cur_train_grp_loss: [0.09486624 0.12300503 0.23744311], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6809, max_kl_dist_index: 2, max_train_grp_loss:  15.8676, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8769, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:04:30,361 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  76, train_loss:  13.4337, val_loss:  12.2610, grad_norm: 0.0037, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6516, 0.3473, 0.6810, param: [4.14578015 9.45990458 4.99521885 8.90960465], weights: [0.27391413 0.29866858 0.42741729], train_wt_loss:  40.3011, val_wt_loss: 36.7831, train_grp_loss: [11.76353461 15.86759411 11.15972589], val_grp_loss: [10.63878438 14.87701613 11.28300164], train_hist_grp_loss: [ 7.37584305  9.53884038 18.49949697], cur_train_grp_loss: [0.09486677 0.12300478 0.23744208], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6810, max_kl_dist_index: 2, max_train_grp_loss:  15.8676, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8770, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:04:31,392 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  77, train_loss:  13.4337, val_loss:  12.2611, grad_norm: 0.0038, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6516, 0.3474, 0.6810, param: [4.14557247 9.45936352 4.99562503 8.91063363], weights: [0.27315453 0.29817574 0.42866973], train_wt_loss:  40.3011, val_wt_loss: 36.7833, train_grp_loss: [11.76358143 15.86758207 11.15967   ], val_grp_loss: [10.63874077 14.87711873 11.2830627 ], train_hist_grp_loss: [ 7.47071026  9.66184499 18.73693795], cur_train_grp_loss: [0.09486721 0.12300461 0.23744098], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6810, max_kl_dist_index: 2, max_train_grp_loss:  15.8676, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8771, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:04:32,432 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  78, train_loss:  13.4337, val_loss:  12.2611, grad_norm: 0.0038, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6517, 0.3474, 0.6810, param: [4.14536084 9.45883064 4.99602795 8.91167185], weights: [0.27239525 0.29768176 0.429923  ], train_wt_loss:  40.3011, val_wt_loss: 36.7834, train_grp_loss: [11.76361931 15.86758009 11.15961027], val_grp_loss: [10.63868937 14.87723646 11.28312078], train_hist_grp_loss: [ 7.56557785  9.7848495  18.97437774], cur_train_grp_loss: [0.09486759 0.12300451 0.23743979], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6810, max_kl_dist_index: 2, max_train_grp_loss:  15.8676, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8772, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:04:33,469 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  79, train_loss:  13.4337, val_loss:  12.2612, grad_norm: 0.0039, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6517, 0.3474, 0.6811, param: [4.14514526 9.45830593 4.99642758 8.9127193 ], weights: [0.27163629 0.29718664 0.43117707], train_wt_loss:  40.3011, val_wt_loss: 36.7835, train_grp_loss: [11.76364826 15.86758817 11.1595467 ], val_grp_loss: [10.63863015 14.87736932 11.28317587], train_hist_grp_loss: [ 7.66044575  9.907854   19.21181625], cur_train_grp_loss: [0.0948679  0.1230045  0.23743852], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6811, max_kl_dist_index: 2, max_train_grp_loss:  15.8676, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8774, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:04:34,518 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  80, train_loss:  13.4337, val_loss:  12.2612, grad_norm: 0.0039, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6518, 0.3474, 0.6811, param: [4.14492575 9.4577894  4.99682394 8.91377599], weights: [0.27087768 0.29669039 0.43243193], train_wt_loss:  40.3011, val_wt_loss: 36.7836, train_grp_loss: [11.76366827 15.86760631 11.15947929], val_grp_loss: [10.63856312 14.87751732 11.28322799], train_hist_grp_loss: [ 7.75531388 10.03085856 19.44925342], cur_train_grp_loss: [0.09486813 0.12300456 0.23743716], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6811, max_kl_dist_index: 2, max_train_grp_loss:  15.8676, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8775, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:04:35,555 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  81, train_loss:  13.4337, val_loss:  12.2613, grad_norm: 0.0039, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6518, 0.3474, 0.6812, param: [4.14470228 9.45728103 4.997217   8.91484192], weights: [0.27011941 0.29619302 0.43368757], train_wt_loss:  40.3011, val_wt_loss: 36.7838, train_grp_loss: [11.76367933 15.86763452 11.15940805], val_grp_loss: [10.63848828 14.87768046 11.28327712], train_hist_grp_loss: [ 7.85018218 10.15386326 19.68668915], cur_train_grp_loss: [0.09486829 0.1230047  0.23743573], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6812, max_kl_dist_index: 2, max_train_grp_loss:  15.8676, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8777, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:04:36,607 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  82, train_loss:  13.4337, val_loss:  12.2613, grad_norm: 0.0040, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6518, 0.3475, 0.6812, param: [4.14447486 9.45678083 4.99760675 8.9159171 ], weights: [0.26936149 0.29569455 0.43494396], train_wt_loss:  40.3011, val_wt_loss: 36.7839, train_grp_loss: [11.76368145 15.86767281 11.15933298], val_grp_loss: [10.63840563 14.87785875 11.28332327], train_hist_grp_loss: [ 7.94505056 10.27686818 19.92412336], cur_train_grp_loss: [0.09486838 0.12300492 0.23743421], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6812, max_kl_dist_index: 2, max_train_grp_loss:  15.8677, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8779, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:04:37,624 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  83, train_loss:  13.4337, val_loss:  12.2614, grad_norm: 0.0040, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6519, 0.3475, 0.6813, param: [4.14424349 9.45628879 4.9979932  8.91700151], weights: [0.26860392 0.29519498 0.4362011 ], train_wt_loss:  40.3012, val_wt_loss: 36.7841, train_grp_loss: [11.76367462 15.86772118 11.15925406], val_grp_loss: [10.63831516 14.8780522  11.28336644], train_hist_grp_loss: [ 8.03991896 10.39987339 20.16155598], cur_train_grp_loss: [0.0948684  0.12300522 0.23743262], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6813, max_kl_dist_index: 2, max_train_grp_loss:  15.8677, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8781, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:04:38,645 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  84, train_loss:  13.4337, val_loss:  12.2614, grad_norm: 0.0041, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6519, 0.3475, 0.6813, param: [4.14400817 9.4558049  4.99837633 8.91809517], weights: [0.26784673 0.29469431 0.43745896], train_wt_loss:  40.3012, val_wt_loss: 36.7842, train_grp_loss: [11.76365883 15.86777963 11.15917131], val_grp_loss: [10.63821689 14.87826082 11.28340663], train_hist_grp_loss: [ 8.1347873  10.52287898 20.39898692], cur_train_grp_loss: [0.09486834 0.12300559 0.23743094], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6813, max_kl_dist_index: 2, max_train_grp_loss:  15.8678, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8783, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:04:39,652 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  85, train_loss:  13.4337, val_loss:  12.2615, grad_norm: 0.0041, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6520, 0.3475, 0.6814, param: [4.14376888 9.45532916 4.99875614 8.91919806], weights: [0.26708991 0.29419256 0.43871753], train_wt_loss:  40.3012, val_wt_loss: 36.7844, train_grp_loss: [11.7636341  15.86784816 11.15908473], val_grp_loss: [10.63811079 14.8784846  11.28344383], train_hist_grp_loss: [ 8.22965552 10.64588503 20.63641609], cur_train_grp_loss: [0.09486822 0.12300604 0.23742918], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6814, max_kl_dist_index: 2, max_train_grp_loss:  15.8678, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8785, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:04:40,700 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  86, train_loss:  13.4337, val_loss:  12.2615, grad_norm: 0.0041, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6520, 0.3475, 0.6814, param: [4.14352564 9.45486157 4.99913261 8.9203102 ], weights: [0.26633347 0.29368974 0.43997679], train_wt_loss:  40.3012, val_wt_loss: 36.7845, train_grp_loss: [11.7636004  15.86792679 11.15899431], val_grp_loss: [10.63799689 14.87872357 11.28347805], train_hist_grp_loss: [ 8.32452353 10.7688916  20.87384343], cur_train_grp_loss: [0.09486802 0.12300657 0.23742733], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6814, max_kl_dist_index: 2, max_train_grp_loss:  15.8679, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8787, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:04:41,717 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  87, train_loss:  13.4337, val_loss:  12.2616, grad_norm: 0.0042, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6521, 0.3476, 0.6815, param: [4.14327844 9.45440211 4.99950573 8.92143158], weights: [0.26557742 0.29318585 0.44123672], train_wt_loss:  40.3012, val_wt_loss: 36.7847, train_grp_loss: [11.76355775 15.86801551 11.15890006], val_grp_loss: [10.63787517 14.87897771 11.2835093 ], train_hist_grp_loss: [ 8.41939128 10.89189879 21.11126884], cur_train_grp_loss: [0.09486775 0.12300718 0.23742541], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6815, max_kl_dist_index: 2, max_train_grp_loss:  15.8680, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8790, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:04:42,752 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  88, train_loss:  13.4338, val_loss:  12.2616, grad_norm: 0.0042, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6521, 0.3476, 0.6815, param: [4.14302728 9.45395078 4.99987551 8.9225622 ], weights: [0.26482178 0.29268091 0.44249731], train_wt_loss:  40.3013, val_wt_loss: 36.7849, train_grp_loss: [11.76350614 15.86811433 11.15880197], val_grp_loss: [10.63774564 14.87924705 11.28353756], train_hist_grp_loss: [ 8.51425868 11.01490666 21.34869224], cur_train_grp_loss: [0.0948674  0.12300787 0.23742341], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6815, max_kl_dist_index: 2, max_train_grp_loss:  15.8681, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8792, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:04:43,793 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  89, train_loss:  13.4338, val_loss:  12.2617, grad_norm: 0.0042, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6522, 0.3476, 0.6816, param: [4.14277216 9.45350758 5.00024192 8.92370206], weights: [0.26406653 0.29217492 0.44375855], train_wt_loss:  40.3013, val_wt_loss: 36.7850, train_grp_loss: [11.76344557 15.86822326 11.15870005], val_grp_loss: [10.6376083  14.87953158 11.28356284], train_hist_grp_loss: [ 8.60912566 11.1379153  21.58611356], cur_train_grp_loss: [0.09486698 0.12300864 0.23742132], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6816, max_kl_dist_index: 2, max_train_grp_loss:  15.8682, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8795, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:04:44,805 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  90, train_loss:  13.4338, val_loss:  12.2617, grad_norm: 0.0043, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6522, 0.3476, 0.6816, param: [4.14251306 9.4530725  5.00060497 8.92485115], weights: [0.2633117 0.2916679 0.4450204], train_wt_loss:  40.3013, val_wt_loss: 36.7852, train_grp_loss: [11.76337603 15.86834229 11.1585943 ], val_grp_loss: [10.63746314 14.87983131 11.28358514], train_hist_grp_loss: [ 8.70399216 11.26092478 21.82353271], cur_train_grp_loss: [0.0948665  0.12300948 0.23741915], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6816, max_kl_dist_index: 2, max_train_grp_loss:  15.8683, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8798, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:04:45,875 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  91, train_loss:  13.4338, val_loss:  12.2618, grad_norm: 0.0043, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6523, 0.3477, 0.6817, param: [4.14225    9.45264553 5.00096464 8.92600948], weights: [0.26255729 0.29115984 0.44628287], train_wt_loss:  40.3013, val_wt_loss: 36.7854, train_grp_loss: [11.76329753 15.86847143 11.15848472], val_grp_loss: [10.63731017 14.88014625 11.28360447], train_hist_grp_loss: [ 8.7988581  11.38393518 22.06094961], cur_train_grp_loss: [0.09486594 0.12301041 0.2374169 ], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6817, max_kl_dist_index: 2, max_train_grp_loss:  15.8685, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8801, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:04:46,901 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  92, train_loss:  13.4338, val_loss:  12.2619, grad_norm: 0.0044, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6523, 0.3477, 0.6818, param: [4.14198297 9.45222667 5.00132092 8.92717705], weights: [0.26180331 0.29065077 0.44754592], train_wt_loss:  40.3013, val_wt_loss: 36.7856, train_grp_loss: [11.76321007 15.86861068 11.1583713 ], val_grp_loss: [10.6371494  14.8804764  11.28362082], train_hist_grp_loss: [ 8.8937234  11.50694659 22.29836418], cur_train_grp_loss: [0.0948653  0.12301141 0.23741457], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6818, max_kl_dist_index: 2, max_train_grp_loss:  15.8686, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8805, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:04:47,937 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  93, train_loss:  13.4338, val_loss:  12.2619, grad_norm: 0.0044, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6524, 0.3477, 0.6818, param: [4.14171197 9.45181591 5.00167381 8.92835385], weights: [0.26104977 0.29014069 0.44880954], train_wt_loss:  40.3013, val_wt_loss: 36.7858, train_grp_loss: [11.76311364 15.86876004 11.15825407], val_grp_loss: [10.63698082 14.88082176 11.28363419], train_hist_grp_loss: [ 8.988588   11.62995908 22.53577634], cur_train_grp_loss: [0.0948646  0.12301249 0.23741216], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6818, max_kl_dist_index: 2, max_train_grp_loss:  15.8688, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8808, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:04:48,987 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  94, train_loss:  13.4338, val_loss:  12.2620, grad_norm: 0.0044, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6524, 0.3478, 0.6819, param: [4.141437   9.45141324 5.0020233  8.92953987], weights: [0.26029667 0.2896296  0.45007372], train_wt_loss:  40.3014, val_wt_loss: 36.7859, train_grp_loss: [11.76300825 15.86891953 11.158133  ], val_grp_loss: [10.63680443 14.88118234 11.28364459], train_hist_grp_loss: [ 9.08345182 11.75297272 22.773186  ], cur_train_grp_loss: [0.09486382 0.12301364 0.23740966], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6819, max_kl_dist_index: 2, max_train_grp_loss:  15.8689, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8812, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:04:50,035 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  95, train_loss:  13.4338, val_loss:  12.2620, grad_norm: 0.0045, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6525, 0.3478, 0.6819, param: [4.14115805 9.45101866 5.00236938 8.93073513], weights: [0.25954403 0.28911753 0.45133844], train_wt_loss:  40.3014, val_wt_loss: 36.7861, train_grp_loss: [11.76289389 15.86908914 11.15800811], val_grp_loss: [10.63662023 14.88155815 11.28365202], train_hist_grp_loss: [ 9.17831479 11.8759876  23.01059308], cur_train_grp_loss: [0.09486297 0.12301488 0.23740709], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6819, max_kl_dist_index: 2, max_train_grp_loss:  15.8691, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8816, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:04:51,077 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  96, train_loss:  13.4338, val_loss:  12.2621, grad_norm: 0.0045, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6525, 0.3478, 0.6820, param: [4.14087513 9.45063215 5.00271204 8.93193961], weights: [0.25879184 0.28860447 0.45260369], train_wt_loss:  40.3014, val_wt_loss: 36.7863, train_grp_loss: [11.76277056 15.86926887 11.1578794 ], val_grp_loss: [10.63642824 14.88194918 11.28365648], train_hist_grp_loss: [ 9.27317683 11.9990038  23.24799751], cur_train_grp_loss: [0.09486205 0.12301619 0.23740443], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6820, max_kl_dist_index: 2, max_train_grp_loss:  15.8693, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8819, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:04:52,098 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  97, train_loss:  13.4338, val_loss:  12.2622, grad_norm: 0.0045, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6526, 0.3478, 0.6821, param: [4.14058822 9.45025372 5.00305127 8.9331533 ], weights: [0.25804013 0.28809044 0.45386943], train_wt_loss:  40.3014, val_wt_loss: 36.7866, train_grp_loss: [11.76263827 15.86945873 11.15774687], val_grp_loss: [10.63622845 14.88235544 11.28365796], train_hist_grp_loss: [ 9.36803789 12.12202138 23.4853992 ], cur_train_grp_loss: [0.09486105 0.12301759 0.23740169], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6821, max_kl_dist_index: 2, max_train_grp_loss:  15.8695, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8824, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:04:53,144 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  98, train_loss:  13.4338, val_loss:  12.2623, grad_norm: 0.0046, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6526, 0.3479, 0.6821, param: [4.14029734 9.44988335 5.00338706 8.93437622], weights: [0.25728889 0.28757544 0.45513567], train_wt_loss:  40.3014, val_wt_loss: 36.7868, train_grp_loss: [11.76249702 15.86965873 11.15761053], val_grp_loss: [10.63602085 14.88277694 11.28365648], train_hist_grp_loss: [ 9.46289787 12.24504044 23.72279807], cur_train_grp_loss: [0.09485999 0.12301906 0.23739887], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6821, max_kl_dist_index: 2, max_train_grp_loss:  15.8697, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8828, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:04:54,170 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  99, train_loss:  13.4338, val_loss:  12.2623, grad_norm: 0.0046, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6527, 0.3479, 0.6822, param: [4.14000248 9.44952104 5.00371941 8.93560834], weights: [0.25653813 0.2870595  0.45640237], train_wt_loss:  40.3015, val_wt_loss: 36.7870, train_grp_loss: [11.7623468  15.86986885 11.15747036], val_grp_loss: [10.63580547 14.88321368 11.28365204], train_hist_grp_loss: [ 9.55775672 12.36806105 23.96019404], cur_train_grp_loss: [0.09485885 0.12302061 0.23739597], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6822, max_kl_dist_index: 2, max_train_grp_loss:  15.8699, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8832, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:04:55,225 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  100, train_loss:  13.4338, val_loss:  12.2624, grad_norm: 0.0046, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6527, 0.3479, 0.6823, param: [4.13970363 9.44916678 5.0040483  8.93684968], weights: [0.25578787 0.2865426  0.45766953], train_wt_loss:  40.3015, val_wt_loss: 36.7872, train_grp_loss: [11.76218762 15.87008911 11.15732639], val_grp_loss: [10.63558229 14.88366566 11.28364463], train_hist_grp_loss: [ 9.65261435 12.49108329 24.19758702], cur_train_grp_loss: [0.09485764 0.12302224 0.23739299], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6823, max_kl_dist_index: 2, max_train_grp_loss:  15.8701, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8837, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:04:56,255 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  101, train_loss:  13.4338, val_loss:  12.2625, grad_norm: 0.0047, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6528, 0.3480, 0.6823, param: [4.1394008  9.44882055 5.00437374 8.93810022], weights: [0.2550381  0.28602477 0.45893712], train_wt_loss:  40.3015, val_wt_loss: 36.7874, train_grp_loss: [11.76201947 15.8703195  11.1571786 ], val_grp_loss: [10.63535132 14.88413289 11.28363426], train_hist_grp_loss: [ 9.74747071 12.61410724 24.43497695], cur_train_grp_loss: [0.09485635 0.12302395 0.23738992], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6823, max_kl_dist_index: 2, max_train_grp_loss:  15.8703, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8841, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:04:57,280 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  102, train_loss:  13.4338, val_loss:  12.2625, grad_norm: 0.0047, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6529, 0.3480, 0.6824, param: [4.13909399 9.44848236 5.0046957  8.93935996], weights: [0.25428885 0.28550602 0.46020514], train_wt_loss:  40.3015, val_wt_loss: 36.7876, train_grp_loss: [11.76184237 15.87056004 11.15702701], val_grp_loss: [10.63511257 14.88461536 11.28362094], train_hist_grp_loss: [ 9.8423257  12.73713297 24.67236373], cur_train_grp_loss: [0.094855   0.12302573 0.23738678], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6824, max_kl_dist_index: 2, max_train_grp_loss:  15.8706, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8846, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:04:58,316 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  103, train_loss:  13.4338, val_loss:  12.2626, grad_norm: 0.0047, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6529, 0.3480, 0.6825, param: [4.13878319 9.44815219 5.00501419 8.9406289 ], weights: [0.25354011 0.28498635 0.46147355], train_wt_loss:  40.3015, val_wt_loss: 36.7879, train_grp_loss: [11.76165631 15.87081071 11.15687161], val_grp_loss: [10.63486604 14.88511308 11.28360465], train_hist_grp_loss: [ 9.93717927 12.86016057 24.90974728], cur_train_grp_loss: [0.09485357 0.1230276  0.23738355], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6825, max_kl_dist_index: 2, max_train_grp_loss:  15.8708, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8851, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:04:59,334 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  104, train_loss:  13.4338, val_loss:  12.2627, grad_norm: 0.0048, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6530, 0.3481, 0.6825, param: [4.13846839 9.44783003 5.00532919 8.94190702], weights: [0.25279189 0.28446577 0.46274235], train_wt_loss:  40.3015, val_wt_loss: 36.7881, train_grp_loss: [11.76146129 15.87107153 11.15671241], val_grp_loss: [10.63461173 14.88562606 11.28358542], train_hist_grp_loss: [10.03203134 12.98319011 25.14712753], cur_train_grp_loss: [0.09485207 0.12302954 0.23738025], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6825, max_kl_dist_index: 2, max_train_grp_loss:  15.8711, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8856, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:05:00,388 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  105, train_loss:  13.4339, val_loss:  12.2628, grad_norm: 0.0048, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6530, 0.3481, 0.6826, param: [4.13814961 9.44751587 5.00564069 8.94319433], weights: [0.2520442  0.28394429 0.46401151], train_wt_loss:  40.3016, val_wt_loss: 36.7884, train_grp_loss: [11.76125732 15.87134249 11.15654941], val_grp_loss: [10.63434965 14.88615429 11.28356323], train_hist_grp_loss: [10.12688183 13.10622167 25.38450439], cur_train_grp_loss: [0.09485049 0.12303156 0.23737686], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6826, max_kl_dist_index: 2, max_train_grp_loss:  15.8713, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8862, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:05:01,399 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  106, train_loss:  13.4339, val_loss:  12.2629, grad_norm: 0.0048, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6531, 0.3481, 0.6827, param: [4.13782684 9.44720971 5.00594869 8.94449082], weights: [0.25129705 0.28342192 0.46528103], train_wt_loss:  40.3016, val_wt_loss: 36.7886, train_grp_loss: [11.7610444  15.8716236  11.15638261], val_grp_loss: [10.6340798  14.88669777 11.28353809], train_hist_grp_loss: [10.22173068 13.22925533 25.62187778], cur_train_grp_loss: [0.09484885 0.12303366 0.23737339], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6827, max_kl_dist_index: 2, max_train_grp_loss:  15.8716, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8867, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:05:02,423 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  107, train_loss:  13.4339, val_loss:  12.2630, grad_norm: 0.0049, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6532, 0.3482, 0.6827, param: [4.13750008 9.44691154 5.00625318 8.94579648], weights: [0.25055045 0.28289868 0.46655087], train_wt_loss:  40.3016, val_wt_loss: 36.7889, train_grp_loss: [11.76082253 15.87191486 11.15621203], val_grp_loss: [10.63380218 14.88725651 11.28351001], train_hist_grp_loss: [10.31657781 13.35229118 25.85924762], cur_train_grp_loss: [0.09484713 0.12303584 0.23736984], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6827, max_kl_dist_index: 2, max_train_grp_loss:  15.8719, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8873, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:05:03,434 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  108, train_loss:  13.4339, val_loss:  12.2630, grad_norm: 0.0049, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6532, 0.3482, 0.6828, param: [4.13716932 9.44662134 5.00655414 8.9471113 ], weights: [0.2498044  0.28237457 0.46782104], train_wt_loss:  40.3016, val_wt_loss: 36.7891, train_grp_loss: [11.76059171 15.87221626 11.15603765], val_grp_loss: [10.63351681 14.88783052 11.28347899], train_hist_grp_loss: [10.41142316 13.47532928 26.09661383], cur_train_grp_loss: [0.09484534 0.1230381  0.23736621], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6828, max_kl_dist_index: 2, max_train_grp_loss:  15.8722, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8878, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:05:04,444 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  109, train_loss:  13.4339, val_loss:  12.2631, grad_norm: 0.0049, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6533, 0.3483, 0.6829, param: [4.13683457 9.44633911 5.00685158 8.94843528], weights: [0.24905891 0.28184959 0.4690915 ], train_wt_loss:  40.3017, val_wt_loss: 36.7894, train_grp_loss: [11.76035195 15.87252782 11.1558595 ], val_grp_loss: [10.63322368 14.88841978 11.28344503], train_hist_grp_loss: [10.50626664 13.59836971 26.33397634], cur_train_grp_loss: [0.09484348 0.12304044 0.2373625 ], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6829, max_kl_dist_index: 2, max_train_grp_loss:  15.8725, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8884, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:05:05,470 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  110, train_loss:  13.4339, val_loss:  12.2632, grad_norm: 0.0050, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6533, 0.3483, 0.6830, param: [4.13649583 9.44606483 5.00714548 8.94976842], weights: [0.24831399 0.28132377 0.47036224], train_wt_loss:  40.3017, val_wt_loss: 36.7896, train_grp_loss: [11.76010325 15.87284953 11.15567756], val_grp_loss: [10.6329228  14.8890243  11.28340813], train_hist_grp_loss: [10.60110819 13.72141256 26.57133505], cur_train_grp_loss: [0.09484155 0.12304285 0.23735871], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6830, max_kl_dist_index: 2, max_train_grp_loss:  15.8728, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8890, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:05:06,484 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  111, train_loss:  13.4339, val_loss:  12.2633, grad_norm: 0.0050, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6534, 0.3483, 0.6830, param: [4.13615308 9.4457985  5.00743583 8.9511107 ], weights: [0.24756965 0.28079711 0.47163324], train_wt_loss:  40.3017, val_wt_loss: 36.7899, train_grp_loss: [11.75984562 15.87318138 11.15549184], val_grp_loss: [10.63261418 14.88964408 11.28336831], train_hist_grp_loss: [10.69594773 13.84445791 26.80868989], cur_train_grp_loss: [0.09483954 0.12304535 0.23735484], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6830, max_kl_dist_index: 2, max_train_grp_loss:  15.8732, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8896, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:05:07,526 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  112, train_loss:  13.4339, val_loss:  12.2634, grad_norm: 0.0050, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6535, 0.3484, 0.6831, param: [4.13580634 9.4455401  5.00772263 8.95246212], weights: [0.2468259  0.28026961 0.47290449], train_wt_loss:  40.3017, val_wt_loss: 36.7902, train_grp_loss: [11.75957905 15.87352339 11.15530236], val_grp_loss: [10.63229782 14.89027913 11.28332555], train_hist_grp_loss: [10.79078519 13.96750583 27.04604078], cur_train_grp_loss: [0.09483746 0.12304792 0.23735089], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6831, max_kl_dist_index: 2, max_train_grp_loss:  15.8735, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8903, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:05:08,555 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  113, train_loss:  13.4339, val_loss:  12.2635, grad_norm: 0.0051, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6535, 0.3484, 0.6832, param: [4.1354556  9.44528963 5.00800586 8.95382266], weights: [0.24608274 0.2797413  0.47417597], train_wt_loss:  40.3017, val_wt_loss: 36.7904, train_grp_loss: [11.75930356 15.87387556 11.1551091 ], val_grp_loss: [10.63197373 14.89092943 11.28327987], train_hist_grp_loss: [10.88562051 14.0905564  27.28338764], cur_train_grp_loss: [0.09483531 0.12305057 0.23734686], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6832, max_kl_dist_index: 2, max_train_grp_loss:  15.8739, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8909, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2373, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:05:09,604 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  114, train_loss:  13.4339, val_loss:  12.2636, grad_norm: 0.0051, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6536, 0.3485, 0.6833, param: [4.13510086 9.44504708 5.00828553 8.95519233], weights: [0.24534018 0.27921217 0.47544765], train_wt_loss:  40.3018, val_wt_loss: 36.7907, train_grp_loss: [11.75901914 15.87423787 11.15491208], val_grp_loss: [10.63164191 14.891595   11.28323127], train_hist_grp_loss: [10.9804536  14.21360969 27.52073039], cur_train_grp_loss: [0.09483309 0.1230533  0.23734275], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6833, max_kl_dist_index: 2, max_train_grp_loss:  15.8742, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8916, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2373, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:05:10,681 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  115, train_loss:  13.4339, val_loss:  12.2637, grad_norm: 0.0051, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6537, 0.3485, 0.6834, param: [4.13474212 9.44481242 5.00856161 8.95657111], weights: [0.24459822 0.27868224 0.47671953], train_wt_loss:  40.3018, val_wt_loss: 36.7910, train_grp_loss: [11.7587258  15.87461034 11.1547113 ], val_grp_loss: [10.63130237 14.89227583 11.28317975], train_hist_grp_loss: [11.0752844  14.3366658  27.75806894], cur_train_grp_loss: [0.0948308  0.12305611 0.23733855], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6834, max_kl_dist_index: 2, max_train_grp_loss:  15.8746, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8923, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2373, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:05:11,694 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  116, train_loss:  13.4339, val_loss:  12.2638, grad_norm: 0.0052, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6537, 0.3485, 0.6834, param: [4.13437938 9.44458566 5.00883411 8.95795899], weights: [0.24385689 0.27815152 0.47799159], train_wt_loss:  40.3018, val_wt_loss: 36.7913, train_grp_loss: [11.75842355 15.87499297 11.15450677], val_grp_loss: [10.63095511 14.89297192 11.28312532], train_hist_grp_loss: [11.17011283 14.4597248  27.99540323], cur_train_grp_loss: [0.09482843 0.12305899 0.23733428], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6834, max_kl_dist_index: 2, max_train_grp_loss:  15.8750, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8930, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2373, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:05:12,701 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  117, train_loss:  13.4339, val_loss:  12.2639, grad_norm: 0.0052, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6538, 0.3486, 0.6835, param: [4.13401263 9.44436678 5.009103   8.95935597], weights: [0.24311618 0.27762002 0.47926381], train_wt_loss:  40.3018, val_wt_loss: 36.7916, train_grp_loss: [11.75811239 15.87538574 11.15429849], val_grp_loss: [10.63060015 14.89368327 11.28306798], train_hist_grp_loss: [11.26493883 14.58278676 28.23273316], cur_train_grp_loss: [0.094826   0.12306196 0.23732993], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6835, max_kl_dist_index: 2, max_train_grp_loss:  15.8754, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8937, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2373, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:05:13,757 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  118, train_loss:  13.4340, val_loss:  12.2640, grad_norm: 0.0052, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6539, 0.3486, 0.6836, param: [4.13364188 9.44415577 5.0093683  8.96076203], weights: [0.2423761  0.27708774 0.48053616], train_wt_loss:  40.3019, val_wt_loss: 36.7919, train_grp_loss: [11.75779233 15.87578868 11.15408647], val_grp_loss: [10.63023749 14.89440987 11.28300774], train_hist_grp_loss: [11.35976232 14.70585176 28.47005866], cur_train_grp_loss: [0.09482349 0.12306501 0.2373255 ], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6836, max_kl_dist_index: 2, max_train_grp_loss:  15.8758, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8944, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2373, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:05:14,792 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  119, train_loss:  13.4340, val_loss:  12.2641, grad_norm: 0.0053, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6539, 0.3487, 0.6837, param: [4.13326713 9.44395261 5.00962998 8.96217717], weights: [0.24163665 0.2765547  0.48180864], train_wt_loss:  40.3019, val_wt_loss: 36.7922, train_grp_loss: [11.75746337 15.87620176 11.1538707 ], val_grp_loss: [10.62986714 14.89515174 11.2829446 ], train_hist_grp_loss: [11.45458322 14.82891989 28.70737965], cur_train_grp_loss: [0.09482091 0.12306813 0.23732099], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6837, max_kl_dist_index: 2, max_train_grp_loss:  15.8762, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8952, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2373, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:05:15,821 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  120, train_loss:  13.4340, val_loss:  12.2642, grad_norm: 0.0053, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6540, 0.3487, 0.6838, param: [4.13288837 9.4437573  5.00988804 8.96360137], weights: [0.24089786 0.27602091 0.48308123], train_wt_loss:  40.3019, val_wt_loss: 36.7925, train_grp_loss: [11.75712551 15.876625   11.1536512 ], val_grp_loss: [10.6294891  14.89590886 11.28287856], train_hist_grp_loss: [11.54940148 14.95199122 28.94469604], cur_train_grp_loss: [0.09481825 0.12307133 0.2373164 ], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6838, max_kl_dist_index: 2, max_train_grp_loss:  15.8766, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8959, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2373, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:05:16,852 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  121, train_loss:  13.4340, val_loss:  12.2643, grad_norm: 0.0053, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6541, 0.3488, 0.6839, param: [4.13250561 9.44356982 5.01014246 8.96503463], weights: [0.24015972 0.27548637 0.4843539 ], train_wt_loss:  40.3019, val_wt_loss: 36.7928, train_grp_loss: [11.75677877 15.87705839 11.15342798], val_grp_loss: [10.62910339 14.89668123 11.28280963], train_hist_grp_loss: [11.644217   15.07506584 29.18200777], cur_train_grp_loss: [0.09481553 0.12307461 0.23731173], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6839, max_kl_dist_index: 2, max_train_grp_loss:  15.8771, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8967, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2373, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:05:17,894 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  122, train_loss:  13.4340, val_loss:  12.2644, grad_norm: 0.0054, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6541, 0.3488, 0.6840, param: [4.13211884 9.44339016 5.01039325 8.96647694], weights: [0.23942225 0.2749511  0.48562665], train_wt_loss:  40.3019, val_wt_loss: 36.7931, train_grp_loss: [11.75642315 15.87750194 11.15320103], val_grp_loss: [10.62871    14.89746886 11.28273782], train_hist_grp_loss: [11.73902974 15.19814381 29.41931475], cur_train_grp_loss: [0.09481273 0.12307797 0.23730698], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6840, max_kl_dist_index: 2, max_train_grp_loss:  15.8775, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8975, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2373, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:05:18,902 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  123, train_loss:  13.4340, val_loss:  12.2645, grad_norm: 0.0054, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6542, 0.3489, 0.6840, param: [4.13172806 9.44321831 5.01064039 8.96792828], weights: [0.23868544 0.27441511 0.48689945], train_wt_loss:  40.3020, val_wt_loss: 36.7935, train_grp_loss: [11.75605866 15.87795563 11.15297036], val_grp_loss: [10.62830896 14.89827174 11.28266312], train_hist_grp_loss: [11.8338396  15.32122522 29.6566169 ], cur_train_grp_loss: [0.09480986 0.12308141 0.23730215], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6840, max_kl_dist_index: 2, max_train_grp_loss:  15.8780, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8983, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2373, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:05:19,974 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  124, train_loss:  13.4340, val_loss:  12.2646, grad_norm: 0.0054, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6543, 0.3489, 0.6841, param: [4.13133328 9.44305426 5.01088388 8.96938864], weights: [0.23794931 0.2738784  0.48817228], train_wt_loss:  40.3020, val_wt_loss: 36.7938, train_grp_loss: [11.7556853  15.87841948 11.15273598], val_grp_loss: [10.62790026 14.89908986 11.28258555], train_hist_grp_loss: [11.92864653 15.44431015 29.89391414], cur_train_grp_loss: [0.09480692 0.12308493 0.23729724], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6841, max_kl_dist_index: 2, max_train_grp_loss:  15.8784, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8991, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2373, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:05:20,992 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  125, train_loss:  13.4340, val_loss:  12.2647, grad_norm: 0.0055, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6544, 0.3490, 0.6842, param: [4.13093448 9.44289799 5.01112371 8.97085802], weights: [0.23721387 0.27334099 0.48944514], train_wt_loss:  40.3020, val_wt_loss: 36.7941, train_grp_loss: [11.75530308 15.87889348 11.1524979 ], val_grp_loss: [10.62748391 14.89992322 11.28250511], train_hist_grp_loss: [12.02345044 15.56739867 30.1312064 ], cur_train_grp_loss: [0.09480391 0.12308852 0.23729225], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6842, max_kl_dist_index: 2, max_train_grp_loss:  15.8789, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8999, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2373, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:05:22,017 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  126, train_loss:  13.4340, val_loss:  12.2648, grad_norm: 0.0055, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6544, 0.3490, 0.6843, param: [4.13053168 9.44274948 5.01135986 8.97233639], weights: [0.23647912 0.27280289 0.49071799], train_wt_loss:  40.3020, val_wt_loss: 36.7945, train_grp_loss: [11.75491201 15.87937762 11.15225612], val_grp_loss: [10.62705993 14.90077183 11.2824218 ], train_hist_grp_loss: [12.11825127 15.69049087 30.36849358], cur_train_grp_loss: [0.09480083 0.1230922  0.23728719], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6843, max_kl_dist_index: 2, max_train_grp_loss:  15.8794, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9008, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2373, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:05:23,052 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  127, train_loss:  13.4340, val_loss:  12.2649, grad_norm: 0.0055, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6545, 0.3490, 0.6844, param: [4.13012487 9.44260874 5.01159233 8.97382375], weights: [0.23574507 0.27226409 0.49199083], train_wt_loss:  40.3021, val_wt_loss: 36.7948, train_grp_loss: [11.75451209 15.87987191 11.15201064], val_grp_loss: [10.62662832 14.90163567 11.28233564], train_hist_grp_loss: [12.21304895 15.81358682 30.60577563], cur_train_grp_loss: [0.09479768 0.12309595 0.23728205], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6844, max_kl_dist_index: 2, max_train_grp_loss:  15.8799, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9016, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2373, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:05:24,108 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  128, train_loss:  13.4340, val_loss:  12.2651, grad_norm: 0.0056, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6546, 0.3491, 0.6845, param: [4.12971405 9.44247573 5.01182111 8.97532009], weights: [0.23501173 0.27172463 0.49326364], train_wt_loss:  40.3021, val_wt_loss: 36.7952, train_grp_loss: [11.75410334 15.88037634 11.15176148], val_grp_loss: [10.6261891  14.90251475 11.28224662], train_hist_grp_loss: [12.3078434  15.9366866  30.84305245], cur_train_grp_loss: [0.09479445 0.12309978 0.23727682], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6845, max_kl_dist_index: 2, max_train_grp_loss:  15.8804, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9025, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2373, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:05:25,135 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  129, train_loss:  13.4340, val_loss:  12.2652, grad_norm: 0.0056, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6547, 0.3491, 0.6846, param: [4.12929922 9.44235045 5.0120462  8.97682539], weights: [0.23427911 0.2711845  0.49453639], train_wt_loss:  40.3021, val_wt_loss: 36.7955, train_grp_loss: [11.75368575 15.88089092 11.15150864], val_grp_loss: [10.62574226 14.90340906 11.28215475], train_hist_grp_loss: [12.40263456 16.05979029 31.08032397], cur_train_grp_loss: [0.09479116 0.12310369 0.23727152], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6846, max_kl_dist_index: 2, max_train_grp_loss:  15.8809, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9034, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2373, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:05:26,200 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  130, train_loss:  13.4341, val_loss:  12.2653, grad_norm: 0.0056, live_grad: 0.0000, reward_err: 0.0035, 0.0310, 0.0013, KL_dist: 0.6547, 0.3492, 0.6847, param: [4.12888037 9.44223289 5.01226759 8.97833964], weights: [0.23354721 0.27064371 0.49580908], train_wt_loss:  40.3022, val_wt_loss: 36.7959, train_grp_loss: [11.75325935 15.88141564 11.15125212], val_grp_loss: [10.62528783 14.90431859 11.28206004], train_hist_grp_loss: [12.49742234 16.18289797 31.31759011], cur_train_grp_loss: [0.09478779 0.12310768 0.23726614], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6847, max_kl_dist_index: 2, max_train_grp_loss:  15.8814, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9043, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2373, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:05:27,228 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  131, train_loss:  13.4341, val_loss:  12.2654, grad_norm: 0.0057, live_grad: 0.0000, reward_err: 0.0035, 0.0310, 0.0013, KL_dist: 0.6548, 0.3493, 0.6848, param: [4.12845752 9.44212303 5.01248526 8.97986283], weights: [0.23281604 0.27010228 0.49708168], train_wt_loss:  40.3022, val_wt_loss: 36.7962, train_grp_loss: [11.75282413 15.8819505  11.15099194], val_grp_loss: [10.6248258  14.90524335 11.28196249], train_hist_grp_loss: [12.59220669 16.30600972 31.5548508 ], cur_train_grp_loss: [0.09478435 0.12311175 0.23726068], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6848, max_kl_dist_index: 2, max_train_grp_loss:  15.8820, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9052, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2373, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:05:28,261 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  132, train_loss:  13.4341, val_loss:  12.2655, grad_norm: 0.0057, live_grad: 0.0000, reward_err: 0.0035, 0.0310, 0.0013, KL_dist: 0.6549, 0.3493, 0.6849, param: [4.12803066 9.44202085 5.01269921 8.98139494], weights: [0.2320856  0.26956022 0.49835418], train_wt_loss:  40.3022, val_wt_loss: 36.7966, train_grp_loss: [11.75238011 15.8824955  11.1507281 ], val_grp_loss: [10.6243562  14.90618332 11.28186211], train_hist_grp_loss: [12.68698753 16.42912562 31.79210594], cur_train_grp_loss: [0.09478084 0.1231159  0.23725515], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6849, max_kl_dist_index: 2, max_train_grp_loss:  15.8825, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9062, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2373, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:05:29,262 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  133, train_loss:  13.4341, val_loss:  12.2657, grad_norm: 0.0057, live_grad: 0.0000, reward_err: 0.0035, 0.0310, 0.0013, KL_dist: 0.6550, 0.3494, 0.6850, param: [4.12759978 9.44192635 5.01290943 8.98293596], weights: [0.23135592 0.26901753 0.49962655], train_wt_loss:  40.3022, val_wt_loss: 36.7970, train_grp_loss: [11.75192729 15.88305064 11.1504606 ], val_grp_loss: [10.62387903 14.9071385  11.2817589 ], train_hist_grp_loss: [12.78176479 16.55224574 32.02935548], cur_train_grp_loss: [0.09477726 0.12312012 0.23724953], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6850, max_kl_dist_index: 2, max_train_grp_loss:  15.8831, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9071, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2372, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:05:30,316 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  134, train_loss:  13.4341, val_loss:  12.2658, grad_norm: 0.0058, live_grad: 0.0000, reward_err: 0.0035, 0.0310, 0.0013, KL_dist: 0.6550, 0.3494, 0.6851, param: [4.1271649  9.4418395  5.01311591 8.98448588], weights: [0.23062699 0.26847422 0.50089879], train_wt_loss:  40.3023, val_wt_loss: 36.7973, train_grp_loss: [11.75146569 15.8836159  11.15018946], val_grp_loss: [10.62339431 14.90810889 11.28165288], train_hist_grp_loss: [12.8765384  16.67537016 32.26659932], cur_train_grp_loss: [0.09477361 0.12312442 0.23724384], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6851, max_kl_dist_index: 2, max_train_grp_loss:  15.8836, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9081, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2372, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:05:31,330 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  135, train_loss:  13.4341, val_loss:  12.2659, grad_norm: 0.0058, live_grad: 0.0000, reward_err: 0.0035, 0.0314, 0.0013, KL_dist: 0.6551, 0.3495, 0.6852, param: [4.126726   9.4417603  5.01331865 8.98604468], weights: [0.22989882 0.26793031 0.50217087], train_wt_loss:  40.3023, val_wt_loss: 36.7977, train_grp_loss: [11.75099531 15.8841913  11.14991469], val_grp_loss: [10.62290203 14.90909448 11.28154405], train_hist_grp_loss: [12.97130828 16.79849897 32.50383739], cur_train_grp_loss: [0.09476988 0.12312881 0.23723807], max_reward_err:  0.0314, max_reward_err_index: 1, max_kl_dist:  0.6852, max_kl_dist_index: 2, max_train_grp_loss:  15.8842, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9091, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2372, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:05:32,353 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  136, train_loss:  13.4341, val_loss:  12.2660, grad_norm: 0.0058, live_grad: 0.0000, reward_err: 0.0035, 0.0314, 0.0013, KL_dist: 0.6552, 0.3495, 0.6853, param: [4.12628309 9.44168872 5.01351763 8.98761234], weights: [0.22917141 0.2673858  0.50344278], train_wt_loss:  40.3023, val_wt_loss: 36.7981, train_grp_loss: [11.75051617 15.88477682 11.14963628], val_grp_loss: [10.62240222 14.91009526 11.28143241], train_hist_grp_loss: [13.06607438 16.92163223 32.74106962], cur_train_grp_loss: [0.09476609 0.12313327 0.23723223], max_reward_err:  0.0314, max_reward_err_index: 1, max_kl_dist:  0.6853, max_kl_dist_index: 2, max_train_grp_loss:  15.8848, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9101, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2372, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:05:33,407 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  137, train_loss:  13.4341, val_loss:  12.2662, grad_norm: 0.0059, live_grad: 0.0000, reward_err: 0.0035, 0.0314, 0.0013, KL_dist: 0.6553, 0.3496, 0.6854, param: [4.12583617 9.44162476 5.01371285 8.98918886], weights: [0.22844479 0.26684071 0.5047145 ], train_wt_loss:  40.3024, val_wt_loss: 36.7985, train_grp_loss: [11.75002826 15.88537247 11.14935425], val_grp_loss: [10.62189488 14.91111124 11.28131797], train_hist_grp_loss: [13.1608366  17.04477004 32.97829593], cur_train_grp_loss: [0.09476223 0.1231378  0.2372263 ], max_reward_err:  0.0314, max_reward_err_index: 1, max_kl_dist:  0.6854, max_kl_dist_index: 2, max_train_grp_loss:  15.8854, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9111, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2372, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:05:34,436 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  138, train_loss:  13.4341, val_loss:  12.2663, grad_norm: 0.0059, live_grad: 0.0000, reward_err: 0.0035, 0.0314, 0.0013, KL_dist: 0.6554, 0.3496, 0.6855, param: [4.12538524 9.44156839 5.01390431 8.99077421], weights: [0.22771895 0.26629504 0.50598601], train_wt_loss:  40.3024, val_wt_loss: 36.7989, train_grp_loss: [11.74953161 15.88597824 11.1490686 ], val_grp_loss: [10.62138003 14.9121424  11.28120074], train_hist_grp_loss: [13.2555949  17.16791246 33.21551623], cur_train_grp_loss: [0.09475829 0.12314242 0.2372203 ], max_reward_err:  0.0314, max_reward_err_index: 1, max_kl_dist:  0.6855, max_kl_dist_index: 2, max_train_grp_loss:  15.8860, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9121, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2372, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:05:35,451 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  139, train_loss:  13.4341, val_loss:  12.2664, grad_norm: 0.0060, live_grad: 0.0000, reward_err: 0.0035, 0.0314, 0.0013, KL_dist: 0.6555, 0.3497, 0.6856, param: [4.12493029 9.4415196  5.01409198 8.99236838], weights: [0.22699389 0.26574881 0.5072573 ], train_wt_loss:  40.3024, val_wt_loss: 36.7993, train_grp_loss: [11.74902623 15.88659413 11.14877935], val_grp_loss: [10.62085768 14.91318873 11.28108072], train_hist_grp_loss: [13.35034918 17.29105958 33.45273045], cur_train_grp_loss: [0.09475429 0.12314712 0.23721423], max_reward_err:  0.0314, max_reward_err_index: 1, max_kl_dist:  0.6856, max_kl_dist_index: 2, max_train_grp_loss:  15.8866, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9132, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2372, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:05:36,466 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  140, train_loss:  13.4342, val_loss:  12.2666, grad_norm: 0.0060, live_grad: 0.0000, reward_err: 0.0035, 0.0314, 0.0013, KL_dist: 0.6555, 0.3497, 0.6857, param: [4.12447134 9.44147838 5.01427588 8.99397136], weights: [0.22626964 0.26520202 0.50852834], train_wt_loss:  40.3025, val_wt_loss: 36.7997, train_grp_loss: [11.74851212 15.88722014 11.1484865 ], val_grp_loss: [10.62032784 14.91425024 11.28095792], train_hist_grp_loss: [13.44509939 17.41421147 33.68993853], cur_train_grp_loss: [0.09475021 0.12315189 0.23720807], max_reward_err:  0.0314, max_reward_err_index: 1, max_kl_dist:  0.6857, max_kl_dist_index: 2, max_train_grp_loss:  15.8872, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9143, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2372, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:05:37,504 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  141, train_loss:  13.4342, val_loss:  12.2667, grad_norm: 0.0060, live_grad: 0.0000, reward_err: 0.0035, 0.0314, 0.0013, KL_dist: 0.6556, 0.3498, 0.6858, param: [4.12400837 9.44144471 5.01445597 8.99558313], weights: [0.22554619 0.26465468 0.50979913], train_wt_loss:  40.3025, val_wt_loss: 36.8001, train_grp_loss: [11.74798929 15.88785625 11.14819006], val_grp_loss: [10.61979052 14.91532691 11.28083236], train_hist_grp_loss: [13.53984546 17.53736822 33.92714037], cur_train_grp_loss: [0.09474607 0.12315675 0.23720184], max_reward_err:  0.0314, max_reward_err_index: 1, max_kl_dist:  0.6858, max_kl_dist_index: 2, max_train_grp_loss:  15.8879, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9153, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2372, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:05:38,544 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  142, train_loss:  13.4342, val_loss:  12.2668, grad_norm: 0.0061, live_grad: 0.0000, reward_err: 0.0035, 0.0314, 0.0013, KL_dist: 0.6557, 0.3499, 0.6859, param: [4.12354139 9.44141857 5.01463227 8.99720367], weights: [0.22482356 0.26410681 0.51106963], train_wt_loss:  40.3025, val_wt_loss: 36.8005, train_grp_loss: [11.74745776 15.88850248 11.14789003], val_grp_loss: [10.61924573 14.91641873 11.28070403], train_hist_grp_loss: [13.63458731 17.66052989 34.1643359 ], cur_train_grp_loss: [0.09474185 0.12316168 0.23719553], max_reward_err:  0.0314, max_reward_err_index: 1, max_kl_dist:  0.6859, max_kl_dist_index: 2, max_train_grp_loss:  15.8885, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9164, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2372, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:05:39,556 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  143, train_loss:  13.4342, val_loss:  12.2670, grad_norm: 0.0061, live_grad: 0.0000, reward_err: 0.0035, 0.0314, 0.0013, KL_dist: 0.6558, 0.3499, 0.6860, param: [4.1230704  9.44139995 5.01480476 8.99883296], weights: [0.22410174 0.26355841 0.51233984], train_wt_loss:  40.3026, val_wt_loss: 36.8009, train_grp_loss: [11.74691754 15.88915881 11.14758643], val_grp_loss: [10.61869349 14.9175257  11.28057294], train_hist_grp_loss: [13.72932487 17.78369658 34.40152505], cur_train_grp_loss: [0.09473756 0.12316669 0.23718915], max_reward_err:  0.0314, max_reward_err_index: 1, max_kl_dist:  0.6860, max_kl_dist_index: 2, max_train_grp_loss:  15.8892, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9175, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2372, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:05:40,609 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  144, train_loss:  13.4342, val_loss:  12.2671, grad_norm: 0.0061, live_grad: 0.0000, reward_err: 0.0035, 0.0314, 0.0013, KL_dist: 0.6559, 0.3500, 0.6862, param: [4.1225954  9.44138883 5.01497343 9.00047099], weights: [0.22338076 0.2630095  0.51360975], train_wt_loss:  40.3026, val_wt_loss: 36.8013, train_grp_loss: [11.74636863 15.88982524 11.14727927], val_grp_loss: [10.61813381 14.91864781 11.2804391 ], train_hist_grp_loss: [13.82405808 17.90686835 34.63870774], cur_train_grp_loss: [0.09473321 0.12317177 0.23718269], max_reward_err:  0.0314, max_reward_err_index: 1, max_kl_dist:  0.6862, max_kl_dist_index: 2, max_train_grp_loss:  15.8898, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9186, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2372, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:05:41,658 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  145, train_loss:  13.4342, val_loss:  12.2673, grad_norm: 0.0062, live_grad: 0.0000, reward_err: 0.0035, 0.0314, 0.0013, KL_dist: 0.6560, 0.3500, 0.6863, param: [4.12211639 9.44138519 5.01513827 9.00211775], weights: [0.2226606  0.26246008 0.51487932], train_wt_loss:  40.3026, val_wt_loss: 36.8018, train_grp_loss: [11.74581106 15.89050177 11.14696855], val_grp_loss: [10.6175667  14.91978506 11.28030252], train_hist_grp_loss: [13.91878686 18.03004529 34.87588389], cur_train_grp_loss: [0.09472878 0.12317694 0.23717615], max_reward_err:  0.0314, max_reward_err_index: 1, max_kl_dist:  0.6863, max_kl_dist_index: 2, max_train_grp_loss:  15.8905, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9198, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2372, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:05:42,692 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  146, train_loss:  13.4342, val_loss:  12.2674, grad_norm: 0.0062, live_grad: 0.0000, reward_err: 0.0035, 0.0314, 0.0013, KL_dist: 0.6560, 0.3501, 0.6864, param: [4.12163337 9.44138902 5.01529928 9.0037732 ], weights: [0.22194129 0.26191016 0.51614854], train_wt_loss:  40.3027, val_wt_loss: 36.8022, train_grp_loss: [11.74524483 15.89118839 11.14665428], val_grp_loss: [10.61699218 14.92093743 11.28016321], train_hist_grp_loss: [14.01351114 18.15322748 35.11305344], cur_train_grp_loss: [0.09472428 0.12318218 0.23716954], max_reward_err:  0.0314, max_reward_err_index: 1, max_kl_dist:  0.6864, max_kl_dist_index: 2, max_train_grp_loss:  15.8912, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9209, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2372, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:05:43,719 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  147, train_loss:  13.4342, val_loss:  12.2675, grad_norm: 0.0063, live_grad: 0.0000, reward_err: 0.0035, 0.0314, 0.0013, KL_dist: 0.6561, 0.3502, 0.6865, param: [4.12114634 9.4414003  5.01545645 9.00543734], weights: [0.22122283 0.26135976 0.5174174 ], train_wt_loss:  40.3027, val_wt_loss: 36.8026, train_grp_loss: [11.74466996 15.8918851  11.14633647], val_grp_loss: [10.61641025 14.92210491 11.28002117], train_hist_grp_loss: [14.10823086 18.27641498 35.35021629], cur_train_grp_loss: [0.09471972 0.12318751 0.23716286], max_reward_err:  0.0314, max_reward_err_index: 1, max_kl_dist:  0.6865, max_kl_dist_index: 2, max_train_grp_loss:  15.8919, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9221, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2372, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:05:44,758 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  148, train_loss:  13.4342, val_loss:  12.2677, grad_norm: 0.0063, live_grad: 0.0000, reward_err: 0.0035, 0.0314, 0.0013, KL_dist: 0.6562, 0.3502, 0.6866, param: [4.1206553  9.44141902 5.01560978 9.00711015], weights: [0.22050523 0.26080888 0.51868589], train_wt_loss:  40.3027, val_wt_loss: 36.8031, train_grp_loss: [11.74408645 15.89259189 11.14601513], val_grp_loss: [10.61582094 14.9232875  11.27987641], train_hist_grp_loss: [14.20294594 18.39960789 35.58737239], cur_train_grp_loss: [0.09471508 0.12319291 0.2371561 ], max_reward_err:  0.0314, max_reward_err_index: 1, max_kl_dist:  0.6866, max_kl_dist_index: 2, max_train_grp_loss:  15.8926, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9233, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2372, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:05:45,780 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  149, train_loss:  13.4343, val_loss:  12.2678, grad_norm: 0.0064, live_grad: 0.0000, reward_err: 0.0035, 0.0314, 0.0013, KL_dist: 0.6563, 0.3503, 0.6867, param: [4.12016025 9.44144515 5.01575925 9.00879161], weights: [0.21978849 0.26025754 0.51995397], train_wt_loss:  40.3028, val_wt_loss: 36.8035, train_grp_loss: [11.74349433 15.89330876 11.14569028], val_grp_loss: [10.61522426 14.92448519 11.27972894], train_hist_grp_loss: [14.29765631 18.52280628 35.82452165], cur_train_grp_loss: [0.09471037 0.12319839 0.23714926], max_reward_err:  0.0314, max_reward_err_index: 1, max_kl_dist:  0.6867, max_kl_dist_index: 2, max_train_grp_loss:  15.8933, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9245, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2371, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:05:46,803 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  150, train_loss:  13.4343, val_loss:  12.2680, grad_norm: 0.0064, live_grad: 0.0000, reward_err: 0.0035, 0.0314, 0.0013, KL_dist: 0.6564, 0.3504, 0.6868, param: [4.1196612  9.44147867 5.01590485 9.01048169], weights: [0.21907262 0.25970574 0.52122164], train_wt_loss:  40.3028, val_wt_loss: 36.8040, train_grp_loss: [11.74289359 15.8940357  11.14536191], val_grp_loss: [10.61462021 14.92569796 11.27957877], train_hist_grp_loss: [14.39236191 18.64601022 36.06166399], cur_train_grp_loss: [0.0947056  0.12320394 0.23714235], max_reward_err:  0.0314, max_reward_err_index: 1, max_kl_dist:  0.6868, max_kl_dist_index: 2, max_train_grp_loss:  15.8940, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9257, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2371, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:05:47,864 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  151, train_loss:  13.4343, val_loss:  12.2681, grad_norm: 0.0064, live_grad: 0.0000, reward_err: 0.0035, 0.0314, 0.0013, KL_dist: 0.6565, 0.3504, 0.6870, param: [4.11915813 9.44151958 5.01604658 9.01218039], weights: [0.21835763 0.25915349 0.52248888], train_wt_loss:  40.3029, val_wt_loss: 36.8044, train_grp_loss: [11.74228427 15.89477271 11.14503003], val_grp_loss: [10.61400882 14.92692581 11.27942591], train_hist_grp_loss: [14.48706266 18.7692198  36.29879935], cur_train_grp_loss: [0.09470075 0.12320958 0.23713536], max_reward_err:  0.0314, max_reward_err_index: 1, max_kl_dist:  0.6870, max_kl_dist_index: 2, max_train_grp_loss:  15.8948, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9269, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2371, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:05:48,906 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  152, train_loss:  13.4343, val_loss:  12.2683, grad_norm: 0.0065, live_grad: 0.0000, reward_err: 0.0035, 0.0314, 0.0013, KL_dist: 0.6566, 0.3505, 0.6871, param: [4.11865106 9.44156785 5.01618444 9.01388768], weights: [0.21764353 0.25860081 0.52375567], train_wt_loss:  40.3029, val_wt_loss: 36.8049, train_grp_loss: [11.74166636 15.89551979 11.14469467], val_grp_loss: [10.6133901  14.92816873 11.27927036], train_hist_grp_loss: [14.58175851 18.89243509 36.53592765], cur_train_grp_loss: [0.09469584 0.12321529 0.2371283 ], max_reward_err:  0.0314, max_reward_err_index: 1, max_kl_dist:  0.6871, max_kl_dist_index: 2, max_train_grp_loss:  15.8955, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9282, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2371, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:05:49,936 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  153, train_loss:  13.4343, val_loss:  12.2685, grad_norm: 0.0065, live_grad: 0.0000, reward_err: 0.0035, 0.0314, 0.0013, KL_dist: 0.6567, 0.3505, 0.6872, param: [4.11813999 9.44162346 5.0163184  9.01560353], weights: [0.21693031 0.2580477  0.52502199], train_wt_loss:  40.3029, val_wt_loss: 36.8054, train_grp_loss: [11.74103989 15.89627693 11.14435583], val_grp_loss: [10.61276407 14.92942671 11.27911213], train_hist_grp_loss: [14.67644936 19.01565618 36.77304882], cur_train_grp_loss: [0.09469086 0.12322108 0.23712116], max_reward_err:  0.0314, max_reward_err_index: 1, max_kl_dist:  0.6872, max_kl_dist_index: 2, max_train_grp_loss:  15.8963, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9294, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2371, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:05:50,971 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  154, train_loss:  13.4343, val_loss:  12.2686, grad_norm: 0.0066, live_grad: 0.0000, reward_err: 0.0035, 0.0314, 0.0013, KL_dist: 0.6568, 0.3506, 0.6873, param: [4.1176249  9.4416864  5.01644848 9.01732794], weights: [0.216218   0.25749417 0.52628783], train_wt_loss:  40.3030, val_wt_loss: 36.8058, train_grp_loss: [11.74040487 15.89704411 11.14401351], val_grp_loss: [10.61213073 14.93069974 11.27895123], train_hist_grp_loss: [14.77113517 19.13888313 37.01016277], cur_train_grp_loss: [0.09468581 0.12322695 0.23711395], max_reward_err:  0.0314, max_reward_err_index: 1, max_kl_dist:  0.6873, max_kl_dist_index: 2, max_train_grp_loss:  15.8970, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9307, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2371, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:05:51,997 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  155, train_loss:  13.4343, val_loss:  12.2688, grad_norm: 0.0066, live_grad: 0.0000, reward_err: 0.0034, 0.0314, 0.0014, KL_dist: 0.6569, 0.3507, 0.6874, param: [4.11710582 9.44175665 5.01657465 9.01906088], weights: [0.21550659 0.25694024 0.52755317], train_wt_loss:  40.3030, val_wt_loss: 36.8063, train_grp_loss: [11.73976131 15.89782135 11.14366773], val_grp_loss: [10.6114901  14.9319878  11.27878768], train_hist_grp_loss: [14.86581585 19.26211603 37.24726944], cur_train_grp_loss: [0.09468068 0.1232329  0.23710667], max_reward_err:  0.0314, max_reward_err_index: 1, max_kl_dist:  0.6874, max_kl_dist_index: 2, max_train_grp_loss:  15.8978, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9320, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2371, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:05:53,014 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  156, train_loss:  13.4344, val_loss:  12.2689, grad_norm: 0.0067, live_grad: 0.0000, reward_err: 0.0034, 0.0314, 0.0014, KL_dist: 0.6569, 0.3507, 0.6876, param: [4.11658273 9.44183418 5.01669691 9.02080233], weights: [0.2147961  0.25638591 0.52881799], train_wt_loss:  40.3031, val_wt_loss: 36.8068, train_grp_loss: [11.73910923 15.89860863 11.1433185 ], val_grp_loss: [10.61084221 14.93329089 11.27862147], train_hist_grp_loss: [14.96049135 19.38535496 37.48436875], cur_train_grp_loss: [0.09467549 0.12323893 0.23709931], max_reward_err:  0.0314, max_reward_err_index: 1, max_kl_dist:  0.6876, max_kl_dist_index: 2, max_train_grp_loss:  15.8986, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9333, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2371, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:05:54,013 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  157, train_loss:  13.4344, val_loss:  12.2691, grad_norm: 0.0067, live_grad: 0.0000, reward_err: 0.0034, 0.0314, 0.0014, KL_dist: 0.6570, 0.3508, 0.6877, param: [4.11605563 9.44191899 5.01681526 9.02255227], weights: [0.21408653 0.25583119 0.53008228], train_wt_loss:  40.3031, val_wt_loss: 36.8073, train_grp_loss: [11.73844863 15.89940594 11.14296582], val_grp_loss: [10.61018706 14.93460899 11.27845262], train_hist_grp_loss: [15.05516158 19.50859998 37.72146064], cur_train_grp_loss: [0.09467024 0.12324503 0.23709188], max_reward_err:  0.0314, max_reward_err_index: 1, max_kl_dist:  0.6877, max_kl_dist_index: 2, max_train_grp_loss:  15.8994, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9346, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2371, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:05:55,055 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  158, train_loss:  13.4344, val_loss:  12.2693, grad_norm: 0.0068, live_grad: 0.0000, reward_err: 0.0034, 0.0314, 0.0014, KL_dist: 0.6571, 0.3509, 0.6878, param: [4.11552454 9.44201104 5.01692968 9.02431067], weights: [0.21337789 0.2552761  0.53134602], train_wt_loss:  40.3031, val_wt_loss: 36.8078, train_grp_loss: [11.73777955 15.90021328 11.14260972], val_grp_loss: [10.60952467 14.93594209 11.27828114], train_hist_grp_loss: [15.14982649 19.63185119 37.95854502], cur_train_grp_loss: [0.09466491 0.12325121 0.23708438], max_reward_err:  0.0314, max_reward_err_index: 1, max_kl_dist:  0.6878, max_kl_dist_index: 2, max_train_grp_loss:  15.9002, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9359, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2371, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:05:56,086 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  159, train_loss:  13.4344, val_loss:  12.2694, grad_norm: 0.0068, live_grad: 0.0000, reward_err: 0.0034, 0.0314, 0.0014, KL_dist: 0.6572, 0.3510, 0.6879, param: [4.11498944 9.44211033 5.01704018 9.02607752], weights: [0.21267018 0.25472064 0.53260919], train_wt_loss:  40.3032, val_wt_loss: 36.8083, train_grp_loss: [11.73710198 15.90103065 11.14225019], val_grp_loss: [10.60885505 14.93729019 11.27810703], train_hist_grp_loss: [15.244486   19.75510866 38.19562182], cur_train_grp_loss: [0.09465951 0.12325747 0.2370768 ], max_reward_err:  0.0314, max_reward_err_index: 1, max_kl_dist:  0.6879, max_kl_dist_index: 2, max_train_grp_loss:  15.9010, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9373, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2371, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:05:57,117 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  160, train_loss:  13.4344, val_loss:  12.2696, grad_norm: 0.0069, live_grad: 0.0000, reward_err: 0.0034, 0.0314, 0.0014, KL_dist: 0.6573, 0.3510, 0.6880, param: [4.11445035 9.44221683 5.01714673 9.0278528 ], weights: [0.21196341 0.25416482 0.53387177], train_wt_loss:  40.3032, val_wt_loss: 36.8088, train_grp_loss: [11.73641596 15.90185803 11.14188725], val_grp_loss: [10.60817823 14.93865326 11.27793031], train_hist_grp_loss: [15.33914005 19.87837246 38.43269097], cur_train_grp_loss: [0.09465405 0.1232638  0.23706915], max_reward_err:  0.0314, max_reward_err_index: 1, max_kl_dist:  0.6880, max_kl_dist_index: 2, max_train_grp_loss:  15.9019, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9387, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2371, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:05:58,145 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  161, train_loss:  13.4344, val_loss:  12.2698, grad_norm: 0.0069, live_grad: 0.0000, reward_err: 0.0034, 0.0314, 0.0014, KL_dist: 0.6574, 0.3511, 0.6882, param: [4.11390726 9.44233052 5.01724934 9.02963648], weights: [0.21125759 0.25360865 0.53513376], train_wt_loss:  40.3033, val_wt_loss: 36.8093, train_grp_loss: [11.73572148 15.90269543 11.14152091], val_grp_loss: [10.60749422 14.9400313  11.27775099], train_hist_grp_loss: [15.43378857 20.00164268 38.6697524 ], cur_train_grp_loss: [0.09464852 0.12327022 0.23706143], max_reward_err:  0.0314, max_reward_err_index: 1, max_kl_dist:  0.6882, max_kl_dist_index: 2, max_train_grp_loss:  15.9027, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9400, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2371, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:05:59,166 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  162, train_loss:  13.4344, val_loss:  12.2699, grad_norm: 0.0070, live_grad: 0.0000, reward_err: 0.0034, 0.0314, 0.0014, KL_dist: 0.6575, 0.3512, 0.6883, param: [4.11336016 9.44245139 5.017348   9.03142853], weights: [0.21055272 0.25305215 0.53639513], train_wt_loss:  40.3033, val_wt_loss: 36.8098, train_grp_loss: [11.73501857 15.90354283 11.14115119], val_grp_loss: [10.60680303 14.94142429 11.27756906], train_hist_grp_loss: [15.52843148 20.12491939 38.90680604], cur_train_grp_loss: [0.09464292 0.12327671 0.23705364], max_reward_err:  0.0314, max_reward_err_index: 1, max_kl_dist:  0.6883, max_kl_dist_index: 2, max_train_grp_loss:  15.9035, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9414, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2371, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:06:00,223 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  163, train_loss:  13.4345, val_loss:  12.2701, grad_norm: 0.0070, live_grad: 0.0000, reward_err: 0.0034, 0.0314, 0.0014, KL_dist: 0.6576, 0.3512, 0.6884, param: [4.11280908 9.44257941 5.01744269 9.03322895], weights: [0.20984882 0.25249532 0.53765586], train_wt_loss:  40.3034, val_wt_loss: 36.8103, train_grp_loss: [11.73430725 15.90440022 11.14077809], val_grp_loss: [10.60610469 14.94283222 11.27738455], train_hist_grp_loss: [15.62306873 20.24820267 39.14385181], cur_train_grp_loss: [0.09463725 0.12328328 0.23704577], max_reward_err:  0.0314, max_reward_err_index: 1, max_kl_dist:  0.6884, max_kl_dist_index: 2, max_train_grp_loss:  15.9044, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9428, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2370, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:06:01,242 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  164, train_loss:  13.4345, val_loss:  12.2703, grad_norm: 0.0071, live_grad: 0.0000, reward_err: 0.0034, 0.0314, 0.0014, KL_dist: 0.6577, 0.3513, 0.6886, param: [4.11225399 9.44271457 5.01753342 9.03503769], weights: [0.20914589 0.25193817 0.53891594], train_wt_loss:  40.3034, val_wt_loss: 36.8108, train_grp_loss: [11.73358753 15.9052676  11.14040162], val_grp_loss: [10.6053992  14.94425508 11.27719747], train_hist_grp_loss: [15.71770024 20.37149259 39.38088964], cur_train_grp_loss: [0.09463151 0.12328992 0.23703783], max_reward_err:  0.0314, max_reward_err_index: 1, max_kl_dist:  0.6886, max_kl_dist_index: 2, max_train_grp_loss:  15.9053, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9443, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2370, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:06:02,266 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  165, train_loss:  13.4345, val_loss:  12.2705, grad_norm: 0.0072, live_grad: 0.0000, reward_err: 0.0034, 0.0314, 0.0014, KL_dist: 0.6578, 0.3514, 0.6887, param: [4.11169492 9.44285684 5.01762018 9.03685475], weights: [0.20844393 0.25138072 0.54017535], train_wt_loss:  40.3035, val_wt_loss: 36.8114, train_grp_loss: [11.73285942 15.90614497 11.14002179], val_grp_loss: [10.60468659 14.94569286 11.27700782], train_hist_grp_loss: [15.81232595 20.49478924 39.61791946], cur_train_grp_loss: [0.09462571 0.12329665 0.23702982], max_reward_err:  0.0314, max_reward_err_index: 1, max_kl_dist:  0.6887, max_kl_dist_index: 2, max_train_grp_loss:  15.9061, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9457, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2370, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:06:03,290 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  166, train_loss:  13.4345, val_loss:  12.2706, grad_norm: 0.0072, live_grad: 0.0000, reward_err: 0.0034, 0.0314, 0.0014, KL_dist: 0.6579, 0.3515, 0.6888, param: [4.11113185 9.4430062  5.01770295 9.0386801 ], weights: [0.20774295 0.25082297 0.54143408], train_wt_loss:  40.3035, val_wt_loss: 36.8119, train_grp_loss: [11.73212295 15.90703231 11.13963862], val_grp_loss: [10.60396688 14.94714553 11.27681561], train_hist_grp_loss: [15.90694578 20.61809269 39.8549412 ], cur_train_grp_loss: [0.09461983 0.12330345 0.23702174], max_reward_err:  0.0314, max_reward_err_index: 1, max_kl_dist:  0.6888, max_kl_dist_index: 2, max_train_grp_loss:  15.9070, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9471, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2370, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:06:04,330 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  167, train_loss:  13.4345, val_loss:  12.2708, grad_norm: 0.0073, live_grad: 0.0000, reward_err: 0.0034, 0.0314, 0.0014, KL_dist: 0.6580, 0.3515, 0.6890, param: [4.11056479 9.44316263 5.01778174 9.04051371], weights: [0.20704297 0.25026493 0.54269211], train_wt_loss:  40.3036, val_wt_loss: 36.8124, train_grp_loss: [11.73137813 15.90792962 11.13925212], val_grp_loss: [10.60324008 14.94861308 11.27662085], train_hist_grp_loss: [16.00155967 20.74140302 40.09195479], cur_train_grp_loss: [0.09461389 0.12331033 0.23701359], max_reward_err:  0.0314, max_reward_err_index: 1, max_kl_dist:  0.6890, max_kl_dist_index: 2, max_train_grp_loss:  15.9079, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9486, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2370, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:06:05,376 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  168, train_loss:  13.4345, val_loss:  12.2710, grad_norm: 0.0073, live_grad: 0.0000, reward_err: 0.0034, 0.0314, 0.0014, KL_dist: 0.6581, 0.3516, 0.6891, param: [4.10999374 9.44332612 5.01785653 9.04235555], weights: [0.20634397 0.24970661 0.54394942], train_wt_loss:  40.3036, val_wt_loss: 36.8130, train_grp_loss: [11.73062498 15.90883689 11.1388623 ], val_grp_loss: [10.6025062  14.95009551 11.27642355], train_hist_grp_loss: [16.09616756 20.8647203  40.32896015], cur_train_grp_loss: [0.09460789 0.12331728 0.23700536], max_reward_err:  0.0314, max_reward_err_index: 1, max_kl_dist:  0.6891, max_kl_dist_index: 2, max_train_grp_loss:  15.9088, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9501, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2370, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:06:06,409 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  169, train_loss:  13.4346, val_loss:  12.2712, grad_norm: 0.0074, live_grad: 0.0000, reward_err: 0.0034, 0.0314, 0.0014, KL_dist: 0.6582, 0.3517, 0.6892, param: [4.1094187  9.44349664 5.01792731 9.04420561], weights: [0.20564599 0.24914802 0.54520599], train_wt_loss:  40.3037, val_wt_loss: 36.8135, train_grp_loss: [11.72986351 15.90975412 11.13846917], val_grp_loss: [10.60176528 14.9515928  11.27622373], train_hist_grp_loss: [16.19076938 20.98804462 40.56595722], cur_train_grp_loss: [0.09460181 0.12332432 0.23699707], max_reward_err:  0.0314, max_reward_err_index: 1, max_kl_dist:  0.6892, max_kl_dist_index: 2, max_train_grp_loss:  15.9098, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9516, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2370, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:06:07,417 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  170, train_loss:  13.4346, val_loss:  12.2714, grad_norm: 0.0075, live_grad: 0.0000, reward_err: 0.0034, 0.0314, 0.0014, KL_dist: 0.6583, 0.3518, 0.6894, param: [4.10883968 9.44367417 5.01799409 9.04606386], weights: [0.20494901 0.24858918 0.54646182], train_wt_loss:  40.3037, val_wt_loss: 36.8141, train_grp_loss: [11.72909375 15.91068128 11.13807274], val_grp_loss: [10.60101732 14.95310492 11.2760214 ], train_hist_grp_loss: [16.28536505 21.11137604 40.80294593], cur_train_grp_loss: [0.09459567 0.12333143 0.23698871], max_reward_err:  0.0314, max_reward_err_index: 1, max_kl_dist:  0.6894, max_kl_dist_index: 2, max_train_grp_loss:  15.9107, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9531, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2370, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:06:08,435 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  171, train_loss:  13.4346, val_loss:  12.2715, grad_norm: 0.0075, live_grad: 0.0000, reward_err: 0.0034, 0.0314, 0.0014, KL_dist: 0.6584, 0.3518, 0.6895, param: [4.10825667 9.44385869 5.01805686 9.04793028], weights: [0.20425304 0.24803008 0.54771687], train_wt_loss:  40.3038, val_wt_loss: 36.8146, train_grp_loss: [11.72831571 15.91161839 11.13767303], val_grp_loss: [10.60026234 14.95463187 11.27581655], train_hist_grp_loss: [16.37995452 21.23471466 41.0399262 ], cur_train_grp_loss: [0.09458947 0.12333861 0.23698027], max_reward_err:  0.0314, max_reward_err_index: 1, max_kl_dist:  0.6895, max_kl_dist_index: 2, max_train_grp_loss:  15.9116, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9546, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2370, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:06:09,453 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  172, train_loss:  13.4346, val_loss:  12.2717, grad_norm: 0.0076, live_grad: 0.0000, reward_err: 0.0034, 0.0314, 0.0014, KL_dist: 0.6585, 0.3519, 0.6896, param: [4.10766967 9.44405018 5.0181156  9.04980483], weights: [0.2035581  0.24747075 0.54897115], train_wt_loss:  40.3039, val_wt_loss: 36.8152, train_grp_loss: [11.72752941 15.91256542 11.13727004], val_grp_loss: [10.59950037 14.95617364 11.27560922], train_hist_grp_loss: [16.47453771 21.35806054 41.27689797], cur_train_grp_loss: [0.09458319 0.12334588 0.23697177], max_reward_err:  0.0314, max_reward_err_index: 1, max_kl_dist:  0.6896, max_kl_dist_index: 2, max_train_grp_loss:  15.9126, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9562, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2370, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:06:10,514 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  173, train_loss:  13.4346, val_loss:  12.2719, grad_norm: 0.0077, live_grad: 0.0000, reward_err: 0.0034, 0.0314, 0.0014, KL_dist: 0.6586, 0.3520, 0.6898, param: [4.1070787  9.44424861 5.01817031 9.0516875 ], weights: [0.20286419 0.24691119 0.55022462], train_wt_loss:  40.3039, val_wt_loss: 36.8158, train_grp_loss: [11.72673486 15.91352237 11.1368638 ], val_grp_loss: [10.59873142 14.9577302  11.27539939], train_hist_grp_loss: [16.56911456 21.48141376 41.51386116], cur_train_grp_loss: [0.09457685 0.12335322 0.23696319], max_reward_err:  0.0314, max_reward_err_index: 1, max_kl_dist:  0.6898, max_kl_dist_index: 2, max_train_grp_loss:  15.9135, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9577, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2370, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:06:11,536 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  174, train_loss:  13.4347, val_loss:  12.2721, grad_norm: 0.0077, live_grad: 0.0000, reward_err: 0.0034, 0.0314, 0.0014, KL_dist: 0.6587, 0.3521, 0.6899, param: [4.10648375 9.44445397 5.01822099 9.05357826], weights: [0.20217131 0.24635141 0.55147728], train_wt_loss:  40.3040, val_wt_loss: 36.8164, train_grp_loss: [11.72593209 15.91448923 11.1364543 ], val_grp_loss: [10.5979555  14.95930153 11.27518709], train_hist_grp_loss: [16.663685   21.6047744  41.75081571], cur_train_grp_loss: [0.09457044 0.12336064 0.23695455], max_reward_err:  0.0314, max_reward_err_index: 1, max_kl_dist:  0.6899, max_kl_dist_index: 2, max_train_grp_loss:  15.9145, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9593, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2370, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:06:12,583 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  175, train_loss:  13.4347, val_loss:  12.2723, grad_norm: 0.0078, live_grad: 0.0000, reward_err: 0.0034, 0.0314, 0.0014, KL_dist: 0.6588, 0.3521, 0.6900, param: [4.10588482 9.44466624 5.01826762 9.05547707], weights: [0.20147948 0.24579141 0.55272911], train_wt_loss:  40.3040, val_wt_loss: 36.8169, train_grp_loss: [11.72512112 15.91546599 11.13604157], val_grp_loss: [10.59717265 14.96088763 11.27497233], train_hist_grp_loss: [16.75824897 21.72814253 41.98776154], cur_train_grp_loss: [0.09456397 0.12336813 0.23694584], max_reward_err:  0.0314, max_reward_err_index: 1, max_kl_dist:  0.6900, max_kl_dist_index: 2, max_train_grp_loss:  15.9155, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9609, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2369, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:06:13,625 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  176, train_loss:  13.4347, val_loss:  12.2725, grad_norm: 0.0079, live_grad: 0.0000, reward_err: 0.0034, 0.0314, 0.0014, KL_dist: 0.6589, 0.3522, 0.6902, param: [4.10528191 9.44488538 5.01831021 9.05738392], weights: [0.20078869 0.24523122 0.55398009], train_wt_loss:  40.3041, val_wt_loss: 36.8175, train_grp_loss: [11.72430196 15.91645265 11.13562562], val_grp_loss: [10.59638288 14.96248848 11.27475512], train_hist_grp_loss: [16.8528064  21.85151824 42.2246986 ], cur_train_grp_loss: [0.09455743 0.12337571 0.23693705], max_reward_err:  0.0314, max_reward_err_index: 1, max_kl_dist:  0.6902, max_kl_dist_index: 2, max_train_grp_loss:  15.9165, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9625, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2369, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:06:14,648 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  177, train_loss:  13.4347, val_loss:  12.2727, grad_norm: 0.0079, live_grad: 0.0000, reward_err: 0.0034, 0.0314, 0.0014, KL_dist: 0.6590, 0.3523, 0.6903, param: [4.10467503 9.44511139 5.01834874 9.05929878], weights: [0.20009896 0.24467084 0.5552302 ], train_wt_loss:  40.3042, val_wt_loss: 36.8181, train_grp_loss: [11.72347464 15.91744918 11.13520646], val_grp_loss: [10.59558621 14.96410405 11.27453546], train_hist_grp_loss: [16.94735722 21.97490159 42.4616268 ], cur_train_grp_loss: [0.09455082 0.12338335 0.2369282 ], max_reward_err:  0.0314, max_reward_err_index: 1, max_kl_dist:  0.6903, max_kl_dist_index: 2, max_train_grp_loss:  15.9174, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9641, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2369, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:06:15,662 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  178, train_loss:  13.4347, val_loss:  12.2729, grad_norm: 0.0080, live_grad: 0.0000, reward_err: 0.0034, 0.0314, 0.0014, KL_dist: 0.6591, 0.3524, 0.6905, param: [4.10406418 9.44534423 5.01838321 9.06122162], weights: [0.19941028 0.24411028 0.55647944], train_wt_loss:  40.3042, val_wt_loss: 36.8187, train_grp_loss: [11.72263916 15.9184556  11.13478409], val_grp_loss: [10.59478266 14.96573433 11.27431338], train_hist_grp_loss: [17.04190137 22.09829267 42.69854609], cur_train_grp_loss: [0.09454415 0.12339108 0.23691929], max_reward_err:  0.0314, max_reward_err_index: 1, max_kl_dist:  0.6905, max_kl_dist_index: 2, max_train_grp_loss:  15.9185, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9657, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2369, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:06:16,696 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  179, train_loss:  13.4348, val_loss:  12.2731, grad_norm: 0.0081, live_grad: 0.0000, reward_err: 0.0034, 0.0314, 0.0014, KL_dist: 0.6592, 0.3525, 0.6906, param: [4.10344935 9.44558389 5.01841361 9.06315242], weights: [0.19872268 0.24354955 0.55772778], train_wt_loss:  40.3043, val_wt_loss: 36.8193, train_grp_loss: [11.72179556 15.91947188 11.13435855], val_grp_loss: [10.59397224 14.96737931 11.27408887], train_hist_grp_loss: [17.13643878 22.22169155 42.93545639], cur_train_grp_loss: [0.09453741 0.12339888 0.2369103 ], max_reward_err:  0.0314, max_reward_err_index: 1, max_kl_dist:  0.6906, max_kl_dist_index: 2, max_train_grp_loss:  15.9195, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9674, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2369, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:06:17,709 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  180, train_loss:  13.4348, val_loss:  12.2733, grad_norm: 0.0082, live_grad: 0.0000, reward_err: 0.0034, 0.0314, 0.0014, KL_dist: 0.6594, 0.3525, 0.6908, param: [4.10283056 9.44583034 5.01843993 9.06509114], weights: [0.19803615 0.24298865 0.5589752 ], train_wt_loss:  40.3044, val_wt_loss: 36.8199, train_grp_loss: [11.72094385 15.92049801 11.13392983], val_grp_loss: [10.59315499 14.96903897 11.27386196], train_hist_grp_loss: [17.23096939 22.34509831 43.17235764], cur_train_grp_loss: [0.09453061 0.12340676 0.23690125], max_reward_err:  0.0314, max_reward_err_index: 1, max_kl_dist:  0.6908, max_kl_dist_index: 2, max_train_grp_loss:  15.9205, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9690, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2369, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:06:18,729 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  181, train_loss:  13.4348, val_loss:  12.2735, grad_norm: 0.0082, live_grad: 0.0000, reward_err: 0.0034, 0.0314, 0.0014, KL_dist: 0.6595, 0.3526, 0.6909, param: [4.10220781 9.44608357 5.01846218 9.06703776], weights: [0.1973507 0.2424276 0.5602217], train_wt_loss:  40.3044, val_wt_loss: 36.8205, train_grp_loss: [11.72008406 15.92153399 11.13349795], val_grp_loss: [10.59233091 14.97071329 11.27363265], train_hist_grp_loss: [17.32549313 22.46851302 43.40924976], cur_train_grp_loss: [0.09452374 0.12341471 0.23689212], max_reward_err:  0.0314, max_reward_err_index: 1, max_kl_dist:  0.6909, max_kl_dist_index: 2, max_train_grp_loss:  15.9215, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9707, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2369, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:06:19,738 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  182, train_loss:  13.4348, val_loss:  12.2737, grad_norm: 0.0083, live_grad: 0.0000, reward_err: 0.0034, 0.0314, 0.0014, KL_dist: 0.6596, 0.3527, 0.6910, param: [4.10158109 9.44634354 5.01848034 9.06899225], weights: [0.19666633 0.24186642 0.56146725], train_wt_loss:  40.3045, val_wt_loss: 36.8211, train_grp_loss: [11.7192162  15.92257981 11.13306293], val_grp_loss: [10.59150004 14.97240224 11.27340096], train_hist_grp_loss: [17.42000994 22.59193577 43.64613269], cur_train_grp_loss: [0.09451681 0.12342274 0.23688294], max_reward_err:  0.0314, max_reward_err_index: 1, max_kl_dist:  0.6910, max_kl_dist_index: 2, max_train_grp_loss:  15.9226, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9724, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2369, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:06:20,776 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  183, train_loss:  13.4349, val_loss:  12.2739, grad_norm: 0.0084, live_grad: 0.0000, reward_err: 0.0034, 0.0314, 0.0014, KL_dist: 0.6597, 0.3528, 0.6912, param: [4.10095041 9.44661023 5.0184944  9.07095458], weights: [0.19598306 0.2413051  0.56271185], train_wt_loss:  40.3046, val_wt_loss: 36.8218, train_grp_loss: [11.71834029 15.92363545 11.13262478], val_grp_loss: [10.59066238 14.97410582 11.27316689], train_hist_grp_loss: [17.51451975 22.71536662 43.88300637], cur_train_grp_loss: [0.09450981 0.12343085 0.23687368], max_reward_err:  0.0314, max_reward_err_index: 1, max_kl_dist:  0.6912, max_kl_dist_index: 2, max_train_grp_loss:  15.9236, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9741, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2369, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:06:21,802 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  184, train_loss:  13.4349, val_loss:  12.2741, grad_norm: 0.0085, live_grad: 0.0000, reward_err: 0.0034, 0.0314, 0.0014, KL_dist: 0.6598, 0.3529, 0.6913, param: [4.10031577 9.44688363 5.01850437 9.07292472], weights: [0.19530088 0.24074365 0.56395547], train_wt_loss:  40.3046, val_wt_loss: 36.8224, train_grp_loss: [11.71745635 15.92470091 11.1321835 ], val_grp_loss: [10.58981797 14.975824   11.27293046], train_hist_grp_loss: [17.60902249 22.83880565 44.11987073], cur_train_grp_loss: [0.09450274 0.12343903 0.23686436], max_reward_err:  0.0314, max_reward_err_index: 1, max_kl_dist:  0.6913, max_kl_dist_index: 2, max_train_grp_loss:  15.9247, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9758, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2369, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:06:22,852 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  185, train_loss:  13.4349, val_loss:  12.2743, grad_norm: 0.0086, live_grad: 0.0000, reward_err: 0.0034, 0.0314, 0.0014, KL_dist: 0.6599, 0.3530, 0.6915, param: [4.09967717 9.44716371 5.01851023 9.07490264], weights: [0.19461981 0.2401821  0.56519809], train_wt_loss:  40.3047, val_wt_loss: 36.8230, train_grp_loss: [11.71656441 15.92577617 11.13173912], val_grp_loss: [10.58896682 14.97755676 11.27269168], train_hist_grp_loss: [17.70351811 22.96225295 44.3567257 ], cur_train_grp_loss: [0.09449562 0.12344729 0.23685497], max_reward_err:  0.0314, max_reward_err_index: 1, max_kl_dist:  0.6915, max_kl_dist_index: 2, max_train_grp_loss:  15.9258, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9776, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2369, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:06:23,887 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  186, train_loss:  13.4349, val_loss:  12.2746, grad_norm: 0.0087, live_grad: 0.0000, reward_err: 0.0034, 0.0314, 0.0014, KL_dist: 0.6600, 0.3530, 0.6916, param: [4.09903462 9.44745044 5.01851198 9.07688832], weights: [0.19393985 0.23962043 0.56643971], train_wt_loss:  40.3048, val_wt_loss: 36.8237, train_grp_loss: [11.71566449 15.92686123 11.13129166], val_grp_loss: [10.58810896 14.97930409 11.27245056], train_hist_grp_loss: [17.79800653 23.08570857 44.59357121], cur_train_grp_loss: [0.09448842 0.12345563 0.23684551], max_reward_err:  0.0314, max_reward_err_index: 1, max_kl_dist:  0.6916, max_kl_dist_index: 2, max_train_grp_loss:  15.9269, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9793, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2368, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:06:24,928 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  187, train_loss:  13.4350, val_loss:  12.2748, grad_norm: 0.0088, live_grad: 0.0000, reward_err: 0.0034, 0.0314, 0.0014, KL_dist: 0.6601, 0.3531, 0.6918, param: [4.09838812 9.4477438  5.01850961 9.07888173], weights: [0.19326101 0.23905868 0.56768031], train_wt_loss:  40.3049, val_wt_loss: 36.8243, train_grp_loss: [11.71475661 15.92795607 11.13084111], val_grp_loss: [10.5872444  14.98106596 11.27220712], train_hist_grp_loss: [17.8924877  23.20917262 44.83040721], cur_train_grp_loss: [0.09448117 0.12346404 0.23683599], max_reward_err:  0.0314, max_reward_err_index: 1, max_kl_dist:  0.6918, max_kl_dist_index: 2, max_train_grp_loss:  15.9280, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9811, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2368, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:06:26,007 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  188, train_loss:  13.4350, val_loss:  12.2750, grad_norm: 0.0088, live_grad: 0.0000, reward_err: 0.0034, 0.0314, 0.0014, KL_dist: 0.6602, 0.3532, 0.6919, param: [4.09773767 9.44804378 5.01850312 9.08088283], weights: [0.19258329 0.23849684 0.56891987], train_wt_loss:  40.3049, val_wt_loss: 36.8250, train_grp_loss: [11.71384078 15.92906068 11.1303875 ], val_grp_loss: [10.58637317 14.98284236 11.27196136], train_hist_grp_loss: [17.98696154 23.33264514 45.06723361], cur_train_grp_loss: [0.09447384 0.12347253 0.23682641], max_reward_err:  0.0314, max_reward_err_index: 1, max_kl_dist:  0.6919, max_kl_dist_index: 2, max_train_grp_loss:  15.9291, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9828, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2368, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:06:27,029 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  189, train_loss:  13.4350, val_loss:  12.2752, grad_norm: 0.0089, live_grad: 0.0000, reward_err: 0.0034, 0.0314, 0.0014, KL_dist: 0.6603, 0.3533, 0.6921, param: [4.09708328 9.44835033 5.0184925  9.08289159], weights: [0.19190669 0.23793493 0.57015838], train_wt_loss:  40.3050, val_wt_loss: 36.8256, train_grp_loss: [11.71291704 15.93017506 11.12993084], val_grp_loss: [10.58549529 14.98463326 11.2717133 ], train_hist_grp_loss: [18.081428   23.45612623 45.30405037], cur_train_grp_loss: [0.09446646 0.12348109 0.23681676], max_reward_err:  0.0314, max_reward_err_index: 1, max_kl_dist:  0.6921, max_kl_dist_index: 2, max_train_grp_loss:  15.9302, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9846, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2368, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:06:28,060 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  190, train_loss:  13.4350, val_loss:  12.2754, grad_norm: 0.0090, live_grad: 0.0000, reward_err: 0.0034, 0.0314, 0.0014, KL_dist: 0.6604, 0.3534, 0.6922, param: [4.09642494 9.44866345 5.01847775 9.08490799], weights: [0.19123124 0.23737295 0.57139582], train_wt_loss:  40.3051, val_wt_loss: 36.8263, train_grp_loss: [11.7119854  15.93129918 11.12947114], val_grp_loss: [10.58461078 14.98643865 11.27146295], train_hist_grp_loss: [18.17588701 23.57961596 45.54085741], cur_train_grp_loss: [0.09445901 0.12348973 0.23680704], max_reward_err:  0.0314, max_reward_err_index: 1, max_kl_dist:  0.6922, max_kl_dist_index: 2, max_train_grp_loss:  15.9313, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9864, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2368, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:06:29,080 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  191, train_loss:  13.4351, val_loss:  12.2756, grad_norm: 0.0091, live_grad: 0.0000, reward_err: 0.0034, 0.0314, 0.0014, KL_dist: 0.6606, 0.3535, 0.6924, param: [4.09576266 9.44898311 5.01845886 9.086932  ], weights: [0.19055692 0.23681091 0.57263217], train_wt_loss:  40.3052, val_wt_loss: 36.8269, train_grp_loss: [11.71104588 15.93243305 11.12900843], val_grp_loss: [10.58371966 14.9882585  11.27121032], train_hist_grp_loss: [18.2703385  23.70311441 45.77765466], cur_train_grp_loss: [0.0944515  0.12349844 0.23679726], max_reward_err:  0.0314, max_reward_err_index: 1, max_kl_dist:  0.6924, max_kl_dist_index: 2, max_train_grp_loss:  15.9324, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9883, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2368, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:06:30,128 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  192, train_loss:  13.4351, val_loss:  12.2759, grad_norm: 0.0092, live_grad: 0.0000, reward_err: 0.0034, 0.0314, 0.0014, KL_dist: 0.6607, 0.3536, 0.6925, param: [4.09509644 9.44930928 5.01843582 9.08896357], weights: [0.18988375 0.23624882 0.57386743], train_wt_loss:  40.3053, val_wt_loss: 36.8276, train_grp_loss: [11.71009852 15.93357664 11.1285427 ], val_grp_loss: [10.58282197 14.99009279 11.27095543], train_hist_grp_loss: [18.36478242 23.82662164 46.01444208], cur_train_grp_loss: [0.09444392 0.12350723 0.23678741], max_reward_err:  0.0314, max_reward_err_index: 1, max_kl_dist:  0.6925, max_kl_dist_index: 2, max_train_grp_loss:  15.9336, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9901, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2368, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:06:31,160 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  193, train_loss:  13.4351, val_loss:  12.2761, grad_norm: 0.0093, live_grad: 0.0000, reward_err: 0.0034, 0.0314, 0.0014, KL_dist: 0.6608, 0.3537, 0.6927, param: [4.09442629 9.44964193 5.01840863 9.09100269], weights: [0.18921173 0.2356867  0.57510157], train_wt_loss:  40.3053, val_wt_loss: 36.8283, train_grp_loss: [11.70914332 15.93472995 11.12807399], val_grp_loss: [10.58191771 14.9919415  11.27069829], train_hist_grp_loss: [18.4592187  23.95013774 46.25121958], cur_train_grp_loss: [0.09443628 0.1235161  0.2367775 ], max_reward_err:  0.0314, max_reward_err_index: 1, max_kl_dist:  0.6927, max_kl_dist_index: 2, max_train_grp_loss:  15.9347, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9919, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2368, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:06:32,196 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  194, train_loss:  13.4351, val_loss:  12.2763, grad_norm: 0.0094, live_grad: 0.0000, reward_err: 0.0034, 0.0314, 0.0014, KL_dist: 0.6609, 0.3537, 0.6929, param: [4.0937522  9.44998106 5.01837729 9.09304932], weights: [0.18854086 0.23512455 0.57633458], train_wt_loss:  40.3054, val_wt_loss: 36.8290, train_grp_loss: [11.70818032 15.93589296 11.12760229], val_grp_loss: [10.58100691 14.99380461 11.2704389 ], train_hist_grp_loss: [18.55364727 24.07366277 46.48798711], cur_train_grp_loss: [0.09442858 0.12352504 0.23676753], max_reward_err:  0.0314, max_reward_err_index: 1, max_kl_dist:  0.6929, max_kl_dist_index: 2, max_train_grp_loss:  15.9359, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9938, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2368, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:06:33,246 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  195, train_loss:  13.4352, val_loss:  12.2766, grad_norm: 0.0095, live_grad: 0.0000, reward_err: 0.0034, 0.0314, 0.0014, KL_dist: 0.6610, 0.3538, 0.6930, param: [4.09307419 9.45032662 5.01834178 9.09510343], weights: [0.18787117 0.23456239 0.57756645], train_wt_loss:  40.3055, val_wt_loss: 36.8297, train_grp_loss: [11.70720954 15.93706567 11.12712763], val_grp_loss: [10.5800896  14.9956821  11.27017729], train_hist_grp_loss: [18.64806808 24.19719683 46.72474461], cur_train_grp_loss: [0.09442081 0.12353405 0.2367575 ], max_reward_err:  0.0314, max_reward_err_index: 1, max_kl_dist:  0.6930, max_kl_dist_index: 2, max_train_grp_loss:  15.9371, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9957, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2368, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:06:34,284 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  196, train_loss:  13.4352, val_loss:  12.2768, grad_norm: 0.0096, live_grad: 0.0000, reward_err: 0.0034, 0.0314, 0.0014, KL_dist: 0.6611, 0.3539, 0.6932, param: [4.09239225 9.4506786  5.0183021  9.09716498], weights: [0.18720264 0.23400021 0.57879716], train_wt_loss:  40.3056, val_wt_loss: 36.8304, train_grp_loss: [11.70623099 15.93824805 11.12665003], val_grp_loss: [10.5791658  14.99757394 11.26991346], train_hist_grp_loss: [18.74248106 24.32073997 46.96149201], cur_train_grp_loss: [0.09441298 0.12354314 0.2367474 ], max_reward_err:  0.0314, max_reward_err_index: 1, max_kl_dist:  0.6932, max_kl_dist_index: 2, max_train_grp_loss:  15.9382, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9976, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2367, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:06:35,315 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  197, train_loss:  13.4352, val_loss:  12.2770, grad_norm: 0.0097, live_grad: 0.0000, reward_err: 0.0034, 0.0314, 0.0014, KL_dist: 0.6613, 0.3540, 0.6933, param: [4.09170638 9.45103696 5.01825826 9.09923395], weights: [0.18653528 0.23343803 0.58002669], train_wt_loss:  40.3057, val_wt_loss: 36.8311, train_grp_loss: [11.70524471 15.93944011 11.12616949], val_grp_loss: [10.57823553 14.99948012 11.26964744], train_hist_grp_loss: [18.83688615 24.44429228 47.19822924], cur_train_grp_loss: [0.09440509 0.12355231 0.23673723], max_reward_err:  0.0314, max_reward_err_index: 1, max_kl_dist:  0.6933, max_kl_dist_index: 2, max_train_grp_loss:  15.9394, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9995, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2367, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:06:36,370 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  198, train_loss:  13.4353, val_loss:  12.2773, grad_norm: 0.0098, live_grad: 0.0000, reward_err: 0.0034, 0.0319, 0.0014, KL_dist: 0.6614, 0.3541, 0.6935, param: [4.0910166  9.4514017  5.01821023 9.10131029], weights: [0.18586911 0.23287586 0.58125503], train_wt_loss:  40.3058, val_wt_loss: 36.8318, train_grp_loss: [11.70425072 15.94064181 11.12568603], val_grp_loss: [10.57729881 15.0014006  11.26937922], train_hist_grp_loss: [18.93128328 24.56785384 47.43495625], cur_train_grp_loss: [0.09439713 0.12356155 0.23672701], max_reward_err:  0.0319, max_reward_err_index: 1, max_kl_dist:  0.6935, max_kl_dist_index: 2, max_train_grp_loss:  15.9406, max_train_grp_loss_index: 1, max_val_grp_loss:  15.0014, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2367, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:06:37,384 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  199, train_loss:  13.4353, val_loss:  12.2775, grad_norm: 0.0099, live_grad: 0.0000, reward_err: 0.0034, 0.0323, 0.0014, KL_dist: 0.6615, 0.3542, 0.6936, param: [4.0903229  9.45177277 5.01815802 9.10339399], weights: [0.18520412 0.23231371 0.58248217], train_wt_loss:  40.3059, val_wt_loss: 36.8325, train_grp_loss: [11.70324904 15.94185316 11.12519966], val_grp_loss: [10.57635567 15.00333537 11.26910882], train_hist_grp_loss: [19.0256724  24.6914247  47.67167298], cur_train_grp_loss: [0.09438912 0.12357087 0.23671672], max_reward_err:  0.0323, max_reward_err_index: 1, max_kl_dist:  0.6936, max_kl_dist_index: 2, max_train_grp_loss:  15.9419, max_train_grp_loss_index: 1, max_val_grp_loss:  15.0033, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2367, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:06:38,327 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1654] - INFO: Iteration:  199, train_loss:  13.4353, val_loss:  12.2775, grad_norm: 0.0099,  live_grad: 0.0000, reward_err: 0.0034, 0.0323, 0.0014, KL_dist: 0.6615, 0.3542, 0.6936, param: [4.0903229  9.45177277 5.01815802 9.10339399], weights: [0.18520412 0.23231371 0.58248217], train_wt_loss:  40.3059, val_wt_loss: 36.8325, train_grp_loss: [11.70324904 15.94185316 11.12519966], val_grp_loss: [10.57635567 15.00333537 11.26910882], train_hist_grp_loss: [19.0256724  24.6914247  47.67167298], cur_train_grp_loss: [0.09438912 0.12357087 0.23671672], max_reward_err:  0.0323, max_reward_err_index: 1, max_kl_dist:  0.6936, max_kl_dist_index: 2, max_train_grp_loss:  15.9419, max_train_grp_loss_index: 1, max_val_grp_loss:  15.0033, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2367, max_cur_train_grp_loss_index: 2, 
2024-10-07 01:06:38,559 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:388] - INFO: Policy parameter learned solely on the preference data rdpo: [4.0903229  9.45177277 5.01815802 9.10339399].
2024-10-07 01:06:38,911 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Uniform reward: 3.8269, 3.8269, 3.1987
2024-10-07 01:06:38,912 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Optimal reward: 3.8681, 7.1581, 3.3364
2024-10-07 01:06:38,912 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Policy reward: 3.8550, 6.9270, 3.3318
2024-10-07 01:06:38,913 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:402] - INFO: Reward Error: 0.0034, 0.0323, 0.0014
2024-10-07 01:06:39,619 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:417] - INFO: Optimal reward: 3.8681, 7.1581, 3.3364
Known param reward: [[3.8680634765625, 6.699916015625, 3.30809521484375], [3.46072314453125, 7.1581357421875, 3.12821826171875], [3.83464501953125, 7.0068994140625, 3.336449462890625]], Known param reward error: [[0.0, 0.06401383587376193, 0.00849832984501714], [0.10530859550248342, 0.0, 0.06241101610796404], [0.008639583407495802, 0.02112789329121925, 0.0]].
