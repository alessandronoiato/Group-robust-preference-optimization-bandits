2024-10-07 00:34:18,004 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log-hyperparam-search/2024_10_07_00_27_03/rdpo,0.1,0.1,0.01,2023
2024-10-07 00:34:18,006 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2023
2024-10-07 00:34:18,006 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-10-07 00:34:18,099 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.2729, l2 distance: 29.4548, acc: 0.92.
2024-10-07 00:34:18,099 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-10-07 00:34:18,101 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [ 6.99981245 12.85202501  8.22225193 12.39503134]
2024-10-07 00:34:18,318 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.8503, 7.1054, 3.3198
2024-10-07 00:34:18,551 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1314] - INFO: unique_group_ids: {0, 1, 2}
2024-10-07 00:34:19,795 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  0, train_loss:  12.6261, val_loss:  12.2164, grad_norm: 0.4066, live_grad: 0.0000, reward_err: 0.0095, 0.0189, 0.0009, KL_dist: 0.6768, 0.3238, 0.6776, param: [ 4.90032933  6.97936371  5.67464935 10.2328601 ], weights: [0.33307434 0.33311119 0.33381446], train_wt_loss:  37.8784, val_wt_loss: 36.6493, train_grp_loss: [11.44733448 13.75119335 13.00574747], val_grp_loss: [12.59542693 12.82706442 11.22499376], train_hist_grp_loss: [0.1342519  0.14531453 0.3562142 ], cur_train_grp_loss: [0.1342519  0.14531453 0.3562142 ], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6776, max_kl_dist_index: 2, max_train_grp_loss:  13.7512, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8271, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.3562, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:34:20,847 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  1, train_loss:  12.6261, val_loss:  12.2165, grad_norm: 0.0000, live_grad: 0.0000, reward_err: 0.0095, 0.0189, 0.0009, KL_dist: 0.6768, 0.3238, 0.6776, param: [ 4.90027985  6.97892337  5.67494367 10.23277076], weights: [0.33285818 0.33298656 0.33415526], train_wt_loss:  37.8784, val_wt_loss: 36.6494, train_grp_loss: [11.4476184  13.75086888 13.00578093], val_grp_loss: [12.59571091 12.82674775 11.22513342], train_hist_grp_loss: [0.22230832 0.26087078 0.61122885], cur_train_grp_loss: [0.08805642 0.11555625 0.25501466], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6776, max_kl_dist_index: 2, max_train_grp_loss:  13.7509, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8267, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:34:21,935 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  2, train_loss:  12.6261, val_loss:  12.2165, grad_norm: 0.0000, live_grad: 0.0000, reward_err: 0.0095, 0.0189, 0.0009, KL_dist: 0.6768, 0.3238, 0.6775, param: [ 4.90023002  6.97848336  5.67523787 10.23268255], weights: [0.33264199 0.33286179 0.33449622], train_wt_loss:  37.8784, val_wt_loss: 36.6495, train_grp_loss: [11.44790165 13.75054529 13.0058142 ], val_grp_loss: [12.59599428 12.82643212 11.22527279], train_hist_grp_loss: [0.31036692 0.3764243  0.86624417], cur_train_grp_loss: [0.0880586  0.11555352 0.25501531], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6775, max_kl_dist_index: 2, max_train_grp_loss:  13.7505, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8264, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:34:23,013 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  3, train_loss:  12.6261, val_loss:  12.2165, grad_norm: 0.0000, live_grad: 0.0000, reward_err: 0.0095, 0.0189, 0.0009, KL_dist: 0.6767, 0.3238, 0.6775, param: [ 4.90017981  6.97804366  5.67553193 10.23259544], weights: [0.33242576 0.33273689 0.33483735], train_wt_loss:  37.8784, val_wt_loss: 36.6496, train_grp_loss: [11.44818425 13.75022257 13.00584728], val_grp_loss: [12.59627704 12.82611754 11.22541189], train_hist_grp_loss: [0.3984277  0.4919751  1.12126013], cur_train_grp_loss: [0.08806078 0.1155508  0.25501596], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6775, max_kl_dist_index: 2, max_train_grp_loss:  13.7502, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8261, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:34:24,143 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  4, train_loss:  12.6261, val_loss:  12.2166, grad_norm: 0.0001, live_grad: 0.0000, reward_err: 0.0095, 0.0189, 0.0009, KL_dist: 0.6767, 0.3238, 0.6775, param: [ 4.90012923  6.97760428  5.67582587 10.23250946], weights: [0.33220951 0.33261184 0.33517865], train_wt_loss:  37.8784, val_wt_loss: 36.6497, train_grp_loss: [11.44846618 13.74990072 13.00588016], val_grp_loss: [12.59655921 12.82580401 11.2255507 ], train_hist_grp_loss: [0.48649066 0.60752319 1.37627674], cur_train_grp_loss: [0.08806296 0.11554809 0.25501661], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6775, max_kl_dist_index: 2, max_train_grp_loss:  13.7499, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8258, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:34:25,256 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  5, train_loss:  12.6261, val_loss:  12.2166, grad_norm: 0.0001, live_grad: 0.0000, reward_err: 0.0095, 0.0189, 0.0009, KL_dist: 0.6767, 0.3238, 0.6775, param: [ 4.90007829  6.97716522  5.67611969 10.23242459], weights: [0.33199323 0.33248665 0.33552013], train_wt_loss:  37.8784, val_wt_loss: 36.6498, train_grp_loss: [11.44874744 13.74957974 13.00591285], val_grp_loss: [12.59684077 12.82549152 11.22568922], train_hist_grp_loss: [0.57455578 0.72306857 1.631294  ], cur_train_grp_loss: [0.08806512 0.11554538 0.25501726], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6775, max_kl_dist_index: 2, max_train_grp_loss:  13.7496, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8255, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:34:26,339 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  6, train_loss:  12.6261, val_loss:  12.2167, grad_norm: 0.0001, live_grad: 0.0000, reward_err: 0.0095, 0.0189, 0.0009, KL_dist: 0.6767, 0.3238, 0.6775, param: [ 4.90002697  6.97672648  5.67641337 10.23234085], weights: [0.33177691 0.33236132 0.33586177], train_wt_loss:  37.8784, val_wt_loss: 36.6500, train_grp_loss: [11.44902804 13.74925963 13.00594535], val_grp_loss: [12.59712172 12.82518008 11.22582746], train_hist_grp_loss: [0.66262307 0.83861126 1.8863119 ], cur_train_grp_loss: [0.08806729 0.11554269 0.2550179 ], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6775, max_kl_dist_index: 2, max_train_grp_loss:  13.7493, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8252, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:34:27,383 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  7, train_loss:  12.6261, val_loss:  12.2167, grad_norm: 0.0001, live_grad: 0.0000, reward_err: 0.0095, 0.0189, 0.0009, KL_dist: 0.6767, 0.3238, 0.6774, param: [ 4.89997529  6.97628806  5.67670693 10.23225822], weights: [0.33156057 0.33223585 0.33620359], train_wt_loss:  37.8784, val_wt_loss: 36.6501, train_grp_loss: [11.44930798 13.7489404  13.00597765], val_grp_loss: [12.59740207 12.82486968 11.22596542], train_hist_grp_loss: [0.75069252 0.95415125 2.14133044], cur_train_grp_loss: [0.08806945 0.11554    0.25501854], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6774, max_kl_dist_index: 2, max_train_grp_loss:  13.7489, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8249, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:34:28,459 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  8, train_loss:  12.6261, val_loss:  12.2167, grad_norm: 0.0001, live_grad: 0.0000, reward_err: 0.0095, 0.0189, 0.0009, KL_dist: 0.6767, 0.3238, 0.6774, param: [ 4.89992324  6.97584995  5.67700036 10.23217671], weights: [0.3313442  0.33211024 0.33654557], train_wt_loss:  37.8784, val_wt_loss: 36.6502, train_grp_loss: [11.44958725 13.74862204 13.00600976], val_grp_loss: [12.59768181 12.82456033 11.2261031 ], train_hist_grp_loss: [0.83876412 1.06968857 2.39634961], cur_train_grp_loss: [0.0880716  0.11553731 0.25501917], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6774, max_kl_dist_index: 2, max_train_grp_loss:  13.7486, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8246, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:34:29,469 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  9, train_loss:  12.6261, val_loss:  12.2168, grad_norm: 0.0002, live_grad: 0.0000, reward_err: 0.0095, 0.0189, 0.0009, KL_dist: 0.6767, 0.3237, 0.6774, param: [ 4.89987082  6.97541217  5.67729366 10.23209633], weights: [0.33112779 0.33198449 0.33688772], train_wt_loss:  37.8784, val_wt_loss: 36.6503, train_grp_loss: [11.44986586 13.74830455 13.00604168], val_grp_loss: [12.59796095 12.82425203 11.22624049], train_hist_grp_loss: [0.92683787 1.18522321 2.65136941], cur_train_grp_loss: [0.08807375 0.11553464 0.2550198 ], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6774, max_kl_dist_index: 2, max_train_grp_loss:  13.7483, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8243, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:34:30,509 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  10, train_loss:  12.6261, val_loss:  12.2168, grad_norm: 0.0002, live_grad: 0.0000, reward_err: 0.0095, 0.0189, 0.0009, KL_dist: 0.6767, 0.3237, 0.6774, param: [ 4.89981803  6.9749747   5.67758684 10.23201706], weights: [0.33091136 0.3318586  0.33723004], train_wt_loss:  37.8784, val_wt_loss: 36.6504, train_grp_loss: [11.4501438  13.74798793 13.0060734 ], val_grp_loss: [12.59823948 12.82394477 11.22637759], train_hist_grp_loss: [1.01491376 1.30075518 2.90638983], cur_train_grp_loss: [0.08807589 0.11553197 0.25502043], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6774, max_kl_dist_index: 2, max_train_grp_loss:  13.7480, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8239, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:34:31,519 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  11, train_loss:  12.6261, val_loss:  12.2168, grad_norm: 0.0002, live_grad: 0.0000, reward_err: 0.0095, 0.0189, 0.0009, KL_dist: 0.6767, 0.3237, 0.6774, param: [ 4.89976487  6.97453755  5.67787988 10.23193893], weights: [0.3306949  0.33173257 0.33757253], train_wt_loss:  37.8784, val_wt_loss: 36.6505, train_grp_loss: [11.45042108 13.74767219 13.00610493], val_grp_loss: [12.5985174  12.82363857 11.22651441], train_hist_grp_loss: [1.10299179 1.41628449 3.16141088], cur_train_grp_loss: [0.08807803 0.11552931 0.25502105], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6774, max_kl_dist_index: 2, max_train_grp_loss:  13.7477, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8236, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:34:32,569 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  12, train_loss:  12.6261, val_loss:  12.2169, grad_norm: 0.0002, live_grad: 0.0000, reward_err: 0.0095, 0.0189, 0.0009, KL_dist: 0.6767, 0.3237, 0.6773, param: [ 4.89971135  6.97410072  5.6781728  10.23186191], weights: [0.33047841 0.3316064  0.33791519], train_wt_loss:  37.8784, val_wt_loss: 36.6506, train_grp_loss: [11.45069768 13.74735733 13.00613626], val_grp_loss: [12.59879472 12.82333341 11.22665095], train_hist_grp_loss: [1.19107195 1.53181115 3.41643254], cur_train_grp_loss: [0.08808016 0.11552666 0.25502167], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6773, max_kl_dist_index: 2, max_train_grp_loss:  13.7474, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8233, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:34:33,592 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  13, train_loss:  12.6261, val_loss:  12.2169, grad_norm: 0.0002, live_grad: 0.0000, reward_err: 0.0095, 0.0189, 0.0009, KL_dist: 0.6766, 0.3237, 0.6773, param: [ 4.89965745  6.97366421  5.67846559 10.23178602], weights: [0.33026189 0.33148009 0.33825801], train_wt_loss:  37.8784, val_wt_loss: 36.6507, train_grp_loss: [11.45097362 13.74704334 13.0061674 ], val_grp_loss: [12.59907142 12.82302931 11.2267872 ], train_hist_grp_loss: [1.27915424 1.64733516 3.67145482], cur_train_grp_loss: [0.08808229 0.11552401 0.25502228], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6773, max_kl_dist_index: 2, max_train_grp_loss:  13.7470, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8230, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:34:34,627 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  14, train_loss:  12.6261, val_loss:  12.2169, grad_norm: 0.0003, live_grad: 0.0000, reward_err: 0.0095, 0.0189, 0.0009, KL_dist: 0.6766, 0.3237, 0.6773, param: [ 4.89960318  6.97322801  5.67875825 10.23171126], weights: [0.33004534 0.33135365 0.33860101], train_wt_loss:  37.8784, val_wt_loss: 36.6508, train_grp_loss: [11.4512489  13.74673023 13.00619835], val_grp_loss: [12.59934752 12.82272626 11.22692316], train_hist_grp_loss: [1.36723865 1.76285653 3.92647771], cur_train_grp_loss: [0.08808441 0.11552137 0.25502289], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6773, max_kl_dist_index: 2, max_train_grp_loss:  13.7467, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8227, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:34:35,659 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  15, train_loss:  12.6261, val_loss:  12.2170, grad_norm: 0.0003, live_grad: 0.0000, reward_err: 0.0095, 0.0189, 0.0009, KL_dist: 0.6766, 0.3237, 0.6773, param: [ 4.89954854  6.97279214  5.67905078 10.23163763], weights: [0.32982877 0.33122706 0.33894417], train_wt_loss:  37.8784, val_wt_loss: 36.6509, train_grp_loss: [11.4515235  13.74641799 13.0062291 ], val_grp_loss: [12.59962301 12.82242425 11.22705883], train_hist_grp_loss: [1.45532518 1.87837527 4.18150121], cur_train_grp_loss: [0.08808653 0.11551874 0.2550235 ], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6773, max_kl_dist_index: 2, max_train_grp_loss:  13.7464, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8224, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:34:36,642 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  16, train_loss:  12.6261, val_loss:  12.2170, grad_norm: 0.0003, live_grad: 0.0000, reward_err: 0.0095, 0.0189, 0.0009, KL_dist: 0.6766, 0.3237, 0.6773, param: [ 4.89949353  6.97235658  5.67934319 10.23156512], weights: [0.32961216 0.33110034 0.33928749], train_wt_loss:  37.8784, val_wt_loss: 36.6510, train_grp_loss: [11.45179743 13.74610663 13.00625965], val_grp_loss: [12.59989789 12.8221233  11.22719422], train_hist_grp_loss: [1.54341382 1.99389139 4.43652531], cur_train_grp_loss: [0.08808864 0.11551612 0.2550241 ], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6773, max_kl_dist_index: 2, max_train_grp_loss:  13.7461, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8221, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:34:37,659 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  17, train_loss:  12.6261, val_loss:  12.2170, grad_norm: 0.0003, live_grad: 0.0000, reward_err: 0.0095, 0.0189, 0.0009, KL_dist: 0.6766, 0.3237, 0.6772, param: [ 4.89943814  6.97192134  5.67963546 10.23149375], weights: [0.32939553 0.33097348 0.33963099], train_wt_loss:  37.8784, val_wt_loss: 36.6511, train_grp_loss: [11.4520707  13.74579614 13.00629001], val_grp_loss: [12.60017216 12.8218234  11.22732933], train_hist_grp_loss: [1.63150457 2.10940489 4.69155001], cur_train_grp_loss: [0.08809075 0.1155135  0.2550247 ], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6772, max_kl_dist_index: 2, max_train_grp_loss:  13.7458, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8218, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:34:38,704 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  18, train_loss:  12.6261, val_loss:  12.2171, grad_norm: 0.0003, live_grad: 0.0000, reward_err: 0.0095, 0.0189, 0.0009, KL_dist: 0.6766, 0.3237, 0.6772, param: [ 4.89938239  6.97148642  5.67992761 10.2314235 ], weights: [0.32917887 0.33084648 0.33997465], train_wt_loss:  37.8784, val_wt_loss: 36.6512, train_grp_loss: [11.45234329 13.74548653 13.00632018], val_grp_loss: [12.60044582 12.82152456 11.22746414], train_hist_grp_loss: [1.71959743 2.22491578 4.9465753 ], cur_train_grp_loss: [0.08809285 0.11551089 0.25502529], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6772, max_kl_dist_index: 2, max_train_grp_loss:  13.7455, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8215, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:34:39,734 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  19, train_loss:  12.6261, val_loss:  12.2171, grad_norm: 0.0004, live_grad: 0.0000, reward_err: 0.0095, 0.0189, 0.0009, KL_dist: 0.6766, 0.3237, 0.6772, param: [ 4.89932627  6.97105181  5.68021963 10.23135439], weights: [0.32896218 0.33071934 0.34031848], train_wt_loss:  37.8784, val_wt_loss: 36.6514, train_grp_loss: [11.45261522 13.7451778  13.00635015], val_grp_loss: [12.60071887 12.82122677 11.22759867], train_hist_grp_loss: [1.80769237 2.34042407 5.20160119], cur_train_grp_loss: [0.08809495 0.11550829 0.25502589], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6772, max_kl_dist_index: 2, max_train_grp_loss:  13.7452, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8212, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:34:40,770 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  20, train_loss:  12.6261, val_loss:  12.2172, grad_norm: 0.0004, live_grad: 0.0000, reward_err: 0.0095, 0.0189, 0.0009, KL_dist: 0.6766, 0.3237, 0.6772, param: [ 4.89926977  6.97061753  5.68051152 10.2312864 ], weights: [0.32874546 0.33059207 0.34066247], train_wt_loss:  37.8784, val_wt_loss: 36.6515, train_grp_loss: [11.45288647 13.74486995 13.00637992], val_grp_loss: [12.6009913  12.82093003 11.22773291], train_hist_grp_loss: [1.89578941 2.45592977 5.45662766], cur_train_grp_loss: [0.08809704 0.1155057  0.25502647], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6772, max_kl_dist_index: 2, max_train_grp_loss:  13.7449, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8209, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:34:41,789 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  21, train_loss:  12.6261, val_loss:  12.2172, grad_norm: 0.0004, live_grad: 0.0000, reward_err: 0.0095, 0.0189, 0.0009, KL_dist: 0.6766, 0.3237, 0.6772, param: [ 4.8992129   6.97018356  5.68080328 10.23121955], weights: [0.32852872 0.33046465 0.34100663], train_wt_loss:  37.8784, val_wt_loss: 36.6516, train_grp_loss: [11.45315705 13.74456298 13.0064095 ], val_grp_loss: [12.60126313 12.82063435 11.22786686], train_hist_grp_loss: [1.98388854 2.57143288 5.71165472], cur_train_grp_loss: [0.08809913 0.11550311 0.25502706], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6772, max_kl_dist_index: 2, max_train_grp_loss:  13.7446, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8206, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:34:42,822 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  22, train_loss:  12.6261, val_loss:  12.2172, grad_norm: 0.0004, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6766, 0.3237, 0.6772, param: [ 4.89915566  6.96974991  5.68109491 10.23115384], weights: [0.32831195 0.3303371  0.34135095], train_wt_loss:  37.8784, val_wt_loss: 36.6517, train_grp_loss: [11.45342696 13.74425689 13.00643888], val_grp_loss: [12.60153434 12.82033972 11.22800052], train_hist_grp_loss: [2.07198975 2.68693341 5.96668236], cur_train_grp_loss: [0.08810121 0.11550053 0.25502764], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6772, max_kl_dist_index: 2, max_train_grp_loss:  13.7443, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8203, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:34:43,828 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  23, train_loss:  12.6261, val_loss:  12.2173, grad_norm: 0.0005, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6766, 0.3237, 0.6771, param: [ 4.89909805  6.96931658  5.68138641 10.23108926], weights: [0.32809515 0.33020941 0.34169544], train_wt_loss:  37.8784, val_wt_loss: 36.6518, train_grp_loss: [11.45369619 13.74395167 13.00646806], val_grp_loss: [12.60180493 12.82004615 11.2281339 ], train_hist_grp_loss: [2.16009303 2.80243136 6.22171057], cur_train_grp_loss: [0.08810328 0.11549796 0.25502821], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6771, max_kl_dist_index: 2, max_train_grp_loss:  13.7440, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8200, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:34:44,852 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  24, train_loss:  12.6261, val_loss:  12.2173, grad_norm: 0.0005, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6765, 0.3237, 0.6771, param: [ 4.89904007  6.96888356  5.68167779 10.23102581], weights: [0.32787832 0.33008158 0.3420401 ], train_wt_loss:  37.8784, val_wt_loss: 36.6519, train_grp_loss: [11.45396476 13.74364734 13.00649705], val_grp_loss: [12.60207492 12.81975364 11.22826698], train_hist_grp_loss: [2.24819839 2.91792676 6.47673936], cur_train_grp_loss: [0.08810536 0.11549539 0.25502879], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6771, max_kl_dist_index: 2, max_train_grp_loss:  13.7436, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8198, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:34:45,865 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  25, train_loss:  12.6261, val_loss:  12.2173, grad_norm: 0.0005, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6765, 0.3237, 0.6771, param: [ 4.89898171  6.96845087  5.68196903 10.23096351], weights: [0.32766147 0.32995362 0.34238492], train_wt_loss:  37.8784, val_wt_loss: 36.6520, train_grp_loss: [11.45423265 13.74334389 13.00652584], val_grp_loss: [12.60234429 12.81946218 11.22839978], train_hist_grp_loss: [2.33630581 3.03341959 6.73176871], cur_train_grp_loss: [0.08810742 0.11549283 0.25502935], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6771, max_kl_dist_index: 2, max_train_grp_loss:  13.7433, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8195, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:34:46,870 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  26, train_loss:  12.6261, val_loss:  12.2174, grad_norm: 0.0005, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6765, 0.3237, 0.6771, param: [ 4.89892298  6.96801849  5.68226014 10.23090234], weights: [0.32744458 0.32982552 0.3427299 ], train_wt_loss:  37.8784, val_wt_loss: 36.6521, train_grp_loss: [11.45449986 13.74304131 13.00655444], val_grp_loss: [12.60261304 12.81917179 11.22853228], train_hist_grp_loss: [2.42441529 3.14890987 6.98679863], cur_train_grp_loss: [0.08810948 0.11549028 0.25502992], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6771, max_kl_dist_index: 2, max_train_grp_loss:  13.7430, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8192, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:34:47,912 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  27, train_loss:  12.6261, val_loss:  12.2174, grad_norm: 0.0005, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6765, 0.3237, 0.6771, param: [ 4.89886388  6.96758643  5.68255113 10.2308423 ], weights: [0.32722768 0.32969728 0.34307504], train_wt_loss:  37.8784, val_wt_loss: 36.6522, train_grp_loss: [11.4547664  13.74273962 13.00658283], val_grp_loss: [12.60288118 12.81888245 11.2286645 ], train_hist_grp_loss: [2.51252683 3.26439762 7.24182911], cur_train_grp_loss: [0.08811154 0.11548774 0.25503048], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6771, max_kl_dist_index: 2, max_train_grp_loss:  13.7427, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8189, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:34:48,959 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  28, train_loss:  12.6261, val_loss:  12.2174, grad_norm: 0.0006, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6765, 0.3236, 0.6770, param: [ 4.8988044   6.96715468  5.68284199 10.23078341], weights: [0.32701074 0.3295689  0.34342035], train_wt_loss:  37.8784, val_wt_loss: 36.6523, train_grp_loss: [11.45503226 13.74243881 13.00661103], val_grp_loss: [12.60314871 12.81859417 11.22879643], train_hist_grp_loss: [2.60064042 3.37988282 7.49686014], cur_train_grp_loss: [0.08811359 0.11548521 0.25503104], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6770, max_kl_dist_index: 2, max_train_grp_loss:  13.7424, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8186, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:34:50,003 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  29, train_loss:  12.6261, val_loss:  12.2175, grad_norm: 0.0006, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6765, 0.3236, 0.6770, param: [ 4.89874455  6.96672326  5.68313271 10.23072566], weights: [0.32679378 0.32944039 0.34376583], train_wt_loss:  37.8784, val_wt_loss: 36.6525, train_grp_loss: [11.45529745 13.74213889 13.00663904], val_grp_loss: [12.60341561 12.81830695 11.22892806], train_hist_grp_loss: [2.68875605 3.4953655  7.75189173], cur_train_grp_loss: [0.08811563 0.11548268 0.25503159], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6770, max_kl_dist_index: 2, max_train_grp_loss:  13.7421, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8183, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:34:51,033 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  30, train_loss:  12.6261, val_loss:  12.2175, grad_norm: 0.0006, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6765, 0.3236, 0.6770, param: [ 4.89868433  6.96629215  5.68342331 10.23066905], weights: [0.32657679 0.32931174 0.34411146], train_wt_loss:  37.8784, val_wt_loss: 36.6526, train_grp_loss: [11.45556196 13.74183984 13.00666684], val_grp_loss: [12.60368191 12.81802079 11.22905941], train_hist_grp_loss: [2.77687372 3.61084566 8.00692387], cur_train_grp_loss: [0.08811767 0.11548016 0.25503214], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6770, max_kl_dist_index: 2, max_train_grp_loss:  13.7418, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8180, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:34:52,066 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  31, train_loss:  12.6261, val_loss:  12.2176, grad_norm: 0.0006, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6765, 0.3236, 0.6770, param: [ 4.89862373  6.96586136  5.68371378 10.23061358], weights: [0.32635978 0.32918296 0.34445726], train_wt_loss:  37.8784, val_wt_loss: 36.6527, train_grp_loss: [11.4558258  13.74154168 13.00669444], val_grp_loss: [12.60394758 12.81773569 11.22919046], train_hist_grp_loss: [2.86499343 3.72632331 8.26195655], cur_train_grp_loss: [0.08811971 0.11547765 0.25503268], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6770, max_kl_dist_index: 2, max_train_grp_loss:  13.7415, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8177, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:34:53,108 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  32, train_loss:  12.6261, val_loss:  12.2176, grad_norm: 0.0006, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6765, 0.3236, 0.6770, param: [ 4.89856276  6.96543089  5.68400411 10.23055926], weights: [0.32614274 0.32905403 0.34480322], train_wt_loss:  37.8784, val_wt_loss: 36.6528, train_grp_loss: [11.45608895 13.7412444  13.00672185], val_grp_loss: [12.60421264 12.81745165 11.22932122], train_hist_grp_loss: [2.95311517 3.84179845 8.51698978], cur_train_grp_loss: [0.08812174 0.11547514 0.25503322], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6770, max_kl_dist_index: 2, max_train_grp_loss:  13.7412, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8175, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:34:54,168 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  33, train_loss:  12.6261, val_loss:  12.2176, grad_norm: 0.0007, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6765, 0.3236, 0.6770, param: [ 4.89850141  6.96500074  5.68429432 10.23050608], weights: [0.32592568 0.32892498 0.34514935], train_wt_loss:  37.8784, val_wt_loss: 36.6529, train_grp_loss: [11.45635143 13.74094801 13.00674906], val_grp_loss: [12.60447707 12.81716868 11.22945169], train_hist_grp_loss: [3.04123893 3.95727109 8.77202354], cur_train_grp_loss: [0.08812376 0.11547264 0.25503376], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6770, max_kl_dist_index: 2, max_train_grp_loss:  13.7409, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8172, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:34:55,203 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  34, train_loss:  12.6261, val_loss:  12.2177, grad_norm: 0.0007, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6765, 0.3236, 0.6769, param: [ 4.89843969  6.9645709   5.6845844  10.23045404], weights: [0.32570859 0.32879578 0.34549563], train_wt_loss:  37.8784, val_wt_loss: 36.6530, train_grp_loss: [11.45661323 13.7406525  13.00677607], val_grp_loss: [12.60474089 12.81688677 11.22958187], train_hist_grp_loss: [3.12936471 4.07274124 9.02705783], cur_train_grp_loss: [0.08812578 0.11547015 0.2550343 ], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6769, max_kl_dist_index: 2, max_train_grp_loss:  13.7407, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8169, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:34:56,237 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  35, train_loss:  12.6261, val_loss:  12.2177, grad_norm: 0.0007, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6765, 0.3236, 0.6769, param: [ 4.89837759  6.96414138  5.68487435 10.23040316], weights: [0.32549147 0.32866645 0.34584208], train_wt_loss:  37.8784, val_wt_loss: 36.6531, train_grp_loss: [11.45687436 13.74035788 13.00680288], val_grp_loss: [12.60500409 12.81660592 11.22971175], train_hist_grp_loss: [3.2174925  4.18820891 9.28209266], cur_train_grp_loss: [0.08812779 0.11546767 0.25503482], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6769, max_kl_dist_index: 2, max_train_grp_loss:  13.7404, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8166, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:34:57,260 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  36, train_loss:  12.6261, val_loss:  12.2177, grad_norm: 0.0007, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6764, 0.3236, 0.6769, param: [ 4.89831512  6.96371218  5.68516416 10.23035341], weights: [0.32527433 0.32853699 0.34618869], train_wt_loss:  37.8784, val_wt_loss: 36.6532, train_grp_loss: [11.4571348  13.74006414 13.00682949], val_grp_loss: [12.60526668 12.81632614 11.22984135], train_hist_grp_loss: [3.3056223  4.3036741  9.53712801], cur_train_grp_loss: [0.0881298  0.11546519 0.25503535], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6769, max_kl_dist_index: 2, max_train_grp_loss:  13.7401, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8163, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:34:58,309 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  37, train_loss:  12.6261, val_loss:  12.2178, grad_norm: 0.0007, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6764, 0.3236, 0.6769, param: [ 4.89825227  6.96328329  5.68545385 10.23030482], weights: [0.32505716 0.32840739 0.34653546], train_wt_loss:  37.8784, val_wt_loss: 36.6533, train_grp_loss: [11.45739456 13.73977129 13.00685591], val_grp_loss: [12.60552864 12.81604742 11.22997065], train_hist_grp_loss: [3.39375411 4.41913683 9.79216388], cur_train_grp_loss: [0.08813181 0.11546272 0.25503587], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6769, max_kl_dist_index: 2, max_train_grp_loss:  13.7398, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8160, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:34:59,337 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  38, train_loss:  12.6261, val_loss:  12.2178, grad_norm: 0.0008, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6764, 0.3236, 0.6769, param: [ 4.89818905  6.96285472  5.68574341 10.23025738], weights: [0.32483997 0.32827765 0.34688238], train_wt_loss:  37.8784, val_wt_loss: 36.6535, train_grp_loss: [11.45765364 13.73947932 13.00688212], val_grp_loss: [12.60578998 12.81576976 11.23009965], train_hist_grp_loss: [ 3.48188792  4.53459709 10.04720027], cur_train_grp_loss: [0.0881338  0.11546026 0.25503639], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6769, max_kl_dist_index: 2, max_train_grp_loss:  13.7395, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8158, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:35:00,341 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  39, train_loss:  12.6261, val_loss:  12.2179, grad_norm: 0.0008, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6764, 0.3236, 0.6768, param: [ 4.89812545  6.96242647  5.68603283 10.23021108], weights: [0.32462275 0.32814778 0.34722947], train_wt_loss:  37.8784, val_wt_loss: 36.6536, train_grp_loss: [11.45791204 13.73918824 13.00690813], val_grp_loss: [12.6060507  12.81549318 11.23022837], train_hist_grp_loss: [ 3.57002371  4.6500549  10.30223718], cur_train_grp_loss: [0.0881358  0.11545781 0.2550369 ], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6768, max_kl_dist_index: 2, max_train_grp_loss:  13.7392, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8155, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:35:01,353 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  40, train_loss:  12.6261, val_loss:  12.2179, grad_norm: 0.0008, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6764, 0.3236, 0.6768, param: [ 4.89806148  6.96199854  5.68632213 10.23016594], weights: [0.32440551 0.32801777 0.34757672], train_wt_loss:  37.8784, val_wt_loss: 36.6537, train_grp_loss: [11.45816976 13.73889805 13.00693395], val_grp_loss: [12.60631079 12.81521765 11.23035678], train_hist_grp_loss: [ 3.6581615   4.76551026 10.55727459], cur_train_grp_loss: [0.08813778 0.11545536 0.25503741], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6768, max_kl_dist_index: 2, max_train_grp_loss:  13.7389, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8152, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:35:02,386 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  41, train_loss:  12.6261, val_loss:  12.2179, grad_norm: 0.0008, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6764, 0.3236, 0.6768, param: [ 4.89799713  6.96157092  5.68661129 10.23012195], weights: [0.32418824 0.32788763 0.34792413], train_wt_loss:  37.8784, val_wt_loss: 36.6538, train_grp_loss: [11.45842679 13.73860874 13.00695956], val_grp_loss: [12.60657027 12.8149432  11.23048491], train_hist_grp_loss: [ 3.74630126  4.88096319 10.81231251], cur_train_grp_loss: [0.08813977 0.11545292 0.25503792], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6768, max_kl_dist_index: 2, max_train_grp_loss:  13.7386, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8149, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:35:03,414 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  42, train_loss:  12.6262, val_loss:  12.2180, grad_norm: 0.0008, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6764, 0.3236, 0.6768, param: [ 4.8979324   6.96114362  5.68690033 10.23007911], weights: [0.32397095 0.32775735 0.3482717 ], train_wt_loss:  37.8785, val_wt_loss: 36.6539, train_grp_loss: [11.45868315 13.73832032 13.00698497], val_grp_loss: [12.60682912 12.81466981 11.23061274], train_hist_grp_loss: [ 3.83444301  4.99641368 11.06735093], cur_train_grp_loss: [0.08814174 0.11545049 0.25503842], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6768, max_kl_dist_index: 2, max_train_grp_loss:  13.7383, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8147, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:35:04,437 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  43, train_loss:  12.6262, val_loss:  12.2180, grad_norm: 0.0009, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6764, 0.3236, 0.6768, param: [ 4.8978673   6.96071664  5.68718923 10.23003742], weights: [0.32375363 0.32762694 0.34861943], train_wt_loss:  37.8785, val_wt_loss: 36.6540, train_grp_loss: [11.45893882 13.73803279 13.00701019], val_grp_loss: [12.60708735 12.8143975  11.23074028], train_hist_grp_loss: [ 3.92258673  5.11186175 11.32238986], cur_train_grp_loss: [0.08814372 0.11544807 0.25503892], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6768, max_kl_dist_index: 2, max_train_grp_loss:  13.7380, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8144, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:35:05,480 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  44, train_loss:  12.6262, val_loss:  12.2180, grad_norm: 0.0009, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6764, 0.3236, 0.6768, param: [ 4.89780182  6.96028998  5.68747801 10.22999689], weights: [0.32353629 0.32749639 0.34896731], train_wt_loss:  37.8785, val_wt_loss: 36.6541, train_grp_loss: [11.4591938  13.73774615 13.0070352 ], val_grp_loss: [12.60734496 12.81412625 11.23086752], train_hist_grp_loss: [ 4.01073241  5.2273074  11.57742927], cur_train_grp_loss: [0.08814568 0.11544565 0.25503942], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6768, max_kl_dist_index: 2, max_train_grp_loss:  13.7377, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8141, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:35:06,500 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  45, train_loss:  12.6262, val_loss:  12.2181, grad_norm: 0.0009, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6764, 0.3236, 0.6767, param: [ 4.89773596  6.95986363  5.68776665 10.22995752], weights: [0.32331893 0.32736571 0.34931536], train_wt_loss:  37.8785, val_wt_loss: 36.6542, train_grp_loss: [11.45944811 13.7374604  13.00706001], val_grp_loss: [12.60760194 12.81385607 11.23099446], train_hist_grp_loss: [ 4.09888005  5.34275065 11.83246918], cur_train_grp_loss: [0.08814764 0.11544324 0.25503991], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6767, max_kl_dist_index: 2, max_train_grp_loss:  13.7375, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8139, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:35:07,555 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  46, train_loss:  12.6262, val_loss:  12.2181, grad_norm: 0.0009, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6764, 0.3236, 0.6767, param: [ 4.89766973  6.9594376   5.68805516 10.2299193 ], weights: [0.32310154 0.3272349  0.34966356], train_wt_loss:  37.8785, val_wt_loss: 36.6544, train_grp_loss: [11.45970172 13.73717554 13.00708462], val_grp_loss: [12.6078583  12.81358696 11.23112111], train_hist_grp_loss: [ 4.18702965  5.45819149 12.08750957], cur_train_grp_loss: [0.0881496  0.11544084 0.25504039], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6767, max_kl_dist_index: 2, max_train_grp_loss:  13.7372, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8136, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:35:08,630 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  47, train_loss:  12.6262, val_loss:  12.2182, grad_norm: 0.0010, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6764, 0.3236, 0.6767, param: [ 4.89760311  6.95901188  5.68834354 10.22988224], weights: [0.32288413 0.32710395 0.35001192], train_wt_loss:  37.8785, val_wt_loss: 36.6545, train_grp_loss: [11.45995466 13.73689157 13.00710903], val_grp_loss: [12.60811403 12.81331892 11.23124747], train_hist_grp_loss: [ 4.27518121  5.57362994 12.34255044], cur_train_grp_loss: [0.08815155 0.11543845 0.25504087], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6767, max_kl_dist_index: 2, max_train_grp_loss:  13.7369, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8133, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:35:09,681 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  48, train_loss:  12.6262, val_loss:  12.2182, grad_norm: 0.0010, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6763, 0.3236, 0.6767, param: [ 4.89753612  6.95858648  5.68863179 10.22984634], weights: [0.32266669 0.32697287 0.35036044], train_wt_loss:  37.8785, val_wt_loss: 36.6546, train_grp_loss: [11.4602069  13.73660849 13.00713323], val_grp_loss: [12.60836914 12.81305196 11.23137353], train_hist_grp_loss: [ 4.3633347   5.68906601 12.5975918 ], cur_train_grp_loss: [0.0881535  0.11543606 0.25504135], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6767, max_kl_dist_index: 2, max_train_grp_loss:  13.7366, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8131, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:35:10,702 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  49, train_loss:  12.6262, val_loss:  12.2182, grad_norm: 0.0010, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6763, 0.3236, 0.6767, param: [ 4.89746876  6.9581614   5.68891991 10.22981159], weights: [0.32244923 0.32684165 0.35070911], train_wt_loss:  37.8785, val_wt_loss: 36.6547, train_grp_loss: [11.46045846 13.7363263  13.00715724], val_grp_loss: [12.60862362 12.81278606 11.23149929], train_hist_grp_loss: [ 4.45149014  5.80449969 12.85263363], cur_train_grp_loss: [0.08815544 0.11543368 0.25504183], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6767, max_kl_dist_index: 2, max_train_grp_loss:  13.7363, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8128, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:35:11,730 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  50, train_loss:  12.6262, val_loss:  12.2183, grad_norm: 0.0010, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6763, 0.3236, 0.6767, param: [ 4.89740101  6.95773664  5.68920789 10.22977801], weights: [0.32223175 0.3267103  0.35105795], train_wt_loss:  37.8785, val_wt_loss: 36.6548, train_grp_loss: [11.46070933 13.73604501 13.00718104], val_grp_loss: [12.60887747 12.81252124 11.23162475], train_hist_grp_loss: [ 4.53964751  5.919931   13.10767592], cur_train_grp_loss: [0.08815737 0.11543131 0.2550423 ], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6767, max_kl_dist_index: 2, max_train_grp_loss:  13.7360, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8125, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:35:12,759 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  51, train_loss:  12.6262, val_loss:  12.2183, grad_norm: 0.0010, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6763, 0.3235, 0.6766, param: [ 4.89733289  6.95731219  5.68949575 10.22974559], weights: [0.32201425 0.32657882 0.35140693], train_wt_loss:  37.8785, val_wt_loss: 36.6549, train_grp_loss: [11.46095952 13.7357646  13.00720464], val_grp_loss: [12.6091307  12.8122575  11.23174992], train_hist_grp_loss: [ 4.62780682  6.03535995 13.36271869], cur_train_grp_loss: [0.0881593  0.11542895 0.25504277], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6766, max_kl_dist_index: 2, max_train_grp_loss:  13.7358, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8123, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:35:13,773 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  52, train_loss:  12.6262, val_loss:  12.2183, grad_norm: 0.0011, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6763, 0.3235, 0.6766, param: [ 4.89726438  6.95688806  5.68978347 10.22971433], weights: [0.32179672 0.3264472  0.35175608], train_wt_loss:  37.8785, val_wt_loss: 36.6550, train_grp_loss: [11.46120902 13.73548509 13.00722804], val_grp_loss: [12.6093833  12.81199482 11.23187479], train_hist_grp_loss: [ 4.71596804  6.15078655 13.61776192], cur_train_grp_loss: [0.08816123 0.11542659 0.25504323], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6766, max_kl_dist_index: 2, max_train_grp_loss:  13.7355, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8120, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:35:14,806 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  53, train_loss:  12.6262, val_loss:  12.2184, grad_norm: 0.0011, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6763, 0.3235, 0.6766, param: [ 4.8971955   6.95646424  5.69007106 10.22968423], weights: [0.32157917 0.32631545 0.35210538], train_wt_loss:  37.8785, val_wt_loss: 36.6551, train_grp_loss: [11.46145783 13.73520647 13.00725124], val_grp_loss: [12.60963527 12.81173322 11.23199936], train_hist_grp_loss: [ 4.80413119  6.26621079 13.87280561], cur_train_grp_loss: [0.08816315 0.11542424 0.25504369], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6766, max_kl_dist_index: 2, max_train_grp_loss:  13.7352, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8117, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:35:15,828 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  54, train_loss:  12.6262, val_loss:  12.2184, grad_norm: 0.0011, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6763, 0.3235, 0.6766, param: [ 4.89712624  6.95604075  5.69035852 10.2296553 ], weights: [0.3213616  0.32618357 0.35245484], train_wt_loss:  37.8785, val_wt_loss: 36.6553, train_grp_loss: [11.46170595 13.73492875 13.00727423], val_grp_loss: [12.60988661 12.8114727  11.23212364], train_hist_grp_loss: [ 4.89229625  6.38163269 14.12784975], cur_train_grp_loss: [0.08816506 0.1154219  0.25504414], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6766, max_kl_dist_index: 2, max_train_grp_loss:  13.7349, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8115, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:35:16,866 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  55, train_loss:  12.6262, val_loss:  12.2185, grad_norm: 0.0011, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6763, 0.3235, 0.6766, param: [ 4.8970566   6.95561756  5.69064585 10.22962754], weights: [0.321144   0.32605155 0.35280445], train_wt_loss:  37.8785, val_wt_loss: 36.6554, train_grp_loss: [11.46195338 13.73465192 13.00729702], val_grp_loss: [12.61013733 12.81121325 11.23224762], train_hist_grp_loss: [ 4.98046322  6.49705226 14.38289434], cur_train_grp_loss: [0.08816697 0.11541957 0.25504459], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6766, max_kl_dist_index: 2, max_train_grp_loss:  13.7347, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8112, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:35:17,875 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  56, train_loss:  12.6262, val_loss:  12.2185, grad_norm: 0.0011, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6763, 0.3235, 0.6766, param: [ 4.89698658  6.9551947   5.69093305 10.22960093], weights: [0.32092638 0.32591941 0.35315421], train_wt_loss:  37.8785, val_wt_loss: 36.6555, train_grp_loss: [11.46220012 13.73437598 13.00731961], val_grp_loss: [12.61038741 12.81095488 11.23237129], train_hist_grp_loss: [ 5.06863209  6.61246951 14.63793938], cur_train_grp_loss: [0.08816887 0.11541724 0.25504504], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6766, max_kl_dist_index: 2, max_train_grp_loss:  13.7344, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8110, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:35:18,911 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  57, train_loss:  12.6262, val_loss:  12.2185, grad_norm: 0.0012, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6763, 0.3235, 0.6766, param: [ 4.89691618  6.95477215  5.69122011 10.2295755 ], weights: [0.32070874 0.32578712 0.35350413], train_wt_loss:  37.8785, val_wt_loss: 36.6556, train_grp_loss: [11.46244617 13.73410094 13.007342  ], val_grp_loss: [12.61063687 12.81069759 11.23249467], train_hist_grp_loss: [ 5.15680286  6.72788443 14.89298486], cur_train_grp_loss: [0.08817077 0.11541492 0.25504548], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6766, max_kl_dist_index: 2, max_train_grp_loss:  13.7341, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8107, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:35:19,932 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  58, train_loss:  12.6262, val_loss:  12.2186, grad_norm: 0.0012, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6763, 0.3235, 0.6765, param: [ 4.8968454   6.95434992  5.69150704 10.22955123], weights: [0.32049108 0.32565471 0.35385421], train_wt_loss:  37.8785, val_wt_loss: 36.6557, train_grp_loss: [11.46269153 13.73382679 13.00736418], val_grp_loss: [12.61088569 12.81044137 11.23261775], train_hist_grp_loss: [ 5.24497552  6.84329704 15.14803078], cur_train_grp_loss: [0.08817266 0.11541261 0.25504592], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6765, max_kl_dist_index: 2, max_train_grp_loss:  13.7338, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8104, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:35:20,952 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  59, train_loss:  12.6262, val_loss:  12.2186, grad_norm: 0.0012, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6763, 0.3235, 0.6765, param: [ 4.89677424  6.953928    5.69179384 10.22952814], weights: [0.32027339 0.32552217 0.35420444], train_wt_loss:  37.8785, val_wt_loss: 36.6558, train_grp_loss: [11.46293619 13.73355354 13.00738615], val_grp_loss: [12.61113388 12.81018623 11.23274053], train_hist_grp_loss: [ 5.33315007  6.95870735 15.40307714], cur_train_grp_loss: [0.08817455 0.11541031 0.25504636], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6765, max_kl_dist_index: 2, max_train_grp_loss:  13.7336, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8102, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:35:21,981 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  60, train_loss:  12.6262, val_loss:  12.2187, grad_norm: 0.0012, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6763, 0.3235, 0.6765, param: [ 4.8967027   6.9535064   5.69208051 10.22950621], weights: [0.32005569 0.32538949 0.35455482], train_wt_loss:  37.8785, val_wt_loss: 36.6560, train_grp_loss: [11.46318017 13.73328118 13.00740793], val_grp_loss: [12.61138145 12.80993218 11.23286302], train_hist_grp_loss: [ 5.42132651  7.07411537 15.65812393], cur_train_grp_loss: [0.08817643 0.11540801 0.25504679], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6765, max_kl_dist_index: 2, max_train_grp_loss:  13.7333, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8099, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:35:23,004 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  61, train_loss:  12.6262, val_loss:  12.2187, grad_norm: 0.0012, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6763, 0.3235, 0.6765, param: [ 4.89663078  6.95308512  5.69236704 10.22948545], weights: [0.31983796 0.32525668 0.35490536], train_wt_loss:  37.8785, val_wt_loss: 36.6561, train_grp_loss: [11.46342345 13.73300972 13.0074295 ], val_grp_loss: [12.61162837 12.8096792  11.2329852 ], train_hist_grp_loss: [ 5.50950482  7.18952109 15.91317114], cur_train_grp_loss: [0.08817831 0.11540572 0.25504721], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6765, max_kl_dist_index: 2, max_train_grp_loss:  13.7330, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8097, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:35:24,026 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  62, train_loss:  12.6262, val_loss:  12.2187, grad_norm: 0.0013, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6762, 0.3235, 0.6765, param: [ 4.89655848  6.95266415  5.69265345 10.22946587], weights: [0.31962021 0.32512374 0.35525605], train_wt_loss:  37.8785, val_wt_loss: 36.6562, train_grp_loss: [11.46366604 13.73273916 13.00745086], val_grp_loss: [12.61187467 12.8094273  11.23310708], train_hist_grp_loss: [ 5.597685    7.30492453 16.16821878], cur_train_grp_loss: [0.08818018 0.11540344 0.25504764], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6765, max_kl_dist_index: 2, max_train_grp_loss:  13.7327, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8094, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:35:25,071 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  63, train_loss:  12.6262, val_loss:  12.2188, grad_norm: 0.0013, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6762, 0.3235, 0.6765, param: [ 4.89648579  6.9522435   5.69293972 10.22944745], weights: [0.31940244 0.32499067 0.35560689], train_wt_loss:  37.8785, val_wt_loss: 36.6563, train_grp_loss: [11.46390794 13.7324695  13.00747202], val_grp_loss: [12.61212034 12.80917648 11.23322866], train_hist_grp_loss: [ 5.68586704  7.4203257  16.42326684], cur_train_grp_loss: [0.08818205 0.11540117 0.25504806], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6765, max_kl_dist_index: 2, max_train_grp_loss:  13.7325, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8092, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:35:26,145 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  64, train_loss:  12.6262, val_loss:  12.2188, grad_norm: 0.0013, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6762, 0.3235, 0.6764, param: [ 4.89641273  6.95182316  5.69322585 10.22943021], weights: [0.31918465 0.32485746 0.35595788], train_wt_loss:  37.8785, val_wt_loss: 36.6564, train_grp_loss: [11.46414914 13.73220073 13.00749298], val_grp_loss: [12.61236537 12.80892675 11.23334994], train_hist_grp_loss: [ 5.77405095  7.53572461 16.67831531], cur_train_grp_loss: [0.08818391 0.1153989  0.25504847], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6764, max_kl_dist_index: 2, max_train_grp_loss:  13.7322, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8089, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:35:27,155 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  65, train_loss:  12.6262, val_loss:  12.2188, grad_norm: 0.0013, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6762, 0.3235, 0.6764, param: [ 4.89633928  6.95140314  5.69351186 10.22941415], weights: [0.31896684 0.32472413 0.35630903], train_wt_loss:  37.8785, val_wt_loss: 36.6565, train_grp_loss: [11.46438965 13.73193287 13.00751373], val_grp_loss: [12.61260976 12.80867809 11.23347092], train_hist_grp_loss: [ 5.86223671  7.65112125 16.93336419], cur_train_grp_loss: [0.08818576 0.11539664 0.25504888], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6764, max_kl_dist_index: 2, max_train_grp_loss:  13.7319, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8087, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:35:28,195 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  66, train_loss:  12.6262, val_loss:  12.2189, grad_norm: 0.0014, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6762, 0.3235, 0.6764, param: [ 4.89626545  6.95098343  5.69379773 10.22939926], weights: [0.31874901 0.32459066 0.35666033], train_wt_loss:  37.8785, val_wt_loss: 36.6566, train_grp_loss: [11.46462946 13.7316659  13.00753427], val_grp_loss: [12.61285353 12.80843052 11.2335916 ], train_hist_grp_loss: [ 5.95042432  7.76651564 17.18841348], cur_train_grp_loss: [0.08818761 0.11539439 0.25504929], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6764, max_kl_dist_index: 2, max_train_grp_loss:  13.7317, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8084, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:35:29,233 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  67, train_loss:  12.6262, val_loss:  12.2189, grad_norm: 0.0014, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6762, 0.3235, 0.6764, param: [ 4.89619124  6.95056404  5.69408347 10.22938555], weights: [0.31853115 0.32445707 0.35701178], train_wt_loss:  37.8785, val_wt_loss: 36.6568, train_grp_loss: [11.46486857 13.73139983 13.00755461], val_grp_loss: [12.61309665 12.80818404 11.23371197], train_hist_grp_loss: [ 6.03861378  7.88190779 17.44346317], cur_train_grp_loss: [0.08818946 0.11539215 0.25504969], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6764, max_kl_dist_index: 2, max_train_grp_loss:  13.7314, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8082, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:35:30,257 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  68, train_loss:  12.6262, val_loss:  12.2190, grad_norm: 0.0014, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6762, 0.3235, 0.6764, param: [ 4.89611665  6.95014497  5.69436908 10.22937301], weights: [0.31831328 0.32432334 0.35736338], train_wt_loss:  37.8786, val_wt_loss: 36.6569, train_grp_loss: [11.46510699 13.73113466 13.00757475], val_grp_loss: [12.61333915 12.80793863 11.23383205], train_hist_grp_loss: [ 6.12680508  7.99729771 17.69851326], cur_train_grp_loss: [0.0881913  0.11538991 0.25505009], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6764, max_kl_dist_index: 2, max_train_grp_loss:  13.7311, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8079, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:35:31,286 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  69, train_loss:  12.6262, val_loss:  12.2190, grad_norm: 0.0014, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6762, 0.3235, 0.6764, param: [ 4.89604168  6.94972621  5.69465455 10.22936166], weights: [0.31809539 0.32418948 0.35771513], train_wt_loss:  37.8786, val_wt_loss: 36.6570, train_grp_loss: [11.46534472 13.73087039 13.00759468], val_grp_loss: [12.613581   12.80769431 11.23395182], train_hist_grp_loss: [ 6.21499821  8.1126854  17.95356374], cur_train_grp_loss: [0.08819313 0.11538769 0.25505049], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6764, max_kl_dist_index: 2, max_train_grp_loss:  13.7309, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8077, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:35:32,309 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  70, train_loss:  12.6262, val_loss:  12.2190, grad_norm: 0.0014, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6762, 0.3235, 0.6764, param: [ 4.89596632  6.94930777  5.69493989 10.22935148], weights: [0.31787747 0.32405549 0.35806703], train_wt_loss:  37.8786, val_wt_loss: 36.6571, train_grp_loss: [11.46558174 13.73060703 13.0076144 ], val_grp_loss: [12.61382222 12.80745108 11.23407129], train_hist_grp_loss: [ 6.30319317  8.22807086 18.20861462], cur_train_grp_loss: [0.08819496 0.11538547 0.25505088], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6764, max_kl_dist_index: 2, max_train_grp_loss:  13.7306, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8075, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:35:33,329 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  71, train_loss:  12.6262, val_loss:  12.2191, grad_norm: 0.0015, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6762, 0.3235, 0.6763, param: [ 4.89589058  6.94888964  5.69522509 10.22934248], weights: [0.31765954 0.32392138 0.35841909], train_wt_loss:  37.8786, val_wt_loss: 36.6572, train_grp_loss: [11.46581807 13.73034456 13.00763391], val_grp_loss: [12.6140628  12.80720894 11.23419045], train_hist_grp_loss: [ 6.39138995  8.34345411 18.46366588], cur_train_grp_loss: [0.08819678 0.11538325 0.25505126], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6763, max_kl_dist_index: 2, max_train_grp_loss:  13.7303, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8072, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:35:34,381 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  72, train_loss:  12.6262, val_loss:  12.2191, grad_norm: 0.0015, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6762, 0.3235, 0.6763, param: [ 4.89581446  6.94847183  5.69551017 10.22933466], weights: [0.31744158 0.32378713 0.35877129], train_wt_loss:  37.8786, val_wt_loss: 36.6573, train_grp_loss: [11.4660537  13.730083   13.00765323], val_grp_loss: [12.61430275 12.80696788 11.23430932], train_hist_grp_loss: [ 6.47958855  8.45883516 18.71871753], cur_train_grp_loss: [0.0881986  0.11538105 0.25505165], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6763, max_kl_dist_index: 2, max_train_grp_loss:  13.7301, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8070, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:35:35,422 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  73, train_loss:  12.6262, val_loss:  12.2192, grad_norm: 0.0015, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6762, 0.3235, 0.6763, param: [ 4.89573795  6.94805433  5.69579511 10.22932803], weights: [0.31722361 0.32365275 0.35912364], train_wt_loss:  37.8786, val_wt_loss: 36.6575, train_grp_loss: [11.46628863 13.72982234 13.00767233], val_grp_loss: [12.61454206 12.8067279  11.23442788], train_hist_grp_loss: [ 6.56778897  8.57421401 18.97376955], cur_train_grp_loss: [0.08820041 0.11537885 0.25505202], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6763, max_kl_dist_index: 2, max_train_grp_loss:  13.7298, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8067, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:35:36,471 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  74, train_loss:  12.6262, val_loss:  12.2192, grad_norm: 0.0015, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6762, 0.3235, 0.6763, param: [ 4.89566106  6.94763715  5.69607991 10.22932258], weights: [0.31700562 0.32351824 0.35947614], train_wt_loss:  37.8786, val_wt_loss: 36.6576, train_grp_loss: [11.46652286 13.72956258 13.00769123], val_grp_loss: [12.61478073 12.80648902 11.23454614], train_hist_grp_loss: [ 6.65599119  8.68959067 19.22882195], cur_train_grp_loss: [0.08820222 0.11537666 0.2550524 ], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6763, max_kl_dist_index: 2, max_train_grp_loss:  13.7296, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8065, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:35:37,542 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  75, train_loss:  12.6262, val_loss:  12.2192, grad_norm: 0.0015, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6762, 0.3235, 0.6763, param: [ 4.89558379  6.94722028  5.69636458 10.22931831], weights: [0.31678761 0.3233836  0.35982879], train_wt_loss:  37.8786, val_wt_loss: 36.6577, train_grp_loss: [11.4667564  13.72930372 13.00770992], val_grp_loss: [12.61501876 12.80625122 11.23466409], train_hist_grp_loss: [ 6.74419521  8.80496514 19.48387472], cur_train_grp_loss: [0.08820402 0.11537448 0.25505277], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6763, max_kl_dist_index: 2, max_train_grp_loss:  13.7293, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8063, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:35:38,585 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  76, train_loss:  12.6262, val_loss:  12.2193, grad_norm: 0.0016, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6762, 0.3235, 0.6763, param: [ 4.89550613  6.94680373  5.69664912 10.22931523], weights: [0.31656958 0.32324883 0.36018159], train_wt_loss:  37.8786, val_wt_loss: 36.6578, train_grp_loss: [11.46698923 13.72904577 13.0077284 ], val_grp_loss: [12.61525615 12.80601452 11.23478174], train_hist_grp_loss: [ 6.83240103  8.92033744 19.73892786], cur_train_grp_loss: [0.08820582 0.1153723  0.25505314], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6763, max_kl_dist_index: 2, max_train_grp_loss:  13.7290, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8060, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:35:39,618 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  77, train_loss:  12.6262, val_loss:  12.2193, grad_norm: 0.0016, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6762, 0.3235, 0.6763, param: [ 4.89542809  6.9463875   5.69693353 10.22931333], weights: [0.31635153 0.32311394 0.36053453], train_wt_loss:  37.8786, val_wt_loss: 36.6579, train_grp_loss: [11.46722136 13.72878872 13.00774668], val_grp_loss: [12.6154929  12.8057789  11.23489908], train_hist_grp_loss: [ 6.92060864  9.03570758 19.99398135], cur_train_grp_loss: [0.08820761 0.11537013 0.2550535 ], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6763, max_kl_dist_index: 2, max_train_grp_loss:  13.7288, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8058, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:35:40,628 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  78, train_loss:  12.6262, val_loss:  12.2193, grad_norm: 0.0016, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6761, 0.3235, 0.6762, param: [ 4.89534966  6.94597158  5.6972178  10.22931262], weights: [0.31613346 0.32297891 0.36088763], train_wt_loss:  37.8786, val_wt_loss: 36.6580, train_grp_loss: [11.46745279 13.72853258 13.00776474], val_grp_loss: [12.61572901 12.80554437 11.23501612], train_hist_grp_loss: [ 7.00881803  9.15107555 20.24903521], cur_train_grp_loss: [0.0882094  0.11536797 0.25505386], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6762, max_kl_dist_index: 2, max_train_grp_loss:  13.7285, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8055, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:35:41,662 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  79, train_loss:  12.6262, val_loss:  12.2194, grad_norm: 0.0016, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6761, 0.3235, 0.6762, param: [ 4.89527085  6.94555597  5.69750193 10.2293131 ], weights: [0.31591537 0.32284376 0.36124087], train_wt_loss:  37.8786, val_wt_loss: 36.6582, train_grp_loss: [11.46768351 13.72827734 13.0077826 ], val_grp_loss: [12.61596448 12.80531094 11.23513285], train_hist_grp_loss: [ 7.09702921  9.26644137 20.50408942], cur_train_grp_loss: [0.08821118 0.11536582 0.25505421], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6762, max_kl_dist_index: 2, max_train_grp_loss:  13.7283, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8053, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:35:42,720 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  80, train_loss:  12.6262, val_loss:  12.2194, grad_norm: 0.0017, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6761, 0.3235, 0.6762, param: [ 4.89519166  6.94514068  5.69778594 10.22931476], weights: [0.31569727 0.32270848 0.36159426], train_wt_loss:  37.8786, val_wt_loss: 36.6583, train_grp_loss: [11.46791354 13.72802301 13.00780026], val_grp_loss: [12.61619931 12.80507859 11.23524928], train_hist_grp_loss: [ 7.18524216  9.38180504 20.75914398], cur_train_grp_loss: [0.08821295 0.11536368 0.25505456], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6762, max_kl_dist_index: 2, max_train_grp_loss:  13.7280, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8051, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:35:43,754 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  81, train_loss:  12.6262, val_loss:  12.2195, grad_norm: 0.0017, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6761, 0.3234, 0.6762, param: [ 4.89511207  6.9447257   5.6980698  10.22931762], weights: [0.31547914 0.32257306 0.36194779], train_wt_loss:  37.8786, val_wt_loss: 36.6584, train_grp_loss: [11.46814286 13.72776958 13.0078177 ], val_grp_loss: [12.6164335  12.80484734 11.23536541], train_hist_grp_loss: [ 7.27345688  9.49716658 21.01419889], cur_train_grp_loss: [0.08821472 0.11536154 0.25505491], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6762, max_kl_dist_index: 2, max_train_grp_loss:  13.7278, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8048, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:35:44,813 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  82, train_loss:  12.6262, val_loss:  12.2195, grad_norm: 0.0017, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6761, 0.3234, 0.6762, param: [ 4.89503211  6.94431104  5.69835354 10.22932167], weights: [0.315261   0.32243752 0.36230148], train_wt_loss:  37.8786, val_wt_loss: 36.6585, train_grp_loss: [11.46837148 13.72751706 13.00783494], val_grp_loss: [12.61666704 12.80461719 11.23548122], train_hist_grp_loss: [ 7.36167336  9.61252599 21.26925414], cur_train_grp_loss: [0.08821648 0.11535941 0.25505525], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6762, max_kl_dist_index: 2, max_train_grp_loss:  13.7275, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8046, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:35:45,841 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  83, train_loss:  12.6262, val_loss:  12.2195, grad_norm: 0.0017, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6761, 0.3234, 0.6762, param: [ 4.89495176  6.94389669  5.69863714 10.22932691], weights: [0.31504284 0.32230186 0.3626553 ], train_wt_loss:  37.8786, val_wt_loss: 36.6586, train_grp_loss: [11.4685994  13.72726544 13.00785197], val_grp_loss: [12.61689994 12.80438812 11.23559674], train_hist_grp_loss: [ 7.4498916   9.72788328 21.52430973], cur_train_grp_loss: [0.08821824 0.11535729 0.25505559], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6762, max_kl_dist_index: 2, max_train_grp_loss:  13.7273, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8044, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:35:46,879 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  84, train_loss:  12.6262, val_loss:  12.2196, grad_norm: 0.0017, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6761, 0.3234, 0.6762, param: [ 4.89487102  6.94348266  5.6989206  10.22933334], weights: [0.31482466 0.32216606 0.36300928], train_wt_loss:  37.8786, val_wt_loss: 36.6588, train_grp_loss: [11.46882661 13.72701474 13.00786878], val_grp_loss: [12.6171322  12.80416015 11.23571194], train_hist_grp_loss: [ 7.5381116   9.84323845 21.77936565], cur_train_grp_loss: [0.08822    0.11535517 0.25505592], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6762, max_kl_dist_index: 2, max_train_grp_loss:  13.7270, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8042, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:35:47,909 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  85, train_loss:  12.6262, val_loss:  12.2196, grad_norm: 0.0018, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6761, 0.3234, 0.6761, param: [ 4.89478989  6.94306894  5.69920393 10.22934096], weights: [0.31460647 0.32203013 0.3633634 ], train_wt_loss:  37.8786, val_wt_loss: 36.6589, train_grp_loss: [11.46905311 13.72676494 13.00788539], val_grp_loss: [12.61736382 12.80393328 11.23582684], train_hist_grp_loss: [ 7.62633334  9.95859151 22.0344219 ], cur_train_grp_loss: [0.08822174 0.11535307 0.25505625], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6761, max_kl_dist_index: 2, max_train_grp_loss:  13.7268, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8039, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:35:48,959 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  86, train_loss:  12.6262, val_loss:  12.2197, grad_norm: 0.0018, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6761, 0.3234, 0.6761, param: [ 4.89470838  6.94265553  5.69948712 10.22934978], weights: [0.31438825 0.32189408 0.36371766], train_wt_loss:  37.8786, val_wt_loss: 36.6590, train_grp_loss: [11.46927891 13.72651605 13.0079018 ], val_grp_loss: [12.61759479 12.8037075  11.23594143], train_hist_grp_loss: [ 7.71455683 10.07394248 22.28947847], cur_train_grp_loss: [0.08822349 0.11535097 0.25505658], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6761, max_kl_dist_index: 2, max_train_grp_loss:  13.7265, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8037, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:35:49,999 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  87, train_loss:  12.6262, val_loss:  12.2197, grad_norm: 0.0018, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6761, 0.3234, 0.6761, param: [ 4.89462649  6.94224244  5.69977018 10.22935979], weights: [0.31417002 0.3217579  0.36407207], train_wt_loss:  37.8787, val_wt_loss: 36.6591, train_grp_loss: [11.469504   13.72626807 13.00791799], val_grp_loss: [12.61782511 12.80348282 11.23605571], train_hist_grp_loss: [ 7.80278205 10.18929135 22.54453537], cur_train_grp_loss: [0.08822522 0.11534887 0.2550569 ], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6761, max_kl_dist_index: 2, max_train_grp_loss:  13.7263, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8035, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:35:51,055 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  88, train_loss:  12.6262, val_loss:  12.2197, grad_norm: 0.0018, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6761, 0.3234, 0.6761, param: [ 4.8945442   6.94182967  5.70005311 10.22937101], weights: [0.31395178 0.3216216  0.36442663], train_wt_loss:  37.8787, val_wt_loss: 36.6592, train_grp_loss: [11.46972839 13.726021   13.00793397], val_grp_loss: [12.61805479 12.80325923 11.23616969], train_hist_grp_loss: [ 7.891009   10.30463814 22.79959259], cur_train_grp_loss: [0.08822695 0.11534679 0.25505722], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6761, max_kl_dist_index: 2, max_train_grp_loss:  13.7260, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8033, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:35:52,090 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  89, train_loss:  12.6262, val_loss:  12.2198, grad_norm: 0.0018, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6761, 0.3234, 0.6761, param: [ 4.89446153  6.9414172   5.7003359  10.22938341], weights: [0.31373351 0.32148516 0.36478132], train_wt_loss:  37.8787, val_wt_loss: 36.6594, train_grp_loss: [11.46995207 13.72577484 13.00794974], val_grp_loss: [12.61828383 12.80303675 11.23628336], train_hist_grp_loss: [ 7.97923768 10.41998286 23.05465012], cur_train_grp_loss: [0.08822868 0.11534471 0.25505753], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6761, max_kl_dist_index: 2, max_train_grp_loss:  13.7258, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8030, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:35:53,116 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  90, train_loss:  12.6262, val_loss:  12.2198, grad_norm: 0.0019, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6761, 0.3234, 0.6761, param: [ 4.89437848  6.94100506  5.70061855 10.22939702], weights: [0.31351523 0.3213486  0.36513617], train_wt_loss:  37.8787, val_wt_loss: 36.6595, train_grp_loss: [11.47017504 13.72552958 13.00796531], val_grp_loss: [12.61851222 12.80281536 11.23639672], train_hist_grp_loss: [ 8.06746808 10.5353255  23.30970795], cur_train_grp_loss: [0.0882304  0.11534265 0.25505784], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6761, max_kl_dist_index: 0, max_train_grp_loss:  13.7255, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8028, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:35:54,172 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  91, train_loss:  12.6262, val_loss:  12.2199, grad_norm: 0.0019, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6761, 0.3234, 0.6761, param: [ 4.89429503  6.94059322  5.70090107 10.22941183], weights: [0.31329693 0.32121191 0.36549115], train_wt_loss:  37.8787, val_wt_loss: 36.6596, train_grp_loss: [11.47039731 13.72528524 13.00798066], val_grp_loss: [12.61873996 12.80259507 11.23650977], train_hist_grp_loss: [ 8.1557002  10.65066609 23.5647661 ], cur_train_grp_loss: [0.08823212 0.11534058 0.25505814], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6761, max_kl_dist_index: 0, max_train_grp_loss:  13.7253, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8026, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:35:55,196 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  92, train_loss:  12.6262, val_loss:  12.2199, grad_norm: 0.0019, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6761, 0.3234, 0.6761, param: [ 4.8942112   6.9401817   5.70118345 10.22942783], weights: [0.31307862 0.3210751  0.36584628], train_wt_loss:  37.8787, val_wt_loss: 36.6597, train_grp_loss: [11.47061887 13.72504181 13.0079958 ], val_grp_loss: [12.61896706 12.80237588 11.23662252], train_hist_grp_loss: [ 8.24393402 10.76600462 23.81982454], cur_train_grp_loss: [0.08823383 0.11533853 0.25505844], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6761, max_kl_dist_index: 0, max_train_grp_loss:  13.7250, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8024, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:35:56,261 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  93, train_loss:  12.6262, val_loss:  12.2199, grad_norm: 0.0019, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6761, 0.3234, 0.6760, param: [ 4.89412698  6.93977049  5.7014657  10.22944504], weights: [0.31286029 0.32093816 0.36620155], train_wt_loss:  37.8787, val_wt_loss: 36.6598, train_grp_loss: [11.47083971 13.7247993  13.00801073], val_grp_loss: [12.6191935  12.80215779 11.23673495], train_hist_grp_loss: [ 8.33216955 10.8813411  24.07488328], cur_train_grp_loss: [0.08823553 0.11533649 0.25505874], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6761, max_kl_dist_index: 0, max_train_grp_loss:  13.7248, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8022, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:35:57,294 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  94, train_loss:  12.6262, val_loss:  12.2200, grad_norm: 0.0020, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6761, 0.3234, 0.6760, param: [ 4.89404237  6.9393596   5.70174781 10.22946345], weights: [0.31264194 0.32080109 0.36655697], train_wt_loss:  37.8787, val_wt_loss: 36.6600, train_grp_loss: [11.47105985 13.72455769 13.00802545], val_grp_loss: [12.6194193  12.8019408  11.23684708], train_hist_grp_loss: [ 8.42040678 10.99667555 24.32994232], cur_train_grp_loss: [0.08823723 0.11533445 0.25505903], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6761, max_kl_dist_index: 0, max_train_grp_loss:  13.7246, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8019, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:35:58,335 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  95, train_loss:  12.6262, val_loss:  12.2200, grad_norm: 0.0020, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6761, 0.3234, 0.6760, param: [ 4.89395737  6.93894902  5.70202979 10.22948306], weights: [0.31242358 0.3206639  0.36691252], train_wt_loss:  37.8787, val_wt_loss: 36.6601, train_grp_loss: [11.47127928 13.724317   13.00803997], val_grp_loss: [12.61964445 12.80172491 11.23695889], train_hist_grp_loss: [ 8.5086457  11.11200797 24.58500164], cur_train_grp_loss: [0.08823892 0.11533242 0.25505932], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6761, max_kl_dist_index: 0, max_train_grp_loss:  13.7243, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8017, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:35:59,359 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  96, train_loss:  12.6262, val_loss:  12.2201, grad_norm: 0.0020, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6761, 0.3234, 0.6760, param: [ 4.89387199  6.93853876  5.70231163 10.22950387], weights: [0.3122052  0.32052658 0.36726822], train_wt_loss:  37.8787, val_wt_loss: 36.6602, train_grp_loss: [11.47149799 13.72407722 13.00805427], val_grp_loss: [12.61986895 12.80151012 11.2370704 ], train_hist_grp_loss: [ 8.59688631 11.22733837 24.84006125], cur_train_grp_loss: [0.08824061 0.11533039 0.25505961], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6761, max_kl_dist_index: 0, max_train_grp_loss:  13.7241, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8015, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:36:00,401 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  97, train_loss:  12.6262, val_loss:  12.2201, grad_norm: 0.0020, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6760, 0.3234, 0.6760, param: [ 4.89378621  6.9381288   5.70259334 10.2295259 ], weights: [0.31198681 0.32038913 0.36762406], train_wt_loss:  37.8787, val_wt_loss: 36.6603, train_grp_loss: [11.471716   13.72383835 13.00806835], val_grp_loss: [12.62009281 12.80129644 11.2371816 ], train_hist_grp_loss: [ 8.68512861 11.34266675 25.09512113], cur_train_grp_loss: [0.08824229 0.11532838 0.25505989], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6760, max_kl_dist_index: 0, max_train_grp_loss:  13.7238, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8013, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:36:01,434 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  98, train_loss:  12.6262, val_loss:  12.2201, grad_norm: 0.0020, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6760, 0.3234, 0.6760, param: [ 4.89370005  6.93771916  5.7028749  10.22954912], weights: [0.3117684  0.32025156 0.36798004], train_wt_loss:  37.8787, val_wt_loss: 36.6604, train_grp_loss: [11.47193329 13.7236004  13.00808223], val_grp_loss: [12.62031601 12.80108386 11.23729248], train_hist_grp_loss: [ 8.77337257 11.45799312 25.3501813 ], cur_train_grp_loss: [0.08824397 0.11532637 0.25506016], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6760, max_kl_dist_index: 0, max_train_grp_loss:  13.7236, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8011, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:36:02,462 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  99, train_loss:  12.6262, val_loss:  12.2202, grad_norm: 0.0021, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6760, 0.3234, 0.6760, param: [ 4.8936135   6.93730984  5.70315634 10.22957356], weights: [0.31154998 0.32011386 0.36833616], train_wt_loss:  37.8787, val_wt_loss: 36.6606, train_grp_loss: [11.47214988 13.72336336 13.0080959 ], val_grp_loss: [12.62053856 12.80087239 11.23740306], train_hist_grp_loss: [ 8.86161822 11.57331749 25.60524173], cur_train_grp_loss: [0.08824564 0.11532437 0.25506044], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6760, max_kl_dist_index: 0, max_train_grp_loss:  13.7234, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8009, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:36:03,484 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  100, train_loss:  12.6262, val_loss:  12.2202, grad_norm: 0.0021, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6760, 0.3234, 0.6760, param: [ 4.89352655  6.93690083  5.70343763 10.2295992 ], weights: [0.31133154 0.31997604 0.36869242], train_wt_loss:  37.8787, val_wt_loss: 36.6607, train_grp_loss: [11.47236575 13.72312724 13.00810935], val_grp_loss: [12.62076046 12.80066202 11.23751333], train_hist_grp_loss: [ 8.94986552 11.68863987 25.86030244], cur_train_grp_loss: [0.08824731 0.11532238 0.2550607 ], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6760, max_kl_dist_index: 0, max_train_grp_loss:  13.7231, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8007, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:36:04,524 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  101, train_loss:  12.6262, val_loss:  12.2203, grad_norm: 0.0021, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6760, 0.3234, 0.6759, param: [ 4.89343922  6.93649213  5.70371879 10.22962605], weights: [0.31111308 0.31983809 0.36904882], train_wt_loss:  37.8787, val_wt_loss: 36.6608, train_grp_loss: [11.4725809  13.72289203 13.00812259], val_grp_loss: [12.62098171 12.80045275 11.23762328], train_hist_grp_loss: [ 9.03811449 11.80396027 26.1153634 ], cur_train_grp_loss: [0.08824897 0.1153204  0.25506097], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6760, max_kl_dist_index: 0, max_train_grp_loss:  13.7229, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8005, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:36:05,559 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  102, train_loss:  12.6262, val_loss:  12.2203, grad_norm: 0.0021, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6760, 0.3234, 0.6759, param: [ 4.8933515   6.93608374  5.70399982 10.22965411], weights: [0.31089461 0.31970002 0.36940536], train_wt_loss:  37.8787, val_wt_loss: 36.6609, train_grp_loss: [11.47279534 13.72265774 13.00813562], val_grp_loss: [12.62120231 12.80024459 11.23773292], train_hist_grp_loss: [ 9.12636511 11.91927869 26.37042463], cur_train_grp_loss: [0.08825062 0.11531842 0.25506123], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6760, max_kl_dist_index: 0, max_train_grp_loss:  13.7227, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8002, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:36:06,574 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  103, train_loss:  12.6263, val_loss:  12.2203, grad_norm: 0.0022, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6760, 0.3234, 0.6759, param: [ 4.89326339  6.93567567  5.7042807  10.22968338], weights: [0.31067613 0.31956183 0.36976204], train_wt_loss:  37.8788, val_wt_loss: 36.6610, train_grp_loss: [11.47300907 13.72242437 13.00814844], val_grp_loss: [12.62142225 12.80003754 11.23784225], train_hist_grp_loss: [ 9.21461738 12.03459514 26.62548611], cur_train_grp_loss: [0.08825227 0.11531645 0.25506148], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6760, max_kl_dist_index: 0, max_train_grp_loss:  13.7224, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8000, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:36:07,592 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  104, train_loss:  12.6263, val_loss:  12.2204, grad_norm: 0.0022, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6760, 0.3234, 0.6759, param: [ 4.89317489  6.93526791  5.70456145 10.22971386], weights: [0.31045763 0.3194235  0.37011886], train_wt_loss:  37.8788, val_wt_loss: 36.6612, train_grp_loss: [11.47322209 13.72219191 13.00816104], val_grp_loss: [12.62164154 12.7998316  11.23795127], train_hist_grp_loss: [ 9.3028713  12.14990963 26.88054785], cur_train_grp_loss: [0.08825392 0.11531449 0.25506173], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6760, max_kl_dist_index: 0, max_train_grp_loss:  13.7222, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7998, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:36:08,633 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  105, train_loss:  12.6263, val_loss:  12.2204, grad_norm: 0.0022, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6760, 0.3234, 0.6759, param: [ 4.89308599  6.93486046  5.70484207 10.22974555], weights: [0.31023912 0.31928506 0.37047582], train_wt_loss:  37.8788, val_wt_loss: 36.6613, train_grp_loss: [11.47343439 13.72196037 13.00817343], val_grp_loss: [12.62186018 12.79962676 11.23805998], train_hist_grp_loss: [ 9.39112685 12.26522217 27.13560983], cur_train_grp_loss: [0.08825555 0.11531254 0.25506198], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6760, max_kl_dist_index: 0, max_train_grp_loss:  13.7220, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7996, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:36:09,673 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  106, train_loss:  12.6263, val_loss:  12.2205, grad_norm: 0.0022, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6760, 0.3234, 0.6759, param: [ 4.89299671  6.93445332  5.70512254 10.22977846], weights: [0.31002059 0.31914649 0.37083292], train_wt_loss:  37.8788, val_wt_loss: 36.6614, train_grp_loss: [11.47364597 13.72172975 13.00818561], val_grp_loss: [12.62207816 12.79942303 11.23816837], train_hist_grp_loss: [ 9.47938404 12.38053276 27.39067205], cur_train_grp_loss: [0.08825719 0.11531059 0.25506222], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6760, max_kl_dist_index: 0, max_train_grp_loss:  13.7217, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7994, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:36:10,720 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  107, train_loss:  12.6263, val_loss:  12.2205, grad_norm: 0.0022, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6760, 0.3234, 0.6759, param: [ 4.89290704  6.9340465   5.70540288 10.22981259], weights: [0.30980205 0.3190078  0.37119015], train_wt_loss:  37.8788, val_wt_loss: 36.6615, train_grp_loss: [11.47385683 13.72150004 13.00819758], val_grp_loss: [12.62229549 12.79922041 11.23827646], train_hist_grp_loss: [ 9.56764286 12.49584141 27.64573452], cur_train_grp_loss: [0.08825882 0.11530865 0.25506246], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6760, max_kl_dist_index: 0, max_train_grp_loss:  13.7215, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7992, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:36:11,779 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  108, train_loss:  12.6263, val_loss:  12.2206, grad_norm: 0.0023, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6760, 0.3234, 0.6759, param: [ 4.89281697  6.93363999  5.70568308 10.22984792], weights: [0.3095835  0.31886898 0.37154752], train_wt_loss:  37.8788, val_wt_loss: 36.6617, train_grp_loss: [11.47406698 13.72127126 13.00820933], val_grp_loss: [12.62251217 12.79901891 11.23838422], train_hist_grp_loss: [ 9.65590329 12.61114814 27.90079721], cur_train_grp_loss: [0.08826044 0.11530672 0.2550627 ], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6760, max_kl_dist_index: 0, max_train_grp_loss:  13.7213, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7990, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:36:12,812 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  109, train_loss:  12.6263, val_loss:  12.2206, grad_norm: 0.0023, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6760, 0.3234, 0.6758, param: [ 4.89272651  6.93323379  5.70596315 10.22988448], weights: [0.30936493 0.31873004 0.37190503], train_wt_loss:  37.8788, val_wt_loss: 36.6618, train_grp_loss: [11.47427642 13.72104339 13.00822087], val_grp_loss: [12.62272819 12.79881851 11.23849168], train_hist_grp_loss: [ 9.74416535 12.72645294 28.15586014], cur_train_grp_loss: [0.08826205 0.1153048  0.25506293], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6760, max_kl_dist_index: 0, max_train_grp_loss:  13.7210, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7988, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:36:13,852 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  110, train_loss:  12.6263, val_loss:  12.2206, grad_norm: 0.0023, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6760, 0.3234, 0.6758, param: [ 4.89263566  6.93282791  5.70624308 10.22992225], weights: [0.30914635 0.31859097 0.37226268], train_wt_loss:  37.8788, val_wt_loss: 36.6619, train_grp_loss: [11.47448513 13.72081645 13.00823219], val_grp_loss: [12.62294355 12.79861922 11.23859882], train_hist_grp_loss: [ 9.83242901 12.84175582 28.4109233 ], cur_train_grp_loss: [0.08826366 0.11530289 0.25506315], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6760, max_kl_dist_index: 0, max_train_grp_loss:  13.7208, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7986, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:36:14,890 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  111, train_loss:  12.6263, val_loss:  12.2207, grad_norm: 0.0023, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6760, 0.3234, 0.6758, param: [ 4.89254442  6.93242233  5.70652287 10.22996124], weights: [0.30892776 0.31845178 0.37262046], train_wt_loss:  37.8788, val_wt_loss: 36.6620, train_grp_loss: [11.47469313 13.72059042 13.0082433 ], val_grp_loss: [12.62315826 12.79842105 11.23870565], train_hist_grp_loss: [ 9.92069428 12.9570568  28.66598667], cur_train_grp_loss: [0.08826527 0.11530098 0.25506338], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6760, max_kl_dist_index: 0, max_train_grp_loss:  13.7206, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7984, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:36:15,911 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  112, train_loss:  12.6263, val_loss:  12.2207, grad_norm: 0.0023, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6760, 0.3234, 0.6758, param: [ 4.89245279  6.93201707  5.70680252 10.23000145], weights: [0.30870915 0.31831247 0.37297838], train_wt_loss:  37.8788, val_wt_loss: 36.6621, train_grp_loss: [11.47490041 13.72036532 13.0082542 ], val_grp_loss: [12.62337231 12.79822399 11.23881216], train_hist_grp_loss: [10.00896115 13.07235588 28.92105027], cur_train_grp_loss: [0.08826687 0.11529908 0.25506359], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6760, max_kl_dist_index: 0, max_train_grp_loss:  13.7204, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7982, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:36:16,939 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  113, train_loss:  12.6263, val_loss:  12.2208, grad_norm: 0.0024, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6760, 0.3234, 0.6758, param: [ 4.89236076  6.93161212  5.70708203 10.23004288], weights: [0.30849053 0.31817304 0.37333644], train_wt_loss:  37.8788, val_wt_loss: 36.6623, train_grp_loss: [11.47510697 13.72014113 13.00826488], val_grp_loss: [12.6235857  12.79802804 11.23891837], train_hist_grp_loss: [10.09722962 13.18765307 29.17611407], cur_train_grp_loss: [0.08826846 0.11529719 0.25506381], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6760, max_kl_dist_index: 0, max_train_grp_loss:  13.7201, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7980, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:36:17,988 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  114, train_loss:  12.6263, val_loss:  12.2208, grad_norm: 0.0024, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6760, 0.3234, 0.6758, param: [ 4.89226835  6.93120748  5.70736141 10.23008553], weights: [0.3082719  0.31803348 0.37369463], train_wt_loss:  37.8788, val_wt_loss: 36.6624, train_grp_loss: [11.47531281 13.71991787 13.00827535], val_grp_loss: [12.62379843 12.79783321 11.23902425], train_hist_grp_loss: [10.18549967 13.30294837 29.43117809], cur_train_grp_loss: [0.08827005 0.1152953  0.25506402], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6760, max_kl_dist_index: 0, max_train_grp_loss:  13.7199, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7978, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:36:19,094 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  115, train_loss:  12.6263, val_loss:  12.2208, grad_norm: 0.0024, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6760, 0.3234, 0.6758, param: [ 4.89217553  6.93080316  5.70764065 10.2301294 ], weights: [0.30805325 0.3178938  0.37405295], train_wt_loss:  37.8788, val_wt_loss: 36.6625, train_grp_loss: [11.47551792 13.71969553 13.0082856 ], val_grp_loss: [12.62401051 12.79763949 11.23912982], train_hist_grp_loss: [10.27377131 13.4182418  29.68624231], cur_train_grp_loss: [0.08827164 0.11529343 0.25506422], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6760, max_kl_dist_index: 0, max_train_grp_loss:  13.7197, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7976, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:36:20,108 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  116, train_loss:  12.6263, val_loss:  12.2209, grad_norm: 0.0024, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6760, 0.3234, 0.6758, param: [ 4.89208233  6.93039914  5.70791975 10.2301745 ], weights: [0.30783459 0.317754   0.37441141], train_wt_loss:  37.8788, val_wt_loss: 36.6626, train_grp_loss: [11.47572232 13.71947412 13.00829564], val_grp_loss: [12.62422193 12.79744689 11.23923508], train_hist_grp_loss: [10.36204452 13.53353336 29.94130674], cur_train_grp_loss: [0.08827321 0.11529156 0.25506442], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6760, max_kl_dist_index: 0, max_train_grp_loss:  13.7195, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7974, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:36:21,114 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  117, train_loss:  12.6263, val_loss:  12.2209, grad_norm: 0.0025, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6760, 0.3234, 0.6758, param: [ 4.89198873  6.92999544  5.70819871 10.23022082], weights: [0.30761592 0.31761407 0.37477001], train_wt_loss:  37.8789, val_wt_loss: 36.6628, train_grp_loss: [11.475926   13.71925362 13.00830546], val_grp_loss: [12.62443269 12.7972554  11.23934002], train_hist_grp_loss: [10.45031931 13.64882306 30.19637136], cur_train_grp_loss: [0.08827479 0.1152897  0.25506462], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6760, max_kl_dist_index: 0, max_train_grp_loss:  13.7193, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7973, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:36:22,150 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  118, train_loss:  12.6263, val_loss:  12.2210, grad_norm: 0.0025, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6760, 0.3234, 0.6757, param: [ 4.89189474  6.92959205  5.70847754 10.23026837], weights: [0.30739724 0.31747403 0.37512873], train_wt_loss:  37.8789, val_wt_loss: 36.6629, train_grp_loss: [11.47612895 13.71903405 13.00831507], val_grp_loss: [12.62464278 12.79706503 11.23944464], train_hist_grp_loss: [10.53859566 13.7641109  30.45143617], cur_train_grp_loss: [0.08827635 0.11528785 0.25506481], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6760, max_kl_dist_index: 0, max_train_grp_loss:  13.7190, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7971, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:36:23,181 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  119, train_loss:  12.6263, val_loss:  12.2210, grad_norm: 0.0025, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6760, 0.3234, 0.6757, param: [ 4.89180036  6.92918897  5.70875623 10.23031714], weights: [0.30717855 0.31733386 0.3754876 ], train_wt_loss:  37.8789, val_wt_loss: 36.6630, train_grp_loss: [11.47633119 13.71881541 13.00832446], val_grp_loss: [12.62485222 12.79687578 11.23954895], train_hist_grp_loss: [10.62687358 13.8793969  30.70650117], cur_train_grp_loss: [0.08827792 0.115286   0.255065  ], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6760, max_kl_dist_index: 0, max_train_grp_loss:  13.7188, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7969, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:36:24,223 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  120, train_loss:  12.6263, val_loss:  12.2210, grad_norm: 0.0025, live_grad: 0.0000, reward_err: 0.0098, 0.0186, 0.0009, KL_dist: 0.6760, 0.3234, 0.6757, param: [ 4.89170558  6.9287862   5.70903477 10.23036714], weights: [0.30695984 0.31719357 0.37584659], train_wt_loss:  37.8789, val_wt_loss: 36.6631, train_grp_loss: [11.4765327  13.71859769 13.00833364], val_grp_loss: [12.625061   12.79668764 11.23965294], train_hist_grp_loss: [10.71515305 13.99468107 30.96156636], cur_train_grp_loss: [0.08827947 0.11528416 0.25506519], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6760, max_kl_dist_index: 0, max_train_grp_loss:  13.7186, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7967, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:36:25,267 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  121, train_loss:  12.6263, val_loss:  12.2211, grad_norm: 0.0025, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6759, 0.3234, 0.6757, param: [ 4.8916104   6.92838375  5.70931318 10.23041836], weights: [0.30674112 0.31705315 0.37620572], train_wt_loss:  37.8789, val_wt_loss: 36.6633, train_grp_loss: [11.47673348 13.71838089 13.0083426 ], val_grp_loss: [12.62526912 12.79650063 11.23975662], train_hist_grp_loss: [10.80343407 14.1099634  31.21663172], cur_train_grp_loss: [0.08828102 0.11528233 0.25506537], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6759, max_kl_dist_index: 0, max_train_grp_loss:  13.7184, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7965, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:36:26,325 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  122, train_loss:  12.6263, val_loss:  12.2211, grad_norm: 0.0026, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6759, 0.3234, 0.6757, param: [ 4.89151483  6.9279816   5.70959145 10.23047082], weights: [0.3065224  0.31691262 0.37656498], train_wt_loss:  37.8789, val_wt_loss: 36.6634, train_grp_loss: [11.47693355 13.71816502 13.00835134], val_grp_loss: [12.62547657 12.79631473 11.23985998], train_hist_grp_loss: [10.89171664 14.22524391 31.47169727], cur_train_grp_loss: [0.08828257 0.11528051 0.25506554], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6759, max_kl_dist_index: 0, max_train_grp_loss:  13.7182, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7963, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:36:27,362 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  123, train_loss:  12.6263, val_loss:  12.2212, grad_norm: 0.0026, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6759, 0.3234, 0.6757, param: [ 4.89141887  6.92757976  5.70986958 10.2305245 ], weights: [0.30630366 0.31677197 0.37692438], train_wt_loss:  37.8789, val_wt_loss: 36.6635, train_grp_loss: [11.47713289 13.71795008 13.00835987], val_grp_loss: [12.62568336 12.79612996 11.23996302], train_hist_grp_loss: [10.98000074 14.34052261 31.72676298], cur_train_grp_loss: [0.0882841  0.1152787  0.25506571], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6759, max_kl_dist_index: 0, max_train_grp_loss:  13.7180, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7961, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:36:28,385 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  124, train_loss:  12.6263, val_loss:  12.2212, grad_norm: 0.0026, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6759, 0.3234, 0.6757, param: [ 4.89132251  6.92717824  5.71014758 10.23057942], weights: [0.30608491 0.31663119 0.3772839 ], train_wt_loss:  37.8789, val_wt_loss: 36.6636, train_grp_loss: [11.4773315  13.71773607 13.00836818], val_grp_loss: [12.6258895  12.7959463  11.24006575], train_hist_grp_loss: [11.06828638 14.4557995  31.98182886], cur_train_grp_loss: [0.08828564 0.11527689 0.25506588], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6759, max_kl_dist_index: 0, max_train_grp_loss:  13.7177, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7959, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:36:29,402 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  125, train_loss:  12.6263, val_loss:  12.2213, grad_norm: 0.0026, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6759, 0.3234, 0.6757, param: [ 4.89122576  6.92677703  5.71042543 10.23063556], weights: [0.30586614 0.3164903  0.37764356], train_wt_loss:  37.8789, val_wt_loss: 36.6638, train_grp_loss: [11.47752939 13.71752298 13.00837628], val_grp_loss: [12.62609496 12.79576377 11.24016816], train_hist_grp_loss: [11.15657354 14.57107459 32.2368949 ], cur_train_grp_loss: [0.08828717 0.11527509 0.25506604], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6759, max_kl_dist_index: 0, max_train_grp_loss:  13.7175, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7958, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:36:30,447 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  126, train_loss:  12.6263, val_loss:  12.2213, grad_norm: 0.0027, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6759, 0.3234, 0.6757, param: [ 4.89112861  6.92637612  5.71070315 10.23069294], weights: [0.30564737 0.31634928 0.37800335], train_wt_loss:  37.8789, val_wt_loss: 36.6639, train_grp_loss: [11.47772655 13.71731081 13.00838416], val_grp_loss: [12.62629977 12.79558236 11.24027025], train_hist_grp_loss: [11.24486223 14.6863479  32.4919611 ], cur_train_grp_loss: [0.08828869 0.1152733  0.2550662 ], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6759, max_kl_dist_index: 0, max_train_grp_loss:  13.7173, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7956, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:36:31,480 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  127, train_loss:  12.6263, val_loss:  12.2213, grad_norm: 0.0027, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6759, 0.3234, 0.6757, param: [ 4.89103107  6.92597553  5.71098072 10.23075156], weights: [0.30542859 0.31620814 0.37836327], train_wt_loss:  37.8789, val_wt_loss: 36.6640, train_grp_loss: [11.47792299 13.71709958 13.00839182], val_grp_loss: [12.6265039  12.79540207 11.24037202], train_hist_grp_loss: [11.33315243 14.80161941 32.74702746], cur_train_grp_loss: [0.0882902  0.11527152 0.25506636], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6759, max_kl_dist_index: 0, max_train_grp_loss:  13.7171, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7954, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:36:32,532 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  128, train_loss:  12.6263, val_loss:  12.2214, grad_norm: 0.0027, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6759, 0.3234, 0.6756, param: [ 4.89093313  6.92557525  5.71125816 10.23081141], weights: [0.3052098  0.31606689 0.37872332], train_wt_loss:  37.8789, val_wt_loss: 36.6641, train_grp_loss: [11.4781187  13.71688928 13.00839926], val_grp_loss: [12.62670738 12.7952229  11.24047347], train_hist_grp_loss: [11.42144415 14.91688916 33.00209396], cur_train_grp_loss: [0.08829172 0.11526974 0.25506651], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6759, max_kl_dist_index: 0, max_train_grp_loss:  13.7169, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7952, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:36:33,572 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  129, train_loss:  12.6263, val_loss:  12.2214, grad_norm: 0.0027, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6759, 0.3234, 0.6756, param: [ 4.89083479  6.92517528  5.71153545 10.23087249], weights: [0.304991   0.31592551 0.3790835 ], train_wt_loss:  37.8789, val_wt_loss: 36.6643, train_grp_loss: [11.47831368 13.7166799  13.00840649], val_grp_loss: [12.62691019 12.79504486 11.24057461], train_hist_grp_loss: [11.50973737 15.03215714 33.25716062], cur_train_grp_loss: [0.08829322 0.11526798 0.25506665], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6759, max_kl_dist_index: 0, max_train_grp_loss:  13.7167, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7950, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:36:34,613 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  130, train_loss:  12.6263, val_loss:  12.2215, grad_norm: 0.0027, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6759, 0.3234, 0.6756, param: [ 4.89073606  6.92477562  5.71181261 10.23093481], weights: [0.30477218 0.31578401 0.37944381], train_wt_loss:  37.8790, val_wt_loss: 36.6644, train_grp_loss: [11.47850794 13.71647146 13.0084135 ], val_grp_loss: [12.62711233 12.79486794 11.24067543], train_hist_grp_loss: [11.59803209 15.14742335 33.51222741], cur_train_grp_loss: [0.08829472 0.11526622 0.25506679], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6759, max_kl_dist_index: 0, max_train_grp_loss:  13.7165, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7949, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:36:35,657 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  131, train_loss:  12.6263, val_loss:  12.2215, grad_norm: 0.0028, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6759, 0.3233, 0.6756, param: [ 4.89063693  6.92437627  5.71208963 10.23099837], weights: [0.30455336 0.31564239 0.37980424], train_wt_loss:  37.8790, val_wt_loss: 36.6645, train_grp_loss: [11.47870146 13.71626394 13.00842029], val_grp_loss: [12.62731381 12.79469215 11.24077592], train_hist_grp_loss: [11.68632831 15.26268782 33.76729434], cur_train_grp_loss: [0.08829621 0.11526447 0.25506693], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6759, max_kl_dist_index: 0, max_train_grp_loss:  13.7163, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7947, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:36:36,698 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  132, train_loss:  12.6263, val_loss:  12.2215, grad_norm: 0.0028, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6759, 0.3233, 0.6756, param: [ 4.8905374   6.92397723  5.7123665  10.23106316], weights: [0.30433453 0.31550066 0.38016481], train_wt_loss:  37.8790, val_wt_loss: 36.6646, train_grp_loss: [11.47889426 13.71605736 13.00842686], val_grp_loss: [12.62751462 12.79451749 11.2408761 ], train_hist_grp_loss: [11.77462601 15.37795054 34.02236141], cur_train_grp_loss: [0.0882977  0.11526272 0.25506706], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6759, max_kl_dist_index: 0, max_train_grp_loss:  13.7161, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7945, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:36:37,725 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  133, train_loss:  12.6263, val_loss:  12.2216, grad_norm: 0.0028, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6759, 0.3233, 0.6756, param: [ 4.89043748  6.92357849  5.71264324 10.2311292 ], weights: [0.30411569 0.3153588  0.38052551], train_wt_loss:  37.8790, val_wt_loss: 36.6648, train_grp_loss: [11.47908633 13.7158517  13.00843322], val_grp_loss: [12.62771477 12.79434395 11.24097596], train_hist_grp_loss: [11.8629252  15.49321153 34.2774286 ], cur_train_grp_loss: [0.08829919 0.11526099 0.25506719], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6759, max_kl_dist_index: 0, max_train_grp_loss:  13.7159, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7943, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:36:38,769 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  134, train_loss:  12.6263, val_loss:  12.2216, grad_norm: 0.0028, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6759, 0.3233, 0.6756, param: [ 4.89033716  6.92318007  5.71291984 10.23119648], weights: [0.30389684 0.31521683 0.38088633], train_wt_loss:  37.8790, val_wt_loss: 36.6649, train_grp_loss: [11.47927767 13.71564698 13.00843935], val_grp_loss: [12.62791425 12.79417154 11.2410755 ], train_hist_grp_loss: [11.95122586 15.60847079 34.53249592], cur_train_grp_loss: [0.08830066 0.11525926 0.25506732], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6759, max_kl_dist_index: 0, max_train_grp_loss:  13.7156, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7942, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:36:39,814 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  135, train_loss:  12.6263, val_loss:  12.2217, grad_norm: 0.0029, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6759, 0.3233, 0.6756, param: [ 4.89023644  6.92278196  5.7131963  10.23126499], weights: [0.30367798 0.31507473 0.38124729], train_wt_loss:  37.8790, val_wt_loss: 36.6650, train_grp_loss: [11.47946828 13.71544319 13.00844527], val_grp_loss: [12.62811306 12.79400026 11.24117472], train_hist_grp_loss: [12.039528   15.72372832 34.78756336], cur_train_grp_loss: [0.08830214 0.11525754 0.25506744], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6759, max_kl_dist_index: 0, max_train_grp_loss:  13.7154, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7940, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:36:40,859 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  136, train_loss:  12.6263, val_loss:  12.2217, grad_norm: 0.0029, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6759, 0.3233, 0.6756, param: [ 4.89013533  6.92238416  5.71347261 10.23133475], weights: [0.30345911 0.31493252 0.38160837], train_wt_loss:  37.8790, val_wt_loss: 36.6651, train_grp_loss: [11.47965815 13.71524033 13.00845097], val_grp_loss: [12.6283112  12.7938301  11.24127362], train_hist_grp_loss: [12.1278316  15.83898415 35.04263091], cur_train_grp_loss: [0.0883036  0.11525583 0.25506755], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6759, max_kl_dist_index: 0, max_train_grp_loss:  13.7152, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7938, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:36:41,866 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  137, train_loss:  12.6263, val_loss:  12.2218, grad_norm: 0.0029, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6759, 0.3233, 0.6756, param: [ 4.89003381  6.92198667  5.71374879 10.23140576], weights: [0.30324023 0.31479019 0.38196958], train_wt_loss:  37.8790, val_wt_loss: 36.6653, train_grp_loss: [11.4798473  13.71503841 13.00845645], val_grp_loss: [12.62850867 12.79366108 11.2413722 ], train_hist_grp_loss: [12.21613666 15.95423827 35.29769858], cur_train_grp_loss: [0.08830506 0.11525412 0.25506767], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6759, max_kl_dist_index: 0, max_train_grp_loss:  13.7150, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7937, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:36:42,903 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  138, train_loss:  12.6263, val_loss:  12.2218, grad_norm: 0.0029, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6759, 0.3233, 0.6756, param: [ 4.8899319   6.92158948  5.71402482 10.231478  ], weights: [0.30302135 0.31464774 0.38233091], train_wt_loss:  37.8790, val_wt_loss: 36.6654, train_grp_loss: [11.48003571 13.71483742 13.00846171], val_grp_loss: [12.62870547 12.79349318 11.24147046], train_hist_grp_loss: [12.30444318 16.06949069 35.55276635], cur_train_grp_loss: [0.08830652 0.11525242 0.25506777], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6759, max_kl_dist_index: 0, max_train_grp_loss:  13.7148, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7935, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:36:43,932 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  139, train_loss:  12.6263, val_loss:  12.2218, grad_norm: 0.0029, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6759, 0.3233, 0.6755, param: [ 4.88982959  6.92119261  5.71430072 10.2315515 ], weights: [0.30280245 0.31450517 0.38269237], train_wt_loss:  37.8790, val_wt_loss: 36.6655, train_grp_loss: [11.4802234  13.71463736 13.00846676], val_grp_loss: [12.62890161 12.79332642 11.24156839], train_hist_grp_loss: [12.39275115 16.18474143 35.80783423], cur_train_grp_loss: [0.08830797 0.11525073 0.25506788], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6759, max_kl_dist_index: 0, max_train_grp_loss:  13.7146, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7933, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:36:44,947 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  140, train_loss:  12.6263, val_loss:  12.2219, grad_norm: 0.0030, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6759, 0.3233, 0.6755, param: [ 4.88972688  6.92079605  5.71457647 10.23162623], weights: [0.30258355 0.31436249 0.38305396], train_wt_loss:  37.8790, val_wt_loss: 36.6656, train_grp_loss: [11.48041035 13.71443824 13.00847158], val_grp_loss: [12.62909707 12.79316079 11.24166601], train_hist_grp_loss: [12.48106056 16.29999048 36.0629022 ], cur_train_grp_loss: [0.08830941 0.11524905 0.25506798], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6759, max_kl_dist_index: 0, max_train_grp_loss:  13.7144, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7932, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:36:45,984 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  141, train_loss:  12.6263, val_loss:  12.2219, grad_norm: 0.0030, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6759, 0.3233, 0.6755, param: [ 4.88962377  6.92039979  5.71485209 10.23170222], weights: [0.30236464 0.31421969 0.38341567], train_wt_loss:  37.8790, val_wt_loss: 36.6658, train_grp_loss: [11.48059656 13.71424005 13.00847618], val_grp_loss: [12.62929186 12.79299629 11.2417633 ], train_hist_grp_loss: [12.56937141 16.41523786 36.31797027], cur_train_grp_loss: [0.08831085 0.11524738 0.25506807], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6759, max_kl_dist_index: 0, max_train_grp_loss:  13.7142, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7930, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:36:47,007 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  142, train_loss:  12.6264, val_loss:  12.2220, grad_norm: 0.0030, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6759, 0.3233, 0.6755, param: [ 4.88952027  6.92000384  5.71512756 10.23177945], weights: [0.30214573 0.31407677 0.38377751], train_wt_loss:  37.8791, val_wt_loss: 36.6659, train_grp_loss: [11.48078205 13.7140428  13.00848057], val_grp_loss: [12.62948598 12.79283293 11.24186027], train_hist_grp_loss: [12.65768369 16.53048358 36.57303843], cur_train_grp_loss: [0.08831228 0.11524571 0.25506816], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6759, max_kl_dist_index: 0, max_train_grp_loss:  13.7140, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7928, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:36:48,051 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  143, train_loss:  12.6264, val_loss:  12.2220, grad_norm: 0.0030, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6759, 0.3233, 0.6755, param: [ 4.88941636  6.9196082   5.71540289 10.23185794], weights: [0.3019268  0.31393373 0.38413947], train_wt_loss:  37.8791, val_wt_loss: 36.6660, train_grp_loss: [11.48096679 13.71384649 13.00848473], val_grp_loss: [12.62967943 12.79267069 11.24195692], train_hist_grp_loss: [12.74599739 16.64572763 36.82810668], cur_train_grp_loss: [0.08831371 0.11524406 0.25506825], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6759, max_kl_dist_index: 0, max_train_grp_loss:  13.7138, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7927, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:36:49,100 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  144, train_loss:  12.6264, val_loss:  12.2220, grad_norm: 0.0031, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6759, 0.3233, 0.6755, param: [ 4.88931205  6.91921288  5.71567808 10.23193767], weights: [0.30170787 0.31379057 0.38450156], train_wt_loss:  37.8791, val_wt_loss: 36.6661, train_grp_loss: [11.48115081 13.71365111 13.00848867], val_grp_loss: [12.62987221 12.7925096  11.24205325], train_hist_grp_loss: [12.83431252 16.76097004 37.08317501], cur_train_grp_loss: [0.08831513 0.11524241 0.25506833], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6759, max_kl_dist_index: 0, max_train_grp_loss:  13.7137, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7925, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:36:50,138 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  145, train_loss:  12.6264, val_loss:  12.2221, grad_norm: 0.0031, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6759, 0.3233, 0.6755, param: [ 4.88920735  6.91881785  5.71595313 10.23201865], weights: [0.30148893 0.3136473  0.38486377], train_wt_loss:  37.8791, val_wt_loss: 36.6663, train_grp_loss: [11.48133409 13.71345667 13.0084924 ], val_grp_loss: [12.63006431 12.79234963 11.24214926], train_hist_grp_loss: [12.92262907 16.87621081 37.33824341], cur_train_grp_loss: [0.08831654 0.11524077 0.25506841], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6759, max_kl_dist_index: 0, max_train_grp_loss:  13.7135, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7923, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:36:51,167 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  146, train_loss:  12.6264, val_loss:  12.2221, grad_norm: 0.0031, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6759, 0.3233, 0.6755, param: [ 4.88910224  6.91842314  5.71622803 10.23210089], weights: [0.30126998 0.31350391 0.38522611], train_wt_loss:  37.8791, val_wt_loss: 36.6664, train_grp_loss: [11.48151663 13.71326316 13.0084959 ], val_grp_loss: [12.63025575 12.79219081 11.24224494], train_hist_grp_loss: [13.01094702 16.99144994 37.59331189], cur_train_grp_loss: [0.08831795 0.11523913 0.25506848], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6759, max_kl_dist_index: 0, max_train_grp_loss:  13.7133, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7922, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:36:52,205 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  147, train_loss:  12.6264, val_loss:  12.2222, grad_norm: 0.0031, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6759, 0.3233, 0.6755, param: [ 4.88899674  6.91802874  5.7165028  10.23218437], weights: [0.30105103 0.31336041 0.38558857], train_wt_loss:  37.8791, val_wt_loss: 36.6665, train_grp_loss: [11.48169844 13.7130706  13.00849918], val_grp_loss: [12.6304465  12.79203312 11.2423403 ], train_hist_grp_loss: [13.09926638 17.10668744 37.84838044], cur_train_grp_loss: [0.08831936 0.11523751 0.25506855], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6759, max_kl_dist_index: 0, max_train_grp_loss:  13.7131, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7920, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:36:53,243 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  148, train_loss:  12.6264, val_loss:  12.2222, grad_norm: 0.0031, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6759, 0.3233, 0.6755, param: [ 4.88889083  6.91763464  5.71677742 10.23226912], weights: [0.30083207 0.31321678 0.38595115], train_wt_loss:  37.8791, val_wt_loss: 36.6667, train_grp_loss: [11.48187951 13.71287897 13.00850224], val_grp_loss: [12.63063659 12.79187656 11.24243534], train_hist_grp_loss: [13.18758714 17.22192333 38.10344905], cur_train_grp_loss: [0.08832076 0.11523589 0.25506861], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6759, max_kl_dist_index: 0, max_train_grp_loss:  13.7129, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7919, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:36:54,293 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  149, train_loss:  12.6264, val_loss:  12.2223, grad_norm: 0.0032, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6759, 0.3233, 0.6755, param: [ 4.88878452  6.91724085  5.7170519  10.23235511], weights: [0.3006131  0.31307305 0.38631386], train_wt_loss:  37.8791, val_wt_loss: 36.6668, train_grp_loss: [11.48205984 13.71268829 13.00850508], val_grp_loss: [12.630826   12.79172115 11.24253005], train_hist_grp_loss: [13.27590929 17.33715761 38.35851772], cur_train_grp_loss: [0.08832215 0.11523428 0.25506867], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6759, max_kl_dist_index: 0, max_train_grp_loss:  13.7127, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7917, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:36:55,321 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  150, train_loss:  12.6264, val_loss:  12.2223, grad_norm: 0.0032, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6759, 0.3233, 0.6755, param: [ 4.88867781  6.91684737  5.71732624 10.23244237], weights: [0.30039413 0.31292919 0.38667668], train_wt_loss:  37.8791, val_wt_loss: 36.6669, train_grp_loss: [11.48223943 13.71249854 13.0085077 ], val_grp_loss: [12.63101473 12.79156687 11.24262444], train_hist_grp_loss: [13.36423283 17.45239028 38.61358645], cur_train_grp_loss: [0.08832354 0.11523267 0.25506873], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6759, max_kl_dist_index: 0, max_train_grp_loss:  13.7125, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7916, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:36:56,336 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  151, train_loss:  12.6264, val_loss:  12.2223, grad_norm: 0.0032, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6759, 0.3233, 0.6754, param: [ 4.8885707   6.9164542   5.71760044 10.23253087], weights: [0.30017515 0.31278522 0.38703963], train_wt_loss:  37.8791, val_wt_loss: 36.6670, train_grp_loss: [11.48241829 13.71230973 13.00851009], val_grp_loss: [12.63120279 12.79141373 11.2427185 ], train_hist_grp_loss: [13.45255775 17.56762136 38.86865523], cur_train_grp_loss: [0.08832492 0.11523108 0.25506878], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6759, max_kl_dist_index: 0, max_train_grp_loss:  13.7123, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7914, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:36:57,406 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  152, train_loss:  12.6264, val_loss:  12.2224, grad_norm: 0.0032, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6759, 0.3233, 0.6754, param: [ 4.88846319  6.91606134  5.71787449 10.23262064], weights: [0.29995616 0.31264114 0.3874027 ], train_wt_loss:  37.8791, val_wt_loss: 36.6672, train_grp_loss: [11.48259641 13.71212186 13.00851227], val_grp_loss: [12.63139017 12.79126173 11.24281224], train_hist_grp_loss: [13.54088404 17.68285086 39.12372405], cur_train_grp_loss: [0.08832629 0.11522949 0.25506883], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6759, max_kl_dist_index: 0, max_train_grp_loss:  13.7121, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7913, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:36:58,435 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  153, train_loss:  12.6264, val_loss:  12.2224, grad_norm: 0.0033, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6759, 0.3233, 0.6754, param: [ 4.88835528  6.91566878  5.7181484  10.23271167], weights: [0.29973717 0.31249693 0.3877659 ], train_wt_loss:  37.8792, val_wt_loss: 36.6673, train_grp_loss: [11.48277379 13.71193494 13.00851422], val_grp_loss: [12.63157688 12.79111087 11.24290566], train_hist_grp_loss: [13.6292117  17.79807877 39.37879292], cur_train_grp_loss: [0.08832766 0.11522791 0.25506887], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6759, max_kl_dist_index: 0, max_train_grp_loss:  13.7119, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7911, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:36:59,459 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  154, train_loss:  12.6264, val_loss:  12.2225, grad_norm: 0.0033, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6759, 0.3233, 0.6754, param: [ 4.88824696  6.91527653  5.71842217 10.23280395], weights: [0.29951817 0.31235262 0.38812921], train_wt_loss:  37.8792, val_wt_loss: 36.6674, train_grp_loss: [11.48295043 13.71174895 13.00851595], val_grp_loss: [12.63176291 12.79096116 11.24299875], train_hist_grp_loss: [13.71754073 17.91330512 39.63386183], cur_train_grp_loss: [0.08832903 0.11522634 0.25506891], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6759, max_kl_dist_index: 0, max_train_grp_loss:  13.7117, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7910, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:37:00,469 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  155, train_loss:  12.6264, val_loss:  12.2225, grad_norm: 0.0033, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6759, 0.3233, 0.6754, param: [ 4.88813824  6.91488459  5.7186958  10.2328975 ], weights: [0.29929917 0.31220819 0.38849264], train_wt_loss:  37.8792, val_wt_loss: 36.6676, train_grp_loss: [11.48312633 13.71156391 13.00851746], val_grp_loss: [12.63194826 12.79081258 11.24309152], train_hist_grp_loss: [13.80587112 18.0285299  39.88893077], cur_train_grp_loss: [0.08833039 0.11522478 0.25506894], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6759, max_kl_dist_index: 0, max_train_grp_loss:  13.7116, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7908, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:37:01,483 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  156, train_loss:  12.6264, val_loss:  12.2226, grad_norm: 0.0033, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6759, 0.3233, 0.6754, param: [ 4.88802912  6.91449295  5.71896929 10.2329923 ], weights: [0.29908016 0.31206364 0.3888562 ], train_wt_loss:  37.8792, val_wt_loss: 36.6677, train_grp_loss: [11.48330148 13.71137981 13.00851874], val_grp_loss: [12.63213293 12.79066515 11.24318396], train_hist_grp_loss: [13.89420286 18.14375312 40.14399974], cur_train_grp_loss: [0.08833174 0.11522323 0.25506897], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6759, max_kl_dist_index: 0, max_train_grp_loss:  13.7114, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7907, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:37:02,507 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  157, train_loss:  12.6264, val_loss:  12.2226, grad_norm: 0.0033, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6759, 0.3233, 0.6754, param: [ 4.8879196   6.91410162  5.71924263 10.23308837], weights: [0.29886115 0.31191898 0.38921987], train_wt_loss:  37.8792, val_wt_loss: 36.6678, train_grp_loss: [11.4834759  13.71119666 13.00851981], val_grp_loss: [12.63231693 12.79051886 11.24327607], train_hist_grp_loss: [13.98253595 18.2589748  40.39906873], cur_train_grp_loss: [0.08833309 0.11522168 0.25506899], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6759, max_kl_dist_index: 0, max_train_grp_loss:  13.7112, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7905, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:37:03,545 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  158, train_loss:  12.6264, val_loss:  12.2226, grad_norm: 0.0034, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6759, 0.3233, 0.6754, param: [ 4.88780968  6.9137106   5.71951582 10.23318571], weights: [0.29864213 0.3117742  0.38958367], train_wt_loss:  37.8792, val_wt_loss: 36.6679, train_grp_loss: [11.48364958 13.71101444 13.00852065], val_grp_loss: [12.63250025 12.79037371 11.24336786], train_hist_grp_loss: [14.07087038 18.37419494 40.65413775], cur_train_grp_loss: [0.08833443 0.11522014 0.25506902], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6759, max_kl_dist_index: 0, max_train_grp_loss:  13.7110, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7904, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:37:04,589 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  159, train_loss:  12.6264, val_loss:  12.2227, grad_norm: 0.0034, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6759, 0.3233, 0.6754, param: [ 4.88769935  6.91331989  5.71978888 10.2332843 ], weights: [0.29842311 0.31162931 0.38994758], train_wt_loss:  37.8792, val_wt_loss: 36.6681, train_grp_loss: [11.48382251 13.71083317 13.00852126], val_grp_loss: [12.63268289 12.79022971 11.24345933], train_hist_grp_loss: [14.15920615 18.48941355 40.90920678], cur_train_grp_loss: [0.08833577 0.11521861 0.25506903], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6759, max_kl_dist_index: 0, max_train_grp_loss:  13.7108, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7902, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:37:05,625 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  160, train_loss:  12.6264, val_loss:  12.2227, grad_norm: 0.0034, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6759, 0.3233, 0.6754, param: [ 4.88758861  6.91292948  5.72006179 10.23338417], weights: [0.29820408 0.31148431 0.39031161], train_wt_loss:  37.8792, val_wt_loss: 36.6682, train_grp_loss: [11.4839947  13.71065285 13.00852166], val_grp_loss: [12.63286484 12.79008686 11.24355046], train_hist_grp_loss: [14.24754324 18.60463064 41.16427582], cur_train_grp_loss: [0.0883371  0.11521709 0.25506904], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6759, max_kl_dist_index: 0, max_train_grp_loss:  13.7107, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7901, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:37:06,641 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  161, train_loss:  12.6264, val_loss:  12.2228, grad_norm: 0.0034, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6759, 0.3233, 0.6754, param: [ 4.88747748  6.91253938  5.72033456 10.23348529], weights: [0.29798505 0.31133919 0.39067576], train_wt_loss:  37.8792, val_wt_loss: 36.6683, train_grp_loss: [11.48416615 13.71047347 13.00852183], val_grp_loss: [12.63304612 12.78994515 11.24364127], train_hist_grp_loss: [14.33588166 18.71984621 41.41934487], cur_train_grp_loss: [0.08833842 0.11521557 0.25506905], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6759, max_kl_dist_index: 0, max_train_grp_loss:  13.7105, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7899, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:37:07,672 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  162, train_loss:  12.6264, val_loss:  12.2228, grad_norm: 0.0035, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6759, 0.3233, 0.6754, param: [ 4.88736594  6.91214958  5.72060719 10.23358769], weights: [0.29776602 0.31119396 0.39104002], train_wt_loss:  37.8792, val_wt_loss: 36.6685, train_grp_loss: [11.48433685 13.71029504 13.00852178], val_grp_loss: [12.63322672 12.78980459 11.24373176], train_hist_grp_loss: [14.4242214  18.83506027 41.67441393], cur_train_grp_loss: [0.08833974 0.11521406 0.25506906], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6759, max_kl_dist_index: 0, max_train_grp_loss:  13.7103, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7898, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:37:08,751 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  163, train_loss:  12.6264, val_loss:  12.2229, grad_norm: 0.0035, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6759, 0.3233, 0.6754, param: [ 4.887254    6.91176009  5.72087967 10.23369135], weights: [0.29754698 0.31104862 0.39140441], train_wt_loss:  37.8792, val_wt_loss: 36.6686, train_grp_loss: [11.48450682 13.71011755 13.0085215 ], val_grp_loss: [12.63340664 12.78966517 11.24382192], train_hist_grp_loss: [14.51256246 18.95027283 41.92948298], cur_train_grp_loss: [0.08834105 0.11521256 0.25506905], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6759, max_kl_dist_index: 0, max_train_grp_loss:  13.7101, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7897, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:37:09,804 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  164, train_loss:  12.6264, val_loss:  12.2229, grad_norm: 0.0035, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6759, 0.3233, 0.6754, param: [ 4.88714165  6.91137091  5.721152   10.23379629], weights: [0.29732793 0.31090316 0.39176891], train_wt_loss:  37.8793, val_wt_loss: 36.6687, train_grp_loss: [11.48467603 13.70994101 13.008521  ], val_grp_loss: [12.63358587 12.78952691 11.24391175], train_hist_grp_loss: [14.60090482 19.0654839  42.18455203], cur_train_grp_loss: [0.08834236 0.11521107 0.25506905], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6759, max_kl_dist_index: 0, max_train_grp_loss:  13.7099, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7895, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:37:10,837 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  165, train_loss:  12.6264, val_loss:  12.2230, grad_norm: 0.0035, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6759, 0.3233, 0.6753, param: [ 4.88702889  6.91098203  5.7214242  10.23390249], weights: [0.29710889 0.31075759 0.39213353], train_wt_loss:  37.8793, val_wt_loss: 36.6689, train_grp_loss: [11.4848445  13.70976542 13.00852028], val_grp_loss: [12.63376442 12.78938979 11.24400125], train_hist_grp_loss: [14.68924848 19.18069349 42.43962107], cur_train_grp_loss: [0.08834366 0.11520959 0.25506904], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6759, max_kl_dist_index: 0, max_train_grp_loss:  13.7098, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7894, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:37:11,914 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  166, train_loss:  12.6264, val_loss:  12.2230, grad_norm: 0.0035, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6759, 0.3233, 0.6753, param: [ 4.88691574  6.91059346  5.72169625 10.23400997], weights: [0.29688984 0.3106119  0.39249826], train_wt_loss:  37.8793, val_wt_loss: 36.6690, train_grp_loss: [11.48501223 13.70959078 13.00851933], val_grp_loss: [12.63394229 12.78925382 11.24409042], train_hist_grp_loss: [14.77759344 19.2959016  42.6946901 ], cur_train_grp_loss: [0.08834496 0.11520811 0.25506903], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6759, max_kl_dist_index: 0, max_train_grp_loss:  13.7096, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7893, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:37:12,944 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  167, train_loss:  12.6264, val_loss:  12.2230, grad_norm: 0.0036, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6759, 0.3233, 0.6753, param: [ 4.88680217  6.9102052   5.72196815 10.23411871], weights: [0.29667078 0.3104661  0.39286311], train_wt_loss:  37.8793, val_wt_loss: 36.6691, train_grp_loss: [11.48517921 13.70941708 13.00851815], val_grp_loss: [12.63411948 12.789119   11.24417927], train_hist_grp_loss: [14.86593968 19.41110825 42.9497591 ], cur_train_grp_loss: [0.08834625 0.11520665 0.25506901], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6759, max_kl_dist_index: 0, max_train_grp_loss:  13.7094, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7891, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:37:13,970 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  168, train_loss:  12.6264, val_loss:  12.2231, grad_norm: 0.0036, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6759, 0.3233, 0.6753, param: [ 4.88668821  6.90981724  5.72223991 10.23422873], weights: [0.29645173 0.3103202  0.39322808], train_wt_loss:  37.8793, val_wt_loss: 36.6692, train_grp_loss: [11.48534544 13.70924433 13.00851675], val_grp_loss: [12.63429599 12.78898533 11.24426779], train_hist_grp_loss: [14.95428722 19.52631344 43.20482809], cur_train_grp_loss: [0.08834753 0.11520519 0.25506898], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6759, max_kl_dist_index: 0, max_train_grp_loss:  13.7092, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7890, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:37:14,991 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  169, train_loss:  12.6264, val_loss:  12.2231, grad_norm: 0.0036, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6759, 0.3233, 0.6753, param: [ 4.88657383  6.90942958  5.72251153 10.23434003], weights: [0.29623267 0.31017417 0.39359316], train_wt_loss:  37.8793, val_wt_loss: 36.6694, train_grp_loss: [11.48551092 13.70907254 13.00851513], val_grp_loss: [12.63447181 12.78885282 11.24435598], train_hist_grp_loss: [15.04263603 19.64151717 43.45989704], cur_train_grp_loss: [0.08834881 0.11520373 0.25506896], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6759, max_kl_dist_index: 0, max_train_grp_loss:  13.7091, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7889, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:37:16,041 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  170, train_loss:  12.6264, val_loss:  12.2232, grad_norm: 0.0036, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6759, 0.3233, 0.6753, param: [ 4.88645906  6.90904223  5.722783   10.2344526 ], weights: [0.2960136  0.31002804 0.39395836], train_wt_loss:  37.8793, val_wt_loss: 36.6695, train_grp_loss: [11.48567566 13.70890169 13.00851328], val_grp_loss: [12.63464694 12.78872145 11.24444384], train_hist_grp_loss: [15.13098611 19.75671946 43.71496597], cur_train_grp_loss: [0.08835008 0.11520229 0.25506892], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6759, max_kl_dist_index: 0, max_train_grp_loss:  13.7089, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7887, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:37:17,063 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  171, train_loss:  12.6264, val_loss:  12.2232, grad_norm: 0.0037, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6758, 0.3233, 0.6753, param: [ 4.88634387  6.90865519  5.72305433 10.23456644], weights: [0.29579454 0.30988179 0.39432367], train_wt_loss:  37.8793, val_wt_loss: 36.6696, train_grp_loss: [11.48583965 13.70873179 13.00851121], val_grp_loss: [12.63482139 12.78859124 11.24453137], train_hist_grp_loss: [15.21933746 19.87192031 43.97003486], cur_train_grp_loss: [0.08835135 0.11520085 0.25506889], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6758, max_kl_dist_index: 0, max_train_grp_loss:  13.7087, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7886, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:37:18,066 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  172, train_loss:  12.6264, val_loss:  12.2233, grad_norm: 0.0037, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6758, 0.3233, 0.6753, param: [ 4.88622828  6.90826845  5.72332551 10.23468156], weights: [0.29557547 0.30973544 0.39468909], train_wt_loss:  37.8793, val_wt_loss: 36.6698, train_grp_loss: [11.48600289 13.70856284 13.00850891], val_grp_loss: [12.63499516 12.78846219 11.24461858], train_hist_grp_loss: [15.30769007 19.98711974 44.2251037 ], cur_train_grp_loss: [0.08835261 0.11519943 0.25506885], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6758, max_kl_dist_index: 0, max_train_grp_loss:  13.7086, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7885, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:37:19,114 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  173, train_loss:  12.6264, val_loss:  12.2233, grad_norm: 0.0037, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6758, 0.3233, 0.6753, param: [ 4.88611228  6.90788201  5.72359655 10.23479796], weights: [0.2953564  0.30958897 0.39505463], train_wt_loss:  37.8793, val_wt_loss: 36.6699, train_grp_loss: [11.48616539 13.70839485 13.00850639], val_grp_loss: [12.63516824 12.78833428 11.24470545], train_hist_grp_loss: [15.39604394 20.10231775 44.48017251], cur_train_grp_loss: [0.08835387 0.11519801 0.2550688 ], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6758, max_kl_dist_index: 0, max_train_grp_loss:  13.7084, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7883, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:37:20,150 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  174, train_loss:  12.6265, val_loss:  12.2233, grad_norm: 0.0037, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6758, 0.3233, 0.6753, param: [ 4.88599588  6.90749589  5.72386744 10.23491564], weights: [0.29513733 0.30944239 0.39542028], train_wt_loss:  37.8794, val_wt_loss: 36.6700, train_grp_loss: [11.48632713 13.7082278  13.00850364], val_grp_loss: [12.63534063 12.78820754 11.244792  ], train_hist_grp_loss: [15.48439906 20.21751434 44.73524126], cur_train_grp_loss: [0.08835512 0.1151966  0.25506875], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6758, max_kl_dist_index: 0, max_train_grp_loss:  13.7082, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7882, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:37:21,172 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  175, train_loss:  12.6265, val_loss:  12.2234, grad_norm: 0.0038, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6758, 0.3233, 0.6753, param: [ 4.88587907  6.90711006  5.72413819 10.2350346 ], weights: [0.29491826 0.3092957  0.39578604], train_wt_loss:  37.8794, val_wt_loss: 36.6702, train_grp_loss: [11.48648812 13.70806171 13.00850066], val_grp_loss: [12.63551234 12.78808195 11.24487821], train_hist_grp_loss: [15.57275542 20.33270954 44.99030996], cur_train_grp_loss: [0.08835636 0.11519519 0.2550687 ], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6758, max_kl_dist_index: 0, max_train_grp_loss:  13.7081, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7881, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:37:22,219 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  176, train_loss:  12.6265, val_loss:  12.2234, grad_norm: 0.0038, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6758, 0.3233, 0.6753, param: [ 4.88576185  6.90672454  5.72440879 10.23515483], weights: [0.29469918 0.3091489  0.39615192], train_wt_loss:  37.8794, val_wt_loss: 36.6703, train_grp_loss: [11.48664837 13.70789657 13.00849746], val_grp_loss: [12.63568336 12.78795751 11.2449641 ], train_hist_grp_loss: [15.66111303 20.44790333 45.2453786 ], cur_train_grp_loss: [0.0883576  0.1151938  0.25506864], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6758, max_kl_dist_index: 0, max_train_grp_loss:  13.7079, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7880, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:37:23,235 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  177, train_loss:  12.6265, val_loss:  12.2235, grad_norm: 0.0038, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6758, 0.3233, 0.6753, param: [ 4.88564422  6.90633932  5.72467925 10.23527636], weights: [0.29448011 0.30900198 0.39651791], train_wt_loss:  37.8794, val_wt_loss: 36.6704, train_grp_loss: [11.48680786 13.70773239 13.00849403], val_grp_loss: [12.63585369 12.78783423 11.24504965], train_hist_grp_loss: [15.74947186 20.56309574 45.50044717], cur_train_grp_loss: [0.08835883 0.11519241 0.25506858], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6758, max_kl_dist_index: 0, max_train_grp_loss:  13.7077, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7878, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:37:24,268 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  178, train_loss:  12.6265, val_loss:  12.2235, grad_norm: 0.0038, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6758, 0.3233, 0.6753, param: [ 4.88552619  6.90595441  5.72494956 10.23539916], weights: [0.29426103 0.30885496 0.39688401], train_wt_loss:  37.8794, val_wt_loss: 36.6706, train_grp_loss: [11.4869666  13.70756916 13.00849038], val_grp_loss: [12.63602333 12.78771211 11.24513488], train_hist_grp_loss: [15.83783192 20.67828677 45.75551569], cur_train_grp_loss: [0.08836006 0.11519103 0.25506851], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6758, max_kl_dist_index: 0, max_train_grp_loss:  13.7076, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7877, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:37:25,302 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  179, train_loss:  12.6265, val_loss:  12.2236, grad_norm: 0.0038, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6758, 0.3233, 0.6753, param: [ 4.88540775  6.9055698   5.72521972 10.23552324], weights: [0.29404195 0.30870783 0.39725022], train_wt_loss:  37.8794, val_wt_loss: 36.6707, train_grp_loss: [11.48712459 13.70740688 13.0084865 ], val_grp_loss: [12.63619229 12.78759115 11.24521977], train_hist_grp_loss: [15.9261932  20.79347642 46.01058412], cur_train_grp_loss: [0.08836128 0.11518966 0.25506844], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6758, max_kl_dist_index: 0, max_train_grp_loss:  13.7074, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7876, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:37:26,323 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  180, train_loss:  12.6265, val_loss:  12.2236, grad_norm: 0.0039, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6758, 0.3233, 0.6753, param: [ 4.8852889   6.9051855   5.72548974 10.23564862], weights: [0.29382287 0.30856058 0.39761654], train_wt_loss:  37.8794, val_wt_loss: 36.6708, train_grp_loss: [11.48728183 13.70724556 13.00848239], val_grp_loss: [12.63636055 12.78747135 11.24530433], train_hist_grp_loss: [16.0145557  20.90866472 46.26565249], cur_train_grp_loss: [0.0883625  0.11518829 0.25506836], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6758, max_kl_dist_index: 0, max_train_grp_loss:  13.7072, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7875, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:37:27,364 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  181, train_loss:  12.6265, val_loss:  12.2237, grad_norm: 0.0039, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6758, 0.3233, 0.6753, param: [ 4.88516964  6.9048015   5.72575961 10.23577527], weights: [0.29360379 0.30841323 0.39798298], train_wt_loss:  37.8794, val_wt_loss: 36.6710, train_grp_loss: [11.48743831 13.70708519 13.00847805], val_grp_loss: [12.63652813 12.78735271 11.24538856], train_hist_grp_loss: [16.1029194  21.02385165 46.52072077], cur_train_grp_loss: [0.08836371 0.11518694 0.25506828], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6758, max_kl_dist_index: 0, max_train_grp_loss:  13.7071, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7874, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:37:28,421 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  182, train_loss:  12.6265, val_loss:  12.2237, grad_norm: 0.0039, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6758, 0.3233, 0.6752, param: [ 4.88504997  6.9044178   5.72602934 10.23590322], weights: [0.29338471 0.30826577 0.39834952], train_wt_loss:  37.8794, val_wt_loss: 36.6711, train_grp_loss: [11.48759404 13.70692578 13.00847349], val_grp_loss: [12.63669502 12.78723523 11.24547246], train_hist_grp_loss: [16.19128431 21.13903724 46.77578897], cur_train_grp_loss: [0.08836491 0.11518559 0.2550682 ], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6758, max_kl_dist_index: 0, max_train_grp_loss:  13.7069, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7872, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:37:29,478 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  183, train_loss:  12.6265, val_loss:  12.2237, grad_norm: 0.0039, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6758, 0.3233, 0.6752, param: [ 4.8849299   6.90403441  5.72629892 10.23603245], weights: [0.29316563 0.3081182  0.39871617], train_wt_loss:  37.8794, val_wt_loss: 36.6712, train_grp_loss: [11.48774902 13.70676733 13.0084687 ], val_grp_loss: [12.63686121 12.78711891 11.24555603], train_hist_grp_loss: [16.27965042 21.2542215  47.03085707], cur_train_grp_loss: [0.08836611 0.11518425 0.25506811], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6758, max_kl_dist_index: 0, max_train_grp_loss:  13.7068, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7871, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:37:30,500 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  184, train_loss:  12.6265, val_loss:  12.2238, grad_norm: 0.0040, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6758, 0.3233, 0.6752, param: [ 4.88480941  6.90365132  5.72656835 10.23616296], weights: [0.29294655 0.30797051 0.39908293], train_wt_loss:  37.8795, val_wt_loss: 36.6714, train_grp_loss: [11.48790324 13.70660983 13.00846368], val_grp_loss: [12.63702672 12.78700375 11.24563927], train_hist_grp_loss: [16.36801772 21.36940441 47.28592509], cur_train_grp_loss: [0.0883673  0.11518292 0.25506801], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6758, max_kl_dist_index: 0, max_train_grp_loss:  13.7066, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7870, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:37:31,545 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  185, train_loss:  12.6265, val_loss:  12.2238, grad_norm: 0.0040, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6758, 0.3233, 0.6752, param: [ 4.88468852  6.90326853  5.72683764 10.23629477], weights: [0.29272747 0.30782272 0.39944981], train_wt_loss:  37.8795, val_wt_loss: 36.6715, train_grp_loss: [11.48805671 13.70645329 13.00845844], val_grp_loss: [12.63719153 12.78688975 11.24572217], train_hist_grp_loss: [16.45638621 21.48458601 47.540993  ], cur_train_grp_loss: [0.08836849 0.1151816  0.25506792], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6758, max_kl_dist_index: 0, max_train_grp_loss:  13.7065, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7869, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:37:32,566 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  186, train_loss:  12.6265, val_loss:  12.2239, grad_norm: 0.0040, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6758, 0.3233, 0.6752, param: [ 4.88456722  6.90288604  5.72710678 10.23642787], weights: [0.29250839 0.30767482 0.39981678], train_wt_loss:  37.8795, val_wt_loss: 36.6716, train_grp_loss: [11.48820943 13.70629771 13.00845296], val_grp_loss: [12.63735566 12.78677692 11.24580474], train_hist_grp_loss: [16.54475588 21.59976629 47.79606082], cur_train_grp_loss: [0.08836967 0.11518028 0.25506781], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6758, max_kl_dist_index: 0, max_train_grp_loss:  13.7063, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7868, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:37:33,581 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  187, train_loss:  12.6265, val_loss:  12.2239, grad_norm: 0.0040, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6758, 0.3233, 0.6752, param: [ 4.88444551  6.90250386  5.72737578 10.23656226], weights: [0.29228931 0.30752682 0.40018387], train_wt_loss:  37.8795, val_wt_loss: 36.6718, train_grp_loss: [11.48836138 13.70614309 13.00844726], val_grp_loss: [12.63751909 12.78666525 11.24588698], train_hist_grp_loss: [16.63312672 21.71494526 48.05112852], cur_train_grp_loss: [0.08837084 0.11517897 0.25506771], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6758, max_kl_dist_index: 0, max_train_grp_loss:  13.7061, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7867, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:37:34,645 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  188, train_loss:  12.6265, val_loss:  12.2240, grad_norm: 0.0040, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6758, 0.3234, 0.6752, param: [ 4.88432338  6.90212198  5.72764462 10.23669794], weights: [0.29207023 0.3073787  0.40055107], train_wt_loss:  37.8795, val_wt_loss: 36.6719, train_grp_loss: [11.48851258 13.70598942 13.00844133], val_grp_loss: [12.63768182 12.78655475 11.24596889], train_hist_grp_loss: [16.72149873 21.83012293 48.30619611], cur_train_grp_loss: [0.08837201 0.11517767 0.25506759], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6758, max_kl_dist_index: 0, max_train_grp_loss:  13.7060, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7866, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:37:35,688 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  189, train_loss:  12.6265, val_loss:  12.2240, grad_norm: 0.0041, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6759, 0.3234, 0.6752, param: [ 4.88420085  6.9017404   5.72791332 10.23683492], weights: [0.29185115 0.30723048 0.40091837], train_wt_loss:  37.8795, val_wt_loss: 36.6720, train_grp_loss: [11.48866303 13.70583672 13.00843518], val_grp_loss: [12.63784387 12.78644542 11.24605046], train_hist_grp_loss: [16.8098719  21.94529932 48.56126359], cur_train_grp_loss: [0.08837317 0.11517638 0.25506748], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6759, max_kl_dist_index: 0, max_train_grp_loss:  13.7058, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7864, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:37:36,719 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  190, train_loss:  12.6265, val_loss:  12.2241, grad_norm: 0.0041, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6759, 0.3234, 0.6752, param: [ 4.88407791  6.90135913  5.72818188 10.23697319], weights: [0.29163208 0.30708214 0.40128578], train_wt_loss:  37.8795, val_wt_loss: 36.6722, train_grp_loss: [11.48881272 13.70568497 13.00842879], val_grp_loss: [12.63800522 12.78633725 11.2461317 ], train_hist_grp_loss: [16.89824623 22.06047441 48.81633095], cur_train_grp_loss: [0.08837433 0.1151751  0.25506736], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6759, max_kl_dist_index: 0, max_train_grp_loss:  13.7057, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7863, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:37:37,749 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  191, train_loss:  12.6265, val_loss:  12.2241, grad_norm: 0.0041, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6759, 0.3234, 0.6752, param: [ 4.88395455  6.90097816  5.72845028 10.23711275], weights: [0.291413  0.3069337 0.4016533], train_wt_loss:  37.8795, val_wt_loss: 36.6723, train_grp_loss: [11.48896165 13.70553419 13.00842217], val_grp_loss: [12.63816588 12.78623024 11.24621261], train_hist_grp_loss: [16.98662172 22.17564824 49.07139818], cur_train_grp_loss: [0.08837548 0.11517382 0.25506723], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6759, max_kl_dist_index: 0, max_train_grp_loss:  13.7055, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7862, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:37:38,793 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  192, train_loss:  12.6265, val_loss:  12.2241, grad_norm: 0.0041, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6759, 0.3234, 0.6752, param: [ 4.88383079  6.90059749  5.72871854 10.23725361], weights: [0.29119393 0.30678515 0.40202092], train_wt_loss:  37.8795, val_wt_loss: 36.6724, train_grp_loss: [11.48910982 13.70538437 13.00841533], val_grp_loss: [12.63832584 12.78612441 11.24629318], train_hist_grp_loss: [17.07499834 22.29082079 49.32646528], cur_train_grp_loss: [0.08837663 0.11517256 0.2550671 ], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6759, max_kl_dist_index: 0, max_train_grp_loss:  13.7054, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7861, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:37:39,821 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  193, train_loss:  12.6265, val_loss:  12.2242, grad_norm: 0.0042, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6759, 0.3234, 0.6752, param: [ 4.88370661  6.90021712  5.72898665 10.23739577], weights: [0.29097485 0.3066365  0.40238865], train_wt_loss:  37.8796, val_wt_loss: 36.6726, train_grp_loss: [11.48925723 13.70523551 13.00840826], val_grp_loss: [12.6384851  12.78601974 11.24637342], train_hist_grp_loss: [17.16337611 22.40599209 49.58153225], cur_train_grp_loss: [0.08837777 0.1151713  0.25506697], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6759, max_kl_dist_index: 0, max_train_grp_loss:  13.7052, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7860, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:37:40,855 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  194, train_loss:  12.6265, val_loss:  12.2242, grad_norm: 0.0042, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6759, 0.3234, 0.6752, param: [ 4.88358202  6.89983705  5.72925461 10.23753923], weights: [0.29075578 0.30648774 0.40275648], train_wt_loss:  37.8796, val_wt_loss: 36.6727, train_grp_loss: [11.48940389 13.70508761 13.00840095], val_grp_loss: [12.63864368 12.78591624 11.24645332], train_hist_grp_loss: [17.25175501 22.52116214 49.83659908], cur_train_grp_loss: [0.0883789  0.11517005 0.25506683], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6759, max_kl_dist_index: 0, max_train_grp_loss:  13.7051, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7859, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:37:41,897 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  195, train_loss:  12.6265, val_loss:  12.2243, grad_norm: 0.0042, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6759, 0.3234, 0.6752, param: [ 4.88345702  6.89945729  5.72952243 10.23768398], weights: [0.29053671 0.30633887 0.40312442], train_wt_loss:  37.8796, val_wt_loss: 36.6728, train_grp_loss: [11.48954978 13.70494068 13.00839342], val_grp_loss: [12.63880155 12.78581391 11.24653289], train_hist_grp_loss: [17.34013504 22.63633094 50.09166576], cur_train_grp_loss: [0.08838003 0.1151688  0.25506669], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6759, max_kl_dist_index: 0, max_train_grp_loss:  13.7049, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7858, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:37:42,937 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  196, train_loss:  12.6265, val_loss:  12.2243, grad_norm: 0.0042, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6759, 0.3234, 0.6752, param: [ 4.88333161  6.89907782  5.72979009 10.23783004], weights: [0.29031764 0.30618989 0.40349246], train_wt_loss:  37.8796, val_wt_loss: 36.6730, train_grp_loss: [11.48969492 13.7047947  13.00838566], val_grp_loss: [12.63895873 12.78571276 11.24661213], train_hist_grp_loss: [17.4285162  22.75149851 50.3467323 ], cur_train_grp_loss: [0.08838115 0.11516757 0.25506654], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6759, max_kl_dist_index: 0, max_train_grp_loss:  13.7048, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7857, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:37:43,964 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  197, train_loss:  12.6265, val_loss:  12.2244, grad_norm: 0.0042, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6759, 0.3234, 0.6752, param: [ 4.88320579  6.89869866  5.73005761 10.23797739], weights: [0.29009858 0.30604081 0.40386061], train_wt_loss:  37.8796, val_wt_loss: 36.6731, train_grp_loss: [11.4898393  13.7046497  13.00837767], val_grp_loss: [12.63911521 12.78561277 11.24669103], train_hist_grp_loss: [17.51689846 22.86666485 50.60179868], cur_train_grp_loss: [0.08838227 0.11516634 0.25506639], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6759, max_kl_dist_index: 0, max_train_grp_loss:  13.7046, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7856, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:37:45,019 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  198, train_loss:  12.6265, val_loss:  12.2244, grad_norm: 0.0043, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6759, 0.3234, 0.6752, param: [ 4.88307955  6.8983198   5.73032498 10.23812605], weights: [0.28987952 0.30589162 0.40422886], train_wt_loss:  37.8796, val_wt_loss: 36.6732, train_grp_loss: [11.48998291 13.70450565 13.00836944], val_grp_loss: [12.639271   12.78551396 11.24676959], train_hist_grp_loss: [17.60528184 22.98182997 50.85686491], cur_train_grp_loss: [0.08838338 0.11516512 0.25506623], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6759, max_kl_dist_index: 0, max_train_grp_loss:  13.7045, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7855, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:37:46,042 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  199, train_loss:  12.6265, val_loss:  12.2245, grad_norm: 0.0043, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6759, 0.3234, 0.6752, param: [ 4.8829529   6.89794124  5.7305922  10.23827601], weights: [0.28966046 0.30574233 0.40459722], train_wt_loss:  37.8796, val_wt_loss: 36.6734, train_grp_loss: [11.49012576 13.70436257 13.00836099], val_grp_loss: [12.63942609 12.78541632 11.24684782], train_hist_grp_loss: [17.69366633 23.09699389 51.11193098], cur_train_grp_loss: [0.08838448 0.11516391 0.25506607], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6759, max_kl_dist_index: 0, max_train_grp_loss:  13.7044, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7854, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:37:46,988 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1654] - INFO: Iteration:  199, train_loss:  12.6265, val_loss:  12.2245, grad_norm: 0.0043,  live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6759, 0.3234, 0.6752, param: [ 4.8829529   6.89794124  5.7305922  10.23827601], weights: [0.28966046 0.30574233 0.40459722], train_wt_loss:  37.8796, val_wt_loss: 36.6734, train_grp_loss: [11.49012576 13.70436257 13.00836099], val_grp_loss: [12.63942609 12.78541632 11.24684782], train_hist_grp_loss: [17.69366633 23.09699389 51.11193098], cur_train_grp_loss: [0.08838448 0.11516391 0.25506607], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6759, max_kl_dist_index: 0, max_train_grp_loss:  13.7044, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7854, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 00:37:47,217 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:388] - INFO: Policy parameter learned solely on the preference data rdpo: [ 4.8829529   6.89794124  5.7305922  10.23827601].
2024-10-07 00:37:47,571 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Uniform reward: 3.8511, 3.8511, 3.1970
2024-10-07 00:37:47,572 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Optimal reward: 3.8856, 7.2460, 3.3201
2024-10-07 00:37:47,572 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Policy reward: 3.8467, 7.1116, 3.3168
2024-10-07 00:37:47,573 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:402] - INFO: Reward Error: 0.0100, 0.0186, 0.0010
2024-10-07 00:37:48,290 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:417] - INFO: Optimal reward: 3.8856, 7.2460, 3.3201
Known param reward: [[3.885563232421875, 6.83889453125, 3.291370361328125], [3.493690185546875, 7.24602734375, 3.1155205078125], [3.850873046875, 7.10487548828125, 3.320061279296875]], Known param reward error: [[0.0, 0.05618703783269167, 0.008641683256769945], [0.10085360176489651, 0.0, 0.06160752898142066], [0.008927968346368324, 0.019479895503085456, 0.0]].
