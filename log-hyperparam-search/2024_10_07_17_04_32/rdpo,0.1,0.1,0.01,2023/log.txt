2024-10-07 17:08:16,554 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log-hyperparam-search/2024_10_07_17_04_32/rdpo,0.1,0.1,0.01,2023
2024-10-07 17:08:16,556 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2023
2024-10-07 17:08:16,557 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-10-07 17:08:16,646 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.2729, l2 distance: 29.4548, acc: 0.92.
2024-10-07 17:08:16,647 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-10-07 17:08:16,648 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [ 6.99981245 12.85202501  8.22225193 12.39503134]
2024-10-07 17:08:16,867 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.8503, 7.1054, 3.3198
2024-10-07 17:08:17,097 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1314] - INFO: unique_group_ids: {0, 1, 2}
2024-10-07 17:08:18,350 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  0, train_loss:  12.6261, val_loss:  12.2164, grad_norm: 0.4066, live_grad: 0.0000, reward_err: 0.0095, 0.0189, 0.0009, KL_dist: 0.6768, 0.3238, 0.6776, param: [ 4.90032933  6.97936371  5.67464935 10.2328601 ], weights: [0.33307434 0.33311119 0.33381446], train_wt_loss:  37.8784, val_wt_loss: 36.6493, train_grp_loss: [11.44733448 13.75119335 13.00574747], val_grp_loss: [12.59542693 12.82706442 11.22499376], train_hist_grp_loss: [0.1342519  0.14531453 0.3562142 ], cur_train_grp_loss: [0.1342519  0.14531453 0.3562142 ], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6776, max_kl_dist_index: 2, max_train_grp_loss:  13.7512, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8271, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.3562, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:08:19,423 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  1, train_loss:  12.6261, val_loss:  12.2165, grad_norm: 0.0000, live_grad: 0.0000, reward_err: 0.0095, 0.0189, 0.0009, KL_dist: 0.6768, 0.3238, 0.6776, param: [ 4.90027985  6.97892337  5.67494367 10.23277076], weights: [0.33285818 0.33298656 0.33415526], train_wt_loss:  37.8784, val_wt_loss: 36.6494, train_grp_loss: [11.4476184  13.75086888 13.00578093], val_grp_loss: [12.59571091 12.82674775 11.22513342], train_hist_grp_loss: [0.22230832 0.26087078 0.61122885], cur_train_grp_loss: [0.08805642 0.11555625 0.25501466], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6776, max_kl_dist_index: 2, max_train_grp_loss:  13.7509, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8267, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:08:20,537 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  2, train_loss:  12.6261, val_loss:  12.2165, grad_norm: 0.0000, live_grad: 0.0000, reward_err: 0.0095, 0.0189, 0.0009, KL_dist: 0.6768, 0.3238, 0.6775, param: [ 4.90023002  6.97848336  5.67523787 10.23268255], weights: [0.33264199 0.33286179 0.33449622], train_wt_loss:  37.8784, val_wt_loss: 36.6495, train_grp_loss: [11.44790165 13.75054529 13.0058142 ], val_grp_loss: [12.59599428 12.82643212 11.22527279], train_hist_grp_loss: [0.31036692 0.3764243  0.86624417], cur_train_grp_loss: [0.0880586  0.11555352 0.25501531], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6775, max_kl_dist_index: 2, max_train_grp_loss:  13.7505, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8264, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:08:21,631 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  3, train_loss:  12.6261, val_loss:  12.2165, grad_norm: 0.0000, live_grad: 0.0000, reward_err: 0.0095, 0.0189, 0.0009, KL_dist: 0.6767, 0.3238, 0.6775, param: [ 4.90017981  6.97804366  5.67553193 10.23259544], weights: [0.33242576 0.33273689 0.33483735], train_wt_loss:  37.8784, val_wt_loss: 36.6496, train_grp_loss: [11.44818425 13.75022257 13.00584728], val_grp_loss: [12.59627704 12.82611754 11.22541189], train_hist_grp_loss: [0.3984277  0.4919751  1.12126013], cur_train_grp_loss: [0.08806078 0.1155508  0.25501596], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6775, max_kl_dist_index: 2, max_train_grp_loss:  13.7502, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8261, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:08:22,753 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  4, train_loss:  12.6261, val_loss:  12.2166, grad_norm: 0.0001, live_grad: 0.0000, reward_err: 0.0095, 0.0189, 0.0009, KL_dist: 0.6767, 0.3238, 0.6775, param: [ 4.90012923  6.97760428  5.67582587 10.23250946], weights: [0.33220951 0.33261184 0.33517865], train_wt_loss:  37.8784, val_wt_loss: 36.6497, train_grp_loss: [11.44846618 13.74990072 13.00588016], val_grp_loss: [12.59655921 12.82580401 11.2255507 ], train_hist_grp_loss: [0.48649066 0.60752319 1.37627674], cur_train_grp_loss: [0.08806296 0.11554809 0.25501661], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6775, max_kl_dist_index: 2, max_train_grp_loss:  13.7499, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8258, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:08:23,834 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  5, train_loss:  12.6261, val_loss:  12.2166, grad_norm: 0.0001, live_grad: 0.0000, reward_err: 0.0095, 0.0189, 0.0009, KL_dist: 0.6767, 0.3238, 0.6775, param: [ 4.90007829  6.97716522  5.67611969 10.23242459], weights: [0.33199323 0.33248665 0.33552013], train_wt_loss:  37.8784, val_wt_loss: 36.6498, train_grp_loss: [11.44874744 13.74957974 13.00591285], val_grp_loss: [12.59684077 12.82549152 11.22568922], train_hist_grp_loss: [0.57455578 0.72306857 1.631294  ], cur_train_grp_loss: [0.08806512 0.11554538 0.25501726], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6775, max_kl_dist_index: 2, max_train_grp_loss:  13.7496, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8255, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:08:24,943 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  6, train_loss:  12.6261, val_loss:  12.2167, grad_norm: 0.0001, live_grad: 0.0000, reward_err: 0.0095, 0.0189, 0.0009, KL_dist: 0.6767, 0.3238, 0.6775, param: [ 4.90002697  6.97672648  5.67641337 10.23234085], weights: [0.33177691 0.33236132 0.33586177], train_wt_loss:  37.8784, val_wt_loss: 36.6500, train_grp_loss: [11.44902804 13.74925963 13.00594535], val_grp_loss: [12.59712172 12.82518008 11.22582746], train_hist_grp_loss: [0.66262307 0.83861126 1.8863119 ], cur_train_grp_loss: [0.08806729 0.11554269 0.2550179 ], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6775, max_kl_dist_index: 2, max_train_grp_loss:  13.7493, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8252, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:08:25,952 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  7, train_loss:  12.6261, val_loss:  12.2167, grad_norm: 0.0001, live_grad: 0.0000, reward_err: 0.0095, 0.0189, 0.0009, KL_dist: 0.6767, 0.3238, 0.6774, param: [ 4.89997529  6.97628806  5.67670693 10.23225822], weights: [0.33156057 0.33223585 0.33620359], train_wt_loss:  37.8784, val_wt_loss: 36.6501, train_grp_loss: [11.44930798 13.7489404  13.00597765], val_grp_loss: [12.59740207 12.82486968 11.22596542], train_hist_grp_loss: [0.75069252 0.95415125 2.14133044], cur_train_grp_loss: [0.08806945 0.11554    0.25501854], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6774, max_kl_dist_index: 2, max_train_grp_loss:  13.7489, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8249, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:08:26,984 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  8, train_loss:  12.6261, val_loss:  12.2167, grad_norm: 0.0001, live_grad: 0.0000, reward_err: 0.0095, 0.0189, 0.0009, KL_dist: 0.6767, 0.3238, 0.6774, param: [ 4.89992324  6.97584995  5.67700036 10.23217671], weights: [0.3313442  0.33211024 0.33654557], train_wt_loss:  37.8784, val_wt_loss: 36.6502, train_grp_loss: [11.44958725 13.74862204 13.00600976], val_grp_loss: [12.59768181 12.82456033 11.2261031 ], train_hist_grp_loss: [0.83876412 1.06968857 2.39634961], cur_train_grp_loss: [0.0880716  0.11553731 0.25501917], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6774, max_kl_dist_index: 2, max_train_grp_loss:  13.7486, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8246, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:08:27,982 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  9, train_loss:  12.6261, val_loss:  12.2168, grad_norm: 0.0002, live_grad: 0.0000, reward_err: 0.0095, 0.0189, 0.0009, KL_dist: 0.6767, 0.3237, 0.6774, param: [ 4.89987082  6.97541217  5.67729366 10.23209633], weights: [0.33112779 0.33198449 0.33688772], train_wt_loss:  37.8784, val_wt_loss: 36.6503, train_grp_loss: [11.44986586 13.74830455 13.00604168], val_grp_loss: [12.59796095 12.82425203 11.22624049], train_hist_grp_loss: [0.92683787 1.18522321 2.65136941], cur_train_grp_loss: [0.08807375 0.11553464 0.2550198 ], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6774, max_kl_dist_index: 2, max_train_grp_loss:  13.7483, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8243, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:08:28,980 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  10, train_loss:  12.6261, val_loss:  12.2168, grad_norm: 0.0002, live_grad: 0.0000, reward_err: 0.0095, 0.0189, 0.0009, KL_dist: 0.6767, 0.3237, 0.6774, param: [ 4.89981803  6.9749747   5.67758684 10.23201706], weights: [0.33091136 0.3318586  0.33723004], train_wt_loss:  37.8784, val_wt_loss: 36.6504, train_grp_loss: [11.4501438  13.74798793 13.0060734 ], val_grp_loss: [12.59823948 12.82394477 11.22637759], train_hist_grp_loss: [1.01491376 1.30075518 2.90638983], cur_train_grp_loss: [0.08807589 0.11553197 0.25502043], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6774, max_kl_dist_index: 2, max_train_grp_loss:  13.7480, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8239, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:08:29,980 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  11, train_loss:  12.6261, val_loss:  12.2168, grad_norm: 0.0002, live_grad: 0.0000, reward_err: 0.0095, 0.0189, 0.0009, KL_dist: 0.6767, 0.3237, 0.6774, param: [ 4.89976487  6.97453755  5.67787988 10.23193893], weights: [0.3306949  0.33173257 0.33757253], train_wt_loss:  37.8784, val_wt_loss: 36.6505, train_grp_loss: [11.45042108 13.74767219 13.00610493], val_grp_loss: [12.5985174  12.82363857 11.22651441], train_hist_grp_loss: [1.10299179 1.41628449 3.16141088], cur_train_grp_loss: [0.08807803 0.11552931 0.25502105], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6774, max_kl_dist_index: 2, max_train_grp_loss:  13.7477, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8236, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:08:30,996 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  12, train_loss:  12.6261, val_loss:  12.2169, grad_norm: 0.0002, live_grad: 0.0000, reward_err: 0.0095, 0.0189, 0.0009, KL_dist: 0.6767, 0.3237, 0.6773, param: [ 4.89971135  6.97410072  5.6781728  10.23186191], weights: [0.33047841 0.3316064  0.33791519], train_wt_loss:  37.8784, val_wt_loss: 36.6506, train_grp_loss: [11.45069768 13.74735733 13.00613626], val_grp_loss: [12.59879472 12.82333341 11.22665095], train_hist_grp_loss: [1.19107195 1.53181115 3.41643254], cur_train_grp_loss: [0.08808016 0.11552666 0.25502167], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6773, max_kl_dist_index: 2, max_train_grp_loss:  13.7474, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8233, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:08:32,036 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  13, train_loss:  12.6261, val_loss:  12.2169, grad_norm: 0.0002, live_grad: 0.0000, reward_err: 0.0095, 0.0189, 0.0009, KL_dist: 0.6766, 0.3237, 0.6773, param: [ 4.89965745  6.97366421  5.67846559 10.23178602], weights: [0.33026189 0.33148009 0.33825801], train_wt_loss:  37.8784, val_wt_loss: 36.6507, train_grp_loss: [11.45097362 13.74704334 13.0061674 ], val_grp_loss: [12.59907142 12.82302931 11.2267872 ], train_hist_grp_loss: [1.27915424 1.64733516 3.67145482], cur_train_grp_loss: [0.08808229 0.11552401 0.25502228], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6773, max_kl_dist_index: 2, max_train_grp_loss:  13.7470, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8230, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:08:33,127 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  14, train_loss:  12.6261, val_loss:  12.2169, grad_norm: 0.0003, live_grad: 0.0000, reward_err: 0.0095, 0.0189, 0.0009, KL_dist: 0.6766, 0.3237, 0.6773, param: [ 4.89960318  6.97322801  5.67875825 10.23171126], weights: [0.33004534 0.33135365 0.33860101], train_wt_loss:  37.8784, val_wt_loss: 36.6508, train_grp_loss: [11.4512489  13.74673023 13.00619835], val_grp_loss: [12.59934752 12.82272626 11.22692316], train_hist_grp_loss: [1.36723865 1.76285653 3.92647771], cur_train_grp_loss: [0.08808441 0.11552137 0.25502289], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6773, max_kl_dist_index: 2, max_train_grp_loss:  13.7467, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8227, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:08:34,148 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  15, train_loss:  12.6261, val_loss:  12.2170, grad_norm: 0.0003, live_grad: 0.0000, reward_err: 0.0095, 0.0189, 0.0009, KL_dist: 0.6766, 0.3237, 0.6773, param: [ 4.89954854  6.97279214  5.67905078 10.23163763], weights: [0.32982877 0.33122706 0.33894417], train_wt_loss:  37.8784, val_wt_loss: 36.6509, train_grp_loss: [11.4515235  13.74641799 13.0062291 ], val_grp_loss: [12.59962301 12.82242425 11.22705883], train_hist_grp_loss: [1.45532518 1.87837527 4.18150121], cur_train_grp_loss: [0.08808653 0.11551874 0.2550235 ], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6773, max_kl_dist_index: 2, max_train_grp_loss:  13.7464, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8224, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:08:35,174 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  16, train_loss:  12.6261, val_loss:  12.2170, grad_norm: 0.0003, live_grad: 0.0000, reward_err: 0.0095, 0.0189, 0.0009, KL_dist: 0.6766, 0.3237, 0.6773, param: [ 4.89949353  6.97235658  5.67934319 10.23156512], weights: [0.32961216 0.33110034 0.33928749], train_wt_loss:  37.8784, val_wt_loss: 36.6510, train_grp_loss: [11.45179743 13.74610663 13.00625965], val_grp_loss: [12.59989789 12.8221233  11.22719422], train_hist_grp_loss: [1.54341382 1.99389139 4.43652531], cur_train_grp_loss: [0.08808864 0.11551612 0.2550241 ], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6773, max_kl_dist_index: 2, max_train_grp_loss:  13.7461, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8221, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:08:36,198 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  17, train_loss:  12.6261, val_loss:  12.2170, grad_norm: 0.0003, live_grad: 0.0000, reward_err: 0.0095, 0.0189, 0.0009, KL_dist: 0.6766, 0.3237, 0.6772, param: [ 4.89943814  6.97192134  5.67963546 10.23149375], weights: [0.32939553 0.33097348 0.33963099], train_wt_loss:  37.8784, val_wt_loss: 36.6511, train_grp_loss: [11.4520707  13.74579614 13.00629001], val_grp_loss: [12.60017216 12.8218234  11.22732933], train_hist_grp_loss: [1.63150457 2.10940489 4.69155001], cur_train_grp_loss: [0.08809075 0.1155135  0.2550247 ], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6772, max_kl_dist_index: 2, max_train_grp_loss:  13.7458, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8218, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:08:37,255 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  18, train_loss:  12.6261, val_loss:  12.2171, grad_norm: 0.0003, live_grad: 0.0000, reward_err: 0.0095, 0.0189, 0.0009, KL_dist: 0.6766, 0.3237, 0.6772, param: [ 4.89938239  6.97148642  5.67992761 10.2314235 ], weights: [0.32917887 0.33084648 0.33997465], train_wt_loss:  37.8784, val_wt_loss: 36.6512, train_grp_loss: [11.45234329 13.74548653 13.00632018], val_grp_loss: [12.60044582 12.82152456 11.22746414], train_hist_grp_loss: [1.71959743 2.22491578 4.9465753 ], cur_train_grp_loss: [0.08809285 0.11551089 0.25502529], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6772, max_kl_dist_index: 2, max_train_grp_loss:  13.7455, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8215, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:08:38,297 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  19, train_loss:  12.6261, val_loss:  12.2171, grad_norm: 0.0004, live_grad: 0.0000, reward_err: 0.0095, 0.0189, 0.0009, KL_dist: 0.6766, 0.3237, 0.6772, param: [ 4.89932627  6.97105181  5.68021963 10.23135439], weights: [0.32896218 0.33071934 0.34031848], train_wt_loss:  37.8784, val_wt_loss: 36.6514, train_grp_loss: [11.45261522 13.7451778  13.00635015], val_grp_loss: [12.60071887 12.82122677 11.22759867], train_hist_grp_loss: [1.80769237 2.34042407 5.20160119], cur_train_grp_loss: [0.08809495 0.11550829 0.25502589], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6772, max_kl_dist_index: 2, max_train_grp_loss:  13.7452, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8212, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:08:39,362 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  20, train_loss:  12.6261, val_loss:  12.2172, grad_norm: 0.0004, live_grad: 0.0000, reward_err: 0.0095, 0.0189, 0.0009, KL_dist: 0.6766, 0.3237, 0.6772, param: [ 4.89926977  6.97061753  5.68051152 10.2312864 ], weights: [0.32874546 0.33059207 0.34066247], train_wt_loss:  37.8784, val_wt_loss: 36.6515, train_grp_loss: [11.45288647 13.74486995 13.00637992], val_grp_loss: [12.6009913  12.82093003 11.22773291], train_hist_grp_loss: [1.89578941 2.45592977 5.45662766], cur_train_grp_loss: [0.08809704 0.1155057  0.25502647], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6772, max_kl_dist_index: 2, max_train_grp_loss:  13.7449, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8209, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:08:40,397 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  21, train_loss:  12.6261, val_loss:  12.2172, grad_norm: 0.0004, live_grad: 0.0000, reward_err: 0.0095, 0.0189, 0.0009, KL_dist: 0.6766, 0.3237, 0.6772, param: [ 4.8992129   6.97018356  5.68080328 10.23121955], weights: [0.32852872 0.33046465 0.34100663], train_wt_loss:  37.8784, val_wt_loss: 36.6516, train_grp_loss: [11.45315705 13.74456298 13.0064095 ], val_grp_loss: [12.60126313 12.82063435 11.22786686], train_hist_grp_loss: [1.98388854 2.57143288 5.71165472], cur_train_grp_loss: [0.08809913 0.11550311 0.25502706], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6772, max_kl_dist_index: 2, max_train_grp_loss:  13.7446, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8206, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:08:41,399 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  22, train_loss:  12.6261, val_loss:  12.2172, grad_norm: 0.0004, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6766, 0.3237, 0.6772, param: [ 4.89915566  6.96974991  5.68109491 10.23115384], weights: [0.32831195 0.3303371  0.34135095], train_wt_loss:  37.8784, val_wt_loss: 36.6517, train_grp_loss: [11.45342696 13.74425689 13.00643888], val_grp_loss: [12.60153434 12.82033972 11.22800052], train_hist_grp_loss: [2.07198975 2.68693341 5.96668236], cur_train_grp_loss: [0.08810121 0.11550053 0.25502764], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6772, max_kl_dist_index: 2, max_train_grp_loss:  13.7443, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8203, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:08:42,434 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  23, train_loss:  12.6261, val_loss:  12.2173, grad_norm: 0.0005, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6766, 0.3237, 0.6771, param: [ 4.89909805  6.96931658  5.68138641 10.23108926], weights: [0.32809515 0.33020941 0.34169544], train_wt_loss:  37.8784, val_wt_loss: 36.6518, train_grp_loss: [11.45369619 13.74395167 13.00646806], val_grp_loss: [12.60180493 12.82004615 11.2281339 ], train_hist_grp_loss: [2.16009303 2.80243136 6.22171057], cur_train_grp_loss: [0.08810328 0.11549796 0.25502821], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6771, max_kl_dist_index: 2, max_train_grp_loss:  13.7440, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8200, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:08:43,446 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  24, train_loss:  12.6261, val_loss:  12.2173, grad_norm: 0.0005, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6765, 0.3237, 0.6771, param: [ 4.89904007  6.96888356  5.68167779 10.23102581], weights: [0.32787832 0.33008158 0.3420401 ], train_wt_loss:  37.8784, val_wt_loss: 36.6519, train_grp_loss: [11.45396476 13.74364734 13.00649705], val_grp_loss: [12.60207492 12.81975364 11.22826698], train_hist_grp_loss: [2.24819839 2.91792676 6.47673936], cur_train_grp_loss: [0.08810536 0.11549539 0.25502879], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6771, max_kl_dist_index: 2, max_train_grp_loss:  13.7436, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8198, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:08:44,443 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  25, train_loss:  12.6261, val_loss:  12.2173, grad_norm: 0.0005, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6765, 0.3237, 0.6771, param: [ 4.89898171  6.96845087  5.68196903 10.23096351], weights: [0.32766147 0.32995362 0.34238492], train_wt_loss:  37.8784, val_wt_loss: 36.6520, train_grp_loss: [11.45423265 13.74334389 13.00652584], val_grp_loss: [12.60234429 12.81946218 11.22839978], train_hist_grp_loss: [2.33630581 3.03341959 6.73176871], cur_train_grp_loss: [0.08810742 0.11549283 0.25502935], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6771, max_kl_dist_index: 2, max_train_grp_loss:  13.7433, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8195, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:08:45,478 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  26, train_loss:  12.6261, val_loss:  12.2174, grad_norm: 0.0005, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6765, 0.3237, 0.6771, param: [ 4.89892298  6.96801849  5.68226014 10.23090234], weights: [0.32744458 0.32982552 0.3427299 ], train_wt_loss:  37.8784, val_wt_loss: 36.6521, train_grp_loss: [11.45449986 13.74304131 13.00655444], val_grp_loss: [12.60261304 12.81917179 11.22853228], train_hist_grp_loss: [2.42441529 3.14890987 6.98679863], cur_train_grp_loss: [0.08810948 0.11549028 0.25502992], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6771, max_kl_dist_index: 2, max_train_grp_loss:  13.7430, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8192, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:08:46,482 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  27, train_loss:  12.6261, val_loss:  12.2174, grad_norm: 0.0005, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6765, 0.3237, 0.6771, param: [ 4.89886388  6.96758643  5.68255113 10.2308423 ], weights: [0.32722768 0.32969728 0.34307504], train_wt_loss:  37.8784, val_wt_loss: 36.6522, train_grp_loss: [11.4547664  13.74273962 13.00658283], val_grp_loss: [12.60288118 12.81888245 11.2286645 ], train_hist_grp_loss: [2.51252683 3.26439762 7.24182911], cur_train_grp_loss: [0.08811154 0.11548774 0.25503048], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6771, max_kl_dist_index: 2, max_train_grp_loss:  13.7427, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8189, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:08:47,526 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  28, train_loss:  12.6261, val_loss:  12.2174, grad_norm: 0.0006, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6765, 0.3236, 0.6770, param: [ 4.8988044   6.96715468  5.68284199 10.23078341], weights: [0.32701074 0.3295689  0.34342035], train_wt_loss:  37.8784, val_wt_loss: 36.6523, train_grp_loss: [11.45503226 13.74243881 13.00661103], val_grp_loss: [12.60314871 12.81859417 11.22879643], train_hist_grp_loss: [2.60064042 3.37988282 7.49686014], cur_train_grp_loss: [0.08811359 0.11548521 0.25503104], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6770, max_kl_dist_index: 2, max_train_grp_loss:  13.7424, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8186, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:08:48,537 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  29, train_loss:  12.6261, val_loss:  12.2175, grad_norm: 0.0006, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6765, 0.3236, 0.6770, param: [ 4.89874455  6.96672326  5.68313271 10.23072566], weights: [0.32679378 0.32944039 0.34376583], train_wt_loss:  37.8784, val_wt_loss: 36.6525, train_grp_loss: [11.45529745 13.74213889 13.00663904], val_grp_loss: [12.60341561 12.81830695 11.22892806], train_hist_grp_loss: [2.68875605 3.4953655  7.75189173], cur_train_grp_loss: [0.08811563 0.11548268 0.25503159], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6770, max_kl_dist_index: 2, max_train_grp_loss:  13.7421, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8183, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:08:49,550 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  30, train_loss:  12.6261, val_loss:  12.2175, grad_norm: 0.0006, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6765, 0.3236, 0.6770, param: [ 4.89868433  6.96629215  5.68342331 10.23066905], weights: [0.32657679 0.32931174 0.34411146], train_wt_loss:  37.8784, val_wt_loss: 36.6526, train_grp_loss: [11.45556196 13.74183984 13.00666684], val_grp_loss: [12.60368191 12.81802079 11.22905941], train_hist_grp_loss: [2.77687372 3.61084566 8.00692387], cur_train_grp_loss: [0.08811767 0.11548016 0.25503214], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6770, max_kl_dist_index: 2, max_train_grp_loss:  13.7418, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8180, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:08:50,543 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  31, train_loss:  12.6261, val_loss:  12.2176, grad_norm: 0.0006, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6765, 0.3236, 0.6770, param: [ 4.89862373  6.96586136  5.68371378 10.23061358], weights: [0.32635978 0.32918296 0.34445726], train_wt_loss:  37.8784, val_wt_loss: 36.6527, train_grp_loss: [11.4558258  13.74154168 13.00669444], val_grp_loss: [12.60394758 12.81773569 11.22919046], train_hist_grp_loss: [2.86499343 3.72632331 8.26195655], cur_train_grp_loss: [0.08811971 0.11547765 0.25503268], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6770, max_kl_dist_index: 2, max_train_grp_loss:  13.7415, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8177, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:08:51,550 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  32, train_loss:  12.6261, val_loss:  12.2176, grad_norm: 0.0006, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6765, 0.3236, 0.6770, param: [ 4.89856276  6.96543089  5.68400411 10.23055926], weights: [0.32614274 0.32905403 0.34480322], train_wt_loss:  37.8784, val_wt_loss: 36.6528, train_grp_loss: [11.45608895 13.7412444  13.00672185], val_grp_loss: [12.60421264 12.81745165 11.22932122], train_hist_grp_loss: [2.95311517 3.84179845 8.51698978], cur_train_grp_loss: [0.08812174 0.11547514 0.25503322], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6770, max_kl_dist_index: 2, max_train_grp_loss:  13.7412, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8175, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:08:52,564 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  33, train_loss:  12.6261, val_loss:  12.2176, grad_norm: 0.0007, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6765, 0.3236, 0.6770, param: [ 4.89850141  6.96500074  5.68429432 10.23050608], weights: [0.32592568 0.32892498 0.34514935], train_wt_loss:  37.8784, val_wt_loss: 36.6529, train_grp_loss: [11.45635143 13.74094801 13.00674906], val_grp_loss: [12.60447707 12.81716868 11.22945169], train_hist_grp_loss: [3.04123893 3.95727109 8.77202354], cur_train_grp_loss: [0.08812376 0.11547264 0.25503376], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6770, max_kl_dist_index: 2, max_train_grp_loss:  13.7409, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8172, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:08:53,575 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  34, train_loss:  12.6261, val_loss:  12.2177, grad_norm: 0.0007, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6765, 0.3236, 0.6769, param: [ 4.89843969  6.9645709   5.6845844  10.23045404], weights: [0.32570859 0.32879578 0.34549563], train_wt_loss:  37.8784, val_wt_loss: 36.6530, train_grp_loss: [11.45661323 13.7406525  13.00677607], val_grp_loss: [12.60474089 12.81688677 11.22958187], train_hist_grp_loss: [3.12936471 4.07274124 9.02705783], cur_train_grp_loss: [0.08812578 0.11547015 0.2550343 ], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6769, max_kl_dist_index: 2, max_train_grp_loss:  13.7407, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8169, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:08:54,579 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  35, train_loss:  12.6261, val_loss:  12.2177, grad_norm: 0.0007, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6765, 0.3236, 0.6769, param: [ 4.89837759  6.96414138  5.68487435 10.23040316], weights: [0.32549147 0.32866645 0.34584208], train_wt_loss:  37.8784, val_wt_loss: 36.6531, train_grp_loss: [11.45687436 13.74035788 13.00680288], val_grp_loss: [12.60500409 12.81660592 11.22971175], train_hist_grp_loss: [3.2174925  4.18820891 9.28209266], cur_train_grp_loss: [0.08812779 0.11546767 0.25503482], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6769, max_kl_dist_index: 2, max_train_grp_loss:  13.7404, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8166, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:08:55,572 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  36, train_loss:  12.6261, val_loss:  12.2177, grad_norm: 0.0007, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6764, 0.3236, 0.6769, param: [ 4.89831512  6.96371218  5.68516416 10.23035341], weights: [0.32527433 0.32853699 0.34618869], train_wt_loss:  37.8784, val_wt_loss: 36.6532, train_grp_loss: [11.4571348  13.74006414 13.00682949], val_grp_loss: [12.60526668 12.81632614 11.22984135], train_hist_grp_loss: [3.3056223  4.3036741  9.53712801], cur_train_grp_loss: [0.0881298  0.11546519 0.25503535], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6769, max_kl_dist_index: 2, max_train_grp_loss:  13.7401, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8163, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:08:56,571 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  37, train_loss:  12.6261, val_loss:  12.2178, grad_norm: 0.0007, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6764, 0.3236, 0.6769, param: [ 4.89825227  6.96328329  5.68545385 10.23030482], weights: [0.32505716 0.32840739 0.34653546], train_wt_loss:  37.8784, val_wt_loss: 36.6533, train_grp_loss: [11.45739456 13.73977129 13.00685591], val_grp_loss: [12.60552864 12.81604742 11.22997065], train_hist_grp_loss: [3.39375411 4.41913683 9.79216388], cur_train_grp_loss: [0.08813181 0.11546272 0.25503587], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6769, max_kl_dist_index: 2, max_train_grp_loss:  13.7398, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8160, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:08:57,650 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  38, train_loss:  12.6261, val_loss:  12.2178, grad_norm: 0.0008, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6764, 0.3236, 0.6769, param: [ 4.89818905  6.96285472  5.68574341 10.23025738], weights: [0.32483997 0.32827765 0.34688238], train_wt_loss:  37.8784, val_wt_loss: 36.6535, train_grp_loss: [11.45765364 13.73947932 13.00688212], val_grp_loss: [12.60578998 12.81576976 11.23009965], train_hist_grp_loss: [ 3.48188792  4.53459709 10.04720027], cur_train_grp_loss: [0.0881338  0.11546026 0.25503639], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6769, max_kl_dist_index: 2, max_train_grp_loss:  13.7395, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8158, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:08:58,646 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  39, train_loss:  12.6261, val_loss:  12.2179, grad_norm: 0.0008, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6764, 0.3236, 0.6768, param: [ 4.89812545  6.96242647  5.68603283 10.23021108], weights: [0.32462275 0.32814778 0.34722947], train_wt_loss:  37.8784, val_wt_loss: 36.6536, train_grp_loss: [11.45791204 13.73918824 13.00690813], val_grp_loss: [12.6060507  12.81549318 11.23022837], train_hist_grp_loss: [ 3.57002371  4.6500549  10.30223718], cur_train_grp_loss: [0.0881358  0.11545781 0.2550369 ], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6768, max_kl_dist_index: 2, max_train_grp_loss:  13.7392, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8155, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:08:59,634 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  40, train_loss:  12.6261, val_loss:  12.2179, grad_norm: 0.0008, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6764, 0.3236, 0.6768, param: [ 4.89806148  6.96199854  5.68632213 10.23016594], weights: [0.32440551 0.32801777 0.34757672], train_wt_loss:  37.8784, val_wt_loss: 36.6537, train_grp_loss: [11.45816976 13.73889805 13.00693395], val_grp_loss: [12.60631079 12.81521765 11.23035678], train_hist_grp_loss: [ 3.6581615   4.76551026 10.55727459], cur_train_grp_loss: [0.08813778 0.11545536 0.25503741], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6768, max_kl_dist_index: 2, max_train_grp_loss:  13.7389, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8152, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:09:00,653 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  41, train_loss:  12.6261, val_loss:  12.2179, grad_norm: 0.0008, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6764, 0.3236, 0.6768, param: [ 4.89799713  6.96157092  5.68661129 10.23012195], weights: [0.32418824 0.32788763 0.34792413], train_wt_loss:  37.8784, val_wt_loss: 36.6538, train_grp_loss: [11.45842679 13.73860874 13.00695956], val_grp_loss: [12.60657027 12.8149432  11.23048491], train_hist_grp_loss: [ 3.74630126  4.88096319 10.81231251], cur_train_grp_loss: [0.08813977 0.11545292 0.25503792], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6768, max_kl_dist_index: 2, max_train_grp_loss:  13.7386, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8149, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:09:01,646 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  42, train_loss:  12.6262, val_loss:  12.2180, grad_norm: 0.0008, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6764, 0.3236, 0.6768, param: [ 4.8979324   6.96114362  5.68690033 10.23007911], weights: [0.32397095 0.32775735 0.3482717 ], train_wt_loss:  37.8785, val_wt_loss: 36.6539, train_grp_loss: [11.45868315 13.73832032 13.00698497], val_grp_loss: [12.60682912 12.81466981 11.23061274], train_hist_grp_loss: [ 3.83444301  4.99641368 11.06735093], cur_train_grp_loss: [0.08814174 0.11545049 0.25503842], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6768, max_kl_dist_index: 2, max_train_grp_loss:  13.7383, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8147, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:09:02,670 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  43, train_loss:  12.6262, val_loss:  12.2180, grad_norm: 0.0009, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6764, 0.3236, 0.6768, param: [ 4.8978673   6.96071664  5.68718923 10.23003742], weights: [0.32375363 0.32762694 0.34861943], train_wt_loss:  37.8785, val_wt_loss: 36.6540, train_grp_loss: [11.45893882 13.73803279 13.00701019], val_grp_loss: [12.60708735 12.8143975  11.23074028], train_hist_grp_loss: [ 3.92258673  5.11186175 11.32238986], cur_train_grp_loss: [0.08814372 0.11544807 0.25503892], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6768, max_kl_dist_index: 2, max_train_grp_loss:  13.7380, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8144, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:09:03,671 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  44, train_loss:  12.6262, val_loss:  12.2180, grad_norm: 0.0009, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6764, 0.3236, 0.6768, param: [ 4.89780182  6.96028998  5.68747801 10.22999689], weights: [0.32353629 0.32749639 0.34896731], train_wt_loss:  37.8785, val_wt_loss: 36.6541, train_grp_loss: [11.4591938  13.73774615 13.0070352 ], val_grp_loss: [12.60734496 12.81412625 11.23086752], train_hist_grp_loss: [ 4.01073241  5.2273074  11.57742927], cur_train_grp_loss: [0.08814568 0.11544565 0.25503942], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6768, max_kl_dist_index: 2, max_train_grp_loss:  13.7377, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8141, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:09:04,668 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  45, train_loss:  12.6262, val_loss:  12.2181, grad_norm: 0.0009, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6764, 0.3236, 0.6767, param: [ 4.89773596  6.95986363  5.68776665 10.22995752], weights: [0.32331893 0.32736571 0.34931536], train_wt_loss:  37.8785, val_wt_loss: 36.6542, train_grp_loss: [11.45944811 13.7374604  13.00706001], val_grp_loss: [12.60760194 12.81385607 11.23099446], train_hist_grp_loss: [ 4.09888005  5.34275065 11.83246918], cur_train_grp_loss: [0.08814764 0.11544324 0.25503991], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6767, max_kl_dist_index: 2, max_train_grp_loss:  13.7375, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8139, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:09:05,691 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  46, train_loss:  12.6262, val_loss:  12.2181, grad_norm: 0.0009, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6764, 0.3236, 0.6767, param: [ 4.89766973  6.9594376   5.68805516 10.2299193 ], weights: [0.32310154 0.3272349  0.34966356], train_wt_loss:  37.8785, val_wt_loss: 36.6544, train_grp_loss: [11.45970172 13.73717554 13.00708462], val_grp_loss: [12.6078583  12.81358696 11.23112111], train_hist_grp_loss: [ 4.18702965  5.45819149 12.08750957], cur_train_grp_loss: [0.0881496  0.11544084 0.25504039], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6767, max_kl_dist_index: 2, max_train_grp_loss:  13.7372, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8136, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:09:06,741 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  47, train_loss:  12.6262, val_loss:  12.2182, grad_norm: 0.0010, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6764, 0.3236, 0.6767, param: [ 4.89760311  6.95901188  5.68834354 10.22988224], weights: [0.32288413 0.32710395 0.35001192], train_wt_loss:  37.8785, val_wt_loss: 36.6545, train_grp_loss: [11.45995466 13.73689157 13.00710903], val_grp_loss: [12.60811403 12.81331892 11.23124747], train_hist_grp_loss: [ 4.27518121  5.57362994 12.34255044], cur_train_grp_loss: [0.08815155 0.11543845 0.25504087], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6767, max_kl_dist_index: 2, max_train_grp_loss:  13.7369, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8133, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:09:07,742 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  48, train_loss:  12.6262, val_loss:  12.2182, grad_norm: 0.0010, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6763, 0.3236, 0.6767, param: [ 4.89753612  6.95858648  5.68863179 10.22984634], weights: [0.32266669 0.32697287 0.35036044], train_wt_loss:  37.8785, val_wt_loss: 36.6546, train_grp_loss: [11.4602069  13.73660849 13.00713323], val_grp_loss: [12.60836914 12.81305196 11.23137353], train_hist_grp_loss: [ 4.3633347   5.68906601 12.5975918 ], cur_train_grp_loss: [0.0881535  0.11543606 0.25504135], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6767, max_kl_dist_index: 2, max_train_grp_loss:  13.7366, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8131, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:09:08,758 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  49, train_loss:  12.6262, val_loss:  12.2182, grad_norm: 0.0010, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6763, 0.3236, 0.6767, param: [ 4.89746876  6.9581614   5.68891991 10.22981159], weights: [0.32244923 0.32684165 0.35070911], train_wt_loss:  37.8785, val_wt_loss: 36.6547, train_grp_loss: [11.46045846 13.7363263  13.00715724], val_grp_loss: [12.60862362 12.81278606 11.23149929], train_hist_grp_loss: [ 4.45149014  5.80449969 12.85263363], cur_train_grp_loss: [0.08815544 0.11543368 0.25504183], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6767, max_kl_dist_index: 2, max_train_grp_loss:  13.7363, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8128, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:09:09,759 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  50, train_loss:  12.6262, val_loss:  12.2183, grad_norm: 0.0010, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6763, 0.3236, 0.6767, param: [ 4.89740101  6.95773664  5.68920789 10.22977801], weights: [0.32223175 0.3267103  0.35105795], train_wt_loss:  37.8785, val_wt_loss: 36.6548, train_grp_loss: [11.46070933 13.73604501 13.00718104], val_grp_loss: [12.60887747 12.81252124 11.23162475], train_hist_grp_loss: [ 4.53964751  5.919931   13.10767592], cur_train_grp_loss: [0.08815737 0.11543131 0.2550423 ], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6767, max_kl_dist_index: 2, max_train_grp_loss:  13.7360, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8125, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:09:10,772 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  51, train_loss:  12.6262, val_loss:  12.2183, grad_norm: 0.0010, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6763, 0.3235, 0.6766, param: [ 4.89733289  6.95731219  5.68949575 10.22974559], weights: [0.32201425 0.32657882 0.35140693], train_wt_loss:  37.8785, val_wt_loss: 36.6549, train_grp_loss: [11.46095952 13.7357646  13.00720464], val_grp_loss: [12.6091307  12.8122575  11.23174992], train_hist_grp_loss: [ 4.62780682  6.03535995 13.36271869], cur_train_grp_loss: [0.0881593  0.11542895 0.25504277], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6766, max_kl_dist_index: 2, max_train_grp_loss:  13.7358, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8123, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:09:11,772 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  52, train_loss:  12.6262, val_loss:  12.2183, grad_norm: 0.0011, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6763, 0.3235, 0.6766, param: [ 4.89726438  6.95688806  5.68978347 10.22971433], weights: [0.32179672 0.3264472  0.35175608], train_wt_loss:  37.8785, val_wt_loss: 36.6550, train_grp_loss: [11.46120902 13.73548509 13.00722804], val_grp_loss: [12.6093833  12.81199482 11.23187479], train_hist_grp_loss: [ 4.71596804  6.15078655 13.61776192], cur_train_grp_loss: [0.08816123 0.11542659 0.25504323], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6766, max_kl_dist_index: 2, max_train_grp_loss:  13.7355, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8120, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:09:12,774 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  53, train_loss:  12.6262, val_loss:  12.2184, grad_norm: 0.0011, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6763, 0.3235, 0.6766, param: [ 4.8971955   6.95646424  5.69007106 10.22968423], weights: [0.32157917 0.32631545 0.35210538], train_wt_loss:  37.8785, val_wt_loss: 36.6551, train_grp_loss: [11.46145783 13.73520647 13.00725124], val_grp_loss: [12.60963527 12.81173322 11.23199936], train_hist_grp_loss: [ 4.80413119  6.26621079 13.87280561], cur_train_grp_loss: [0.08816315 0.11542424 0.25504369], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6766, max_kl_dist_index: 2, max_train_grp_loss:  13.7352, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8117, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:09:13,787 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  54, train_loss:  12.6262, val_loss:  12.2184, grad_norm: 0.0011, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6763, 0.3235, 0.6766, param: [ 4.89712624  6.95604075  5.69035852 10.2296553 ], weights: [0.3213616  0.32618357 0.35245484], train_wt_loss:  37.8785, val_wt_loss: 36.6553, train_grp_loss: [11.46170595 13.73492875 13.00727423], val_grp_loss: [12.60988661 12.8114727  11.23212364], train_hist_grp_loss: [ 4.89229625  6.38163269 14.12784975], cur_train_grp_loss: [0.08816506 0.1154219  0.25504414], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6766, max_kl_dist_index: 2, max_train_grp_loss:  13.7349, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8115, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:09:14,782 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  55, train_loss:  12.6262, val_loss:  12.2185, grad_norm: 0.0011, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6763, 0.3235, 0.6766, param: [ 4.8970566   6.95561756  5.69064585 10.22962754], weights: [0.321144   0.32605155 0.35280445], train_wt_loss:  37.8785, val_wt_loss: 36.6554, train_grp_loss: [11.46195338 13.73465192 13.00729702], val_grp_loss: [12.61013733 12.81121325 11.23224762], train_hist_grp_loss: [ 4.98046322  6.49705226 14.38289434], cur_train_grp_loss: [0.08816697 0.11541957 0.25504459], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6766, max_kl_dist_index: 2, max_train_grp_loss:  13.7347, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8112, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:09:15,782 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  56, train_loss:  12.6262, val_loss:  12.2185, grad_norm: 0.0011, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6763, 0.3235, 0.6766, param: [ 4.89698658  6.9551947   5.69093305 10.22960093], weights: [0.32092638 0.32591941 0.35315421], train_wt_loss:  37.8785, val_wt_loss: 36.6555, train_grp_loss: [11.46220012 13.73437598 13.00731961], val_grp_loss: [12.61038741 12.81095488 11.23237129], train_hist_grp_loss: [ 5.06863209  6.61246951 14.63793938], cur_train_grp_loss: [0.08816887 0.11541724 0.25504504], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6766, max_kl_dist_index: 2, max_train_grp_loss:  13.7344, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8110, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:09:16,822 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  57, train_loss:  12.6262, val_loss:  12.2185, grad_norm: 0.0012, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6763, 0.3235, 0.6766, param: [ 4.89691618  6.95477215  5.69122011 10.2295755 ], weights: [0.32070874 0.32578712 0.35350413], train_wt_loss:  37.8785, val_wt_loss: 36.6556, train_grp_loss: [11.46244617 13.73410094 13.007342  ], val_grp_loss: [12.61063687 12.81069759 11.23249467], train_hist_grp_loss: [ 5.15680286  6.72788443 14.89298486], cur_train_grp_loss: [0.08817077 0.11541492 0.25504548], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6766, max_kl_dist_index: 2, max_train_grp_loss:  13.7341, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8107, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:09:17,831 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  58, train_loss:  12.6262, val_loss:  12.2186, grad_norm: 0.0012, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6763, 0.3235, 0.6765, param: [ 4.8968454   6.95434992  5.69150704 10.22955123], weights: [0.32049108 0.32565471 0.35385421], train_wt_loss:  37.8785, val_wt_loss: 36.6557, train_grp_loss: [11.46269153 13.73382679 13.00736418], val_grp_loss: [12.61088569 12.81044137 11.23261775], train_hist_grp_loss: [ 5.24497552  6.84329704 15.14803078], cur_train_grp_loss: [0.08817266 0.11541261 0.25504592], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6765, max_kl_dist_index: 2, max_train_grp_loss:  13.7338, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8104, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:09:18,848 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  59, train_loss:  12.6262, val_loss:  12.2186, grad_norm: 0.0012, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6763, 0.3235, 0.6765, param: [ 4.89677424  6.953928    5.69179384 10.22952814], weights: [0.32027339 0.32552217 0.35420444], train_wt_loss:  37.8785, val_wt_loss: 36.6558, train_grp_loss: [11.46293619 13.73355354 13.00738615], val_grp_loss: [12.61113388 12.81018623 11.23274053], train_hist_grp_loss: [ 5.33315007  6.95870735 15.40307714], cur_train_grp_loss: [0.08817455 0.11541031 0.25504636], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6765, max_kl_dist_index: 2, max_train_grp_loss:  13.7336, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8102, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:09:19,844 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  60, train_loss:  12.6262, val_loss:  12.2187, grad_norm: 0.0012, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6763, 0.3235, 0.6765, param: [ 4.8967027   6.9535064   5.69208051 10.22950621], weights: [0.32005569 0.32538949 0.35455482], train_wt_loss:  37.8785, val_wt_loss: 36.6560, train_grp_loss: [11.46318017 13.73328118 13.00740793], val_grp_loss: [12.61138145 12.80993218 11.23286302], train_hist_grp_loss: [ 5.42132651  7.07411537 15.65812393], cur_train_grp_loss: [0.08817643 0.11540801 0.25504679], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6765, max_kl_dist_index: 2, max_train_grp_loss:  13.7333, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8099, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:09:20,822 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  61, train_loss:  12.6262, val_loss:  12.2187, grad_norm: 0.0012, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6763, 0.3235, 0.6765, param: [ 4.89663078  6.95308512  5.69236704 10.22948545], weights: [0.31983796 0.32525668 0.35490536], train_wt_loss:  37.8785, val_wt_loss: 36.6561, train_grp_loss: [11.46342345 13.73300972 13.0074295 ], val_grp_loss: [12.61162837 12.8096792  11.2329852 ], train_hist_grp_loss: [ 5.50950482  7.18952109 15.91317114], cur_train_grp_loss: [0.08817831 0.11540572 0.25504721], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6765, max_kl_dist_index: 2, max_train_grp_loss:  13.7330, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8097, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:09:21,814 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  62, train_loss:  12.6262, val_loss:  12.2187, grad_norm: 0.0013, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6762, 0.3235, 0.6765, param: [ 4.89655848  6.95266415  5.69265345 10.22946587], weights: [0.31962021 0.32512374 0.35525605], train_wt_loss:  37.8785, val_wt_loss: 36.6562, train_grp_loss: [11.46366604 13.73273916 13.00745086], val_grp_loss: [12.61187467 12.8094273  11.23310708], train_hist_grp_loss: [ 5.597685    7.30492453 16.16821878], cur_train_grp_loss: [0.08818018 0.11540344 0.25504764], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6765, max_kl_dist_index: 2, max_train_grp_loss:  13.7327, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8094, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:09:22,837 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  63, train_loss:  12.6262, val_loss:  12.2188, grad_norm: 0.0013, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6762, 0.3235, 0.6765, param: [ 4.89648579  6.9522435   5.69293972 10.22944745], weights: [0.31940244 0.32499067 0.35560689], train_wt_loss:  37.8785, val_wt_loss: 36.6563, train_grp_loss: [11.46390794 13.7324695  13.00747202], val_grp_loss: [12.61212034 12.80917648 11.23322866], train_hist_grp_loss: [ 5.68586704  7.4203257  16.42326684], cur_train_grp_loss: [0.08818205 0.11540117 0.25504806], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6765, max_kl_dist_index: 2, max_train_grp_loss:  13.7325, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8092, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:09:23,819 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  64, train_loss:  12.6262, val_loss:  12.2188, grad_norm: 0.0013, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6762, 0.3235, 0.6764, param: [ 4.89641273  6.95182316  5.69322585 10.22943021], weights: [0.31918465 0.32485746 0.35595788], train_wt_loss:  37.8785, val_wt_loss: 36.6564, train_grp_loss: [11.46414914 13.73220073 13.00749298], val_grp_loss: [12.61236537 12.80892675 11.23334994], train_hist_grp_loss: [ 5.77405095  7.53572461 16.67831531], cur_train_grp_loss: [0.08818391 0.1153989  0.25504847], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6764, max_kl_dist_index: 2, max_train_grp_loss:  13.7322, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8089, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:09:24,824 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  65, train_loss:  12.6262, val_loss:  12.2188, grad_norm: 0.0013, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6762, 0.3235, 0.6764, param: [ 4.89633928  6.95140314  5.69351186 10.22941415], weights: [0.31896684 0.32472413 0.35630903], train_wt_loss:  37.8785, val_wt_loss: 36.6565, train_grp_loss: [11.46438965 13.73193287 13.00751373], val_grp_loss: [12.61260976 12.80867809 11.23347092], train_hist_grp_loss: [ 5.86223671  7.65112125 16.93336419], cur_train_grp_loss: [0.08818576 0.11539664 0.25504888], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6764, max_kl_dist_index: 2, max_train_grp_loss:  13.7319, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8087, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:09:25,830 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  66, train_loss:  12.6262, val_loss:  12.2189, grad_norm: 0.0014, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6762, 0.3235, 0.6764, param: [ 4.89626545  6.95098343  5.69379773 10.22939926], weights: [0.31874901 0.32459066 0.35666033], train_wt_loss:  37.8785, val_wt_loss: 36.6566, train_grp_loss: [11.46462946 13.7316659  13.00753427], val_grp_loss: [12.61285353 12.80843052 11.2335916 ], train_hist_grp_loss: [ 5.95042432  7.76651564 17.18841348], cur_train_grp_loss: [0.08818761 0.11539439 0.25504929], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6764, max_kl_dist_index: 2, max_train_grp_loss:  13.7317, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8084, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:09:26,870 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  67, train_loss:  12.6262, val_loss:  12.2189, grad_norm: 0.0014, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6762, 0.3235, 0.6764, param: [ 4.89619124  6.95056404  5.69408347 10.22938555], weights: [0.31853115 0.32445707 0.35701178], train_wt_loss:  37.8785, val_wt_loss: 36.6568, train_grp_loss: [11.46486857 13.73139983 13.00755461], val_grp_loss: [12.61309665 12.80818404 11.23371197], train_hist_grp_loss: [ 6.03861378  7.88190779 17.44346317], cur_train_grp_loss: [0.08818946 0.11539215 0.25504969], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6764, max_kl_dist_index: 2, max_train_grp_loss:  13.7314, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8082, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:09:27,887 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  68, train_loss:  12.6262, val_loss:  12.2190, grad_norm: 0.0014, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6762, 0.3235, 0.6764, param: [ 4.89611665  6.95014497  5.69436908 10.22937301], weights: [0.31831328 0.32432334 0.35736338], train_wt_loss:  37.8786, val_wt_loss: 36.6569, train_grp_loss: [11.46510699 13.73113466 13.00757475], val_grp_loss: [12.61333915 12.80793863 11.23383205], train_hist_grp_loss: [ 6.12680508  7.99729771 17.69851326], cur_train_grp_loss: [0.0881913  0.11538991 0.25505009], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6764, max_kl_dist_index: 2, max_train_grp_loss:  13.7311, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8079, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:09:28,876 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  69, train_loss:  12.6262, val_loss:  12.2190, grad_norm: 0.0014, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6762, 0.3235, 0.6764, param: [ 4.89604168  6.94972621  5.69465455 10.22936166], weights: [0.31809539 0.32418948 0.35771513], train_wt_loss:  37.8786, val_wt_loss: 36.6570, train_grp_loss: [11.46534472 13.73087039 13.00759468], val_grp_loss: [12.613581   12.80769431 11.23395182], train_hist_grp_loss: [ 6.21499821  8.1126854  17.95356374], cur_train_grp_loss: [0.08819313 0.11538769 0.25505049], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6764, max_kl_dist_index: 2, max_train_grp_loss:  13.7309, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8077, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:09:29,874 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  70, train_loss:  12.6262, val_loss:  12.2190, grad_norm: 0.0014, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6762, 0.3235, 0.6764, param: [ 4.89596632  6.94930777  5.69493989 10.22935148], weights: [0.31787747 0.32405549 0.35806703], train_wt_loss:  37.8786, val_wt_loss: 36.6571, train_grp_loss: [11.46558174 13.73060703 13.0076144 ], val_grp_loss: [12.61382222 12.80745108 11.23407129], train_hist_grp_loss: [ 6.30319317  8.22807086 18.20861462], cur_train_grp_loss: [0.08819496 0.11538547 0.25505088], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6764, max_kl_dist_index: 2, max_train_grp_loss:  13.7306, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8075, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:09:30,887 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  71, train_loss:  12.6262, val_loss:  12.2191, grad_norm: 0.0015, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6762, 0.3235, 0.6763, param: [ 4.89589058  6.94888964  5.69522509 10.22934248], weights: [0.31765954 0.32392138 0.35841909], train_wt_loss:  37.8786, val_wt_loss: 36.6572, train_grp_loss: [11.46581807 13.73034456 13.00763391], val_grp_loss: [12.6140628  12.80720894 11.23419045], train_hist_grp_loss: [ 6.39138995  8.34345411 18.46366588], cur_train_grp_loss: [0.08819678 0.11538325 0.25505126], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6763, max_kl_dist_index: 2, max_train_grp_loss:  13.7303, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8072, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:09:31,889 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  72, train_loss:  12.6262, val_loss:  12.2191, grad_norm: 0.0015, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6762, 0.3235, 0.6763, param: [ 4.89581446  6.94847183  5.69551017 10.22933466], weights: [0.31744158 0.32378713 0.35877129], train_wt_loss:  37.8786, val_wt_loss: 36.6573, train_grp_loss: [11.4660537  13.730083   13.00765323], val_grp_loss: [12.61430275 12.80696788 11.23430932], train_hist_grp_loss: [ 6.47958855  8.45883516 18.71871753], cur_train_grp_loss: [0.0881986  0.11538105 0.25505165], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6763, max_kl_dist_index: 2, max_train_grp_loss:  13.7301, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8070, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:09:32,883 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  73, train_loss:  12.6262, val_loss:  12.2192, grad_norm: 0.0015, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6762, 0.3235, 0.6763, param: [ 4.89573795  6.94805433  5.69579511 10.22932803], weights: [0.31722361 0.32365275 0.35912364], train_wt_loss:  37.8786, val_wt_loss: 36.6575, train_grp_loss: [11.46628863 13.72982234 13.00767233], val_grp_loss: [12.61454206 12.8067279  11.23442788], train_hist_grp_loss: [ 6.56778897  8.57421401 18.97376955], cur_train_grp_loss: [0.08820041 0.11537885 0.25505202], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6763, max_kl_dist_index: 2, max_train_grp_loss:  13.7298, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8067, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:09:33,873 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  74, train_loss:  12.6262, val_loss:  12.2192, grad_norm: 0.0015, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6762, 0.3235, 0.6763, param: [ 4.89566106  6.94763715  5.69607991 10.22932258], weights: [0.31700562 0.32351824 0.35947614], train_wt_loss:  37.8786, val_wt_loss: 36.6576, train_grp_loss: [11.46652286 13.72956258 13.00769123], val_grp_loss: [12.61478073 12.80648902 11.23454614], train_hist_grp_loss: [ 6.65599119  8.68959067 19.22882195], cur_train_grp_loss: [0.08820222 0.11537666 0.2550524 ], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6763, max_kl_dist_index: 2, max_train_grp_loss:  13.7296, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8065, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:09:34,875 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  75, train_loss:  12.6262, val_loss:  12.2192, grad_norm: 0.0015, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6762, 0.3235, 0.6763, param: [ 4.89558379  6.94722028  5.69636458 10.22931831], weights: [0.31678761 0.3233836  0.35982879], train_wt_loss:  37.8786, val_wt_loss: 36.6577, train_grp_loss: [11.4667564  13.72930372 13.00770992], val_grp_loss: [12.61501876 12.80625122 11.23466409], train_hist_grp_loss: [ 6.74419521  8.80496514 19.48387472], cur_train_grp_loss: [0.08820402 0.11537448 0.25505277], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6763, max_kl_dist_index: 2, max_train_grp_loss:  13.7293, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8063, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:09:35,893 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  76, train_loss:  12.6262, val_loss:  12.2193, grad_norm: 0.0016, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6762, 0.3235, 0.6763, param: [ 4.89550613  6.94680373  5.69664912 10.22931523], weights: [0.31656958 0.32324883 0.36018159], train_wt_loss:  37.8786, val_wt_loss: 36.6578, train_grp_loss: [11.46698923 13.72904577 13.0077284 ], val_grp_loss: [12.61525615 12.80601452 11.23478174], train_hist_grp_loss: [ 6.83240103  8.92033744 19.73892786], cur_train_grp_loss: [0.08820582 0.1153723  0.25505314], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6763, max_kl_dist_index: 2, max_train_grp_loss:  13.7290, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8060, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:09:36,935 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  77, train_loss:  12.6262, val_loss:  12.2193, grad_norm: 0.0016, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6762, 0.3235, 0.6763, param: [ 4.89542809  6.9463875   5.69693353 10.22931333], weights: [0.31635153 0.32311394 0.36053453], train_wt_loss:  37.8786, val_wt_loss: 36.6579, train_grp_loss: [11.46722136 13.72878872 13.00774668], val_grp_loss: [12.6154929  12.8057789  11.23489908], train_hist_grp_loss: [ 6.92060864  9.03570758 19.99398135], cur_train_grp_loss: [0.08820761 0.11537013 0.2550535 ], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6763, max_kl_dist_index: 2, max_train_grp_loss:  13.7288, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8058, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:09:37,930 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  78, train_loss:  12.6262, val_loss:  12.2193, grad_norm: 0.0016, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6761, 0.3235, 0.6762, param: [ 4.89534966  6.94597158  5.6972178  10.22931262], weights: [0.31613346 0.32297891 0.36088763], train_wt_loss:  37.8786, val_wt_loss: 36.6580, train_grp_loss: [11.46745279 13.72853258 13.00776474], val_grp_loss: [12.61572901 12.80554437 11.23501612], train_hist_grp_loss: [ 7.00881803  9.15107555 20.24903521], cur_train_grp_loss: [0.0882094  0.11536797 0.25505386], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6762, max_kl_dist_index: 2, max_train_grp_loss:  13.7285, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8055, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:09:38,941 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  79, train_loss:  12.6262, val_loss:  12.2194, grad_norm: 0.0016, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6761, 0.3235, 0.6762, param: [ 4.89527085  6.94555597  5.69750193 10.2293131 ], weights: [0.31591537 0.32284376 0.36124087], train_wt_loss:  37.8786, val_wt_loss: 36.6582, train_grp_loss: [11.46768351 13.72827734 13.0077826 ], val_grp_loss: [12.61596448 12.80531094 11.23513285], train_hist_grp_loss: [ 7.09702921  9.26644137 20.50408942], cur_train_grp_loss: [0.08821118 0.11536582 0.25505421], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6762, max_kl_dist_index: 2, max_train_grp_loss:  13.7283, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8053, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:09:39,946 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  80, train_loss:  12.6262, val_loss:  12.2194, grad_norm: 0.0017, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6761, 0.3235, 0.6762, param: [ 4.89519166  6.94514068  5.69778594 10.22931476], weights: [0.31569727 0.32270848 0.36159426], train_wt_loss:  37.8786, val_wt_loss: 36.6583, train_grp_loss: [11.46791354 13.72802301 13.00780026], val_grp_loss: [12.61619931 12.80507859 11.23524928], train_hist_grp_loss: [ 7.18524216  9.38180504 20.75914398], cur_train_grp_loss: [0.08821295 0.11536368 0.25505456], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6762, max_kl_dist_index: 2, max_train_grp_loss:  13.7280, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8051, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:09:40,968 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  81, train_loss:  12.6262, val_loss:  12.2195, grad_norm: 0.0017, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6761, 0.3234, 0.6762, param: [ 4.89511207  6.9447257   5.6980698  10.22931762], weights: [0.31547914 0.32257306 0.36194779], train_wt_loss:  37.8786, val_wt_loss: 36.6584, train_grp_loss: [11.46814286 13.72776958 13.0078177 ], val_grp_loss: [12.6164335  12.80484734 11.23536541], train_hist_grp_loss: [ 7.27345688  9.49716658 21.01419889], cur_train_grp_loss: [0.08821472 0.11536154 0.25505491], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6762, max_kl_dist_index: 2, max_train_grp_loss:  13.7278, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8048, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:09:41,974 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  82, train_loss:  12.6262, val_loss:  12.2195, grad_norm: 0.0017, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6761, 0.3234, 0.6762, param: [ 4.89503211  6.94431104  5.69835354 10.22932167], weights: [0.315261   0.32243752 0.36230148], train_wt_loss:  37.8786, val_wt_loss: 36.6585, train_grp_loss: [11.46837148 13.72751706 13.00783494], val_grp_loss: [12.61666704 12.80461719 11.23548122], train_hist_grp_loss: [ 7.36167336  9.61252599 21.26925414], cur_train_grp_loss: [0.08821648 0.11535941 0.25505525], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6762, max_kl_dist_index: 2, max_train_grp_loss:  13.7275, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8046, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:09:42,967 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  83, train_loss:  12.6262, val_loss:  12.2195, grad_norm: 0.0017, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6761, 0.3234, 0.6762, param: [ 4.89495176  6.94389669  5.69863714 10.22932691], weights: [0.31504284 0.32230186 0.3626553 ], train_wt_loss:  37.8786, val_wt_loss: 36.6586, train_grp_loss: [11.4685994  13.72726544 13.00785197], val_grp_loss: [12.61689994 12.80438812 11.23559674], train_hist_grp_loss: [ 7.4498916   9.72788328 21.52430973], cur_train_grp_loss: [0.08821824 0.11535729 0.25505559], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6762, max_kl_dist_index: 2, max_train_grp_loss:  13.7273, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8044, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:09:43,971 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  84, train_loss:  12.6262, val_loss:  12.2196, grad_norm: 0.0017, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6761, 0.3234, 0.6762, param: [ 4.89487102  6.94348266  5.6989206  10.22933334], weights: [0.31482466 0.32216606 0.36300928], train_wt_loss:  37.8786, val_wt_loss: 36.6588, train_grp_loss: [11.46882661 13.72701474 13.00786878], val_grp_loss: [12.6171322  12.80416015 11.23571194], train_hist_grp_loss: [ 7.5381116   9.84323845 21.77936565], cur_train_grp_loss: [0.08822    0.11535517 0.25505592], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6762, max_kl_dist_index: 2, max_train_grp_loss:  13.7270, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8042, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:09:44,959 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  85, train_loss:  12.6262, val_loss:  12.2196, grad_norm: 0.0018, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6761, 0.3234, 0.6761, param: [ 4.89478989  6.94306894  5.69920393 10.22934096], weights: [0.31460647 0.32203013 0.3633634 ], train_wt_loss:  37.8786, val_wt_loss: 36.6589, train_grp_loss: [11.46905311 13.72676494 13.00788539], val_grp_loss: [12.61736382 12.80393328 11.23582684], train_hist_grp_loss: [ 7.62633334  9.95859151 22.0344219 ], cur_train_grp_loss: [0.08822174 0.11535307 0.25505625], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6761, max_kl_dist_index: 2, max_train_grp_loss:  13.7268, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8039, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:09:45,956 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  86, train_loss:  12.6262, val_loss:  12.2197, grad_norm: 0.0018, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6761, 0.3234, 0.6761, param: [ 4.89470838  6.94265553  5.69948712 10.22934978], weights: [0.31438825 0.32189408 0.36371766], train_wt_loss:  37.8786, val_wt_loss: 36.6590, train_grp_loss: [11.46927891 13.72651605 13.0079018 ], val_grp_loss: [12.61759479 12.8037075  11.23594143], train_hist_grp_loss: [ 7.71455683 10.07394248 22.28947847], cur_train_grp_loss: [0.08822349 0.11535097 0.25505658], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6761, max_kl_dist_index: 2, max_train_grp_loss:  13.7265, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8037, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:09:46,961 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  87, train_loss:  12.6262, val_loss:  12.2197, grad_norm: 0.0018, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6761, 0.3234, 0.6761, param: [ 4.89462649  6.94224244  5.69977018 10.22935979], weights: [0.31417002 0.3217579  0.36407207], train_wt_loss:  37.8787, val_wt_loss: 36.6591, train_grp_loss: [11.469504   13.72626807 13.00791799], val_grp_loss: [12.61782511 12.80348282 11.23605571], train_hist_grp_loss: [ 7.80278205 10.18929135 22.54453537], cur_train_grp_loss: [0.08822522 0.11534887 0.2550569 ], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6761, max_kl_dist_index: 2, max_train_grp_loss:  13.7263, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8035, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:09:47,972 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  88, train_loss:  12.6262, val_loss:  12.2197, grad_norm: 0.0018, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6761, 0.3234, 0.6761, param: [ 4.8945442   6.94182967  5.70005311 10.22937101], weights: [0.31395178 0.3216216  0.36442663], train_wt_loss:  37.8787, val_wt_loss: 36.6592, train_grp_loss: [11.46972839 13.726021   13.00793397], val_grp_loss: [12.61805479 12.80325923 11.23616969], train_hist_grp_loss: [ 7.891009   10.30463814 22.79959259], cur_train_grp_loss: [0.08822695 0.11534679 0.25505722], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6761, max_kl_dist_index: 2, max_train_grp_loss:  13.7260, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8033, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:09:48,965 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  89, train_loss:  12.6262, val_loss:  12.2198, grad_norm: 0.0018, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6761, 0.3234, 0.6761, param: [ 4.89446153  6.9414172   5.7003359  10.22938341], weights: [0.31373351 0.32148516 0.36478132], train_wt_loss:  37.8787, val_wt_loss: 36.6594, train_grp_loss: [11.46995207 13.72577484 13.00794974], val_grp_loss: [12.61828383 12.80303675 11.23628336], train_hist_grp_loss: [ 7.97923768 10.41998286 23.05465012], cur_train_grp_loss: [0.08822868 0.11534471 0.25505753], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6761, max_kl_dist_index: 2, max_train_grp_loss:  13.7258, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8030, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:09:49,956 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  90, train_loss:  12.6262, val_loss:  12.2198, grad_norm: 0.0019, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6761, 0.3234, 0.6761, param: [ 4.89437848  6.94100506  5.70061855 10.22939702], weights: [0.31351523 0.3213486  0.36513617], train_wt_loss:  37.8787, val_wt_loss: 36.6595, train_grp_loss: [11.47017504 13.72552958 13.00796531], val_grp_loss: [12.61851222 12.80281536 11.23639672], train_hist_grp_loss: [ 8.06746808 10.5353255  23.30970795], cur_train_grp_loss: [0.0882304  0.11534265 0.25505784], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6761, max_kl_dist_index: 0, max_train_grp_loss:  13.7255, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8028, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:09:50,959 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  91, train_loss:  12.6262, val_loss:  12.2199, grad_norm: 0.0019, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6761, 0.3234, 0.6761, param: [ 4.89429503  6.94059322  5.70090107 10.22941183], weights: [0.31329693 0.32121191 0.36549115], train_wt_loss:  37.8787, val_wt_loss: 36.6596, train_grp_loss: [11.47039731 13.72528524 13.00798066], val_grp_loss: [12.61873996 12.80259507 11.23650977], train_hist_grp_loss: [ 8.1557002  10.65066609 23.5647661 ], cur_train_grp_loss: [0.08823212 0.11534058 0.25505814], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6761, max_kl_dist_index: 0, max_train_grp_loss:  13.7253, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8026, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:09:51,945 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  92, train_loss:  12.6262, val_loss:  12.2199, grad_norm: 0.0019, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6761, 0.3234, 0.6761, param: [ 4.8942112   6.9401817   5.70118345 10.22942783], weights: [0.31307862 0.3210751  0.36584628], train_wt_loss:  37.8787, val_wt_loss: 36.6597, train_grp_loss: [11.47061887 13.72504181 13.0079958 ], val_grp_loss: [12.61896706 12.80237588 11.23662252], train_hist_grp_loss: [ 8.24393402 10.76600462 23.81982454], cur_train_grp_loss: [0.08823383 0.11533853 0.25505844], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6761, max_kl_dist_index: 0, max_train_grp_loss:  13.7250, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8024, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:09:52,948 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  93, train_loss:  12.6262, val_loss:  12.2199, grad_norm: 0.0019, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6761, 0.3234, 0.6760, param: [ 4.89412698  6.93977049  5.7014657  10.22944504], weights: [0.31286029 0.32093816 0.36620155], train_wt_loss:  37.8787, val_wt_loss: 36.6598, train_grp_loss: [11.47083971 13.7247993  13.00801073], val_grp_loss: [12.6191935  12.80215779 11.23673495], train_hist_grp_loss: [ 8.33216955 10.8813411  24.07488328], cur_train_grp_loss: [0.08823553 0.11533649 0.25505874], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6761, max_kl_dist_index: 0, max_train_grp_loss:  13.7248, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8022, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:09:53,925 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  94, train_loss:  12.6262, val_loss:  12.2200, grad_norm: 0.0020, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6761, 0.3234, 0.6760, param: [ 4.89404237  6.9393596   5.70174781 10.22946345], weights: [0.31264194 0.32080109 0.36655697], train_wt_loss:  37.8787, val_wt_loss: 36.6600, train_grp_loss: [11.47105985 13.72455769 13.00802545], val_grp_loss: [12.6194193  12.8019408  11.23684708], train_hist_grp_loss: [ 8.42040678 10.99667555 24.32994232], cur_train_grp_loss: [0.08823723 0.11533445 0.25505903], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6761, max_kl_dist_index: 0, max_train_grp_loss:  13.7246, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8019, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:09:54,916 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  95, train_loss:  12.6262, val_loss:  12.2200, grad_norm: 0.0020, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6761, 0.3234, 0.6760, param: [ 4.89395737  6.93894902  5.70202979 10.22948306], weights: [0.31242358 0.3206639  0.36691252], train_wt_loss:  37.8787, val_wt_loss: 36.6601, train_grp_loss: [11.47127928 13.724317   13.00803997], val_grp_loss: [12.61964445 12.80172491 11.23695889], train_hist_grp_loss: [ 8.5086457  11.11200797 24.58500164], cur_train_grp_loss: [0.08823892 0.11533242 0.25505932], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6761, max_kl_dist_index: 0, max_train_grp_loss:  13.7243, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8017, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:09:55,919 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  96, train_loss:  12.6262, val_loss:  12.2201, grad_norm: 0.0020, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6761, 0.3234, 0.6760, param: [ 4.89387199  6.93853876  5.70231163 10.22950387], weights: [0.3122052  0.32052658 0.36726822], train_wt_loss:  37.8787, val_wt_loss: 36.6602, train_grp_loss: [11.47149799 13.72407722 13.00805427], val_grp_loss: [12.61986895 12.80151012 11.2370704 ], train_hist_grp_loss: [ 8.59688631 11.22733837 24.84006125], cur_train_grp_loss: [0.08824061 0.11533039 0.25505961], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6761, max_kl_dist_index: 0, max_train_grp_loss:  13.7241, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8015, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:09:56,941 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  97, train_loss:  12.6262, val_loss:  12.2201, grad_norm: 0.0020, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6760, 0.3234, 0.6760, param: [ 4.89378621  6.9381288   5.70259334 10.2295259 ], weights: [0.31198681 0.32038913 0.36762406], train_wt_loss:  37.8787, val_wt_loss: 36.6603, train_grp_loss: [11.471716   13.72383835 13.00806835], val_grp_loss: [12.62009281 12.80129644 11.2371816 ], train_hist_grp_loss: [ 8.68512861 11.34266675 25.09512113], cur_train_grp_loss: [0.08824229 0.11532838 0.25505989], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6760, max_kl_dist_index: 0, max_train_grp_loss:  13.7238, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8013, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:09:57,917 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  98, train_loss:  12.6262, val_loss:  12.2201, grad_norm: 0.0020, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6760, 0.3234, 0.6760, param: [ 4.89370005  6.93771916  5.7028749  10.22954912], weights: [0.3117684  0.32025156 0.36798004], train_wt_loss:  37.8787, val_wt_loss: 36.6604, train_grp_loss: [11.47193329 13.7236004  13.00808223], val_grp_loss: [12.62031601 12.80108386 11.23729248], train_hist_grp_loss: [ 8.77337257 11.45799312 25.3501813 ], cur_train_grp_loss: [0.08824397 0.11532637 0.25506016], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6760, max_kl_dist_index: 0, max_train_grp_loss:  13.7236, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8011, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:09:58,900 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  99, train_loss:  12.6262, val_loss:  12.2202, grad_norm: 0.0021, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6760, 0.3234, 0.6760, param: [ 4.8936135   6.93730984  5.70315634 10.22957356], weights: [0.31154998 0.32011386 0.36833616], train_wt_loss:  37.8787, val_wt_loss: 36.6606, train_grp_loss: [11.47214988 13.72336336 13.0080959 ], val_grp_loss: [12.62053856 12.80087239 11.23740306], train_hist_grp_loss: [ 8.86161822 11.57331749 25.60524173], cur_train_grp_loss: [0.08824564 0.11532437 0.25506044], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6760, max_kl_dist_index: 0, max_train_grp_loss:  13.7234, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8009, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:09:59,810 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1654] - INFO: Iteration:  99, train_loss:  12.6262, val_loss:  12.2202, grad_norm: 0.0021,  live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6760, 0.3234, 0.6760, param: [ 4.8936135   6.93730984  5.70315634 10.22957356], weights: [0.31154998 0.32011386 0.36833616], train_wt_loss:  37.8787, val_wt_loss: 36.6606, train_grp_loss: [11.47214988 13.72336336 13.0080959 ], val_grp_loss: [12.62053856 12.80087239 11.23740306], train_hist_grp_loss: [ 8.86161822 11.57331749 25.60524173], cur_train_grp_loss: [0.08824564 0.11532437 0.25506044], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6760, max_kl_dist_index: 0, max_train_grp_loss:  13.7234, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8009, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2551, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:10:00,034 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:388] - INFO: Policy parameter learned solely on the preference data rdpo: [ 4.8936135   6.93730984  5.70315634 10.22957356].
2024-10-07 17:10:00,376 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Uniform reward: 3.8511, 3.8511, 3.1970
2024-10-07 17:10:00,376 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Optimal reward: 3.8856, 7.2460, 3.3201
2024-10-07 17:10:00,377 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Policy reward: 3.8477, 7.1090, 3.3171
2024-10-07 17:10:00,377 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:402] - INFO: Reward Error: 0.0098, 0.0189, 0.0009
2024-10-07 17:10:01,061 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:417] - INFO: Optimal reward: 3.8856, 7.2460, 3.3201
Known param reward: [[3.885563232421875, 6.83889453125, 3.291370361328125], [3.493690185546875, 7.24602734375, 3.1155205078125], [3.850873046875, 7.10487548828125, 3.320061279296875]], Known param reward error: [[0.0, 0.05618703783269167, 0.008641683256769945], [0.10085360176489651, 0.0, 0.06160752898142066], [0.008927968346368324, 0.019479895503085456, 0.0]].
