2024-10-07 17:30:04,332 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log-hyperparam-search/2024_10_07_17_04_32/rdpo,0.2,0.1,0.1,2023
2024-10-07 17:30:04,334 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2023
2024-10-07 17:30:04,334 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-10-07 17:30:04,424 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.2729, l2 distance: 29.4548, acc: 0.92.
2024-10-07 17:30:04,424 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-10-07 17:30:04,425 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [ 6.99981245 12.85202501  8.22225193 12.39503134]
2024-10-07 17:30:04,635 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.8503, 7.1054, 3.3198
2024-10-07 17:30:04,863 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1314] - INFO: unique_group_ids: {0, 1, 2}
2024-10-07 17:30:06,058 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  0, train_loss:  12.6261, val_loss:  12.2168, grad_norm: 0.4066, live_grad: 0.0000, reward_err: 0.0095, 0.0189, 0.0009, KL_dist: 0.6770, 0.3239, 0.6779, param: [ 4.897829    6.97796199  5.67603919 10.23833146], weights: [0.33073691 0.33110299 0.3381601 ], train_wt_loss:  37.8784, val_wt_loss: 36.6505, train_grp_loss: [11.44552015 13.75359224 13.00478332], val_grp_loss: [12.59390297 12.83047537 11.22426656], train_hist_grp_loss: [0.1342519  0.14531453 0.3562142 ], cur_train_grp_loss: [0.1342519  0.14531453 0.3562142 ], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6779, max_kl_dist_index: 2, max_train_grp_loss:  13.7536, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8305, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.3562, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:30:07,117 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  1, train_loss:  12.6261, val_loss:  12.2172, grad_norm: 0.0002, live_grad: 0.0000, reward_err: 0.0095, 0.0189, 0.0009, KL_dist: 0.6769, 0.3239, 0.6777, param: [ 4.89728117  6.9735816   5.67897602 10.23759433], weights: [0.3285664 0.329837  0.3415966], train_wt_loss:  37.8784, val_wt_loss: 36.6516, train_grp_loss: [11.44827564 13.75045405 13.00509061], val_grp_loss: [12.59666701 12.82744062 11.22562654], train_hist_grp_loss: [0.22229436 0.26089094 0.61120995], cur_train_grp_loss: [0.08804246 0.11557641 0.25499575], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6777, max_kl_dist_index: 2, max_train_grp_loss:  13.7505, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8274, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:30:08,169 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  2, train_loss:  12.6261, val_loss:  12.2176, grad_norm: 0.0003, live_grad: 0.0000, reward_err: 0.0095, 0.0189, 0.0009, KL_dist: 0.6768, 0.3238, 0.6775, param: [ 4.89669599  6.96923312  5.68189983 10.23697095], weights: [0.32639319 0.32855723 0.34504958], train_wt_loss:  37.8784, val_wt_loss: 36.6527, train_grp_loss: [11.45096375 13.74740421 13.00537825], val_grp_loss: [12.59936964 12.82451194 11.22695768], train_hist_grp_loss: [0.31035802 0.37644097 0.86621172], cur_train_grp_loss: [0.08806366 0.11555003 0.25500178], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6775, max_kl_dist_index: 2, max_train_grp_loss:  13.7474, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8245, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:30:09,252 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  3, train_loss:  12.6261, val_loss:  12.2179, grad_norm: 0.0005, live_grad: 0.0000, reward_err: 0.0095, 0.0189, 0.0009, KL_dist: 0.6767, 0.3238, 0.6773, param: [ 4.89607325  6.96491653  5.68481053 10.23646226], weights: [0.32421742 0.32726383 0.34851875], train_wt_loss:  37.8784, val_wt_loss: 36.6538, train_grp_loss: [11.45358395 13.74444318 13.00564605], val_grp_loss: [12.60201036 12.82168993 11.22825967], train_hist_grp_loss: [0.39844236 0.49196538 1.12121914], cur_train_grp_loss: [0.08808434 0.11552441 0.25500742], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6773, max_kl_dist_index: 2, max_train_grp_loss:  13.7444, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8217, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:30:10,352 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  4, train_loss:  12.6262, val_loss:  12.2183, grad_norm: 0.0007, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6766, 0.3237, 0.6771, param: [ 4.89541273  6.96063176  5.68770805 10.23606918], weights: [0.32203926 0.32595694 0.3520038 ], train_wt_loss:  37.8785, val_wt_loss: 36.6549, train_grp_loss: [11.4561357  13.7415714  13.00589382], val_grp_loss: [12.60458866 12.81897521 11.22953223], train_hist_grp_loss: [0.48654685 0.6074649  1.37623181], cur_train_grp_loss: [0.08810449 0.11549952 0.25501267], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6771, max_kl_dist_index: 2, max_train_grp_loss:  13.7416, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8190, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:30:11,398 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  5, train_loss:  12.6262, val_loss:  12.2187, grad_norm: 0.0009, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6766, 0.3237, 0.6770, param: [ 4.89471421  6.95637877  5.69059229 10.23579268], weights: [0.31985886 0.32463672 0.35550442], train_wt_loss:  37.8785, val_wt_loss: 36.6560, train_grp_loss: [11.4586185  13.73878932 13.00612133], val_grp_loss: [12.60710407 12.8163684  11.23077506], train_hist_grp_loss: [0.57467097 0.72294029 1.63124933], cur_train_grp_loss: [0.08812412 0.11547539 0.25501753], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6770, max_kl_dist_index: 2, max_train_grp_loss:  13.7388, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8164, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:30:12,448 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  6, train_loss:  12.6262, val_loss:  12.2191, grad_norm: 0.0011, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6765, 0.3237, 0.6768, param: [ 4.89397747  6.9521575   5.69346316 10.23563368], weights: [0.31767638 0.32330333 0.35902029], train_wt_loss:  37.8785, val_wt_loss: 36.6572, train_grp_loss: [11.46103182 13.7360974  13.0063284 ], val_grp_loss: [12.60955607 12.81387013 11.23198786], train_hist_grp_loss: [0.66281419 0.8383923  1.88627132], cur_train_grp_loss: [0.08814322 0.11545201 0.25502199], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6768, max_kl_dist_index: 2, max_train_grp_loss:  13.7361, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8139, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:30:13,521 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  7, train_loss:  12.6262, val_loss:  12.2195, grad_norm: 0.0013, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6764, 0.3236, 0.6767, param: [ 4.89320227  6.94796788  5.69632056 10.23559316], weights: [0.31549197 0.32195694 0.36255108], train_wt_loss:  37.8786, val_wt_loss: 36.6584, train_grp_loss: [11.46337514 13.7334961  13.00651482], val_grp_loss: [12.61194418 12.81148105 11.23317037], train_hist_grp_loss: [0.75097597 0.95382169 2.14129737], cur_train_grp_loss: [0.08816178 0.11542939 0.25502605], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6767, max_kl_dist_index: 2, max_train_grp_loss:  13.7335, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8115, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:30:14,540 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  8, train_loss:  12.6262, val_loss:  12.2199, grad_norm: 0.0015, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6764, 0.3236, 0.6765, param: [ 4.8923884   6.94380984  5.6991644  10.23567205], weights: [0.31330582 0.32059771 0.36609647], train_wt_loss:  37.8786, val_wt_loss: 36.6596, train_grp_loss: [11.46564795 13.73098589 13.0066804 ], val_grp_loss: [12.61426792 12.80920177 11.23432228], train_hist_grp_loss: [0.83915578 1.06922922 2.39632707], cur_train_grp_loss: [0.08817981 0.11540753 0.2550297 ], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6765, max_kl_dist_index: 2, max_train_grp_loss:  13.7310, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8092, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:30:15,546 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  9, train_loss:  12.6262, val_loss:  12.2203, grad_norm: 0.0017, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6763, 0.3236, 0.6764, param: [ 4.89153563  6.9396833   5.70199457 10.23587131], weights: [0.31111807 0.31922581 0.36965612], train_wt_loss:  37.8787, val_wt_loss: 36.6608, train_grp_loss: [11.46784974 13.72856724 13.00682494], val_grp_loss: [12.61652678 12.80703297 11.23544334], train_hist_grp_loss: [0.92735307 1.18461565 2.65136002], cur_train_grp_loss: [0.08819729 0.11538644 0.25503295], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6764, max_kl_dist_index: 2, max_train_grp_loss:  13.7286, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8070, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:30:16,546 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  10, train_loss:  12.6262, val_loss:  12.2207, grad_norm: 0.0019, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6763, 0.3236, 0.6763, param: [ 4.89064373  6.93558818  5.70481097 10.2361919 ], weights: [0.3089289  0.31784142 0.37322968], train_wt_loss:  37.8787, val_wt_loss: 36.6620, train_grp_loss: [11.46997998 13.72624064 13.00694824], val_grp_loss: [12.61872028 12.80497529 11.23653326], train_hist_grp_loss: [1.0155673  1.29998177 2.9063958 ], cur_train_grp_loss: [0.08821423 0.11536611 0.25503578], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6763, max_kl_dist_index: 2, max_train_grp_loss:  13.7262, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8050, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:30:17,538 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  11, train_loss:  12.6263, val_loss:  12.2211, grad_norm: 0.0021, live_grad: 0.0000, reward_err: 0.0098, 0.0189, 0.0009, KL_dist: 0.6762, 0.3235, 0.6762, param: [ 4.88971248  6.93152438  5.70761348 10.23663478], weights: [0.30673848 0.31644472 0.3768168 ], train_wt_loss:  37.8788, val_wt_loss: 36.6632, train_grp_loss: [11.47203819 13.72400656 13.00705011], val_grp_loss: [12.62084794 12.80302939 11.23759177], train_hist_grp_loss: [1.10379792 1.41532833 3.161434  ], cur_train_grp_loss: [0.08823062 0.11534656 0.2550382 ], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6762, max_kl_dist_index: 0, max_train_grp_loss:  13.7240, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8030, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:30:18,526 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  12, train_loss:  12.6263, val_loss:  12.2215, grad_norm: 0.0024, live_grad: 0.0000, reward_err: 0.0100, 0.0189, 0.0010, KL_dist: 0.6762, 0.3235, 0.6761, param: [ 4.88874164  6.9274918   5.710402   10.2372009 ], weights: [0.30454699 0.31503588 0.38041713], train_wt_loss:  37.8789, val_wt_loss: 36.6645, train_grp_loss: [11.47402384 13.7218655  13.00713036], val_grp_loss: [12.62290928 12.80119593 11.23861861], train_hist_grp_loss: [1.19204437 1.53065611 3.4164742 ], cur_train_grp_loss: [0.08824645 0.11532779 0.2550402 ], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6762, max_kl_dist_index: 0, max_train_grp_loss:  13.7219, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8012, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:30:19,519 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  13, train_loss:  12.6263, val_loss:  12.2219, grad_norm: 0.0026, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6762, 0.3235, 0.6760, param: [ 4.88773097  6.92349034  5.71317641 10.23789122], weights: [0.30235459 0.31361511 0.3840303 ], train_wt_loss:  37.8790, val_wt_loss: 36.6657, train_grp_loss: [11.47593644 13.71981794 13.00718879], val_grp_loss: [12.62490381 12.7994756  11.23961352], train_hist_grp_loss: [1.28030609 1.64596591 3.67151597], cur_train_grp_loss: [0.08826172 0.11530979 0.25504177], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6762, max_kl_dist_index: 0, max_train_grp_loss:  13.7198, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7995, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:30:20,528 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  14, train_loss:  12.6264, val_loss:  12.2223, grad_norm: 0.0028, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6762, 0.3235, 0.6759, param: [ 4.88668026  6.91951987  5.71593658 10.23870671], weights: [0.30016148 0.31218257 0.38765595], train_wt_loss:  37.8791, val_wt_loss: 36.6670, train_grp_loss: [11.47777549 13.71786438 13.00722522], val_grp_loss: [12.62683106 12.79786908 11.24057625], train_hist_grp_loss: [1.36858252 1.76125849 3.92655889], cur_train_grp_loss: [0.08827643 0.11529259 0.25504292], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6762, max_kl_dist_index: 0, max_train_grp_loss:  13.7179, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7979, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:30:21,511 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  15, train_loss:  12.6264, val_loss:  12.2228, grad_norm: 0.0030, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6761, 0.3235, 0.6758, param: [ 4.88558926  6.91558028  5.71868241 10.23964833], weights: [0.29796782 0.31073848 0.3912937 ], train_wt_loss:  37.8791, val_wt_loss: 36.6683, train_grp_loss: [11.4795405  13.71600533 13.00723946], val_grp_loss: [12.62869056 12.79637703 11.24150654], train_hist_grp_loss: [1.4568731  1.87653467 4.18160252], cur_train_grp_loss: [0.08829058 0.11527617 0.25504363], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6761, max_kl_dist_index: 0, max_train_grp_loss:  13.7160, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7964, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:30:22,497 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  16, train_loss:  12.6264, val_loss:  12.2232, grad_norm: 0.0033, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6761, 0.3235, 0.6758, param: [ 4.88445774  6.91167144  5.72141375 10.24071704], weights: [0.2957738  0.30928302 0.39494318], train_wt_loss:  37.8792, val_wt_loss: 36.6696, train_grp_loss: [11.48123098 13.71424129 13.00723133], val_grp_loss: [12.63048183 12.79500017 11.24240415], train_hist_grp_loss: [1.54517726 1.99179521 4.43664643], cur_train_grp_loss: [0.08830416 0.11526055 0.25504391], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6761, max_kl_dist_index: 0, max_train_grp_loss:  13.7142, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7950, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:30:23,479 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  17, train_loss:  12.6264, val_loss:  12.2236, grad_norm: 0.0035, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6761, 0.3235, 0.6757, param: [ 4.88328547  6.9077932   5.72413048 10.2419138 ], weights: [0.29357961 0.3078164  0.39860399], train_wt_loss:  37.8793, val_wt_loss: 36.6709, train_grp_loss: [11.48284644 13.71257277 13.00720063], val_grp_loss: [12.63220441 12.79373918 11.24326885], train_hist_grp_loss: [1.63349442 2.10704094 4.69169019], cur_train_grp_loss: [0.08831716 0.11524573 0.25504375], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6761, max_kl_dist_index: 0, max_train_grp_loss:  13.7126, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7937, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:30:24,480 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  18, train_loss:  12.6265, val_loss:  12.2241, grad_norm: 0.0037, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6761, 0.3235, 0.6757, param: [ 4.8820722   6.90394542  5.72683247 10.24323957], weights: [0.29138543 0.30633882 0.40227575], train_wt_loss:  37.8794, val_wt_loss: 36.6723, train_grp_loss: [11.4843864  13.71100029 13.0071472 ], val_grp_loss: [12.63385783 12.79259476 11.24410039], train_hist_grp_loss: [1.72182401 2.22227264 4.94673334], cur_train_grp_loss: [0.08832959 0.1152317  0.25504315], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6761, max_kl_dist_index: 0, max_train_grp_loss:  13.7110, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7926, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:30:25,467 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  19, train_loss:  12.6265, val_loss:  12.2245, grad_norm: 0.0039, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6761, 0.3235, 0.6756, param: [ 4.88081771  6.90012795  5.72951958 10.24469532], weights: [0.28919144 0.30485049 0.40595807], train_wt_loss:  37.8795, val_wt_loss: 36.6736, train_grp_loss: [11.48585037 13.70952437 13.00707084], val_grp_loss: [12.63544164 12.79156763 11.24489854], train_hist_grp_loss: [1.81016544 2.33749113 5.20177544], cur_train_grp_loss: [0.08834143 0.11521849 0.2550421 ], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6761, max_kl_dist_index: 0, max_train_grp_loss:  13.7095, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7916, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:30:26,459 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  20, train_loss:  12.6266, val_loss:  12.2250, grad_norm: 0.0042, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6762, 0.3236, 0.6756, param: [ 4.87952174  6.89634061  5.73219168 10.24628201], weights: [0.28699784 0.30335162 0.40965055], train_wt_loss:  37.8797, val_wt_loss: 36.6750, train_grp_loss: [11.4872379  13.70814553 13.00697139], val_grp_loss: [12.63695538 12.79065849 11.2456631 ], train_hist_grp_loss: [1.89851814 2.45269722 5.45681604], cur_train_grp_loss: [0.0883527  0.11520609 0.2550406 ], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6762, max_kl_dist_index: 0, max_train_grp_loss:  13.7081, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7907, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:30:27,493 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  21, train_loss:  12.6266, val_loss:  12.2255, grad_norm: 0.0044, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6762, 0.3236, 0.6756, param: [ 4.87818407  6.89258324  5.73484861 10.2480006 ], weights: [0.28480481 0.30184242 0.41335277], train_wt_loss:  37.8798, val_wt_loss: 36.6764, train_grp_loss: [11.48854852 13.70686429 13.00684867], val_grp_loss: [12.6383986  12.78986807 11.24639383], train_hist_grp_loss: [1.98688151 2.56789172 5.7118547 ], cur_train_grp_loss: [0.08836337 0.1151945  0.25503865], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6762, max_kl_dist_index: 0, max_train_grp_loss:  13.7069, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7899, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:30:28,486 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  22, train_loss:  12.6266, val_loss:  12.2259, grad_norm: 0.0046, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6762, 0.3236, 0.6755, param: [ 4.87680445  6.88885565  5.73749023 10.24985204], weights: [0.28261255 0.30032311 0.41706433], train_wt_loss:  37.8799, val_wt_loss: 36.6778, train_grp_loss: [11.48978175 13.70568119 13.00670251], val_grp_loss: [12.63977085 12.78919708 11.24709053], train_hist_grp_loss: [2.07525496 2.68307545 5.96689095], cur_train_grp_loss: [0.08837345 0.11518373 0.25503625], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6762, max_kl_dist_index: 0, max_train_grp_loss:  13.7057, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7892, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:30:29,475 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  23, train_loss:  12.6267, val_loss:  12.2264, grad_norm: 0.0049, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6762, 0.3236, 0.6755, param: [ 4.87538264  6.88515765  5.74011639 10.25183729], weights: [0.28042126 0.29879392 0.42078483], train_wt_loss:  37.8800, val_wt_loss: 36.6792, train_grp_loss: [11.49093716 13.70459676 13.00653273], val_grp_loss: [12.6410717  12.78864626 11.247753  ], train_hist_grp_loss: [2.16363789 2.79824925 6.22192433], cur_train_grp_loss: [0.08838294 0.11517379 0.25503338], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6762, max_kl_dist_index: 0, max_train_grp_loss:  13.7046, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7886, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:30:30,465 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  24, train_loss:  12.6267, val_loss:  12.2269, grad_norm: 0.0051, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6763, 0.3237, 0.6755, param: [ 4.87391841  6.88148904  5.74272694 10.25395732], weights: [0.27823112 0.29725505 0.42451383], train_wt_loss:  37.8801, val_wt_loss: 36.6806, train_grp_loss: [11.49201428 13.70361155 13.00633917], val_grp_loss: [12.6423007  12.78821633 11.24838104], train_hist_grp_loss: [2.25202972 2.91341392 6.47695438], cur_train_grp_loss: [0.08839182 0.11516468 0.25503005], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6763, max_kl_dist_index: 0, max_train_grp_loss:  13.7036, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7882, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:30:31,451 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  25, train_loss:  12.6268, val_loss:  12.2273, grad_norm: 0.0053, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6763, 0.3237, 0.6756, param: [ 4.87241151  6.87784961  5.74532173 10.25621306], weights: [0.27604233 0.29570675 0.42825092], train_wt_loss:  37.8803, val_wt_loss: 36.6820, train_grp_loss: [11.49301268 13.70272609 13.00612166], val_grp_loss: [12.64345743 12.78790803 11.24897445], train_hist_grp_loss: [2.34042983 3.02857032 6.73198064], cur_train_grp_loss: [0.08840011 0.1151564  0.25502626], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6763, max_kl_dist_index: 0, max_train_grp_loss:  13.7027, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7879, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:30:32,438 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  26, train_loss:  12.6268, val_loss:  12.2278, grad_norm: 0.0056, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6764, 0.3237, 0.6756, param: [ 4.87086169  6.87423915  5.74790058 10.25860547], weights: [0.27385509 0.29414924 0.43199568], train_wt_loss:  37.8804, val_wt_loss: 36.6835, train_grp_loss: [11.49393191 13.70194092 13.00588006], val_grp_loss: [12.64454146 12.78772211 11.24953306], train_hist_grp_loss: [2.42883762 3.14371928 6.98700263], cur_train_grp_loss: [0.08840779 0.11514896 0.25502199], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6764, max_kl_dist_index: 0, max_train_grp_loss:  13.7019, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7877, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:30:33,435 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  27, train_loss:  12.6269, val_loss:  12.2283, grad_norm: 0.0058, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6764, 0.3238, 0.6756, param: [ 4.86926873  6.87065742  5.75046335 10.26113551], weights: [0.27166959 0.29258274 0.43574767], train_wt_loss:  37.8806, val_wt_loss: 36.6849, train_grp_loss: [11.49477156 13.70125661 13.00561418], val_grp_loss: [12.64555238 12.78765931 11.25005669], train_hist_grp_loss: [2.51725248 3.25886164 7.24201989], cur_train_grp_loss: [0.08841486 0.11514236 0.25501726], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6764, max_kl_dist_index: 0, max_train_grp_loss:  13.7013, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7877, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:30:34,434 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  28, train_loss:  12.6269, val_loss:  12.2288, grad_norm: 0.0060, live_grad: 0.0000, reward_err: 0.0100, 0.0186, 0.0010, KL_dist: 0.6765, 0.3238, 0.6757, param: [ 4.86763236  6.86710418  5.75300986 10.2638041 ], weights: [0.26948604 0.2910075  0.43950646], train_wt_loss:  37.8807, val_wt_loss: 36.6864, train_grp_loss: [11.49553119 13.70067369 13.00532389], val_grp_loss: [12.64648976 12.78772037 11.25054517], train_hist_grp_loss: [2.6056738  3.37399825 7.49703193], cur_train_grp_loss: [0.08842132 0.11513661 0.25501204], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6765, max_kl_dist_index: 0, max_train_grp_loss:  13.7007, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7877, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:30:35,434 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  29, train_loss:  12.6270, val_loss:  12.2293, grad_norm: 0.0063, live_grad: 0.0000, reward_err: 0.0103, 0.0186, 0.0011, KL_dist: 0.6766, 0.3239, 0.6757, param: [ 4.86595237  6.86357918  5.75553994 10.2666122 ], weights: [0.26730464 0.28942375 0.44327161], train_wt_loss:  37.8809, val_wt_loss: 36.6879, train_grp_loss: [11.4962104  13.70019272 13.00500902], val_grp_loss: [12.64735321 12.78790605 11.25099834], train_hist_grp_loss: [2.69410096 3.48912997 7.75203828], cur_train_grp_loss: [0.08842716 0.11513171 0.25500635], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6766, max_kl_dist_index: 0, max_train_grp_loss:  13.7002, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7879, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:30:36,431 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  30, train_loss:  12.6270, val_loss:  12.2298, grad_norm: 0.0065, live_grad: 0.0000, reward_err: 0.0103, 0.0186, 0.0011, KL_dist: 0.6766, 0.3239, 0.6758, param: [ 4.86422849  6.86008218  5.75805342 10.26956074], weights: [0.26512558 0.28783173 0.4470427 ], train_wt_loss:  37.8810, val_wt_loss: 36.6895, train_grp_loss: [11.49680877 13.69981427 13.00466943], val_grp_loss: [12.64814233 12.78821712 11.25141605], train_hist_grp_loss: [2.78253335 3.60425764 8.00703846], cur_train_grp_loss: [0.08843239 0.11512767 0.25500018], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6766, max_kl_dist_index: 0, max_train_grp_loss:  13.6998, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7882, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:30:37,410 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  31, train_loss:  12.6271, val_loss:  12.2303, grad_norm: 0.0068, live_grad: 0.0000, reward_err: 0.0103, 0.0186, 0.0011, KL_dist: 0.6767, 0.3240, 0.6758, param: [ 4.86246048  6.85661288  5.76055013 10.27265065], weights: [0.26294907 0.28623167 0.45081926], train_wt_loss:  37.8812, val_wt_loss: 36.6910, train_grp_loss: [11.49732592 13.69953889 13.00430497], val_grp_loss: [12.64885672 12.78865432 11.25179814], train_hist_grp_loss: [2.87097034 3.71938212 8.26203198], cur_train_grp_loss: [0.08843699 0.11512449 0.25499352], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6767, max_kl_dist_index: 0, max_train_grp_loss:  13.6995, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7887, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:30:38,390 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  32, train_loss:  12.6271, val_loss:  12.2308, grad_norm: 0.0070, live_grad: 0.0000, reward_err: 0.0103, 0.0186, 0.0011, KL_dist: 0.6768, 0.3241, 0.6759, param: [ 4.86064812  6.85317103  5.76302989 10.27588286], weights: [0.2607753  0.28462383 0.45460087], train_wt_loss:  37.8813, val_wt_loss: 36.6925, train_grp_loss: [11.49776143 13.69936714 13.00391551], val_grp_loss: [12.649496   12.78921843 11.25214449], train_hist_grp_loss: [2.95941131 3.8345043  8.51701835], cur_train_grp_loss: [0.08844097 0.11512218 0.25498637], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6768, max_kl_dist_index: 0, max_train_grp_loss:  13.6994, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7892, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:30:39,367 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  33, train_loss:  12.6272, val_loss:  12.2314, grad_norm: 0.0073, live_grad: 0.0000, reward_err: 0.0103, 0.0186, 0.0012, KL_dist: 0.6769, 0.3241, 0.6760, param: [ 4.85879114  6.84975631  5.76549251 10.27925829], weights: [0.25860448 0.28300845 0.45838707], train_wt_loss:  37.8815, val_wt_loss: 36.6941, train_grp_loss: [11.49811495 13.69929958 13.00350089], val_grp_loss: [12.65005979 12.7899102  11.25245497], train_hist_grp_loss: [3.04785563 3.94962503 8.77199709], cur_train_grp_loss: [0.08844432 0.11512073 0.25497874], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6769, max_kl_dist_index: 0, max_train_grp_loss:  13.6993, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7899, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:30:40,351 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  34, train_loss:  12.6272, val_loss:  12.2319, grad_norm: 0.0075, live_grad: 0.0000, reward_err: 0.0105, 0.0186, 0.0013, KL_dist: 0.6770, 0.3242, 0.6761, param: [ 4.85688932  6.84636845  5.76793781 10.28277787], weights: [0.25643682 0.28138577 0.46217741], train_wt_loss:  37.8817, val_wt_loss: 36.6957, train_grp_loss: [11.49838608 13.6993368  13.00306098], val_grp_loss: [12.65054773 12.79073042 11.25272945], train_hist_grp_loss: [3.13630267 4.0647452  9.02696769], cur_train_grp_loss: [0.08844704 0.11512016 0.25497061], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6770, max_kl_dist_index: 0, max_train_grp_loss:  13.6993, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7907, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:30:41,337 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  35, train_loss:  12.6273, val_loss:  12.2324, grad_norm: 0.0078, live_grad: 0.0000, reward_err: 0.0105, 0.0186, 0.0013, KL_dist: 0.6771, 0.3243, 0.6762, param: [ 4.85494241  6.84300712  5.77036561 10.28644249], weights: [0.25427251 0.27975604 0.46597144], train_wt_loss:  37.8819, val_wt_loss: 36.6973, train_grp_loss: [11.49857447 13.69947935 13.00259566], val_grp_loss: [12.65095945 12.79167985 11.25296782], train_hist_grp_loss: [3.22475179 4.17986567 9.28192967], cur_train_grp_loss: [0.08844912 0.11512048 0.25496198], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6771, max_kl_dist_index: 0, max_train_grp_loss:  13.6995, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7917, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:30:42,331 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  36, train_loss:  12.6273, val_loss:  12.2330, grad_norm: 0.0080, live_grad: 0.0000, reward_err: 0.0105, 0.0186, 0.0013, KL_dist: 0.6772, 0.3244, 0.6763, param: [ 4.85295017  6.839672    5.77277571 10.29025306], weights: [0.25211176 0.27811952 0.46976872], train_wt_loss:  37.8820, val_wt_loss: 36.6989, train_grp_loss: [11.49867977 13.69972781 13.00210479], val_grp_loss: [12.65129459 12.79275926 11.25316997], train_hist_grp_loss: [3.31320236 4.29498735 9.53688253], cur_train_grp_loss: [0.08845057 0.11512168 0.25495286], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6772, max_kl_dist_index: 0, max_train_grp_loss:  13.6997, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7928, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2550, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:30:43,308 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  37, train_loss:  12.6274, val_loss:  12.2335, grad_norm: 0.0083, live_grad: 0.0000, reward_err: 0.0105, 0.0186, 0.0013, KL_dist: 0.6773, 0.3245, 0.6764, param: [ 4.85091235  6.83636276  5.77516792 10.29421049], weights: [0.24995476 0.27647646 0.47356878], train_wt_loss:  37.8822, val_wt_loss: 36.7005, train_grp_loss: [11.49870162 13.70008275 13.00158824], val_grp_loss: [12.65155282 12.79396944 11.25333583], train_hist_grp_loss: [3.40165374 4.41011111 9.79182576], cur_train_grp_loss: [0.08845138 0.11512376 0.25494323], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6773, max_kl_dist_index: 0, max_train_grp_loss:  13.7001, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7940, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2549, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:30:44,294 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  38, train_loss:  12.6275, val_loss:  12.2341, grad_norm: 0.0085, live_grad: 0.0000, reward_err: 0.0105, 0.0186, 0.0013, KL_dist: 0.6775, 0.3245, 0.6766, param: [ 4.84882873  6.83307905  5.77754205 10.29831567], weights: [0.24780173 0.27482711 0.47737116], train_wt_loss:  37.8824, val_wt_loss: 36.7022, train_grp_loss: [11.49863971 13.70054474 13.00104591], val_grp_loss: [12.6517338  12.79531117 11.2534653 ], train_hist_grp_loss: [ 3.4901053   4.52523786 10.04675886], cur_train_grp_loss: [0.08845155 0.11512675 0.2549331 ], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6775, max_kl_dist_index: 0, max_train_grp_loss:  13.7005, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7953, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2549, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:30:45,315 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  39, train_loss:  12.6275, val_loss:  12.2346, grad_norm: 0.0088, live_grad: 0.0000, reward_err: 0.0105, 0.0186, 0.0013, KL_dist: 0.6776, 0.3246, 0.6767, param: [ 4.84669905  6.82982052  5.77989789 10.30256947], weights: [0.24565286 0.27317172 0.48117542], train_wt_loss:  37.8826, val_wt_loss: 36.7039, train_grp_loss: [11.49849369 13.70111436 13.00047767], val_grp_loss: [12.65183721 12.79678522 11.2535583 ], train_hist_grp_loss: [ 3.57855637  4.64036849 10.30168133], cur_train_grp_loss: [0.08845107 0.11513063 0.25492247], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6776, max_kl_dist_index: 0, max_train_grp_loss:  13.7011, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7968, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2549, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:30:46,326 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  40, train_loss:  12.6276, val_loss:  12.2352, grad_norm: 0.0090, live_grad: 0.0000, reward_err: 0.0105, 0.0186, 0.0013, KL_dist: 0.6777, 0.3247, 0.6769, param: [ 4.84452309  6.82658681  5.78223525 10.30697278], weights: [0.24350836 0.27151056 0.48498109], train_wt_loss:  37.8828, val_wt_loss: 36.7056, train_grp_loss: [11.49826326 13.70179219 12.99988341], val_grp_loss: [12.65186272 12.79839238 11.25361477], train_hist_grp_loss: [ 3.66700632  4.7555039  10.55659266], cur_train_grp_loss: [0.08844995 0.11513541 0.25491133], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6777, max_kl_dist_index: 0, max_train_grp_loss:  13.7018, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7984, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2549, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:30:47,309 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  41, train_loss:  12.6277, val_loss:  12.2358, grad_norm: 0.0093, live_grad: 0.0000, reward_err: 0.0105, 0.0186, 0.0013, KL_dist: 0.6779, 0.3248, 0.6770, param: [ 4.8423006   6.82337753  5.78455392 10.31152646], weights: [0.24136842 0.26984387 0.48878771], train_wt_loss:  37.8830, val_wt_loss: 36.7073, train_grp_loss: [11.49794813 13.7025788  12.99926302], val_grp_loss: [12.65181004 12.80013343 11.25363466], train_hist_grp_loss: [ 3.7554545   4.87064501 10.81149233], cur_train_grp_loss: [0.08844818 0.11514111 0.25489967], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6779, max_kl_dist_index: 0, max_train_grp_loss:  13.7026, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8001, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2549, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:30:48,283 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  42, train_loss:  12.6277, val_loss:  12.2363, grad_norm: 0.0096, live_grad: 0.0000, reward_err: 0.0105, 0.0186, 0.0013, KL_dist: 0.6780, 0.3249, 0.6772, param: [ 4.84003135  6.82019229  5.7868537  10.31623138], weights: [0.23923325 0.26817192 0.49259483], train_wt_loss:  37.8832, val_wt_loss: 36.7090, train_grp_loss: [11.49754798 13.70347478 12.9986164 ], val_grp_loss: [12.65167886 12.80200916 11.25361791], train_hist_grp_loss: [ 3.84390026  4.98579273 11.06637984], cur_train_grp_loss: [0.08844575 0.11514772 0.25488751], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6780, max_kl_dist_index: 0, max_train_grp_loss:  13.7035, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8020, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2549, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:30:49,270 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  43, train_loss:  12.6278, val_loss:  12.2369, grad_norm: 0.0098, live_grad: 0.0000, reward_err: 0.0105, 0.0186, 0.0013, KL_dist: 0.6782, 0.3250, 0.6774, param: [ 4.83771511  6.8170307   5.78913438 10.32108838], weights: [0.23710305 0.26649497 0.49640198], train_wt_loss:  37.8835, val_wt_loss: 36.7108, train_grp_loss: [11.49706256 13.70448071 12.99794345], val_grp_loss: [12.6514689  12.80402036 11.2535645 ], train_hist_grp_loss: [ 3.93234293  5.10094798 11.32125467], cur_train_grp_loss: [0.08844268 0.11515525 0.25487483], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6782, max_kl_dist_index: 0, max_train_grp_loss:  13.7045, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8040, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2549, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:30:50,268 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  44, train_loss:  12.6279, val_loss:  12.2375, grad_norm: 0.0101, live_grad: 0.0000, reward_err: 0.0103, 0.0186, 0.0014, KL_dist: 0.6783, 0.3252, 0.6776, param: [ 4.83535164  6.81389235  5.79139574 10.3260983 ], weights: [0.23497802 0.26481328 0.5002087 ], train_wt_loss:  37.8837, val_wt_loss: 36.7125, train_grp_loss: [11.49649159 13.70559716 12.99724407], val_grp_loss: [12.65117989 12.80616781 11.2534744 ], train_hist_grp_loss: [ 4.02078188  5.21611169 11.57611631], cur_train_grp_loss: [0.08843894 0.1151637  0.25486164], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6783, max_kl_dist_index: 0, max_train_grp_loss:  13.7056, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8062, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2549, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:30:51,249 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  45, train_loss:  12.6280, val_loss:  12.2381, grad_norm: 0.0104, live_grad: 0.0000, reward_err: 0.0103, 0.0186, 0.0014, KL_dist: 0.6785, 0.3253, 0.6778, param: [ 4.83294071  6.8107768   5.79363758 10.33126198], weights: [0.23285835 0.2631271  0.50401455], train_wt_loss:  37.8839, val_wt_loss: 36.7143, train_grp_loss: [11.49583482 13.70682472 12.99651818], val_grp_loss: [12.65081156 12.8084523  11.25334759], train_hist_grp_loss: [ 4.10921643  5.33128477 11.83096423], cur_train_grp_loss: [0.08843455 0.11517309 0.25484792], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6785, max_kl_dist_index: 0, max_train_grp_loss:  13.7068, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8085, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2548, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:30:52,271 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  46, train_loss:  12.6281, val_loss:  12.2387, grad_norm: 0.0106, live_grad: 0.0000, reward_err: 0.0102, 0.0186, 0.0014, KL_dist: 0.6787, 0.3254, 0.6780, param: [ 4.83048209  6.80768364  5.79585968 10.33658024], weights: [0.23074425 0.2614367  0.50781904], train_wt_loss:  37.8842, val_wt_loss: 36.7161, train_grp_loss: [11.49509201 13.70816396 12.99576569], val_grp_loss: [12.65036367 12.81087462 11.25318408], train_hist_grp_loss: [ 4.19764592  5.44646817 12.08579792], cur_train_grp_loss: [0.0884295  0.1151834  0.25483369], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6787, max_kl_dist_index: 0, max_train_grp_loss:  13.7082, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8109, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2548, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:30:53,244 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  47, train_loss:  12.6281, val_loss:  12.2393, grad_norm: 0.0109, live_grad: 0.0000, reward_err: 0.0104, 0.0186, 0.0015, KL_dist: 0.6789, 0.3255, 0.6782, param: [ 4.82797555  6.8046124   5.79806182 10.34205388], weights: [0.22863592 0.25974235 0.51162174], train_wt_loss:  37.8844, val_wt_loss: 36.7180, train_grp_loss: [11.49426293 13.70961547 12.99498652], val_grp_loss: [12.64983596 12.81343555 11.25298385], train_hist_grp_loss: [ 4.28606971  5.56166283 12.34061686], cur_train_grp_loss: [0.08842378 0.11519466 0.25481894], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6789, max_kl_dist_index: 0, max_train_grp_loss:  13.7096, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8134, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2548, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:30:54,236 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  48, train_loss:  12.6282, val_loss:  12.2399, grad_norm: 0.0112, live_grad: 0.0000, reward_err: 0.0104, 0.0186, 0.0015, KL_dist: 0.6790, 0.3257, 0.6784, param: [ 4.82542087  6.80156263  5.80024379 10.34768371], weights: [0.22653353 0.25804429 0.51542218], train_wt_loss:  37.8847, val_wt_loss: 36.7198, train_grp_loss: [11.49334736 13.71117983 12.9941806 ], val_grp_loss: [12.64922822 12.81613588 11.25274695], train_hist_grp_loss: [ 4.37448712  5.67686968 12.59542051], cur_train_grp_loss: [0.08841741 0.11520685 0.25480366], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6790, max_kl_dist_index: 0, max_train_grp_loss:  13.7112, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8161, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2548, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:30:55,254 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  49, train_loss:  12.6283, val_loss:  12.2406, grad_norm: 0.0115, live_grad: 0.0000, reward_err: 0.0104, 0.0186, 0.0015, KL_dist: 0.6792, 0.3258, 0.6787, param: [ 4.82281782  6.79853387  5.80240537 10.35347052], weights: [0.2244373 0.2563428 0.5192199], train_wt_loss:  37.8850, val_wt_loss: 36.7217, train_grp_loss: [11.4923451  13.71285761 12.99334785], val_grp_loss: [12.64854022 12.81897641 11.25247338], train_hist_grp_loss: [ 4.46289748  5.79208968 12.85020837], cur_train_grp_loss: [0.08841036 0.11522    0.25478785], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6792, max_kl_dist_index: 0, max_train_grp_loss:  13.7129, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8190, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2548, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:30:56,240 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  50, train_loss:  12.6284, val_loss:  12.2412, grad_norm: 0.0118, live_grad: 0.0000, reward_err: 0.0104, 0.0186, 0.0015, KL_dist: 0.6794, 0.3259, 0.6789, param: [ 4.82016618  6.79552563  5.80454633 10.35941507], weights: [0.22234742 0.25463814 0.52301444], train_wt_loss:  37.8852, val_wt_loss: 36.7236, train_grp_loss: [11.49125597 13.7146494  12.99248821], val_grp_loss: [12.64777176 12.8219579  11.2521632 ], train_hist_grp_loss: [ 4.55130014  5.90732378 13.1049799 ], cur_train_grp_loss: [0.08840265 0.1152341  0.25477153], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6794, max_kl_dist_index: 0, max_train_grp_loss:  13.7146, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8220, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2548, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:30:57,225 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  51, train_loss:  12.6285, val_loss:  12.2419, grad_norm: 0.0121, live_grad: 0.0000, reward_err: 0.0104, 0.0186, 0.0015, KL_dist: 0.6797, 0.3261, 0.6792, param: [ 4.81746573  6.79253743  5.80666645 10.36551813], weights: [0.22026407 0.25293056 0.52680537], train_wt_loss:  37.8855, val_wt_loss: 36.7256, train_grp_loss: [11.49007979 13.71655578 12.99160161], val_grp_loss: [12.64692265 12.82508115 11.25181645], train_hist_grp_loss: [ 4.63969441  6.02257293 13.35973457], cur_train_grp_loss: [0.08839428 0.11524915 0.25475467], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6797, max_kl_dist_index: 0, max_train_grp_loss:  13.7166, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8251, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2548, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:30:58,217 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  52, train_loss:  12.6286, val_loss:  12.2425, grad_norm: 0.0124, live_grad: 0.0000, reward_err: 0.0104, 0.0186, 0.0015, KL_dist: 0.6799, 0.3262, 0.6794, param: [ 4.81471626  6.78956875  5.8087655  10.37178045], weights: [0.21818745 0.25122034 0.53059221], train_wt_loss:  37.8858, val_wt_loss: 36.7275, train_grp_loss: [11.4888164  13.71857731 12.99068802], val_grp_loss: [12.64599272 12.82834694 11.2514332 ], train_hist_grp_loss: [ 4.72807964  6.13783811 13.61447185], cur_train_grp_loss: [0.08838523 0.11526517 0.25473729], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6799, max_kl_dist_index: 0, max_train_grp_loss:  13.7186, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8283, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2547, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:30:59,211 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  53, train_loss:  12.6287, val_loss:  12.2432, grad_norm: 0.0127, live_grad: 0.0000, reward_err: 0.0104, 0.0186, 0.0015, KL_dist: 0.6801, 0.3264, 0.6797, param: [ 4.81191754  6.78661908  5.81084327 10.37820277], weights: [0.21611774 0.24950772 0.53437453], train_wt_loss:  37.8861, val_wt_loss: 36.7295, train_grp_loss: [11.48746566 13.72071458 12.98974737], val_grp_loss: [12.64498179 12.83175606 11.25101352], train_hist_grp_loss: [ 4.81645515  6.25312027 13.86919123], cur_train_grp_loss: [0.08837551 0.11528216 0.25471937], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6801, max_kl_dist_index: 0, max_train_grp_loss:  13.7207, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8318, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2547, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:31:00,223 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  54, train_loss:  12.6288, val_loss:  12.2438, grad_norm: 0.0130, live_grad: 0.0000, reward_err: 0.0104, 0.0186, 0.0015, KL_dist: 0.6803, 0.3265, 0.6800, param: [ 4.80906938  6.78368791  5.81289951 10.3847858 ], weights: [0.21405514 0.24779298 0.53815188], train_wt_loss:  37.8864, val_wt_loss: 36.7315, train_grp_loss: [11.48602744 13.72296816 12.98877962], val_grp_loss: [12.64388972 12.83530926 11.2505575 ], train_hist_grp_loss: [ 4.90482027  6.36842039 14.12389215], cur_train_grp_loss: [0.08836512 0.11530012 0.25470093], max_reward_err:  0.0186, max_reward_err_index: 1, max_kl_dist:  0.6803, max_kl_dist_index: 0, max_train_grp_loss:  13.7230, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8353, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2547, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:31:01,211 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  55, train_loss:  12.6289, val_loss:  12.2445, grad_norm: 0.0133, live_grad: 0.0000, reward_err: 0.0104, 0.0189, 0.0015, KL_dist: 0.6805, 0.3267, 0.6803, param: [ 4.80617155  6.78077468  5.81493401 10.39153027], weights: [0.21199982 0.24607637 0.54192381], train_wt_loss:  37.8868, val_wt_loss: 36.7336, train_grp_loss: [11.48450163 13.72533862 12.98778473], val_grp_loss: [12.64271637 12.83900735 11.25006524], train_hist_grp_loss: [ 4.99317433  6.48373945 14.37857411], cur_train_grp_loss: [0.08835406 0.11531906 0.25468195], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6805, max_kl_dist_index: 0, max_train_grp_loss:  13.7253, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8390, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2547, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:31:02,197 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  56, train_loss:  12.6290, val_loss:  12.2452, grad_norm: 0.0136, live_grad: 0.0000, reward_err: 0.0103, 0.0189, 0.0016, KL_dist: 0.6808, 0.3269, 0.6806, param: [ 4.80322386  6.77787885  5.81694654 10.39843685], weights: [0.20995198 0.24435815 0.54568987], train_wt_loss:  37.8871, val_wt_loss: 36.7356, train_grp_loss: [11.48288813 13.72782653 12.98676268], val_grp_loss: [12.64146162 12.84285108 11.24953685], train_hist_grp_loss: [ 5.08151665  6.59907843 14.63323655], cur_train_grp_loss: [0.08834232 0.11533898 0.25466245], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6808, max_kl_dist_index: 0, max_train_grp_loss:  13.7278, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8429, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2547, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:31:03,182 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  57, train_loss:  12.6292, val_loss:  12.2459, grad_norm: 0.0139, live_grad: 0.0000, reward_err: 0.0103, 0.0189, 0.0016, KL_dist: 0.6810, 0.3270, 0.6809, param: [ 4.8002261   6.77499986  5.81893685 10.40550623], weights: [0.20791178 0.24263859 0.54944963], train_wt_loss:  37.8875, val_wt_loss: 36.7377, train_grp_loss: [11.48118685 13.73043246 12.98571344], val_grp_loss: [12.64012536 12.84684122 11.24897245], train_hist_grp_loss: [ 5.16984656  6.71443832 14.88787896], cur_train_grp_loss: [0.08832991 0.11535989 0.25464241], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6810, max_kl_dist_index: 0, max_train_grp_loss:  13.7304, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8468, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2546, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:31:04,167 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  58, train_loss:  12.6293, val_loss:  12.2466, grad_norm: 0.0142, live_grad: 0.0000, reward_err: 0.0103, 0.0189, 0.0016, KL_dist: 0.6813, 0.3272, 0.6812, param: [ 4.79717807  6.77213715  5.82090473 10.41273907], weights: [0.20587942 0.24091793 0.55320265], train_wt_loss:  37.8878, val_wt_loss: 36.7399, train_grp_loss: [11.47939774 13.73315697 12.98463698], val_grp_loss: [12.6387075  12.85097855 11.24837218], train_hist_grp_loss: [ 5.25816338  6.8298201  15.14250079], cur_train_grp_loss: [0.08831682 0.11538179 0.25462183], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6813, max_kl_dist_index: 0, max_train_grp_loss:  13.7332, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8510, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2546, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:31:05,173 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  59, train_loss:  12.6294, val_loss:  12.2473, grad_norm: 0.0146, live_grad: 0.0000, reward_err: 0.0103, 0.0189, 0.0016, KL_dist: 0.6815, 0.3274, 0.6816, param: [ 4.79407959  6.76929012  5.82284994 10.42013601], weights: [0.20385506 0.23919643 0.5569485 ], train_wt_loss:  37.8882, val_wt_loss: 36.7420, train_grp_loss: [11.47752074 13.73600063 12.98353329], val_grp_loss: [12.63720795 12.85526383 11.24773618], train_hist_grp_loss: [ 5.34646644  6.94522478 15.39710152], cur_train_grp_loss: [0.08830306 0.11540468 0.25460073], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6816, max_kl_dist_index: 2, max_train_grp_loss:  13.7360, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8553, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2546, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:31:06,157 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  60, train_loss:  12.6295, val_loss:  12.2481, grad_norm: 0.0149, live_grad: 0.0000, reward_err: 0.0102, 0.0189, 0.0017, KL_dist: 0.6818, 0.3276, 0.6819, param: [ 4.79093044  6.76645819  5.82477225 10.42769769], weights: [0.20183889 0.23747436 0.56068675], train_wt_loss:  37.8886, val_wt_loss: 36.7442, train_grp_loss: [11.47555583 13.73896399 12.98240236], val_grp_loss: [12.63562666 12.8596978  11.24706461], train_hist_grp_loss: [ 5.43475506  7.06065336 15.6516806 ], cur_train_grp_loss: [0.08828862 0.11542858 0.25457908], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6819, max_kl_dist_index: 2, max_train_grp_loss:  13.7390, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8597, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2546, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:31:07,140 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  61, train_loss:  12.6297, val_loss:  12.2488, grad_norm: 0.0152, live_grad: 0.0000, reward_err: 0.0102, 0.0189, 0.0017, KL_dist: 0.6821, 0.3278, 0.6823, param: [ 4.78773046  6.76364075  5.82667143 10.43542472], weights: [0.19983108 0.23575196 0.56441697], train_wt_loss:  37.8890, val_wt_loss: 36.7465, train_grp_loss: [11.47350298 13.7420476  12.9812442 ], val_grp_loss: [12.63396358 12.86428124 11.24635765], train_hist_grp_loss: [ 5.52302857  7.17610684 15.90623751], cur_train_grp_loss: [0.08827351 0.11545348 0.25455691], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6823, max_kl_dist_index: 2, max_train_grp_loss:  13.7420, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8643, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2546, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:31:08,124 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  62, train_loss:  12.6298, val_loss:  12.2496, grad_norm: 0.0156, live_grad: 0.0000, reward_err: 0.0102, 0.0189, 0.0017, KL_dist: 0.6824, 0.3280, 0.6827, param: [ 4.78447946  6.76083718  5.82854724 10.44331769], weights: [0.19783178 0.23402948 0.56813873], train_wt_loss:  37.8895, val_wt_loss: 36.7487, train_grp_loss: [11.4713622  13.74525203 12.9800588 ], val_grp_loss: [12.63221867 12.86901487 11.24561549], train_hist_grp_loss: [ 5.61128628  7.29158623 16.16077171], cur_train_grp_loss: [0.08825772 0.11547939 0.2545342 ], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6827, max_kl_dist_index: 2, max_train_grp_loss:  13.7453, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8690, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2545, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:31:09,105 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  63, train_loss:  12.6300, val_loss:  12.2503, grad_norm: 0.0160, live_grad: 0.0000, reward_err: 0.0102, 0.0189, 0.0017, KL_dist: 0.6826, 0.3282, 0.6830, param: [ 4.78117725  6.75804687  5.83039945 10.45137717], weights: [0.19584119 0.23230718 0.57185163], train_wt_loss:  37.8899, val_wt_loss: 36.7510, train_grp_loss: [11.46913351 13.74857781 12.97884617], val_grp_loss: [12.63039193 12.87389946 11.24483832], train_hist_grp_loss: [ 5.69952753  7.40709255 16.41528267], cur_train_grp_loss: [0.08824125 0.11550632 0.25451096], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6830, max_kl_dist_index: 2, max_train_grp_loss:  13.7486, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8739, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2545, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:31:10,093 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  64, train_loss:  12.6301, val_loss:  12.2511, grad_norm: 0.0163, live_grad: 0.0000, reward_err: 0.0102, 0.0189, 0.0017, KL_dist: 0.6829, 0.3284, 0.6834, param: [ 4.77782366  6.75526919  5.83222784 10.45960373], weights: [0.19385945 0.23058531 0.57555524], train_wt_loss:  37.8904, val_wt_loss: 36.7533, train_grp_loss: [11.46681695 13.75202549 12.97760633], val_grp_loss: [12.62848335 12.87893574 11.24402635], train_hist_grp_loss: [ 5.78775163  7.52262682 16.66976985], cur_train_grp_loss: [0.0882241  0.11553427 0.25448718], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6834, max_kl_dist_index: 2, max_train_grp_loss:  13.7520, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8789, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2545, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:31:11,073 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  65, train_loss:  12.6303, val_loss:  12.2519, grad_norm: 0.0167, live_grad: 0.0000, reward_err: 0.0102, 0.0189, 0.0017, KL_dist: 0.6832, 0.3286, 0.6838, param: [ 4.77441853  6.75250347  5.83403216 10.4679979 ], weights: [0.19188673 0.22886412 0.57924916], train_wt_loss:  37.8908, val_wt_loss: 36.7557, train_grp_loss: [11.46441258 13.75559562 12.97633931], val_grp_loss: [12.62649294 12.88412443 11.24317981], train_hist_grp_loss: [ 5.87595792  7.63819006 16.92423272], cur_train_grp_loss: [0.08820628 0.11556324 0.25446287], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6838, max_kl_dist_index: 2, max_train_grp_loss:  13.7556, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8841, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2545, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:31:12,064 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  66, train_loss:  12.6304, val_loss:  12.2527, grad_norm: 0.0171, live_grad: 0.0000, reward_err: 0.0102, 0.0189, 0.0017, KL_dist: 0.6835, 0.3288, 0.6842, param: [ 4.77096169  6.74974908  5.83581218 10.4765602 ], weights: [0.18992319 0.22714384 0.58293297], train_wt_loss:  37.8913, val_wt_loss: 36.7581, train_grp_loss: [11.46192046 13.75928871 12.97504513], val_grp_loss: [12.62442075 12.88946626 11.24229893], train_hist_grp_loss: [ 5.96414571  7.7537833  17.17867074], cur_train_grp_loss: [0.08818779 0.11559324 0.25443803], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6842, max_kl_dist_index: 2, max_train_grp_loss:  13.7593, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8895, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2544, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:31:13,052 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  67, train_loss:  12.6306, val_loss:  12.2535, grad_norm: 0.0175, live_grad: 0.0000, reward_err: 0.0103, 0.0189, 0.0018, KL_dist: 0.6839, 0.3290, 0.6846, param: [ 4.76745297  6.74700534  5.83756769 10.48529114], weights: [0.18796898 0.22542473 0.58660629], train_wt_loss:  37.8918, val_wt_loss: 36.7605, train_grp_loss: [11.45934071 13.76310531 12.97372382], val_grp_loss: [12.62226683 12.89496196 11.24138397], train_hist_grp_loss: [ 6.05231433  7.86940757 17.43308339], cur_train_grp_loss: [0.08816862 0.11562427 0.25441265], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6846, max_kl_dist_index: 2, max_train_grp_loss:  13.7631, max_train_grp_loss_index: 1, max_val_grp_loss:  12.8950, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2544, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:31:14,033 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  68, train_loss:  12.6308, val_loss:  12.2543, grad_norm: 0.0179, live_grad: 0.0000, reward_err: 0.0103, 0.0189, 0.0018, KL_dist: 0.6842, 0.3292, 0.6851, param: [ 4.76389223  6.74427158  5.83929844 10.49419118], weights: [0.18602427 0.22370702 0.59026871], train_wt_loss:  37.8924, val_wt_loss: 36.7630, train_grp_loss: [11.45667341 13.76704593 12.97237544], val_grp_loss: [12.62003124 12.90061224 11.24043518], train_hist_grp_loss: [ 6.1404631   7.98506392 17.68747013], cur_train_grp_loss: [0.08814877 0.11565635 0.25438674], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6851, max_kl_dist_index: 2, max_train_grp_loss:  13.7670, max_train_grp_loss_index: 1, max_val_grp_loss:  12.9006, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2544, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:31:15,033 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  69, train_loss:  12.6310, val_loss:  12.2552, grad_norm: 0.0183, live_grad: 0.0000, reward_err: 0.0103, 0.0189, 0.0018, KL_dist: 0.6845, 0.3295, 0.6855, param: [ 4.76027932  6.74154712  5.8410042  10.50326079], weights: [0.1840892  0.22199096 0.59391984], train_wt_loss:  37.8929, val_wt_loss: 36.7655, train_grp_loss: [11.45391872 13.7711111  12.97100003], val_grp_loss: [12.61771407 12.90641779 11.23945285], train_hist_grp_loss: [ 6.22859136  8.10075338 17.94183043], cur_train_grp_loss: [0.08812826 0.11568946 0.2543603 ], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6855, max_kl_dist_index: 2, max_train_grp_loss:  13.7711, max_train_grp_loss_index: 1, max_val_grp_loss:  12.9064, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2544, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:31:16,014 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  70, train_loss:  12.6312, val_loss:  12.2560, grad_norm: 0.0187, live_grad: 0.0000, reward_err: 0.0105, 0.0189, 0.0019, KL_dist: 0.6848, 0.3297, 0.6859, param: [ 4.75661408  6.73883127  5.84268476 10.51250041], weights: [0.18216393 0.22027678 0.59755929], train_wt_loss:  37.8935, val_wt_loss: 36.7681, train_grp_loss: [11.45107677 13.77530133 12.96959764], val_grp_loss: [12.61531542 12.91237932 11.23843727], train_hist_grp_loss: [ 6.31669843  8.216477   18.19616377], cur_train_grp_loss: [0.08810707 0.11572362 0.25433333], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6859, max_kl_dist_index: 2, max_train_grp_loss:  13.7753, max_train_grp_loss_index: 1, max_val_grp_loss:  12.9124, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2543, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:31:17,039 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  71, train_loss:  12.6314, val_loss:  12.2569, grad_norm: 0.0191, live_grad: 0.0000, reward_err: 0.0105, 0.0189, 0.0019, KL_dist: 0.6852, 0.3299, 0.6864, param: [ 4.75289639  6.73612333  5.84433987 10.52191044], weights: [0.18024859 0.21856472 0.6011867 ], train_wt_loss:  37.8941, val_wt_loss: 36.7707, train_grp_loss: [11.44814775 13.77961712 12.96816834], val_grp_loss: [12.61283541 12.91849751 11.23738873], train_hist_grp_loss: [ 6.40478363  8.33223584 18.4504696 ], cur_train_grp_loss: [0.08808521 0.11575883 0.25430584], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6864, max_kl_dist_index: 2, max_train_grp_loss:  13.7796, max_train_grp_loss_index: 1, max_val_grp_loss:  12.9185, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2543, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:31:18,026 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  72, train_loss:  12.6316, val_loss:  12.2578, grad_norm: 0.0195, live_grad: 0.0000, reward_err: 0.0104, 0.0189, 0.0020, KL_dist: 0.6855, 0.3302, 0.6869, param: [ 4.74912611  6.73342258  5.84596932 10.53149128], weights: [0.17834332 0.216855   0.60480167], train_wt_loss:  37.8947, val_wt_loss: 36.7734, train_grp_loss: [11.44513184 13.78405898 12.9667122 ], val_grp_loss: [12.61027419 12.92477304 11.23630755], train_hist_grp_loss: [ 6.49284631  8.44803094 18.70474742], cur_train_grp_loss: [0.08806267 0.1157951  0.25427781], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6869, max_kl_dist_index: 2, max_train_grp_loss:  13.7841, max_train_grp_loss_index: 1, max_val_grp_loss:  12.9248, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2543, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:31:19,024 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  73, train_loss:  12.6318, val_loss:  12.2587, grad_norm: 0.0200, live_grad: 0.0000, reward_err: 0.0104, 0.0189, 0.0020, KL_dist: 0.6859, 0.3304, 0.6873, param: [ 4.74530312  6.7307283   5.84757289 10.5412433 ], weights: [0.17644828 0.21514787 0.60840385], train_wt_loss:  37.8954, val_wt_loss: 36.7761, train_grp_loss: [11.44202924 13.78862739 12.9652293 ], val_grp_loss: [12.60763191 12.93120658 11.23519407], train_hist_grp_loss: [ 6.58088578  8.56386337 18.95899667], cur_train_grp_loss: [0.08803948 0.11583243 0.25424926], max_reward_err:  0.0189, max_reward_err_index: 1, max_kl_dist:  0.6873, max_kl_dist_index: 2, max_train_grp_loss:  13.7886, max_train_grp_loss_index: 1, max_val_grp_loss:  12.9312, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2542, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:31:20,017 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  74, train_loss:  12.6320, val_loss:  12.2596, grad_norm: 0.0204, live_grad: 0.0000, reward_err: 0.0103, 0.0193, 0.0021, KL_dist: 0.6862, 0.3307, 0.6878, param: [ 4.74142729  6.72803979  5.84915034 10.55116685], weights: [0.17456359 0.21344354 0.61199287], train_wt_loss:  37.8960, val_wt_loss: 36.7788, train_grp_loss: [11.4388402  13.79332284 12.96371971], val_grp_loss: [12.60490875 12.9377988  11.23404862], train_hist_grp_loss: [ 6.66890139  8.67973419 19.21321686], cur_train_grp_loss: [0.08801561 0.11587082 0.25422018], max_reward_err:  0.0193, max_reward_err_index: 1, max_kl_dist:  0.6878, max_kl_dist_index: 2, max_train_grp_loss:  13.7933, max_train_grp_loss_index: 1, max_val_grp_loss:  12.9378, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2542, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:31:21,000 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  75, train_loss:  12.6322, val_loss:  12.2605, grad_norm: 0.0209, live_grad: 0.0000, reward_err: 0.0103, 0.0193, 0.0021, KL_dist: 0.6866, 0.3309, 0.6883, param: [ 4.73749852  6.72535629  5.85070147 10.56126224], weights: [0.17268939 0.21174225 0.61556837], train_wt_loss:  37.8967, val_wt_loss: 36.7816, train_grp_loss: [11.43556496 13.79814582 12.96218353], val_grp_loss: [12.60210491 12.94455034 11.23287156], train_hist_grp_loss: [ 6.75689247  8.79564446 19.46740744], cur_train_grp_loss: [0.08799108 0.11591028 0.25419058], max_reward_err:  0.0193, max_reward_err_index: 1, max_kl_dist:  0.6883, max_kl_dist_index: 2, max_train_grp_loss:  13.7981, max_train_grp_loss_index: 1, max_val_grp_loss:  12.9446, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2542, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:31:21,972 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  76, train_loss:  12.6325, val_loss:  12.2615, grad_norm: 0.0214, live_grad: 0.0000, reward_err: 0.0103, 0.0194, 0.0021, KL_dist: 0.6869, 0.3312, 0.6888, param: [ 4.73351669  6.72267707  5.85222605 10.57152978], weights: [0.1708258 0.2100442 0.61913  ], train_wt_loss:  37.8975, val_wt_loss: 36.7844, train_grp_loss: [11.43220379 13.80309679 12.96062086], val_grp_loss: [12.59922059 12.95146184 11.23166325], train_hist_grp_loss: [ 6.84485835  8.91159527 19.7215679 ], cur_train_grp_loss: [0.08796588 0.11595081 0.25416046], max_reward_err:  0.0194, max_reward_err_index: 1, max_kl_dist:  0.6888, max_kl_dist_index: 2, max_train_grp_loss:  13.8031, max_train_grp_loss_index: 1, max_val_grp_loss:  12.9515, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2542, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:31:22,962 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  77, train_loss:  12.6327, val_loss:  12.2624, grad_norm: 0.0219, live_grad: 0.0000, reward_err: 0.0103, 0.0194, 0.0021, KL_dist: 0.6873, 0.3315, 0.6894, param: [ 4.72948172  6.72000138  5.85372386 10.58196974], weights: [0.16897295 0.20834963 0.62267742], train_wt_loss:  37.8982, val_wt_loss: 36.7873, train_grp_loss: [11.42875699 13.80817621 12.95903179], val_grp_loss: [12.59625603 12.95853394 11.23042409], train_hist_grp_loss: [ 6.93279838  9.02758768 19.97569772], cur_train_grp_loss: [0.08794003 0.11599241 0.25412982], max_reward_err:  0.0194, max_reward_err_index: 1, max_kl_dist:  0.6894, max_kl_dist_index: 2, max_train_grp_loss:  13.8082, max_train_grp_loss_index: 1, max_val_grp_loss:  12.9585, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2541, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:31:23,959 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  78, train_loss:  12.6330, val_loss:  12.2634, grad_norm: 0.0224, live_grad: 0.0000, reward_err: 0.0103, 0.0194, 0.0021, KL_dist: 0.6877, 0.3317, 0.6899, param: [ 4.7253935   6.71732847  5.85519469 10.59258237], weights: [0.16713097 0.20665875 0.62621028], train_wt_loss:  37.8990, val_wt_loss: 36.7902, train_grp_loss: [11.42522486 13.81338454 12.95741645], val_grp_loss: [12.59321148 12.96576725 11.22915447], train_hist_grp_loss: [ 7.0207119   9.14362277 20.22979638], cur_train_grp_loss: [0.08791352 0.11603509 0.25409866], max_reward_err:  0.0194, max_reward_err_index: 1, max_kl_dist:  0.6899, max_kl_dist_index: 2, max_train_grp_loss:  13.8134, max_train_grp_loss_index: 1, max_val_grp_loss:  12.9658, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2541, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:31:24,961 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  79, train_loss:  12.6333, val_loss:  12.2644, grad_norm: 0.0229, live_grad: 0.0000, reward_err: 0.0103, 0.0194, 0.0021, KL_dist: 0.6881, 0.3320, 0.6904, param: [ 4.72125196  6.71465757  5.85663834 10.60336788], weights: [0.16529998 0.20497176 0.62972826], train_wt_loss:  37.8998, val_wt_loss: 36.7932, train_grp_loss: [11.42160775 13.81872223 12.95577495], val_grp_loss: [12.59008721 12.97316237 11.22785478], train_hist_grp_loss: [ 7.10859824  9.25970163 20.48386337], cur_train_grp_loss: [0.08788635 0.11607886 0.25406699], max_reward_err:  0.0194, max_reward_err_index: 1, max_kl_dist:  0.6904, max_kl_dist_index: 2, max_train_grp_loss:  13.8187, max_train_grp_loss_index: 1, max_val_grp_loss:  12.9732, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2541, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:31:25,953 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  80, train_loss:  12.6336, val_loss:  12.2654, grad_norm: 0.0234, live_grad: 0.0000, reward_err: 0.0103, 0.0194, 0.0021, KL_dist: 0.6885, 0.3323, 0.6910, param: [ 4.71705701  6.71198792  5.8580546  10.61432649], weights: [0.16348009 0.20328889 0.63323103], train_wt_loss:  37.9007, val_wt_loss: 36.7963, train_grp_loss: [11.417906   13.82418972 12.95410742], val_grp_loss: [12.58688351 12.98071991 11.22652546], train_hist_grp_loss: [ 7.19645676  9.37582535 20.73789818], cur_train_grp_loss: [0.08785852 0.11612372 0.2540348 ], max_reward_err:  0.0194, max_reward_err_index: 1, max_kl_dist:  0.6910, max_kl_dist_index: 2, max_train_grp_loss:  13.8242, max_train_grp_loss_index: 1, max_val_grp_loss:  12.9807, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2540, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:31:26,938 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  81, train_loss:  12.6338, val_loss:  12.2665, grad_norm: 0.0240, live_grad: 0.0000, reward_err: 0.0101, 0.0194, 0.0022, KL_dist: 0.6889, 0.3326, 0.6915, param: [ 4.71280859  6.70931875  5.85944325 10.62545835], weights: [0.16167141 0.20161032 0.63671827], train_wt_loss:  37.9015, val_wt_loss: 36.7994, train_grp_loss: [11.41411999 13.82978742 12.95241399], val_grp_loss: [12.5836007  12.98844044 11.22516694], train_hist_grp_loss: [ 7.28428681  9.49199501 20.99190028], cur_train_grp_loss: [0.08783005 0.11616966 0.25400211], max_reward_err:  0.0194, max_reward_err_index: 1, max_kl_dist:  0.6915, max_kl_dist_index: 2, max_train_grp_loss:  13.8298, max_train_grp_loss_index: 1, max_val_grp_loss:  12.9884, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2540, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:31:27,924 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  82, train_loss:  12.6341, val_loss:  12.2675, grad_norm: 0.0245, live_grad: 0.0000, reward_err: 0.0101, 0.0196, 0.0022, KL_dist: 0.6893, 0.3329, 0.6921, param: [ 4.70850664  6.70664928  5.8608041  10.63676362], weights: [0.15987405 0.19993628 0.64018966], train_wt_loss:  37.9024, val_wt_loss: 36.8025, train_grp_loss: [11.41025012 13.83551577 12.9506948 ], val_grp_loss: [12.58023909 12.99632453 11.22377966], train_hist_grp_loss: [ 7.37208773  9.60821171 21.24586918], cur_train_grp_loss: [0.08780092 0.1162167  0.2539689 ], max_reward_err:  0.0196, max_reward_err_index: 1, max_kl_dist:  0.6921, max_kl_dist_index: 2, max_train_grp_loss:  13.8355, max_train_grp_loss_index: 1, max_val_grp_loss:  12.9963, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2540, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:31:28,918 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  83, train_loss:  12.6345, val_loss:  12.2686, grad_norm: 0.0251, live_grad: 0.0000, reward_err: 0.0101, 0.0200, 0.0022, KL_dist: 0.6897, 0.3332, 0.6927, param: [ 4.7041511   6.70397872  5.86213694 10.64824241], weights: [0.15808813 0.19826696 0.64364491], train_wt_loss:  37.9034, val_wt_loss: 36.8057, train_grp_loss: [11.4062968  13.84137516 12.94894999], val_grp_loss: [12.57679904 13.00437274 11.22236409], train_hist_grp_loss: [ 7.45985889  9.72447655 21.49980438], cur_train_grp_loss: [0.08777115 0.11626484 0.25393519], max_reward_err:  0.0200, max_reward_err_index: 1, max_kl_dist:  0.6927, max_kl_dist_index: 2, max_train_grp_loss:  13.8414, max_train_grp_loss_index: 1, max_val_grp_loss:  13.0044, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2539, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:31:29,904 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  84, train_loss:  12.6348, val_loss:  12.2697, grad_norm: 0.0257, live_grad: 0.0000, reward_err: 0.0101, 0.0203, 0.0022, KL_dist: 0.6902, 0.3335, 0.6933, param: [ 4.69974193  6.7013063   5.86344159 10.6598948 ], weights: [0.15631373 0.19660255 0.64708371], train_wt_loss:  37.9044, val_wt_loss: 36.8090, train_grp_loss: [11.40226049 13.847366   12.94717973], val_grp_loss: [12.57328092 13.01258561 11.22092069], train_hist_grp_loss: [ 7.54759963  9.84079063 21.75370536], cur_train_grp_loss: [0.08774074 0.11631408 0.25390098], max_reward_err:  0.0203, max_reward_err_index: 1, max_kl_dist:  0.6933, max_kl_dist_index: 2, max_train_grp_loss:  13.8474, max_train_grp_loss_index: 1, max_val_grp_loss:  13.0126, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2539, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:31:30,879 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  85, train_loss:  12.6351, val_loss:  12.2708, grad_norm: 0.0263, live_grad: 0.0000, reward_err: 0.0101, 0.0205, 0.0022, KL_dist: 0.6906, 0.3338, 0.6939, param: [ 4.69527909  6.69863121  5.86471786 10.67172087], weights: [0.15455097 0.19494326 0.65050577], train_wt_loss:  37.9054, val_wt_loss: 36.8124, train_grp_loss: [11.39814162 13.85348867 12.94538418], val_grp_loss: [12.56968511 13.02096366 11.21944995], train_hist_grp_loss: [ 7.63530933  9.95715505 22.00757163], cur_train_grp_loss: [0.0877097  0.11636442 0.25386627], max_reward_err:  0.0205, max_reward_err_index: 1, max_kl_dist:  0.6939, max_kl_dist_index: 2, max_train_grp_loss:  13.8535, max_train_grp_loss_index: 1, max_val_grp_loss:  13.0210, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2539, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:31:31,857 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  86, train_loss:  12.6355, val_loss:  12.2719, grad_norm: 0.0269, live_grad: 0.0000, reward_err: 0.0101, 0.0205, 0.0022, KL_dist: 0.6910, 0.3341, 0.6945, param: [ 4.69076256  6.69595266  5.86596554 10.68372063], weights: [0.15279993 0.19328925 0.65391081], train_wt_loss:  37.9064, val_wt_loss: 36.8157, train_grp_loss: [11.3939407  13.85974355 12.94356349], val_grp_loss: [12.56601203 13.02950742 11.21795236], train_hist_grp_loss: [ 7.72298734 10.07357092 22.26140269], cur_train_grp_loss: [0.08767801 0.11641587 0.25383106], max_reward_err:  0.0205, max_reward_err_index: 1, max_kl_dist:  0.6945, max_kl_dist_index: 2, max_train_grp_loss:  13.8597, max_train_grp_loss_index: 1, max_val_grp_loss:  13.0295, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2538, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:31:32,842 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  87, train_loss:  12.6358, val_loss:  12.2731, grad_norm: 0.0275, live_grad: 0.0000, reward_err: 0.0101, 0.0205, 0.0022, KL_dist: 0.6915, 0.3344, 0.6951, param: [ 4.68619232  6.69326986  5.86718447 10.69589411], weights: [0.15106071 0.19164074 0.65729855], train_wt_loss:  37.9075, val_wt_loss: 36.8192, train_grp_loss: [11.38965822 13.86613101 12.94171787], val_grp_loss: [12.5622621  13.03821737 11.21642844], train_hist_grp_loss: [ 7.81063304 10.19003935 22.51519805], cur_train_grp_loss: [0.0876457  0.11646843 0.25379536], max_reward_err:  0.0205, max_reward_err_index: 1, max_kl_dist:  0.6951, max_kl_dist_index: 2, max_train_grp_loss:  13.8661, max_train_grp_loss_index: 1, max_val_grp_loss:  13.0382, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2538, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:31:33,830 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  88, train_loss:  12.6362, val_loss:  12.2742, grad_norm: 0.0281, live_grad: 0.0000, reward_err: 0.0101, 0.0208, 0.0022, KL_dist: 0.6919, 0.3348, 0.6957, param: [ 4.68156835  6.690582    5.86837445 10.70824127], weights: [0.1493334  0.18999789 0.66066871], train_wt_loss:  37.9087, val_wt_loss: 36.8227, train_grp_loss: [11.38529471 13.8726514  12.93984747], val_grp_loss: [12.55843576 13.04709399 11.21487871], train_hist_grp_loss: [ 7.8982458  10.30656146 22.76895722], cur_train_grp_loss: [0.08761276 0.11652211 0.25375917], max_reward_err:  0.0208, max_reward_err_index: 1, max_kl_dist:  0.6957, max_kl_dist_index: 2, max_train_grp_loss:  13.8727, max_train_grp_loss_index: 1, max_val_grp_loss:  13.0471, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2538, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:31:34,845 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  89, train_loss:  12.6366, val_loss:  12.2754, grad_norm: 0.0288, live_grad: 0.0000, reward_err: 0.0101, 0.0208, 0.0022, KL_dist: 0.6924, 0.3351, 0.6963, param: [ 4.67689066  6.68788828  5.86953532 10.72076205], weights: [0.14761808 0.18836088 0.66402104], train_wt_loss:  37.9098, val_wt_loss: 36.8263, train_grp_loss: [11.38085072 13.87930506 12.9379525 ], val_grp_loss: [12.55453349 13.05613776 11.21330369], train_hist_grp_loss: [ 7.98582499 10.42313837 23.02267972], cur_train_grp_loss: [0.08757919 0.1165769  0.2537225 ], max_reward_err:  0.0208, max_reward_err_index: 1, max_kl_dist:  0.6963, max_kl_dist_index: 2, max_train_grp_loss:  13.8793, max_train_grp_loss_index: 1, max_val_grp_loss:  13.0561, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2537, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:31:35,826 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  90, train_loss:  12.6370, val_loss:  12.2767, grad_norm: 0.0294, live_grad: 0.0000, reward_err: 0.0099, 0.0208, 0.0022, KL_dist: 0.6928, 0.3354, 0.6970, param: [ 4.67215926  6.68518789  5.8706669  10.73345638], weights: [0.14591482 0.1867299  0.66735528], train_wt_loss:  37.9111, val_wt_loss: 36.8300, train_grp_loss: [11.37632681 13.88609231 12.93603316], val_grp_loss: [12.55055577 13.06534912 11.21170394], train_hist_grp_loss: [ 8.07336999 10.53977118 23.27636507], cur_train_grp_loss: [0.08754501 0.11663282 0.25368534], max_reward_err:  0.0208, max_reward_err_index: 1, max_kl_dist:  0.6970, max_kl_dist_index: 2, max_train_grp_loss:  13.8861, max_train_grp_loss_index: 1, max_val_grp_loss:  13.0653, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2537, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:31:36,816 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  91, train_loss:  12.6374, val_loss:  12.2779, grad_norm: 0.0301, live_grad: 0.0000, reward_err: 0.0099, 0.0212, 0.0022, KL_dist: 0.6933, 0.3358, 0.6976, param: [ 4.66737417  6.68248003  5.87176903 10.74632413], weights: [0.14422372 0.1851051  0.67067118], train_wt_loss:  37.9123, val_wt_loss: 36.8337, train_grp_loss: [11.37172358 13.89301349 12.93408965], val_grp_loss: [12.54650311 13.0747285  11.21008   ], train_hist_grp_loss: [ 8.1608802  10.65646103 23.53001278], cur_train_grp_loss: [0.08751021 0.11668985 0.25364771], max_reward_err:  0.0212, max_reward_err_index: 1, max_kl_dist:  0.6976, max_kl_dist_index: 2, max_train_grp_loss:  13.8930, max_train_grp_loss_index: 1, max_val_grp_loss:  13.0747, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2536, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:31:37,789 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  92, train_loss:  12.6379, val_loss:  12.2792, grad_norm: 0.0308, live_grad: 0.0000, reward_err: 0.0099, 0.0213, 0.0022, KL_dist: 0.6938, 0.3361, 0.6983, param: [ 4.66253541  6.67976389  5.87284155 10.75936517], weights: [0.14254484 0.18348667 0.67396849], train_wt_loss:  37.9136, val_wt_loss: 36.8375, train_grp_loss: [11.36704164 13.90006889 12.93212219], val_grp_loss: [12.54237604 13.08427631 11.20843245], train_hist_grp_loss: [ 8.24835499 10.77320904 23.78362238], cur_train_grp_loss: [0.0874748  0.11674801 0.2536096 ], max_reward_err:  0.0213, max_reward_err_index: 1, max_kl_dist:  0.6983, max_kl_dist_index: 2, max_train_grp_loss:  13.9001, max_train_grp_loss_index: 1, max_val_grp_loss:  13.0843, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2536, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:31:38,797 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  93, train_loss:  12.6383, val_loss:  12.2805, grad_norm: 0.0315, live_grad: 0.0000, reward_err: 0.0099, 0.0213, 0.0022, KL_dist: 0.6943, 0.3365, 0.6990, param: [ 4.65764303  6.67703867  5.87388429 10.77257931], weights: [0.14087825 0.18187476 0.67724699], train_wt_loss:  37.9150, val_wt_loss: 36.8414, train_grp_loss: [11.36228162 13.90725879 12.93013098], val_grp_loss: [12.5381751  13.09399296 11.20676187], train_hist_grp_loss: [ 8.33579378 10.89001635 24.0371934 ], cur_train_grp_loss: [0.08743878 0.1168073  0.25357102], max_reward_err:  0.0213, max_reward_err_index: 1, max_kl_dist:  0.6990, max_kl_dist_index: 2, max_train_grp_loss:  13.9073, max_train_grp_loss_index: 1, max_val_grp_loss:  13.0940, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2536, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:31:39,799 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  94, train_loss:  12.6388, val_loss:  12.2818, grad_norm: 0.0323, live_grad: 0.0000, reward_err: 0.0099, 0.0213, 0.0022, KL_dist: 0.6947, 0.3368, 0.6997, param: [ 4.65269708  6.67430355  5.87489712 10.78596635], weights: [0.13922403 0.18026954 0.68050644], train_wt_loss:  37.9164, val_wt_loss: 36.8453, train_grp_loss: [11.35744418 13.91458349 12.92811627], val_grp_loss: [12.53390086 13.10387881 11.20506885], train_hist_grp_loss: [ 8.42319594 11.00688407 24.29072538], cur_train_grp_loss: [0.08740217 0.11686772 0.25353198], max_reward_err:  0.0213, max_reward_err_index: 1, max_kl_dist:  0.6997, max_kl_dist_index: 2, max_train_grp_loss:  13.9146, max_train_grp_loss_index: 1, max_val_grp_loss:  13.1039, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2535, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:31:40,788 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  95, train_loss:  12.6393, val_loss:  12.2831, grad_norm: 0.0330, live_grad: 0.0000, reward_err: 0.0099, 0.0217, 0.0022, KL_dist: 0.6952, 0.3372, 0.7004, param: [ 4.6476976   6.67155772  5.87587987 10.79952605], weights: [0.13758222 0.17867115 0.68374663], train_wt_loss:  37.9178, val_wt_loss: 36.8493, train_grp_loss: [11.35252999 13.92204324 12.92607828], val_grp_loss: [12.52955391 13.11393423 11.20335398], train_hist_grp_loss: [ 8.5105609  11.12381334 24.54421786], cur_train_grp_loss: [0.08736496 0.11692927 0.25349248], max_reward_err:  0.0217, max_reward_err_index: 1, max_kl_dist:  0.7004, max_kl_dist_index: 2, max_train_grp_loss:  13.9220, max_train_grp_loss_index: 1, max_val_grp_loss:  13.1139, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2535, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:31:41,770 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  96, train_loss:  12.6398, val_loss:  12.2845, grad_norm: 0.0338, live_grad: 0.0000, reward_err: 0.0099, 0.0217, 0.0022, KL_dist: 0.6957, 0.3376, 0.7011, param: [ 4.64264468  6.66880038  5.87683241 10.81325813], weights: [0.1359529  0.17707976 0.68696734], train_wt_loss:  37.9193, val_wt_loss: 36.8534, train_grp_loss: [11.34753975 13.92963828 12.92401727], val_grp_loss: [12.52513485 13.12415955 11.20161788], train_hist_grp_loss: [ 8.59788805 11.2408053  24.79767037], cur_train_grp_loss: [0.08732715 0.11699196 0.25345252], max_reward_err:  0.0217, max_reward_err_index: 1, max_kl_dist:  0.7011, max_kl_dist_index: 2, max_train_grp_loss:  13.9296, max_train_grp_loss_index: 1, max_val_grp_loss:  13.1242, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2535, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:31:42,769 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  97, train_loss:  12.6403, val_loss:  12.2859, grad_norm: 0.0346, live_grad: 0.0000, reward_err: 0.0099, 0.0217, 0.0022, KL_dist: 0.6963, 0.3379, 0.7018, param: [ 4.6375384   6.66603072  5.87775461 10.8271623 ], weights: [0.13433612 0.17549551 0.69016837], train_wt_loss:  37.9209, val_wt_loss: 36.8576, train_grp_loss: [11.34247418 13.93736886 12.92193346], val_grp_loss: [12.52064432 13.13455509 11.19986118], train_hist_grp_loss: [ 8.68517682 11.35786108 25.05108247], cur_train_grp_loss: [0.08728877 0.11705578 0.2534121 ], max_reward_err:  0.0217, max_reward_err_index: 1, max_kl_dist:  0.7018, max_kl_dist_index: 2, max_train_grp_loss:  13.9374, max_train_grp_loss_index: 1, max_val_grp_loss:  13.1346, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2534, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:31:43,756 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  98, train_loss:  12.6408, val_loss:  12.2873, grad_norm: 0.0354, live_grad: 0.0000, reward_err: 0.0099, 0.0217, 0.0022, KL_dist: 0.6968, 0.3383, 0.7025, param: [ 4.63237885  6.66324795  5.87864633 10.84123821], weights: [0.13273193 0.17391854 0.69334953], train_wt_loss:  37.9225, val_wt_loss: 36.8619, train_grp_loss: [11.33733402 13.9452352  12.91982713], val_grp_loss: [12.51608295 13.14512115 11.19808449], train_hist_grp_loss: [ 8.77242662 11.47498183 25.30445372], cur_train_grp_loss: [0.0872498  0.11712075 0.25337124], max_reward_err:  0.0217, max_reward_err_index: 1, max_kl_dist:  0.7025, max_kl_dist_index: 2, max_train_grp_loss:  13.9452, max_train_grp_loss_index: 1, max_val_grp_loss:  13.1451, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2534, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:31:44,776 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  99, train_loss:  12.6414, val_loss:  12.2887, grad_norm: 0.0362, live_grad: 0.0000, reward_err: 0.0099, 0.0221, 0.0022, KL_dist: 0.6973, 0.3387, 0.7033, param: [ 4.62716612  6.66045125  5.87950745 10.85548551], weights: [0.13114038 0.17234901 0.69651061], train_wt_loss:  37.9241, val_wt_loss: 36.8662, train_grp_loss: [11.33212003 13.95323748 12.91769854], val_grp_loss: [12.5114514  13.15585801 11.19628847], train_hist_grp_loss: [ 8.85963688 11.59216868 25.55778366], cur_train_grp_loss: [0.08721026 0.11718685 0.25332994], max_reward_err:  0.0221, max_reward_err_index: 1, max_kl_dist:  0.7033, max_kl_dist_index: 2, max_train_grp_loss:  13.9532, max_train_grp_loss_index: 1, max_val_grp_loss:  13.1559, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2533, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:31:45,689 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1654] - INFO: Iteration:  99, train_loss:  12.6414, val_loss:  12.2887, grad_norm: 0.0362,  live_grad: 0.0000, reward_err: 0.0099, 0.0221, 0.0022, KL_dist: 0.6973, 0.3387, 0.7033, param: [ 4.62716612  6.66045125  5.87950745 10.85548551], weights: [0.13114038 0.17234901 0.69651061], train_wt_loss:  37.9241, val_wt_loss: 36.8662, train_grp_loss: [11.33212003 13.95323748 12.91769854], val_grp_loss: [12.5114514  13.15585801 11.19628847], train_hist_grp_loss: [ 8.85963688 11.59216868 25.55778366], cur_train_grp_loss: [0.08721026 0.11718685 0.25332994], max_reward_err:  0.0221, max_reward_err_index: 1, max_kl_dist:  0.7033, max_kl_dist_index: 2, max_train_grp_loss:  13.9532, max_train_grp_loss_index: 1, max_val_grp_loss:  13.1559, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2533, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:31:45,910 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:388] - INFO: Policy parameter learned solely on the preference data rdpo: [ 4.62716612  6.66045125  5.87950745 10.85548551].
2024-10-07 17:31:46,251 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Uniform reward: 3.8511, 3.8511, 3.1970
2024-10-07 17:31:46,252 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Optimal reward: 3.8856, 7.2460, 3.3201
2024-10-07 17:31:46,253 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Policy reward: 3.8470, 7.0861, 3.3128
2024-10-07 17:31:46,253 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:402] - INFO: Reward Error: 0.0099, 0.0221, 0.0022
2024-10-07 17:31:46,932 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:417] - INFO: Optimal reward: 3.8856, 7.2460, 3.3201
Known param reward: [[3.885563232421875, 6.83889453125, 3.291370361328125], [3.493690185546875, 7.24602734375, 3.1155205078125], [3.850873046875, 7.10487548828125, 3.320061279296875]], Known param reward error: [[0.0, 0.05618703783269167, 0.008641683256769945], [0.10085360176489651, 0.0, 0.06160752898142066], [0.008927968346368324, 0.019479895503085456, 0.0]].
