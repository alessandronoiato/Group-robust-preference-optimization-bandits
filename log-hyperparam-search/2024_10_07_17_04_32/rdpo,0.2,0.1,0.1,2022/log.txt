2024-10-07 17:28:16,325 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log-hyperparam-search/2024_10_07_17_04_32/rdpo,0.2,0.1,0.1,2022
2024-10-07 17:28:16,327 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2022
2024-10-07 17:28:16,328 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-10-07 17:28:16,415 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.3214, l2 distance: 25.6155, acc: 0.89.
2024-10-07 17:28:16,416 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-10-07 17:28:16,417 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [ 4.91492317 13.51244723  6.71533233  9.49961375]
2024-10-07 17:28:16,625 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.8530, 6.9304, 3.3326
2024-10-07 17:28:16,849 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1314] - INFO: unique_group_ids: {0, 1, 2}
2024-10-07 17:28:18,047 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  0, train_loss:  13.4334, val_loss:  12.2626, grad_norm: 0.5704, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6510, 0.3482, 0.6813, param: [4.14843583 9.52724086 4.95510366 8.8621961 ], weights: [0.33003072 0.33042461 0.33954466], train_wt_loss:  40.3003, val_wt_loss: 36.7878, train_grp_loss: [11.73152113 15.90071696 11.15160157], val_grp_loss: [10.61699614 14.91775387 11.26897761], train_hist_grp_loss: [0.17243466 0.18436246 0.45663202], cur_train_grp_loss: [0.17243466 0.18436246 0.45663202], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6813, max_kl_dist_index: 2, max_train_grp_loss:  15.9007, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9178, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.4566, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:28:19,077 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  1, train_loss:  13.4334, val_loss:  12.2625, grad_norm: 0.0004, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6509, 0.3481, 0.6812, param: [4.14861844 9.52438716 4.95666684 8.86313813], weights: [0.32811886 0.32945308 0.34242806], train_wt_loss:  40.3003, val_wt_loss: 36.7874, train_grp_loss: [11.73321321 15.89889274 11.15213802], val_grp_loss: [10.61827278 14.91532182 11.26965348], train_hist_grp_loss: [0.2670437  0.30762383 0.69390014], cur_train_grp_loss: [0.09460904 0.12326137 0.23726812], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6812, max_kl_dist_index: 2, max_train_grp_loss:  15.8989, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9153, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2373, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:28:20,098 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  2, train_loss:  13.4334, val_loss:  12.2623, grad_norm: 0.0003, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6509, 0.3480, 0.6811, param: [4.14877769 9.52158362 4.95821291 8.86413337], weights: [0.32620587 0.3284712  0.34532293], train_wt_loss:  40.3003, val_wt_loss: 36.7869, train_grp_loss: [11.7348543  15.89712785 11.15265273], val_grp_loss: [10.61950434 14.91297834 11.27031272], train_hist_grp_loss: [0.36166639 0.43087106 0.93117967], cur_train_grp_loss: [0.09462269 0.12324723 0.23727953], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6811, max_kl_dist_index: 2, max_train_grp_loss:  15.8971, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9130, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2373, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:28:21,184 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  3, train_loss:  13.4334, val_loss:  12.2622, grad_norm: 0.0002, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6509, 0.3479, 0.6810, param: [4.14891353 9.51883034 4.95974179 8.86518208], weights: [0.32429184 0.32747905 0.34822911], train_wt_loss:  40.3003, val_wt_loss: 36.7865, train_grp_loss: [11.73644415 15.89542247 11.15314558], val_grp_loss: [10.62069059 14.91072372 11.27095522], train_hist_grp_loss: [0.45630231 0.55410461 1.16847016], cur_train_grp_loss: [0.09463592 0.12323355 0.23729048], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6810, max_kl_dist_index: 2, max_train_grp_loss:  15.8954, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9107, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2373, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:28:22,255 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  4, train_loss:  13.4334, val_loss:  12.2620, grad_norm: 0.0003, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6509, 0.3479, 0.6810, param: [4.1490259  9.51612745 4.96125335 8.86628451], weights: [0.32237687 0.32647672 0.35114641], train_wt_loss:  40.3003, val_wt_loss: 36.7861, train_grp_loss: [11.7379825  15.89377676 11.15361643], val_grp_loss: [10.62183132 14.90855822 11.27158086], train_hist_grp_loss: [0.55095105 0.67732494 1.40577113], cur_train_grp_loss: [0.09464874 0.12322033 0.23730097], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6810, max_kl_dist_index: 2, max_train_grp_loss:  15.8938, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9086, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2373, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:28:23,340 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  5, train_loss:  13.4334, val_loss:  12.2619, grad_norm: 0.0004, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6508, 0.3478, 0.6809, param: [4.14911474 9.51347505 4.9627475  8.86744092], weights: [0.32046105 0.3254643  0.35407464], train_wt_loss:  40.3003, val_wt_loss: 36.7858, train_grp_loss: [11.73946911 15.89219087 11.15406516], val_grp_loss: [10.62292634 14.90648214 11.27218952], train_hist_grp_loss: [0.6456122  0.80053251 1.64308212], cur_train_grp_loss: [0.09466115 0.12320757 0.23731099], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6809, max_kl_dist_index: 2, max_train_grp_loss:  15.8922, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9065, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2373, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:28:24,404 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  6, train_loss:  13.4334, val_loss:  12.2618, grad_norm: 0.0005, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6508, 0.3478, 0.6809, param: [4.14918001 9.51087326 4.96422413 8.86865156], weights: [0.3185445  0.32444189 0.35701361], train_wt_loss:  40.3003, val_wt_loss: 36.7854, train_grp_loss: [11.74090373 15.89066498 11.15449164], val_grp_loss: [10.62397543 14.90449574 11.27278109], train_hist_grp_loss: [0.74028534 0.92372779 1.88040265], cur_train_grp_loss: [0.09467314 0.12319528 0.23732054], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6809, max_kl_dist_index: 2, max_train_grp_loss:  15.8907, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9045, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2373, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:28:25,454 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  7, train_loss:  13.4334, val_loss:  12.2617, grad_norm: 0.0006, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6508, 0.3477, 0.6808, param: [4.14922165 9.50832216 4.96568313 8.86991665], weights: [0.31662731 0.32340956 0.35996313], train_wt_loss:  40.3003, val_wt_loss: 36.7851, train_grp_loss: [11.74228613 15.88919923 11.15489574], val_grp_loss: [10.6249784  14.90259929 11.27335547], train_hist_grp_loss: [0.83497005 1.04691124 2.11773226], cur_train_grp_loss: [0.09468471 0.12318345 0.23732961], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6808, max_kl_dist_index: 2, max_train_grp_loss:  15.8892, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9026, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2373, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:28:26,465 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  8, train_loss:  13.4334, val_loss:  12.2616, grad_norm: 0.0008, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6508, 0.3477, 0.6808, param: [4.1492396  9.50582185 4.9671244  8.87123644], weights: [0.31470958 0.32236743 0.362923  ], train_wt_loss:  40.3003, val_wt_loss: 36.7848, train_grp_loss: [11.74361608 15.88779378 11.15527736], val_grp_loss: [10.62593507 14.90079305 11.27391256], train_hist_grp_loss: [0.92966591 1.17008333 2.35507047], cur_train_grp_loss: [0.09469586 0.12317209 0.23733821], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6808, max_kl_dist_index: 2, max_train_grp_loss:  15.8878, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9008, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2373, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:28:27,473 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  9, train_loss:  13.4334, val_loss:  12.2615, grad_norm: 0.0009, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6508, 0.3476, 0.6807, param: [4.14923382 9.50337241 4.96854781 8.87261113], weights: [0.31279141 0.32131558 0.36589301], train_wt_loss:  40.3003, val_wt_loss: 36.7846, train_grp_loss: [11.74489334 15.88644878 11.15563637], val_grp_loss: [10.62684525 14.89907729 11.27445224], train_hist_grp_loss: [1.02437249 1.29324452 2.59241679], cur_train_grp_loss: [0.09470658 0.12316119 0.23734633], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6807, max_kl_dist_index: 2, max_train_grp_loss:  15.8864, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8991, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2373, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:28:28,465 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  10, train_loss:  13.4335, val_loss:  12.2615, grad_norm: 0.0010, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6508, 0.3476, 0.6807, param: [4.14920424 9.50097394 4.96995327 8.87404096], weights: [0.31087291 0.32025411 0.36887297], train_wt_loss:  40.3004, val_wt_loss: 36.7844, train_grp_loss: [11.74611771 15.88516438 11.15597268], val_grp_loss: [10.62770877 14.89745226 11.27497444], train_hist_grp_loss: [1.11908937 1.41639529 2.82977076], cur_train_grp_loss: [0.09471688 0.12315077 0.23735397], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6807, max_kl_dist_index: 2, max_train_grp_loss:  15.8852, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8975, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:28:29,453 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  11, train_loss:  13.4335, val_loss:  12.2614, grad_norm: 0.0012, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6509, 0.3476, 0.6807, param: [4.14915082 9.49862649 4.97134065 8.87552613], weights: [0.3089542  0.31918314 0.37186267], train_wt_loss:  40.3004, val_wt_loss: 36.7841, train_grp_loss: [11.74728897 15.88394074 11.15628617], val_grp_loss: [10.62852546 14.8959182  11.27547904], train_hist_grp_loss: [1.21381612 1.53953609 3.06713188], cur_train_grp_loss: [0.09472676 0.12314081 0.23736112], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6807, max_kl_dist_index: 2, max_train_grp_loss:  15.8839, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8959, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:28:30,430 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  12, train_loss:  13.4335, val_loss:  12.2613, grad_norm: 0.0013, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6509, 0.3475, 0.6807, param: [4.14907352 9.49633015 4.97270985 8.87706683], weights: [0.30703536 0.31810275 0.37486189], train_wt_loss:  40.3004, val_wt_loss: 36.7840, train_grp_loss: [11.74840691 15.88277799 11.15657675], val_grp_loss: [10.62929514 14.89447537 11.27596597], train_hist_grp_loss: [1.30855233 1.66266742 3.30449967], cur_train_grp_loss: [0.0947362  0.12313132 0.23736779], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6807, max_kl_dist_index: 2, max_train_grp_loss:  15.8828, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8945, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:28:31,437 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  13, train_loss:  13.4335, val_loss:  12.2613, grad_norm: 0.0014, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6509, 0.3475, 0.6806, param: [4.14897227 9.49408497 4.97406074 8.87866327], weights: [0.30511652 0.31701305 0.37787043], train_wt_loss:  40.3004, val_wt_loss: 36.7838, train_grp_loss: [11.74947134 15.88167627 11.15684432], val_grp_loss: [10.63001767 14.893124   11.27643514], train_hist_grp_loss: [1.40329754 1.78578973 3.54187365], cur_train_grp_loss: [0.09474522 0.12312231 0.23737397], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6806, max_kl_dist_index: 2, max_train_grp_loss:  15.8817, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8931, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:28:32,445 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  14, train_loss:  13.4335, val_loss:  12.2612, grad_norm: 0.0016, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6509, 0.3475, 0.6806, param: [4.14884703 9.49189102 4.97539321 8.88031562], weights: [0.30319778 0.31591416 0.38088806], train_wt_loss:  40.3004, val_wt_loss: 36.7837, train_grp_loss: [11.75048207 15.88063573 11.15708879], val_grp_loss: [10.63069289 14.89186432 11.27688647], train_hist_grp_loss: [1.49805134 1.9089035  3.77925331], cur_train_grp_loss: [0.0947538  0.12311377 0.23737967], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6806, max_kl_dist_index: 2, max_train_grp_loss:  15.8806, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8919, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:28:33,430 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  15, train_loss:  13.4335, val_loss:  12.2612, grad_norm: 0.0017, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6510, 0.3475, 0.6806, param: [4.14869775 9.48974834 4.97670715 8.88202407], weights: [0.30127925 0.31480618 0.38391457], train_wt_loss:  40.3005, val_wt_loss: 36.7836, train_grp_loss: [11.75143889 15.8796565  11.15731006], val_grp_loss: [10.63132066 14.89069657 11.27731988], train_hist_grp_loss: [1.5928133  2.0320092  4.01663818], cur_train_grp_loss: [0.09476195 0.1231057  0.23738487], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6806, max_kl_dist_index: 2, max_train_grp_loss:  15.8797, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8907, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:28:34,414 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  16, train_loss:  13.4335, val_loss:  12.2612, grad_norm: 0.0018, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6510, 0.3474, 0.6807, param: [4.14852438 9.48765697 4.97800244 8.88378878], weights: [0.29936104 0.31368922 0.38694974], train_wt_loss:  40.3005, val_wt_loss: 36.7835, train_grp_loss: [11.75234165 15.87873871 11.15750807], val_grp_loss: [10.63190083 14.88962097 11.27773529], train_hist_grp_loss: [1.68758296 2.15510731 4.25402776], cur_train_grp_loss: [0.09476967 0.12309811 0.23738958], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6807, max_kl_dist_index: 2, max_train_grp_loss:  15.8787, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8896, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:28:35,400 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  17, train_loss:  13.4335, val_loss:  12.2612, grad_norm: 0.0020, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6510, 0.3474, 0.6807, param: [4.14832687 9.48561696 4.97927895 8.88560991], weights: [0.29744326 0.3125634  0.38999334], train_wt_loss:  40.3005, val_wt_loss: 36.7835, train_grp_loss: [11.75319016 15.87788249 11.15768272], val_grp_loss: [10.63243328 14.88863774 11.27813264], train_hist_grp_loss: [1.78235991 2.27819831 4.49142154], cur_train_grp_loss: [0.09477695 0.123091   0.23739379], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6807, max_kl_dist_index: 2, max_train_grp_loss:  15.8779, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8886, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:28:36,384 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  18, train_loss:  13.4335, val_loss:  12.2611, grad_norm: 0.0021, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6511, 0.3474, 0.6807, param: [4.14810518 9.48362833 4.98053657 8.88748762], weights: [0.29552603 0.31142883 0.39304514], train_wt_loss:  40.3006, val_wt_loss: 36.7834, train_grp_loss: [11.75398427 15.87708797 11.15783396], val_grp_loss: [10.63291788 14.88774707 11.27851185], train_hist_grp_loss: [1.8771437  2.40128267 4.72881905], cur_train_grp_loss: [0.09478379 0.12308436 0.2373975 ], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6807, max_kl_dist_index: 2, max_train_grp_loss:  15.8771, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8877, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:28:37,406 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  19, train_loss:  13.4335, val_loss:  12.2612, grad_norm: 0.0022, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6511, 0.3474, 0.6807, param: [4.14785927 9.48169111 4.98177518 8.88942204], weights: [0.29360946 0.31028562 0.39610492], train_wt_loss:  40.3006, val_wt_loss: 36.7835, train_grp_loss: [11.75472381 15.87635528 11.15796169], val_grp_loss: [10.63335452 14.8869492  11.27887288], train_hist_grp_loss: [1.9719339  2.52436087 4.96621977], cur_train_grp_loss: [0.0947902  0.1230782  0.23740072], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6807, max_kl_dist_index: 2, max_train_grp_loss:  15.8764, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8869, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:28:38,393 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  20, train_loss:  13.4335, val_loss:  12.2612, grad_norm: 0.0023, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6512, 0.3474, 0.6808, param: [4.14758908 9.47980531 4.98299464 8.89141332], weights: [0.29169367 0.3091339  0.39917243], train_wt_loss:  40.3006, val_wt_loss: 36.7835, train_grp_loss: [11.75540863 15.87568452 11.15806588], val_grp_loss: [10.63374308 14.8862443  11.27921566], train_hist_grp_loss: [2.06673006 2.64743339 5.20362321], cur_train_grp_loss: [0.09479616 0.12307252 0.23740344], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6808, max_kl_dist_index: 2, max_train_grp_loss:  15.8757, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8862, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:28:39,414 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  21, train_loss:  13.4336, val_loss:  12.2612, grad_norm: 0.0024, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6512, 0.3474, 0.6808, param: [4.14729458 9.47797096 4.98419485 8.89346158], weights: [0.28977876 0.30797378 0.40224746], train_wt_loss:  40.3007, val_wt_loss: 36.7835, train_grp_loss: [11.75603859 15.87507583 11.15814644], val_grp_loss: [10.63408346 14.88563257 11.27954013], train_hist_grp_loss: [2.16153174 2.77050072 5.44102887], cur_train_grp_loss: [0.09480168 0.12306732 0.23740566], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6808, max_kl_dist_index: 2, max_train_grp_loss:  15.8751, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8856, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:28:40,410 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  22, train_loss:  13.4336, val_loss:  12.2612, grad_norm: 0.0026, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6513, 0.3474, 0.6809, param: [4.14697571 9.47618804 4.98537568 8.89556693], weights: [0.28786487 0.30680539 0.40532975], train_wt_loss:  40.3007, val_wt_loss: 36.7836, train_grp_loss: [11.75661356 15.8745293  11.15820333], val_grp_loss: [10.63437557 14.88511421 11.27984625], train_hist_grp_loss: [2.25633851 2.89356332 5.67843624], cur_train_grp_loss: [0.09480676 0.1230626  0.23740737], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6809, max_kl_dist_index: 2, max_train_grp_loss:  15.8745, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8851, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:28:41,414 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  23, train_loss:  13.4336, val_loss:  12.2612, grad_norm: 0.0027, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6514, 0.3475, 0.6809, param: [4.14663245 9.47445656 4.98653699 8.89772949], weights: [0.28595209 0.30562885 0.40841906], train_wt_loss:  40.3007, val_wt_loss: 36.7837, train_grp_loss: [11.75713341 15.87404505 11.15823651], val_grp_loss: [10.6346193  14.88468938 11.28013397], train_hist_grp_loss: [2.35114991 3.01662169 5.91584482], cur_train_grp_loss: [0.0948114  0.12305837 0.23740858], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6809, max_kl_dist_index: 2, max_train_grp_loss:  15.8740, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8847, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:28:42,407 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  24, train_loss:  13.4336, val_loss:  12.2613, grad_norm: 0.0028, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6514, 0.3475, 0.6810, param: [4.14626474 9.47277652 4.98767867 8.89994935], weights: [0.28404055 0.30444428 0.41151517], train_wt_loss:  40.3008, val_wt_loss: 36.7839, train_grp_loss: [11.75759802 15.87362318 11.15824591], val_grp_loss: [10.6348146  14.88435827 11.28040326], train_hist_grp_loss: [2.4459655  3.1396763  6.15325411], cur_train_grp_loss: [0.09481559 0.12305461 0.23740929], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6810, max_kl_dist_index: 2, max_train_grp_loss:  15.8736, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8844, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:28:43,453 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  25, train_loss:  13.4336, val_loss:  12.2613, grad_norm: 0.0029, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6515, 0.3475, 0.6810, param: [4.14587255 9.47114788 4.98880059 8.90222659], weights: [0.28213037 0.30325182 0.41461781], train_wt_loss:  40.3008, val_wt_loss: 36.7840, train_grp_loss: [11.75800728 15.8732638  11.15823151], val_grp_loss: [10.63496137 14.88412103 11.28065407], train_hist_grp_loss: [2.54078484 3.26272764 6.3906636 ], cur_train_grp_loss: [0.09481934 0.12305134 0.23740949], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6810, max_kl_dist_index: 2, max_train_grp_loss:  15.8733, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8841, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:28:44,444 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  26, train_loss:  13.4336, val_loss:  12.2614, grad_norm: 0.0030, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6516, 0.3475, 0.6811, param: [4.14545583 9.46957063 4.98990263 8.90456131], weights: [0.28022167 0.30205159 0.41772674], train_wt_loss:  40.3008, val_wt_loss: 36.7842, train_grp_loss: [11.75836108 15.87296701 11.15819327], val_grp_loss: [10.63505956 14.88397784 11.28088638], train_hist_grp_loss: [2.63560748 3.3857762  6.62807278], cur_train_grp_loss: [0.09482264 0.12304856 0.23740918], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6811, max_kl_dist_index: 2, max_train_grp_loss:  15.8730, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8840, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:28:45,425 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  27, train_loss:  13.4336, val_loss:  12.2615, grad_norm: 0.0031, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6517, 0.3476, 0.6812, param: [4.14501455 9.46804474 4.99098464 8.90695356], weights: [0.27831456 0.30084372 0.42084172], train_wt_loss:  40.3009, val_wt_loss: 36.7844, train_grp_loss: [11.75865933 15.87273289 11.15813116], val_grp_loss: [10.6351091  14.88392883 11.28110015], train_hist_grp_loss: [2.73043297 3.50882245 6.86548114], cur_train_grp_loss: [0.09482549 0.12304626 0.23740837], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6812, max_kl_dist_index: 2, max_train_grp_loss:  15.8727, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8839, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:28:46,457 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  28, train_loss:  13.4336, val_loss:  12.2616, grad_norm: 0.0032, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6518, 0.3476, 0.6813, param: [4.14454868 9.46657017 4.99204652 8.9094034 ], weights: [0.27640917 0.29962834 0.42396249], train_wt_loss:  40.3009, val_wt_loss: 36.7847, train_grp_loss: [11.75890195 15.87256153 11.15804515], val_grp_loss: [10.63510995 14.88397415 11.28129537], train_hist_grp_loss: [2.82526087 3.63186689 7.10288819], cur_train_grp_loss: [0.0948279  0.12304444 0.23740705], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6813, max_kl_dist_index: 2, max_train_grp_loss:  15.8726, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8840, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:28:47,464 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  29, train_loss:  13.4337, val_loss:  12.2616, grad_norm: 0.0034, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6519, 0.3476, 0.6814, param: [4.14405817 9.46514687 4.99308812 8.9119109 ], weights: [0.27450561 0.29840559 0.4270888 ], train_wt_loss:  40.3010, val_wt_loss: 36.7849, train_grp_loss: [11.75908884 15.87245302 11.15793523], val_grp_loss: [10.63506206 14.88411394 11.28147202], train_hist_grp_loss: [2.92009072 3.75491001 7.34029341], cur_train_grp_loss: [0.09482985 0.12304311 0.23740522], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6814, max_kl_dist_index: 2, max_train_grp_loss:  15.8725, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8841, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:28:48,449 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  30, train_loss:  13.4337, val_loss:  12.2617, grad_norm: 0.0035, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6520, 0.3477, 0.6815, param: [4.14354299 9.46377478 4.99410931 8.91447608], weights: [0.272604   0.2971756  0.43022039], train_wt_loss:  40.3010, val_wt_loss: 36.7852, train_grp_loss: [11.75921996 15.87240745 11.15780138], val_grp_loss: [10.6349654  14.88434834 11.28163008], train_hist_grp_loss: [3.01492208 3.87795228 7.57769628], cur_train_grp_loss: [0.09483136 0.12304227 0.23740288], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6815, max_kl_dist_index: 2, max_train_grp_loss:  15.8724, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8843, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:28:49,429 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  31, train_loss:  13.4337, val_loss:  12.2619, grad_norm: 0.0036, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6521, 0.3477, 0.6816, param: [4.14300311 9.46245386 4.99510998 8.91709897], weights: [0.27070447 0.29593851 0.43335702], train_wt_loss:  40.3010, val_wt_loss: 36.7856, train_grp_loss: [11.75929522 15.87242488 11.1576436 ], val_grp_loss: [10.63481994 14.88467745 11.28176954], train_hist_grp_loss: [3.1097545  4.0009942  7.81509631], cur_train_grp_loss: [0.09483242 0.12304192 0.23740003], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6816, max_kl_dist_index: 2, max_train_grp_loss:  15.8724, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8847, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:28:50,417 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  32, train_loss:  13.4337, val_loss:  12.2620, grad_norm: 0.0037, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6522, 0.3478, 0.6817, param: [4.14243849 9.46118403 4.99608998 8.9197796 ], weights: [0.26880714 0.29469445 0.43649841], train_wt_loss:  40.3011, val_wt_loss: 36.7859, train_grp_loss: [11.75931458 15.8725054  11.15746187], val_grp_loss: [10.63462566 14.8851014  11.2818904 ], train_hist_grp_loss: [3.20458753 4.12403625 8.05249299], cur_train_grp_loss: [0.09483303 0.12304205 0.23739667], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6817, max_kl_dist_index: 2, max_train_grp_loss:  15.8725, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8851, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:28:51,397 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  33, train_loss:  13.4337, val_loss:  12.2621, grad_norm: 0.0038, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6523, 0.3478, 0.6818, param: [4.14184911 9.45996521 4.99704919 8.92251797], weights: [0.26691213 0.29344356 0.43964431], train_wt_loss:  40.3011, val_wt_loss: 36.7863, train_grp_loss: [11.75927799 15.87264906 11.1572562 ], val_grp_loss: [10.63438255 14.88562029 11.28199266], train_hist_grp_loss: [3.29942071 4.24707893 8.28988579], cur_train_grp_loss: [0.09483318 0.12304268 0.23739281], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6818, max_kl_dist_index: 2, max_train_grp_loss:  15.8726, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8856, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:28:52,397 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  34, train_loss:  13.4337, val_loss:  12.2622, grad_norm: 0.0039, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6524, 0.3479, 0.6820, param: [4.14123492 9.45879733 4.99798748 8.92531408], weights: [0.26501956 0.29218599 0.44279446], train_wt_loss:  40.3012, val_wt_loss: 36.7867, train_grp_loss: [11.75918542 15.87285593 11.1570266 ], val_grp_loss: [10.63409062 14.88623422 11.28207632], train_hist_grp_loss: [3.3942536  4.37012272 8.52727422], cur_train_grp_loss: [0.09483289 0.12304379 0.23738843], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6820, max_kl_dist_index: 2, max_train_grp_loss:  15.8729, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8862, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:28:53,383 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  35, train_loss:  13.4337, val_loss:  12.2624, grad_norm: 0.0040, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6525, 0.3479, 0.6821, param: [4.14059591 9.45768029 4.99890471 8.92816791], weights: [0.26312955 0.29092186 0.44594859], train_wt_loss:  40.3012, val_wt_loss: 36.7871, train_grp_loss: [11.75903685 15.87312607 11.15677308], val_grp_loss: [10.63374986 14.88694327 11.2821414 ], train_hist_grp_loss: [3.48908574 4.49316811 8.76465777], cur_train_grp_loss: [0.09483214 0.12304539 0.23738354], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6821, max_kl_dist_index: 2, max_train_grp_loss:  15.8731, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8869, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:28:54,363 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  36, train_loss:  13.4338, val_loss:  12.2625, grad_norm: 0.0041, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6526, 0.3480, 0.6822, param: [4.13993204 9.456614   4.99980075 8.93107945], weights: [0.26124222 0.28965133 0.44910645], train_wt_loss:  40.3013, val_wt_loss: 36.7876, train_grp_loss: [11.75883224 15.87345954 11.15649565], val_grp_loss: [10.63336029 14.88774753 11.28218791], train_hist_grp_loss: [3.58391668 4.6162156  9.00203592], cur_train_grp_loss: [0.09483094 0.12304749 0.23737815], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6822, max_kl_dist_index: 2, max_train_grp_loss:  15.8735, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8877, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:28:55,373 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  37, train_loss:  13.4338, val_loss:  12.2627, grad_norm: 0.0041, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6528, 0.3481, 0.6824, param: [4.13924329 9.45559834 5.00067547 8.93404867], weights: [0.2593577  0.28837455 0.45226776], train_wt_loss:  40.3013, val_wt_loss: 36.7881, train_grp_loss: [11.7585716  15.87385638 11.15619435], val_grp_loss: [10.63292193 14.88864708 11.28221586], train_hist_grp_loss: [3.67874597 4.73926568 9.23940816], cur_train_grp_loss: [0.09482929 0.12305007 0.23737225], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6824, max_kl_dist_index: 2, max_train_grp_loss:  15.8739, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8886, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:28:56,358 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  38, train_loss:  13.4338, val_loss:  12.2629, grad_norm: 0.0042, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6529, 0.3482, 0.6826, param: [4.13852963 9.45463322 5.00152874 8.9370755 ], weights: [0.2574761  0.28709164 0.45543226], train_wt_loss:  40.3014, val_wt_loss: 36.7886, train_grp_loss: [11.75825492 15.87431663 11.15586919], val_grp_loss: [10.63243482 14.88964197 11.28222529], train_hist_grp_loss: [3.77357316 4.86231883 9.476774  ], cur_train_grp_loss: [0.09482719 0.12305315 0.23736584], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6826, max_kl_dist_index: 2, max_train_grp_loss:  15.8743, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8896, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:28:57,376 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  39, train_loss:  13.4338, val_loss:  12.2630, grad_norm: 0.0043, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6530, 0.3482, 0.6827, param: [4.13779104 9.4537185  5.00236043 8.94015991], weights: [0.25559756 0.28580276 0.45859968], train_wt_loss:  40.3014, val_wt_loss: 36.7891, train_grp_loss: [11.75788221 15.87484035 11.15552022], val_grp_loss: [10.63189899 14.89073226 11.28221621], train_hist_grp_loss: [3.8683978  4.98537555 9.71413292], cur_train_grp_loss: [0.09482464 0.12305672 0.23735892], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6827, max_kl_dist_index: 2, max_train_grp_loss:  15.8748, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8907, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:28:58,358 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  40, train_loss:  13.4338, val_loss:  12.2632, grad_norm: 0.0044, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6532, 0.3483, 0.6829, param: [4.13702749 9.45285405 5.0031704  8.94330181], weights: [0.25372218 0.28450806 0.46176975], train_wt_loss:  40.3015, val_wt_loss: 36.7897, train_grp_loss: [11.75745349 15.87542755 11.15514746], val_grp_loss: [10.63131449 14.89191799 11.28218867], train_hist_grp_loss: [3.96321943 5.10843632 9.95148441], cur_train_grp_loss: [0.09482163 0.12306078 0.23735149], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6829, max_kl_dist_index: 2, max_train_grp_loss:  15.8754, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8919, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:28:59,350 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  41, train_loss:  13.4338, val_loss:  12.2634, grad_norm: 0.0045, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6533, 0.3484, 0.6831, param: [4.13623897 9.45203975 5.00395852 8.94650114], weights: [0.2518501  0.28320768 0.46494221], train_wt_loss:  40.3015, val_wt_loss: 36.7903, train_grp_loss: [11.75696878 15.87607827 11.15475098], val_grp_loss: [10.63068138 14.89319921 11.2821427 ], train_hist_grp_loss: [ 4.0580376   5.23150165 10.18882798], cur_train_grp_loss: [0.09481817 0.12306533 0.23734356], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6831, max_kl_dist_index: 2, max_train_grp_loss:  15.8761, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8932, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2373, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:29:00,340 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  42, train_loss:  13.4339, val_loss:  12.2636, grad_norm: 0.0046, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6535, 0.3485, 0.6832, param: [4.13542545 9.45127545 5.00472466 8.94975781], weights: [0.24998144 0.28190178 0.46811678], train_wt_loss:  40.3016, val_wt_loss: 36.7909, train_grp_loss: [11.75642813 15.87679253 11.15433081], val_grp_loss: [10.62999973 14.89457594 11.28207835], train_hist_grp_loss: [ 4.15285187  5.35457203 10.4261631 ], cur_train_grp_loss: [0.09481426 0.12307037 0.23733513], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6832, max_kl_dist_index: 2, max_train_grp_loss:  15.8768, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8946, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2373, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:29:01,372 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  43, train_loss:  13.4339, val_loss:  12.2639, grad_norm: 0.0047, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6536, 0.3486, 0.6834, param: [4.13458692 9.450561   5.00546869 8.95307171], weights: [0.24811632 0.28059049 0.4712932 ], train_wt_loss:  40.3016, val_wt_loss: 36.7916, train_grp_loss: [11.75583157 15.87757036 11.15388702], val_grp_loss: [10.6292696  14.89604821 11.28199565], train_hist_grp_loss: [ 4.24766177  5.47764794 10.66348929], cur_train_grp_loss: [0.0948099  0.12307591 0.23732619], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6834, max_kl_dist_index: 2, max_train_grp_loss:  15.8776, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8960, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2373, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:29:02,375 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  44, train_loss:  13.4339, val_loss:  12.2641, grad_norm: 0.0048, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6538, 0.3487, 0.6836, param: [4.13372335 9.44989624 5.00619048 8.95644273], weights: [0.24625485 0.27927397 0.47447118], train_wt_loss:  40.3017, val_wt_loss: 36.7922, train_grp_loss: [11.75517917 15.87841176 11.15341966], val_grp_loss: [10.62849109 14.89761601 11.28189467], train_hist_grp_loss: [ 4.34246686  5.60072988 10.90080604], cur_train_grp_loss: [0.09480509 0.12308194 0.23731675], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6836, max_kl_dist_index: 2, max_train_grp_loss:  15.8784, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8976, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2373, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:29:03,357 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  45, train_loss:  13.4339, val_loss:  12.2643, grad_norm: 0.0049, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6540, 0.3488, 0.6838, param: [4.13283473 9.449281   5.00688989 8.95987075], weights: [0.24439716 0.27795237 0.47765047], train_wt_loss:  40.3017, val_wt_loss: 36.7929, train_grp_loss: [11.75447098 15.87931675 11.1529288 ], val_grp_loss: [10.62766428 14.89927935 11.28177547], train_hist_grp_loss: [ 4.4372667   5.72381834 11.13811284], cur_train_grp_loss: [0.09479983 0.12308846 0.2373068 ], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6838, max_kl_dist_index: 2, max_train_grp_loss:  15.8793, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8993, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2373, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:29:04,360 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  46, train_loss:  13.4339, val_loss:  12.2646, grad_norm: 0.0050, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6541, 0.3489, 0.6840, param: [4.13192106 9.44871512 5.0075668  8.96335564], weights: [0.24254337 0.27662585 0.48083078], train_wt_loss:  40.3018, val_wt_loss: 36.7937, train_grp_loss: [11.75370708 15.88028533 11.15241452], val_grp_loss: [10.62678927 14.90103823 11.28163809], train_hist_grp_loss: [ 4.53206082  5.84691382 11.3754092 ], cur_train_grp_loss: [0.09479412 0.12309548 0.23729636], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6840, max_kl_dist_index: 2, max_train_grp_loss:  15.8803, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9010, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2373, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:29:05,354 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  47, train_loss:  13.4340, val_loss:  12.2648, grad_norm: 0.0050, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6543, 0.3490, 0.6842, param: [4.1309823  9.4481984  5.00822107 8.96689724], weights: [0.24069361 0.27529455 0.48401184], train_wt_loss:  40.3019, val_wt_loss: 36.7944, train_grp_loss: [11.75288756 15.88131749 11.15187689], val_grp_loss: [10.62586617 14.90289262 11.28148262], train_hist_grp_loss: [ 4.62684878  5.97001681 11.61269461], cur_train_grp_loss: [0.09478796 0.12310299 0.23728542], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6842, max_kl_dist_index: 2, max_train_grp_loss:  15.8813, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9029, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2373, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:29:06,343 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  48, train_loss:  13.4340, val_loss:  12.2651, grad_norm: 0.0051, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6545, 0.3491, 0.6845, param: [4.13001847 9.44773066 5.00885257 8.9704954 ], weights: [0.23884799 0.27395862 0.48719339], train_wt_loss:  40.3019, val_wt_loss: 36.7952, train_grp_loss: [11.7520125  15.88241323 11.15131599], val_grp_loss: [10.6248951  14.90484249 11.28130912], train_hist_grp_loss: [ 4.72163013  6.0931278  11.84996859], cur_train_grp_loss: [0.09478135 0.12311099 0.23727398], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6845, max_kl_dist_index: 2, max_train_grp_loss:  15.8824, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9048, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2373, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:29:07,351 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  49, train_loss:  13.4340, val_loss:  12.2654, grad_norm: 0.0052, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6547, 0.3492, 0.6847, param: [4.12902953 9.4473117  5.00946118 8.97414995], weights: [0.23700662 0.27261823 0.49037515], train_wt_loss:  40.3020, val_wt_loss: 36.7961, train_grp_loss: [11.751082   15.88357253 11.15073192], val_grp_loss: [10.62387619 14.90688781 11.28111768], train_hist_grp_loss: [ 4.81640442  6.21624728 12.08723063], cur_train_grp_loss: [0.09477429 0.12311948 0.23726204], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6847, max_kl_dist_index: 2, max_train_grp_loss:  15.8836, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9069, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2373, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:29:08,356 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  50, train_loss:  13.4340, val_loss:  12.2656, grad_norm: 0.0053, live_grad: 0.0000, reward_err: 0.0035, 0.0310, 0.0013, KL_dist: 0.6548, 0.3494, 0.6849, param: [4.1280155  9.44694133 5.01004676 8.97786072], weights: [0.23516964 0.27127351 0.49355684], train_wt_loss:  40.3021, val_wt_loss: 36.7969, train_grp_loss: [11.75009618 15.88479538 11.15012476], val_grp_loss: [10.62280956 14.90902853 11.28090836], train_hist_grp_loss: [ 4.91117121  6.33937575 12.32448025], cur_train_grp_loss: [0.09476679 0.12312847 0.23724962], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6849, max_kl_dist_index: 2, max_train_grp_loss:  15.8848, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9090, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2372, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:29:09,348 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  51, train_loss:  13.4340, val_loss:  12.2659, grad_norm: 0.0054, live_grad: 0.0000, reward_err: 0.0035, 0.0314, 0.0013, KL_dist: 0.6550, 0.3495, 0.6852, param: [4.12697635 9.44661932 5.01060919 8.9816275 ], weights: [0.23333716 0.26992464 0.4967382 ], train_wt_loss:  40.3021, val_wt_loss: 36.7978, train_grp_loss: [11.74905517 15.88608174 11.14949462], val_grp_loss: [10.62169537 14.91126458 11.28068126], train_hist_grp_loss: [ 5.00593005  6.4625137  12.56171694], cur_train_grp_loss: [0.09475884 0.12313795 0.2372367 ], max_reward_err:  0.0314, max_reward_err_index: 1, max_kl_dist:  0.6852, max_kl_dist_index: 2, max_train_grp_loss:  15.8861, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9113, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2372, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:29:10,334 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  52, train_loss:  13.4341, val_loss:  12.2662, grad_norm: 0.0055, live_grad: 0.0000, reward_err: 0.0035, 0.0314, 0.0013, KL_dist: 0.6552, 0.3496, 0.6854, param: [4.12591209 9.44634546 5.01114834 8.98545009], weights: [0.23150929 0.26857176 0.49991895], train_wt_loss:  40.3022, val_wt_loss: 36.7987, train_grp_loss: [11.74795907 15.88743159 11.14884161], val_grp_loss: [10.62053377 14.91359591 11.28043647], train_hist_grp_loss: [ 5.1006805   6.58566162 12.79894023], cur_train_grp_loss: [0.09475044 0.12314792 0.23722329], max_reward_err:  0.0314, max_reward_err_index: 1, max_kl_dist:  0.6854, max_kl_dist_index: 2, max_train_grp_loss:  15.8874, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9136, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2372, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:29:11,327 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  53, train_loss:  13.4341, val_loss:  12.2666, grad_norm: 0.0056, live_grad: 0.0000, reward_err: 0.0035, 0.0314, 0.0013, KL_dist: 0.6554, 0.3497, 0.6857, param: [4.12482272 9.44611953 5.01166408 8.98932828], weights: [0.22968616 0.26721502 0.50309882], train_wt_loss:  40.3023, val_wt_loss: 36.7997, train_grp_loss: [11.74680805 15.8888449  11.14816583], val_grp_loss: [10.61932491 14.91602243 11.28017408], train_hist_grp_loss: [ 5.1954221   6.70882    13.03614963], cur_train_grp_loss: [0.09474161 0.12315838 0.2372094 ], max_reward_err:  0.0314, max_reward_err_index: 1, max_kl_dist:  0.6857, max_kl_dist_index: 2, max_train_grp_loss:  15.8888, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9160, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2372, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:29:12,324 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  54, train_loss:  13.4341, val_loss:  12.2669, grad_norm: 0.0057, live_grad: 0.0000, reward_err: 0.0035, 0.0314, 0.0013, KL_dist: 0.6556, 0.3499, 0.6859, param: [4.12370823 9.44594129 5.01215628 8.99326184], weights: [0.22786788 0.26585458 0.50627754], train_wt_loss:  40.3024, val_wt_loss: 36.8006, train_grp_loss: [11.74560224 15.89032162 11.14746739], val_grp_loss: [10.61806897 14.91854406 11.2798942 ], train_hist_grp_loss: [ 5.29015443  6.83198934 13.27334465], cur_train_grp_loss: [0.09473232 0.12316934 0.23719502], max_reward_err:  0.0314, max_reward_err_index: 1, max_kl_dist:  0.6859, max_kl_dist_index: 2, max_train_grp_loss:  15.8903, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9185, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2372, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:29:13,316 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  55, train_loss:  13.4342, val_loss:  12.2672, grad_norm: 0.0058, live_grad: 0.0000, reward_err: 0.0035, 0.0314, 0.0013, KL_dist: 0.6558, 0.3500, 0.6862, param: [4.12256861 9.44581049 5.01262483 8.99725053], weights: [0.22605457 0.2644906  0.50945483], train_wt_loss:  40.3025, val_wt_loss: 36.8016, train_grp_loss: [11.74434181 15.89186169 11.14674643], val_grp_loss: [10.61676612 14.92116069 11.27959692], train_hist_grp_loss: [ 5.38487703  6.95517013 13.5105248 ], cur_train_grp_loss: [0.0947226  0.12318079 0.23718016], max_reward_err:  0.0314, max_reward_err_index: 1, max_kl_dist:  0.6862, max_kl_dist_index: 2, max_train_grp_loss:  15.8919, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9212, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2372, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:29:14,302 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  56, train_loss:  13.4342, val_loss:  12.2676, grad_norm: 0.0059, live_grad: 0.0000, reward_err: 0.0035, 0.0314, 0.0013, KL_dist: 0.6560, 0.3502, 0.6864, param: [4.12140389 9.4457269  5.01306959 9.00129409], weights: [0.22424634 0.26312324 0.51263043], train_wt_loss:  40.3025, val_wt_loss: 36.8027, train_grp_loss: [11.74302692 15.89346508 11.14600306], val_grp_loss: [10.61541656 14.92387222 11.27928236], train_hist_grp_loss: [ 5.47958946  7.07836286 13.74768962], cur_train_grp_loss: [0.09471243 0.12319273 0.23716482], max_reward_err:  0.0314, max_reward_err_index: 1, max_kl_dist:  0.6864, max_kl_dist_index: 2, max_train_grp_loss:  15.8935, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9239, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2372, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:29:15,277 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  57, train_loss:  13.4342, val_loss:  12.2679, grad_norm: 0.0060, live_grad: 0.0000, reward_err: 0.0035, 0.0314, 0.0013, KL_dist: 0.6563, 0.3503, 0.6867, param: [4.12021405 9.44569025 5.01349045 9.00539228], weights: [0.2224433  0.26175263 0.51580407], train_wt_loss:  40.3026, val_wt_loss: 36.8037, train_grp_loss: [11.74165775 15.89513172 11.14523742], val_grp_loss: [10.61402047 14.92667853 11.27895064], train_hist_grp_loss: [ 5.57429129  7.20156801 13.98483862], cur_train_grp_loss: [0.09470183 0.12320516 0.237149  ], max_reward_err:  0.0314, max_reward_err_index: 1, max_kl_dist:  0.6867, max_kl_dist_index: 2, max_train_grp_loss:  15.8951, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9267, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2371, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:29:16,274 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  58, train_loss:  13.4342, val_loss:  12.2683, grad_norm: 0.0061, live_grad: 0.0000, reward_err: 0.0035, 0.0314, 0.0013, KL_dist: 0.6565, 0.3505, 0.6870, param: [4.11899911 9.44570029 5.01388728 9.0095448 ], weights: [0.22064558 0.26037896 0.51897547], train_wt_loss:  40.3027, val_wt_loss: 36.8048, train_grp_loss: [11.74023448 15.89686153 11.14444964], val_grp_loss: [10.61257806 14.92957948 11.27860186], train_hist_grp_loss: [ 5.66898208  7.32478609 14.22197133], cur_train_grp_loss: [0.09469079 0.12321808 0.23713271], max_reward_err:  0.0314, max_reward_err_index: 1, max_kl_dist:  0.6870, max_kl_dist_index: 2, max_train_grp_loss:  15.8969, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9296, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2371, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:29:17,310 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  59, train_loss:  13.4343, val_loss:  12.2686, grad_norm: 0.0063, live_grad: 0.0000, reward_err: 0.0035, 0.0314, 0.0013, KL_dist: 0.6567, 0.3506, 0.6873, param: [4.11775907 9.44575674 5.01425997 9.01375138], weights: [0.21885328 0.25900235 0.52214437], train_wt_loss:  40.3028, val_wt_loss: 36.8059, train_grp_loss: [11.73875732 15.89865446 11.14363988], val_grp_loss: [10.61108954 14.93257494 11.27823616], train_hist_grp_loss: [ 5.76366139  7.44801757 14.45908728], cur_train_grp_loss: [0.09467931 0.12323148 0.23711595], max_reward_err:  0.0314, max_reward_err_index: 1, max_kl_dist:  0.6873, max_kl_dist_index: 2, max_train_grp_loss:  15.8987, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9326, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2371, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:29:18,296 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  60, train_loss:  13.4343, val_loss:  12.2690, grad_norm: 0.0064, live_grad: 0.0000, reward_err: 0.0034, 0.0314, 0.0014, KL_dist: 0.6569, 0.3508, 0.6876, param: [4.11649395 9.44585933 5.01460838 9.01801172], weights: [0.21706651 0.25762299 0.5253105 ], train_wt_loss:  40.3029, val_wt_loss: 36.8071, train_grp_loss: [11.73722646 15.90051042 11.14280826], val_grp_loss: [10.60955514 14.93566475 11.27785366], train_hist_grp_loss: [ 5.85832879  7.57126295 14.696186  ], cur_train_grp_loss: [0.0946674  0.12324538 0.23709872], max_reward_err:  0.0314, max_reward_err_index: 1, max_kl_dist:  0.6876, max_kl_dist_index: 2, max_train_grp_loss:  15.9005, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9357, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2371, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:29:19,273 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  61, train_loss:  13.4343, val_loss:  12.2694, grad_norm: 0.0065, live_grad: 0.0000, reward_err: 0.0034, 0.0314, 0.0014, KL_dist: 0.6571, 0.3510, 0.6879, param: [4.11520375 9.44600778 5.01493242 9.02232551], weights: [0.21528539 0.25624101 0.5284736 ], train_wt_loss:  40.3030, val_wt_loss: 36.8083, train_grp_loss: [11.73564213 15.90242933 11.14195495], val_grp_loss: [10.60797509 14.93884876 11.27745449], train_hist_grp_loss: [ 5.95298384  7.69452273 14.93326703], cur_train_grp_loss: [0.09465505 0.12325977 0.23708103], max_reward_err:  0.0314, max_reward_err_index: 1, max_kl_dist:  0.6879, max_kl_dist_index: 2, max_train_grp_loss:  15.9024, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9388, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2371, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:29:20,263 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  62, train_loss:  13.4344, val_loss:  12.2698, grad_norm: 0.0066, live_grad: 0.0000, reward_err: 0.0034, 0.0314, 0.0014, KL_dist: 0.6574, 0.3511, 0.6882, param: [4.11388849 9.44620179 5.01523195 9.02669242], weights: [0.21351002 0.25485657 0.53163341], train_wt_loss:  40.3032, val_wt_loss: 36.8095, train_grp_loss: [11.73400454 15.9044111  11.1410801 ], val_grp_loss: [10.60634961 14.94212678 11.27703879], train_hist_grp_loss: [ 6.04762611  7.81779737 15.1703299 ], cur_train_grp_loss: [0.09464228 0.12327465 0.23706287], max_reward_err:  0.0314, max_reward_err_index: 1, max_kl_dist:  0.6882, max_kl_dist_index: 2, max_train_grp_loss:  15.9044, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9421, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2371, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:29:21,252 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  63, train_loss:  13.4344, val_loss:  12.2703, grad_norm: 0.0068, live_grad: 0.0000, reward_err: 0.0034, 0.0314, 0.0014, KL_dist: 0.6576, 0.3513, 0.6885, param: [4.11254818 9.44644108 5.01550686 9.03111213], weights: [0.21174052 0.25346983 0.53478964], train_wt_loss:  40.3033, val_wt_loss: 36.8108, train_grp_loss: [11.73231393 15.90645563 11.14018388], val_grp_loss: [10.60467896 14.94549865 11.2766067 ], train_hist_grp_loss: [ 6.14225518  7.94108738 15.40737416], cur_train_grp_loss: [0.09462907 0.12329001 0.23704426], max_reward_err:  0.0314, max_reward_err_index: 1, max_kl_dist:  0.6885, max_kl_dist_index: 2, max_train_grp_loss:  15.9065, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9455, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2370, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:29:22,224 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  64, train_loss:  13.4345, val_loss:  12.2707, grad_norm: 0.0069, live_grad: 0.0000, reward_err: 0.0034, 0.0314, 0.0014, KL_dist: 0.6579, 0.3515, 0.6888, param: [4.11118284 9.44672533 5.01575705 9.03558428], weights: [0.209977   0.25208094 0.53794206], train_wt_loss:  40.3034, val_wt_loss: 36.8120, train_grp_loss: [11.73057054 15.90856282 11.13926645], val_grp_loss: [10.6029634  14.94896415 11.27615837], train_hist_grp_loss: [ 6.23687062  8.06439324 15.64439935], cur_train_grp_loss: [0.09461543 0.12330586 0.23702519], max_reward_err:  0.0314, max_reward_err_index: 1, max_kl_dist:  0.6888, max_kl_dist_index: 2, max_train_grp_loss:  15.9086, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9490, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2370, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:29:23,223 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  65, train_loss:  13.4345, val_loss:  12.2711, grad_norm: 0.0071, live_grad: 0.0000, reward_err: 0.0034, 0.0314, 0.0014, KL_dist: 0.6581, 0.3517, 0.6891, param: [4.10979249 9.44705424 5.0159824  9.04010854], weights: [0.20821955 0.25069007 0.54109039], train_wt_loss:  40.3035, val_wt_loss: 36.8134, train_grp_loss: [11.72877462 15.91073256 11.13832799], val_grp_loss: [10.60120318 14.9525231  11.27569393], train_hist_grp_loss: [ 6.33147199  8.18771543 15.88140502], cur_train_grp_loss: [0.09460138 0.12332219 0.23700567], max_reward_err:  0.0314, max_reward_err_index: 1, max_kl_dist:  0.6891, max_kl_dist_index: 2, max_train_grp_loss:  15.9107, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9525, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2370, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:29:24,223 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  66, train_loss:  13.4346, val_loss:  12.2716, grad_norm: 0.0072, live_grad: 0.0000, reward_err: 0.0034, 0.0314, 0.0014, KL_dist: 0.6583, 0.3518, 0.6895, param: [4.10837716 9.44742749 5.0161828  9.04468451], weights: [0.20646828 0.24929735 0.54423437], train_wt_loss:  40.3037, val_wt_loss: 36.8147, train_grp_loss: [11.72692643 15.91296474 11.13736867], val_grp_loss: [10.59939857 14.95617526 11.27521356], train_hist_grp_loss: [ 6.42605888  8.31105444 16.11839072], cur_train_grp_loss: [0.09458689 0.12333901 0.2369857 ], max_reward_err:  0.0314, max_reward_err_index: 1, max_kl_dist:  0.6895, max_kl_dist_index: 2, max_train_grp_loss:  15.9130, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9562, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2370, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:29:25,210 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  67, train_loss:  13.4346, val_loss:  12.2720, grad_norm: 0.0074, live_grad: 0.0000, reward_err: 0.0034, 0.0314, 0.0014, KL_dist: 0.6586, 0.3520, 0.6898, param: [4.10693686 9.44784476 5.01635814 9.04931184], weights: [0.2047233  0.24790294 0.54737375], train_wt_loss:  40.3038, val_wt_loss: 36.8161, train_grp_loss: [11.72502624 15.91525923 11.13638866], val_grp_loss: [10.59754986 14.95992043 11.2747174 ], train_hist_grp_loss: [ 6.52063087  8.43441076 16.35535601], cur_train_grp_loss: [0.09457199 0.12335632 0.23696529], max_reward_err:  0.0314, max_reward_err_index: 1, max_kl_dist:  0.6898, max_kl_dist_index: 2, max_train_grp_loss:  15.9153, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9599, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2370, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:29:26,200 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  68, train_loss:  13.4347, val_loss:  12.2725, grad_norm: 0.0076, live_grad: 0.0000, reward_err: 0.0034, 0.0314, 0.0014, KL_dist: 0.6588, 0.3522, 0.6901, param: [4.10547162 9.44830572 5.01650831 9.05399013], weights: [0.20298472 0.24650701 0.55050827], train_wt_loss:  40.3040, val_wt_loss: 36.8175, train_grp_loss: [11.72307433 15.91761591 11.13538817], val_grp_loss: [10.59565733 14.96375835 11.27420562], train_hist_grp_loss: [ 6.61518753  8.55778486 16.59230045], cur_train_grp_loss: [0.09455666 0.1233741  0.23694444], max_reward_err:  0.0314, max_reward_err_index: 1, max_kl_dist:  0.6901, max_kl_dist_index: 2, max_train_grp_loss:  15.9176, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9638, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2369, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:29:27,219 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  69, train_loss:  13.4347, val_loss:  12.2730, grad_norm: 0.0077, live_grad: 0.0000, reward_err: 0.0034, 0.0314, 0.0014, KL_dist: 0.6591, 0.3524, 0.6905, param: [4.10398147 9.44881004 5.01663322 9.05871897], weights: [0.20125262 0.24510969 0.55363768], train_wt_loss:  40.3041, val_wt_loss: 36.8190, train_grp_loss: [11.72107099 15.92003464 11.13436738], val_grp_loss: [10.59372127 14.96768878 11.27367837], train_hist_grp_loss: [ 6.70972846  8.68117723 16.8292236 ], cur_train_grp_loss: [0.09454092 0.12339237 0.23692315], max_reward_err:  0.0314, max_reward_err_index: 1, max_kl_dist:  0.6905, max_kl_dist_index: 2, max_train_grp_loss:  15.9200, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9677, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2369, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:29:28,221 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  70, train_loss:  13.4348, val_loss:  12.2735, grad_norm: 0.0079, live_grad: 0.0000, reward_err: 0.0034, 0.0314, 0.0014, KL_dist: 0.6594, 0.3526, 0.6908, param: [4.10246644 9.44935738 5.01673276 9.06349796], weights: [0.19952712 0.24371115 0.55676173], train_wt_loss:  40.3043, val_wt_loss: 36.8204, train_grp_loss: [11.71901651 15.92251529 11.13332648], val_grp_loss: [10.59174199 14.97171146 11.27313584], train_hist_grp_loss: [ 6.80425322  8.80458835 17.06612504], cur_train_grp_loss: [0.09452477 0.12341112 0.23690143], max_reward_err:  0.0314, max_reward_err_index: 1, max_kl_dist:  0.6908, max_kl_dist_index: 2, max_train_grp_loss:  15.9225, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9717, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2369, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:29:29,203 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  71, train_loss:  13.4348, val_loss:  12.2740, grad_norm: 0.0081, live_grad: 0.0000, reward_err: 0.0034, 0.0314, 0.0014, KL_dist: 0.6596, 0.3528, 0.6912, param: [4.10092656 9.44994738 5.01680683 9.06832667], weights: [0.19780832 0.24231153 0.55988016], train_wt_loss:  40.3045, val_wt_loss: 36.8219, train_grp_loss: [11.71691119 15.9250577  11.13226568], val_grp_loss: [10.5897198  14.97582612 11.27257819], train_hist_grp_loss: [ 6.89876142  8.9280187  17.30300432], cur_train_grp_loss: [0.0945082  0.12343035 0.23687929], max_reward_err:  0.0314, max_reward_err_index: 1, max_kl_dist:  0.6912, max_kl_dist_index: 2, max_train_grp_loss:  15.9251, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9758, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2369, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:29:30,190 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  72, train_loss:  13.4349, val_loss:  12.2745, grad_norm: 0.0083, live_grad: 0.0000, reward_err: 0.0034, 0.0314, 0.0014, KL_dist: 0.6599, 0.3530, 0.6916, param: [4.09936187 9.45057971 5.01685533 9.07320467], weights: [0.1960963  0.24091098 0.56299272], train_wt_loss:  40.3046, val_wt_loss: 36.8235, train_grp_loss: [11.71475535 15.92766173 11.13118517], val_grp_loss: [10.58765501 14.98003248 11.2720056 ], train_hist_grp_loss: [ 6.99325264  9.05146876 17.53986104], cur_train_grp_loss: [0.09449122 0.12345006 0.23685672], max_reward_err:  0.0314, max_reward_err_index: 1, max_kl_dist:  0.6916, max_kl_dist_index: 2, max_train_grp_loss:  15.9277, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9800, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2369, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:29:31,189 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  73, train_loss:  13.4349, val_loss:  12.2750, grad_norm: 0.0086, live_grad: 0.0000, reward_err: 0.0034, 0.0314, 0.0014, KL_dist: 0.6602, 0.3532, 0.6919, param: [4.0977724  9.451254   5.01687818 9.07813151], weights: [0.19439117 0.23950965 0.56609918], train_wt_loss:  40.3048, val_wt_loss: 36.8251, train_grp_loss: [11.71254932 15.93032722 11.13008517], val_grp_loss: [10.58554795 14.98433024 11.27141825], train_hist_grp_loss: [ 7.08772647  9.17493901 17.77669477], cur_train_grp_loss: [0.09447383 0.12347025 0.23683373], max_reward_err:  0.0314, max_reward_err_index: 1, max_kl_dist:  0.6919, max_kl_dist_index: 2, max_train_grp_loss:  15.9303, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9843, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2368, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:29:32,183 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  74, train_loss:  13.4350, val_loss:  12.2756, grad_norm: 0.0088, live_grad: 0.0000, reward_err: 0.0034, 0.0314, 0.0014, KL_dist: 0.6605, 0.3534, 0.6923, param: [4.09615818 9.45196988 5.01687526 9.08310673], weights: [0.19269302 0.2381077  0.56919928], train_wt_loss:  40.3050, val_wt_loss: 36.8267, train_grp_loss: [11.71029341 15.933054   11.1289659 ], val_grp_loss: [10.58339895 14.98871911 11.27081633], train_hist_grp_loss: [ 7.18218252  9.29842992 18.01350509], cur_train_grp_loss: [0.09445604 0.12349091 0.23681032], max_reward_err:  0.0314, max_reward_err_index: 1, max_kl_dist:  0.6923, max_kl_dist_index: 2, max_train_grp_loss:  15.9331, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9887, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2368, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:29:33,163 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  75, train_loss:  13.4351, val_loss:  12.2761, grad_norm: 0.0090, live_grad: 0.0000, reward_err: 0.0034, 0.0314, 0.0014, KL_dist: 0.6607, 0.3537, 0.6927, param: [4.09451927 9.452727   5.0168465  9.08812988], weights: [0.19100194 0.23670527 0.57229279], train_wt_loss:  40.3052, val_wt_loss: 36.8283, train_grp_loss: [11.70798797 15.93584189 11.12782755], val_grp_loss: [10.58120835 14.99319878 11.27020002], train_hist_grp_loss: [ 7.27662037  9.42194197 18.2502916 ], cur_train_grp_loss: [0.09443785 0.12351205 0.23678651], max_reward_err:  0.0314, max_reward_err_index: 1, max_kl_dist:  0.6927, max_kl_dist_index: 2, max_train_grp_loss:  15.9358, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9932, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2368, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:29:34,142 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  76, train_loss:  13.4351, val_loss:  12.2767, grad_norm: 0.0093, live_grad: 0.0000, reward_err: 0.0034, 0.0314, 0.0014, KL_dist: 0.6610, 0.3539, 0.6931, param: [4.0928557  9.45352497 5.01679181 9.09320047], weights: [0.18931804 0.2353025  0.57537946], train_wt_loss:  40.3054, val_wt_loss: 36.8300, train_grp_loss: [11.70563334 15.93869073 11.12667037], val_grp_loss: [10.57897651 14.9977689  11.26956951], train_hist_grp_loss: [ 7.37103962  9.54547562 18.48705389], cur_train_grp_loss: [0.09441926 0.12353366 0.23676229], max_reward_err:  0.0314, max_reward_err_index: 1, max_kl_dist:  0.6931, max_kl_dist_index: 2, max_train_grp_loss:  15.9387, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9978, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2368, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:29:35,136 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  77, train_loss:  13.4352, val_loss:  12.2772, grad_norm: 0.0095, live_grad: 0.0000, reward_err: 0.0034, 0.0319, 0.0014, KL_dist: 0.6613, 0.3541, 0.6934, param: [4.09116752 9.45436342 5.0167111  9.09831801], weights: [0.18764138 0.23389955 0.57845906], train_wt_loss:  40.3057, val_wt_loss: 36.8317, train_grp_loss: [11.70322989 15.94160033 11.12549457], val_grp_loss: [10.57670376 15.00242916 11.268925  ], train_hist_grp_loss: [ 7.46543989  9.66903137 18.72379155], cur_train_grp_loss: [0.09440027 0.12355574 0.23673767], max_reward_err:  0.0319, max_reward_err_index: 1, max_kl_dist:  0.6934, max_kl_dist_index: 2, max_train_grp_loss:  15.9416, max_train_grp_loss_index: 1, max_val_grp_loss:  15.0024, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2367, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:29:36,124 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  78, train_loss:  13.4353, val_loss:  12.2778, grad_norm: 0.0098, live_grad: 0.0000, reward_err: 0.0034, 0.0323, 0.0014, KL_dist: 0.6616, 0.3543, 0.6938, param: [4.08945478 9.45524197 5.01660429 9.103482  ], weights: [0.18597208 0.23249656 0.58153136], train_wt_loss:  40.3059, val_wt_loss: 36.8335, train_grp_loss: [11.70077796 15.94457049 11.12430037], val_grp_loss: [10.57439048 15.0071792  11.26826668], train_hist_grp_loss: [ 7.55982078  9.79260966 18.9605042 ], cur_train_grp_loss: [0.09438089 0.1235783  0.23671265], max_reward_err:  0.0323, max_reward_err_index: 1, max_kl_dist:  0.6938, max_kl_dist_index: 2, max_train_grp_loss:  15.9446, max_train_grp_loss_index: 1, max_val_grp_loss:  15.0072, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2367, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:29:37,114 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  79, train_loss:  13.4354, val_loss:  12.2784, grad_norm: 0.0101, live_grad: 0.0000, reward_err: 0.0034, 0.0326, 0.0014, KL_dist: 0.6619, 0.3546, 0.6942, param: [4.08771752 9.45616022 5.01647129 9.10869195], weights: [0.18431021 0.23109368 0.58459611], train_wt_loss:  40.3061, val_wt_loss: 36.8353, train_grp_loss: [11.69827794 15.94760102 11.12308802], val_grp_loss: [10.57203703 15.01201866 11.26759477], train_hist_grp_loss: [ 7.65418189  9.91621098 19.19719145], cur_train_grp_loss: [0.09436111 0.12360132 0.23668724], max_reward_err:  0.0326, max_reward_err_index: 1, max_kl_dist:  0.6942, max_kl_dist_index: 2, max_train_grp_loss:  15.9476, max_train_grp_loss_index: 1, max_val_grp_loss:  15.0120, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2367, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:29:38,100 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  80, train_loss:  13.4355, val_loss:  12.2790, grad_norm: 0.0104, live_grad: 0.0000, reward_err: 0.0034, 0.0326, 0.0014, KL_dist: 0.6622, 0.3548, 0.6946, param: [4.0859558  9.45711779 5.01631204 9.11394732], weights: [0.18265586 0.22969104 0.5876531 ], train_wt_loss:  40.3064, val_wt_loss: 36.8371, train_grp_loss: [11.69573019 15.95069172 11.12185775], val_grp_loss: [10.56964379 15.01694718 11.26690945], train_hist_grp_loss: [ 7.74852284 10.0398358  19.43385289], cur_train_grp_loss: [0.09434095 0.12362481 0.23666145], max_reward_err:  0.0326, max_reward_err_index: 1, max_kl_dist:  0.6946, max_kl_dist_index: 2, max_train_grp_loss:  15.9507, max_train_grp_loss_index: 1, max_val_grp_loss:  15.0169, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2367, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:29:39,084 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  81, train_loss:  13.4355, val_loss:  12.2797, grad_norm: 0.0107, live_grad: 0.0000, reward_err: 0.0034, 0.0326, 0.0014, KL_dist: 0.6625, 0.3550, 0.6951, param: [4.08416968 9.45811428 5.01612645 9.11924759], weights: [0.18100911 0.22828879 0.5907021 ], train_wt_loss:  40.3066, val_wt_loss: 36.8390, train_grp_loss: [11.69313511 15.95384238 11.1206098 ], val_grp_loss: [10.56721113 15.02196438 11.26621094], train_hist_grp_loss: [ 7.84284325 10.16348457 19.67048816], cur_train_grp_loss: [0.0943204  0.12364877 0.23663527], max_reward_err:  0.0326, max_reward_err_index: 1, max_kl_dist:  0.6951, max_kl_dist_index: 2, max_train_grp_loss:  15.9538, max_train_grp_loss_index: 1, max_val_grp_loss:  15.0220, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2366, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:29:40,065 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  82, train_loss:  13.4356, val_loss:  12.2803, grad_norm: 0.0110, live_grad: 0.0000, reward_err: 0.0034, 0.0326, 0.0014, KL_dist: 0.6628, 0.3553, 0.6955, param: [4.08235921 9.45914929 5.01591446 9.12459222], weights: [0.17937004 0.22688708 0.59374288], train_wt_loss:  40.3069, val_wt_loss: 36.8409, train_grp_loss: [11.69049309 15.95705278 11.11934441], val_grp_loss: [10.56473945 15.02706987 11.26549945], train_hist_grp_loss: [ 7.93714272 10.28715777 19.90709688], cur_train_grp_loss: [0.09429948 0.1236732  0.23660872], max_reward_err:  0.0326, max_reward_err_index: 1, max_kl_dist:  0.6955, max_kl_dist_index: 2, max_train_grp_loss:  15.9571, max_train_grp_loss_index: 1, max_val_grp_loss:  15.0271, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2366, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:29:41,056 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  83, train_loss:  13.4357, val_loss:  12.2809, grad_norm: 0.0113, live_grad: 0.0000, reward_err: 0.0034, 0.0326, 0.0014, KL_dist: 0.6631, 0.3555, 0.6959, param: [4.08052444 9.46022241 5.015676   9.12998067], weights: [0.17773874 0.22548604 0.59677522], train_wt_loss:  40.3072, val_wt_loss: 36.8428, train_grp_loss: [11.68780453 15.9603227  11.11806183], val_grp_loss: [10.56222913 15.03226325 11.26477519], train_hist_grp_loss: [ 8.03142089 10.41085585 20.14367868], cur_train_grp_loss: [0.09427817 0.12369808 0.2365818 ], max_reward_err:  0.0326, max_reward_err_index: 1, max_kl_dist:  0.6959, max_kl_dist_index: 2, max_train_grp_loss:  15.9603, max_train_grp_loss_index: 1, max_val_grp_loss:  15.0323, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2366, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:29:42,036 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  84, train_loss:  13.4358, val_loss:  12.2816, grad_norm: 0.0117, live_grad: 0.0000, reward_err: 0.0034, 0.0326, 0.0014, KL_dist: 0.6634, 0.3558, 0.6963, param: [4.07866545 9.46133323 5.01541099 9.13541237], weights: [0.17611529 0.22408581 0.5997989 ], train_wt_loss:  40.3075, val_wt_loss: 36.8448, train_grp_loss: [11.68506984 15.96365191 11.1167623 ], val_grp_loss: [10.55968059 15.0375441  11.26403838], train_hist_grp_loss: [ 8.12567738 10.53457928 20.38023319], cur_train_grp_loss: [0.09425649 0.12372343 0.23655451], max_reward_err:  0.0326, max_reward_err_index: 1, max_kl_dist:  0.6963, max_kl_dist_index: 2, max_train_grp_loss:  15.9637, max_train_grp_loss_index: 1, max_val_grp_loss:  15.0375, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2366, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:29:43,024 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  85, train_loss:  13.4359, val_loss:  12.2823, grad_norm: 0.0120, live_grad: 0.0000, reward_err: 0.0034, 0.0329, 0.0014, KL_dist: 0.6637, 0.3560, 0.6967, param: [4.0767823  9.46248134 5.01511939 9.14088676], weights: [0.17449976 0.22268652 0.60281371], train_wt_loss:  40.3078, val_wt_loss: 36.8468, train_grp_loss: [11.68228942 15.96704019 11.11544609], val_grp_loss: [10.55709422 15.04291201 11.26328923], train_hist_grp_loss: [ 8.21991182 10.65832852 20.61676004], cur_train_grp_loss: [0.09423443 0.12374924 0.23652686], max_reward_err:  0.0329, max_reward_err_index: 1, max_kl_dist:  0.6967, max_kl_dist_index: 2, max_train_grp_loss:  15.9670, max_train_grp_loss_index: 1, max_val_grp_loss:  15.0429, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2365, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:29:44,003 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  86, train_loss:  13.4360, val_loss:  12.2829, grad_norm: 0.0124, live_grad: 0.0000, reward_err: 0.0034, 0.0329, 0.0014, KL_dist: 0.6640, 0.3563, 0.6972, param: [4.07487504 9.46366632 5.01480113 9.14640326], weights: [0.17289223 0.22128833 0.60581944], train_wt_loss:  40.3081, val_wt_loss: 36.8488, train_grp_loss: [11.67946371 15.97048728 11.11411344], val_grp_loss: [10.55447043 15.04836654 11.26252797], train_hist_grp_loss: [ 8.31412383 10.78210403 20.8532589 ], cur_train_grp_loss: [0.09421201 0.12377551 0.23649885], max_reward_err:  0.0329, max_reward_err_index: 1, max_kl_dist:  0.6972, max_kl_dist_index: 2, max_train_grp_loss:  15.9705, max_train_grp_loss_index: 1, max_val_grp_loss:  15.0484, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2365, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:29:44,990 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  87, train_loss:  13.4361, val_loss:  12.2836, grad_norm: 0.0127, live_grad: 0.0000, reward_err: 0.0034, 0.0329, 0.0014, KL_dist: 0.6643, 0.3565, 0.6976, param: [4.07294376 9.46488775 5.01445615 9.15196128], weights: [0.17129278 0.21989135 0.60881587], train_wt_loss:  40.3084, val_wt_loss: 36.8509, train_grp_loss: [11.67659314 15.97399294 11.11276462], val_grp_loss: [10.55180965 15.05390726 11.26175482], train_hist_grp_loss: [ 8.40831305 10.90590626 21.0897294 ], cur_train_grp_loss: [0.09418922 0.12380223 0.2364705 ], max_reward_err:  0.0329, max_reward_err_index: 1, max_kl_dist:  0.6976, max_kl_dist_index: 2, max_train_grp_loss:  15.9740, max_train_grp_loss_index: 1, max_val_grp_loss:  15.0539, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2365, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:29:45,964 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  88, train_loss:  13.4363, val_loss:  12.2843, grad_norm: 0.0131, live_grad: 0.0000, reward_err: 0.0034, 0.0329, 0.0014, KL_dist: 0.6646, 0.3568, 0.6981, param: [4.07098853 9.46614522 5.0140844  9.15756024], weights: [0.16970147 0.21849573 0.61180281], train_wt_loss:  40.3088, val_wt_loss: 36.8530, train_grp_loss: [11.67367813 15.97755692 11.11139989], val_grp_loss: [10.5491123  15.0595337  11.26097001], train_hist_grp_loss: [ 8.50247913 11.02973566 21.3261712 ], cur_train_grp_loss: [0.09416607 0.1238294  0.2364418 ], max_reward_err:  0.0329, max_reward_err_index: 1, max_kl_dist:  0.6981, max_kl_dist_index: 2, max_train_grp_loss:  15.9776, max_train_grp_loss_index: 1, max_val_grp_loss:  15.0595, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2364, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:29:47,011 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  89, train_loss:  13.4364, val_loss:  12.2851, grad_norm: 0.0135, live_grad: 0.0000, reward_err: 0.0034, 0.0329, 0.0014, KL_dist: 0.6650, 0.3571, 0.6985, param: [4.06900941 9.46743829 5.01368583 9.16319952], weights: [0.16811837 0.21710159 0.61478004], train_wt_loss:  40.3091, val_wt_loss: 36.8552, train_grp_loss: [11.67071913 15.98117896 11.11001951], val_grp_loss: [10.5463788  15.06524541 11.26017375], train_hist_grp_loss: [ 8.59662169 11.15359269 21.56258396], cur_train_grp_loss: [0.09414257 0.12385703 0.23641276], max_reward_err:  0.0329, max_reward_err_index: 1, max_kl_dist:  0.6985, max_kl_dist_index: 2, max_train_grp_loss:  15.9812, max_train_grp_loss_index: 1, max_val_grp_loss:  15.0652, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2364, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:29:47,997 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  90, train_loss:  13.4365, val_loss:  12.2858, grad_norm: 0.0139, live_grad: 0.0000, reward_err: 0.0034, 0.0329, 0.0014, KL_dist: 0.6653, 0.3573, 0.6990, param: [4.06700649 9.46876653 5.01326041 9.16887852], weights: [0.16654356 0.21570908 0.61774737], train_wt_loss:  40.3095, val_wt_loss: 36.8573, train_grp_loss: [11.66771659 15.98485879 11.10862375], val_grp_loss: [10.5436096 15.0710419 11.2593663], train_hist_grp_loss: [ 8.69074039 11.2774778  21.79896735], cur_train_grp_loss: [0.0941187  0.12388511 0.23638339], max_reward_err:  0.0329, max_reward_err_index: 1, max_kl_dist:  0.6990, max_kl_dist_index: 2, max_train_grp_loss:  15.9849, max_train_grp_loss_index: 1, max_val_grp_loss:  15.0710, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2364, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:29:48,983 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  91, train_loss:  13.4366, val_loss:  12.2865, grad_norm: 0.0144, live_grad: 0.0000, reward_err: 0.0034, 0.0329, 0.0014, KL_dist: 0.6656, 0.3576, 0.6994, param: [4.06497984 9.47012951 5.01280807 9.17459662], weights: [0.1649771  0.21431831 0.6207046 ], train_wt_loss:  40.3099, val_wt_loss: 36.8596, train_grp_loss: [11.66467096 15.98859615 11.10721288], val_grp_loss: [10.54080512 15.07692271 11.25854786], train_hist_grp_loss: [ 8.78483488 11.40139143 22.03532105], cur_train_grp_loss: [0.09409449 0.12391363 0.2363537 ], max_reward_err:  0.0329, max_reward_err_index: 1, max_kl_dist:  0.6994, max_kl_dist_index: 2, max_train_grp_loss:  15.9886, max_train_grp_loss_index: 1, max_val_grp_loss:  15.0769, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2364, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:29:49,959 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  92, train_loss:  13.4368, val_loss:  12.2873, grad_norm: 0.0148, live_grad: 0.0000, reward_err: 0.0034, 0.0338, 0.0014, KL_dist: 0.6659, 0.3579, 0.6999, param: [4.06292955 9.4715268  5.0123288  9.18035319], weights: [0.16341905 0.21292941 0.62365154], train_wt_loss:  40.3103, val_wt_loss: 36.8618, train_grp_loss: [11.66158271 15.99239076 11.10578717], val_grp_loss: [10.53796582 15.08288732 11.25771869], train_hist_grp_loss: [ 8.87890481 11.52533404 22.27164473], cur_train_grp_loss: [0.09406993 0.12394261 0.23632368], max_reward_err:  0.0338, max_reward_err_index: 1, max_kl_dist:  0.6999, max_kl_dist_index: 2, max_train_grp_loss:  15.9924, max_train_grp_loss_index: 1, max_val_grp_loss:  15.0829, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2363, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:29:50,945 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  93, train_loss:  13.4369, val_loss:  12.2880, grad_norm: 0.0152, live_grad: 0.0000, reward_err: 0.0034, 0.0342, 0.0014, KL_dist: 0.6663, 0.3581, 0.7003, param: [4.0608557  9.47295796 5.01182254 9.18614758], weights: [0.16186949 0.21154252 0.62658799], train_wt_loss:  40.3107, val_wt_loss: 36.8641, train_grp_loss: [11.6584523  15.99624233 11.1043469 ], val_grp_loss: [10.53509214 15.08893525 11.25687902], train_hist_grp_loss: [ 8.97294983 11.64930606 22.50793807], cur_train_grp_loss: [0.09404502 0.12397202 0.23629334], max_reward_err:  0.0342, max_reward_err_index: 1, max_kl_dist:  0.7003, max_kl_dist_index: 2, max_train_grp_loss:  15.9962, max_train_grp_loss_index: 1, max_val_grp_loss:  15.0889, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2363, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:29:51,935 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  94, train_loss:  13.4370, val_loss:  12.2888, grad_norm: 0.0157, live_grad: 0.0000, reward_err: 0.0034, 0.0342, 0.0014, KL_dist: 0.6666, 0.3584, 0.7008, param: [4.05875838 9.47442255 5.01128928 9.19197917], weights: [0.16032847 0.21015775 0.62951378], train_wt_loss:  40.3111, val_wt_loss: 36.8665, train_grp_loss: [11.65528021 16.00015058 11.10289234], val_grp_loss: [10.53218454 15.09506597 11.25602908], train_hist_grp_loss: [ 9.06696961 11.77330794 22.74420077], cur_train_grp_loss: [0.09401978 0.12400188 0.2362627 ], max_reward_err:  0.0342, max_reward_err_index: 1, max_kl_dist:  0.7008, max_kl_dist_index: 2, max_train_grp_loss:  16.0002, max_train_grp_loss_index: 1, max_val_grp_loss:  15.0951, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2363, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:29:52,927 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  95, train_loss:  13.4372, val_loss:  12.2896, grad_norm: 0.0162, live_grad: 0.0000, reward_err: 0.0032, 0.0342, 0.0015, KL_dist: 0.6669, 0.3587, 0.7013, param: [4.05663767 9.47592013 5.01072898 9.19784728], weights: [0.15879604 0.20877524 0.63242872], train_wt_loss:  40.3115, val_wt_loss: 36.8689, train_grp_loss: [11.65206691 16.00411521 11.10142378], val_grp_loss: [10.52924348 15.10127896 11.25516911], train_hist_grp_loss: [ 9.1609638  11.89734011 22.98043252], cur_train_grp_loss: [0.0939942  0.12403218 0.23623175], max_reward_err:  0.0342, max_reward_err_index: 1, max_kl_dist:  0.7013, max_kl_dist_index: 2, max_train_grp_loss:  16.0041, max_train_grp_loss_index: 1, max_val_grp_loss:  15.1013, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2362, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:29:53,941 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  96, train_loss:  13.4373, val_loss:  12.2904, grad_norm: 0.0166, live_grad: 0.0000, reward_err: 0.0031, 0.0342, 0.0016, KL_dist: 0.6673, 0.3590, 0.7018, param: [4.05449367 9.47745025 5.01014161 9.20375128], weights: [0.15727228 0.2073951  0.63533262], train_wt_loss:  40.3120, val_wt_loss: 36.8713, train_grp_loss: [11.64881288 16.00813591 11.09994149], val_grp_loss: [10.52626941 15.10757368 11.25429936], train_hist_grp_loss: [ 9.25493208 12.02140302 23.21663303], cur_train_grp_loss: [0.09396828 0.12406291 0.23620051], max_reward_err:  0.0342, max_reward_err_index: 1, max_kl_dist:  0.7018, max_kl_dist_index: 2, max_train_grp_loss:  16.0081, max_train_grp_loss_index: 1, max_val_grp_loss:  15.1076, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2362, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:29:54,927 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  97, train_loss:  13.4375, val_loss:  12.2912, grad_norm: 0.0171, live_grad: 0.0000, reward_err: 0.0031, 0.0342, 0.0016, KL_dist: 0.6676, 0.3593, 0.7022, param: [4.05232648 9.47901248 5.00952717 9.20969048], weights: [0.15575723 0.20601745 0.63822531], train_wt_loss:  40.3125, val_wt_loss: 36.8737, train_grp_loss: [11.64551862 16.0122124  11.09844576], val_grp_loss: [10.52326281 15.1139496  11.25342007], train_hist_grp_loss: [ 9.34887412 12.1454971  23.452802  ], cur_train_grp_loss: [0.09394204 0.12409408 0.23616897], max_reward_err:  0.0342, max_reward_err_index: 1, max_kl_dist:  0.7022, max_kl_dist_index: 2, max_train_grp_loss:  16.0122, max_train_grp_loss_index: 1, max_val_grp_loss:  15.1139, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2362, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:29:55,935 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  98, train_loss:  13.4377, val_loss:  12.2921, grad_norm: 0.0176, live_grad: 0.0000, reward_err: 0.0031, 0.0342, 0.0016, KL_dist: 0.6680, 0.3596, 0.7027, param: [4.05013619 9.48060636 5.00888563 9.21566422], weights: [0.15425095 0.20464242 0.64110663], train_wt_loss:  40.3130, val_wt_loss: 36.8762, train_grp_loss: [11.64218462 16.01634434 11.09693687], val_grp_loss: [10.52022415 15.12040617 11.25253148], train_hist_grp_loss: [ 9.4427896  12.26962277 23.68893914], cur_train_grp_loss: [0.09391547 0.12412568 0.23613714], max_reward_err:  0.0342, max_reward_err_index: 1, max_kl_dist:  0.7027, max_kl_dist_index: 2, max_train_grp_loss:  16.0163, max_train_grp_loss_index: 1, max_val_grp_loss:  15.1204, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2361, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:29:56,937 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  99, train_loss:  13.4378, val_loss:  12.2929, grad_norm: 0.0182, live_grad: 0.0000, reward_err: 0.0031, 0.0342, 0.0016, KL_dist: 0.6683, 0.3599, 0.7032, param: [4.0479229  9.48223144 5.00821698 9.22167182], weights: [0.15275349 0.20327011 0.64397639], train_wt_loss:  40.3135, val_wt_loss: 36.8788, train_grp_loss: [11.63881137 16.02053143 11.09541511], val_grp_loss: [10.5171539  15.12694281 11.25163384], train_hist_grp_loss: [ 9.53667818 12.39378048 23.92504418], cur_train_grp_loss: [0.09388859 0.12415771 0.23610504], max_reward_err:  0.0342, max_reward_err_index: 1, max_kl_dist:  0.7032, max_kl_dist_index: 2, max_train_grp_loss:  16.0205, max_train_grp_loss_index: 1, max_val_grp_loss:  15.1269, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2361, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:29:57,849 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1654] - INFO: Iteration:  99, train_loss:  13.4378, val_loss:  12.2929, grad_norm: 0.0182,  live_grad: 0.0000, reward_err: 0.0031, 0.0342, 0.0016, KL_dist: 0.6683, 0.3599, 0.7032, param: [4.0479229  9.48223144 5.00821698 9.22167182], weights: [0.15275349 0.20327011 0.64397639], train_wt_loss:  40.3135, val_wt_loss: 36.8788, train_grp_loss: [11.63881137 16.02053143 11.09541511], val_grp_loss: [10.5171539  15.12694281 11.25163384], train_hist_grp_loss: [ 9.53667818 12.39378048 23.92504418], cur_train_grp_loss: [0.09388859 0.12415771 0.23610504], max_reward_err:  0.0342, max_reward_err_index: 1, max_kl_dist:  0.7032, max_kl_dist_index: 2, max_train_grp_loss:  16.0205, max_train_grp_loss_index: 1, max_val_grp_loss:  15.1269, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2361, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:29:58,069 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:388] - INFO: Policy parameter learned solely on the preference data rdpo: [4.0479229  9.48223144 5.00821698 9.22167182].
2024-10-07 17:29:58,408 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Uniform reward: 3.8269, 3.8269, 3.1987
2024-10-07 17:29:58,409 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Optimal reward: 3.8681, 7.1581, 3.3364
2024-10-07 17:29:58,410 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Policy reward: 3.8562, 6.9133, 3.3312
2024-10-07 17:29:58,410 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:402] - INFO: Reward Error: 0.0031, 0.0342, 0.0016
2024-10-07 17:29:59,099 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:417] - INFO: Optimal reward: 3.8681, 7.1581, 3.3364
Known param reward: [[3.8680634765625, 6.699916015625, 3.30809521484375], [3.46072314453125, 7.1581357421875, 3.12821826171875], [3.83464501953125, 7.0068994140625, 3.336449462890625]], Known param reward error: [[0.0, 0.06401383587376193, 0.00849832984501714], [0.10530859550248342, 0.0, 0.06241101610796404], [0.008639583407495802, 0.02112789329121925, 0.0]].
