2024-10-07 17:22:49,533 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log-hyperparam-search/2024_10_07_17_04_32/rdpo,0.2,0.1,0.01,2022
2024-10-07 17:22:49,535 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2022
2024-10-07 17:22:49,535 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-10-07 17:22:49,623 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.3214, l2 distance: 25.6155, acc: 0.89.
2024-10-07 17:22:49,623 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-10-07 17:22:49,624 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [ 4.91492317 13.51244723  6.71533233  9.49961375]
2024-10-07 17:22:49,835 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.8530, 6.9304, 3.3326
2024-10-07 17:22:50,059 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1314] - INFO: unique_group_ids: {0, 1, 2}
2024-10-07 17:22:51,247 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  0, train_loss:  13.4334, val_loss:  12.2618, grad_norm: 0.5704, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6505, 0.3478, 0.6807, param: [4.15112139 9.52389454 4.95553387 8.8558309 ], weights: [0.33300418 0.3330439  0.33395192], train_wt_loss:  40.3003, val_wt_loss: 36.7855, train_grp_loss: [11.73586405 15.89578613 11.15365364], val_grp_loss: [10.62097178 14.91008014 11.27026442], train_hist_grp_loss: [0.17243466 0.18436246 0.45663202], cur_train_grp_loss: [0.17243466 0.18436246 0.45663202], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6807, max_kl_dist_index: 2, max_train_grp_loss:  15.8958, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9101, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.4566, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:22:52,284 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  1, train_loss:  13.4334, val_loss:  12.2618, grad_norm: 0.0000, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6505, 0.3478, 0.6807, param: [4.15114364 9.52360181 4.95569255 8.85591503], weights: [0.33281382 0.33294866 0.33423752], train_wt_loss:  40.3003, val_wt_loss: 36.7854, train_grp_loss: [11.73604179 15.89559431 11.15371113], val_grp_loss: [10.62110705 14.90982261 11.27033487], train_hist_grp_loss: [0.26707873 0.30758561 0.6939438 ], cur_train_grp_loss: [0.09464406 0.12322315 0.23731178], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6807, max_kl_dist_index: 2, max_train_grp_loss:  15.8956, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9098, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2373, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:22:53,362 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  2, train_loss:  13.4334, val_loss:  12.2618, grad_norm: 0.0000, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6505, 0.3478, 0.6806, param: [4.15116566 9.52330958 4.95585107 8.85599968], weights: [0.33262344 0.33285331 0.33452325], train_wt_loss:  40.3003, val_wt_loss: 36.7854, train_grp_loss: [11.73621903 15.89540308 11.1537684 ], val_grp_loss: [10.62124187 14.90956595 11.27040515], train_hist_grp_loss: [0.36172422 0.43080727 0.93125681], cur_train_grp_loss: [0.0946455  0.12322166 0.237313  ], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6806, max_kl_dist_index: 2, max_train_grp_loss:  15.8954, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9096, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2373, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:22:54,421 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  3, train_loss:  13.4334, val_loss:  12.2618, grad_norm: 0.0000, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6505, 0.3478, 0.6806, param: [4.15118745 9.52301784 4.95600942 8.85608485], weights: [0.33243305 0.33275785 0.33480909], train_wt_loss:  40.3003, val_wt_loss: 36.7853, train_grp_loss: [11.73639576 15.89521243 11.15382545], val_grp_loss: [10.62137624 14.90931016 11.27047527], train_hist_grp_loss: [0.45637115 0.55402745 1.16857103], cur_train_grp_loss: [0.09464693 0.12322018 0.23731422], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6806, max_kl_dist_index: 2, max_train_grp_loss:  15.8952, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9093, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2373, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:22:55,526 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  4, train_loss:  13.4334, val_loss:  12.2618, grad_norm: 0.0000, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6505, 0.3478, 0.6806, param: [4.15120901 9.5227266  4.95616761 8.85617056], weights: [0.33224265 0.33266229 0.33509506], train_wt_loss:  40.3003, val_wt_loss: 36.7853, train_grp_loss: [11.736572   15.89502237 11.15388229], val_grp_loss: [10.62151017 14.90905525 11.27054523], train_hist_grp_loss: [0.55101951 0.67724615 1.40588646], cur_train_grp_loss: [0.09464835 0.1232187  0.23731544], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6806, max_kl_dist_index: 2, max_train_grp_loss:  15.8950, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9091, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2373, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:22:56,609 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  5, train_loss:  13.4334, val_loss:  12.2617, grad_norm: 0.0000, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6505, 0.3478, 0.6806, param: [4.15123033 9.52243586 4.95632562 8.85625678], weights: [0.33205223 0.33256663 0.33538114], train_wt_loss:  40.3003, val_wt_loss: 36.7852, train_grp_loss: [11.73674772 15.8948329  11.15393891], val_grp_loss: [10.62164365 14.90880122 11.27061502], train_hist_grp_loss: [0.64566928 0.80046338 1.64320311], cur_train_grp_loss: [0.09464977 0.12321723 0.23731664], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6806, max_kl_dist_index: 2, max_train_grp_loss:  15.8948, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9088, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2373, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:22:57,673 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  6, train_loss:  13.4334, val_loss:  12.2617, grad_norm: 0.0001, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6505, 0.3477, 0.6806, param: [4.15125143 9.52214562 4.95648347 8.85634354], weights: [0.3318618  0.33247086 0.33566734], train_wt_loss:  40.3003, val_wt_loss: 36.7852, train_grp_loss: [11.73692295 15.89464401 11.15399532], val_grp_loss: [10.62177668 14.90854806 11.27068464], train_hist_grp_loss: [0.74032047 0.92367914 1.88052096], cur_train_grp_loss: [0.09465119 0.12321576 0.23731785], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6806, max_kl_dist_index: 2, max_train_grp_loss:  15.8946, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9085, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2373, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:22:58,664 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  7, train_loss:  13.4334, val_loss:  12.2617, grad_norm: 0.0001, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6505, 0.3477, 0.6806, param: [4.15127229 9.52185587 4.95664115 8.85643082], weights: [0.33167135 0.33237498 0.33595367], train_wt_loss:  40.3003, val_wt_loss: 36.7851, train_grp_loss: [11.73709767 15.89445571 11.15405152], val_grp_loss: [10.62190927 14.90829578 11.27075411], train_hist_grp_loss: [0.83497308 1.04689343 2.11784001], cur_train_grp_loss: [0.0946526  0.12321429 0.23731905], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6806, max_kl_dist_index: 2, max_train_grp_loss:  15.8945, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9083, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2373, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:22:59,673 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  8, train_loss:  13.4334, val_loss:  12.2617, grad_norm: 0.0001, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6505, 0.3477, 0.6806, param: [4.15129292 9.52156663 4.95679866 8.85651863], weights: [0.3314809  0.332279   0.33624011], train_wt_loss:  40.3003, val_wt_loss: 36.7851, train_grp_loss: [11.73727188 15.894268   11.1541075 ], val_grp_loss: [10.62204141 14.90804438 11.2708234 ], train_hist_grp_loss: [0.92962709 1.17010627 2.35516025], cur_train_grp_loss: [0.09465401 0.12321283 0.23732025], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6806, max_kl_dist_index: 2, max_train_grp_loss:  15.8943, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9080, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2373, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:23:00,662 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  9, train_loss:  13.4334, val_loss:  12.2617, grad_norm: 0.0001, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6505, 0.3477, 0.6806, param: [4.15131332 9.52127788 4.95695601 8.85660697], weights: [0.33129042 0.33218291 0.33652667], train_wt_loss:  40.3003, val_wt_loss: 36.7850, train_grp_loss: [11.73744559 15.89408088 11.15416326], val_grp_loss: [10.6221731  14.90779385 11.27089254], train_hist_grp_loss: [1.02428251 1.29331765 2.59248169], cur_train_grp_loss: [0.09465542 0.12321138 0.23732144], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6806, max_kl_dist_index: 2, max_train_grp_loss:  15.8941, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9078, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2373, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:23:01,652 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  10, train_loss:  13.4334, val_loss:  12.2617, grad_norm: 0.0001, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6505, 0.3477, 0.6806, param: [4.15133349 9.52098963 4.95711318 8.85669583], weights: [0.33109994 0.33208672 0.33681334], train_wt_loss:  40.3003, val_wt_loss: 36.7850, train_grp_loss: [11.73761879 15.89389435 11.15421881], val_grp_loss: [10.62230435 14.90754421 11.2709615 ], train_hist_grp_loss: [1.11893933 1.41652758 2.82980431], cur_train_grp_loss: [0.09465682 0.12320993 0.23732262], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6806, max_kl_dist_index: 2, max_train_grp_loss:  15.8939, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9075, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2373, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:23:02,633 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  11, train_loss:  13.4334, val_loss:  12.2616, grad_norm: 0.0001, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6505, 0.3477, 0.6806, param: [4.15135343 9.52070188 4.95727019 8.85678522], weights: [0.33090944 0.33199042 0.33710014], train_wt_loss:  40.3003, val_wt_loss: 36.7849, train_grp_loss: [11.73779149 15.8937084  11.15427414], val_grp_loss: [10.62243515 14.90729544 11.27103031], train_hist_grp_loss: [1.21359754 1.53973606 3.06712811], cur_train_grp_loss: [0.09465822 0.12320848 0.2373238 ], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6806, max_kl_dist_index: 2, max_train_grp_loss:  15.8937, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9073, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2373, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:23:03,617 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  12, train_loss:  13.4334, val_loss:  12.2616, grad_norm: 0.0001, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6505, 0.3477, 0.6805, param: [4.15137314 9.52041463 4.95742703 8.85687514], weights: [0.33071892 0.33189402 0.33738706], train_wt_loss:  40.3003, val_wt_loss: 36.7849, train_grp_loss: [11.73796368 15.89352305 11.15432926], val_grp_loss: [10.6225655  14.90704755 11.27109895], train_hist_grp_loss: [1.30825715 1.6629431  3.3044531 ], cur_train_grp_loss: [0.09465961 0.12320704 0.23732498], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6805, max_kl_dist_index: 2, max_train_grp_loss:  15.8935, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9070, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2373, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:23:04,612 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  13, train_loss:  13.4334, val_loss:  12.2616, grad_norm: 0.0002, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6505, 0.3477, 0.6805, param: [4.15139261 9.52012788 4.9575837  8.85696559], weights: [0.3305284  0.33179751 0.33767409], train_wt_loss:  40.3003, val_wt_loss: 36.7848, train_grp_loss: [11.73813537 15.89333828 11.15438416], val_grp_loss: [10.62269541 14.90680053 11.27116742], train_hist_grp_loss: [1.40291815 1.78614871 3.54177925], cur_train_grp_loss: [0.094661   0.12320561 0.23732615], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6805, max_kl_dist_index: 2, max_train_grp_loss:  15.8933, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9068, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2373, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:23:05,604 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  14, train_loss:  13.4334, val_loss:  12.2616, grad_norm: 0.0002, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6505, 0.3477, 0.6805, param: [4.15141185 9.51984162 4.9577402  8.85705657], weights: [0.33033786 0.3317009  0.33796124], train_wt_loss:  40.3003, val_wt_loss: 36.7848, train_grp_loss: [11.73830655 15.8931541  11.15443884], val_grp_loss: [10.62282486 14.9065544  11.27123573], train_hist_grp_loss: [1.49758053 1.90935288 3.77910657], cur_train_grp_loss: [0.09466238 0.12320417 0.23732732], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6805, max_kl_dist_index: 2, max_train_grp_loss:  15.8932, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9066, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2373, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:23:06,591 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  15, train_loss:  13.4334, val_loss:  12.2616, grad_norm: 0.0002, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6505, 0.3477, 0.6805, param: [4.15143086 9.51955587 4.95789654 8.85714808], weights: [0.33014731 0.33160419 0.33824851], train_wt_loss:  40.3003, val_wt_loss: 36.7847, train_grp_loss: [11.73847722 15.89297051 11.15449331], val_grp_loss: [10.62295387 14.90630915 11.27130387], train_hist_grp_loss: [1.59224429 2.03255562 4.01643506], cur_train_grp_loss: [0.09466376 0.12320274 0.23732849], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6805, max_kl_dist_index: 2, max_train_grp_loss:  15.8930, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9063, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2373, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:23:07,579 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  16, train_loss:  13.4334, val_loss:  12.2616, grad_norm: 0.0002, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6505, 0.3477, 0.6805, param: [4.15144964 9.51927062 4.9580527  8.85724011], weights: [0.32995674 0.33150737 0.33853589], train_wt_loss:  40.3003, val_wt_loss: 36.7847, train_grp_loss: [11.73864739 15.8927875  11.15454756], val_grp_loss: [10.62308243 14.90606477 11.27137184], train_hist_grp_loss: [1.68690943 2.15575695 4.2537647 ], cur_train_grp_loss: [0.09466514 0.12320132 0.23732964], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6805, max_kl_dist_index: 2, max_train_grp_loss:  15.8928, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9061, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2373, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:23:08,575 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  17, train_loss:  13.4334, val_loss:  12.2615, grad_norm: 0.0002, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6505, 0.3477, 0.6805, param: [4.15146819 9.51898586 4.9582087  8.85733268], weights: [0.32976616 0.33141044 0.33882339], train_wt_loss:  40.3003, val_wt_loss: 36.7846, train_grp_loss: [11.73881705 15.89260509 11.1546016 ], val_grp_loss: [10.62321054 14.90582127 11.27143965], train_hist_grp_loss: [1.78157594 2.27895685 4.4910955 ], cur_train_grp_loss: [0.09466651 0.1231999  0.2373308 ], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6805, max_kl_dist_index: 2, max_train_grp_loss:  15.8926, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9058, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2373, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:23:09,583 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  18, train_loss:  13.4334, val_loss:  12.2615, grad_norm: 0.0002, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6504, 0.3477, 0.6805, param: [4.1514865  9.51870161 4.95836452 8.85742577], weights: [0.32957557 0.33131342 0.33911101], train_wt_loss:  40.3003, val_wt_loss: 36.7846, train_grp_loss: [11.7389862  15.89242327 11.15465541], val_grp_loss: [10.6233382  14.90557866 11.2715073 ], train_hist_grp_loss: [1.87624382 2.40215534 4.72842745], cur_train_grp_loss: [0.09466788 0.12319849 0.23733195], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6805, max_kl_dist_index: 2, max_train_grp_loss:  15.8924, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9056, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2373, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:23:10,581 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  19, train_loss:  13.4334, val_loss:  12.2615, grad_norm: 0.0002, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6504, 0.3476, 0.6805, param: [4.15150458 9.51841785 4.95852018 8.8575194 ], weights: [0.32938497 0.33121628 0.33939875], train_wt_loss:  40.3003, val_wt_loss: 36.7845, train_grp_loss: [11.73915484 15.89224203 11.15470901], val_grp_loss: [10.62346541 14.90533692 11.27157478], train_hist_grp_loss: [1.97091307 2.52535242 4.96576055], cur_train_grp_loss: [0.09466924 0.12319708 0.23733309], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6805, max_kl_dist_index: 2, max_train_grp_loss:  15.8922, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9053, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2373, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:23:11,569 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  20, train_loss:  13.4334, val_loss:  12.2615, grad_norm: 0.0003, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6504, 0.3476, 0.6805, param: [4.15152243 9.51813459 4.95867567 8.85761355], weights: [0.32919435 0.33111904 0.3396866 ], train_wt_loss:  40.3003, val_wt_loss: 36.7845, train_grp_loss: [11.73932298 15.89206139 11.1547624 ], val_grp_loss: [10.62359217 14.90509607 11.27164209], train_hist_grp_loss: [2.06558367 2.64854809 5.20309478], cur_train_grp_loss: [0.0946706  0.12319567 0.23733423], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6805, max_kl_dist_index: 2, max_train_grp_loss:  15.8921, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9051, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2373, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:23:12,566 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  21, train_loss:  13.4334, val_loss:  12.2615, grad_norm: 0.0003, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6504, 0.3476, 0.6805, param: [4.15154005 9.51785184 4.95883099 8.85770824], weights: [0.32900373 0.3310217  0.33997457], train_wt_loss:  40.3003, val_wt_loss: 36.7845, train_grp_loss: [11.7394906  15.89188134 11.15481557], val_grp_loss: [10.62371848 14.9048561  11.27170924], train_hist_grp_loss: [2.16025563 2.77174237 5.44043015], cur_train_grp_loss: [0.09467196 0.12319427 0.23733537], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6805, max_kl_dist_index: 2, max_train_grp_loss:  15.8919, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9049, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2373, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:23:13,624 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  22, train_loss:  13.4334, val_loss:  12.2615, grad_norm: 0.0003, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6504, 0.3476, 0.6805, param: [4.15155743 9.51756958 4.95898614 8.85780346], weights: [0.32881309 0.33092426 0.34026266], train_wt_loss:  40.3003, val_wt_loss: 36.7844, train_grp_loss: [11.73965772 15.89170187 11.15486851], val_grp_loss: [10.62384434 14.904617   11.27177621], train_hist_grp_loss: [2.25492894 2.89493524 5.67776665], cur_train_grp_loss: [0.09467331 0.12319288 0.2373365 ], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6805, max_kl_dist_index: 2, max_train_grp_loss:  15.8917, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9046, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2373, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:23:14,607 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  23, train_loss:  13.4334, val_loss:  12.2615, grad_norm: 0.0003, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6504, 0.3476, 0.6805, param: [4.15157459 9.51728783 4.95914112 8.8578992 ], weights: [0.32862243 0.33082671 0.34055086], train_wt_loss:  40.3003, val_wt_loss: 36.7844, train_grp_loss: [11.73982433 15.891523   11.15492125], val_grp_loss: [10.62396976 14.90437879 11.27184303], train_hist_grp_loss: [2.3496036  3.01812673 5.91510428], cur_train_grp_loss: [0.09467466 0.12319149 0.23733763], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6805, max_kl_dist_index: 2, max_train_grp_loss:  15.8915, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9044, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2373, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:23:15,570 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  24, train_loss:  13.4334, val_loss:  12.2614, grad_norm: 0.0003, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6504, 0.3476, 0.6804, param: [4.15159151 9.51700657 4.95929593 8.85799548], weights: [0.32843177 0.33072906 0.34083918], train_wt_loss:  40.3003, val_wt_loss: 36.7843, train_grp_loss: [11.73999043 15.89134472 11.15497376], val_grp_loss: [10.62409472 14.90414147 11.27190967], train_hist_grp_loss: [2.4442796  3.14131683 6.15244303], cur_train_grp_loss: [0.094676   0.1231901  0.23733875], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6804, max_kl_dist_index: 2, max_train_grp_loss:  15.8913, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9041, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2373, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:23:16,563 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  25, train_loss:  13.4334, val_loss:  12.2614, grad_norm: 0.0003, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6504, 0.3476, 0.6804, param: [4.1516082  9.51672582 4.95945057 8.85809229], weights: [0.32824109 0.3306313  0.34112761], train_wt_loss:  40.3003, val_wt_loss: 36.7843, train_grp_loss: [11.74015602 15.89116703 11.15502606], val_grp_loss: [10.62421923 14.90390502 11.27197615], train_hist_grp_loss: [2.53895694 3.26450555 6.3897829 ], cur_train_grp_loss: [0.09467734 0.12318872 0.23733987], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6804, max_kl_dist_index: 2, max_train_grp_loss:  15.8912, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9039, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2373, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:23:17,540 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  26, train_loss:  13.4334, val_loss:  12.2614, grad_norm: 0.0003, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6504, 0.3476, 0.6804, param: [4.15162465 9.51644556 4.95960504 8.85818964], weights: [0.3280504  0.33053344 0.34141616], train_wt_loss:  40.3003, val_wt_loss: 36.7842, train_grp_loss: [11.7403211  15.89098992 11.15507814], val_grp_loss: [10.62434329 14.90366945 11.27204247], train_hist_grp_loss: [2.63363562 3.38769289 6.62712388], cur_train_grp_loss: [0.09467868 0.12318734 0.23734098], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6804, max_kl_dist_index: 2, max_train_grp_loss:  15.8910, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9037, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2373, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:23:18,531 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  27, train_loss:  13.4334, val_loss:  12.2614, grad_norm: 0.0004, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6504, 0.3476, 0.6804, param: [4.15164087 9.51616581 4.95975935 8.85828751], weights: [0.3278597  0.33043548 0.34170482], train_wt_loss:  40.3003, val_wt_loss: 36.7842, train_grp_loss: [11.74048567 15.89081341 11.15513   ], val_grp_loss: [10.6244669  14.90343477 11.27210861], train_hist_grp_loss: [2.72831563 3.51087886 6.86446596], cur_train_grp_loss: [0.09468001 0.12318597 0.23734209], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6804, max_kl_dist_index: 2, max_train_grp_loss:  15.8908, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9034, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2373, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:23:19,547 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  28, train_loss:  13.4334, val_loss:  12.2614, grad_norm: 0.0004, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6504, 0.3476, 0.6804, param: [4.15165687 9.51588656 4.95991348 8.85838592], weights: [0.32766899 0.33033741 0.3419936 ], train_wt_loss:  40.3003, val_wt_loss: 36.7841, train_grp_loss: [11.74064973 15.8906375  11.15518164], val_grp_loss: [10.62459006 14.90320097 11.27217459], train_hist_grp_loss: [2.82299697 3.63406346 7.10180916], cur_train_grp_loss: [0.09468134 0.1231846  0.23734319], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6804, max_kl_dist_index: 2, max_train_grp_loss:  15.8906, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9032, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2373, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:23:20,581 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  29, train_loss:  13.4334, val_loss:  12.2614, grad_norm: 0.0004, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6504, 0.3476, 0.6804, param: [4.15167262 9.51560781 4.96006744 8.85848486], weights: [0.32747826 0.33023924 0.3422825 ], train_wt_loss:  40.3003, val_wt_loss: 36.7841, train_grp_loss: [11.74081329 15.89046217 11.15523307], val_grp_loss: [10.62471276 14.90296806 11.2722404 ], train_hist_grp_loss: [2.91767963 3.7572467  7.33915345], cur_train_grp_loss: [0.09468266 0.12318324 0.23734429], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6804, max_kl_dist_index: 2, max_train_grp_loss:  15.8905, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9030, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2373, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:23:21,595 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  30, train_loss:  13.4334, val_loss:  12.2614, grad_norm: 0.0004, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6504, 0.3476, 0.6804, param: [4.15168815 9.51532956 4.96022123 8.85858433], weights: [0.32728753 0.33014096 0.34257151], train_wt_loss:  40.3003, val_wt_loss: 36.7841, train_grp_loss: [11.74097633 15.89028743 11.15528427], val_grp_loss: [10.62483502 14.90273603 11.27230605], train_hist_grp_loss: [3.0123636  3.88042857 7.57649883], cur_train_grp_loss: [0.09468398 0.12318188 0.23734538], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6804, max_kl_dist_index: 2, max_train_grp_loss:  15.8903, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9027, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2373, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:23:22,613 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  31, train_loss:  13.4334, val_loss:  12.2613, grad_norm: 0.0004, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6504, 0.3476, 0.6804, param: [4.15170344 9.51505181 4.96037485 8.85868434], weights: [0.32709678 0.33004258 0.34286064], train_wt_loss:  40.3003, val_wt_loss: 36.7840, train_grp_loss: [11.74113886 15.89011329 11.15533526], val_grp_loss: [10.62495682 14.90250488 11.27237152], train_hist_grp_loss: [3.1070489 4.0036091 7.8138453], cur_train_grp_loss: [0.09468529 0.12318052 0.23734647], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6804, max_kl_dist_index: 2, max_train_grp_loss:  15.8901, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9025, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2373, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:23:23,590 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  32, train_loss:  13.4334, val_loss:  12.2613, grad_norm: 0.0004, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6504, 0.3476, 0.6804, param: [4.1517185  9.51477456 4.9605283  8.85878488], weights: [0.32690602 0.3299441  0.34314987], train_wt_loss:  40.3003, val_wt_loss: 36.7840, train_grp_loss: [11.74130087 15.88993973 11.15538603], val_grp_loss: [10.62507817 14.90227461 11.27243683], train_hist_grp_loss: [3.2017355  4.12678827 8.05119286], cur_train_grp_loss: [0.0946866  0.12317917 0.23734756], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6804, max_kl_dist_index: 2, max_train_grp_loss:  15.8899, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9023, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2373, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:23:24,584 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  33, train_loss:  13.4334, val_loss:  12.2613, grad_norm: 0.0004, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6504, 0.3476, 0.6804, param: [4.15173333 9.51449782 4.96068158 8.85888596], weights: [0.32671525 0.32984552 0.34343923], train_wt_loss:  40.3003, val_wt_loss: 36.7839, train_grp_loss: [11.74146238 15.88976677 11.15543658], val_grp_loss: [10.62519907 14.90204523 11.27250197], train_hist_grp_loss: [3.29642341 4.2499661  8.2885415 ], cur_train_grp_loss: [0.09468791 0.12317783 0.23734864], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6804, max_kl_dist_index: 2, max_train_grp_loss:  15.8898, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9020, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2373, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:23:25,589 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  34, train_loss:  13.4334, val_loss:  12.2613, grad_norm: 0.0005, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6504, 0.3475, 0.6804, param: [4.15174792 9.51422157 4.96083469 8.85898756], weights: [0.32652447 0.32974683 0.3437287 ], train_wt_loss:  40.3003, val_wt_loss: 36.7839, train_grp_loss: [11.74162337 15.8895944  11.15548691], val_grp_loss: [10.62531952 14.90181674 11.27256695], train_hist_grp_loss: [3.39111262 4.37314258 8.52589122], cur_train_grp_loss: [0.09468921 0.12317649 0.23734971], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6804, max_kl_dist_index: 2, max_train_grp_loss:  15.8896, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9018, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2373, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:23:26,570 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  35, train_loss:  13.4334, val_loss:  12.2613, grad_norm: 0.0005, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6504, 0.3475, 0.6804, param: [4.15176228 9.51394583 4.96098763 8.85908971], weights: [0.32633368 0.32964804 0.34401828], train_wt_loss:  40.3003, val_wt_loss: 36.7839, train_grp_loss: [11.74178386 15.88942263 11.15553702], val_grp_loss: [10.62543951 14.90158913 11.27263175], train_hist_grp_loss: [3.48580313 4.49631773 8.763242  ], cur_train_grp_loss: [0.09469051 0.12317515 0.23735079], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6804, max_kl_dist_index: 2, max_train_grp_loss:  15.8894, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9016, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:23:27,547 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  36, train_loss:  13.4334, val_loss:  12.2613, grad_norm: 0.0005, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6504, 0.3475, 0.6804, param: [4.15177641 9.51367059 4.9611404  8.85919238], weights: [0.32614287 0.32954915 0.34430798], train_wt_loss:  40.3003, val_wt_loss: 36.7838, train_grp_loss: [11.74194383 15.88925144 11.15558692], val_grp_loss: [10.62555905 14.9013624  11.27269639], train_hist_grp_loss: [3.58049494 4.61949155 9.00059385], cur_train_grp_loss: [0.09469181 0.12317382 0.23735185], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6804, max_kl_dist_index: 2, max_train_grp_loss:  15.8893, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9014, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:23:28,525 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  37, train_loss:  13.4334, val_loss:  12.2613, grad_norm: 0.0005, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6504, 0.3475, 0.6803, param: [4.1517903  9.51339585 4.96129299 8.8592956 ], weights: [0.32595206 0.32945016 0.34459779], train_wt_loss:  40.3003, val_wt_loss: 36.7838, train_grp_loss: [11.74210329 15.88908085 11.15563659], val_grp_loss: [10.62567813 14.90113656 11.27276086], train_hist_grp_loss: [3.67518804 4.74266405 9.23794677], cur_train_grp_loss: [0.0946931  0.12317249 0.23735291], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6803, max_kl_dist_index: 2, max_train_grp_loss:  15.8891, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9011, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:23:29,509 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  38, train_loss:  13.4334, val_loss:  12.2612, grad_norm: 0.0005, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6504, 0.3475, 0.6803, param: [4.15180397 9.51312161 4.96144542 8.85939934], weights: [0.32576123 0.32935106 0.34488771], train_wt_loss:  40.3003, val_wt_loss: 36.7837, train_grp_loss: [11.74226223 15.88891085 11.15568604], val_grp_loss: [10.62579677 14.90091161 11.27282516], train_hist_grp_loss: [3.76988242 4.86583521 9.47530074], cur_train_grp_loss: [0.09469438 0.12317117 0.23735397], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6803, max_kl_dist_index: 2, max_train_grp_loss:  15.8889, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9009, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:23:30,508 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  39, train_loss:  13.4334, val_loss:  12.2612, grad_norm: 0.0005, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6504, 0.3475, 0.6803, param: [4.15181739 9.51284788 4.96159767 8.85950363], weights: [0.3255704  0.32925186 0.34517775], train_wt_loss:  40.3003, val_wt_loss: 36.7837, train_grp_loss: [11.74242067 15.88874145 11.15573528], val_grp_loss: [10.62591495 14.90068754 11.27288929], train_hist_grp_loss: [3.86457808 4.98900507 9.71265576], cur_train_grp_loss: [0.09469566 0.12316985 0.23735502], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6803, max_kl_dist_index: 2, max_train_grp_loss:  15.8887, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9007, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:23:31,497 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  40, train_loss:  13.4334, val_loss:  12.2612, grad_norm: 0.0005, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6504, 0.3475, 0.6803, param: [4.15183059 9.51257465 4.96174976 8.85960844], weights: [0.32537955 0.32915255 0.3454679 ], train_wt_loss:  40.3003, val_wt_loss: 36.7836, train_grp_loss: [11.74257858 15.88857264 11.15578429], val_grp_loss: [10.62603267 14.90046436 11.27295326], train_hist_grp_loss: [3.95927502 5.1121736  9.95001183], cur_train_grp_loss: [0.09469694 0.12316854 0.23735607], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6803, max_kl_dist_index: 2, max_train_grp_loss:  15.8886, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9005, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:23:32,479 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  41, train_loss:  13.4334, val_loss:  12.2612, grad_norm: 0.0006, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6504, 0.3475, 0.6803, param: [4.15184355 9.51230192 4.96190167 8.8597138 ], weights: [0.32518869 0.32905315 0.34575816], train_wt_loss:  40.3003, val_wt_loss: 36.7836, train_grp_loss: [11.74273599 15.88840442 11.15583309], val_grp_loss: [10.62614995 14.90024207 11.27301705], train_hist_grp_loss: [ 4.05397324  5.23534083 10.18736894], cur_train_grp_loss: [0.09469821 0.12316723 0.23735711], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6803, max_kl_dist_index: 2, max_train_grp_loss:  15.8884, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9002, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:23:33,478 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  42, train_loss:  13.4334, val_loss:  12.2612, grad_norm: 0.0006, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6504, 0.3475, 0.6803, param: [4.15185628 9.51202969 4.96205341 8.85981969], weights: [0.32499783 0.32895364 0.34604853], train_wt_loss:  40.3003, val_wt_loss: 36.7836, train_grp_loss: [11.74289288 15.88823679 11.15588166], val_grp_loss: [10.62626676 14.90002066 11.27308068], train_hist_grp_loss: [ 4.14867272  5.35850676 10.42472709], cur_train_grp_loss: [0.09469948 0.12316593 0.23735815], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6803, max_kl_dist_index: 2, max_train_grp_loss:  15.8882, max_train_grp_loss_index: 1, max_val_grp_loss:  14.9000, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:23:34,459 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  43, train_loss:  13.4334, val_loss:  12.2612, grad_norm: 0.0006, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6504, 0.3475, 0.6803, param: [4.15186877 9.51175796 4.96220498 8.85992611], weights: [0.32480695 0.32885403 0.34633902], train_wt_loss:  40.3003, val_wt_loss: 36.7835, train_grp_loss: [11.74304926 15.88806976 11.15593002], val_grp_loss: [10.62638313 14.89980014 11.27314414], train_hist_grp_loss: [ 4.24337347  5.48167139 10.66208628], cur_train_grp_loss: [0.09470075 0.12316463 0.23735918], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6803, max_kl_dist_index: 2, max_train_grp_loss:  15.8881, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8998, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:23:35,446 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  44, train_loss:  13.4334, val_loss:  12.2612, grad_norm: 0.0006, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6504, 0.3475, 0.6803, param: [4.15188104 9.51148674 4.96235638 8.86003308], weights: [0.32461606 0.32875432 0.34662962], train_wt_loss:  40.3003, val_wt_loss: 36.7835, train_grp_loss: [11.74320512 15.88790332 11.15597815], val_grp_loss: [10.62649903 14.89958051 11.27320742], train_hist_grp_loss: [ 4.33807548  5.60483472 10.89944649], cur_train_grp_loss: [0.09470201 0.12316333 0.23736021], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6803, max_kl_dist_index: 2, max_train_grp_loss:  15.8879, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8996, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:23:36,427 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  45, train_loss:  13.4334, val_loss:  12.2611, grad_norm: 0.0006, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6504, 0.3475, 0.6803, param: [4.15189306 9.51121602 4.9625076  8.86014058], weights: [0.32442516 0.3286545  0.34692033], train_wt_loss:  40.3003, val_wt_loss: 36.7834, train_grp_loss: [11.74336047 15.88773748 11.15602607], val_grp_loss: [10.62661449 14.89936176 11.27327054], train_hist_grp_loss: [ 4.43277875  5.72799676 11.13680773], cur_train_grp_loss: [0.09470327 0.12316204 0.23736124], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6803, max_kl_dist_index: 2, max_train_grp_loss:  15.8877, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8994, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:23:37,392 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  46, train_loss:  13.4334, val_loss:  12.2611, grad_norm: 0.0006, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6504, 0.3475, 0.6803, param: [4.15190486 9.51094581 4.96265866 8.86024862], weights: [0.32423425 0.32855459 0.34721116], train_wt_loss:  40.3003, val_wt_loss: 36.7834, train_grp_loss: [11.74351531 15.88757223 11.15607376], val_grp_loss: [10.62672949 14.8991439  11.27333349], train_hist_grp_loss: [ 4.52748327  5.85115751 11.37416998], cur_train_grp_loss: [0.09470452 0.12316076 0.23736226], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6803, max_kl_dist_index: 2, max_train_grp_loss:  15.8876, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8991, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:23:38,383 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  47, train_loss:  13.4334, val_loss:  12.2611, grad_norm: 0.0006, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6504, 0.3475, 0.6803, param: [4.15191642 9.5106761  4.96280954 8.86035719], weights: [0.32404333 0.32845457 0.3475021 ], train_wt_loss:  40.3003, val_wt_loss: 36.7834, train_grp_loss: [11.74366963 15.88740757 11.15612123], val_grp_loss: [10.62684403 14.89892694 11.27339627], train_hist_grp_loss: [ 4.62218903  5.97431699 11.61153325], cur_train_grp_loss: [0.09470577 0.12315947 0.23736327], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6803, max_kl_dist_index: 2, max_train_grp_loss:  15.8874, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8989, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:23:39,362 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  48, train_loss:  13.4334, val_loss:  12.2611, grad_norm: 0.0007, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6504, 0.3475, 0.6803, param: [4.15192774 9.51040689 4.96296025 8.8604663 ], weights: [0.32385241 0.32835445 0.34779314], train_wt_loss:  40.3003, val_wt_loss: 36.7833, train_grp_loss: [11.74382343 15.88724351 11.15616849], val_grp_loss: [10.62695812 14.89871086 11.27345889], train_hist_grp_loss: [ 4.71689605  6.09747519 11.84889754], cur_train_grp_loss: [0.09470701 0.1231582  0.23736428], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6803, max_kl_dist_index: 2, max_train_grp_loss:  15.8872, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8987, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:23:40,332 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  49, train_loss:  13.4334, val_loss:  12.2611, grad_norm: 0.0007, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6504, 0.3474, 0.6803, param: [4.15193884 9.51013818 4.96311078 8.86057595], weights: [0.32366147 0.32825423 0.3480843 ], train_wt_loss:  40.3003, val_wt_loss: 36.7833, train_grp_loss: [11.74397672 15.88708004 11.15621552], val_grp_loss: [10.62707175 14.89849566 11.27352133], train_hist_grp_loss: [ 4.8116043   6.22063211 12.08626282], cur_train_grp_loss: [0.09470825 0.12315693 0.23736529], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6803, max_kl_dist_index: 2, max_train_grp_loss:  15.8871, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8985, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:23:41,338 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  50, train_loss:  13.4334, val_loss:  12.2611, grad_norm: 0.0007, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6504, 0.3474, 0.6803, param: [4.1519497  9.50986998 4.96326115 8.86068614], weights: [0.32347052 0.32815391 0.34837557], train_wt_loss:  40.3003, val_wt_loss: 36.7833, train_grp_loss: [11.74412949 15.88691717 11.15626233], val_grp_loss: [10.62718493 14.89828136 11.2735836 ], train_hist_grp_loss: [ 4.90631379  6.34378777 12.32362911], cur_train_grp_loss: [0.09470949 0.12315566 0.23736629], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6803, max_kl_dist_index: 2, max_train_grp_loss:  15.8869, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8983, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:23:42,328 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  51, train_loss:  13.4334, val_loss:  12.2611, grad_norm: 0.0007, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6504, 0.3474, 0.6802, param: [4.15196032 9.50960228 4.96341134 8.86079687], weights: [0.32327956 0.32805348 0.34866696], train_wt_loss:  40.3003, val_wt_loss: 36.7832, train_grp_loss: [11.74428175 15.88675489 11.15630892], val_grp_loss: [10.62729765 14.89806795 11.2736457 ], train_hist_grp_loss: [ 5.00102451  6.46694217 12.56099639], cur_train_grp_loss: [0.09471072 0.1231544  0.23736728], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6802, max_kl_dist_index: 2, max_train_grp_loss:  15.8868, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8981, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:23:43,344 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  52, train_loss:  13.4334, val_loss:  12.2611, grad_norm: 0.0007, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6504, 0.3474, 0.6802, param: [4.15197071 9.50933508 4.96356136 8.86090814], weights: [0.3230886  0.32795295 0.34895845], train_wt_loss:  40.3003, val_wt_loss: 36.7832, train_grp_loss: [11.74443349 15.88659321 11.15635528], val_grp_loss: [10.62740991 14.89785543 11.27370763], train_hist_grp_loss: [ 5.09573646  6.59009531 12.79836467], cur_train_grp_loss: [0.09471195 0.12315314 0.23736827], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6802, max_kl_dist_index: 2, max_train_grp_loss:  15.8866, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8979, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:23:44,330 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  53, train_loss:  13.4334, val_loss:  12.2610, grad_norm: 0.0007, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6504, 0.3474, 0.6802, param: [4.15198087 9.50906839 4.96371121 8.86101994], weights: [0.32289762 0.32785233 0.34925005], train_wt_loss:  40.3003, val_wt_loss: 36.7831, train_grp_loss: [11.74458472 15.88643212 11.15640143], val_grp_loss: [10.62752172 14.89764379 11.2737694 ], train_hist_grp_loss: [ 5.19044964  6.71324719 13.03573393], cur_train_grp_loss: [0.09471317 0.12315189 0.23736926], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6802, max_kl_dist_index: 2, max_train_grp_loss:  15.8864, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8976, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:23:45,321 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  54, train_loss:  13.4334, val_loss:  12.2610, grad_norm: 0.0007, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6504, 0.3474, 0.6802, param: [4.15199079 9.5088022  4.96386089 8.86113229], weights: [0.32270663 0.3277516  0.34954177], train_wt_loss:  40.3003, val_wt_loss: 36.7831, train_grp_loss: [11.74473542 15.88627163 11.15644736], val_grp_loss: [10.62763307 14.89743305 11.27383099], train_hist_grp_loss: [ 5.28516403  6.83639783 13.27310417], cur_train_grp_loss: [0.09471439 0.12315064 0.23737024], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6802, max_kl_dist_index: 2, max_train_grp_loss:  15.8863, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8974, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:23:46,315 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  55, train_loss:  13.4334, val_loss:  12.2610, grad_norm: 0.0008, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6504, 0.3474, 0.6802, param: [4.15200048 9.50853652 4.96401039 8.86124517], weights: [0.32251564 0.32765077 0.34983359], train_wt_loss:  40.3003, val_wt_loss: 36.7831, train_grp_loss: [11.74488562 15.88611174 11.15649306], val_grp_loss: [10.62774396 14.8972232  11.27389241], train_hist_grp_loss: [ 5.37987964  6.95954722 13.51047539], cur_train_grp_loss: [0.09471561 0.12314939 0.23737122], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6802, max_kl_dist_index: 2, max_train_grp_loss:  15.8861, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8972, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:23:47,293 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  56, train_loss:  13.4334, val_loss:  12.2610, grad_norm: 0.0008, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6504, 0.3474, 0.6802, param: [4.15200994 9.50827134 4.96415972 8.86135859], weights: [0.32232464 0.32754984 0.35012553], train_wt_loss:  40.3003, val_wt_loss: 36.7830, train_grp_loss: [11.74503529 15.88595244 11.15653854], val_grp_loss: [10.6278544  14.89701424 11.27395366], train_hist_grp_loss: [ 5.47459646  7.08269538 13.74784759], cur_train_grp_loss: [0.09471682 0.12314815 0.23737219], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6802, max_kl_dist_index: 2, max_train_grp_loss:  15.8860, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8970, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:23:48,270 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  57, train_loss:  13.4334, val_loss:  12.2610, grad_norm: 0.0008, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6504, 0.3474, 0.6802, param: [4.15201916 9.50800666 4.96430887 8.86147256], weights: [0.32213362 0.3274488  0.35041757], train_wt_loss:  40.3003, val_wt_loss: 36.7830, train_grp_loss: [11.74518445 15.88579373 11.1565838 ], val_grp_loss: [10.62796437 14.89680617 11.27401474], train_hist_grp_loss: [ 5.56931448  7.20584229 13.98522075], cur_train_grp_loss: [0.09471803 0.12314692 0.23737316], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6802, max_kl_dist_index: 2, max_train_grp_loss:  15.8858, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8968, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:23:49,253 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  58, train_loss:  13.4334, val_loss:  12.2610, grad_norm: 0.0008, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6504, 0.3474, 0.6802, param: [4.15202815 9.50774249 4.96445786 8.86158706], weights: [0.3219426  0.32734767 0.35070973], train_wt_loss:  40.3003, val_wt_loss: 36.7830, train_grp_loss: [11.74533308 15.88563563 11.15662884], val_grp_loss: [10.6280739  14.89659899 11.27407565], train_hist_grp_loss: [ 5.66403371  7.32898798 14.22259487], cur_train_grp_loss: [0.09471923 0.12314569 0.23737412], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6802, max_kl_dist_index: 2, max_train_grp_loss:  15.8856, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8966, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:23:50,272 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  59, train_loss:  13.4334, val_loss:  12.2610, grad_norm: 0.0008, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6504, 0.3474, 0.6802, param: [4.1520369  9.50747883 4.96460667 8.8617021 ], weights: [0.32175157 0.32724644 0.35100199], train_wt_loss:  40.3003, val_wt_loss: 36.7829, train_grp_loss: [11.7454812  15.88547811 11.15667365], val_grp_loss: [10.62818296 14.8963927  11.27413639], train_hist_grp_loss: [ 5.75875414  7.45213244 14.45996995], cur_train_grp_loss: [0.09472043 0.12314446 0.23737508], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6802, max_kl_dist_index: 2, max_train_grp_loss:  15.8855, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8964, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:23:51,280 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  60, train_loss:  13.4334, val_loss:  12.2610, grad_norm: 0.0008, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6504, 0.3474, 0.6802, param: [4.15204542 9.50721566 4.9647553  8.86181769], weights: [0.32156053 0.3271451  0.35129436], train_wt_loss:  40.3003, val_wt_loss: 36.7829, train_grp_loss: [11.74562881 15.8853212  11.15671824], val_grp_loss: [10.62829156 14.89618731 11.27419696], train_hist_grp_loss: [ 5.85347576  7.57527569 14.69734599], cur_train_grp_loss: [0.09472162 0.12314324 0.23737604], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6802, max_kl_dist_index: 2, max_train_grp_loss:  15.8853, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8962, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:23:52,278 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  61, train_loss:  13.4334, val_loss:  12.2610, grad_norm: 0.0008, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6504, 0.3474, 0.6802, param: [4.1520537  9.50695301 4.96490377 8.86193381], weights: [0.32136949 0.32704367 0.35158685], train_wt_loss:  40.3003, val_wt_loss: 36.7829, train_grp_loss: [11.74577589 15.88516488 11.15676262], val_grp_loss: [10.62839971 14.8959828  11.27425736], train_hist_grp_loss: [ 5.94819858  7.69841771 14.93472297], cur_train_grp_loss: [0.09472281 0.12314202 0.23737698], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6802, max_kl_dist_index: 2, max_train_grp_loss:  15.8852, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8960, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:23:53,273 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  62, train_loss:  13.4334, val_loss:  12.2609, grad_norm: 0.0009, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6504, 0.3474, 0.6802, param: [4.15206175 9.50669085 4.96505206 8.86205048], weights: [0.32117843 0.32694213 0.35187944], train_wt_loss:  40.3003, val_wt_loss: 36.7828, train_grp_loss: [11.74592245 15.88500916 11.15680676], val_grp_loss: [10.6285074  14.89577919 11.27431758], train_hist_grp_loss: [ 6.04292257  7.82155852 15.1721009 ], cur_train_grp_loss: [0.094724   0.12314081 0.23737793], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6802, max_kl_dist_index: 2, max_train_grp_loss:  15.8850, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8958, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:23:54,253 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  63, train_loss:  13.4334, val_loss:  12.2609, grad_norm: 0.0009, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6504, 0.3474, 0.6802, param: [4.15206956 9.5064292  4.96520017 8.86216769], weights: [0.32098737 0.3268405  0.35217214], train_wt_loss:  40.3003, val_wt_loss: 36.7828, train_grp_loss: [11.7460685  15.88485403 11.15685069], val_grp_loss: [10.62861463 14.89557647 11.27437764], train_hist_grp_loss: [ 6.13764776  7.94469813 15.40947977], cur_train_grp_loss: [0.09472518 0.12313961 0.23737887], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6802, max_kl_dist_index: 2, max_train_grp_loss:  15.8849, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8956, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:23:55,245 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  64, train_loss:  13.4334, val_loss:  12.2609, grad_norm: 0.0009, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6504, 0.3474, 0.6802, param: [4.15207714 9.50616806 4.96534812 8.86228544], weights: [0.32079629 0.32673876 0.35246495], train_wt_loss:  40.3003, val_wt_loss: 36.7828, train_grp_loss: [11.74621403 15.8846995  11.15689439], val_grp_loss: [10.6287214  14.89537465 11.27443752], train_hist_grp_loss: [ 6.23237411  8.06783653 15.64685957], cur_train_grp_loss: [0.09472636 0.1231384  0.2373798 ], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6802, max_kl_dist_index: 2, max_train_grp_loss:  15.8847, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8954, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:23:56,253 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  65, train_loss:  13.4334, val_loss:  12.2609, grad_norm: 0.0009, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6504, 0.3474, 0.6802, param: [4.15208449 9.50590742 4.96549588 8.86240373], weights: [0.32060521 0.32663692 0.35275787], train_wt_loss:  40.3003, val_wt_loss: 36.7827, train_grp_loss: [11.74635903 15.88454557 11.15693787], val_grp_loss: [10.62882772 14.89517372 11.27449724], train_hist_grp_loss: [ 6.32710165  8.19097374 15.8842403 ], cur_train_grp_loss: [0.09472753 0.12313721 0.23738073], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6802, max_kl_dist_index: 2, max_train_grp_loss:  15.8845, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8952, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:23:57,241 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  66, train_loss:  13.4334, val_loss:  12.2609, grad_norm: 0.0009, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6504, 0.3473, 0.6802, param: [4.1520916  9.50564729 4.96564348 8.86252256], weights: [0.32041412 0.32653498 0.35305089], train_wt_loss:  40.3003, val_wt_loss: 36.7827, train_grp_loss: [11.74650352 15.88439224 11.15698113], val_grp_loss: [10.62893357 14.89497368 11.27455678], train_hist_grp_loss: [ 6.42183035  8.31410975 16.12162196], cur_train_grp_loss: [0.0947287  0.12313601 0.23738166], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6802, max_kl_dist_index: 2, max_train_grp_loss:  15.8844, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8950, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:23:58,232 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  67, train_loss:  13.4334, val_loss:  12.2609, grad_norm: 0.0009, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6504, 0.3473, 0.6801, param: [4.15209847 9.50538766 4.9657909  8.86264194], weights: [0.32022303 0.32643295 0.35334403], train_wt_loss:  40.3003, val_wt_loss: 36.7827, train_grp_loss: [11.74664749 15.8842395  11.15702416], val_grp_loss: [10.62903896 14.89477454 11.27461615], train_hist_grp_loss: [ 6.51656022  8.43724457 16.35900453], cur_train_grp_loss: [0.09472987 0.12313482 0.23738258], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6801, max_kl_dist_index: 2, max_train_grp_loss:  15.8842, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8948, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:23:59,236 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  68, train_loss:  13.4334, val_loss:  12.2609, grad_norm: 0.0009, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6503, 0.3473, 0.6801, param: [4.15210512 9.50512854 4.96593815 8.86276186], weights: [0.32003192 0.32633081 0.35363727], train_wt_loss:  40.3003, val_wt_loss: 36.7826, train_grp_loss: [11.74679094 15.88408737 11.15706697], val_grp_loss: [10.6291439  14.89457629 11.27467535], train_hist_grp_loss: [ 6.61129124  8.56037821 16.59638803], cur_train_grp_loss: [0.09473103 0.12313364 0.23738349], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6801, max_kl_dist_index: 2, max_train_grp_loss:  15.8841, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8946, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:24:00,262 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  69, train_loss:  13.4334, val_loss:  12.2609, grad_norm: 0.0010, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6503, 0.3473, 0.6801, param: [4.15211152 9.50486992 4.96608522 8.86288232], weights: [0.31984081 0.32622857 0.35393062], train_wt_loss:  40.3003, val_wt_loss: 36.7826, train_grp_loss: [11.74693387 15.88393582 11.15710956], val_grp_loss: [10.62924837 14.89437893 11.27473437], train_hist_grp_loss: [ 6.70602343  8.68351067 16.83377243], cur_train_grp_loss: [0.09473218 0.12313246 0.2373844 ], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6801, max_kl_dist_index: 2, max_train_grp_loss:  15.8839, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8944, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:24:01,272 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  70, train_loss:  13.4334, val_loss:  12.2609, grad_norm: 0.0010, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6503, 0.3473, 0.6801, param: [4.15211769 9.50461181 4.96623211 8.86300333], weights: [0.31964969 0.32612624 0.35422407], train_wt_loss:  40.3003, val_wt_loss: 36.7826, train_grp_loss: [11.74707627 15.88378488 11.15715192], val_grp_loss: [10.62935239 14.89418247 11.27479323], train_hist_grp_loss: [ 6.80075677  8.80664196 17.07115774], cur_train_grp_loss: [0.09473334 0.12313129 0.23738531], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6801, max_kl_dist_index: 2, max_train_grp_loss:  15.8838, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8942, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:24:02,238 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  71, train_loss:  13.4334, val_loss:  12.2608, grad_norm: 0.0010, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6503, 0.3473, 0.6801, param: [4.15212363 9.50435421 4.96637884 8.86312487], weights: [0.31945856 0.3260238  0.35451764], train_wt_loss:  40.3003, val_wt_loss: 36.7825, train_grp_loss: [11.74721816 15.88363454 11.15719406], val_grp_loss: [10.62945594 14.8939869  11.27485191], train_hist_grp_loss: [ 6.89549125  8.92977207 17.30854395], cur_train_grp_loss: [0.09473449 0.12313012 0.23738621], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6801, max_kl_dist_index: 2, max_train_grp_loss:  15.8836, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8940, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:24:03,222 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  72, train_loss:  13.4334, val_loss:  12.2608, grad_norm: 0.0010, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6503, 0.3473, 0.6801, param: [4.15212933 9.50409711 4.96652539 8.86324697], weights: [0.31926743 0.32592126 0.35481131], train_wt_loss:  40.3003, val_wt_loss: 36.7825, train_grp_loss: [11.74735952 15.88348479 11.15723598], val_grp_loss: [10.62955904 14.89379223 11.27491042], train_hist_grp_loss: [ 6.99022688  9.05290102 17.54593106], cur_train_grp_loss: [0.09473563 0.12312895 0.23738711], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6801, max_kl_dist_index: 2, max_train_grp_loss:  15.8835, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8938, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:24:04,220 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  73, train_loss:  13.4334, val_loss:  12.2608, grad_norm: 0.0010, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6503, 0.3473, 0.6801, param: [4.1521348  9.50384051 4.96667176 8.8633696 ], weights: [0.31907629 0.32581863 0.35510509], train_wt_loss:  40.3003, val_wt_loss: 36.7825, train_grp_loss: [11.74750037 15.88333564 11.15727767], val_grp_loss: [10.62966167 14.89359846 11.27496876], train_hist_grp_loss: [ 7.08496365  9.17602881 17.78331906], cur_train_grp_loss: [0.09473677 0.12312779 0.237388  ], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6801, max_kl_dist_index: 2, max_train_grp_loss:  15.8833, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8936, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:24:05,217 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  74, train_loss:  13.4334, val_loss:  12.2608, grad_norm: 0.0010, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6503, 0.3473, 0.6801, param: [4.15214003 9.50358442 4.96681796 8.86349278], weights: [0.31888514 0.32571589 0.35539897], train_wt_loss:  40.3003, val_wt_loss: 36.7824, train_grp_loss: [11.74764069 15.88318709 11.15731913], val_grp_loss: [10.62976384 14.89340558 11.27502692], train_hist_grp_loss: [ 7.17970156  9.29915545 18.02070795], cur_train_grp_loss: [0.09473791 0.12312663 0.23738889], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6801, max_kl_dist_index: 2, max_train_grp_loss:  15.8832, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8934, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:24:06,192 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  75, train_loss:  13.4334, val_loss:  12.2608, grad_norm: 0.0010, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6503, 0.3473, 0.6801, param: [4.15214502 9.50332884 4.96696398 8.86361651], weights: [0.31869398 0.32561306 0.35569296], train_wt_loss:  40.3003, val_wt_loss: 36.7824, train_grp_loss: [11.74778049 15.88303914 11.15736038], val_grp_loss: [10.62986556 14.89321359 11.27508492], train_hist_grp_loss: [ 7.2744406   9.42228093 18.25809771], cur_train_grp_loss: [0.09473904 0.12312548 0.23738977], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6801, max_kl_dist_index: 2, max_train_grp_loss:  15.8830, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8932, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:24:07,173 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  76, train_loss:  13.4334, val_loss:  12.2608, grad_norm: 0.0011, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6503, 0.3473, 0.6801, param: [4.15214978 9.50307377 4.96710983 8.86374077], weights: [0.31850282 0.32551012 0.35598706], train_wt_loss:  40.3003, val_wt_loss: 36.7824, train_grp_loss: [11.74791977 15.88289179 11.1574014 ], val_grp_loss: [10.62996681 14.89302251 11.27514274], train_hist_grp_loss: [ 7.36918076  9.54540526 18.49548836], cur_train_grp_loss: [0.09474017 0.12312433 0.23739065], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6801, max_kl_dist_index: 2, max_train_grp_loss:  15.8829, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8930, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:24:08,194 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  77, train_loss:  13.4334, val_loss:  12.2608, grad_norm: 0.0011, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6503, 0.3473, 0.6801, param: [4.15215431 9.5028192  4.9672555  8.86386559], weights: [0.31831164 0.32540709 0.35628127], train_wt_loss:  40.3003, val_wt_loss: 36.7823, train_grp_loss: [11.74805852 15.88274504 11.15744219], val_grp_loss: [10.6300676  14.89283232 11.27520039], train_hist_grp_loss: [ 7.46392205  9.66852845 18.73287988], cur_train_grp_loss: [0.09474129 0.12312319 0.23739152], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6801, max_kl_dist_index: 2, max_train_grp_loss:  15.8827, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8928, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:24:09,177 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  78, train_loss:  13.4334, val_loss:  12.2608, grad_norm: 0.0011, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6503, 0.3473, 0.6801, param: [4.1521586  9.50256513 4.967401   8.86399095], weights: [0.31812047 0.32530396 0.35657558], train_wt_loss:  40.3003, val_wt_loss: 36.7823, train_grp_loss: [11.74819676 15.88259889 11.15748276], val_grp_loss: [10.63016793 14.89264302 11.27525786], train_hist_grp_loss: [ 7.55866446  9.79165051 18.97027227], cur_train_grp_loss: [0.09474241 0.12312205 0.23739239], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6801, max_kl_dist_index: 2, max_train_grp_loss:  15.8826, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8926, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:24:10,168 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  79, train_loss:  13.4334, val_loss:  12.2608, grad_norm: 0.0011, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6503, 0.3473, 0.6801, param: [4.15216265 9.50231158 4.96754633 8.86411685], weights: [0.31792928 0.32520073 0.35686999], train_wt_loss:  40.3003, val_wt_loss: 36.7823, train_grp_loss: [11.74833447 15.88245333 11.15752311], val_grp_loss: [10.63026779 14.89245463 11.27531516], train_hist_grp_loss: [ 7.65340798  9.91477143 19.20766552], cur_train_grp_loss: [0.09474352 0.12312092 0.23739325], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6801, max_kl_dist_index: 2, max_train_grp_loss:  15.8825, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8925, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:24:11,162 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  80, train_loss:  13.4334, val_loss:  12.2607, grad_norm: 0.0011, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6503, 0.3473, 0.6801, param: [4.15216647 9.50205852 4.96769147 8.8642433 ], weights: [0.31773809 0.3250974  0.35716451], train_wt_loss:  40.3003, val_wt_loss: 36.7822, train_grp_loss: [11.74847166 15.88230838 11.15756323], val_grp_loss: [10.6303672  14.89226713 11.27537229], train_hist_grp_loss: [ 7.74815261 10.03789122 19.44505963], cur_train_grp_loss: [0.09474463 0.12311979 0.23739411], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6801, max_kl_dist_index: 2, max_train_grp_loss:  15.8823, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8923, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:24:12,142 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  81, train_loss:  13.4334, val_loss:  12.2607, grad_norm: 0.0011, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6503, 0.3473, 0.6801, param: [4.15217005 9.50180598 4.96783645 8.86437029], weights: [0.31754689 0.32499397 0.35745914], train_wt_loss:  40.3003, val_wt_loss: 36.7822, train_grp_loss: [11.74860832 15.88216403 11.15760313], val_grp_loss: [10.63046614 14.89208052 11.27542925], train_hist_grp_loss: [ 7.84289835 10.16100989 19.68245459], cur_train_grp_loss: [0.09474574 0.12311867 0.23739496], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6801, max_kl_dist_index: 2, max_train_grp_loss:  15.8822, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8921, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:24:13,117 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  82, train_loss:  13.4334, val_loss:  12.2607, grad_norm: 0.0011, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6503, 0.3473, 0.6801, param: [4.1521734  9.50155394 4.96798124 8.86449783], weights: [0.31735569 0.32489044 0.35775387], train_wt_loss:  40.3003, val_wt_loss: 36.7822, train_grp_loss: [11.74874446 15.88202027 11.1576428 ], val_grp_loss: [10.63056462 14.89189482 11.27548603], train_hist_grp_loss: [ 7.93764519 10.28412744 19.9198504 ], cur_train_grp_loss: [0.09474684 0.12311755 0.23739581], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6801, max_kl_dist_index: 2, max_train_grp_loss:  15.8820, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8919, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:24:14,105 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  83, train_loss:  13.4334, val_loss:  12.2607, grad_norm: 0.0012, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6503, 0.3473, 0.6801, param: [4.15217651 9.50130241 4.96812586 8.86462592], weights: [0.31716448 0.32478681 0.35804871], train_wt_loss:  40.3003, val_wt_loss: 36.7822, train_grp_loss: [11.74888008 15.88187712 11.15768224], val_grp_loss: [10.63066264 14.89171001 11.27554264], train_hist_grp_loss: [ 8.03239313 10.40724388 20.15724705], cur_train_grp_loss: [0.09474794 0.12311644 0.23739666], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6801, max_kl_dist_index: 2, max_train_grp_loss:  15.8819, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8917, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:24:15,093 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  84, train_loss:  13.4334, val_loss:  12.2607, grad_norm: 0.0012, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6503, 0.3473, 0.6801, param: [4.15217939 9.50105139 4.96827031 8.86475455], weights: [0.31697326 0.32468309 0.35834365], train_wt_loss:  40.3003, val_wt_loss: 36.7821, train_grp_loss: [11.74901517 15.88173456 11.15772147], val_grp_loss: [10.6307602  14.89152611 11.27559908], train_hist_grp_loss: [ 8.12714217 10.53035921 20.39464455], cur_train_grp_loss: [0.09474903 0.12311533 0.23739749], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6801, max_kl_dist_index: 2, max_train_grp_loss:  15.8817, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8915, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:24:16,082 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  85, train_loss:  13.4334, val_loss:  12.2607, grad_norm: 0.0012, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6503, 0.3473, 0.6801, param: [4.15218203 9.50080087 4.96841457 8.86488373], weights: [0.31678204 0.32457926 0.3586387 ], train_wt_loss:  40.3003, val_wt_loss: 36.7821, train_grp_loss: [11.74914974 15.88159261 11.15776046], val_grp_loss: [10.63085729 14.8913431  11.27565534], train_hist_grp_loss: [ 8.22189229 10.65347343 20.63204288], cur_train_grp_loss: [0.09475012 0.12311422 0.23739833], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6801, max_kl_dist_index: 2, max_train_grp_loss:  15.8816, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8913, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:24:17,068 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  86, train_loss:  13.4334, val_loss:  12.2607, grad_norm: 0.0012, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6503, 0.3472, 0.6801, param: [4.15218444 9.50055086 4.96855867 8.86501346], weights: [0.31659081 0.32447534 0.35893385], train_wt_loss:  40.3003, val_wt_loss: 36.7821, train_grp_loss: [11.74928379 15.88145126 11.15779923], val_grp_loss: [10.63095392 14.89116099 11.27571143], train_hist_grp_loss: [ 8.3166435  10.77658655 20.86944204], cur_train_grp_loss: [0.09475121 0.12311312 0.23739916], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6801, max_kl_dist_index: 2, max_train_grp_loss:  15.8815, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8912, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:24:18,041 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  87, train_loss:  13.4335, val_loss:  12.2607, grad_norm: 0.0012, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6503, 0.3472, 0.6801, param: [4.15218661 9.50030136 4.96870258 8.86514373], weights: [0.31639957 0.32437132 0.3592291 ], train_wt_loss:  40.3004, val_wt_loss: 36.7820, train_grp_loss: [11.74941731 15.8813105  11.15783778], val_grp_loss: [10.63105009 14.89097978 11.27576735], train_hist_grp_loss: [ 8.41139578 10.89969857 21.10684202], cur_train_grp_loss: [0.09475229 0.12311203 0.23739998], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6801, max_kl_dist_index: 2, max_train_grp_loss:  15.8813, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8910, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:24:19,065 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  88, train_loss:  13.4335, val_loss:  12.2607, grad_norm: 0.0012, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6503, 0.3472, 0.6800, param: [4.15218854 9.50005237 4.96884632 8.86527456], weights: [0.31620833 0.32426721 0.35952446], train_wt_loss:  40.3004, val_wt_loss: 36.7820, train_grp_loss: [11.7495503  15.88117035 11.1578761 ], val_grp_loss: [10.63114579 14.89079946 11.27582309], train_hist_grp_loss: [ 8.50614915 11.02280951 21.34424282], cur_train_grp_loss: [0.09475337 0.12311093 0.2374008 ], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6800, max_kl_dist_index: 2, max_train_grp_loss:  15.8812, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8908, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:24:20,085 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  89, train_loss:  13.4335, val_loss:  12.2607, grad_norm: 0.0012, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6503, 0.3472, 0.6800, param: [4.15219024 9.49980388 4.96898989 8.86540592], weights: [0.31601709 0.32416299 0.35981992], train_wt_loss:  40.3004, val_wt_loss: 36.7820, train_grp_loss: [11.74968277 15.8810308  11.15791419], val_grp_loss: [10.63124103 14.89062005 11.27587866], train_hist_grp_loss: [ 8.60090359 11.14591936 21.58164444], cur_train_grp_loss: [0.09475444 0.12310985 0.23740162], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6800, max_kl_dist_index: 2, max_train_grp_loss:  15.8810, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8906, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:24:21,083 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  90, train_loss:  13.4335, val_loss:  12.2607, grad_norm: 0.0013, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6503, 0.3472, 0.6800, param: [4.1521917  9.4995559  4.96913327 8.86553784], weights: [0.31582583 0.32405868 0.36011549], train_wt_loss:  40.3004, val_wt_loss: 36.7820, train_grp_loss: [11.74981472 15.88089185 11.15795206], val_grp_loss: [10.63133581 14.89044154 11.27593405], train_hist_grp_loss: [ 8.69565909 11.26902812 21.81904687], cur_train_grp_loss: [0.09475551 0.12310877 0.23740243], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6800, max_kl_dist_index: 2, max_train_grp_loss:  15.8809, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8904, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:24:22,067 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  91, train_loss:  13.4335, val_loss:  12.2606, grad_norm: 0.0013, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6503, 0.3472, 0.6800, param: [4.15219292 9.49930842 4.96927648 8.8656703 ], weights: [0.31563458 0.32395426 0.36041116], train_wt_loss:  40.3004, val_wt_loss: 36.7819, train_grp_loss: [11.74994614 15.8807535  11.1579897 ], val_grp_loss: [10.63143012 14.89026393 11.27598927], train_hist_grp_loss: [ 8.79041566 11.39213581 22.05645011], cur_train_grp_loss: [0.09475657 0.12310769 0.23740324], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6800, max_kl_dist_index: 2, max_train_grp_loss:  15.8808, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8903, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:24:23,055 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  92, train_loss:  13.4335, val_loss:  12.2606, grad_norm: 0.0013, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6503, 0.3472, 0.6800, param: [4.15219391 9.49906146 4.96941951 8.86580332], weights: [0.31544331 0.32384975 0.36070693], train_wt_loss:  40.3004, val_wt_loss: 36.7819, train_grp_loss: [11.75007704 15.88061575 11.15802711], val_grp_loss: [10.63152397 14.89008722 11.27604432], train_hist_grp_loss: [ 8.88517329 11.51524243 22.29385414], cur_train_grp_loss: [0.09475763 0.12310662 0.23740404], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6800, max_kl_dist_index: 2, max_train_grp_loss:  15.8806, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8901, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:24:24,039 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  93, train_loss:  13.4335, val_loss:  12.2606, grad_norm: 0.0013, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6503, 0.3472, 0.6800, param: [4.15219466 9.498815   4.96956237 8.86593688], weights: [0.31525205 0.32374515 0.36100281], train_wt_loss:  40.3004, val_wt_loss: 36.7819, train_grp_loss: [11.7502074  15.88047861 11.1580643 ], val_grp_loss: [10.63161735 14.88991141 11.27609919], train_hist_grp_loss: [ 8.97993198 11.63834798 22.53125898], cur_train_grp_loss: [0.09475869 0.12310555 0.23740483], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6800, max_kl_dist_index: 2, max_train_grp_loss:  15.8805, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8899, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:24:25,026 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  94, train_loss:  13.4335, val_loss:  12.2606, grad_norm: 0.0013, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6503, 0.3472, 0.6800, param: [4.15219518 9.49856905 4.96970505 8.86607099], weights: [0.31506077 0.32364044 0.36129879], train_wt_loss:  40.3004, val_wt_loss: 36.7819, train_grp_loss: [11.75033725 15.88034206 11.15810127], val_grp_loss: [10.63171027 14.8897365  11.27615389], train_hist_grp_loss: [ 9.07469172 11.76145246 22.7686646 ], cur_train_grp_loss: [0.09475974 0.12310449 0.23740562], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6800, max_kl_dist_index: 2, max_train_grp_loss:  15.8803, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8897, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:24:26,019 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  95, train_loss:  13.4335, val_loss:  12.2606, grad_norm: 0.0013, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6503, 0.3472, 0.6800, param: [4.15219546 9.49832361 4.96984755 8.86620565], weights: [0.31486949 0.32353564 0.36159487], train_wt_loss:  40.3004, val_wt_loss: 36.7818, train_grp_loss: [11.75046656 15.88020612 11.158138  ], val_grp_loss: [10.63180272 14.88956249 11.27620841], train_hist_grp_loss: [ 9.1694525  11.88455589 23.00607101], cur_train_grp_loss: [0.09476078 0.12310343 0.23740641], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6800, max_kl_dist_index: 2, max_train_grp_loss:  15.8802, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8896, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:24:27,007 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  96, train_loss:  13.4335, val_loss:  12.2606, grad_norm: 0.0013, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6503, 0.3472, 0.6800, param: [4.15219551 9.49807868 4.96998988 8.86634085], weights: [0.31467821 0.32343074 0.36189105], train_wt_loss:  40.3004, val_wt_loss: 36.7818, train_grp_loss: [11.75059535 15.88007078 11.15817451], val_grp_loss: [10.63189471 14.88938938 11.27626276], train_hist_grp_loss: [ 9.26421433 12.00765826 23.2434782 ], cur_train_grp_loss: [0.09476183 0.12310237 0.23740719], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6800, max_kl_dist_index: 2, max_train_grp_loss:  15.8801, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8894, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:24:27,999 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  97, train_loss:  13.4335, val_loss:  12.2606, grad_norm: 0.0014, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6503, 0.3472, 0.6800, param: [4.15219531 9.49783425 4.97013202 8.86647661], weights: [0.31448692 0.32332574 0.36218733], train_wt_loss:  40.3004, val_wt_loss: 36.7818, train_grp_loss: [11.75072361 15.87993604 11.1582108 ], val_grp_loss: [10.63198624 14.88921718 11.27631693], train_hist_grp_loss: [ 9.35897719 12.13075958 23.48088617], cur_train_grp_loss: [0.09476287 0.12310132 0.23740797], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6800, max_kl_dist_index: 2, max_train_grp_loss:  15.8799, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8892, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:24:28,981 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  98, train_loss:  13.4335, val_loss:  12.2606, grad_norm: 0.0014, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6503, 0.3472, 0.6800, param: [4.15219488 9.49759033 4.97027399 8.86661292], weights: [0.31429563 0.32322065 0.36248372], train_wt_loss:  40.3004, val_wt_loss: 36.7818, train_grp_loss: [11.75085135 15.87980191 11.15824685], val_grp_loss: [10.6320773  14.88904588 11.27637093], train_hist_grp_loss: [ 9.45374109 12.25385986 23.71829491], cur_train_grp_loss: [0.0947639  0.12310028 0.23740874], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6800, max_kl_dist_index: 2, max_train_grp_loss:  15.8798, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8890, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:24:29,998 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  99, train_loss:  13.4335, val_loss:  12.2606, grad_norm: 0.0014, live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6503, 0.3472, 0.6800, param: [4.15219422 9.49734692 4.97041579 8.86674977], weights: [0.31410433 0.32311546 0.36278021], train_wt_loss:  40.3004, val_wt_loss: 36.7817, train_grp_loss: [11.75097856 15.87966838 11.15828268], val_grp_loss: [10.63216789 14.88887547 11.27642476], train_hist_grp_loss: [ 9.54850603 12.3769591  23.95570442], cur_train_grp_loss: [0.09476493 0.12309924 0.23740951], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6800, max_kl_dist_index: 2, max_train_grp_loss:  15.8797, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8889, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:24:30,907 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1654] - INFO: Iteration:  99, train_loss:  13.4335, val_loss:  12.2606, grad_norm: 0.0014,  live_grad: 0.0000, reward_err: 0.0036, 0.0310, 0.0012, KL_dist: 0.6503, 0.3472, 0.6800, param: [4.15219422 9.49734692 4.97041579 8.86674977], weights: [0.31410433 0.32311546 0.36278021], train_wt_loss:  40.3004, val_wt_loss: 36.7817, train_grp_loss: [11.75097856 15.87966838 11.15828268], val_grp_loss: [10.63216789 14.88887547 11.27642476], train_hist_grp_loss: [ 9.54850603 12.3769591  23.95570442], cur_train_grp_loss: [0.09476493 0.12309924 0.23740951], max_reward_err:  0.0310, max_reward_err_index: 1, max_kl_dist:  0.6800, max_kl_dist_index: 2, max_train_grp_loss:  15.8797, max_train_grp_loss_index: 1, max_val_grp_loss:  14.8889, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2374, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:24:31,130 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:388] - INFO: Policy parameter learned solely on the preference data rdpo: [4.15219422 9.49734692 4.97041579 8.86674977].
2024-10-07 17:24:31,468 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Uniform reward: 3.8269, 3.8269, 3.1987
2024-10-07 17:24:31,468 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Optimal reward: 3.8681, 7.1581, 3.3364
2024-10-07 17:24:31,469 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Policy reward: 3.8540, 6.9363, 3.3325
2024-10-07 17:24:31,469 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:402] - INFO: Reward Error: 0.0036, 0.0310, 0.0012
2024-10-07 17:24:32,158 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:417] - INFO: Optimal reward: 3.8681, 7.1581, 3.3364
Known param reward: [[3.8680634765625, 6.699916015625, 3.30809521484375], [3.46072314453125, 7.1581357421875, 3.12821826171875], [3.83464501953125, 7.0068994140625, 3.336449462890625]], Known param reward error: [[0.0, 0.06401383587376193, 0.00849832984501714], [0.10530859550248342, 0.0, 0.06241101610796404], [0.008639583407495802, 0.02112789329121925, 0.0]].
