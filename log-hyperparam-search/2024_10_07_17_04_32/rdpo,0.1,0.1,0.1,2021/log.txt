2024-10-07 17:10:06,094 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log-hyperparam-search/2024_10_07_17_04_32/rdpo,0.1,0.1,0.1,2021
2024-10-07 17:10:06,095 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2021
2024-10-07 17:10:06,096 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-10-07 17:10:06,187 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.2351, l2 distance: 36.4442, acc: 0.90.
2024-10-07 17:10:06,188 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-10-07 17:10:06,189 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [ 9.05939251 17.1373287   9.50347978 12.39752865]
2024-10-07 17:10:06,400 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.8285, 7.1348, 3.2752
2024-10-07 17:10:06,629 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1314] - INFO: unique_group_ids: {0, 1, 2}
2024-10-07 17:10:07,838 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  0, train_loss:  12.1558, val_loss:  12.4222, grad_norm: 0.4595, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6575, 0.3055, 0.6508, param: [5.44160773 8.30422321 5.14586335 8.58351783], weights: [0.33110125 0.33071804 0.33818071], train_wt_loss:  36.4675, val_wt_loss: 37.2666, train_grp_loss: [11.8000696  13.08156758 10.73086642], val_grp_loss: [12.66253707 12.45937553 12.14399798], train_hist_grp_loss: [0.15100158 0.13942111 0.36256349], cur_train_grp_loss: [0.15100158 0.13942111 0.36256349], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6575, max_kl_dist_index: 0, max_train_grp_loss:  13.0816, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6625, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.3626, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:10:08,873 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  1, train_loss:  12.1558, val_loss:  12.4225, grad_norm: 0.0004, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6578, 0.3057, 0.6511, param: [5.44219962 8.30249722 5.14846895 8.58730321], weights: [0.32964118 0.32959739 0.34076143], train_wt_loss:  36.4675, val_wt_loss: 37.2675, train_grp_loss: [11.80079706 13.08120199 10.72998541], val_grp_loss: [12.66370468 12.45898669 12.14409227], train_hist_grp_loss: [0.24540213 0.24407365 0.57718082], cur_train_grp_loss: [0.09440056 0.10465254 0.21461733], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6578, max_kl_dist_index: 0, max_train_grp_loss:  13.0812, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6637, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2146, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:10:09,917 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  2, train_loss:  12.1558, val_loss:  12.4228, grad_norm: 0.0005, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6580, 0.3058, 0.6513, param: [5.4427849  8.30078509 5.1510858  8.59114435], weights: [0.32817809 0.32847078 0.34335113], train_wt_loss:  36.4675, val_wt_loss: 37.2684, train_grp_loss: [11.80150362 13.08086666 10.72909332], val_grp_loss: [12.66485507 12.45863226 12.14417855], train_hist_grp_loss: [0.33980851 0.34872326 0.79178052], cur_train_grp_loss: [0.09440638 0.10464962 0.21459971], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6580, max_kl_dist_index: 0, max_train_grp_loss:  13.0809, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6649, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2146, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:10:11,006 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  3, train_loss:  12.1558, val_loss:  12.4231, grad_norm: 0.0007, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6583, 0.3060, 0.6515, param: [5.44336354 8.29908672 5.15371402 8.5950415 ], weights: [0.32671204 0.32733828 0.34594969], train_wt_loss:  36.4675, val_wt_loss: 37.2693, train_grp_loss: [11.8021893  13.08056167 10.72819013], val_grp_loss: [12.66598825 12.45831235 12.14425683], train_hist_grp_loss: [0.43422054 0.4533702  1.00636239], cur_train_grp_loss: [0.09441203 0.10464693 0.21458187], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6583, max_kl_dist_index: 0, max_train_grp_loss:  13.0806, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6660, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2146, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:10:12,174 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  4, train_loss:  12.1559, val_loss:  12.4234, grad_norm: 0.0009, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6586, 0.3061, 0.6518, param: [5.44393548 8.29740202 5.15635371 8.5989949 ], weights: [0.32524309 0.32619995 0.34855697], train_wt_loss:  36.4676, val_wt_loss: 37.2702, train_grp_loss: [11.80285411 13.08028712 10.72727582], val_grp_loss: [12.66710424 12.45802706 12.14432715], train_hist_grp_loss: [0.52863805 0.55801469 1.22092619], cur_train_grp_loss: [0.09441751 0.10464449 0.2145638 ], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6586, max_kl_dist_index: 0, max_train_grp_loss:  13.0803, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6671, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2146, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:10:13,271 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  5, train_loss:  12.1559, val_loss:  12.4237, grad_norm: 0.0011, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6589, 0.3063, 0.6520, param: [5.4445007  8.29573093 5.15900494 8.60300479], weights: [0.32377131 0.32505586 0.35117283], train_wt_loss:  36.4676, val_wt_loss: 37.2711, train_grp_loss: [11.80349807 13.0800431  10.72635038], val_grp_loss: [12.66820308 12.4577765  12.14438953], train_hist_grp_loss: [0.62306089 0.66265699 1.43547171], cur_train_grp_loss: [0.09442283 0.1046423  0.21454552], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6589, max_kl_dist_index: 0, max_train_grp_loss:  13.0800, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6682, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2145, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:10:14,336 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  6, train_loss:  12.1559, val_loss:  12.4240, grad_norm: 0.0013, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6592, 0.3064, 0.6523, param: [5.44505913 8.29407334 5.16166783 8.60707143], weights: [0.32229677 0.32390608 0.35379715], train_wt_loss:  36.4676, val_wt_loss: 37.2720, train_grp_loss: [11.80412122 13.07982971 10.72541379], val_grp_loss: [12.66928477 12.45756077 12.144444  ], train_hist_grp_loss: [0.71748887 0.76729733 1.64999872], cur_train_grp_loss: [0.09442798 0.10464034 0.21452701], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6592, max_kl_dist_index: 0, max_train_grp_loss:  13.0798, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6693, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2145, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:10:15,421 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  7, train_loss:  12.1559, val_loss:  12.4243, grad_norm: 0.0015, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6594, 0.3066, 0.6525, param: [5.44561074 8.29242917 5.16434247 8.61119504], weights: [0.32081953 0.32275069 0.35642978], train_wt_loss:  36.4677, val_wt_loss: 37.2730, train_grp_loss: [11.80472357 13.07964702 10.72446605], val_grp_loss: [12.67034936 12.45737998 12.1444906 ], train_hist_grp_loss: [0.81192184 0.87193597 1.86450699], cur_train_grp_loss: [0.09443297 0.10463864 0.21450828], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6594, max_kl_dist_index: 0, max_train_grp_loss:  13.0796, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6703, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2145, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:10:16,474 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  8, train_loss:  12.1559, val_loss:  12.4246, grad_norm: 0.0017, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6597, 0.3068, 0.6528, param: [5.44615549 8.29079834 5.16702895 8.61537587], weights: [0.31933966 0.32158975 0.35907058], train_wt_loss:  36.4678, val_wt_loss: 37.2739, train_grp_loss: [11.80530516 13.07949513 10.72350714], val_grp_loss: [12.67139685 12.45723422 12.14452935], train_hist_grp_loss: [0.90635963 0.97657315 2.07899631], cur_train_grp_loss: [0.09443779 0.10463718 0.21448932], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6597, max_kl_dist_index: 0, max_train_grp_loss:  13.0795, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6714, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2145, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:10:17,466 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  9, train_loss:  12.1559, val_loss:  12.4250, grad_norm: 0.0019, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6600, 0.3069, 0.6531, param: [5.44669333 8.28918075 5.16972737 8.61961416], weights: [0.31785724 0.32042334 0.36171941], train_wt_loss:  36.4678, val_wt_loss: 37.2749, train_grp_loss: [11.80586601 13.07937414 10.72253706], val_grp_loss: [12.6724273  12.45712361 12.14456029], train_hist_grp_loss: [1.00080207 1.08120911 2.29346646], cur_train_grp_loss: [0.09444244 0.10463596 0.21447014], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6600, max_kl_dist_index: 0, max_train_grp_loss:  13.0794, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6724, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2145, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:10:18,466 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  10, train_loss:  12.1560, val_loss:  12.4253, grad_norm: 0.0022, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6603, 0.3071, 0.6534, param: [5.44722421 8.2875763  5.17243782 8.62391013], weights: [0.31637234 0.31925154 0.36437612], train_wt_loss:  36.4679, val_wt_loss: 37.2758, train_grp_loss: [11.80640615 13.07928413 10.72155579], val_grp_loss: [12.67344071 12.45704825 12.14458345], train_hist_grp_loss: [1.095249  1.1858441 2.5079172], cur_train_grp_loss: [0.09444693 0.10463499 0.21445074], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6603, max_kl_dist_index: 0, max_train_grp_loss:  13.0793, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6734, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2145, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:10:19,459 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  11, train_loss:  12.1560, val_loss:  12.4256, grad_norm: 0.0024, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6606, 0.3072, 0.6536, param: [5.44774809 8.28598491 5.17516038 8.62826402], weights: [0.31488502 0.31807442 0.36704056], train_wt_loss:  36.4680, val_wt_loss: 37.2768, train_grp_loss: [11.80692563 13.0792252  10.72056334], val_grp_loss: [12.67443713 12.45700824 12.14459888], train_hist_grp_loss: [1.18970025 1.29047837 2.72234831], cur_train_grp_loss: [0.09445125 0.10463427 0.21443112], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6606, max_kl_dist_index: 0, max_train_grp_loss:  13.0792, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6744, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2144, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:10:20,447 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  12, train_loss:  12.1560, val_loss:  12.4259, grad_norm: 0.0026, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6609, 0.3074, 0.6539, param: [5.44826492 8.28440647 5.17789516 8.63267606], weights: [0.31339536 0.31689205 0.36971259], train_wt_loss:  36.4681, val_wt_loss: 37.2778, train_grp_loss: [11.80742447 13.07919742 10.71955969], val_grp_loss: [12.67541659 12.45700369 12.1446066 ], train_hist_grp_loss: [1.28415565 1.39511218 2.93675958], cur_train_grp_loss: [0.09445541 0.1046338  0.21441127], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6609, max_kl_dist_index: 0, max_train_grp_loss:  13.0792, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6754, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2144, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:10:21,458 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  13, train_loss:  12.1561, val_loss:  12.4263, grad_norm: 0.0029, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6613, 0.3076, 0.6542, param: [5.44877465 8.28284089 5.18064224 8.63714648], weights: [0.31190343 0.31570452 0.37239205], train_wt_loss:  36.4682, val_wt_loss: 37.2788, train_grp_loss: [11.80790272 13.07920091 10.71854486], val_grp_loss: [12.67637912 12.45703469 12.14460666], train_hist_grp_loss: [1.37861505 1.49974575 3.15115077], cur_train_grp_loss: [0.0944594  0.10463358 0.21439119], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6613, max_kl_dist_index: 0, max_train_grp_loss:  13.0792, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6764, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2144, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:10:22,466 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  14, train_loss:  12.1561, val_loss:  12.4266, grad_norm: 0.0031, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6616, 0.3078, 0.6545, param: [5.44927723 8.28128806 5.18340172 8.6416755 ], weights: [0.31040931 0.31451189 0.3750788 ], train_wt_loss:  36.4683, val_wt_loss: 37.2798, train_grp_loss: [11.80836041 13.07923573 10.71751882], val_grp_loss: [12.67732476 12.45710135 12.1445991 ], train_hist_grp_loss: [1.47307827 1.60437936 3.36552167], cur_train_grp_loss: [0.09446322 0.10463361 0.2143709 ], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6616, max_kl_dist_index: 0, max_train_grp_loss:  13.0792, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6773, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2144, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:10:23,458 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  15, train_loss:  12.1561, val_loss:  12.4269, grad_norm: 0.0034, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6619, 0.3079, 0.6548, param: [5.44977262 8.27974789 5.18617367 8.64626334], weights: [0.30891307 0.31331426 0.37777267], train_wt_loss:  36.4684, val_wt_loss: 37.2808, train_grp_loss: [11.80879759 13.07930198 10.7164816 ], val_grp_loss: [12.67825355 12.45720378 12.14458396], train_hist_grp_loss: [1.56754515 1.70901325 3.57987205], cur_train_grp_loss: [0.09446688 0.10463389 0.21435038], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6619, max_kl_dist_index: 0, max_train_grp_loss:  13.0793, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6783, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2144, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:10:24,459 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  16, train_loss:  12.1562, val_loss:  12.4273, grad_norm: 0.0036, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6622, 0.3081, 0.6551, param: [5.45026077 8.27822027 5.18895818 8.65091023], weights: [0.30741479 0.3121117  0.38047351], train_wt_loss:  36.4685, val_wt_loss: 37.2818, train_grp_loss: [11.80921431 13.07939976 10.71543318], val_grp_loss: [12.67916552 12.45734208 12.14456128], train_hist_grp_loss: [1.66201554 1.81364766 3.79420168], cur_train_grp_loss: [0.09447038 0.10463442 0.21432963], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6622, max_kl_dist_index: 0, max_train_grp_loss:  13.0794, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6792, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2143, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:10:25,453 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  17, train_loss:  12.1562, val_loss:  12.4276, grad_norm: 0.0039, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6625, 0.3083, 0.6554, param: [5.45074163 8.2767051  5.19175535 8.65561638], weights: [0.30591454 0.3109043  0.38318116], train_wt_loss:  36.4686, val_wt_loss: 37.2829, train_grp_loss: [11.80961061 13.07952914 10.71437357], val_grp_loss: [12.68006073 12.45751635 12.14453112], train_hist_grp_loss: [1.75648925 1.91828286 4.00851034], cur_train_grp_loss: [0.09447371 0.1046352  0.21430866], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6625, max_kl_dist_index: 0, max_train_grp_loss:  13.0795, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6801, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2143, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:10:26,464 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  18, train_loss:  12.1562, val_loss:  12.4280, grad_norm: 0.0042, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6629, 0.3085, 0.6557, param: [5.45121515 8.27520226 5.19456526 8.66038201], weights: [0.3044124  0.30969213 0.38589547], train_wt_loss:  36.4687, val_wt_loss: 37.2839, train_grp_loss: [11.80998654 13.07969022 10.71330279], val_grp_loss: [12.6809392  12.45772669 12.14449352], train_hist_grp_loss: [1.85096613 2.0229191  4.22279782], cur_train_grp_loss: [0.09447688 0.10463623 0.21428747], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6629, max_kl_dist_index: 0, max_train_grp_loss:  13.0797, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6809, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2143, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:10:27,479 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  19, train_loss:  12.1563, val_loss:  12.4283, grad_norm: 0.0044, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6632, 0.3086, 0.6560, param: [5.45168127 8.27371164 5.19738798 8.66520733], weights: [0.30290845 0.30847527 0.38861627], train_wt_loss:  36.4689, val_wt_loss: 37.2850, train_grp_loss: [11.81034217 13.07988309 10.71222083], val_grp_loss: [12.68180098 12.4579732  12.14444853], train_hist_grp_loss: [1.94544603 2.12755662 4.43706387], cur_train_grp_loss: [0.09447989 0.10463752 0.21426606], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6632, max_kl_dist_index: 0, max_train_grp_loss:  13.0799, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6818, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2143, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:10:28,457 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  20, train_loss:  12.1563, val_loss:  12.4287, grad_norm: 0.0047, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6635, 0.3088, 0.6563, param: [5.45213994 8.27223314 5.20022361 8.67009254], weights: [0.30140277 0.30725382 0.3913434 ], train_wt_loss:  36.4690, val_wt_loss: 37.2861, train_grp_loss: [11.81067753 13.08010782 10.71112771], val_grp_loss: [12.68264613 12.45825598 12.1443962 ], train_hist_grp_loss: [2.03992876 2.23219568 4.65130829], cur_train_grp_loss: [0.09448274 0.10463906 0.21424442], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6635, max_kl_dist_index: 0, max_train_grp_loss:  13.0801, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6826, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2142, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:10:29,461 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  21, train_loss:  12.1564, val_loss:  12.4291, grad_norm: 0.0050, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6639, 0.3090, 0.6567, param: [5.45259112 8.27076665 5.20307222 8.67503786], weights: [0.29989544 0.30602786 0.3940767 ], train_wt_loss:  36.4692, val_wt_loss: 37.2872, train_grp_loss: [11.8109927  13.08036451 10.71002344], val_grp_loss: [12.68347468 12.45857514 12.14433659], train_hist_grp_loss: [2.13441418 2.33683654 4.86553084], cur_train_grp_loss: [0.09448542 0.10464086 0.21422255], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6639, max_kl_dist_index: 0, max_train_grp_loss:  13.0804, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6835, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2142, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:10:30,467 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  22, train_loss:  12.1565, val_loss:  12.4294, grad_norm: 0.0053, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6642, 0.3092, 0.6570, param: [5.45303476 8.26931203 5.2059339  8.68004348], weights: [0.29838654 0.30479746 0.396816  ], train_wt_loss:  36.4694, val_wt_loss: 37.2883, train_grp_loss: [11.81128772 13.08065324 10.70890802], val_grp_loss: [12.6842867  12.45893077 12.14426974], train_hist_grp_loss: [2.22890213 2.44147946 5.07973131], cur_train_grp_loss: [0.09448794 0.10464292 0.21420047], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6642, max_kl_dist_index: 0, max_train_grp_loss:  13.0807, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6843, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2142, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:10:31,441 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  23, train_loss:  12.1565, val_loss:  12.4298, grad_norm: 0.0056, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6646, 0.3094, 0.6573, param: [5.45347079 8.26786918 5.20880872 8.68510961], weights: [0.29687615 0.30356273 0.39956112], train_wt_loss:  36.4696, val_wt_loss: 37.2894, train_grp_loss: [11.81156267 13.08097409 10.70778148], val_grp_loss: [12.68508222 12.45932297 12.14419571], train_hist_grp_loss: [2.32339243 2.54612469 5.29390947], cur_train_grp_loss: [0.0944903  0.10464523 0.21417816], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6646, max_kl_dist_index: 0, max_train_grp_loss:  13.0810, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6851, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2142, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:10:32,438 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  24, train_loss:  12.1566, val_loss:  12.4302, grad_norm: 0.0059, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6649, 0.3096, 0.6577, param: [5.45389917 8.26643798 5.21169675 8.69023644], weights: [0.29536435 0.30232374 0.40231191], train_wt_loss:  36.4698, val_wt_loss: 37.2905, train_grp_loss: [11.81181761 13.08132716 10.70664384], val_grp_loss: [12.6858613  12.45975185 12.14411456], train_hist_grp_loss: [2.41788493 2.65077248 5.5080651 ], cur_train_grp_loss: [0.0944925  0.10464779 0.21415563], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6649, max_kl_dist_index: 0, max_train_grp_loss:  13.0813, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6859, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2142, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:10:33,446 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  25, train_loss:  12.1567, val_loss:  12.4305, grad_norm: 0.0062, live_grad: 0.0000, reward_err: 0.0105, 0.0139, 0.0002, KL_dist: 0.6653, 0.3098, 0.6580, param: [5.45431984 8.2650183  5.21459809 8.69542417], weights: [0.29385122 0.30108058 0.4050682 ], train_wt_loss:  36.4700, val_wt_loss: 37.2916, train_grp_loss: [11.81205261 13.08171251 10.7054951 ], val_grp_loss: [12.686624   12.46021749 12.14402636], train_hist_grp_loss: [2.51237947 2.7554231  5.72219798], cur_train_grp_loss: [0.09449454 0.10465062 0.21413288], max_reward_err:  0.0139, max_reward_err_index: 1, max_kl_dist:  0.6653, max_kl_dist_index: 0, max_train_grp_loss:  13.0817, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6866, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2141, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:10:34,434 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  26, train_loss:  12.1567, val_loss:  12.4309, grad_norm: 0.0065, live_grad: 0.0000, reward_err: 0.0105, 0.0139, 0.0002, KL_dist: 0.6657, 0.3100, 0.6584, param: [5.45473275 8.26361003 5.2175128  8.70067299], weights: [0.29233685 0.29983335 0.4078298 ], train_wt_loss:  36.4702, val_wt_loss: 37.2928, train_grp_loss: [11.81226773 13.08213025 10.70433529], val_grp_loss: [12.68737037 12.46071999 12.14393116], train_hist_grp_loss: [2.60687589 2.8600768  5.93630788], cur_train_grp_loss: [0.09449642 0.1046537  0.2141099 ], max_reward_err:  0.0139, max_reward_err_index: 1, max_kl_dist:  0.6657, max_kl_dist_index: 0, max_train_grp_loss:  13.0821, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6874, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2141, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:10:35,431 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  27, train_loss:  12.1568, val_loss:  12.4313, grad_norm: 0.0068, live_grad: 0.0000, reward_err: 0.0105, 0.0139, 0.0002, KL_dist: 0.6660, 0.3102, 0.6587, param: [5.45513784 8.26221302 5.22044095 8.70598308], weights: [0.29082132 0.29858213 0.41059655], train_wt_loss:  36.4704, val_wt_loss: 37.2940, train_grp_loss: [11.81246306 13.08258044 10.70316444], val_grp_loss: [12.68810047 12.46125946 12.14382902], train_hist_grp_loss: [2.70137403 2.96473384 6.15039458], cur_train_grp_loss: [0.09449814 0.10465704 0.21408671], max_reward_err:  0.0139, max_reward_err_index: 1, max_kl_dist:  0.6660, max_kl_dist_index: 0, max_train_grp_loss:  13.0826, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6881, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2141, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:10:36,471 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  28, train_loss:  12.1569, val_loss:  12.4317, grad_norm: 0.0071, live_grad: 0.0000, reward_err: 0.0105, 0.0139, 0.0002, KL_dist: 0.6664, 0.3104, 0.6591, param: [5.45553506 8.26082717 5.22338262 8.71135462], weights: [0.28930471 0.29732701 0.41336828], train_wt_loss:  36.4706, val_wt_loss: 37.2951, train_grp_loss: [11.81263866 13.08306317 10.70198256], val_grp_loss: [12.68881436 12.46183598 12.14372   ], train_hist_grp_loss: [2.79587374 3.06939448 6.36445787], cur_train_grp_loss: [0.0944997  0.10466064 0.21406329], max_reward_err:  0.0139, max_reward_err_index: 1, max_kl_dist:  0.6664, max_kl_dist_index: 0, max_train_grp_loss:  13.0831, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6888, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2141, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:10:37,453 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  29, train_loss:  12.1570, val_loss:  12.4321, grad_norm: 0.0074, live_grad: 0.0000, reward_err: 0.0105, 0.0139, 0.0002, KL_dist: 0.6668, 0.3106, 0.6594, param: [5.45592436 8.25945233 5.22633788 8.7167878 ], weights: [0.28778711 0.29606808 0.4161448 ], train_wt_loss:  36.4709, val_wt_loss: 37.2963, train_grp_loss: [11.81279462 13.08357852 10.70078968], val_grp_loss: [12.6895121  12.46244966 12.14360419], train_hist_grp_loss: [2.89037485 3.17405899 6.57849752], cur_train_grp_loss: [0.09450111 0.10466451 0.21403965], max_reward_err:  0.0139, max_reward_err_index: 1, max_kl_dist:  0.6668, max_kl_dist_index: 0, max_train_grp_loss:  13.0836, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6895, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2140, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:10:38,471 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  30, train_loss:  12.1570, val_loss:  12.4325, grad_norm: 0.0078, live_grad: 0.0000, reward_err: 0.0105, 0.0139, 0.0002, KL_dist: 0.6671, 0.3108, 0.6598, param: [5.45630568 8.25808837 5.22930679 8.72228279], weights: [0.28626861 0.29480544 0.41892595], train_wt_loss:  36.4711, val_wt_loss: 37.2975, train_grp_loss: [11.81293101 13.08412656 10.69958583], val_grp_loss: [12.69019376 12.46310057 12.14348163], train_hist_grp_loss: [2.9848772  3.27872762 6.79251332], cur_train_grp_loss: [0.09450236 0.10466863 0.21401579], max_reward_err:  0.0139, max_reward_err_index: 1, max_kl_dist:  0.6671, max_kl_dist_index: 0, max_train_grp_loss:  13.0841, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6902, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2140, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:10:39,483 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  31, train_loss:  12.1571, val_loss:  12.4329, grad_norm: 0.0081, live_grad: 0.0000, reward_err: 0.0105, 0.0139, 0.0002, KL_dist: 0.6675, 0.3110, 0.6602, param: [5.45667895 8.25673516 5.23228942 8.72783977], weights: [0.28474929 0.29353917 0.42171154], train_wt_loss:  36.4714, val_wt_loss: 37.2988, train_grp_loss: [11.81304792 13.08470738 10.69837104], val_grp_loss: [12.6908594  12.46378883 12.14335241], train_hist_grp_loss: [3.07938065 3.38340063 7.00650503], cur_train_grp_loss: [0.09450345 0.10467301 0.21399172], max_reward_err:  0.0139, max_reward_err_index: 1, max_kl_dist:  0.6675, max_kl_dist_index: 0, max_train_grp_loss:  13.0847, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6909, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2140, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:10:40,472 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  32, train_loss:  12.1572, val_loss:  12.4333, grad_norm: 0.0084, live_grad: 0.0000, reward_err: 0.0105, 0.0139, 0.0002, KL_dist: 0.6679, 0.3112, 0.6605, param: [5.45704414 8.25539256 5.23528585 8.7334589 ], weights: [0.28322923 0.29226937 0.4245014 ], train_wt_loss:  36.4717, val_wt_loss: 37.3000, train_grp_loss: [11.81314544 13.08532105 10.69714534], val_grp_loss: [12.69150909 12.46451451 12.14321659], train_hist_grp_loss: [3.17388503 3.48807829 7.22047246], cur_train_grp_loss: [0.09450438 0.10467766 0.21396742], max_reward_err:  0.0139, max_reward_err_index: 1, max_kl_dist:  0.6679, max_kl_dist_index: 0, max_train_grp_loss:  13.0853, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6915, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2140, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:10:41,484 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  33, train_loss:  12.1573, val_loss:  12.4338, grad_norm: 0.0088, live_grad: 0.0000, reward_err: 0.0105, 0.0143, 0.0002, KL_dist: 0.6683, 0.3114, 0.6609, param: [5.45740117 8.25406043 5.23829613 8.73914034], weights: [0.28170852 0.29099614 0.42729534], train_wt_loss:  36.4719, val_wt_loss: 37.3013, train_grp_loss: [11.81322366 13.08596766 10.69590876], val_grp_loss: [12.6921429  12.46527771 12.14307425], train_hist_grp_loss: [3.2683902  3.59276086 7.43441536], cur_train_grp_loss: [0.09450516 0.10468257 0.21394291], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6683, max_kl_dist_index: 0, max_train_grp_loss:  13.0860, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6921, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2139, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:10:42,483 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  34, train_loss:  12.1574, val_loss:  12.4342, grad_norm: 0.0091, live_grad: 0.0000, reward_err: 0.0105, 0.0143, 0.0002, KL_dist: 0.6687, 0.3116, 0.6613, param: [5.45775    8.25273863 5.24132033 8.74488427], weights: [0.28018726 0.28971956 0.43009319], train_wt_loss:  36.4722, val_wt_loss: 37.3025, train_grp_loss: [11.81328267 13.08664726 10.69466135], val_grp_loss: [12.6927609  12.46607852 12.14292546], train_hist_grp_loss: [3.36289599 3.6974486  7.64833354], cur_train_grp_loss: [0.09450579 0.10468774 0.21391818], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6687, max_kl_dist_index: 0, max_train_grp_loss:  13.0866, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6928, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2139, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:10:43,516 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  35, train_loss:  12.1575, val_loss:  12.4346, grad_norm: 0.0095, live_grad: 0.0000, reward_err: 0.0105, 0.0143, 0.0002, KL_dist: 0.6691, 0.3119, 0.6617, param: [5.45809056 8.25142702 5.2443585  8.75069082], weights: [0.27866552 0.28843973 0.43289476], train_wt_loss:  36.4726, val_wt_loss: 37.3038, train_grp_loss: [11.81332256 13.08735994 10.69340312], val_grp_loss: [12.69336315 12.46691703 12.1427703 ], train_hist_grp_loss: [3.45740225 3.80214177 7.86222676], cur_train_grp_loss: [0.09450626 0.10469318 0.21389323], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6691, max_kl_dist_index: 0, max_train_grp_loss:  13.0874, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6934, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2139, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:10:44,505 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  36, train_loss:  12.1576, val_loss:  12.4350, grad_norm: 0.0099, live_grad: 0.0000, reward_err: 0.0105, 0.0143, 0.0002, KL_dist: 0.6695, 0.3121, 0.6621, param: [5.4584228  8.25012546 5.24741071 8.75656016], weights: [0.27714339 0.28715674 0.43569987], train_wt_loss:  36.4729, val_wt_loss: 37.3051, train_grp_loss: [11.81334343 13.08810577 10.69213414], val_grp_loss: [12.69394974 12.46779332 12.14260884], train_hist_grp_loss: [3.55190883 3.90684065 8.07609483], cur_train_grp_loss: [0.09450658 0.10469888 0.21386806], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6695, max_kl_dist_index: 0, max_train_grp_loss:  13.0881, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6939, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2139, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:10:45,509 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  37, train_loss:  12.1577, val_loss:  12.4355, grad_norm: 0.0102, live_grad: 0.0000, reward_err: 0.0105, 0.0143, 0.0002, KL_dist: 0.6699, 0.3123, 0.6625, param: [5.45874667 8.24883378 5.25047702 8.76249244], weights: [0.27562097 0.2858707  0.43850833], train_wt_loss:  36.4732, val_wt_loss: 37.3064, train_grp_loss: [11.81334538 13.08888482 10.69085443], val_grp_loss: [12.69452075 12.46870748 12.14244117], train_hist_grp_loss: [3.64641558 4.0115455  8.28993751], cur_train_grp_loss: [0.09450675 0.10470485 0.21384268], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6699, max_kl_dist_index: 0, max_train_grp_loss:  13.0889, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6945, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2138, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:10:46,515 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  38, train_loss:  12.1579, val_loss:  12.4359, grad_norm: 0.0106, live_grad: 0.0000, reward_err: 0.0102, 0.0143, 0.0001, KL_dist: 0.6703, 0.3125, 0.6629, param: [5.45906209 8.24755185 5.25355747 8.76848779], weights: [0.27409834 0.28458169 0.44131997], train_wt_loss:  36.4736, val_wt_loss: 37.3078, train_grp_loss: [11.81332852 13.08969716 10.68956404], val_grp_loss: [12.69507624 12.46965959 12.14226737], train_hist_grp_loss: [3.74092234 4.11625658 8.5037546 ], cur_train_grp_loss: [0.09450676 0.10471108 0.21381709], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6703, max_kl_dist_index: 0, max_train_grp_loss:  13.0897, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6951, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2138, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:10:47,541 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  39, train_loss:  12.1580, val_loss:  12.4364, grad_norm: 0.0110, live_grad: 0.0000, reward_err: 0.0102, 0.0143, 0.0001, KL_dist: 0.6707, 0.3127, 0.6633, param: [5.45936901 8.24627951 5.25665213 8.77454636], weights: [0.27257559 0.28328982 0.44413459], train_wt_loss:  36.4739, val_wt_loss: 37.3091, train_grp_loss: [11.81329295 13.09054286 10.68826302], val_grp_loss: [12.69561631 12.47064974 12.14208752], train_hist_grp_loss: [3.83542897 4.22097416 8.71754588], cur_train_grp_loss: [0.09450663 0.10471758 0.21379128], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6707, max_kl_dist_index: 0, max_train_grp_loss:  13.0905, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6956, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2138, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:10:48,526 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  40, train_loss:  12.1581, val_loss:  12.4368, grad_norm: 0.0114, live_grad: 0.0000, reward_err: 0.0102, 0.0143, 0.0001, KL_dist: 0.6712, 0.3130, 0.6637, param: [5.45966738 8.24501661 5.25976105 8.78066828], weights: [0.27105281 0.28199518 0.44695202], train_wt_loss:  36.4743, val_wt_loss: 37.3105, train_grp_loss: [11.81323878 13.09142199 10.6869514 ], val_grp_loss: [12.69614103 12.47167801 12.14190171], train_hist_grp_loss: [3.92993531 4.3256985  8.93131114], cur_train_grp_loss: [0.09450634 0.10472434 0.21376526], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6712, max_kl_dist_index: 0, max_train_grp_loss:  13.0914, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6961, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2138, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:10:49,518 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  41, train_loss:  12.1582, val_loss:  12.4373, grad_norm: 0.0118, live_grad: 0.0000, reward_err: 0.0102, 0.0143, 0.0001, KL_dist: 0.6716, 0.3132, 0.6641, param: [5.45995714 8.24376298 5.26288427 8.78685368], weights: [0.26953008 0.28069786 0.44977205], train_wt_loss:  36.4747, val_wt_loss: 37.3119, train_grp_loss: [11.81316612 13.09233461 10.68562925], val_grp_loss: [12.69665049 12.47274448 12.14171002], train_hist_grp_loss: [4.02444122 4.43042987 9.14505017], cur_train_grp_loss: [0.09450591 0.10473138 0.21373903], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6716, max_kl_dist_index: 0, max_train_grp_loss:  13.0923, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6967, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2137, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:10:50,525 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  42, train_loss:  12.1584, val_loss:  12.4378, grad_norm: 0.0121, live_grad: 0.0000, reward_err: 0.0102, 0.0143, 0.0001, KL_dist: 0.6720, 0.3134, 0.6646, param: [5.46023823 8.24251848 5.26602185 8.79310269], weights: [0.26800751 0.27939797 0.45259452], train_wt_loss:  36.4751, val_wt_loss: 37.3133, train_grp_loss: [11.81307508 13.09328078 10.68429662], val_grp_loss: [12.69714477 12.47384922 12.14151255], train_hist_grp_loss: [4.11894655 4.53516855 9.35876275], cur_train_grp_loss: [0.09450533 0.10473868 0.21371259], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6720, max_kl_dist_index: 0, max_train_grp_loss:  13.0933, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6971, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2137, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:10:51,528 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  43, train_loss:  12.1585, val_loss:  12.4382, grad_norm: 0.0125, live_grad: 0.0000, reward_err: 0.0102, 0.0143, 0.0001, KL_dist: 0.6724, 0.3137, 0.6650, param: [5.46051058 8.24128293 5.26917383 8.79941542], weights: [0.26648517 0.27809561 0.45541922], train_wt_loss:  36.4755, val_wt_loss: 37.3147, train_grp_loss: [11.81296579 13.09426058 10.68295355], val_grp_loss: [12.69762396 12.47499233 12.14130937], train_hist_grp_loss: [4.21345115 4.6399148  9.57244869], cur_train_grp_loss: [0.0945046  0.10474625 0.21368593], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6724, max_kl_dist_index: 0, max_train_grp_loss:  13.0943, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6976, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2137, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:10:52,539 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  44, train_loss:  12.1586, val_loss:  12.4387, grad_norm: 0.0130, live_grad: 0.0000, reward_err: 0.0102, 0.0143, 0.0001, KL_dist: 0.6729, 0.3139, 0.6654, param: [5.46077414 8.24005618 5.27234025 8.80579201], weights: [0.26496316 0.27679086 0.45824597], train_wt_loss:  36.4759, val_wt_loss: 37.3161, train_grp_loss: [11.81283836 13.09527405 10.6816001 ], val_grp_loss: [12.69808815 12.47617386 12.1411006 ], train_hist_grp_loss: [4.30795488 4.74466888 9.78610776], cur_train_grp_loss: [0.09450373 0.10475408 0.21365907], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6729, max_kl_dist_index: 0, max_train_grp_loss:  13.0953, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6981, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2137, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:10:53,509 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  45, train_loss:  12.1588, val_loss:  12.4392, grad_norm: 0.0134, live_grad: 0.0000, reward_err: 0.0102, 0.0143, 0.0001, KL_dist: 0.6733, 0.3142, 0.6659, param: [5.46102885 8.23883806 5.27552116 8.81223254], weights: [0.26344157 0.27548384 0.46107459], train_wt_loss:  36.4764, val_wt_loss: 37.3176, train_grp_loss: [11.81269293 13.09632127 10.68023633], val_grp_loss: [12.69853743 12.4773939  12.14088631], train_hist_grp_loss: [4.40245758 4.84943107 9.99973976], cur_train_grp_loss: [0.09450271 0.10476219 0.213632  ], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6733, max_kl_dist_index: 0, max_train_grp_loss:  13.0963, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6985, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2136, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:10:54,519 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  46, train_loss:  12.1589, val_loss:  12.4397, grad_norm: 0.0138, live_grad: 0.0000, reward_err: 0.0102, 0.0143, 0.0001, KL_dist: 0.6738, 0.3144, 0.6663, param: [5.46127465 8.23762839 5.2787166  8.81873715], weights: [0.26192049 0.27417463 0.46390488], train_wt_loss:  36.4768, val_wt_loss: 37.3191, train_grp_loss: [11.8125296  13.09740229 10.67886229], val_grp_loss: [12.6989719  12.47865251 12.14066661], train_hist_grp_loss: [ 4.49695913  4.95420165 10.21334448], cur_train_grp_loss: [0.09450154 0.10477057 0.21360473], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6738, max_kl_dist_index: 0, max_train_grp_loss:  13.0974, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6990, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2136, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:10:55,531 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  47, train_loss:  12.1591, val_loss:  12.4402, grad_norm: 0.0142, live_grad: 0.0000, reward_err: 0.0102, 0.0143, 0.0001, KL_dist: 0.6742, 0.3146, 0.6668, param: [5.46151148 8.23642702 5.28192661 8.82530591], weights: [0.26040001 0.27286334 0.46673665], train_wt_loss:  36.4773, val_wt_loss: 37.3206, train_grp_loss: [11.81234851 13.09851716 10.67747806], val_grp_loss: [12.69939166 12.47994978 12.14044159], train_hist_grp_loss: [ 4.59145937  5.05898086 10.42692173], cur_train_grp_loss: [0.09450024 0.10477922 0.21357725], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6742, max_kl_dist_index: 0, max_train_grp_loss:  13.0985, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6994, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2136, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:10:56,565 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  48, train_loss:  12.1593, val_loss:  12.4407, grad_norm: 0.0146, live_grad: 0.0000, reward_err: 0.0102, 0.0143, 0.0001, KL_dist: 0.6747, 0.3149, 0.6672, param: [5.46173928 8.23523376 5.28515122 8.83193894], weights: [0.25888021 0.27155007 0.46956971], train_wt_loss:  36.4778, val_wt_loss: 37.3221, train_grp_loss: [11.8121498  13.09966595 10.67608369], val_grp_loss: [12.69979679 12.48128576 12.14021136], train_hist_grp_loss: [ 4.68595815  5.163769   10.64047129], cur_train_grp_loss: [0.09449879 0.10478814 0.21354956], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6747, max_kl_dist_index: 0, max_train_grp_loss:  13.0997, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6998, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2135, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:10:57,565 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  49, train_loss:  12.1594, val_loss:  12.4412, grad_norm: 0.0151, live_grad: 0.0000, reward_err: 0.0102, 0.0143, 0.0001, KL_dist: 0.6751, 0.3151, 0.6677, param: [5.46195799 8.23404844 5.28839047 8.83863632], weights: [0.2573612  0.27023492 0.47240388], train_wt_loss:  36.4783, val_wt_loss: 37.3236, train_grp_loss: [11.8119336  13.10084869 10.67467925], val_grp_loss: [12.7001874  12.48266054 12.139976  ], train_hist_grp_loss: [ 4.78045535  5.26856633 10.85399297], cur_train_grp_loss: [0.0944972  0.10479733 0.21352167], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6751, max_kl_dist_index: 0, max_train_grp_loss:  13.1008, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7002, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2135, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:10:58,560 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  50, train_loss:  12.1596, val_loss:  12.4417, grad_norm: 0.0155, live_grad: 0.0000, reward_err: 0.0102, 0.0143, 0.0001, KL_dist: 0.6756, 0.3154, 0.6681, param: [5.46216755 8.23287088 5.29164438 8.84539813], weights: [0.25584306 0.26891798 0.47523897], train_wt_loss:  36.4788, val_wt_loss: 37.3252, train_grp_loss: [11.81170005 13.10206546 10.67326481], val_grp_loss: [12.70056359 12.48407416 12.13973563], train_hist_grp_loss: [ 4.87495082  5.37337312 11.06748655], cur_train_grp_loss: [0.09449547 0.10480679 0.21349359], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6756, max_kl_dist_index: 0, max_train_grp_loss:  13.1021, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7006, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2135, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:10:59,550 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  51, train_loss:  12.1598, val_loss:  12.4422, grad_norm: 0.0160, live_grad: 0.0000, reward_err: 0.0102, 0.0143, 0.0001, KL_dist: 0.6760, 0.3156, 0.6686, param: [5.46236791 8.23170091 5.29491299 8.85222447], weights: [0.25432587 0.26759936 0.47807477], train_wt_loss:  36.4794, val_wt_loss: 37.3267, train_grp_loss: [11.81144928 13.10331628 10.67184044], val_grp_loss: [12.70092546 12.48552669 12.13949035], train_hist_grp_loss: [ 4.96944442  5.47818964 11.28095185], cur_train_grp_loss: [0.0944936  0.10481652 0.2134653 ], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6760, max_kl_dist_index: 0, max_train_grp_loss:  13.1033, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7009, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2135, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:11:00,537 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  52, train_loss:  12.1600, val_loss:  12.4428, grad_norm: 0.0164, live_grad: 0.0000, reward_err: 0.0102, 0.0143, 0.0001, KL_dist: 0.6765, 0.3159, 0.6691, param: [5.46255899 8.23053834 5.29819633 8.85911539], weights: [0.25280974 0.26627915 0.48091111], train_wt_loss:  36.4799, val_wt_loss: 37.3283, train_grp_loss: [11.81118144 13.10460122 10.6704062 ], val_grp_loss: [12.70127312 12.4870182  12.13924027], train_hist_grp_loss: [ 5.06393602  5.58301617 11.49438866], cur_train_grp_loss: [0.09449159 0.10482653 0.21343681], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6765, max_kl_dist_index: 0, max_train_grp_loss:  13.1046, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7013, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2134, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:11:01,543 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  53, train_loss:  12.1602, val_loss:  12.4433, grad_norm: 0.0169, live_grad: 0.0000, reward_err: 0.0102, 0.0143, 0.0001, KL_dist: 0.6770, 0.3162, 0.6696, param: [5.46274075 8.22938298 5.30149442 8.86607099], weights: [0.25129475 0.26495746 0.48374779], train_wt_loss:  36.4805, val_wt_loss: 37.3299, train_grp_loss: [11.81089667 13.10592032 10.66896217], val_grp_loss: [12.70160668 12.48854875 12.13898549], train_hist_grp_loss: [ 5.15842547  5.68785298 11.70779678], cur_train_grp_loss: [0.09448945 0.10483681 0.21340812], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6770, max_kl_dist_index: 0, max_train_grp_loss:  13.1059, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7016, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2134, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:11:02,536 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  54, train_loss:  12.1604, val_loss:  12.4438, grad_norm: 0.0174, live_grad: 0.0000, reward_err: 0.0102, 0.0143, 0.0001, KL_dist: 0.6775, 0.3164, 0.6700, param: [5.46291312 8.22823465 5.30480728 8.87309131], weights: [0.24978099 0.26363439 0.48658462], train_wt_loss:  36.4811, val_wt_loss: 37.3315, train_grp_loss: [11.81059514 13.10727361 10.66750844], val_grp_loss: [12.70192624 12.49011839 12.13872611], train_hist_grp_loss: [ 5.25291264  5.79270034 11.92117602], cur_train_grp_loss: [0.09448717 0.10484736 0.21337924], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6775, max_kl_dist_index: 0, max_train_grp_loss:  13.1073, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7019, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2134, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:11:03,529 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  55, train_loss:  12.1606, val_loss:  12.4444, grad_norm: 0.0178, live_grad: 0.0000, reward_err: 0.0102, 0.0143, 0.0001, KL_dist: 0.6779, 0.3167, 0.6705, param: [5.46307604 8.22709316 5.30813493 8.88017642], weights: [0.24826855 0.26231003 0.48942141], train_wt_loss:  36.4817, val_wt_loss: 37.3332, train_grp_loss: [11.81027698 13.10866115 10.66604507], val_grp_loss: [12.70223192 12.49172718 12.13846227], train_hist_grp_loss: [ 5.3473974   5.89755853 12.13452619], cur_train_grp_loss: [0.09448476 0.10485819 0.21335017], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6779, max_kl_dist_index: 0, max_train_grp_loss:  13.1087, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7022, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2134, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:11:04,520 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  56, train_loss:  12.1608, val_loss:  12.4450, grad_norm: 0.0183, live_grad: 0.0000, reward_err: 0.0102, 0.0143, 0.0001, KL_dist: 0.6784, 0.3169, 0.6710, param: [5.46322946 8.22595832 5.31147739 8.88732637], weights: [0.24675753 0.26098449 0.49225798], train_wt_loss:  36.4823, val_wt_loss: 37.3349, train_grp_loss: [11.80994235 13.11008297 10.66457214], val_grp_loss: [12.70252382 12.49337518 12.13819405], train_hist_grp_loss: [ 5.44187962  6.00242782 12.34784709], cur_train_grp_loss: [0.09448222 0.10486929 0.2133209 ], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6784, max_kl_dist_index: 0, max_train_grp_loss:  13.1101, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7025, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2133, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:11:05,501 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  57, train_loss:  12.1610, val_loss:  12.4455, grad_norm: 0.0188, live_grad: 0.0000, reward_err: 0.0102, 0.0143, 0.0001, KL_dist: 0.6789, 0.3172, 0.6715, param: [5.46337331 8.22482994 5.31483468 8.8945412 ], weights: [0.245248   0.25965787 0.49509412], train_wt_loss:  36.4830, val_wt_loss: 37.3366, train_grp_loss: [11.80959141 13.11153911 10.66308975], val_grp_loss: [12.70280206 12.49506242 12.13792159], train_hist_grp_loss: [ 5.53635916  6.10730849 12.56113854], cur_train_grp_loss: [0.09447954 0.10488066 0.21329144], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6789, max_kl_dist_index: 0, max_train_grp_loss:  13.1115, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7028, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2133, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:11:06,498 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  58, train_loss:  12.1612, val_loss:  12.4461, grad_norm: 0.0193, live_grad: 0.0000, reward_err: 0.0102, 0.0143, 0.0001, KL_dist: 0.6794, 0.3175, 0.6720, param: [5.46350754 8.22370781 5.31820681 8.90182097], weights: [0.24374007 0.25833027 0.49792966], train_wt_loss:  36.4836, val_wt_loss: 37.3383, train_grp_loss: [11.80922432 13.1130296  10.66159797], val_grp_loss: [12.70306676 12.49678897 12.13764499], train_hist_grp_loss: [ 5.63083589  6.2122008  12.77440033], cur_train_grp_loss: [0.09447673 0.10489231 0.21326179], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6794, max_kl_dist_index: 0, max_train_grp_loss:  13.1130, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7031, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2133, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:11:07,477 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  59, train_loss:  12.1614, val_loss:  12.4467, grad_norm: 0.0198, live_grad: 0.0000, reward_err: 0.0102, 0.0143, 0.0001, KL_dist: 0.6799, 0.3178, 0.6725, param: [5.46363208 8.22259174 5.32159379 8.90916571], weights: [0.24223382 0.25700178 0.5007644 ], train_wt_loss:  36.4843, val_wt_loss: 37.3400, train_grp_loss: [11.80884124 13.11455448 10.66009688], val_grp_loss: [12.70331804 12.49855487 12.13736437], train_hist_grp_loss: [ 5.72530968  6.31710504 12.98763229], cur_train_grp_loss: [0.09447379 0.10490424 0.21323196], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6799, max_kl_dist_index: 0, max_train_grp_loss:  13.1146, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7033, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2132, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:11:08,469 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  60, train_loss:  12.1617, val_loss:  12.4473, grad_norm: 0.0203, live_grad: 0.0000, reward_err: 0.0102, 0.0143, 0.0001, KL_dist: 0.6804, 0.3180, 0.6730, param: [5.46374689 8.22148154 5.32499563 8.91657544], weights: [0.24072934 0.25567251 0.50359815], train_wt_loss:  36.4850, val_wt_loss: 37.3418, train_grp_loss: [11.80844234 13.11611378 10.65858659], val_grp_loss: [12.70355601 12.50036016 12.13707985], train_hist_grp_loss: [ 5.81978041  6.42202147 13.20083423], cur_train_grp_loss: [0.09447073 0.10491644 0.21320194], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6804, max_kl_dist_index: 0, max_train_grp_loss:  13.1161, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7036, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2132, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:11:09,481 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  61, train_loss:  12.1619, val_loss:  12.4478, grad_norm: 0.0208, live_grad: 0.0000, reward_err: 0.0102, 0.0143, 0.0001, KL_dist: 0.6809, 0.3183, 0.6736, param: [5.46385189 8.22037699 5.32841233 8.92405019], weights: [0.23922672 0.25434255 0.50643072], train_wt_loss:  36.4857, val_wt_loss: 37.3435, train_grp_loss: [11.80802779 13.11770752 10.65706717], val_grp_loss: [12.7037808  12.50220489 12.13679155], train_hist_grp_loss: [ 5.91424795  6.52695038 13.41400596], cur_train_grp_loss: [0.09446754 0.10492891 0.21317173], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6809, max_kl_dist_index: 0, max_train_grp_loss:  13.1177, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7038, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2132, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:11:10,488 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  62, train_loss:  12.1621, val_loss:  12.4484, grad_norm: 0.0214, live_grad: 0.0000, reward_err: 0.0102, 0.0143, 0.0001, KL_dist: 0.6814, 0.3186, 0.6741, param: [5.46394703 8.21927789 5.33184389 8.93158998], weights: [0.23772605 0.25301201 0.50926193], train_wt_loss:  36.4864, val_wt_loss: 37.3453, train_grp_loss: [11.80759777 13.11933574 10.65553872], val_grp_loss: [12.70399253 12.50408909 12.13649959], train_hist_grp_loss: [ 6.00871217  6.63189204 13.6271473 ], cur_train_grp_loss: [0.09446422 0.10494166 0.21314134], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6814, max_kl_dist_index: 0, max_train_grp_loss:  13.1193, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7040, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2131, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:11:11,484 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  63, train_loss:  12.1624, val_loss:  12.4491, grad_norm: 0.0219, live_grad: 0.0000, reward_err: 0.0102, 0.0143, 0.0001, KL_dist: 0.6819, 0.3189, 0.6746, param: [5.46403226 8.21818404 5.33529033 8.93919482], weights: [0.23622742 0.25168099 0.51209159], train_wt_loss:  36.4872, val_wt_loss: 37.3472, train_grp_loss: [11.80715243 13.12099845 10.65400133], val_grp_loss: [12.70419133 12.5060128  12.1362041 ], train_hist_grp_loss: [ 6.10317295  6.73684673 13.84025808], cur_train_grp_loss: [0.09446078 0.10495469 0.21311077], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6819, max_kl_dist_index: 0, max_train_grp_loss:  13.1210, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7042, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2131, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:11:12,467 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  64, train_loss:  12.1627, val_loss:  12.4497, grad_norm: 0.0224, live_grad: 0.0000, reward_err: 0.0104, 0.0143, 0.0002, KL_dist: 0.6824, 0.3191, 0.6751, param: [5.46410752 8.21709522 5.33875162 8.94686472], weights: [0.23473091 0.25034958 0.51491951], train_wt_loss:  36.4880, val_wt_loss: 37.3490, train_grp_loss: [11.80669197 13.12269568 10.65245511], val_grp_loss: [12.70437732 12.50797606 12.13590519], train_hist_grp_loss: [ 6.19763017  6.84181472 14.0533381 ], cur_train_grp_loss: [0.09445722 0.10496799 0.21308003], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6824, max_kl_dist_index: 0, max_train_grp_loss:  13.1227, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7044, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2131, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:11:13,464 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  65, train_loss:  12.1629, val_loss:  12.4503, grad_norm: 0.0230, live_grad: 0.0000, reward_err: 0.0104, 0.0143, 0.0002, KL_dist: 0.6830, 0.3194, 0.6757, param: [5.46417274 8.21601122 5.34222778 8.95459967], weights: [0.23323662 0.24901788 0.5177455 ], train_wt_loss:  36.4888, val_wt_loss: 37.3509, train_grp_loss: [11.80621655 13.12442745 10.65090014], val_grp_loss: [12.70455063 12.50997889 12.135603  ], train_hist_grp_loss: [ 6.29208371  6.94679628 14.26638721], cur_train_grp_loss: [0.09445354 0.10498157 0.2130491 ], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6830, max_kl_dist_index: 0, max_train_grp_loss:  13.1244, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7046, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2130, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:11:14,428 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  66, train_loss:  12.1632, val_loss:  12.4509, grad_norm: 0.0235, live_grad: 0.0000, reward_err: 0.0104, 0.0143, 0.0002, KL_dist: 0.6835, 0.3197, 0.6762, param: [5.46422788 8.21493183 5.34571879 8.96239967], weights: [0.23174462 0.247686   0.52056938], train_wt_loss:  36.4896, val_wt_loss: 37.3528, train_grp_loss: [11.80572637 13.12619376 10.64933653], val_grp_loss: [12.7047114  12.51202134 12.13529765], train_hist_grp_loss: [ 6.38653344  7.0517917  14.47940521], cur_train_grp_loss: [0.09444973 0.10499542 0.213018  ], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6835, max_kl_dist_index: 0, max_train_grp_loss:  13.1262, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7047, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2130, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:11:15,398 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  67, train_loss:  12.1635, val_loss:  12.4516, grad_norm: 0.0241, live_grad: 0.0000, reward_err: 0.0104, 0.0143, 0.0002, KL_dist: 0.6840, 0.3200, 0.6767, param: [5.46427288 8.21385684 5.34922463 8.97026471], weights: [0.23025501 0.24635403 0.52339096], train_wt_loss:  36.4904, val_wt_loss: 37.3547, train_grp_loss: [11.80522161 13.12799465 10.64776439], val_grp_loss: [12.70485975 12.51410341 12.13498927], train_hist_grp_loss: [ 6.48097925  7.15680125 14.69239194], cur_train_grp_loss: [0.09444581 0.10500955 0.21298673], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6840, max_kl_dist_index: 0, max_train_grp_loss:  13.1280, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7049, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2130, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:11:16,403 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  68, train_loss:  12.1638, val_loss:  12.4522, grad_norm: 0.0246, live_grad: 0.0000, reward_err: 0.0104, 0.0143, 0.0002, KL_dist: 0.6846, 0.3203, 0.6773, param: [5.46430767 8.21278602 5.35274531 8.97819477], weights: [0.22876788 0.24502207 0.52621006], train_wt_loss:  36.4913, val_wt_loss: 37.3567, train_grp_loss: [11.80470246 13.1298301  10.64618381], val_grp_loss: [12.70499582 12.51622515 12.134678  ], train_hist_grp_loss: [ 6.57542103  7.26182521 14.90534723], cur_train_grp_loss: [0.09444177 0.10502396 0.21295529], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6846, max_kl_dist_index: 0, max_train_grp_loss:  13.1298, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7050, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2130, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:11:17,414 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  69, train_loss:  12.1640, val_loss:  12.4529, grad_norm: 0.0252, live_grad: 0.0000, reward_err: 0.0104, 0.0143, 0.0002, KL_dist: 0.6851, 0.3206, 0.6779, param: [5.46433222 8.21171916 5.3562808  8.98618982], weights: [0.2272833  0.24369021 0.52902649], train_wt_loss:  36.4921, val_wt_loss: 37.3586, train_grp_loss: [11.8041691  13.13170015 10.6445949 ], val_grp_loss: [12.70511974 12.51838656 12.13436396], train_hist_grp_loss: [ 6.66985865  7.36686385 15.1182709 ], cur_train_grp_loss: [0.09443762 0.10503864 0.21292368], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6851, max_kl_dist_index: 0, max_train_grp_loss:  13.1317, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7051, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2129, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:11:18,417 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  70, train_loss:  12.1643, val_loss:  12.4535, grad_norm: 0.0258, live_grad: 0.0000, reward_err: 0.0104, 0.0143, 0.0002, KL_dist: 0.6856, 0.3209, 0.6784, param: [5.46434645 8.21065603 5.35983108 8.99424982], weights: [0.22580137 0.24235856 0.53184007], train_wt_loss:  36.4930, val_wt_loss: 37.3606, train_grp_loss: [11.80362174 13.13360478 10.64299777], val_grp_loss: [12.70523166 12.52058767 12.13404728], train_hist_grp_loss: [ 6.764292    7.47191745 15.3311628 ], cur_train_grp_loss: [0.09443335 0.1050536  0.2128919 ], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6856, max_kl_dist_index: 0, max_train_grp_loss:  13.1336, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7052, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2129, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:11:19,424 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  71, train_loss:  12.1647, val_loss:  12.4542, grad_norm: 0.0263, live_grad: 0.0000, reward_err: 0.0104, 0.0143, 0.0002, KL_dist: 0.6862, 0.3212, 0.6790, param: [5.46435033 8.20959641 5.36339613 9.00237475], weights: [0.22432217 0.24102721 0.53465062], train_wt_loss:  36.4940, val_wt_loss: 37.3626, train_grp_loss: [11.80306056 13.13554401 10.64139253], val_grp_loss: [12.7053317 12.5228285 12.1337281], train_hist_grp_loss: [ 6.85872097  7.57698629 15.54402276], cur_train_grp_loss: [0.09442897 0.10506884 0.21285996], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6862, max_kl_dist_index: 0, max_train_grp_loss:  13.1355, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7053, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2129, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:11:20,401 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  72, train_loss:  12.1650, val_loss:  12.4549, grad_norm: 0.0269, live_grad: 0.0000, reward_err: 0.0104, 0.0143, 0.0002, KL_dist: 0.6867, 0.3215, 0.6795, param: [5.46434378 8.20854007 5.36697593 9.01056456], weights: [0.22284579 0.23969626 0.53745795], train_wt_loss:  36.4949, val_wt_loss: 37.3647, train_grp_loss: [11.80248576 13.13751783 10.63977929], val_grp_loss: [12.70542002 12.52510905 12.13340655], train_hist_grp_loss: [ 6.95314546  7.68207064 15.75685061], cur_train_grp_loss: [0.09442448 0.10508435 0.21282785], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6867, max_kl_dist_index: 0, max_train_grp_loss:  13.1375, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7054, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2128, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:11:21,400 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  73, train_loss:  12.1653, val_loss:  12.4556, grad_norm: 0.0275, live_grad: 0.0000, reward_err: 0.0104, 0.0143, 0.0002, KL_dist: 0.6873, 0.3218, 0.6801, param: [5.46432677 8.20748678 5.37057045 9.01881919], weights: [0.22137231 0.2383658  0.54026189], train_wt_loss:  36.4959, val_wt_loss: 37.3668, train_grp_loss: [11.80189755 13.13952624 10.63815817], val_grp_loss: [12.70549675 12.52742933 12.13308278], train_hist_grp_loss: [ 7.04756534  7.78717078 15.96964619], cur_train_grp_loss: [0.09441989 0.10510014 0.21279559], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6873, max_kl_dist_index: 0, max_train_grp_loss:  13.1395, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7055, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2128, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:11:22,397 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  74, train_loss:  12.1656, val_loss:  12.4563, grad_norm: 0.0281, live_grad: 0.0000, reward_err: 0.0104, 0.0143, 0.0002, KL_dist: 0.6878, 0.3221, 0.6807, param: [5.46429924 8.20643632 5.37417966 9.02713858], weights: [0.2199018  0.23703593 0.54306226], train_wt_loss:  36.4968, val_wt_loss: 37.3689, train_grp_loss: [11.80129613 13.14156924 10.63652928], val_grp_loss: [12.70556203 12.52978936 12.13275691], train_hist_grp_loss: [ 7.14198052  7.89228699 16.18240936], cur_train_grp_loss: [0.09441518 0.10511621 0.21276316], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6878, max_kl_dist_index: 0, max_train_grp_loss:  13.1416, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7056, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2128, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:11:23,380 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  75, train_loss:  12.1660, val_loss:  12.4570, grad_norm: 0.0287, live_grad: 0.0000, reward_err: 0.0104, 0.0143, 0.0002, KL_dist: 0.6884, 0.3224, 0.6813, param: [5.46426113 8.20538844 5.37780353 9.03552267], weights: [0.21843437 0.23570675 0.54585888], train_wt_loss:  36.4979, val_wt_loss: 37.3710, train_grp_loss: [11.8006817  13.14364682 10.63489274], val_grp_loss: [12.70561602 12.53218913 12.13242909], train_hist_grp_loss: [ 7.23639089  7.99741955 16.39513994], cur_train_grp_loss: [0.09441037 0.10513255 0.21273059], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6884, max_kl_dist_index: 0, max_train_grp_loss:  13.1436, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7056, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2127, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:11:24,388 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  76, train_loss:  12.1663, val_loss:  12.4577, grad_norm: 0.0293, live_grad: 0.0000, reward_err: 0.0102, 0.0143, 0.0001, KL_dist: 0.6890, 0.3227, 0.6819, param: [5.4642124  8.20434292 5.38144201 9.0439714 ], weights: [0.21697008 0.23437835 0.54865158], train_wt_loss:  36.4989, val_wt_loss: 37.3731, train_grp_loss: [11.80005447 13.14575896 10.63324867], val_grp_loss: [12.70565885 12.53462865 12.13209946], train_hist_grp_loss: [ 7.33079635  8.10256872 16.6078378 ], cur_train_grp_loss: [0.09440545 0.10514917 0.21269785], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6890, max_kl_dist_index: 0, max_train_grp_loss:  13.1458, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7057, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2127, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:11:25,366 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  77, train_loss:  12.1666, val_loss:  12.4584, grad_norm: 0.0300, live_grad: 0.0000, reward_err: 0.0102, 0.0143, 0.0001, KL_dist: 0.6895, 0.3230, 0.6825, param: [5.46415299 8.20329952 5.38509508 9.05248467], weights: [0.21550901 0.23305082 0.55144017], train_wt_loss:  36.4999, val_wt_loss: 37.3753, train_grp_loss: [11.79941466 13.14790566 10.63159718], val_grp_loss: [12.70569068 12.53710791 12.13176815], train_hist_grp_loss: [ 7.42519678  8.20773479 16.82050277], cur_train_grp_loss: [0.09440044 0.10516607 0.21266497], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6895, max_kl_dist_index: 0, max_train_grp_loss:  13.1479, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7057, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2127, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:11:26,369 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  78, train_loss:  12.1670, val_loss:  12.4592, grad_norm: 0.0306, live_grad: 0.0000, reward_err: 0.0102, 0.0143, 0.0001, KL_dist: 0.6901, 0.3233, 0.6831, param: [5.46408287 8.20225801 5.38876268 9.06106241], weights: [0.21405126 0.23172426 0.55422448], train_wt_loss:  36.5010, val_wt_loss: 37.3775, train_grp_loss: [11.79876246 13.15008689 10.62993841], val_grp_loss: [12.70571166 12.53962691 12.13143532], train_hist_grp_loss: [ 7.5195921   8.31291804 17.03313471], cur_train_grp_loss: [0.09439532 0.10518325 0.21263194], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6901, max_kl_dist_index: 0, max_train_grp_loss:  13.1501, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7057, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2126, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:11:27,375 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  79, train_loss:  12.1674, val_loss:  12.4599, grad_norm: 0.0312, live_grad: 0.0000, reward_err: 0.0102, 0.0143, 0.0001, KL_dist: 0.6907, 0.3237, 0.6837, param: [5.46400196 8.20121813 5.39244478 9.06970451], weights: [0.2125969  0.23039876 0.55700434], train_wt_loss:  36.5021, val_wt_loss: 37.3797, train_grp_loss: [11.79809811 13.15230263 10.62827247], val_grp_loss: [12.70572193 12.54218564 12.13110109], train_hist_grp_loss: [ 7.6139822   8.41811873 17.24573348], cur_train_grp_loss: [0.0943901  0.1052007  0.21259877], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6907, max_kl_dist_index: 0, max_train_grp_loss:  13.1523, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7057, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2126, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:11:28,377 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  80, train_loss:  12.1678, val_loss:  12.4607, grad_norm: 0.0319, live_grad: 0.0000, reward_err: 0.0102, 0.0143, 0.0001, KL_dist: 0.6913, 0.3240, 0.6843, param: [5.46391024 8.20017966 5.39614133 9.07841089], weights: [0.21114601 0.22907442 0.55977957], train_wt_loss:  36.5033, val_wt_loss: 37.3820, train_grp_loss: [11.79742181 13.15455286 10.6265995 ], val_grp_loss: [12.70572166 12.54478409 12.13076562], train_hist_grp_loss: [ 7.70836698  8.52333715 17.45829893], cur_train_grp_loss: [0.09438478 0.10521842 0.21256545], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6913, max_kl_dist_index: 0, max_train_grp_loss:  13.1546, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7057, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2126, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:11:29,362 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  81, train_loss:  12.1681, val_loss:  12.4614, grad_norm: 0.0325, live_grad: 0.0000, reward_err: 0.0100, 0.0143, 0.0001, KL_dist: 0.6919, 0.3243, 0.6849, param: [5.46380765 8.19914234 5.39985227 9.08718144], weights: [0.20969867 0.22775132 0.56255002], train_wt_loss:  36.5044, val_wt_loss: 37.3843, train_grp_loss: [11.79673379 13.15683756 10.62491961], val_grp_loss: [12.70571098 12.54742224 12.13042905], train_hist_grp_loss: [ 7.80274636  8.62857358 17.67083092], cur_train_grp_loss: [0.09437937 0.10523642 0.21253199], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6919, max_kl_dist_index: 0, max_train_grp_loss:  13.1568, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7057, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2125, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:11:30,360 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  82, train_loss:  12.1685, val_loss:  12.4622, grad_norm: 0.0332, live_grad: 0.0000, reward_err: 0.0100, 0.0143, 0.0001, KL_dist: 0.6925, 0.3246, 0.6855, param: [5.46369415 8.19810593 5.40357755 9.09601604], weights: [0.20825495 0.22642955 0.56531549], train_wt_loss:  36.5056, val_wt_loss: 37.3866, train_grp_loss: [11.79603427 13.1591567  10.62323295], val_grp_loss: [12.70569006 12.55010007 12.13009153], train_hist_grp_loss: [ 7.89712023  8.73382828 17.88332931], cur_train_grp_loss: [0.09437387 0.1052547  0.21249839], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6925, max_kl_dist_index: 0, max_train_grp_loss:  13.1592, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7057, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2125, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:11:31,359 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  83, train_loss:  12.1689, val_loss:  12.4630, grad_norm: 0.0338, live_grad: 0.0000, reward_err: 0.0100, 0.0143, 0.0001, KL_dist: 0.6930, 0.3250, 0.6861, param: [5.46356968 8.19707018 5.40731711 9.10491458], weights: [0.20681494 0.22510922 0.56807584], train_wt_loss:  36.5068, val_wt_loss: 37.3890, train_grp_loss: [11.79532347 13.16151024 10.62153964], val_grp_loss: [12.70565905 12.55281756 12.1297532 ], train_hist_grp_loss: [ 7.9914885   8.83910153 18.09579397], cur_train_grp_loss: [0.09436827 0.10527325 0.21246466], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6930, max_kl_dist_index: 0, max_train_grp_loss:  13.1615, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7057, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2125, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:11:32,331 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  84, train_loss:  12.1693, val_loss:  12.4638, grad_norm: 0.0345, live_grad: 0.0000, reward_err: 0.0100, 0.0143, 0.0001, KL_dist: 0.6936, 0.3253, 0.6867, param: [5.46343422 8.19603485 5.4110709  9.11387692], weights: [0.20537871 0.2237904  0.57083089], train_wt_loss:  36.5080, val_wt_loss: 37.3913, train_grp_loss: [11.79460161 13.16389814 10.61983981], val_grp_loss: [12.70561812 12.55557469 12.12941421], train_hist_grp_loss: [ 8.08585109  8.94439361 18.30822477], cur_train_grp_loss: [0.09436259 0.10529208 0.21243079], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6936, max_kl_dist_index: 0, max_train_grp_loss:  13.1639, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7056, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2124, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:11:33,323 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  85, train_loss:  12.1698, val_loss:  12.4646, grad_norm: 0.0352, live_grad: 0.0000, reward_err: 0.0100, 0.0143, 0.0001, KL_dist: 0.6942, 0.3256, 0.6874, param: [5.4632877  8.19499968 5.41483884 9.12290293], weights: [0.20394633 0.22247319 0.57358048], train_wt_loss:  36.5093, val_wt_loss: 37.3937, train_grp_loss: [11.79386893 13.16632037 10.61813361], val_grp_loss: [12.70556741 12.55837143 12.12907471], train_hist_grp_loss: [ 8.1802079   9.0497048  18.52062156], cur_train_grp_loss: [0.09435681 0.10531119 0.2123968 ], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6942, max_kl_dist_index: 0, max_train_grp_loss:  13.1663, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7056, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2124, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:11:34,314 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  86, train_loss:  12.1702, val_loss:  12.4654, grad_norm: 0.0359, live_grad: 0.0000, reward_err: 0.0100, 0.0143, 0.0001, KL_dist: 0.6949, 0.3259, 0.6880, param: [5.4631301  8.19396443 5.41862088 9.13199247], weights: [0.20251789 0.22115767 0.57632444], train_wt_loss:  36.5106, val_wt_loss: 37.3962, train_grp_loss: [11.79312565 13.16877689 10.61642115], val_grp_loss: [12.70550709 12.56120774 12.12873484], train_hist_grp_loss: [ 8.27455885  9.15503536 18.73298423], cur_train_grp_loss: [0.09435095 0.10533056 0.21236267], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6949, max_kl_dist_index: 0, max_train_grp_loss:  13.1688, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7055, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2124, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:11:35,324 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  87, train_loss:  12.1706, val_loss:  12.4662, grad_norm: 0.0365, live_grad: 0.0000, reward_err: 0.0100, 0.0143, 0.0001, KL_dist: 0.6955, 0.3263, 0.6886, param: [5.46296137 8.19292884 5.42241694 9.1411454 ], weights: [0.20109345 0.21984393 0.57906261], train_wt_loss:  36.5119, val_wt_loss: 37.3986, train_grp_loss: [11.792372   13.17126765 10.61470259], val_grp_loss: [12.70543732 12.5640836  12.12839476], train_hist_grp_loss: [ 8.36890386  9.26038558 18.94531266], cur_train_grp_loss: [0.09434501 0.10535022 0.21232842], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6955, max_kl_dist_index: 0, max_train_grp_loss:  13.1713, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7054, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2123, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:11:36,352 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  88, train_loss:  12.1711, val_loss:  12.4670, grad_norm: 0.0372, live_grad: 0.0000, reward_err: 0.0100, 0.0143, 0.0001, KL_dist: 0.6961, 0.3266, 0.6893, param: [5.46278146 8.19189265 5.42622696 9.15036155], weights: [0.19967309 0.21853207 0.58179484], train_wt_loss:  36.5132, val_wt_loss: 37.4011, train_grp_loss: [11.79160822 13.17379259 10.61297807], val_grp_loss: [12.70535826 12.56699895 12.12805461], train_hist_grp_loss: [ 8.46324284  9.36575572 19.15760671], cur_train_grp_loss: [0.09433898 0.10537014 0.21229405], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6961, max_kl_dist_index: 0, max_train_grp_loss:  13.1738, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7054, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2123, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:11:37,364 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  89, train_loss:  12.1715, val_loss:  12.4679, grad_norm: 0.0379, live_grad: 0.0000, reward_err: 0.0100, 0.0143, 0.0001, KL_dist: 0.6967, 0.3269, 0.6899, param: [5.46259035 8.19085561 5.43005084 9.15964077], weights: [0.19825688 0.21722216 0.58452096], train_wt_loss:  36.5146, val_wt_loss: 37.4037, train_grp_loss: [11.79083455 13.17635168 10.61124771], val_grp_loss: [12.70527008 12.56995377 12.12771455], train_hist_grp_loss: [ 8.5575757   9.47114606 19.36986627], cur_train_grp_loss: [0.09433287 0.10539034 0.21225956], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6967, max_kl_dist_index: 0, max_train_grp_loss:  13.1764, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7053, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2123, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:11:38,357 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  90, train_loss:  12.1720, val_loss:  12.4687, grad_norm: 0.0386, live_grad: 0.0000, reward_err: 0.0100, 0.0143, 0.0001, KL_dist: 0.6973, 0.3273, 0.6906, param: [5.46238799 8.18981746 5.43388852 9.16898288], weights: [0.1968449  0.21591429 0.58724081], train_wt_loss:  36.5160, val_wt_loss: 37.4062, train_grp_loss: [11.79005121 13.17894484 10.60951167], val_grp_loss: [12.70517293 12.57294799 12.12737473], train_hist_grp_loss: [ 8.65190238  9.57655687 19.58209123], cur_train_grp_loss: [0.09432668 0.10541081 0.21222495], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6973, max_kl_dist_index: 0, max_train_grp_loss:  13.1789, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7052, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2122, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:11:39,358 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  91, train_loss:  12.1725, val_loss:  12.4696, grad_norm: 0.0394, live_grad: 0.0000, reward_err: 0.0100, 0.0143, 0.0001, KL_dist: 0.6979, 0.3276, 0.6912, param: [5.46217434 8.18877794 5.43773992 9.17838771], weights: [0.1954372  0.21460855 0.58995424], train_wt_loss:  36.5174, val_wt_loss: 37.4088, train_grp_loss: [11.78925846 13.18157203 10.60777009], val_grp_loss: [12.70506699 12.57598158 12.12703529], train_hist_grp_loss: [ 8.74622279  9.68198843 19.79428146], cur_train_grp_loss: [0.09432041 0.10543156 0.21219023], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6979, max_kl_dist_index: 0, max_train_grp_loss:  13.1816, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7051, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2122, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:11:40,343 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  92, train_loss:  12.1730, val_loss:  12.4705, grad_norm: 0.0401, live_grad: 0.0000, reward_err: 0.0100, 0.0143, 0.0001, KL_dist: 0.6986, 0.3280, 0.6919, param: [5.46194937 8.18773679 5.44160494 9.18785507], weights: [0.19403387 0.21330502 0.59266111], train_wt_loss:  36.5189, val_wt_loss: 37.4114, train_grp_loss: [11.78845652 13.18423318 10.60602311], val_grp_loss: [12.70495241 12.57905448 12.1266964 ], train_hist_grp_loss: [ 8.84053686  9.78744101 20.00643686], cur_train_grp_loss: [0.09431407 0.10545258 0.2121554 ], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6986, max_kl_dist_index: 0, max_train_grp_loss:  13.1842, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7050, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2122, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:11:41,354 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  93, train_loss:  12.1735, val_loss:  12.4714, grad_norm: 0.0408, live_grad: 0.0000, reward_err: 0.0100, 0.0143, 0.0001, KL_dist: 0.6992, 0.3283, 0.6925, param: [5.46171304 8.18669375 5.4454835  9.19738478], weights: [0.19263497 0.21200378 0.59536124], train_wt_loss:  36.5204, val_wt_loss: 37.4141, train_grp_loss: [11.78764564 13.18692823 10.60427088], val_grp_loss: [12.70482937 12.58216663 12.12635819], train_hist_grp_loss: [ 8.93484451  9.89291487 20.21855732], cur_train_grp_loss: [0.09430765 0.10547387 0.21212046], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6992, max_kl_dist_index: 0, max_train_grp_loss:  13.1869, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7048, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2121, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:11:42,369 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  94, train_loss:  12.1740, val_loss:  12.4722, grad_norm: 0.0416, live_grad: 0.0000, reward_err: 0.0098, 0.0143, 0.0001, KL_dist: 0.6998, 0.3287, 0.6932, param: [5.46146533 8.18564856 5.44937551 9.20697663], weights: [0.19124058 0.21070492 0.59805451], train_wt_loss:  36.5219, val_wt_loss: 37.4167, train_grp_loss: [11.78682606 13.18965709 10.60251354], val_grp_loss: [12.70469804 12.58531797 12.12602083], train_hist_grp_loss: [ 9.02914567  9.9984103  20.43064274], cur_train_grp_loss: [0.09430117 0.10549543 0.21208542], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.6998, max_kl_dist_index: 0, max_train_grp_loss:  13.1897, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7047, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2121, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:11:43,385 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  95, train_loss:  12.1745, val_loss:  12.4731, grad_norm: 0.0423, live_grad: 0.0000, reward_err: 0.0098, 0.0143, 0.0001, KL_dist: 0.7005, 0.3290, 0.6939, param: [5.46120619 8.18460095 5.45328086 9.21663043], weights: [0.18985074 0.20940851 0.60074075], train_wt_loss:  36.5234, val_wt_loss: 37.4194, train_grp_loss: [11.78599803 13.19241971 10.60075125], val_grp_loss: [12.70455857 12.58850844 12.12568447], train_hist_grp_loss: [ 9.12344028 10.10392755 20.64269301], cur_train_grp_loss: [0.09429461 0.10551726 0.21205027], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.7005, max_kl_dist_index: 0, max_train_grp_loss:  13.1924, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7046, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2121, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:11:44,399 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  96, train_loss:  12.1750, val_loss:  12.4741, grad_norm: 0.0430, live_grad: 0.0000, reward_err: 0.0098, 0.0143, 0.0001, KL_dist: 0.7011, 0.3294, 0.6946, param: [5.46093561 8.18355066 5.45719947 9.22634595], weights: [0.18846554 0.20811464 0.60341982], train_wt_loss:  36.5250, val_wt_loss: 37.4222, train_grp_loss: [11.78516179 13.19521601 10.59898415], val_grp_loss: [12.70441114 12.59173796 12.12534926], train_hist_grp_loss: [ 9.21772827 10.20946691 20.85470804], cur_train_grp_loss: [0.09428798 0.10553936 0.21201502], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.7011, max_kl_dist_index: 0, max_train_grp_loss:  13.1952, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7044, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2120, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:11:45,379 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  97, train_loss:  12.1755, val_loss:  12.4750, grad_norm: 0.0438, live_grad: 0.0000, reward_err: 0.0098, 0.0143, 0.0001, KL_dist: 0.7018, 0.3297, 0.6952, param: [5.46065354 8.18249742 5.46113124 9.23612297], weights: [0.18708504 0.20682338 0.60609158], train_wt_loss:  36.5266, val_wt_loss: 37.4250, train_grp_loss: [11.78431759 13.1980459  10.5972124 ], val_grp_loss: [12.70425592 12.59500648 12.12501536], train_hist_grp_loss: [ 9.31200956 10.31502864 21.06668772], cur_train_grp_loss: [0.09428129 0.10556173 0.21197968], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.7018, max_kl_dist_index: 0, max_train_grp_loss:  13.1980, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7043, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2120, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:11:46,408 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  98, train_loss:  12.1761, val_loss:  12.4759, grad_norm: 0.0446, live_grad: 0.0000, reward_err: 0.0097, 0.0143, 0.0001, KL_dist: 0.7024, 0.3301, 0.6959, param: [5.46035996 8.18144097 5.46507605 9.24596128], weights: [0.1857093  0.20553482 0.60875588], train_wt_loss:  36.5282, val_wt_loss: 37.4278, train_grp_loss: [11.78346568 13.2009093  10.59543614], val_grp_loss: [12.70409308 12.5983139  12.12468291], train_hist_grp_loss: [ 9.4062841  10.42061301 21.27863197], cur_train_grp_loss: [0.09427454 0.10558437 0.21194425], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.7024, max_kl_dist_index: 0, max_train_grp_loss:  13.2009, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7041, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2119, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:11:47,402 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  99, train_loss:  12.1766, val_loss:  12.4769, grad_norm: 0.0453, live_grad: 0.0000, reward_err: 0.0097, 0.0143, 0.0001, KL_dist: 0.7031, 0.3304, 0.6966, param: [5.46005485 8.18038103 5.4690338  9.25586064], weights: [0.18433838 0.20424903 0.61141259], train_wt_loss:  36.5298, val_wt_loss: 37.4306, train_grp_loss: [11.78260631 13.20380612 10.59365554], val_grp_loss: [12.70392279 12.60166015 12.12435207], train_hist_grp_loss: [ 9.50055183 10.52622028 21.49054069], cur_train_grp_loss: [0.09426773 0.10560727 0.21190872], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.7031, max_kl_dist_index: 0, max_train_grp_loss:  13.2038, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7039, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2119, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:11:48,312 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1654] - INFO: Iteration:  99, train_loss:  12.1766, val_loss:  12.4769, grad_norm: 0.0453,  live_grad: 0.0000, reward_err: 0.0097, 0.0143, 0.0001, KL_dist: 0.7031, 0.3304, 0.6966, param: [5.46005485 8.18038103 5.4690338  9.25586064], weights: [0.18433838 0.20424903 0.61141259], train_wt_loss:  36.5298, val_wt_loss: 37.4306, train_grp_loss: [11.78260631 13.20380612 10.59365554], val_grp_loss: [12.70392279 12.60166015 12.12435207], train_hist_grp_loss: [ 9.50055183 10.52622028 21.49054069], cur_train_grp_loss: [0.09426773 0.10560727 0.21190872], max_reward_err:  0.0143, max_reward_err_index: 1, max_kl_dist:  0.7031, max_kl_dist_index: 0, max_train_grp_loss:  13.2038, max_train_grp_loss_index: 1, max_val_grp_loss:  12.7039, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2119, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:11:48,533 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:388] - INFO: Policy parameter learned solely on the preference data rdpo: [5.46005485 8.18038103 5.4690338  9.25586064].
2024-10-07 17:11:48,873 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Uniform reward: 3.8318, 3.8318, 3.1647
2024-10-07 17:11:48,874 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Optimal reward: 3.8678, 7.2446, 3.2763
2024-10-07 17:11:48,874 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Policy reward: 3.8304, 7.1412, 3.2758
2024-10-07 17:11:48,875 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:402] - INFO: Reward Error: 0.0097, 0.0143, 0.0001
2024-10-07 17:11:49,559 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:417] - INFO: Optimal reward: 3.8678, 7.2446, 3.2763
Known param reward: [[3.867779541015625, 6.77779443359375, 3.255072021484375], [3.441058349609375, 7.24455908203125, 3.05710986328125], [3.841189453125, 7.1339345703125, 3.27631982421875]], Known param reward error: [[0.0, 0.06442968345654335, 0.0064852651372159075], [0.11032717529039895, 0.0, 0.06690737556116683], [0.006874768225192712, 0.015270013049259644, 0.0]].
