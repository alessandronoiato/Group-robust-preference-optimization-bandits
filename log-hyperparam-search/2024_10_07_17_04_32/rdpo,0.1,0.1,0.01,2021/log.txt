2024-10-07 17:04:36,226 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log-hyperparam-search/2024_10_07_17_04_32/rdpo,0.1,0.1,0.01,2021
2024-10-07 17:04:36,228 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2021
2024-10-07 17:04:36,228 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-10-07 17:04:36,324 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.2351, l2 distance: 36.4442, acc: 0.90.
2024-10-07 17:04:36,325 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-10-07 17:04:36,326 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [ 9.05939251 17.1373287   9.50347978 12.39752865]
2024-10-07 17:04:36,539 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.8285, 7.1348, 3.2752
2024-10-07 17:04:36,766 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1314] - INFO: unique_group_ids: {0, 1, 2}
2024-10-07 17:04:38,136 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  0, train_loss:  12.1558, val_loss:  12.4221, grad_norm: 0.4595, live_grad: 0.0000, reward_err: 0.0104, 0.0142, 0.0002, KL_dist: 0.6567, 0.3051, 0.6499, param: [5.44259977 8.3001452  5.14403995 8.57240352], weights: [0.33311103 0.33307246 0.33381651], train_wt_loss:  36.4675, val_wt_loss: 37.2662, train_grp_loss: [11.80518823 13.07539799 10.73345362], val_grp_loss: [12.66677114 12.45251341 12.1461785 ], train_hist_grp_loss: [0.15100158 0.13942111 0.36256349], cur_train_grp_loss: [0.15100158 0.13942111 0.36256349], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6567, max_kl_dist_index: 0, max_train_grp_loss:  13.0754, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6668, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.3626, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:04:39,199 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  1, train_loss:  12.1558, val_loss:  12.4221, grad_norm: 0.0000, live_grad: 0.0000, reward_err: 0.0104, 0.0142, 0.0002, KL_dist: 0.6568, 0.3051, 0.6499, param: [5.4426591  8.29997348 5.14429669 8.57277289], weights: [0.33296605 0.33296132 0.33407263], train_wt_loss:  36.4675, val_wt_loss: 37.2663, train_grp_loss: [11.80526187 13.07535895 10.73336732], val_grp_loss: [12.66688807 12.45247172 12.14618837], train_hist_grp_loss: [0.24544308 0.24402429 0.57723256], cur_train_grp_loss: [0.09444151 0.10460318 0.21466907], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6568, max_kl_dist_index: 0, max_train_grp_loss:  13.0754, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6669, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2147, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:04:40,281 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  2, train_loss:  12.1558, val_loss:  12.4221, grad_norm: 0.0000, live_grad: 0.0000, reward_err: 0.0104, 0.0142, 0.0002, KL_dist: 0.6568, 0.3052, 0.6499, param: [5.44271836 8.29980191 5.14455354 8.57314282], weights: [0.33282103 0.33285013 0.33432884], train_wt_loss:  36.4675, val_wt_loss: 37.2664, train_grp_loss: [11.80533531 13.07532022 10.73328091], val_grp_loss: [12.66700482 12.45243037 12.14619816], train_hist_grp_loss: [0.33988518 0.34862716 0.79189991], cur_train_grp_loss: [0.09444209 0.10460287 0.21466735], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6568, max_kl_dist_index: 0, max_train_grp_loss:  13.0753, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6670, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2147, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:04:41,348 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  3, train_loss:  12.1558, val_loss:  12.4222, grad_norm: 0.0001, live_grad: 0.0000, reward_err: 0.0104, 0.0142, 0.0002, KL_dist: 0.6568, 0.3052, 0.6499, param: [5.44277756 8.29963047 5.1448105  8.57351329], weights: [0.33267599 0.33273887 0.33458514], train_wt_loss:  36.4675, val_wt_loss: 37.2665, train_grp_loss: [11.80540854 13.07528178 10.73319439], val_grp_loss: [12.66712141 12.45238937 12.14620786], train_hist_grp_loss: [0.43432786 0.45322973 1.00656552], cur_train_grp_loss: [0.09444268 0.10460256 0.21466562], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6568, max_kl_dist_index: 0, max_train_grp_loss:  13.0753, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6671, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2147, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:04:42,455 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  4, train_loss:  12.1558, val_loss:  12.4222, grad_norm: 0.0001, live_grad: 0.0000, reward_err: 0.0104, 0.0142, 0.0002, KL_dist: 0.6568, 0.3052, 0.6500, param: [5.4428367  8.29945917 5.14506757 8.57388432], weights: [0.33253091 0.33262756 0.33484154], train_wt_loss:  36.4675, val_wt_loss: 37.2665, train_grp_loss: [11.80548156 13.07524364 10.73310776], val_grp_loss: [12.66723782 12.4523487  12.14621749], train_hist_grp_loss: [0.52877113 0.55783198 1.22122941], cur_train_grp_loss: [0.09444327 0.10460225 0.21466389], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6568, max_kl_dist_index: 0, max_train_grp_loss:  13.0752, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6672, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2147, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:04:43,561 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  5, train_loss:  12.1558, val_loss:  12.4222, grad_norm: 0.0001, live_grad: 0.0000, reward_err: 0.0104, 0.0142, 0.0002, KL_dist: 0.6569, 0.3052, 0.6500, param: [5.44289577 8.29928801 5.14532476 8.57425589], weights: [0.3323858  0.33251618 0.33509802], train_wt_loss:  36.4675, val_wt_loss: 37.2666, train_grp_loss: [11.80555438 13.0752058  10.73302102], val_grp_loss: [12.66735406 12.45230837 12.14622704], train_hist_grp_loss: [0.62321498 0.66243393 1.43589157], cur_train_grp_loss: [0.09444385 0.10460195 0.21466216], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6569, max_kl_dist_index: 0, max_train_grp_loss:  13.0752, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6674, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2147, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:04:44,689 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  6, train_loss:  12.1558, val_loss:  12.4222, grad_norm: 0.0001, live_grad: 0.0000, reward_err: 0.0104, 0.0142, 0.0002, KL_dist: 0.6569, 0.3052, 0.6500, param: [5.44295477 8.29911699 5.14558205 8.57462802], weights: [0.33224065 0.33240474 0.3353546 ], train_wt_loss:  36.4675, val_wt_loss: 37.2667, train_grp_loss: [11.80562698 13.07516825 10.73293417], val_grp_loss: [12.66747013 12.45226838 12.1462365 ], train_hist_grp_loss: [0.71765942 0.76703557 1.65055199], cur_train_grp_loss: [0.09444444 0.10460165 0.21466042], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6569, max_kl_dist_index: 0, max_train_grp_loss:  13.0752, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6675, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2147, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:04:45,773 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  7, train_loss:  12.1558, val_loss:  12.4223, grad_norm: 0.0001, live_grad: 0.0000, reward_err: 0.0104, 0.0142, 0.0002, KL_dist: 0.6569, 0.3052, 0.6500, param: [5.44301371 8.2989461  5.14583946 8.5750007 ], weights: [0.33209548 0.33229324 0.33561128], train_wt_loss:  36.4675, val_wt_loss: 37.2668, train_grp_loss: [11.80569938 13.07513101 10.73284721], val_grp_loss: [12.66758603 12.45222873 12.14624589], train_hist_grp_loss: [0.81210443 0.87163692 1.86521067], cur_train_grp_loss: [0.09444502 0.10460135 0.21465868], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6569, max_kl_dist_index: 0, max_train_grp_loss:  13.0751, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6676, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2147, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:04:46,862 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  8, train_loss:  12.1558, val_loss:  12.4223, grad_norm: 0.0002, live_grad: 0.0000, reward_err: 0.0104, 0.0142, 0.0002, KL_dist: 0.6569, 0.3052, 0.6501, param: [5.44307259 8.29877536 5.14609698 8.57537393], weights: [0.33195027 0.33218168 0.33586804], train_wt_loss:  36.4675, val_wt_loss: 37.2669, train_grp_loss: [11.80577157 13.07509406 10.73276014], val_grp_loss: [12.66770176 12.45218941 12.1462552 ], train_hist_grp_loss: [0.90655003 0.97623797 2.07986762], cur_train_grp_loss: [0.0944456  0.10460105 0.21465694], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6569, max_kl_dist_index: 0, max_train_grp_loss:  13.0751, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6677, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2147, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:04:47,838 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  9, train_loss:  12.1558, val_loss:  12.4223, grad_norm: 0.0002, live_grad: 0.0000, reward_err: 0.0104, 0.0142, 0.0002, KL_dist: 0.6570, 0.3053, 0.6501, param: [5.4431314  8.29860475 5.14635461 8.57574771], weights: [0.33180504 0.33207006 0.3361249 ], train_wt_loss:  36.4675, val_wt_loss: 37.2670, train_grp_loss: [11.80584355 13.07505741 10.73267295], val_grp_loss: [12.66781732 12.45215044 12.14626442], train_hist_grp_loss: [1.0009962  1.08083872 2.29452282], cur_train_grp_loss: [0.09444617 0.10460075 0.2146552 ], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6570, max_kl_dist_index: 0, max_train_grp_loss:  13.0751, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6678, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2147, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:04:48,812 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  10, train_loss:  12.1558, val_loss:  12.4224, grad_norm: 0.0002, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6570, 0.3053, 0.6501, param: [5.44319015 8.29843428 5.14661235 8.57612204], weights: [0.33165977 0.33195838 0.33638185], train_wt_loss:  36.4675, val_wt_loss: 37.2671, train_grp_loss: [11.80591532 13.07502106 10.73258566], val_grp_loss: [12.6679327  12.45211181 12.14627357], train_hist_grp_loss: [1.09544295 1.18543918 2.50917628], cur_train_grp_loss: [0.09444675 0.10460046 0.21465346], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6570, max_kl_dist_index: 0, max_train_grp_loss:  13.0750, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6679, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2147, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:04:49,799 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  11, train_loss:  12.1558, val_loss:  12.4224, grad_norm: 0.0002, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6570, 0.3053, 0.6501, param: [5.44324883 8.29826395 5.1468702  8.57649692], weights: [0.33151447 0.33184664 0.33663889], train_wt_loss:  36.4675, val_wt_loss: 37.2671, train_grp_loss: [11.80598689 13.07498501 10.73249826], val_grp_loss: [12.66804791 12.45207352 12.14628263], train_hist_grp_loss: [1.18989027 1.29003935 2.72382799], cur_train_grp_loss: [0.09444732 0.10460017 0.21465171], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6570, max_kl_dist_index: 0, max_train_grp_loss:  13.0750, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6680, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2147, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:04:50,797 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  12, train_loss:  12.1558, val_loss:  12.4224, grad_norm: 0.0002, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6570, 0.3053, 0.6502, param: [5.44330745 8.29809376 5.14712817 8.57687236], weights: [0.33136913 0.33173484 0.33689603], train_wt_loss:  36.4675, val_wt_loss: 37.2672, train_grp_loss: [11.80605824 13.07494926 10.73241074], val_grp_loss: [12.66816296 12.45203557 12.14629161], train_hist_grp_loss: [1.28433817 1.39463923 2.93847796], cur_train_grp_loss: [0.0944479  0.10459988 0.21464997], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6570, max_kl_dist_index: 0, max_train_grp_loss:  13.0749, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6682, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2146, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:04:51,787 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  13, train_loss:  12.1558, val_loss:  12.4224, grad_norm: 0.0003, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6571, 0.3053, 0.6502, param: [5.443366   8.29792371 5.14738624 8.57724835], weights: [0.33122377 0.33162298 0.33715325], train_wt_loss:  36.4675, val_wt_loss: 37.2673, train_grp_loss: [11.80612939 13.07491381 10.73232312], val_grp_loss: [12.66827783 12.45199796 12.14630052], train_hist_grp_loss: [1.37878663 1.49923882 3.15312617], cur_train_grp_loss: [0.09444847 0.10459959 0.21464821], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6571, max_kl_dist_index: 0, max_train_grp_loss:  13.0749, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6683, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2146, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:04:52,792 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  14, train_loss:  12.1558, val_loss:  12.4225, grad_norm: 0.0003, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6571, 0.3053, 0.6502, param: [5.44342449 8.29775379 5.14764443 8.5776249 ], weights: [0.33107838 0.33151105 0.33741057], train_wt_loss:  36.4675, val_wt_loss: 37.2674, train_grp_loss: [11.80620033 13.07487866 10.73223538], val_grp_loss: [12.66839253 12.45196069 12.14630934], train_hist_grp_loss: [1.47323567 1.60383813 3.36777263], cur_train_grp_loss: [0.09444904 0.10459931 0.21464646], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6571, max_kl_dist_index: 0, max_train_grp_loss:  13.0749, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6684, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2146, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:04:53,787 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  15, train_loss:  12.1558, val_loss:  12.4225, grad_norm: 0.0003, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6571, 0.3053, 0.6502, param: [5.44348291 8.29758401 5.14790273 8.57800199], weights: [0.33093295 0.33139907 0.33766798], train_wt_loss:  36.4675, val_wt_loss: 37.2675, train_grp_loss: [11.80627107 13.07484381 10.73214754], val_grp_loss: [12.66850705 12.45192376 12.14631809], train_hist_grp_loss: [1.56768527 1.70843716 3.58241734], cur_train_grp_loss: [0.0944496  0.10459903 0.21464471], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6571, max_kl_dist_index: 0, max_train_grp_loss:  13.0748, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6685, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2146, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:04:54,779 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  16, train_loss:  12.1558, val_loss:  12.4225, grad_norm: 0.0003, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6571, 0.3054, 0.6502, param: [5.44354126 8.29741437 5.14816114 8.57837964], weights: [0.33078749 0.33128703 0.33792548], train_wt_loss:  36.4675, val_wt_loss: 37.2676, train_grp_loss: [11.80634159 13.07480925 10.73205958], val_grp_loss: [12.66862141 12.45188717 12.14632675], train_hist_grp_loss: [1.66213544 1.81303591 3.79706029], cur_train_grp_loss: [0.09445017 0.10459875 0.21464295], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6571, max_kl_dist_index: 0, max_train_grp_loss:  13.0748, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6686, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2146, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:04:55,767 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  17, train_loss:  12.1558, val_loss:  12.4226, grad_norm: 0.0003, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6572, 0.3054, 0.6503, param: [5.44359956 8.29724486 5.14841967 8.57875785], weights: [0.330642   0.33117493 0.33818307], train_wt_loss:  36.4675, val_wt_loss: 37.2677, train_grp_loss: [11.80641191 13.074775   10.73197151], val_grp_loss: [12.6687356  12.45185092 12.14633533], train_hist_grp_loss: [1.75658617 1.91763439 4.01170148], cur_train_grp_loss: [0.09445073 0.10459847 0.21464119], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6572, max_kl_dist_index: 0, max_train_grp_loss:  13.0748, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6687, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2146, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:04:56,784 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  18, train_loss:  12.1558, val_loss:  12.4226, grad_norm: 0.0003, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6572, 0.3054, 0.6503, param: [5.44365778 8.2970755  5.14867831 8.57913661], weights: [0.33049648 0.33106276 0.33844075], train_wt_loss:  36.4675, val_wt_loss: 37.2677, train_grp_loss: [11.80648202 13.07474104 10.73188333], val_grp_loss: [12.66884961 12.45181501 12.14634384], train_hist_grp_loss: [1.85103747 2.02223259 4.22634091], cur_train_grp_loss: [0.0944513  0.1045982  0.21463943], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6572, max_kl_dist_index: 0, max_train_grp_loss:  13.0747, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6688, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2146, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:04:57,772 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  19, train_loss:  12.1558, val_loss:  12.4226, grad_norm: 0.0004, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6572, 0.3054, 0.6503, param: [5.44371595 8.29690627 5.14893705 8.57951592], weights: [0.33035093 0.33095054 0.33869853], train_wt_loss:  36.4675, val_wt_loss: 37.2678, train_grp_loss: [11.80655192 13.07470739 10.73179504], val_grp_loss: [12.66896345 12.45177944 12.14635226], train_hist_grp_loss: [1.94548932 2.12683052 4.44097858], cur_train_grp_loss: [0.09445186 0.10459793 0.21463767], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6572, max_kl_dist_index: 0, max_train_grp_loss:  13.0747, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6690, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2146, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:04:58,761 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  20, train_loss:  12.1558, val_loss:  12.4226, grad_norm: 0.0004, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6573, 0.3054, 0.6503, param: [5.44377404 8.29673718 5.14919592 8.57989579], weights: [0.33020535 0.33083826 0.33895639], train_wt_loss:  36.4675, val_wt_loss: 37.2679, train_grp_loss: [11.80662161 13.07467403 10.73170664], val_grp_loss: [12.66907713 12.45174422 12.1463606 ], train_hist_grp_loss: [2.03994174 2.23142818 4.65561448], cur_train_grp_loss: [0.09445242 0.10459766 0.2146359 ], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6573, max_kl_dist_index: 0, max_train_grp_loss:  13.0747, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6691, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2146, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:04:59,790 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  21, train_loss:  12.1558, val_loss:  12.4227, grad_norm: 0.0004, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6573, 0.3054, 0.6504, param: [5.44383208 8.29656822 5.14945489 8.58027621], weights: [0.33005974 0.33072591 0.33921435], train_wt_loss:  36.4675, val_wt_loss: 37.2680, train_grp_loss: [11.80669109 13.07464098 10.73161813], val_grp_loss: [12.66919063 12.45170933 12.14636886], train_hist_grp_loss: [2.13439471 2.33602557 4.87024861], cur_train_grp_loss: [0.09445297 0.10459739 0.21463413], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6573, max_kl_dist_index: 0, max_train_grp_loss:  13.0746, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6692, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2146, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:05:00,832 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  22, train_loss:  12.1558, val_loss:  12.4227, grad_norm: 0.0004, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6573, 0.3054, 0.6504, param: [5.44389004 8.29639941 5.14971398 8.58065718], weights: [0.3299141  0.33061351 0.33947239], train_wt_loss:  36.4675, val_wt_loss: 37.2681, train_grp_loss: [11.80676037 13.07460822 10.73152951], val_grp_loss: [12.66930396 12.45167479 12.14637705], train_hist_grp_loss: [2.22884824 2.4406227  5.08488098], cur_train_grp_loss: [0.09445353 0.10459713 0.21463236], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6573, max_kl_dist_index: 0, max_train_grp_loss:  13.0746, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6693, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2146, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:05:01,826 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  23, train_loss:  12.1558, val_loss:  12.4227, grad_norm: 0.0004, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6573, 0.3055, 0.6504, param: [5.44394794 8.29623073 5.14997318 8.58103872], weights: [0.32976842 0.33050105 0.33973053], train_wt_loss:  36.4675, val_wt_loss: 37.2682, train_grp_loss: [11.80682944 13.07457577 10.73144078], val_grp_loss: [12.66941712 12.45164059 12.14638515], train_hist_grp_loss: [2.32330232 2.54521956 5.29951157], cur_train_grp_loss: [0.09445408 0.10459687 0.21463059], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6573, max_kl_dist_index: 0, max_train_grp_loss:  13.0746, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6694, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2146, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:05:02,802 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  24, train_loss:  12.1558, val_loss:  12.4228, grad_norm: 0.0005, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6574, 0.3055, 0.6504, param: [5.44400578 8.29606219 5.15023249 8.5814208 ], weights: [0.32962272 0.33038853 0.33998876], train_wt_loss:  36.4675, val_wt_loss: 37.2683, train_grp_loss: [11.8068983  13.07454362 10.73135193], val_grp_loss: [12.6695301  12.45160672 12.14639317], train_hist_grp_loss: [2.41775696 2.64981617 5.51414038], cur_train_grp_loss: [0.09445464 0.10459661 0.21462882], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6574, max_kl_dist_index: 0, max_train_grp_loss:  13.0745, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6695, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2146, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:05:03,796 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  25, train_loss:  12.1558, val_loss:  12.4228, grad_norm: 0.0005, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6574, 0.3055, 0.6505, param: [5.44406355 8.29589378 5.15049192 8.58180345], weights: [0.32947698 0.33027594 0.34024708], train_wt_loss:  36.4675, val_wt_loss: 37.2684, train_grp_loss: [11.80696695 13.07451176 10.73126298], val_grp_loss: [12.66964292 12.4515732  12.14640111], train_hist_grp_loss: [2.51221214 2.75441252 5.72876742], cur_train_grp_loss: [0.09445519 0.10459635 0.21462704], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6574, max_kl_dist_index: 0, max_train_grp_loss:  13.0745, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6696, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2146, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:05:04,780 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  26, train_loss:  12.1558, val_loss:  12.4228, grad_norm: 0.0005, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6574, 0.3055, 0.6505, param: [5.44412126 8.29572551 5.15075146 8.58218664], weights: [0.32933122 0.3301633  0.34050548], train_wt_loss:  36.4675, val_wt_loss: 37.2684, train_grp_loss: [11.8070354  13.07448021 10.73117391], val_grp_loss: [12.66975556 12.45154003 12.14640898], train_hist_grp_loss: [2.60666788 2.85900861 5.94339268], cur_train_grp_loss: [0.09445574 0.10459609 0.21462526], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6574, max_kl_dist_index: 0, max_train_grp_loss:  13.0745, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6698, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2146, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:05:05,819 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  27, train_loss:  12.1558, val_loss:  12.4228, grad_norm: 0.0005, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6574, 0.3055, 0.6505, param: [5.4441789  8.29555738 5.15101111 8.5825704 ], weights: [0.32918542 0.3300506  0.34076398], train_wt_loss:  36.4675, val_wt_loss: 37.2685, train_grp_loss: [11.80710363 13.07444895 10.73108474], val_grp_loss: [12.66986804 12.45150719 12.14641676], train_hist_grp_loss: [2.70112416 2.96360445 6.15801616], cur_train_grp_loss: [0.09445628 0.10459584 0.21462348], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6574, max_kl_dist_index: 0, max_train_grp_loss:  13.0744, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6699, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2146, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:05:06,852 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  28, train_loss:  12.1558, val_loss:  12.4229, grad_norm: 0.0005, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6575, 0.3055, 0.6505, param: [5.44423647 8.29538939 5.15127088 8.58295471], weights: [0.32903959 0.32993784 0.34102257], train_wt_loss:  36.4675, val_wt_loss: 37.2686, train_grp_loss: [11.80717166 13.074418   10.73099545], val_grp_loss: [12.66998034 12.4514747  12.14642446], train_hist_grp_loss: [2.79558099 3.06820004 6.37263785], cur_train_grp_loss: [0.09445683 0.10459559 0.21462169], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6575, max_kl_dist_index: 0, max_train_grp_loss:  13.0744, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6700, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2146, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:05:07,850 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  29, train_loss:  12.1558, val_loss:  12.4229, grad_norm: 0.0006, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6575, 0.3056, 0.6505, param: [5.44429398 8.29522153 5.15153076 8.58333958], weights: [0.32889374 0.32982502 0.34128124], train_wt_loss:  36.4675, val_wt_loss: 37.2687, train_grp_loss: [11.80723948 13.07438735 10.73090605], val_grp_loss: [12.67009247 12.45144254 12.14643208], train_hist_grp_loss: [2.89003837 3.17279539 6.58725776], cur_train_grp_loss: [0.09445737 0.10459534 0.21461991], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6575, max_kl_dist_index: 0, max_train_grp_loss:  13.0744, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6701, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2146, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:05:08,841 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  30, train_loss:  12.1558, val_loss:  12.4229, grad_norm: 0.0006, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6575, 0.3056, 0.6506, param: [5.44435142 8.29505381 5.15179075 8.58372501], weights: [0.32874785 0.32971214 0.34154001], train_wt_loss:  36.4675, val_wt_loss: 37.2688, train_grp_loss: [11.8073071  13.074357   10.73081654], val_grp_loss: [12.67020444 12.45141073 12.14643963], train_hist_grp_loss: [2.98449628 3.27739049 6.80187588], cur_train_grp_loss: [0.09445792 0.1045951  0.21461812], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6575, max_kl_dist_index: 0, max_train_grp_loss:  13.0744, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6702, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2146, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:05:09,856 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  31, train_loss:  12.1558, val_loss:  12.4230, grad_norm: 0.0006, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6575, 0.3056, 0.6506, param: [5.4444088  8.29488622 5.15205086 8.58411099], weights: [0.32860193 0.3295992  0.34179887], train_wt_loss:  36.4675, val_wt_loss: 37.2689, train_grp_loss: [11.8073745  13.07432695 10.73072692], val_grp_loss: [12.67031623 12.45137926 12.14644709], train_hist_grp_loss: [3.07895474 3.38198534 7.01649221], cur_train_grp_loss: [0.09445846 0.10459486 0.21461633], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6575, max_kl_dist_index: 0, max_train_grp_loss:  13.0743, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6703, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2146, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:05:10,863 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  32, train_loss:  12.1558, val_loss:  12.4230, grad_norm: 0.0006, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6576, 0.3056, 0.6506, param: [5.44446611 8.29471877 5.15231108 8.58449753], weights: [0.32845598 0.32948621 0.34205781], train_wt_loss:  36.4675, val_wt_loss: 37.2690, train_grp_loss: [11.8074417  13.0742972  10.73063719], val_grp_loss: [12.67042784 12.45134814 12.14645447], train_hist_grp_loss: [3.17341373 3.48657996 7.23110675], cur_train_grp_loss: [0.094459   0.10459462 0.21461454], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6576, max_kl_dist_index: 0, max_train_grp_loss:  13.0743, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6704, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2146, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:05:11,850 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  33, train_loss:  12.1558, val_loss:  12.4230, grad_norm: 0.0006, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6576, 0.3056, 0.6506, param: [5.44452336 8.29455146 5.15257142 8.58488463], weights: [0.32831    0.32937315 0.34231685], train_wt_loss:  36.4675, val_wt_loss: 37.2691, train_grp_loss: [11.80750869 13.07426775 10.73054735], val_grp_loss: [12.67053929 12.45131735 12.14646178], train_hist_grp_loss: [3.26787327 3.59117434 7.4457195 ], cur_train_grp_loss: [0.09445953 0.10459438 0.21461274], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6576, max_kl_dist_index: 0, max_train_grp_loss:  13.0743, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6705, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2146, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:05:12,834 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  34, train_loss:  12.1558, val_loss:  12.4231, grad_norm: 0.0007, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6576, 0.3056, 0.6507, param: [5.44458054 8.29438428 5.15283186 8.58527228], weights: [0.328164   0.32926004 0.34257597], train_wt_loss:  36.4675, val_wt_loss: 37.2692, train_grp_loss: [11.80757547 13.0742386  10.7304574 ], val_grp_loss: [12.67065057 12.45128691 12.146469  ], train_hist_grp_loss: [3.36233334 3.69576848 7.66033044], cur_train_grp_loss: [0.09446007 0.10459414 0.21461095], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6576, max_kl_dist_index: 0, max_train_grp_loss:  13.0742, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6707, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2146, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:05:13,838 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  35, train_loss:  12.1558, val_loss:  12.4231, grad_norm: 0.0007, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6577, 0.3056, 0.6507, param: [5.44463765 8.29421724 5.15309243 8.5856605 ], weights: [0.32801796 0.32914686 0.34283518], train_wt_loss:  36.4675, val_wt_loss: 37.2692, train_grp_loss: [11.80764205 13.07420975 10.73036733], val_grp_loss: [12.67076168 12.45125681 12.14647615], train_hist_grp_loss: [3.45679394 3.80036239 7.87493959], cur_train_grp_loss: [0.0944606  0.10459391 0.21460915], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6577, max_kl_dist_index: 0, max_train_grp_loss:  13.0742, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6708, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2146, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:05:14,830 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  36, train_loss:  12.1558, val_loss:  12.4231, grad_norm: 0.0007, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6577, 0.3057, 0.6507, param: [5.4446947  8.29405034 5.1533531  8.58604927], weights: [0.32787189 0.32903363 0.34309448], train_wt_loss:  36.4675, val_wt_loss: 37.2693, train_grp_loss: [11.80770842 13.07418121 10.73027716], val_grp_loss: [12.67087261 12.45122705 12.14648321], train_hist_grp_loss: [3.55125508 3.90495606 8.08954694], cur_train_grp_loss: [0.09446114 0.10459368 0.21460735], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6577, max_kl_dist_index: 0, max_train_grp_loss:  13.0742, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6709, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2146, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:05:15,802 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  37, train_loss:  12.1558, val_loss:  12.4231, grad_norm: 0.0007, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6577, 0.3057, 0.6507, param: [5.44475169 8.29388357 5.15361389 8.5864386 ], weights: [0.32772579 0.32892034 0.34335387], train_wt_loss:  36.4675, val_wt_loss: 37.2694, train_grp_loss: [11.80777457 13.07415296 10.73018687], val_grp_loss: [12.67098338 12.45119764 12.14649019], train_hist_grp_loss: [3.64571674 4.00954951 8.30415248], cur_train_grp_loss: [0.09446167 0.10459345 0.21460554], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6577, max_kl_dist_index: 0, max_train_grp_loss:  13.0742, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6710, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2146, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:05:16,802 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  38, train_loss:  12.1558, val_loss:  12.4232, grad_norm: 0.0007, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6577, 0.3057, 0.6508, param: [5.4448086  8.29371694 5.1538748  8.58682849], weights: [0.32757966 0.32880699 0.34361335], train_wt_loss:  36.4675, val_wt_loss: 37.2695, train_grp_loss: [11.80784053 13.07412502 10.73009648], val_grp_loss: [12.67109397 12.45116857 12.1464971 ], train_hist_grp_loss: [3.74017894 4.11414274 8.51875622], cur_train_grp_loss: [0.0944622  0.10459322 0.21460374], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6577, max_kl_dist_index: 0, max_train_grp_loss:  13.0741, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6711, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2146, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:05:17,798 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  39, train_loss:  12.1558, val_loss:  12.4232, grad_norm: 0.0008, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6578, 0.3057, 0.6508, param: [5.44486546 8.29355044 5.15413582 8.58721894], weights: [0.32743351 0.32869358 0.34387292], train_wt_loss:  36.4675, val_wt_loss: 37.2696, train_grp_loss: [11.80790627 13.07409738 10.73000597], val_grp_loss: [12.67120439 12.45113984 12.14650392], train_hist_grp_loss: [3.83464167 4.21873574 8.73335815], cur_train_grp_loss: [0.09446272 0.104593   0.21460193], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6578, max_kl_dist_index: 0, max_train_grp_loss:  13.0741, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6712, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2146, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:05:18,806 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  40, train_loss:  12.1558, val_loss:  12.4232, grad_norm: 0.0008, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6578, 0.3057, 0.6508, param: [5.44492224 8.29338408 5.15439695 8.58760995], weights: [0.32728732 0.32858011 0.34413257], train_wt_loss:  36.4675, val_wt_loss: 37.2697, train_grp_loss: [11.80797181 13.07407004 10.72991535], val_grp_loss: [12.67131465 12.45111146 12.14651067], train_hist_grp_loss: [3.92910492 4.32332852 8.94795827], cur_train_grp_loss: [0.09446325 0.10459278 0.21460012], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6578, max_kl_dist_index: 0, max_train_grp_loss:  13.0741, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6713, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2146, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:05:19,813 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  41, train_loss:  12.1558, val_loss:  12.4233, grad_norm: 0.0008, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6578, 0.3057, 0.6508, param: [5.44497896 8.29321786 5.1546582  8.58800152], weights: [0.3271411  0.32846658 0.34439232], train_wt_loss:  36.4675, val_wt_loss: 37.2698, train_grp_loss: [11.80803714 13.074043   10.72982462], val_grp_loss: [12.67142473 12.45108341 12.14651734], train_hist_grp_loss: [4.02356869 4.42792108 9.16255657], cur_train_grp_loss: [0.09446377 0.10459256 0.21459831], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6578, max_kl_dist_index: 0, max_train_grp_loss:  13.0740, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6714, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2146, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:05:20,814 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  42, train_loss:  12.1558, val_loss:  12.4233, grad_norm: 0.0008, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6578, 0.3057, 0.6509, param: [5.44503561 8.29305177 5.15491957 8.58839364], weights: [0.32699486 0.328353   0.34465215], train_wt_loss:  36.4675, val_wt_loss: 37.2699, train_grp_loss: [11.80810226 13.07401627 10.72973378], val_grp_loss: [12.67153464 12.45105572 12.14652392], train_hist_grp_loss: [4.11803299 4.53251342 9.37715307], cur_train_grp_loss: [0.0944643  0.10459234 0.21459649], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6578, max_kl_dist_index: 0, max_train_grp_loss:  13.0740, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6715, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2146, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:05:21,820 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  43, train_loss:  12.1558, val_loss:  12.4233, grad_norm: 0.0009, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6579, 0.3058, 0.6509, param: [5.4450922  8.29288582 5.15518105 8.58878633], weights: [0.32684858 0.32823935 0.34491207], train_wt_loss:  36.4675, val_wt_loss: 37.2699, train_grp_loss: [11.80816717 13.07398983 10.72964282], val_grp_loss: [12.67164438 12.45102836 12.14653043], train_hist_grp_loss: [4.21249781 4.63710555 9.59174774], cur_train_grp_loss: [0.09446482 0.10459213 0.21459468], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6579, max_kl_dist_index: 0, max_train_grp_loss:  13.0740, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6716, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2146, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:05:22,827 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  44, train_loss:  12.1558, val_loss:  12.4233, grad_norm: 0.0009, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6579, 0.3058, 0.6509, param: [5.44514872 8.29272    5.15544264 8.58917958], weights: [0.32670227 0.32812565 0.34517207], train_wt_loss:  36.4675, val_wt_loss: 37.2700, train_grp_loss: [11.80823188 13.0739637  10.72955176], val_grp_loss: [12.67175395 12.45100135 12.14653686], train_hist_grp_loss: [4.30696314 4.74169747 9.8063406 ], cur_train_grp_loss: [0.09446534 0.10459192 0.21459286], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6579, max_kl_dist_index: 0, max_train_grp_loss:  13.0740, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6718, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2146, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:05:23,854 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  45, train_loss:  12.1558, val_loss:  12.4234, grad_norm: 0.0009, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6579, 0.3058, 0.6509, param: [5.44520518 8.29255432 5.15570435 8.58957339], weights: [0.32655594 0.32801189 0.34543217], train_wt_loss:  36.4675, val_wt_loss: 37.2701, train_grp_loss: [11.80829637 13.07393787 10.72946058], val_grp_loss: [12.67186335 12.45097468 12.14654321], train_hist_grp_loss: [ 4.401429    4.84628918 10.02093163], cur_train_grp_loss: [0.09446586 0.10459171 0.21459104], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6579, max_kl_dist_index: 0, max_train_grp_loss:  13.0739, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6719, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2146, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:05:24,861 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  46, train_loss:  12.1558, val_loss:  12.4234, grad_norm: 0.0009, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6580, 0.3058, 0.6510, param: [5.44526157 8.29238877 5.15596617 8.58996776], weights: [0.32640958 0.32789808 0.34569235], train_wt_loss:  36.4675, val_wt_loss: 37.2702, train_grp_loss: [11.80836067 13.07391234 10.7293693 ], val_grp_loss: [12.67197257 12.45094836 12.14654947], train_hist_grp_loss: [ 4.49589537  4.95088068 10.23552085], cur_train_grp_loss: [0.09446637 0.1045915  0.21458921], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6580, max_kl_dist_index: 0, max_train_grp_loss:  13.0739, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6720, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2146, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:05:25,857 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  47, train_loss:  12.1558, val_loss:  12.4234, grad_norm: 0.0009, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6580, 0.3058, 0.6510, param: [5.44531789 8.29222336 5.15622811 8.59036269], weights: [0.32626318 0.3277842  0.34595262], train_wt_loss:  36.4675, val_wt_loss: 37.2703, train_grp_loss: [11.80842475 13.07388712 10.7292779 ], val_grp_loss: [12.67208163 12.45092238 12.14655566], train_hist_grp_loss: [ 4.59036225  5.05547198 10.45010823], cur_train_grp_loss: [0.09446689 0.1045913  0.21458739], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6580, max_kl_dist_index: 0, max_train_grp_loss:  13.0739, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6721, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2146, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:05:26,873 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  48, train_loss:  12.1558, val_loss:  12.4235, grad_norm: 0.0010, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6580, 0.3058, 0.6510, param: [5.44537414 8.29205808 5.15649016 8.59075819], weights: [0.32611676 0.32767026 0.34621297], train_wt_loss:  36.4675, val_wt_loss: 37.2704, train_grp_loss: [11.80848863 13.0738622  10.72918639], val_grp_loss: [12.67219052 12.45089674 12.14656177], train_hist_grp_loss: [ 4.68482965  5.16006308 10.66469379], cur_train_grp_loss: [0.0944674  0.1045911  0.21458556], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6580, max_kl_dist_index: 0, max_train_grp_loss:  13.0739, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6722, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2146, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:05:27,886 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  49, train_loss:  12.1558, val_loss:  12.4235, grad_norm: 0.0010, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6580, 0.3058, 0.6510, param: [5.44543033 8.29189294 5.15675233 8.59115424], weights: [0.32597031 0.32755627 0.34647342], train_wt_loss:  36.4675, val_wt_loss: 37.2705, train_grp_loss: [11.80855229 13.07383758 10.72909477], val_grp_loss: [12.67229923 12.45087145 12.1465678 ], train_hist_grp_loss: [ 4.77929756  5.26465398 10.87927752], cur_train_grp_loss: [0.09446791 0.1045909  0.21458373], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6580, max_kl_dist_index: 0, max_train_grp_loss:  13.0738, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6723, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2146, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:05:28,879 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  50, train_loss:  12.1558, val_loss:  12.4235, grad_norm: 0.0010, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6581, 0.3059, 0.6511, param: [5.44548646 8.29172793 5.15701462 8.59155086], weights: [0.32582383 0.32744222 0.34673395], train_wt_loss:  36.4675, val_wt_loss: 37.2706, train_grp_loss: [11.80861576 13.07381326 10.72900304], val_grp_loss: [12.67240778 12.4508465  12.14657375], train_hist_grp_loss: [ 4.87376598  5.36924468 11.09385941], cur_train_grp_loss: [0.09446842 0.1045907  0.2145819 ], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6581, max_kl_dist_index: 0, max_train_grp_loss:  13.0738, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6724, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2146, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:05:29,881 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  51, train_loss:  12.1558, val_loss:  12.4236, grad_norm: 0.0010, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6581, 0.3059, 0.6511, param: [5.44554251 8.29156306 5.15727702 8.59194804], weights: [0.32567732 0.32732811 0.34699457], train_wt_loss:  36.4675, val_wt_loss: 37.2707, train_grp_loss: [11.80867901 13.07378924 10.7289112 ], val_grp_loss: [12.67251615 12.45082189 12.14657963], train_hist_grp_loss: [ 4.96823491  5.47383518 11.30843947], cur_train_grp_loss: [0.09446893 0.10459051 0.21458006], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6581, max_kl_dist_index: 0, max_train_grp_loss:  13.0738, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6725, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2146, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:05:30,876 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  52, train_loss:  12.1558, val_loss:  12.4236, grad_norm: 0.0010, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6581, 0.3059, 0.6511, param: [5.4455985  8.29139832 5.15753954 8.59234578], weights: [0.32553078 0.32721395 0.34725527], train_wt_loss:  36.4675, val_wt_loss: 37.2708, train_grp_loss: [11.80874206 13.07376553 10.72881924], val_grp_loss: [12.67262436 12.45079763 12.14658542], train_hist_grp_loss: [ 5.06270434  5.5784255  11.5230177 ], cur_train_grp_loss: [0.09446943 0.10459031 0.21457822], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6581, max_kl_dist_index: 0, max_train_grp_loss:  13.0738, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6726, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2146, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:05:31,867 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  53, train_loss:  12.1558, val_loss:  12.4236, grad_norm: 0.0011, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6581, 0.3059, 0.6511, param: [5.44565443 8.29123372 5.15780217 8.59274408], weights: [0.32538421 0.32709973 0.34751606], train_wt_loss:  36.4675, val_wt_loss: 37.2708, train_grp_loss: [11.80880489 13.07374212 10.72872718], val_grp_loss: [12.67273239 12.45077372 12.14659113], train_hist_grp_loss: [ 5.15717427  5.68301562 11.73759408], cur_train_grp_loss: [0.09446994 0.10459012 0.21457638], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6581, max_kl_dist_index: 0, max_train_grp_loss:  13.0737, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6727, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2146, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:05:32,860 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  54, train_loss:  12.1559, val_loss:  12.4236, grad_norm: 0.0011, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6582, 0.3059, 0.6512, param: [5.44571029 8.29106925 5.15806492 8.59314295], weights: [0.32523762 0.32698544 0.34777694], train_wt_loss:  36.4676, val_wt_loss: 37.2709, train_grp_loss: [11.80886753 13.07371902 10.728635  ], val_grp_loss: [12.67284026 12.45075015 12.14659677], train_hist_grp_loss: [ 5.25164471  5.78760556 11.95216863], cur_train_grp_loss: [0.09447044 0.10458994 0.21457454], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6582, max_kl_dist_index: 0, max_train_grp_loss:  13.0737, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6728, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2146, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:05:33,843 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  55, train_loss:  12.1559, val_loss:  12.4237, grad_norm: 0.0011, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6582, 0.3059, 0.6512, param: [5.44576608 8.29090492 5.15832778 8.59354238], weights: [0.32509099 0.32687111 0.3480379 ], train_wt_loss:  36.4676, val_wt_loss: 37.2710, train_grp_loss: [11.80892995 13.07369621 10.72854271], val_grp_loss: [12.67294795 12.45072692 12.14660232], train_hist_grp_loss: [ 5.34611565  5.89219531 12.16674133], cur_train_grp_loss: [0.09447094 0.10458975 0.2145727 ], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6582, max_kl_dist_index: 0, max_train_grp_loss:  13.0737, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6729, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2146, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:05:34,867 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  56, train_loss:  12.1559, val_loss:  12.4237, grad_norm: 0.0011, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6582, 0.3060, 0.6512, param: [5.4458218  8.29074072 5.15859076 8.59394237], weights: [0.32494434 0.32675671 0.34829895], train_wt_loss:  36.4676, val_wt_loss: 37.2711, train_grp_loss: [11.80899217 13.07367371 10.72845031], val_grp_loss: [12.67305547 12.45070404 12.1466078 ], train_hist_grp_loss: [ 5.44058709  5.99678488 12.38131218], cur_train_grp_loss: [0.09447144 0.10458957 0.21457085], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6582, max_kl_dist_index: 0, max_train_grp_loss:  13.0737, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6731, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2146, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:05:35,886 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  57, train_loss:  12.1559, val_loss:  12.4237, grad_norm: 0.0011, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6583, 0.3060, 0.6512, param: [5.44587746 8.29057665 5.15885386 8.59434293], weights: [0.32479766 0.32664226 0.34856008], train_wt_loss:  36.4676, val_wt_loss: 37.2712, train_grp_loss: [11.80905418 13.07365151 10.7283578 ], val_grp_loss: [12.67316282 12.4506815  12.14661319], train_hist_grp_loss: [ 5.53505903  6.10137427 12.59588119], cur_train_grp_loss: [0.09447194 0.10458939 0.21456901], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6583, max_kl_dist_index: 0, max_train_grp_loss:  13.0737, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6732, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2146, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:05:36,912 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  58, train_loss:  12.1559, val_loss:  12.4238, grad_norm: 0.0012, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6583, 0.3060, 0.6513, param: [5.44593305 8.29041272 5.15911707 8.59474405], weights: [0.32465095 0.32652775 0.34882131], train_wt_loss:  36.4676, val_wt_loss: 37.2713, train_grp_loss: [11.80911598 13.07362962 10.72826518], val_grp_loss: [12.67327    12.45065931 12.14661851], train_hist_grp_loss: [ 5.62953146  6.20596348 12.81044834], cur_train_grp_loss: [0.09447243 0.10458921 0.21456716], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6583, max_kl_dist_index: 0, max_train_grp_loss:  13.0736, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6733, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2146, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:05:37,915 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  59, train_loss:  12.1559, val_loss:  12.4238, grad_norm: 0.0012, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6583, 0.3060, 0.6513, param: [5.44598857 8.29024893 5.1593804  8.59514573], weights: [0.32450421 0.32641318 0.34908261], train_wt_loss:  36.4676, val_wt_loss: 37.2714, train_grp_loss: [11.80917758 13.07360803 10.72817245], val_grp_loss: [12.67337702 12.45063747 12.14662375], train_hist_grp_loss: [ 5.72400439  6.31055252 13.02501365], cur_train_grp_loss: [0.09447293 0.10458904 0.2145653 ], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6583, max_kl_dist_index: 0, max_train_grp_loss:  13.0736, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6734, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2146, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:05:38,976 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  60, train_loss:  12.1559, val_loss:  12.4238, grad_norm: 0.0012, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6583, 0.3060, 0.6513, param: [5.44604403 8.29008527 5.15964384 8.59554798], weights: [0.32435744 0.32629855 0.349344  ], train_wt_loss:  36.4676, val_wt_loss: 37.2715, train_grp_loss: [11.80923896 13.07358674 10.7280796 ], val_grp_loss: [12.67348386 12.45061596 12.14662891], train_hist_grp_loss: [ 5.81847781  6.41514138 13.23957709], cur_train_grp_loss: [0.09447342 0.10458886 0.21456345], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6583, max_kl_dist_index: 0, max_train_grp_loss:  13.0736, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6735, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2146, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:05:39,974 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  61, train_loss:  12.1559, val_loss:  12.4239, grad_norm: 0.0012, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6584, 0.3060, 0.6513, param: [5.44609942 8.28992174 5.1599074  8.5959508 ], weights: [0.32421065 0.32618387 0.34960548], train_wt_loss:  36.4676, val_wt_loss: 37.2716, train_grp_loss: [11.80930014 13.07356576 10.72798665], val_grp_loss: [12.67359053 12.45059481 12.14663399], train_hist_grp_loss: [ 5.91295172  6.51973008 13.45413869], cur_train_grp_loss: [0.09447391 0.10458869 0.21456159], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6584, max_kl_dist_index: 0, max_train_grp_loss:  13.0736, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6736, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2146, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:05:40,995 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  62, train_loss:  12.1559, val_loss:  12.4239, grad_norm: 0.0012, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6584, 0.3060, 0.6514, param: [5.44615474 8.28975834 5.16017108 8.59635418], weights: [0.32406383 0.32606913 0.34986705], train_wt_loss:  36.4676, val_wt_loss: 37.2717, train_grp_loss: [11.80936112 13.07354508 10.72789358], val_grp_loss: [12.67369703 12.450574   12.14663899], train_hist_grp_loss: [ 6.00742613  6.6243186  13.66869842], cur_train_grp_loss: [0.0944744  0.10458853 0.21455973], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6584, max_kl_dist_index: 0, max_train_grp_loss:  13.0735, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6737, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2146, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:05:41,996 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  63, train_loss:  12.1559, val_loss:  12.4239, grad_norm: 0.0013, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6584, 0.3061, 0.6514, param: [5.44621    8.28959508 5.16043488 8.59675812], weights: [0.32391697 0.32595433 0.35012869], train_wt_loss:  36.4676, val_wt_loss: 37.2718, train_grp_loss: [11.80942188 13.0735247  10.7278004 ], val_grp_loss: [12.67380336 12.45055353 12.14664391], train_hist_grp_loss: [ 6.10190101  6.72890696 13.88325629], cur_train_grp_loss: [0.09447489 0.10458836 0.21455787], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6584, max_kl_dist_index: 0, max_train_grp_loss:  13.0735, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6738, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2146, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:05:42,999 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  64, train_loss:  12.1559, val_loss:  12.4239, grad_norm: 0.0013, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6585, 0.3061, 0.6514, param: [5.44626519 8.28943196 5.16069879 8.59716263], weights: [0.32377009 0.32583948 0.35039043], train_wt_loss:  36.4676, val_wt_loss: 37.2718, train_grp_loss: [11.80948244 13.07350463 10.72770711], val_grp_loss: [12.67390952 12.45053341 12.14664875], train_hist_grp_loss: [ 6.19637639  6.83349516 14.0978123 ], cur_train_grp_loss: [0.09447538 0.1045882  0.21455601], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6585, max_kl_dist_index: 0, max_train_grp_loss:  13.0735, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6739, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2146, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:05:43,992 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  65, train_loss:  12.1559, val_loss:  12.4240, grad_norm: 0.0013, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6585, 0.3061, 0.6514, param: [5.44632031 8.28926896 5.16096282 8.5975677 ], weights: [0.32362319 0.32572457 0.35065224], train_wt_loss:  36.4676, val_wt_loss: 37.2719, train_grp_loss: [11.8095428  13.07348486 10.72761371], val_grp_loss: [12.67401551 12.45051364 12.14665352], train_hist_grp_loss: [ 6.29085225  6.9380832  14.31236644], cur_train_grp_loss: [0.09447586 0.10458804 0.21455414], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6585, max_kl_dist_index: 0, max_train_grp_loss:  13.0735, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6740, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2146, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:05:45,016 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  66, train_loss:  12.1559, val_loss:  12.4240, grad_norm: 0.0013, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6585, 0.3061, 0.6515, param: [5.44637536 8.2891061  5.16122697 8.59797334], weights: [0.32347625 0.3256096  0.35091415], train_wt_loss:  36.4676, val_wt_loss: 37.2720, train_grp_loss: [11.80960294 13.0734654  10.72752019], val_grp_loss: [12.67412133 12.45049421 12.1466582 ], train_hist_grp_loss: [ 6.38532859  7.04267108 14.52691872], cur_train_grp_loss: [0.09447634 0.10458788 0.21455227], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6585, max_kl_dist_index: 0, max_train_grp_loss:  13.0735, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6741, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2146, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:05:46,002 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  67, train_loss:  12.1559, val_loss:  12.4240, grad_norm: 0.0014, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6585, 0.3061, 0.6515, param: [5.44643035 8.28894338 5.16149123 8.59837955], weights: [0.32332929 0.32549458 0.35117613], train_wt_loss:  36.4676, val_wt_loss: 37.2721, train_grp_loss: [11.80966288 13.07344624 10.72742657], val_grp_loss: [12.67422698 12.45047513 12.14666281], train_hist_grp_loss: [ 6.47980541  7.1472588  14.74146912], cur_train_grp_loss: [0.09447682 0.10458772 0.2145504 ], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6585, max_kl_dist_index: 0, max_train_grp_loss:  13.0734, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6742, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2146, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:05:47,036 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  68, train_loss:  12.1559, val_loss:  12.4241, grad_norm: 0.0014, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6586, 0.3061, 0.6515, param: [5.44648527 8.28878079 5.16175561 8.59878632], weights: [0.3231823  0.3253795  0.35143821], train_wt_loss:  36.4676, val_wt_loss: 37.2722, train_grp_loss: [11.80972261 13.07342738 10.72733283], val_grp_loss: [12.67433246 12.45045639 12.14666734], train_hist_grp_loss: [ 6.57428272  7.25184637 14.95601765], cur_train_grp_loss: [0.0944773  0.10458757 0.21454853], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6586, max_kl_dist_index: 0, max_train_grp_loss:  13.0734, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6743, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2145, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:05:48,052 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  69, train_loss:  12.1559, val_loss:  12.4241, grad_norm: 0.0014, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6586, 0.3062, 0.6515, param: [5.44654013 8.28861833 5.16202011 8.59919366], weights: [0.32303528 0.32526436 0.35170036], train_wt_loss:  36.4676, val_wt_loss: 37.2723, train_grp_loss: [11.80978214 13.07340883 10.72723898], val_grp_loss: [12.67443776 12.450438   12.14667179], train_hist_grp_loss: [ 6.6687605   7.35643379 15.17056431], cur_train_grp_loss: [0.09447778 0.10458742 0.21454666], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6586, max_kl_dist_index: 0, max_train_grp_loss:  13.0734, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6744, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2145, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:05:49,042 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  70, train_loss:  12.1559, val_loss:  12.4241, grad_norm: 0.0014, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6586, 0.3062, 0.6516, param: [5.44659491 8.288456   5.16228472 8.59960157], weights: [0.32288823 0.32514917 0.3519626 ], train_wt_loss:  36.4676, val_wt_loss: 37.2724, train_grp_loss: [11.80984145 13.07339059 10.72714502], val_grp_loss: [12.6745429  12.45041996 12.14667616], train_hist_grp_loss: [ 6.76323876  7.46102106 15.38510909], cur_train_grp_loss: [0.09447826 0.10458727 0.21454478], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6586, max_kl_dist_index: 0, max_train_grp_loss:  13.0734, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6745, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2145, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:05:50,055 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  71, train_loss:  12.1559, val_loss:  12.4242, grad_norm: 0.0014, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6587, 0.3062, 0.6516, param: [5.44664963 8.28829381 5.16254945 8.60001004], weights: [0.32274116 0.32503392 0.35222493], train_wt_loss:  36.4676, val_wt_loss: 37.2725, train_grp_loss: [11.80990056 13.07337264 10.72705095], val_grp_loss: [12.67464787 12.45040226 12.14668045], train_hist_grp_loss: [ 6.85771749  7.56560818 15.59965199], cur_train_grp_loss: [0.09447873 0.10458712 0.2145429 ], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6587, max_kl_dist_index: 0, max_train_grp_loss:  13.0734, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6746, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2145, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:05:51,071 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  72, train_loss:  12.1559, val_loss:  12.4242, grad_norm: 0.0015, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6587, 0.3062, 0.6516, param: [5.44670428 8.28813175 5.16281431 8.60041908], weights: [0.32259405 0.32491861 0.35248734], train_wt_loss:  36.4676, val_wt_loss: 37.2726, train_grp_loss: [11.80995947 13.07335501 10.72695677], val_grp_loss: [12.67475267 12.45038491 12.14668466], train_hist_grp_loss: [ 6.95219669  7.67019517 15.81419301], cur_train_grp_loss: [0.0944792  0.10458698 0.21454102], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6587, max_kl_dist_index: 0, max_train_grp_loss:  13.0734, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6748, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2145, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:05:52,075 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  73, train_loss:  12.1559, val_loss:  12.4242, grad_norm: 0.0015, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6587, 0.3062, 0.6516, param: [5.44675887 8.28796982 5.16307927 8.60082869], weights: [0.32244692 0.32480325 0.35274983], train_wt_loss:  36.4676, val_wt_loss: 37.2727, train_grp_loss: [11.81001816 13.07333767 10.72686247], val_grp_loss: [12.6748573  12.4503679  12.14668879], train_hist_grp_loss: [ 7.04667637  7.77478201 16.02873214], cur_train_grp_loss: [0.09447968 0.10458684 0.21453914], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6587, max_kl_dist_index: 0, max_train_grp_loss:  13.0733, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6749, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2145, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:05:53,090 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  74, train_loss:  12.1559, val_loss:  12.4243, grad_norm: 0.0015, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6587, 0.3062, 0.6517, param: [5.44681338 8.28780803 5.16334436 8.60123886], weights: [0.32229977 0.32468783 0.3530124 ], train_wt_loss:  36.4676, val_wt_loss: 37.2728, train_grp_loss: [11.81007665 13.07332064 10.72676807], val_grp_loss: [12.67496176 12.45035124 12.14669285], train_hist_grp_loss: [ 7.14115651  7.87936871 16.24326939], cur_train_grp_loss: [0.09448015 0.1045867  0.21453725], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6587, max_kl_dist_index: 0, max_train_grp_loss:  13.0733, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6750, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2145, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:05:54,090 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  75, train_loss:  12.1559, val_loss:  12.4243, grad_norm: 0.0015, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6588, 0.3062, 0.6517, param: [5.44686783 8.28764637 5.16360956 8.6016496 ], weights: [0.32215258 0.32457235 0.35327506], train_wt_loss:  36.4676, val_wt_loss: 37.2729, train_grp_loss: [11.81013494 13.07330392 10.72667355], val_grp_loss: [12.67506605 12.45033493 12.14669683], train_hist_grp_loss: [ 7.23563713  7.98395527 16.45780475], cur_train_grp_loss: [0.09448061 0.10458657 0.21453536], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6588, max_kl_dist_index: 0, max_train_grp_loss:  13.0733, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6751, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2145, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:05:55,094 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  76, train_loss:  12.1559, val_loss:  12.4243, grad_norm: 0.0016, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6588, 0.3063, 0.6517, param: [5.44692221 8.28748484 5.16387488 8.60206092], weights: [0.32200537 0.32445682 0.35353781], train_wt_loss:  36.4676, val_wt_loss: 37.2729, train_grp_loss: [11.81019301 13.0732875  10.72657892], val_grp_loss: [12.67517017 12.45031897 12.14670073], train_hist_grp_loss: [ 7.33011821  8.0885417  16.67233822], cur_train_grp_loss: [0.09448108 0.10458643 0.21453347], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6588, max_kl_dist_index: 0, max_train_grp_loss:  13.0733, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6752, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2145, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:05:56,116 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  77, train_loss:  12.1559, val_loss:  12.4243, grad_norm: 0.0016, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6588, 0.3063, 0.6517, param: [5.44697653 8.28732345 5.16414032 8.6024728 ], weights: [0.32185813 0.32434123 0.35380063], train_wt_loss:  36.4676, val_wt_loss: 37.2730, train_grp_loss: [11.81025088 13.07327139 10.72648418], val_grp_loss: [12.67527411 12.45030335 12.14670454], train_hist_grp_loss: [ 7.42459975  8.193128   16.8868698 ], cur_train_grp_loss: [0.09448154 0.1045863  0.21453158], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6588, max_kl_dist_index: 0, max_train_grp_loss:  13.0733, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6753, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2145, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:05:57,137 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  78, train_loss:  12.1559, val_loss:  12.4244, grad_norm: 0.0016, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6589, 0.3063, 0.6518, param: [5.44703077 8.28716218 5.16440588 8.60288524], weights: [0.32171087 0.32422559 0.35406354], train_wt_loss:  36.4676, val_wt_loss: 37.2731, train_grp_loss: [11.81030854 13.07325558 10.72638933], val_grp_loss: [12.67537789 12.45028808 12.14670829], train_hist_grp_loss: [ 7.51908176  8.29771417 17.10139949], cur_train_grp_loss: [0.09448201 0.10458617 0.21452968], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6589, max_kl_dist_index: 0, max_train_grp_loss:  13.0733, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6754, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2145, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:05:58,144 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  79, train_loss:  12.1559, val_loss:  12.4244, grad_norm: 0.0016, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6589, 0.3063, 0.6518, param: [5.44708495 8.28700105 5.16467156 8.60329826], weights: [0.32156357 0.32410989 0.35432653], train_wt_loss:  36.4677, val_wt_loss: 37.2732, train_grp_loss: [11.810366   13.07324008 10.72629436], val_grp_loss: [12.6754815  12.45027316 12.14671195], train_hist_grp_loss: [ 7.61356423  8.40230022 17.31592727], cur_train_grp_loss: [0.09448247 0.10458604 0.21452779], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6589, max_kl_dist_index: 0, max_train_grp_loss:  13.0732, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6755, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2145, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:05:59,138 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  80, train_loss:  12.1559, val_loss:  12.4244, grad_norm: 0.0016, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6589, 0.3063, 0.6518, param: [5.44713906 8.28684005 5.16493735 8.60371185], weights: [0.32141626 0.32399414 0.35458961], train_wt_loss:  36.4677, val_wt_loss: 37.2733, train_grp_loss: [11.81042325 13.07322488 10.72619929], val_grp_loss: [12.67558494 12.45025858 12.14671553], train_hist_grp_loss: [ 7.70804715  8.50688614 17.53045316], cur_train_grp_loss: [0.09448293 0.10458592 0.21452589], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6589, max_kl_dist_index: 0, max_train_grp_loss:  13.0732, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6756, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2145, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:06:00,132 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  81, train_loss:  12.1559, val_loss:  12.4245, grad_norm: 0.0017, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6589, 0.3063, 0.6519, param: [5.44719311 8.28667919 5.16520327 8.604126  ], weights: [0.32126891 0.32387833 0.35485277], train_wt_loss:  36.4677, val_wt_loss: 37.2734, train_grp_loss: [11.81048029 13.07320999 10.7261041 ], val_grp_loss: [12.67568821 12.45024435 12.14671904], train_hist_grp_loss: [ 7.80253054  8.61147194 17.74497715], cur_train_grp_loss: [0.09448339 0.1045858  0.21452399], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6589, max_kl_dist_index: 0, max_train_grp_loss:  13.0732, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6757, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2145, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:06:01,204 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  82, train_loss:  12.1559, val_loss:  12.4245, grad_norm: 0.0017, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6590, 0.3064, 0.6519, param: [5.44724708 8.28651845 5.1654693  8.60454073], weights: [0.32112153 0.32376246 0.35511601], train_wt_loss:  36.4677, val_wt_loss: 37.2735, train_grp_loss: [11.81053713 13.0731954  10.7260088 ], val_grp_loss: [12.67579131 12.45023047 12.14672247], train_hist_grp_loss: [ 7.89701438  8.71605762 17.95949923], cur_train_grp_loss: [0.09448384 0.10458568 0.21452208], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6590, max_kl_dist_index: 0, max_train_grp_loss:  13.0732, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6758, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2145, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:06:02,212 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  83, train_loss:  12.1559, val_loss:  12.4245, grad_norm: 0.0017, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6590, 0.3064, 0.6519, param: [5.44730099 8.28635785 5.16573545 8.60495602], weights: [0.32097413 0.32364654 0.35537933], train_wt_loss:  36.4677, val_wt_loss: 37.2736, train_grp_loss: [11.81059376 13.07318112 10.72591339], val_grp_loss: [12.67589424 12.45021694 12.14672582], train_hist_grp_loss: [ 7.99149868  8.82064318 18.1740194 ], cur_train_grp_loss: [0.0944843  0.10458556 0.21452018], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6590, max_kl_dist_index: 0, max_train_grp_loss:  13.0732, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6759, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2145, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:06:03,221 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  84, train_loss:  12.1559, val_loss:  12.4246, grad_norm: 0.0017, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6590, 0.3064, 0.6519, param: [5.44735483 8.28619738 5.16600172 8.60537189], weights: [0.32082671 0.32353056 0.35564273], train_wt_loss:  36.4677, val_wt_loss: 37.2737, train_grp_loss: [11.81065018 13.07316714 10.72581787], val_grp_loss: [12.675997   12.45020375 12.14672909], train_hist_grp_loss: [ 8.08598343  8.92522863 18.38853767], cur_train_grp_loss: [0.09448475 0.10458545 0.21451827], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6590, max_kl_dist_index: 0, max_train_grp_loss:  13.0732, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6760, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2145, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:06:04,245 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  85, train_loss:  12.1559, val_loss:  12.4246, grad_norm: 0.0018, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6591, 0.3064, 0.6520, param: [5.4474086  8.28603705 5.16626811 8.60578833], weights: [0.32067925 0.32341453 0.35590622], train_wt_loss:  36.4677, val_wt_loss: 37.2738, train_grp_loss: [11.8107064  13.07315347 10.72572224], val_grp_loss: [12.67609959 12.45019091 12.14673228], train_hist_grp_loss: [ 8.18046863  9.02981397 18.60305403], cur_train_grp_loss: [0.0944852  0.10458534 0.21451636], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6591, max_kl_dist_index: 0, max_train_grp_loss:  13.0732, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6761, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2145, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:06:05,252 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  86, train_loss:  12.1559, val_loss:  12.4246, grad_norm: 0.0018, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6591, 0.3064, 0.6520, param: [5.44746231 8.28587684 5.16653461 8.60620533], weights: [0.32053177 0.32329844 0.35616979], train_wt_loss:  36.4677, val_wt_loss: 37.2739, train_grp_loss: [11.81076241 13.07314011 10.72562649], val_grp_loss: [12.67620201 12.45017842 12.14673539], train_hist_grp_loss: [ 8.27495428  9.1343992  18.81756847], cur_train_grp_loss: [0.09448565 0.10458523 0.21451444], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6591, max_kl_dist_index: 0, max_train_grp_loss:  13.0731, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6762, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2145, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:06:06,270 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  87, train_loss:  12.1559, val_loss:  12.4247, grad_norm: 0.0018, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6591, 0.3064, 0.6520, param: [5.44751594 8.28571677 5.16680124 8.60662291], weights: [0.32038427 0.3231823  0.35643344], train_wt_loss:  36.4677, val_wt_loss: 37.2740, train_grp_loss: [11.81081821 13.07312705 10.72553063], val_grp_loss: [12.67630426 12.45016628 12.14673843], train_hist_grp_loss: [ 8.36944038  9.23898432 19.032081  ], cur_train_grp_loss: [0.0944861  0.10458512 0.21451253], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6591, max_kl_dist_index: 0, max_train_grp_loss:  13.0731, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6763, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2145, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:06:07,308 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  88, train_loss:  12.1559, val_loss:  12.4247, grad_norm: 0.0018, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6591, 0.3065, 0.6520, param: [5.44756951 8.28555682 5.16706798 8.60704106], weights: [0.32023673 0.3230661  0.35669717], train_wt_loss:  36.4677, val_wt_loss: 37.2741, train_grp_loss: [11.81087381 13.0731143  10.72543466], val_grp_loss: [12.67640634 12.45015449 12.14674139], train_hist_grp_loss: [ 8.46392693  9.34356933 19.24659162], cur_train_grp_loss: [0.09448655 0.10458502 0.21451061], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6591, max_kl_dist_index: 0, max_train_grp_loss:  13.0731, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6764, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2145, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:06:08,327 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  89, train_loss:  12.1559, val_loss:  12.4247, grad_norm: 0.0018, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6592, 0.3065, 0.6521, param: [5.44762301 8.28539701 5.16733485 8.60745978], weights: [0.32008917 0.32294984 0.35696098], train_wt_loss:  36.4677, val_wt_loss: 37.2742, train_grp_loss: [11.8109292  13.07310185 10.72533858], val_grp_loss: [12.67650826 12.45014304 12.14674427], train_hist_grp_loss: [ 8.55841392  9.44815425 19.46110031], cur_train_grp_loss: [0.09448699 0.10458491 0.21450869], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6592, max_kl_dist_index: 0, max_train_grp_loss:  13.0731, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6765, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2145, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:06:09,344 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  90, train_loss:  12.1559, val_loss:  12.4247, grad_norm: 0.0019, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6592, 0.3065, 0.6521, param: [5.44767644 8.28523733 5.16760183 8.60787907], weights: [0.31994159 0.32283353 0.35722488], train_wt_loss:  36.4677, val_wt_loss: 37.2742, train_grp_loss: [11.81098438 13.07308971 10.72524239], val_grp_loss: [12.67661    12.45013194 12.14674707], train_hist_grp_loss: [ 8.65290135  9.55273906 19.67560708], cur_train_grp_loss: [0.09448743 0.10458481 0.21450677], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6592, max_kl_dist_index: 0, max_train_grp_loss:  13.0731, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6766, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2145, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:06:10,366 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  91, train_loss:  12.1559, val_loss:  12.4248, grad_norm: 0.0019, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6592, 0.3065, 0.6521, param: [5.4477298  8.28507779 5.16786893 8.60829893], weights: [0.31979397 0.32271717 0.35748886], train_wt_loss:  36.4677, val_wt_loss: 37.2743, train_grp_loss: [11.81103936 13.07307788 10.72514609], val_grp_loss: [12.67671157 12.45012119 12.14674979], train_hist_grp_loss: [ 8.74738923  9.65732378 19.89011193], cur_train_grp_loss: [0.09448788 0.10458472 0.21450485], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6592, max_kl_dist_index: 0, max_train_grp_loss:  13.0731, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6767, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2145, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:06:11,385 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  92, train_loss:  12.1559, val_loss:  12.4248, grad_norm: 0.0019, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6593, 0.3065, 0.6521, param: [5.4477831  8.28491837 5.16813616 8.60871937], weights: [0.31964634 0.32260075 0.35775291], train_wt_loss:  36.4677, val_wt_loss: 37.2744, train_grp_loss: [11.81109413 13.07306635 10.72504967], val_grp_loss: [12.67681298 12.45011079 12.14675244], train_hist_grp_loss: [ 8.84187754  9.7619084  20.10461485], cur_train_grp_loss: [0.09448831 0.10458462 0.21450292], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6593, max_kl_dist_index: 0, max_train_grp_loss:  13.0731, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6768, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2145, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:06:12,393 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  93, train_loss:  12.1559, val_loss:  12.4248, grad_norm: 0.0019, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6593, 0.3065, 0.6522, param: [5.44783632 8.28475908 5.1684035  8.60914037], weights: [0.31949867 0.32248428 0.35801705], train_wt_loss:  36.4677, val_wt_loss: 37.2745, train_grp_loss: [11.81114869 13.07305513 10.72495314], val_grp_loss: [12.67691421 12.45010074 12.146755  ], train_hist_grp_loss: [ 8.93636629  9.86649293 20.31911584], cur_train_grp_loss: [0.09448875 0.10458453 0.21450099], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6593, max_kl_dist_index: 0, max_train_grp_loss:  13.0731, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6769, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2145, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:06:13,410 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  94, train_loss:  12.1559, val_loss:  12.4249, grad_norm: 0.0020, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6593, 0.3065, 0.6522, param: [5.44788948 8.28459993 5.16867096 8.60956195], weights: [0.31935098 0.32236775 0.35828127], train_wt_loss:  36.4677, val_wt_loss: 37.2746, train_grp_loss: [11.81120305 13.07304422 10.7248565 ], val_grp_loss: [12.67701527 12.45009104 12.14675749], train_hist_grp_loss: [ 9.03085548  9.97107737 20.53361491], cur_train_grp_loss: [0.09448919 0.10458444 0.21449906], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6593, max_kl_dist_index: 0, max_train_grp_loss:  13.0730, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6770, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2145, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:06:14,424 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  95, train_loss:  12.1559, val_loss:  12.4249, grad_norm: 0.0020, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6594, 0.3066, 0.6522, param: [5.44794257 8.28444091 5.16893854 8.60998411], weights: [0.31920326 0.32225117 0.35854557], train_wt_loss:  36.4677, val_wt_loss: 37.2747, train_grp_loss: [11.8112572  13.07303361 10.72475975], val_grp_loss: [12.67711617 12.45008168 12.1467599 ], train_hist_grp_loss: [ 9.12534511 10.07566173 20.74811204], cur_train_grp_loss: [0.09448962 0.10458435 0.21449713], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6594, max_kl_dist_index: 0, max_train_grp_loss:  13.0730, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6771, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2145, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:06:15,432 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  96, train_loss:  12.1559, val_loss:  12.4249, grad_norm: 0.0020, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6594, 0.3066, 0.6523, param: [5.44799559 8.28428201 5.16920624 8.61040683], weights: [0.31905552 0.32213453 0.35880995], train_wt_loss:  36.4677, val_wt_loss: 37.2748, train_grp_loss: [11.81131115 13.07302331 10.72466289], val_grp_loss: [12.67721689 12.45007268 12.14676224], train_hist_grp_loss: [ 9.21983516 10.180246   20.96260723], cur_train_grp_loss: [0.09449006 0.10458427 0.2144952 ], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6594, max_kl_dist_index: 0, max_train_grp_loss:  13.0730, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6772, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2145, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:06:16,460 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  97, train_loss:  12.1559, val_loss:  12.4250, grad_norm: 0.0020, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6594, 0.3066, 0.6523, param: [5.44804855 8.28412325 5.16947407 8.61083013], weights: [0.31890775 0.32201784 0.35907441], train_wt_loss:  36.4678, val_wt_loss: 37.2749, train_grp_loss: [11.81136489 13.07301332 10.72456591], val_grp_loss: [12.67731745 12.45006402 12.14676449], train_hist_grp_loss: [ 9.31432565 10.28483018 21.17710049], cur_train_grp_loss: [0.09449049 0.10458419 0.21449326], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6594, max_kl_dist_index: 0, max_train_grp_loss:  13.0730, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6773, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2145, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:06:17,471 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  98, train_loss:  12.1559, val_loss:  12.4250, grad_norm: 0.0020, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6594, 0.3066, 0.6523, param: [5.44810143 8.28396462 5.16974201 8.611254  ], weights: [0.31875996 0.32190109 0.35933895], train_wt_loss:  36.4678, val_wt_loss: 37.2750, train_grp_loss: [11.81141842 13.07300363 10.72446883], val_grp_loss: [12.67741784 12.45005571 12.14676667], train_hist_grp_loss: [ 9.40881657 10.38941429 21.39159181], cur_train_grp_loss: [0.09449092 0.10458411 0.21449132], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6594, max_kl_dist_index: 0, max_train_grp_loss:  13.0730, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6774, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2145, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:06:18,467 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1546] - INFO: Iteration:  99, train_loss:  12.1559, val_loss:  12.4250, grad_norm: 0.0021, live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6595, 0.3066, 0.6523, param: [5.44815425 8.28380612 5.17001007 8.61167845], weights: [0.31861214 0.32178429 0.35960357], train_wt_loss:  36.4678, val_wt_loss: 37.2751, train_grp_loss: [11.81147175 13.07299425 10.72437163], val_grp_loss: [12.67751806 12.45004776 12.14676877], train_hist_grp_loss: [ 9.50330792 10.49399832 21.60608118], cur_train_grp_loss: [0.09449135 0.10458403 0.21448938], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6595, max_kl_dist_index: 0, max_train_grp_loss:  13.0730, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6775, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2145, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:06:19,393 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1654] - INFO: Iteration:  99, train_loss:  12.1559, val_loss:  12.4250, grad_norm: 0.0021,  live_grad: 0.0000, reward_err: 0.0102, 0.0142, 0.0001, KL_dist: 0.6595, 0.3066, 0.6523, param: [5.44815425 8.28380612 5.17001007 8.61167845], weights: [0.31861214 0.32178429 0.35960357], train_wt_loss:  36.4678, val_wt_loss: 37.2751, train_grp_loss: [11.81147175 13.07299425 10.72437163], val_grp_loss: [12.67751806 12.45004776 12.14676877], train_hist_grp_loss: [ 9.50330792 10.49399832 21.60608118], cur_train_grp_loss: [0.09449135 0.10458403 0.21448938], max_reward_err:  0.0142, max_reward_err_index: 1, max_kl_dist:  0.6595, max_kl_dist_index: 0, max_train_grp_loss:  13.0730, max_train_grp_loss_index: 1, max_val_grp_loss:  12.6775, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2145, max_cur_train_grp_loss_index: 2, 
2024-10-07 17:06:19,631 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:388] - INFO: Policy parameter learned solely on the preference data rdpo: [5.44815425 8.28380612 5.17001007 8.61167845].
2024-10-07 17:06:19,980 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Uniform reward: 3.8318, 3.8318, 3.1647
2024-10-07 17:06:19,980 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Optimal reward: 3.8678, 7.2446, 3.2763
2024-10-07 17:06:19,981 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Policy reward: 3.8283, 7.1413, 3.2759
2024-10-07 17:06:19,981 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:402] - INFO: Reward Error: 0.0102, 0.0142, 0.0001
2024-10-07 17:06:20,676 - /Users/noesis/Code/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:417] - INFO: Optimal reward: 3.8678, 7.2446, 3.2763
Known param reward: [[3.867779541015625, 6.77779443359375, 3.255072021484375], [3.441058349609375, 7.24455908203125, 3.05710986328125], [3.841189453125, 7.1339345703125, 3.27631982421875]], Known param reward error: [[0.0, 0.06442968345654335, 0.0064852651372159075], [0.11032717529039895, 0.0, 0.06690737556116683], [0.006874768225192712, 0.015270013049259644, 0.0]].
