2024-09-17 15:36:57,028 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:198] - INFO: Logging to log_dpo/2024_09_17_15_35_35/swapped_noise1.0_[1,1,1]_2022
2024-09-17 15:36:57,030 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: (IB) Seed: 2022
2024-09-17 15:36:57,031 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Data: 300
2024-09-17 15:36:57,193 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:296] - INFO: MLE reward loss: 0.3316, l2 distance: 39.4446, acc: 0.83.
2024-09-17 15:36:57,194 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-17 15:36:57,194 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: MLE reward parameter: [16.35863729  9.16281242 16.84987109  7.67203992]
2024-09-17 15:36:57,394 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:313] - INFO: Learned oracle reward: 3.6080, 3.8501, 3.2158
2024-09-17 15:36:58,679 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:947] - INFO: Iteration:  0, train_loss:  19.5405, val_loss:  19.3567, grad_norm: 0.7718, reward_err: 0.0827, 0.0183, 0.0490, KL_dist: 0.2890, 0.0513, 0.1768, param: [4.565038   2.56255758 3.06501675 0.98001647]train_grp_loss: [22.83835708 14.35579214 21.53828818], val_grp_loss: [22.88349092 13.95410493 21.56053381], train_hist_grp_loss: [22.86759488 14.46155466 21.58044446], cur_train_grp_loss: [22.86759488 14.46155466 21.58044446],max_reward_err:  0.0827, max_reward_err_index: 0, max_kl_dist:  0.2890, max_kl_dist_index: 0, max_train_grp_loss:  22.8384, max_train_grp_loss_index: 0, max_val_grp_loss:  22.8835, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  22.8676, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:37:01,704 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:947] - INFO: Iteration:  100, train_loss:  15.9871, val_loss:  15.7830, grad_norm: 0.4431, reward_err: 0.0712, 0.0041, 0.0368, KL_dist: 0.8791, 0.3991, 0.6773, param: [8.07602281 3.8978482  7.05746821 3.13865195]train_grp_loss: [20.95949116  8.53013363 18.64233784], val_grp_loss: [21.23406708  7.8899484  18.68734722], train_hist_grp_loss: [2199.12080956 1098.88733815 2013.30585591], cur_train_grp_loss: [20.97086328  8.55794493 18.66158572],max_reward_err:  0.0712, max_reward_err_index: 0, max_kl_dist:  0.8791, max_kl_dist_index: 0, max_train_grp_loss:  20.9595, max_train_grp_loss_index: 0, max_val_grp_loss:  21.2341, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  20.9709, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:37:04,734 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:947] - INFO: Iteration:  200, train_loss:  14.7942, val_loss:  14.7163, grad_norm: 0.2594, reward_err: 0.0747, 0.0027, 0.0394, KL_dist: 1.3414, 0.7164, 1.0795, param: [10.16589595  4.46737816  9.49600528  4.15736807]train_grp_loss: [20.22005781  7.0673602  17.28542446], val_grp_loss: [20.67135089  6.57432064 17.36144101], train_hist_grp_loss: [4252.89563315 1862.04368489 3802.21488924], cur_train_grp_loss: [20.22460784  7.07353453 17.29472858],max_reward_err:  0.0747, max_reward_err_index: 0, max_kl_dist:  1.3414, max_kl_dist_index: 0, max_train_grp_loss:  20.2201, max_train_grp_loss_index: 0, max_val_grp_loss:  20.6714, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  20.2246, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:37:07,886 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:947] - INFO: Iteration:  300, train_loss:  14.3810, val_loss:  14.4168, grad_norm: 0.1536, reward_err: 0.0754, 0.0016, 0.0399, KL_dist: 1.6389, 0.9247, 1.3385, param: [11.38980294  4.71037672 10.99456073  4.65382858]train_grp_loss: [19.91960352  6.80611785 16.61451134], val_grp_loss: [20.49389109  6.47376649 16.71437151], train_hist_grp_loss: [6257.85730959 2551.20707764 5493.78253697], cur_train_grp_loss: [19.92149657  6.80652314 16.61923474],max_reward_err:  0.0754, max_reward_err_index: 0, max_kl_dist:  1.6389, max_kl_dist_index: 0, max_train_grp_loss:  19.9196, max_train_grp_loss_index: 0, max_val_grp_loss:  20.4939, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  19.9215, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:37:10,988 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:947] - INFO: Iteration:  400, train_loss:  14.2350, val_loss:  14.3495, grad_norm: 0.0918, reward_err: 0.0754, 0.0011, 0.0398, KL_dist: 1.8226, 1.0538, 1.4981, param: [12.09258272  4.81391464 11.92442057  4.90311479]train_grp_loss: [19.79143463  6.84609698 16.26748512], val_grp_loss: [20.44839153  6.62618355 16.38275466], train_hist_grp_loss: [8242.61130643 3232.81616363 7136.22148552], cur_train_grp_loss: [19.79227368  6.84526593 16.26997997],max_reward_err:  0.0754, max_reward_err_index: 0, max_kl_dist:  1.8226, max_kl_dist_index: 0, max_train_grp_loss:  19.7914, max_train_grp_loss_index: 0, max_val_grp_loss:  20.4484, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  19.7923, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:37:14,045 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:947] - INFO: Iteration:  500, train_loss:  14.1826, val_loss:  14.3469, grad_norm: 0.0553, reward_err: 0.0754, 0.0008, 0.0398, KL_dist: 1.9344, 1.1324, 1.5950, param: [12.48509855  4.85776937 12.50943666  5.03135033]train_grp_loss: [19.73228197  6.93484363 16.08158425], val_grp_loss: [20.44451566  6.78378327 16.20589177], train_hist_grp_loss: [10218.47593747  3921.81017995  8752.82986442], cur_train_grp_loss: [19.73269245  6.93398595 16.08294102],max_reward_err:  0.0754, max_reward_err_index: 0, max_kl_dist:  1.9344, max_kl_dist_index: 0, max_train_grp_loss:  19.7323, max_train_grp_loss_index: 0, max_val_grp_loss:  20.4445, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  19.7327, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:37:17,087 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:947] - INFO: Iteration:  600, train_loss:  14.1633, val_loss:  14.3582, grad_norm: 0.0339, reward_err: 0.0767, 0.0007, 0.0410, KL_dist: 2.0019, 1.1797, 1.6535, param: [12.69489036  4.87602979 12.88439739  5.09830587]train_grp_loss: [19.70163043  7.01004102 15.97953743], val_grp_loss: [20.45125785  6.898085   16.1087071 ], train_hist_grp_loss: [12190.03829242  4619.20186063 10355.43772442], cur_train_grp_loss: [19.7018596   7.00940163 15.98028914],max_reward_err:  0.0767, max_reward_err_index: 0, max_kl_dist:  2.0019, max_kl_dist_index: 0, max_train_grp_loss:  19.7016, max_train_grp_loss_index: 0, max_val_grp_loss:  20.4513, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  19.7019, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:37:20,125 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:947] - INFO: Iteration:  700, train_loss:  14.1559, val_loss:  14.3691, grad_norm: 0.0213, reward_err: 0.0768, 0.0005, 0.0410, KL_dist: 2.0428, 1.2081, 1.6889, param: [12.79846061  4.88330261 13.13048078  5.13331945]train_grp_loss: [19.68335541  7.06303495 15.92273714], val_grp_loss: [20.45885122  6.97169047 16.05421955], train_hist_grp_loss: [14159.22946028  5323.00297881 11950.30588339], cur_train_grp_loss: [19.68350267  7.06260384 15.92315707],max_reward_err:  0.0768, max_reward_err_index: 0, max_kl_dist:  2.0428, max_kl_dist_index: 0, max_train_grp_loss:  19.6834, max_train_grp_loss_index: 0, max_val_grp_loss:  20.4589, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  19.6835, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:37:23,298 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:947] - INFO: Iteration:  800, train_loss:  14.1529, val_loss:  14.3768, grad_norm: 0.0140, reward_err: 0.0775, 0.0005, 0.0417, KL_dist: 2.0675, 1.2251, 1.7103, param: [12.84136714  4.88586924 13.29665968  5.15129867]train_grp_loss: [19.67090862  7.09804951 15.89101195], val_grp_loss: [20.46482579  7.0163502  16.02332423], train_hist_grp_loss: [16126.91520107  6031.16488791 13540.85559572], cur_train_grp_loss: [19.67101497  7.09776911 15.89124597],max_reward_err:  0.0775, max_reward_err_index: 0, max_kl_dist:  2.0675, max_kl_dist_index: 0, max_train_grp_loss:  19.6709, max_train_grp_loss_index: 0, max_val_grp_loss:  20.4648, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  19.6710, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:37:26,443 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:947] - INFO: Iteration:  900, train_loss:  14.1515, val_loss:  14.3817, grad_norm: 0.0098, reward_err: 0.0781, 0.0005, 0.0423, KL_dist: 2.0825, 1.2353, 1.7233, param: [12.85054093  4.88644241 13.41257623  5.16006092]train_grp_loss: [19.66154353  7.12070985 15.87343342], val_grp_loss: [20.46900566  7.0423792  16.0057524 ], train_hist_grp_loss: [18093.52327578  6742.17384982 15128.99938727], cur_train_grp_loss: [19.66162661  7.12052874 15.87356185],max_reward_err:  0.0781, max_reward_err_index: 0, max_kl_dist:  2.0825, max_kl_dist_index: 0, max_train_grp_loss:  19.6615, max_train_grp_loss_index: 0, max_val_grp_loss:  20.4690, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  19.6616, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:37:29,602 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:947] - INFO: Iteration:  1000, train_loss:  14.1508, val_loss:  14.3846, grad_norm: 0.0073, reward_err: 0.0791, 0.0005, 0.0431, KL_dist: 2.0917, 1.2414, 1.7313, param: [12.84176347  4.88619842 13.49626711  5.16381474]train_grp_loss: [19.6540452   7.13539769 15.86391611], val_grp_loss: [20.47178932  7.05698408 15.99581278], train_hist_grp_loss: [20059.29392864  7455.02405561 16715.82175355], cur_train_grp_loss: [19.65411316  7.13527955 15.86398422],max_reward_err:  0.0791, max_reward_err_index: 0, max_kl_dist:  2.0917, max_kl_dist_index: 0, max_train_grp_loss:  19.6540, max_train_grp_loss_index: 0, max_val_grp_loss:  20.4718, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  19.6541, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:37:32,809 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:947] - INFO: Iteration:  1100, train_loss:  14.1504, val_loss:  14.3861, grad_norm: 0.0058, reward_err: 0.0791, 0.0005, 0.0431, KL_dist: 2.0975, 1.2450, 1.7363, param: [12.82417525  4.88564838 13.55879284  5.16487101]train_grp_loss: [19.64782946  7.14506655 15.85900519], val_grp_loss: [20.47361016  7.06478339 15.99027991], train_hist_grp_loss: [22024.3816543   8169.07509174 18301.94181137], cur_train_grp_loss: [19.64788643  7.14498784 15.85903887],max_reward_err:  0.0791, max_reward_err_index: 0, max_kl_dist:  2.0975, max_kl_dist_index: 0, max_train_grp_loss:  19.6478, max_train_grp_loss_index: 0, max_val_grp_loss:  20.4736, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  19.6479, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:37:35,950 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:947] - INFO: Iteration:  1200, train_loss:  14.1501, val_loss:  14.3869, grad_norm: 0.0048, reward_err: 0.0791, 0.0005, 0.0431, KL_dist: 2.1011, 1.2472, 1.7395, param: [12.80298102  4.8850134  13.60701055  5.16451459]train_grp_loss: [19.64258111  7.15159356 15.85671442], val_grp_loss: [20.47480277  7.06861677 15.98729747], train_hist_grp_loss: [23988.89767575  8883.92531292 19887.71284072], cur_train_grp_loss: [19.64262951  7.15153958 15.85672862],max_reward_err:  0.0791, max_reward_err_index: 0, max_kl_dist:  2.1011, max_kl_dist_index: 0, max_train_grp_loss:  19.6426, max_train_grp_loss_index: 0, max_val_grp_loss:  20.4748, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  19.6426, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:37:39,140 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:947] - INFO: Iteration:  1300, train_loss:  14.1499, val_loss:  14.3872, grad_norm: 0.0041, reward_err: 0.0791, 0.0005, 0.0431, KL_dist: 2.1034, 1.2485, 1.7416, param: [12.7810668   4.88438717 13.64523494  5.16346315]train_grp_loss: [19.63810643  7.15614131 15.85589392], val_grp_loss: [20.47559624  7.07019029 15.9857866 ], train_hist_grp_loss: [25952.92846626  9599.32277422 21473.33474513], cur_train_grp_loss: [19.63814782  7.15610301 15.85589732],max_reward_err:  0.0791, max_reward_err_index: 0, max_kl_dist:  2.1034, max_kl_dist_index: 0, max_train_grp_loss:  19.6381, max_train_grp_loss_index: 0, max_val_grp_loss:  20.4756, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  19.6381, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:37:42,272 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:947] - INFO: Iteration:  1400, train_loss:  14.1498, val_loss:  14.3873, grad_norm: 0.0035, reward_err: 0.0789, 0.0005, 0.0429, KL_dist: 2.1050, 1.2493, 1.7430, param: [12.75996331  4.883807   13.67623419  5.16211583]train_grp_loss: [19.63427134  7.15942301 15.85587657], val_grp_loss: [20.47613865  7.0705135  15.98511678], train_hist_grp_loss: [27916.54440226 10315.10775388 23058.91851494], cur_train_grp_loss: [19.63430688  7.15939485 15.8558742 ],max_reward_err:  0.0789, max_reward_err_index: 0, max_kl_dist:  2.1050, max_kl_dist_index: 0, max_train_grp_loss:  19.6343, max_train_grp_loss_index: 0, max_val_grp_loss:  20.4761, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  19.6343, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:37:45,426 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:947] - INFO: Iteration:  1500, train_loss:  14.1496, val_loss:  14.3873, grad_norm: 0.0030, reward_err: 0.0789, 0.0005, 0.0429, KL_dist: 2.1061, 1.2498, 1.7440, param: [12.74041778  4.88328522 13.70182815  5.16069103]train_grp_loss: [19.63097468  7.16187622 15.85627638], val_grp_loss: [20.4765228   7.0701763  15.98491888], train_hist_grp_loss: [29879.80422704 11031.17707101 24644.52359751], cur_train_grp_loss: [19.63100526  7.1618548  15.85627114],max_reward_err:  0.0789, max_reward_err_index: 0, max_kl_dist:  2.1061, max_kl_dist_index: 0, max_train_grp_loss:  19.6310, max_train_grp_loss_index: 0, max_val_grp_loss:  20.4765, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  19.6310, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:37:48,644 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:947] - INFO: Iteration:  1600, train_loss:  14.1496, val_loss:  14.3872, grad_norm: 0.0026, reward_err: 0.0792, 0.0005, 0.0432, KL_dist: 2.1069, 1.2501, 1.7447, param: [12.72273221  4.88282314 13.72324856  5.15930421]train_grp_loss: [19.62813576  7.16377129 15.85687182], val_grp_loss: [20.47680591  7.06951862 15.98497711], train_hist_grp_loss: [31842.75764997 11747.46232683 26230.17971087], cur_train_grp_loss: [19.62816211  7.16375449 15.85686536],max_reward_err:  0.0792, max_reward_err_index: 0, max_kl_dist:  2.1069, max_kl_dist_index: 0, max_train_grp_loss:  19.6281, max_train_grp_loss_index: 0, max_val_grp_loss:  20.4768, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  19.6282, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:37:51,782 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:947] - INFO: Iteration:  1700, train_loss:  14.1495, val_loss:  14.3870, grad_norm: 0.0022, reward_err: 0.0792, 0.0005, 0.0432, KL_dist: 2.1075, 1.2502, 1.7453, param: [12.70696218  4.88241742 13.74135691  5.15801232]train_grp_loss: [19.62568813  7.16527746 15.85753776], val_grp_loss: [20.47702297  7.06873276 15.98516605], train_hist_grp_loss: [33805.44705406 12463.91673049 27815.89961964], cur_train_grp_loss: [19.62571086  7.16526393 15.85753101],max_reward_err:  0.0792, max_reward_err_index: 0, max_kl_dist:  2.1075, max_kl_dist_index: 0, max_train_grp_loss:  19.6257, max_train_grp_loss_index: 0, max_val_grp_loss:  20.4770, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  19.6257, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:37:55,022 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:947] - INFO: Iteration:  1800, train_loss:  14.1495, val_loss:  14.3869, grad_norm: 0.0019, reward_err: 0.0792, 0.0005, 0.0432, KL_dist: 2.1080, 1.2503, 1.7457, param: [12.69303299  4.88206296 13.75677695  5.15683941]train_grp_loss: [19.62357609  7.16650268 15.85820548], val_grp_loss: [20.47719543  7.06792448 15.98541358], train_hist_grp_loss: [35767.90873276 13180.50712772 29401.68661944], cur_train_grp_loss: [19.62359571  7.16649156 15.85819893],max_reward_err:  0.0792, max_reward_err_index: 0, max_kl_dist:  2.1080, max_kl_dist_index: 0, max_train_grp_loss:  19.6236, max_train_grp_loss_index: 0, max_val_grp_loss:  20.4772, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  19.6236, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:37:58,357 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:947] - INFO: Iteration:  1900, train_loss:  14.1494, val_loss:  14.3867, grad_norm: 0.0017, reward_err: 0.0796, 0.0005, 0.0435, KL_dist: 2.1084, 1.2504, 1.7461, param: [12.68080666  4.88175423 13.76997597  5.15579135]train_grp_loss: [19.6217525   7.16751754 15.85883912], val_grp_loss: [20.47733652  7.06714926 15.98567901], train_hist_grp_loss: [37730.17384772 13897.20915844 30987.5389083 ], cur_train_grp_loss: [19.62176944  7.16750826 15.85883301],max_reward_err:  0.0796, max_reward_err_index: 0, max_kl_dist:  2.1084, max_kl_dist_index: 0, max_train_grp_loss:  19.6218, max_train_grp_loss_index: 0, max_val_grp_loss:  20.4773, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  19.6218, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:38:01,454 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:1040] - INFO: Iteration:  1999, train_loss:  14.1494, val_loss:  14.3866, grad_norm: 0.0015, reward_err: 0.0799, 0.0005, 0.0438, KL_dist: 2.1087, 1.2505, 1.7464, param: [12.67021978  4.88148832 13.78121005  5.15487308]train_grp_loss: [19.62019181  7.16836179 15.85941619], val_grp_loss: [20.47745345  7.06644051 15.98593759], train_hist_grp_loss: [39672.64900958 14606.83592968 32557.59270622], cur_train_grp_loss: [19.62020648  7.16835395 15.85941064],max_reward_err:  0.0799, max_reward_err_index: 0, max_kl_dist:  2.1087, max_kl_dist_index: 0, max_train_grp_loss:  19.6202, max_train_grp_loss_index: 0, max_val_grp_loss:  20.4775, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  19.6202, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:38:01,676 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:386] - INFO: Policy parameter learned solely on the preference data dpo: [12.67021978  4.88148832 13.78121005  5.15487308].
2024-09-17 15:38:02,010 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:397] - INFO: Uniform reward: 3.8395, 3.8395, 3.1958
2024-09-17 15:38:02,011 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Optimal reward: 3.8707, 3.8707, 3.3276
2024-09-17 15:38:02,011 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Policy reward: 3.5616, 3.8690, 3.1818
2024-09-17 15:38:02,012 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Reward Error: 0.0799, 0.0005, 0.0438
2024-09-17 15:38:02,737 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:415] - INFO: Optimal reward: 3.8707, 3.8707, 3.3276
Known param reward: [[3.870737075805664, 3.5440561771392822, 3.277423858642578], [3.5440561771392822, 3.870737075805664, 3.1691665649414062], [3.8269641399383545, 3.639406681060791, 3.327569007873535]], Known param reward error: [[0.0, 0.08439759463599984, 0.015069604600928176], [0.08439759463599984, 0.0, 0.04760305272627693], [0.011308682302633167, 0.059763913232655674, 0.0]].
