2024-09-17 15:35:39,952 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:198] - INFO: Logging to log_dpo/2024_09_17_15_35_35/swapped_noise1.0_[1,1,1]_2021
2024-09-17 15:35:39,953 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: (IB) Seed: 2021
2024-09-17 15:35:39,954 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Data: 300
2024-09-17 15:35:40,120 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:296] - INFO: MLE reward loss: 0.3558, l2 distance: 33.1024, acc: 0.82.
2024-09-17 15:35:40,121 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-17 15:35:40,122 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: MLE reward parameter: [13.32826759  7.48737825 15.0322688   7.4309059 ]
2024-09-17 15:35:40,323 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:313] - INFO: Learned oracle reward: 3.5551, 3.8681, 3.1638
2024-09-17 15:35:41,612 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:947] - INFO: Iteration:  0, train_loss:  20.4470, val_loss:  20.2312, grad_norm: 0.8598, reward_err: 0.0634, 0.0581, 0.0288, KL_dist: 0.1248, 0.1097, 0.0558, param: [2.87849015 3.42812422 2.58210452 0.53704304]train_grp_loss: [22.9675198  16.4020049  22.26450646], val_grp_loss: [22.67139457 15.81399756 22.29361026], train_hist_grp_loss: [22.99467598 16.54526611 22.31027286], cur_train_grp_loss: [22.99467598 16.54526611 22.31027286],max_reward_err:  0.0634, max_reward_err_index: 0, max_kl_dist:  0.1248, max_kl_dist_index: 0, max_train_grp_loss:  22.9675, max_train_grp_loss_index: 0, max_val_grp_loss:  22.6714, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  22.9947, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:35:44,696 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:947] - INFO: Iteration:  100, train_loss:  16.2433, val_loss:  16.1364, grad_norm: 0.4680, reward_err: 0.0821, 0.0052, 0.0422, KL_dist: 0.7109, 0.3400, 0.5389, param: [6.69693701 4.21706596 7.01492268 2.98127574]train_grp_loss: [21.38635358  8.61259891 19.26350338], val_grp_loss: [20.75299514  8.15920502 19.64214589], train_hist_grp_loss: [2226.03860538 1186.67122342 2078.26004024], cur_train_grp_loss: [21.39449052  8.65019644 19.28234385],max_reward_err:  0.0821, max_reward_err_index: 0, max_kl_dist:  0.7109, max_kl_dist_index: 0, max_train_grp_loss:  21.3864, max_train_grp_loss_index: 0, max_val_grp_loss:  20.7530, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  21.3945, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:35:47,834 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:947] - INFO: Iteration:  200, train_loss:  14.9539, val_loss:  14.9132, grad_norm: 0.2647, reward_err: 0.0930, 0.0017, 0.0515, KL_dist: 1.1956, 0.6366, 0.9554, param: [8.83735422 4.41721202 9.66390825 3.94963233]train_grp_loss: [20.94016426  6.50918173 17.98620007], val_grp_loss: [20.16718661  6.14011215 18.58442599], train_hist_grp_loss: [4337.60975879 1922.00114122 3932.8261677 ], cur_train_grp_loss: [20.94216697  6.51965928 17.99457165],max_reward_err:  0.0930, max_reward_err_index: 0, max_kl_dist:  1.1956, max_kl_dist_index: 0, max_train_grp_loss:  20.9402, max_train_grp_loss_index: 0, max_val_grp_loss:  20.1672, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  20.9422, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:35:50,923 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:947] - INFO: Iteration:  300, train_loss:  14.5326, val_loss:  14.5411, grad_norm: 0.1533, reward_err: 0.0992, 0.0006, 0.0570, KL_dist: 1.5066, 0.8381, 1.2234, param: [10.01733529  4.44114324 11.27083275  4.32950775]train_grp_loss: [20.85253672  5.92001453 17.39909913], val_grp_loss: [20.01293355  5.61630497 18.14329894], train_hist_grp_loss: [6425.78993576 2537.65523997 5698.8180467 ], cur_train_grp_loss: [20.85268686  5.92293172 17.40311702],max_reward_err:  0.0992, max_reward_err_index: 0, max_kl_dist:  1.5066, max_kl_dist_index: 0, max_train_grp_loss:  20.8525, max_train_grp_loss_index: 0, max_val_grp_loss:  20.0129, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  20.8527, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:35:53,966 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:947] - INFO: Iteration:  400, train_loss:  14.3890, val_loss:  14.4336, grad_norm: 0.0905, reward_err: 0.1026, 0.0001, 0.0601, KL_dist: 1.6981, 0.9631, 1.3886, param: [10.64859342  4.4232615  12.26385472  4.4754891 ]train_grp_loss: [20.86666893  5.76024803 17.10732103], val_grp_loss: [19.99041833  5.50334769 17.95277873], train_hist_grp_loss: [8511.37616956 3119.99034372 7422.69779689], cur_train_grp_loss: [20.86636072  5.76098874 17.1094055 ],max_reward_err:  0.1026, max_reward_err_index: 0, max_kl_dist:  1.6981, max_kl_dist_index: 0, max_train_grp_loss:  20.8667, max_train_grp_loss_index: 0, max_val_grp_loss:  19.9904, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  20.8664, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:35:57,076 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:947] - INFO: Iteration:  500, train_loss:  14.3380, val_loss:  14.4086, grad_norm: 0.0547, reward_err: 0.1044, 0.0001, 0.0617, KL_dist: 1.8149, 1.0383, 1.4895, param: [10.9682359   4.40285855 12.8918421   4.52918479]train_grp_loss: [20.90104879  5.72364683 16.95062742], val_grp_loss: [20.00185294  5.49811469 17.86902084], train_hist_grp_loss: [10599.71795891  3693.70836614  9124.91814388], cur_train_grp_loss: [20.90070266  5.72377385 16.95179349],max_reward_err:  0.1044, max_reward_err_index: 0, max_kl_dist:  1.8149, max_kl_dist_index: 0, max_train_grp_loss:  20.9010, max_train_grp_loss_index: 0, max_val_grp_loss:  20.0019, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  20.9007, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:36:00,157 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:947] - INFO: Iteration:  600, train_loss:  14.3188, val_loss:  14.4080, grad_norm: 0.0343, reward_err: 0.1054, 0.0001, 0.0627, KL_dist: 1.8865, 1.0830, 1.5516, param: [11.11294599  4.38861374 13.30032673  4.54699947]train_grp_loss: [20.9326798   5.72070452 16.86006099], val_grp_loss: [20.01754133  5.51553976 17.83286123], train_hist_grp_loss: [12691.44364771  4265.80202858 10815.11341103], cur_train_grp_loss: [20.93239825  5.72067525 16.86076054],max_reward_err:  0.1054, max_reward_err_index: 0, max_kl_dist:  1.8865, max_kl_dist_index: 0, max_train_grp_loss:  20.9327, max_train_grp_loss_index: 0, max_val_grp_loss:  20.0175, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  20.9324, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:36:03,192 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:947] - INFO: Iteration:  700, train_loss:  14.3109, val_loss:  14.4138, grad_norm: 0.0228, reward_err: 0.1070, 0.0000, 0.0642, KL_dist: 1.9309, 1.1094, 1.5904, param: [11.16138801  4.38048083 13.57492125  4.55126475]train_grp_loss: [20.95711877  5.72551678 16.80407627], val_grp_loss: [20.03004057  5.53350816 17.81876855], train_hist_grp_loss: [14785.98141709  4838.08916179 12498.13984059], cur_train_grp_loss: [20.95690905  5.72546001 16.8045233 ],max_reward_err:  0.1070, max_reward_err_index: 0, max_kl_dist:  1.9309, max_kl_dist_index: 0, max_train_grp_loss:  20.9571, max_train_grp_loss_index: 0, max_val_grp_loss:  20.0300, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  20.9569, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:36:06,255 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:947] - INFO: Iteration:  800, train_loss:  14.3072, val_loss:  14.4203, grad_norm: 0.0162, reward_err: 0.1096, 0.0000, 0.0665, KL_dist: 1.9589, 1.1251, 1.6152, param: [11.15863249  4.37664071 13.76632846  4.55071801]train_grp_loss: [20.97509062  5.7310656  16.76732223], val_grp_loss: [20.03860999  5.54767229 17.8151617 ], train_hist_grp_loss: [16882.62990617  5410.91970285 14176.60841258], cur_train_grp_loss: [20.9749374   5.73101343 16.7676244 ],max_reward_err:  0.1096, max_reward_err_index: 0, max_kl_dist:  1.9589, max_kl_dist_index: 0, max_train_grp_loss:  20.9751, max_train_grp_loss_index: 0, max_val_grp_loss:  20.0386, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  20.9749, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:36:09,282 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:947] - INFO: Iteration:  900, train_loss:  14.3052, val_loss:  14.4261, grad_norm: 0.0124, reward_err: 0.1109, 0.0000, 0.0678, KL_dist: 1.9772, 1.1343, 1.6315, param: [11.13029223  4.37542772 13.90482705  4.54870211]train_grp_loss: [20.98826323  5.73578955 16.74187639], val_grp_loss: [20.04413436  5.5581923  17.81653289], train_hist_grp_loss: [18980.8243273   5984.26834695 15852.00857514], cur_train_grp_loss: [20.98815014  5.73574719 16.74209095],max_reward_err:  0.1109, max_reward_err_index: 0, max_kl_dist:  1.9772, max_kl_dist_index: 0, max_train_grp_loss:  20.9883, max_train_grp_loss_index: 0, max_val_grp_loss:  20.0441, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  20.9882, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:36:12,338 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:947] - INFO: Iteration:  1000, train_loss:  14.3040, val_loss:  14.4311, grad_norm: 0.0100, reward_err: 0.1123, 0.0000, 0.0692, KL_dist: 1.9895, 1.1398, 1.6427, param: [11.09072594  4.37568215 14.00869607  4.54644147]train_grp_loss: [20.99809048  5.7395743  16.72342815], val_grp_loss: [20.04761047  5.56601636 17.82015866], train_hist_grp_loss: [21080.16001433  6558.04180758 17525.23695078], cur_train_grp_loss: [20.99800501  5.73954053 16.72358708],max_reward_err:  0.1123, max_reward_err_index: 0, max_kl_dist:  1.9895, max_kl_dist_index: 0, max_train_grp_loss:  20.9981, max_train_grp_loss_index: 0, max_val_grp_loss:  20.0476, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  20.9980, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:36:15,400 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:947] - INFO: Iteration:  1100, train_loss:  14.3031, val_loss:  14.4353, grad_norm: 0.0083, reward_err: 0.1127, 0.0000, 0.0695, KL_dist: 1.9982, 1.1430, 1.6507, param: [11.04780499  4.37668078 14.08913034  4.5443443 ]train_grp_loss: [21.00561753  5.74260532 16.70952087], val_grp_loss: [20.04979368  5.57197334 17.82465826], train_hist_grp_loss: [23180.35745471  7132.15469192 19196.8606977 ], cur_train_grp_loss: [21.00555111  5.74257808 16.70964282],max_reward_err:  0.1127, max_reward_err_index: 0, max_kl_dist:  1.9982, max_kl_dist_index: 0, max_train_grp_loss:  21.0056, max_train_grp_loss_index: 0, max_val_grp_loss:  20.0498, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  21.0056, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:36:18,459 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:947] - INFO: Iteration:  1200, train_loss:  14.3025, val_loss:  14.4389, grad_norm: 0.0071, reward_err: 0.1121, 0.0000, 0.0691, KL_dist: 2.0045, 1.1450, 1.6566, param: [11.00568301  4.37800021 14.15311663  4.5425153 ]train_grp_loss: [21.0115443   5.74507353 16.69869568], val_grp_loss: [20.05118619  5.5766423  17.82932766], train_hist_grp_loss: [25281.223714    7706.54142067 20867.25563637], cur_train_grp_loss: [21.0114913   5.74505113 16.69879196],max_reward_err:  0.1121, max_reward_err_index: 0, max_kl_dist:  2.0045, max_kl_dist_index: 0, max_train_grp_loss:  21.0115, max_train_grp_loss_index: 0, max_val_grp_loss:  20.0512, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  21.0115, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:36:21,536 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:947] - INFO: Iteration:  1300, train_loss:  14.3021, val_loss:  14.4419, grad_norm: 0.0060, reward_err: 0.1118, 0.0000, 0.0690, KL_dist: 2.0093, 1.1462, 1.6612, param: [10.96640323  4.3794046  14.20512172  4.54095398]train_grp_loss: [21.01632808  5.74712093 16.69005248], val_grp_loss: [20.05210185  5.58040121 17.83381577], train_hist_grp_loss: [27382.62303015  8281.15316237 22536.68195788], cur_train_grp_loss: [21.01628482  5.74710219 16.69013019],max_reward_err:  0.1118, max_reward_err_index: 0, max_kl_dist:  2.0093, max_kl_dist_index: 0, max_train_grp_loss:  21.0163, max_train_grp_loss_index: 0, max_val_grp_loss:  20.0521, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  21.0163, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:36:24,566 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:947] - INFO: Iteration:  1400, train_loss:  14.3018, val_loss:  14.4445, grad_norm: 0.0052, reward_err: 0.1118, 0.0000, 0.0690, KL_dist: 2.0130, 1.1470, 1.6648, param: [10.93082894  4.38076964 14.24808649  4.53962898]train_grp_loss: [21.02026771  5.74884518 16.68301474], val_grp_loss: [20.0527302   5.58349363 17.8379594 ], train_hist_grp_loss: [29484.45693702  8855.95298277 24205.32728267], cur_train_grp_loss: [21.02023178  5.7488293  16.68307854],max_reward_err:  0.1118, max_reward_err_index: 0, max_kl_dist:  2.0130, max_kl_dist_index: 0, max_train_grp_loss:  21.0203, max_train_grp_loss_index: 0, max_val_grp_loss:  20.0527, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  21.0202, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:36:27,638 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:947] - INFO: Iteration:  1500, train_loss:  14.3016, val_loss:  14.4468, grad_norm: 0.0044, reward_err: 0.1120, 0.0000, 0.0692, KL_dist: 2.0161, 1.1474, 1.6677, param: [10.89917981  4.3820352  14.28401405  4.53850432]train_grp_loss: [21.02356186  5.75031311 16.67719904], val_grp_loss: [20.05318345  5.58607892 17.84169617], train_hist_grp_loss: [31586.65150577  9430.91207963 25873.33194102], cur_train_grp_loss: [21.02353163  5.75029954 16.67725209],max_reward_err:  0.1120, max_reward_err_index: 0, max_kl_dist:  2.0161, max_kl_dist_index: 0, max_train_grp_loss:  21.0236, max_train_grp_loss_index: 0, max_val_grp_loss:  20.0532, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  21.0235, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:36:30,775 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:947] - INFO: Iteration:  1600, train_loss:  14.3014, val_loss:  14.4487, grad_norm: 0.0038, reward_err: 0.1112, 0.0000, 0.0685, KL_dist: 2.0186, 1.1478, 1.6702, param: [10.87133898  4.38317703 14.3143198   4.53754758]train_grp_loss: [21.0263465   5.75157181 16.67234052], val_grp_loss: [20.05352734  5.58826479 17.84501713], train_hist_grp_loss: [33689.14932732 10006.00728085 27540.80425442], cur_train_grp_loss: [21.02632084  5.75156014 16.67238504],max_reward_err:  0.1112, max_reward_err_index: 0, max_kl_dist:  2.0186, max_kl_dist_index: 0, max_train_grp_loss:  21.0263, max_train_grp_loss_index: 0, max_val_grp_loss:  20.0535, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  21.0263, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:36:33,812 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:947] - INFO: Iteration:  1700, train_loss:  14.3013, val_loss:  14.4504, grad_norm: 0.0033, reward_err: 0.1112, 0.0000, 0.0685, KL_dist: 2.0207, 1.1480, 1.6723, param: [10.84702703  4.38419024 14.34004148  4.53673159]train_grp_loss: [21.02871821  5.75265586 16.66824925], val_grp_loss: [20.05380021  5.59012706 17.8479407 ], train_hist_grp_loss: [35791.90448977 10581.21945695 29207.83004311], cur_train_grp_loss: [21.02869628  5.75264579 16.66828686],max_reward_err:  0.1112, max_reward_err_index: 0, max_kl_dist:  2.0207, max_kl_dist_index: 0, max_train_grp_loss:  21.0287, max_train_grp_loss_index: 0, max_val_grp_loss:  20.0538, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  21.0287, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:36:36,919 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:947] - INFO: Iteration:  1800, train_loss:  14.3012, val_loss:  14.4518, grad_norm: 0.0028, reward_err: 0.1112, 0.0000, 0.0685, KL_dist: 2.0224, 1.1481, 1.6740, param: [10.82589895  4.38507994 14.36196676  4.53603404]train_grp_loss: [21.03074833  5.75359187 16.66478423], val_grp_loss: [20.05402457  5.59172155 17.85049815], train_hist_grp_loss: [37894.87939918 11156.53251396 30874.47872287], cur_train_grp_loss: [21.03072953  5.75358317 16.66481615],max_reward_err:  0.1112, max_reward_err_index: 0, max_kl_dist:  2.0224, max_kl_dist_index: 0, max_train_grp_loss:  21.0307, max_train_grp_loss_index: 0, max_val_grp_loss:  20.0540, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  21.0307, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:36:39,953 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:947] - INFO: Iteration:  1900, train_loss:  14.3011, val_loss:  14.4531, grad_norm: 0.0024, reward_err: 0.1112, 0.0000, 0.0685, KL_dist: 2.0239, 1.1482, 1.6755, param: [10.80759672  4.3858559  14.38071184  4.53543664]train_grp_loss: [21.03249168  5.75440111 16.66183741], val_grp_loss: [20.05421377  5.59309107 17.85272563], train_hist_grp_loss: [39998.04272242 11731.93273715 32540.80734366], cur_train_grp_loss: [21.03247552  5.75439359 16.66186461],max_reward_err:  0.1112, max_reward_err_index: 0, max_kl_dist:  2.0239, max_kl_dist_index: 0, max_train_grp_loss:  21.0325, max_train_grp_loss_index: 0, max_val_grp_loss:  20.0542, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  21.0325, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:36:43,088 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:1040] - INFO: Iteration:  1999, train_loss:  14.3011, val_loss:  14.4541, grad_norm: 0.0021, reward_err: 0.1112, 0.0000, 0.0685, KL_dist: 2.0252, 1.1483, 1.6768, param: [10.79192349  4.38652339 14.39662229  4.53492905]train_grp_loss: [21.03397783  5.75509461 16.65934705], val_grp_loss: [20.05437452  5.59425868 17.85464184], train_hist_grp_loss: [42080.3340348  12301.6532493  34190.20401141], cur_train_grp_loss: [21.03396389  5.75508809 16.65937031],max_reward_err:  0.1112, max_reward_err_index: 0, max_kl_dist:  2.0252, max_kl_dist_index: 0, max_train_grp_loss:  21.0340, max_train_grp_loss_index: 0, max_val_grp_loss:  20.0544, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  21.0340, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:36:43,306 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:386] - INFO: Policy parameter learned solely on the preference data dpo: [10.79192349  4.38652339 14.39662229  4.53492905].
2024-09-17 15:36:43,627 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:397] - INFO: Uniform reward: 3.8482, 3.8482, 3.1986
2024-09-17 15:36:43,627 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Optimal reward: 3.8836, 3.8836, 3.3119
2024-09-17 15:36:43,628 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Policy reward: 3.4519, 3.8834, 3.0850
2024-09-17 15:36:43,628 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Reward Error: 0.1112, 0.0000, 0.0685
2024-09-17 15:36:44,315 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:415] - INFO: Optimal reward: 3.8836, 3.8836, 3.3119
Known param reward: [[3.8835737705230713, 3.457217216491699, 3.288090705871582], [3.457217216491699, 3.8835737705230713, 3.0940170288085938], [3.8489270210266113, 3.5929198265075684, 3.3118627071380615]], Known param reward error: [[0.0, 0.10978458997418425, 0.007177834158174392], [0.10978458997418425, 0.0, 0.06577738801187161], [0.00892135737434272, 0.07484187534214273, 0.0]].
