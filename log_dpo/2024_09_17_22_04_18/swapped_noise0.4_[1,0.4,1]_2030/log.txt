2024-09-17 22:07:14,005 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:198] - INFO: Logging to log_dpo/2024_09_17_22_04_18/swapped_noise0.4_[1,0.4,1]_2030
2024-09-17 22:07:14,007 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: (IB) Seed: 2030
2024-09-17 22:07:14,008 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Data: 300
2024-09-17 22:07:14,164 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:296] - INFO: MLE reward loss: 0.4881, l2 distance: 13.8543, acc: 0.79.
2024-09-17 22:07:14,165 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-17 22:07:14,166 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: MLE reward parameter: [6.31481093 3.67149309 7.88828903 3.60917669]
2024-09-17 22:07:14,366 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:313] - INFO: Learned oracle reward: 3.4730, 3.7755, 3.1340
2024-09-17 22:07:15,653 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:947] - INFO: Iteration:  0, train_loss:  20.9904, val_loss:  21.2960, grad_norm: 0.6864, reward_err: 0.0390, 0.0524, 0.0134, KL_dist: 0.0810, 0.1096, 0.0318, param: [2.7456304  3.34985465 2.16704143 1.69496942]train_grp_loss: [22.41071136 19.24830503 21.54526442], val_grp_loss: [22.17966005 19.42572186 22.10568827], train_hist_grp_loss: [22.43742754 19.32024701 21.5841685 ], cur_train_grp_loss: [22.43742754 19.32024701 21.5841685 ],max_reward_err:  0.0524, max_reward_err_index: 1, max_kl_dist:  0.1096, max_kl_dist_index: 1, max_train_grp_loss:  22.4107, max_train_grp_loss_index: 0, max_val_grp_loss:  22.1797, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  22.4374, max_cur_train_grp_loss_index: 0, 
2024-09-17 22:07:18,701 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:1040] - INFO: Iteration:  99, train_loss:  18.3591, val_loss:  18.6918, grad_norm: 0.3711, reward_err: 0.0606, 0.0121, 0.0263, KL_dist: 0.5314, 0.2595, 0.3858, param: [5.69829044 3.98838938 5.80813526 3.39381721]train_grp_loss: [20.79641648 15.64816945 19.02985638], val_grp_loss: [20.4893223  15.34976321 19.9015607 ], train_hist_grp_loss: [2147.98099547 1704.57793994 2012.88427886], cur_train_grp_loss: [20.80554599 15.66366906 19.04569609],max_reward_err:  0.0606, max_reward_err_index: 0, max_kl_dist:  0.5314, max_kl_dist_index: 0, max_train_grp_loss:  20.7964, max_train_grp_loss_index: 0, max_val_grp_loss:  20.4893, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  20.8055, max_cur_train_grp_loss_index: 0, 
2024-09-17 22:07:18,918 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:386] - INFO: Policy parameter learned solely on the preference data dpo: [5.69829044 3.98838938 5.80813526 3.39381721].
2024-09-17 22:07:19,244 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:397] - INFO: Uniform reward: 3.7556, 3.7556, 3.1458
2024-09-17 22:07:19,245 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Optimal reward: 3.7933, 3.7933, 3.2870
2024-09-17 22:07:19,245 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Policy reward: 3.5633, 3.7474, 3.2005
2024-09-17 22:07:19,246 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Reward Error: 0.0606, 0.0121, 0.0263
2024-09-17 22:07:19,915 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:415] - INFO: Optimal reward: 3.7933, 3.7933, 3.2870
Known param reward: [[3.793292999267578, 3.4222915172576904, 3.2522172927856445], [3.4222915172576904, 3.793292999267578, 3.1010961532592773], [3.759493589401245, 3.5484824180603027, 3.287027359008789]], Known param reward error: [[0.0, 0.0978045940773681, 0.010590135834355084], [0.0978045940773681, 0.0, 0.0565651530827476], [0.008910308239532014, 0.0645377462944582, 0.0]].
