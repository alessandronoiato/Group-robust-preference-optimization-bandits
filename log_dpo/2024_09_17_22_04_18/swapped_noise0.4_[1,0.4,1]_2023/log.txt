2024-09-17 22:05:01,211 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:198] - INFO: Logging to log_dpo/2024_09_17_22_04_18/swapped_noise0.4_[1,0.4,1]_2023
2024-09-17 22:05:01,213 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: (IB) Seed: 2023
2024-09-17 22:05:01,213 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Data: 300
2024-09-17 22:05:01,379 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:296] - INFO: MLE reward loss: 0.4525, l2 distance: 18.1721, acc: 0.80.
2024-09-17 22:05:01,380 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-17 22:05:01,380 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: MLE reward parameter: [9.90653594 4.24486875 6.64039083 5.98534533]
2024-09-17 22:05:01,583 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:313] - INFO: Learned oracle reward: 3.5613, 3.8249, 3.1624
2024-09-17 22:05:02,878 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:947] - INFO: Iteration:  0, train_loss:  21.9751, val_loss:  22.2979, grad_norm: 0.8705, reward_err: 0.0871, 0.0528, 0.0589, KL_dist: 0.1459, 0.0698, 0.0889, param: [0.8065409  0.18252571 2.99286745 2.2198645 ]train_grp_loss: [23.98376196 19.30067066 22.8539763 ], val_grp_loss: [23.53248443 20.10257551 23.26541609], train_hist_grp_loss: [24.0263585  19.42099352 22.91390243], cur_train_grp_loss: [24.0263585  19.42099352 22.91390243],max_reward_err:  0.0871, max_reward_err_index: 0, max_kl_dist:  0.1459, max_kl_dist_index: 0, max_train_grp_loss:  23.9838, max_train_grp_loss_index: 0, max_val_grp_loss:  23.5325, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  24.0264, max_cur_train_grp_loss_index: 0, 
2024-09-17 22:05:05,967 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:1040] - INFO: Iteration:  99, train_loss:  18.0419, val_loss:  19.0606, grad_norm: 0.4328, reward_err: 0.0637, 0.0214, 0.0305, KL_dist: 0.4645, 0.2638, 0.3407, param: [4.90221863 2.70507116 5.94286886 4.57696638]train_grp_loss: [21.43576805 13.93552117 19.06184997], val_grp_loss: [21.15079423 15.7679506  20.29049623], train_hist_grp_loss: [2251.19969616 1589.21470886 2070.56963276], cur_train_grp_loss: [21.45018908 13.95402002 19.08523981],max_reward_err:  0.0637, max_reward_err_index: 0, max_kl_dist:  0.4645, max_kl_dist_index: 0, max_train_grp_loss:  21.4358, max_train_grp_loss_index: 0, max_val_grp_loss:  21.1508, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  21.4502, max_cur_train_grp_loss_index: 0, 
2024-09-17 22:05:06,188 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:386] - INFO: Policy parameter learned solely on the preference data dpo: [4.90221863 2.70507116 5.94286886 4.57696638].
2024-09-17 22:05:06,522 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:397] - INFO: Uniform reward: 3.8265, 3.8265, 3.1778
2024-09-17 22:05:06,523 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Optimal reward: 3.8671, 3.8671, 3.3081
2024-09-17 22:05:06,523 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Policy reward: 3.6208, 3.7844, 3.2071
2024-09-17 22:05:06,524 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Reward Error: 0.0637, 0.0214, 0.0305
2024-09-17 22:05:07,226 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:415] - INFO: Optimal reward: 3.8671, 3.8671, 3.3081
Known param reward: [[3.867140769958496, 3.49029541015625, 3.2803642749786377], [3.49029541015625, 3.867140769958496, 3.118959903717041], [3.833752155303955, 3.6075756549835205, 3.3081343173980713]], Known param reward error: [[0.0, 0.09744805845438374, 0.00839447245941193], [0.09744805845438374, 0.0, 0.05718462297196584], [0.008633927917472566, 0.06712067918276514, 0.0]].
