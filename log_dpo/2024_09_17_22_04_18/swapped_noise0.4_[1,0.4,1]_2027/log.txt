2024-09-17 22:06:17,311 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:198] - INFO: Logging to log_dpo/2024_09_17_22_04_18/swapped_noise0.4_[1,0.4,1]_2027
2024-09-17 22:06:17,313 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: (IB) Seed: 2027
2024-09-17 22:06:17,313 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Data: 300
2024-09-17 22:06:17,471 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:296] - INFO: MLE reward loss: 0.5426, l2 distance: 10.6986, acc: 0.78.
2024-09-17 22:06:17,472 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-17 22:06:17,473 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: MLE reward parameter: [5.59184734 2.39285697 5.85807919 4.37757346]
2024-09-17 22:06:17,678 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:313] - INFO: Learned oracle reward: 3.5808, 3.7789, 3.2429
2024-09-17 22:06:18,964 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:947] - INFO: Iteration:  0, train_loss:  22.4061, val_loss:  22.3420, grad_norm: 0.6212, reward_err: 0.0854, 0.0854, 0.0621, KL_dist: 0.1988, 0.2052, 0.1508, param: [0.12162386 0.0939703  3.76747872 3.81918756]train_grp_loss: [22.31255674 22.86482363 22.10127962], val_grp_loss: [22.91746801 21.4033291  22.70075838], train_hist_grp_loss: [22.34280904 22.912306   22.14010217], cur_train_grp_loss: [22.34280904 22.912306   22.14010217],max_reward_err:  0.0854, max_reward_err_index: 0, max_kl_dist:  0.2052, max_kl_dist_index: 1, max_train_grp_loss:  22.8648, max_train_grp_loss_index: 1, max_val_grp_loss:  22.9175, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  22.9123, max_cur_train_grp_loss_index: 1, 
2024-09-17 22:06:22,013 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:1040] - INFO: Iteration:  99, train_loss:  20.0962, val_loss:  19.7755, grad_norm: 0.3615, reward_err: 0.0815, 0.0355, 0.0472, KL_dist: 0.5420, 0.2534, 0.4074, param: [3.20477605 1.80463245 6.81722589 4.62133978]train_grp_loss: [20.21475333 20.85295565 19.32292143], val_grp_loss: [21.54443243 17.36556168 20.40896757], train_hist_grp_loss: [2115.81015145 2153.28001875 2058.77251822], cur_train_grp_loss: [20.22921    20.85646394 19.34279104],max_reward_err:  0.0815, max_reward_err_index: 0, max_kl_dist:  0.5420, max_kl_dist_index: 0, max_train_grp_loss:  20.8530, max_train_grp_loss_index: 1, max_val_grp_loss:  21.5444, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  20.8565, max_cur_train_grp_loss_index: 1, 
2024-09-17 22:06:22,232 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:386] - INFO: Policy parameter learned solely on the preference data dpo: [3.20477605 1.80463245 6.81722589 4.62133978].
2024-09-17 22:06:22,559 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:397] - INFO: Uniform reward: 3.8066, 3.8066, 3.2029
2024-09-17 22:06:22,560 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Optimal reward: 3.8518, 3.8518, 3.3533
2024-09-17 22:06:22,560 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Policy reward: 3.5377, 3.7149, 3.1950
2024-09-17 22:06:22,561 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Reward Error: 0.0815, 0.0355, 0.0472
2024-09-17 22:06:23,239 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:415] - INFO: Optimal reward: 3.8518, 3.8518, 3.3533
Known param reward: [[3.8517885208129883, 3.454472303390503, 3.312851905822754], [3.454472303390503, 3.8517885208129883, 3.153261184692383], [3.809525966644287, 3.5818495750427246, 3.3532655239105225]], Known param reward error: [[0.0, 0.10315109858072496, 0.012052018487530586], [0.10315109858072496, 0.0, 0.05964464722283546], [0.010972189656918369, 0.07008145548792702, 0.0]].
