2024-09-17 22:06:36,207 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:198] - INFO: Logging to log_dpo/2024_09_17_22_04_18/swapped_noise0.4_[1,0.4,1]_2028
2024-09-17 22:06:36,209 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: (IB) Seed: 2028
2024-09-17 22:06:36,210 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Data: 300
2024-09-17 22:06:36,367 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:296] - INFO: MLE reward loss: 0.5103, l2 distance: 15.4764, acc: 0.73.
2024-09-17 22:06:36,368 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-17 22:06:36,368 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: MLE reward parameter: [6.84160916 4.81847435 8.49304786 1.47056677]
2024-09-17 22:06:36,572 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:313] - INFO: Learned oracle reward: 3.4529, 3.8020, 3.0781
2024-09-17 22:06:37,845 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:947] - INFO: Iteration:  0, train_loss:  22.6130, val_loss:  22.4833, grad_norm: 0.7020, reward_err: 0.1375, 0.0030, 0.1000, KL_dist: 0.2503, 0.0175, 0.1573, param: [1.31215286 0.44516827 3.47826161 0.65023073]train_grp_loss: [24.25577311 19.96874884 23.07980667], val_grp_loss: [23.68059543 20.19079427 23.47323261], train_hist_grp_loss: [24.2768759  20.07089438 23.11319126], cur_train_grp_loss: [24.2768759  20.07089438 23.11319126],max_reward_err:  0.1375, max_reward_err_index: 0, max_kl_dist:  0.2503, max_kl_dist_index: 0, max_train_grp_loss:  24.2558, max_train_grp_loss_index: 0, max_val_grp_loss:  23.6806, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  24.2769, max_cur_train_grp_loss_index: 0, 
2024-09-17 22:06:40,954 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:1040] - INFO: Iteration:  99, train_loss:  19.6229, val_loss:  19.5407, grad_norm: 0.4159, reward_err: 0.1137, 0.0052, 0.0734, KL_dist: 0.6080, 0.1849, 0.4303, param: [4.70194405 3.21697655 6.61194463 0.69833213]train_grp_loss: [22.82787668 14.29917668 20.69693984], val_grp_loss: [21.72535271 15.51351504 21.18950697], train_hist_grp_loss: [2346.29301308 1660.23937582 2178.04658534], cur_train_grp_loss: [22.83735269 14.32697775 20.71391849],max_reward_err:  0.1137, max_reward_err_index: 0, max_kl_dist:  0.6080, max_kl_dist_index: 0, max_train_grp_loss:  22.8279, max_train_grp_loss_index: 0, max_val_grp_loss:  21.7254, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  22.8374, max_cur_train_grp_loss_index: 0, 
2024-09-17 22:06:41,171 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:386] - INFO: Policy parameter learned solely on the preference data dpo: [4.70194405 3.21697655 6.61194463 0.69833213].
2024-09-17 22:06:41,496 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:397] - INFO: Uniform reward: 3.7921, 3.7921, 3.1395
2024-09-17 22:06:41,497 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Optimal reward: 3.8328, 3.8328, 3.2723
2024-09-17 22:06:41,497 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Policy reward: 3.3970, 3.8128, 3.0321
2024-09-17 22:06:41,498 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Reward Error: 0.1137, 0.0052, 0.0734
2024-09-17 22:06:42,167 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:415] - INFO: Optimal reward: 3.8328, 3.8328, 3.2723
Known param reward: [[3.8328447341918945, 3.4360735416412354, 3.2429821491241455], [3.4360735416412354, 3.8328447341918945, 3.0682969093322754], [3.796973705291748, 3.567776918411255, 3.272308111190796]], Known param reward error: [[0.0, 0.1035187230547478, 0.008961858440640128], [0.1035187230547478, 0.0, 0.06234474105932544], [0.0093588525984759, 0.06915694064412076, 0.0]].
