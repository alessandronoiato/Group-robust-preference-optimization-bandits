2024-09-17 21:48:09,136 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:198] - INFO: Logging to log_dpo/2024_09_17_21_48_05/swapped_noise0.5_[1,0.5,1]_2021
2024-09-17 21:48:09,138 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: (IB) Seed: 2021
2024-09-17 21:48:09,138 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Data: 300
2024-09-17 21:48:09,300 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:296] - INFO: MLE reward loss: 0.4932, l2 distance: 12.4583, acc: 0.83.
2024-09-17 21:48:09,300 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-17 21:48:09,301 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: MLE reward parameter: [6.14416532 4.10611549 6.4709344  4.40162939]
2024-09-17 21:48:09,501 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:313] - INFO: Learned oracle reward: 3.6199, 3.8275, 3.2155
2024-09-17 21:48:10,773 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:947] - INFO: Iteration:  0, train_loss:  21.1201, val_loss:  21.3827, grad_norm: 0.7625, reward_err: 0.1207, 0.0052, 0.0751, KL_dist: 0.2756, 0.0186, 0.1584, param: [3.43196014 0.21518384 3.27318355 1.51645062]train_grp_loss: [23.08474158 18.05404541 22.44076383], val_grp_loss: [23.39550428 18.56288359 22.35551472], train_hist_grp_loss: [23.12589311 18.13785278 22.48768078], cur_train_grp_loss: [23.12589311 18.13785278 22.48768078],max_reward_err:  0.1207, max_reward_err_index: 0, max_kl_dist:  0.2756, max_kl_dist_index: 0, max_train_grp_loss:  23.0847, max_train_grp_loss_index: 0, max_val_grp_loss:  23.3955, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  23.1259, max_cur_train_grp_loss_index: 0, 
2024-09-17 21:48:13,775 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:1040] - INFO: Iteration:  99, train_loss:  18.2228, val_loss:  18.4349, grad_norm: 0.3553, reward_err: 0.0809, 0.0057, 0.0409, KL_dist: 0.5695, 0.2461, 0.4174, param: [6.07921688 2.98052669 6.08348029 3.72309766]train_grp_loss: [20.53634219 14.9161484  19.44216476], val_grp_loss: [21.01401457 15.08489661 19.39889191], train_hist_grp_loss: [2162.91257482 1591.19398291 2074.65024913], cur_train_grp_loss: [20.55145725 14.92082152 19.46081195],max_reward_err:  0.0809, max_reward_err_index: 0, max_kl_dist:  0.5695, max_kl_dist_index: 0, max_train_grp_loss:  20.5363, max_train_grp_loss_index: 0, max_val_grp_loss:  21.0140, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  20.5515, max_cur_train_grp_loss_index: 0, 
2024-09-17 21:48:13,991 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:386] - INFO: Policy parameter learned solely on the preference data dpo: [6.07921688 2.98052669 6.08348029 3.72309766].
2024-09-17 21:48:14,311 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:397] - INFO: Uniform reward: 3.8503, 3.8503, 3.2061
2024-09-17 21:48:14,312 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Optimal reward: 3.8851, 3.8851, 3.3189
2024-09-17 21:48:14,313 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Policy reward: 3.5710, 3.8628, 3.1832
2024-09-17 21:48:14,313 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Reward Error: 0.0809, 0.0057, 0.0409
2024-09-17 21:48:14,970 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:415] - INFO: Optimal reward: 3.8851, 3.8851, 3.3189
Known param reward: [[3.88508939743042, 3.4581034183502197, 3.2941160202026367], [3.4581034183502197, 3.88508939743042, 3.1016483306884766], [3.85002064704895, 3.5887107849121094, 3.318911552429199]], Known param reward error: [[0.0, 0.10990377193446481, 0.007470983132531505], [0.10990377193446481, 0.0, 0.06546219093476653], [0.009026497666865538, 0.07628617573493521, 0.0]].
