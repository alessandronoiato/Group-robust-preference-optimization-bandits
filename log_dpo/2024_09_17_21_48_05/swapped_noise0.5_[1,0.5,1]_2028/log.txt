2024-09-17 21:50:19,113 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:198] - INFO: Logging to log_dpo/2024_09_17_21_48_05/swapped_noise0.5_[1,0.5,1]_2028
2024-09-17 21:50:19,115 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: (IB) Seed: 2028
2024-09-17 21:50:19,115 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Data: 300
2024-09-17 21:50:19,278 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:296] - INFO: MLE reward loss: 0.4894, l2 distance: 16.2091, acc: 0.81.
2024-09-17 21:50:19,279 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-17 21:50:19,279 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: MLE reward parameter: [8.22721469 5.17294545 7.35715173 4.22990991]
2024-09-17 21:50:19,491 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:313] - INFO: Learned oracle reward: 3.5721, 3.7947, 3.1641
2024-09-17 21:50:20,807 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:947] - INFO: Iteration:  0, train_loss:  20.6197, val_loss:  20.9503, grad_norm: 0.5895, reward_err: 0.0644, 0.0539, 0.0405, KL_dist: 0.2330, 0.1929, 0.1674, param: [4.72483831 4.39004455 1.3527214  0.75188625]train_grp_loss: [22.39199987 17.30500016 21.58027331], val_grp_loss: [22.08333157 19.20547168 21.58002468], train_hist_grp_loss: [22.41352213 17.3565619  21.61532601], cur_train_grp_loss: [22.41352213 17.3565619  21.61532601],max_reward_err:  0.0644, max_reward_err_index: 0, max_kl_dist:  0.2330, max_kl_dist_index: 0, max_train_grp_loss:  22.3920, max_train_grp_loss_index: 0, max_val_grp_loss:  22.0833, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  22.4135, max_cur_train_grp_loss_index: 0, 
2024-09-17 21:50:23,933 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:1040] - INFO: Iteration:  99, train_loss:  18.6182, val_loss:  18.8354, grad_norm: 0.3323, reward_err: 0.0638, 0.0291, 0.0346, KL_dist: 0.6127, 0.3808, 0.4829, param: [7.44357179 5.4308245  4.05603407 2.62135893]train_grp_loss: [21.06564842 14.76985946 19.22358723], val_grp_loss: [20.43290414 16.69375681 19.37035069], train_hist_grp_loss: [2163.21057574 1574.66014591 2027.0663446 ], cur_train_grp_loss: [21.07336658 14.78052319 19.23925481],max_reward_err:  0.0638, max_reward_err_index: 0, max_kl_dist:  0.6127, max_kl_dist_index: 0, max_train_grp_loss:  21.0656, max_train_grp_loss_index: 0, max_val_grp_loss:  20.4329, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  21.0734, max_cur_train_grp_loss_index: 0, 
2024-09-17 21:50:24,164 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:386] - INFO: Policy parameter learned solely on the preference data dpo: [7.44357179 5.4308245  4.05603407 2.62135893].
2024-09-17 21:50:24,493 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:397] - INFO: Uniform reward: 3.7930, 3.7930, 3.1404
2024-09-17 21:50:24,494 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Optimal reward: 3.8338, 3.8338, 3.2741
2024-09-17 21:50:24,494 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Policy reward: 3.5892, 3.7223, 3.1609
2024-09-17 21:50:24,495 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Reward Error: 0.0638, 0.0291, 0.0346
2024-09-17 21:50:25,177 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:415] - INFO: Optimal reward: 3.8338, 3.8338, 3.2741
Known param reward: [[3.833841323852539, 3.4367165565490723, 3.2448534965515137], [3.4367165565490723, 3.833841323852539, 3.0692381858825684], [3.798693895339966, 3.570518970489502, 3.2741200923919678]], Known param reward error: [[0.0, 0.10358403850277383, 0.008938766757047344], [0.10358403850277383, 0.0, 0.06257617336196096], [0.009167679500427106, 0.06868368592219944, 0.0]].
