2024-09-18 20:28:23,723 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log_dpo/2024_09_18_20_28_18/swapped_noise0.5_[1,0.5,1]_2021
2024-09-18 20:28:23,726 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2021
2024-09-18 20:28:23,726 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-09-18 20:28:23,896 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.4755, l2 distance: 14.9753, acc: 0.78.
2024-09-18 20:28:23,897 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-18 20:28:23,897 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [6.83711311 3.34754909 8.55534546 2.66371417]
2024-09-18 20:28:24,110 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.4347, 3.8200, 3.0830
2024-09-18 20:28:25,658 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:947] - INFO: Iteration:  0, train_loss:  19.6979, val_loss:  20.2547, grad_norm: 0.6313, reward_err: 0.0768, 0.0423, 0.0398, KL_dist: 0.3549, 0.2247, 0.2282, param: [4.63047089 0.36141136 4.36906493 4.50718567]train_grp_loss: [21.56536095 17.23855294 21.17753398], val_grp_loss: [22.11395905 17.73638721 21.0198677 ], train_hist_grp_loss: [21.58050077 17.30937216 21.20098593], cur_train_grp_loss: [21.58050077 17.30937216 21.20098593],max_reward_err:  0.0768, max_reward_err_index: 0, max_kl_dist:  0.3549, max_kl_dist_index: 0, max_train_grp_loss:  21.5654, max_train_grp_loss_index: 0, max_val_grp_loss:  22.1140, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  21.5805, max_cur_train_grp_loss_index: 0, 
2024-09-18 20:28:28,884 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:1040] - INFO: Iteration:  99, train_loss:  17.4683, val_loss:  18.2609, grad_norm: 0.3424, reward_err: 0.0978, 0.0018, 0.0569, KL_dist: 0.8899, 0.3510, 0.6662, param: [7.41528514 2.10787092 7.49718192 3.59905215]train_grp_loss: [20.60859058 13.49279964 19.55614002], val_grp_loss: [21.43311755 14.00432158 19.52456547], train_hist_grp_loss: [2102.19403381 1499.0510665  2028.39006089], cur_train_grp_loss: [20.61438383 13.51063207 19.56723162],max_reward_err:  0.0978, max_reward_err_index: 0, max_kl_dist:  0.8899, max_kl_dist_index: 0, max_train_grp_loss:  20.6086, max_train_grp_loss_index: 0, max_val_grp_loss:  21.4331, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  20.6144, max_cur_train_grp_loss_index: 0, 
2024-09-18 20:28:29,112 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:387] - INFO: Policy parameter learned solely on the preference data dpo: [7.41528514 2.10787092 7.49718192 3.59905215].
2024-09-18 20:28:29,452 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Uniform reward: 3.7895, 3.7895, 3.1570
2024-09-18 20:28:29,452 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Optimal reward: 3.8228, 3.8228, 3.2836
2024-09-18 20:28:29,453 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Policy reward: 3.4491, 3.8160, 3.0968
2024-09-18 20:28:29,453 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Reward Error: 0.0978, 0.0018, 0.0569
2024-09-18 20:28:30,133 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:416] - INFO: Optimal reward: 3.8228, 3.8228, 3.2836
Known param reward: [[3.822805166244507, 3.427518129348755, 3.2508020401000977], [3.427518129348755, 3.822805166244507, 3.080749988555908], [3.7867486476898193, 3.5572304725646973, 3.2835702896118164]], Known param reward error: [[0.0, 0.10340234976821452, 0.009979457304564846], [0.10340234976821452, 0.0, 0.061768222747528155], [0.009431952973451988, 0.06947115590008163, 0.0]].
