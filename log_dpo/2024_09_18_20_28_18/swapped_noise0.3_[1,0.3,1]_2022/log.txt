2024-09-18 20:35:33,146 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log_dpo/2024_09_18_20_28_18/swapped_noise0.3_[1,0.3,1]_2022
2024-09-18 20:35:33,148 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2022
2024-09-18 20:35:33,148 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-09-18 20:35:33,316 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.5114, l2 distance: 13.3000, acc: 0.75.
2024-09-18 20:35:33,317 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-18 20:35:33,318 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [2.3431996  2.79147837 9.27451545 2.39716811]
2024-09-18 20:35:33,534 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.4661, 3.8464, 3.0767
2024-09-18 20:35:35,014 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:947] - INFO: Iteration:  0, train_loss:  23.1121, val_loss:  22.5364, grad_norm: 0.7915, reward_err: 0.0095, 0.0979, 0.0189, KL_dist: 0.0244, 0.1610, 0.0271, param: [1.32230719 1.81957806 0.29591014 2.61588311]train_grp_loss: [23.11116846 23.05927179 23.25977984], val_grp_loss: [23.08104731 21.27426781 23.25781138], train_hist_grp_loss: [23.14144033 23.15740367 23.30920746], cur_train_grp_loss: [23.14144033 23.15740367 23.30920746],max_reward_err:  0.0979, max_reward_err_index: 1, max_kl_dist:  0.1610, max_kl_dist_index: 1, max_train_grp_loss:  23.2598, max_train_grp_loss_index: 2, max_val_grp_loss:  23.2578, max_val_grp_loss_index: 2, max_cur_train_grp_loss:  23.3092, max_cur_train_grp_loss_index: 2, 
2024-09-18 20:35:38,274 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:1040] - INFO: Iteration:  99, train_loss:  19.5159, val_loss:  19.3360, grad_norm: 0.4401, reward_err: 0.0568, 0.0132, 0.0250, KL_dist: 0.3648, 0.1506, 0.2491, param: [4.5294811  3.02128523 5.06089257 3.09419112]train_grp_loss: [21.17209701 17.78279612 19.90285709], val_grp_loss: [21.73829091 15.7329769  20.54748996], train_hist_grp_loss: [2201.71206193 1989.79922941 2140.12240467], cur_train_grp_loss: [21.18427492 17.80775013 19.92553283],max_reward_err:  0.0568, max_reward_err_index: 0, max_kl_dist:  0.3648, max_kl_dist_index: 0, max_train_grp_loss:  21.1721, max_train_grp_loss_index: 0, max_val_grp_loss:  21.7383, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  21.1843, max_cur_train_grp_loss_index: 0, 
2024-09-18 20:35:38,501 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:387] - INFO: Policy parameter learned solely on the preference data dpo: [4.5294811  3.02128523 5.06089257 3.09419112].
2024-09-18 20:35:38,838 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Uniform reward: 3.8377, 3.8377, 3.1941
2024-09-18 20:35:38,839 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Optimal reward: 3.8690, 3.8690, 3.3258
2024-09-18 20:35:38,839 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Policy reward: 3.6492, 3.8179, 3.2426
2024-09-18 20:35:38,840 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Reward Error: 0.0568, 0.0132, 0.0250
2024-09-18 20:35:39,512 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:416] - INFO: Optimal reward: 3.8690, 3.8690, 3.3258
Known param reward: [[3.8689613342285156, 3.540985584259033, 3.2756898403167725], [3.540985584259033, 3.8689613342285156, 3.1665854454040527], [3.825187921524048, 3.636335849761963, 3.3258354663848877]], Known param reward error: [[0.0, 0.08477100741945821, 0.01507760277829452], [0.08477100741945821, 0.0, 0.04788271175481099], [0.011313995908205773, 0.060126081490793466, 0.0]].
