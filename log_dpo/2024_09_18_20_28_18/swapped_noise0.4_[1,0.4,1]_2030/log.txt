2024-09-18 20:34:53,324 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log_dpo/2024_09_18_20_28_18/swapped_noise0.4_[1,0.4,1]_2030
2024-09-18 20:34:53,326 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2030
2024-09-18 20:34:53,326 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-09-18 20:34:53,491 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.4711, l2 distance: 12.8291, acc: 0.77.
2024-09-18 20:34:53,492 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-18 20:34:53,493 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [3.6833524  4.41691365 8.37422007 3.00526584]
2024-09-18 20:34:53,698 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.4800, 3.8293, 3.1678
2024-09-18 20:34:55,182 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:947] - INFO: Iteration:  0, train_loss:  22.9078, val_loss:  23.3696, grad_norm: 1.0957, reward_err: 0.0226, 0.1200, 0.0109, KL_dist: 0.0549, 0.1645, 0.0369, param: [0.72587392 0.32005606 1.04028235 2.55932497]train_grp_loss: [23.70800731 22.10419458 23.52227047], val_grp_loss: [23.71925554 22.77867511 23.57482258], train_hist_grp_loss: [23.75344287 22.30264465 23.57118058], cur_train_grp_loss: [23.75344287 22.30264465 23.57118058],max_reward_err:  0.1200, max_reward_err_index: 1, max_kl_dist:  0.1645, max_kl_dist_index: 1, max_train_grp_loss:  23.7080, max_train_grp_loss_index: 0, max_val_grp_loss:  23.7193, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  23.7534, max_cur_train_grp_loss_index: 0, 
2024-09-18 20:34:58,409 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:1040] - INFO: Iteration:  99, train_loss:  17.6973, val_loss:  19.2349, grad_norm: 0.4300, reward_err: 0.0686, 0.0164, 0.0325, KL_dist: 0.4502, 0.2233, 0.3149, param: [4.33355958 3.87202933 5.72609088 3.29053307]train_grp_loss: [21.31121141 13.92285621 20.89819934], val_grp_loss: [21.56381527 15.61202115 20.27601754], train_hist_grp_loss: [2226.73179635 1679.89698931 2195.23237997], cur_train_grp_loss: [21.32254204 13.94850124 20.91081781],max_reward_err:  0.0686, max_reward_err_index: 0, max_kl_dist:  0.4502, max_kl_dist_index: 0, max_train_grp_loss:  21.3112, max_train_grp_loss_index: 0, max_val_grp_loss:  21.5638, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  21.3225, max_cur_train_grp_loss_index: 0, 
2024-09-18 20:34:58,676 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:387] - INFO: Policy parameter learned solely on the preference data dpo: [4.33355958 3.87202933 5.72609088 3.29053307].
2024-09-18 20:34:59,020 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Uniform reward: 3.8314, 3.8314, 3.2257
2024-09-18 20:34:59,021 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Optimal reward: 3.8751, 3.8751, 3.3832
2024-09-18 20:34:59,021 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Policy reward: 3.6092, 3.8116, 3.2733
2024-09-18 20:34:59,022 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Reward Error: 0.0686, 0.0164, 0.0325
2024-09-18 20:34:59,719 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:416] - INFO: Optimal reward: 3.8751, 3.8751, 3.3832
Known param reward: [[3.875110387802124, 3.4832417964935303, 3.3414347171783447], [3.4832417964935303, 3.875110387802124, 3.1878042221069336], [3.835331678390503, 3.593684434890747, 3.3831582069396973]], Known param reward error: [[0.0, 0.1011244976509825, 0.012332704298535996], [0.1011244976509825, 0.0, 0.05774308290757558], [0.010265180970543316, 0.07262398351211756, 0.0]].
