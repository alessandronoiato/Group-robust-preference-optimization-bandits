2024-09-18 20:36:30,799 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log_dpo/2024_09_18_20_28_18/swapped_noise0.3_[1,0.3,1]_2025
2024-09-18 20:36:30,801 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2025
2024-09-18 20:36:30,802 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-09-18 20:36:30,968 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.5798, l2 distance: 6.9075, acc: 0.72.
2024-09-18 20:36:30,969 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-18 20:36:30,969 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [4.52051724 2.23924509 4.09916579 1.35699891]
2024-09-18 20:36:31,174 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.5016, 3.8293, 3.0928
2024-09-18 20:36:32,627 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:947] - INFO: Iteration:  0, train_loss:  21.9695, val_loss:  21.8982, grad_norm: 0.5028, reward_err: 0.0553, 0.0531, 0.0228, KL_dist: 0.1204, 0.1054, 0.0527, param: [2.70273987 3.35341028 2.68581441 0.42710802]train_grp_loss: [22.86337731 20.73352425 23.0008937 ], val_grp_loss: [23.0975097  20.36955539 22.22885509], train_hist_grp_loss: [22.88317047 20.76682602 23.01807211], cur_train_grp_loss: [22.88317047 20.76682602 23.01807211],max_reward_err:  0.0553, max_reward_err_index: 0, max_kl_dist:  0.1204, max_kl_dist_index: 0, max_train_grp_loss:  23.0009, max_train_grp_loss_index: 2, max_val_grp_loss:  23.0975, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  23.0181, max_cur_train_grp_loss_index: 2, 
2024-09-18 20:36:35,878 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:1040] - INFO: Iteration:  99, train_loss:  20.6400, val_loss:  20.2812, grad_norm: 0.2581, reward_err: 0.0671, 0.0178, 0.0315, KL_dist: 0.3858, 0.1626, 0.2630, param: [5.03870031 3.7439877  4.88162362 1.91516812]train_grp_loss: [21.72060499 19.09430887 22.02516232], val_grp_loss: [22.23945205 18.05434832 20.55661482], train_hist_grp_loss: [2219.63245917 1973.59692896 2242.8209157 ], cur_train_grp_loss: [21.72680939 19.10191724 22.0303276 ],max_reward_err:  0.0671, max_reward_err_index: 0, max_kl_dist:  0.3858, max_kl_dist_index: 0, max_train_grp_loss:  22.0252, max_train_grp_loss_index: 2, max_val_grp_loss:  22.2395, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  22.0303, max_cur_train_grp_loss_index: 2, 
2024-09-18 20:36:36,110 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:387] - INFO: Policy parameter learned solely on the preference data dpo: [5.03870031 3.7439877  4.88162362 1.91516812].
2024-09-18 20:36:36,448 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Uniform reward: 3.8078, 3.8078, 3.1434
2024-09-18 20:36:36,449 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Optimal reward: 3.8386, 3.8386, 3.2517
2024-09-18 20:36:36,449 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Policy reward: 3.5809, 3.7702, 3.1493
2024-09-18 20:36:36,450 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Reward Error: 0.0671, 0.0178, 0.0315
2024-09-18 20:36:37,132 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:416] - INFO: Optimal reward: 3.8386, 3.8386, 3.2517
Known param reward: [[3.8385727405548096, 3.460787534713745, 3.2131664752960205], [3.460787534713745, 3.8385727405548096, 3.0634775161743164], [3.796536684036255, 3.582489252090454, 3.2517144680023193]], Known param reward error: [[0.0, 0.09841814428830158, 0.011854667156547932], [0.09841814428830158, 0.0, 0.057888524247839544], [0.010950959994698183, 0.06671320456137621, 0.0]].
