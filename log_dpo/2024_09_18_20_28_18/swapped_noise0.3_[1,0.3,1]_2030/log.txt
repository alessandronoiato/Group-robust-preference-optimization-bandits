2024-09-18 20:38:06,318 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log_dpo/2024_09_18_20_28_18/swapped_noise0.3_[1,0.3,1]_2030
2024-09-18 20:38:06,320 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2030
2024-09-18 20:38:06,321 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-09-18 20:38:06,488 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.5443, l2 distance: 7.9183, acc: 0.76.
2024-09-18 20:38:06,489 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-18 20:38:06,490 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [4.75082508 2.39887969 4.69994759 1.0585373 ]
2024-09-18 20:38:06,702 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.4510, 3.7901, 3.1262
2024-09-18 20:38:08,163 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:947] - INFO: Iteration:  0, train_loss:  21.5132, val_loss:  20.5168, grad_norm: 0.6965, reward_err: 0.0374, 0.0639, 0.0136, KL_dist: 0.1283, 0.1988, 0.0820, param: [3.67307272 2.61702708 2.1944265  4.19333417]train_grp_loss: [21.49992559 21.57924551 21.3480388 ], val_grp_loss: [21.40134669 18.71341974 21.30124369], train_hist_grp_loss: [21.49915266 21.67322865 21.36923273], cur_train_grp_loss: [21.49915266 21.67322865 21.36923273],max_reward_err:  0.0639, max_reward_err_index: 1, max_kl_dist:  0.1988, max_kl_dist_index: 1, max_train_grp_loss:  21.5792, max_train_grp_loss_index: 1, max_val_grp_loss:  21.4013, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  21.6732, max_cur_train_grp_loss_index: 1, 
2024-09-18 20:38:11,422 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:1040] - INFO: Iteration:  99, train_loss:  19.2080, val_loss:  18.9814, grad_norm: 0.3068, reward_err: 0.0791, 0.0050, 0.0417, KL_dist: 0.5973, 0.2058, 0.4284, param: [6.58779831 3.39945918 5.20837116 2.33425214]train_grp_loss: [21.51746042 17.24559726 19.93217677], val_grp_loss: [21.06453757 15.31427079 20.26127013], train_hist_grp_loss: [2151.65521922 1885.87672592 2056.00861536], cur_train_grp_loss: [21.5176799  17.261776   19.94154426],max_reward_err:  0.0791, max_reward_err_index: 0, max_kl_dist:  0.5973, max_kl_dist_index: 0, max_train_grp_loss:  21.5175, max_train_grp_loss_index: 0, max_val_grp_loss:  21.0645, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  21.5177, max_cur_train_grp_loss_index: 0, 
2024-09-18 20:38:11,657 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:387] - INFO: Policy parameter learned solely on the preference data dpo: [6.58779831 3.39945918 5.20837116 2.33425214].
2024-09-18 20:38:11,995 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Uniform reward: 3.7588, 3.7588, 3.1504
2024-09-18 20:38:11,996 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Optimal reward: 3.7981, 3.7981, 3.2939
2024-09-18 20:38:11,996 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Policy reward: 3.4977, 3.7792, 3.1564
2024-09-18 20:38:11,997 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Reward Error: 0.0791, 0.0050, 0.0417
2024-09-18 20:38:12,687 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:416] - INFO: Optimal reward: 3.7981, 3.7981, 3.2939
Known param reward: [[3.798083543777466, 3.4340016841888428, 3.2582314014434814], [3.4340016841888428, 3.798083543777466, 3.1138041019439697], [3.763892412185669, 3.5496251583099365, 3.293947219848633]], Known param reward error: [[0.0, 0.09585936048855775, 0.010842862991226866], [0.09585936048855775, 0.0, 0.054689133092102556], [0.009002206296334216, 0.06541677733092191, 0.0]].
