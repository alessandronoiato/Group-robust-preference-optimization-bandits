2024-09-18 20:30:08,500 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log_dpo/2024_09_18_20_28_18/swapped_noise0.5_[1,0.5,1]_2025
2024-09-18 20:30:08,502 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2025
2024-09-18 20:30:08,503 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-09-18 20:30:08,664 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.4543, l2 distance: 16.6174, acc: 0.81.
2024-09-18 20:30:08,665 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-18 20:30:08,665 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [8.68775344 5.26920364 6.98565022 4.61655316]
2024-09-18 20:30:08,869 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.5914, 3.7958, 3.1513
2024-09-18 20:30:10,308 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:947] - INFO: Iteration:  0, train_loss:  19.4129, val_loss:  19.7226, grad_norm: 0.6935, reward_err: 0.0707, 0.0201, 0.0351, KL_dist: 0.2935, 0.1046, 0.1841, param: [4.20216692 1.43013041 4.30896724 3.3383062 ]train_grp_loss: [21.88496058 16.41149472 21.14431929], val_grp_loss: [22.21581711 15.77041425 21.18647689], train_hist_grp_loss: [21.91114531 16.48597314 21.17639803], cur_train_grp_loss: [21.91114531 16.48597314 21.17639803],max_reward_err:  0.0707, max_reward_err_index: 0, max_kl_dist:  0.2935, max_kl_dist_index: 0, max_train_grp_loss:  21.8850, max_train_grp_loss_index: 0, max_val_grp_loss:  22.2158, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  21.9111, max_cur_train_grp_loss_index: 0, 
2024-09-18 20:30:13,522 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:1040] - INFO: Iteration:  99, train_loss:  17.0302, val_loss:  17.6371, grad_norm: 0.3274, reward_err: 0.0693, 0.0082, 0.0339, KL_dist: 0.7261, 0.3806, 0.5598, param: [7.16233482 4.1072128  6.84381918 3.70907329]train_grp_loss: [20.28348366 13.17074439 19.0659958 ], val_grp_loss: [20.78976728 13.06336463 19.06938596], train_hist_grp_loss: [2096.62474684 1434.33780556 1997.49142873], cur_train_grp_loss: [20.29280166 13.18181533 19.07913143],max_reward_err:  0.0693, max_reward_err_index: 0, max_kl_dist:  0.7261, max_kl_dist_index: 0, max_train_grp_loss:  20.2835, max_train_grp_loss_index: 0, max_val_grp_loss:  20.7898, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  20.2928, max_cur_train_grp_loss_index: 0, 
2024-09-18 20:30:13,750 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:387] - INFO: Policy parameter learned solely on the preference data dpo: [7.16233482 4.1072128  6.84381918 3.70907329].
2024-09-18 20:30:14,086 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Uniform reward: 3.8103, 3.8103, 3.1427
2024-09-18 20:30:14,087 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Optimal reward: 3.8440, 3.8440, 3.2545
2024-09-18 20:30:14,087 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Policy reward: 3.5775, 3.8123, 3.1443
2024-09-18 20:30:14,088 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Reward Error: 0.0693, 0.0082, 0.0339
2024-09-18 20:30:14,759 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:416] - INFO: Optimal reward: 3.8440, 3.8440, 3.2545
Known param reward: [[3.843956232070923, 3.4647014141082764, 3.2180964946746826], [3.4647014141082764, 3.843956232070923, 3.0630156993865967], [3.8041796684265137, 3.590562105178833, 3.254488229751587]], Known param reward error: [[0.0, 0.09866262648841967, 0.011182014654169469], [0.09866262648841967, 0.0, 0.058833376201703216], [0.010347819080910722, 0.06592013841832281, 0.0]].
