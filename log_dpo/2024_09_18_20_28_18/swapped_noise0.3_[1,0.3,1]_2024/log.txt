2024-09-18 20:36:09,647 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log_dpo/2024_09_18_20_28_18/swapped_noise0.3_[1,0.3,1]_2024
2024-09-18 20:36:09,649 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2024
2024-09-18 20:36:09,650 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-09-18 20:36:09,814 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.5272, l2 distance: 8.9728, acc: 0.77.
2024-09-18 20:36:09,815 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-18 20:36:09,816 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [3.13265196 2.31429868 6.45347979 3.11117788]
2024-09-18 20:36:10,029 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.5829, 3.8743, 3.2326
2024-09-18 20:36:11,479 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:947] - INFO: Iteration:  0, train_loss:  22.6344, val_loss:  23.0838, grad_norm: 0.8659, reward_err: 0.0447, 0.0724, 0.0267, KL_dist: 0.0630, 0.1041, 0.0421, param: [1.58519282 1.30981573 0.3627821  1.71606423]train_grp_loss: [23.74640465 21.3794685  23.51865347], val_grp_loss: [23.47486205 22.30975205 23.44912742], train_hist_grp_loss: [23.78522567 21.49272953 23.57069782], cur_train_grp_loss: [23.78522567 21.49272953 23.57069782],max_reward_err:  0.0724, max_reward_err_index: 1, max_kl_dist:  0.1041, max_kl_dist_index: 1, max_train_grp_loss:  23.7464, max_train_grp_loss_index: 0, max_val_grp_loss:  23.4749, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  23.7852, max_cur_train_grp_loss_index: 0, 
2024-09-18 20:36:14,727 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:1040] - INFO: Iteration:  99, train_loss:  19.2594, val_loss:  20.0912, grad_norm: 0.3650, reward_err: 0.0513, 0.0323, 0.0184, KL_dist: 0.2864, 0.1948, 0.1913, param: [4.40062569 2.66885605 4.2281953  4.28754469]train_grp_loss: [21.63605903 16.76791543 20.51270089], val_grp_loss: [21.36941688 18.32455448 20.56166711], train_hist_grp_loss: [2248.96444166 1838.83078929 2176.66143329], cur_train_grp_loss: [21.64647602 16.78275948 20.52922968],max_reward_err:  0.0513, max_reward_err_index: 0, max_kl_dist:  0.2864, max_kl_dist_index: 0, max_train_grp_loss:  21.6361, max_train_grp_loss_index: 0, max_val_grp_loss:  21.3694, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  21.6465, max_cur_train_grp_loss_index: 0, 
2024-09-18 20:36:14,959 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:387] - INFO: Policy parameter learned solely on the preference data dpo: [4.40062569 2.66885605 4.2281953  4.28754469].
2024-09-18 20:36:15,299 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Uniform reward: 3.8844, 3.8844, 3.2699
2024-09-18 20:36:15,300 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Optimal reward: 3.9240, 3.9240, 3.4065
2024-09-18 20:36:15,300 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Policy reward: 3.7226, 3.7973, 3.3437
2024-09-18 20:36:15,301 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Reward Error: 0.0513, 0.0323, 0.0184
2024-09-18 20:36:15,982 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:416] - INFO: Optimal reward: 3.9240, 3.9240, 3.4065
Known param reward: [[3.924014091491699, 3.5108532905578613, 3.372161388397217], [3.5108532905578613, 3.924014091491699, 3.199089765548706], [3.8835723400115967, 3.6450908184051514, 3.40653657913208]], Known param reward error: [[0.0, 0.10529034588068371, 0.010090950129653801], [0.10529034588068371, 0.0, 0.060896693390630634], [0.010306219737536355, 0.0710811089316237, 0.0]].
