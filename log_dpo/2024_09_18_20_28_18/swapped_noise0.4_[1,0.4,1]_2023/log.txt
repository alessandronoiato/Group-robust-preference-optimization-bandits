2024-09-18 20:32:43,004 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log_dpo/2024_09_18_20_28_18/swapped_noise0.4_[1,0.4,1]_2023
2024-09-18 20:32:43,006 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2023
2024-09-18 20:32:43,006 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-09-18 20:32:43,174 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.4814, l2 distance: 15.1900, acc: 0.79.
2024-09-18 20:32:43,175 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-18 20:32:43,176 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [9.60038822 4.4139189  4.42858643 3.54905581]
2024-09-18 20:32:43,379 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.4934, 3.8064, 3.1099
2024-09-18 20:32:44,894 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:947] - INFO: Iteration:  0, train_loss:  20.4231, val_loss:  20.6988, grad_norm: 0.6362, reward_err: 0.0858, 0.0237, 0.0502, KL_dist: 0.2997, 0.0803, 0.1915, param: [2.82981595 0.90214223 4.91782616 3.03729935]train_grp_loss: [22.45585848 17.70153882 21.59163744], val_grp_loss: [22.46945554 17.79513019 21.8079955 ], train_hist_grp_loss: [22.48684571 17.75353613 21.62861536], cur_train_grp_loss: [22.48684571 17.75353613 21.62861536],max_reward_err:  0.0858, max_reward_err_index: 0, max_kl_dist:  0.2997, max_kl_dist_index: 0, max_train_grp_loss:  22.4559, max_train_grp_loss_index: 0, max_val_grp_loss:  22.4695, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  22.4868, max_cur_train_grp_loss_index: 0, 
2024-09-18 20:32:48,458 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:1040] - INFO: Iteration:  99, train_loss:  18.1466, val_loss:  18.8992, grad_norm: 0.3478, reward_err: 0.0726, 0.0062, 0.0359, KL_dist: 0.6495, 0.3062, 0.4875, param: [6.23521433 3.42320174 6.7245049  3.8472367 ]train_grp_loss: [20.42726239 15.23414341 19.12877185], val_grp_loss: [20.87133849 16.23658498 19.60068555], train_hist_grp_loss: [2131.85511054 1616.0972803  2021.87035769], cur_train_grp_loss: [20.44028655 15.24339592 19.14494096],max_reward_err:  0.0726, max_reward_err_index: 0, max_kl_dist:  0.6495, max_kl_dist_index: 0, max_train_grp_loss:  20.4273, max_train_grp_loss_index: 0, max_val_grp_loss:  20.8713, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  20.4403, max_cur_train_grp_loss_index: 0, 
2024-09-18 20:32:48,692 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:387] - INFO: Policy parameter learned solely on the preference data dpo: [6.23521433 3.42320174 6.7245049  3.8472367 ].
2024-09-18 20:32:49,033 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Uniform reward: 3.8122, 3.8122, 3.1725
2024-09-18 20:32:49,034 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Optimal reward: 3.8527, 3.8527, 3.3024
2024-09-18 20:32:49,035 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Policy reward: 3.5728, 3.8288, 3.1838
2024-09-18 20:32:49,035 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Reward Error: 0.0726, 0.0062, 0.0359
2024-09-18 20:32:49,736 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:416] - INFO: Optimal reward: 3.8527, 3.8527, 3.3024
Known param reward: [[3.852689266204834, 3.475465774536133, 3.27390193939209], [3.475465774536133, 3.852689266204834, 3.1151528358459473], [3.8164188861846924, 3.5882885456085205, 3.3024346828460693]], Known param reward error: [[0.0, 0.09791173531113566, 0.008639911518065122], [0.09791173531113566, 0.0, 0.0567102350193103], [0.00941430193664968, 0.06862757474774667, 0.0]].
