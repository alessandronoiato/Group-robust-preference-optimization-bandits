2024-09-18 20:31:24,492 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log_dpo/2024_09_18_20_28_18/swapped_noise0.5_[1,0.5,1]_2029
2024-09-18 20:31:24,494 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2029
2024-09-18 20:31:24,495 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-09-18 20:31:24,660 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.4622, l2 distance: 15.7048, acc: 0.76.
2024-09-18 20:31:24,661 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-18 20:31:24,662 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [8.03172364 3.1446329  7.65537172 4.62681821]
2024-09-18 20:31:24,867 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.5601, 3.8681, 3.2290
2024-09-18 20:31:26,313 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:947] - INFO: Iteration:  0, train_loss:  22.6289, val_loss:  23.1128, grad_norm: 0.9619, reward_err: 0.1493, 0.0052, 0.1139, KL_dist: 0.2350, 0.0444, 0.1602, param: [3.07757828 0.57724099 0.43541469 0.29511177]train_grp_loss: [24.28410151 20.52674843 24.08671327], val_grp_loss: [24.01615215 21.27143828 23.80230739], train_hist_grp_loss: [24.32422269 20.68252461 24.14089072], cur_train_grp_loss: [24.32422269 20.68252461 24.14089072],max_reward_err:  0.1493, max_reward_err_index: 0, max_kl_dist:  0.2350, max_kl_dist_index: 0, max_train_grp_loss:  24.2841, max_train_grp_loss_index: 0, max_val_grp_loss:  24.0162, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  24.3242, max_cur_train_grp_loss_index: 0, 
2024-09-18 20:31:29,573 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:1040] - INFO: Iteration:  99, train_loss:  17.9820, val_loss:  19.1831, grad_norm: 0.4593, reward_err: 0.0947, 0.0044, 0.0536, KL_dist: 0.5900, 0.1869, 0.4240, param: [6.78648165 2.59703691 4.67694083 3.15046462]train_grp_loss: [22.12080363 12.98164406 20.81463574], val_grp_loss: [21.20703443 15.48803726 20.35422293], train_hist_grp_loss: [2298.92591512 1588.46731026 2220.51002196], cur_train_grp_loss: [22.13107826 13.01397105 20.83361776],max_reward_err:  0.0947, max_reward_err_index: 0, max_kl_dist:  0.5900, max_kl_dist_index: 0, max_train_grp_loss:  22.1208, max_train_grp_loss_index: 0, max_val_grp_loss:  21.2070, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  22.1311, max_cur_train_grp_loss_index: 0, 
2024-09-18 20:31:29,803 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:387] - INFO: Policy parameter learned solely on the preference data dpo: [6.78648165 2.59703691 4.67694083 3.15046462].
2024-09-18 20:31:30,151 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Uniform reward: 3.8386, 3.8386, 3.2274
2024-09-18 20:31:30,152 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Optimal reward: 3.8850, 3.8850, 3.3731
2024-09-18 20:31:30,152 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Policy reward: 3.5171, 3.8679, 3.1922
2024-09-18 20:31:30,153 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Reward Error: 0.0947, 0.0044, 0.0536
2024-09-18 20:31:30,859 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:416] - INFO: Optimal reward: 3.8850, 3.8850, 3.3731
Known param reward: [[3.8849852085113525, 3.4774763584136963, 3.335669994354248], [3.4774763584136963, 3.8849852085113525, 3.1690282821655273], [3.8491885662078857, 3.6059226989746094, 3.3731210231781006]], Known param reward error: [[0.0, 0.10489328227167315, 0.011102782428057319], [0.10489328227167315, 0.0, 0.06050560878491111], [0.009214100024124247, 0.07183103527018941, 0.0]].
