2024-09-18 20:33:01,306 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log_dpo/2024_09_18_20_28_18/swapped_noise0.4_[1,0.4,1]_2024
2024-09-18 20:33:01,308 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2024
2024-09-18 20:33:01,309 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-09-18 20:33:01,475 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.5143, l2 distance: 9.9532, acc: 0.78.
2024-09-18 20:33:01,476 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-18 20:33:01,477 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [6.02750083 3.24397078 5.04527759 3.19851879]
2024-09-18 20:33:01,686 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.6302, 3.8888, 3.2825
2024-09-18 20:33:03,191 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:947] - INFO: Iteration:  0, train_loss:  20.8888, val_loss:  21.3506, grad_norm: 0.7233, reward_err: 0.1077, 0.0260, 0.0740, KL_dist: 0.3049, 0.0362, 0.2174, param: [4.83907226 2.17310691 0.93916967 1.30168047]train_grp_loss: [23.15508589 18.63483577 21.67704131], val_grp_loss: [22.84886056 18.82082889 22.33702106], train_hist_grp_loss: [23.18816261 18.7052786  21.72412103], cur_train_grp_loss: [23.18816261 18.7052786  21.72412103],max_reward_err:  0.1077, max_reward_err_index: 0, max_kl_dist:  0.3049, max_kl_dist_index: 0, max_train_grp_loss:  23.1551, max_train_grp_loss_index: 0, max_val_grp_loss:  22.8489, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  23.1882, max_cur_train_grp_loss_index: 0, 
2024-09-18 20:33:06,446 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:1040] - INFO: Iteration:  99, train_loss:  18.5568, val_loss:  18.7859, grad_norm: 0.3013, reward_err: 0.0841, 0.0175, 0.0489, KL_dist: 0.5913, 0.2407, 0.4554, param: [7.36985641 3.57160649 3.61403484 3.77031168]train_grp_loss: [21.32973424 15.98829511 18.88812242], val_grp_loss: [20.59795213 15.75823407 19.94868084], train_hist_grp_loss: [2207.25670598 1687.04122909 2006.43996814], cur_train_grp_loss: [21.33888394 15.99520854 18.90396662],max_reward_err:  0.0841, max_reward_err_index: 0, max_kl_dist:  0.5913, max_kl_dist_index: 0, max_train_grp_loss:  21.3297, max_train_grp_loss_index: 0, max_val_grp_loss:  20.5980, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  21.3389, max_cur_train_grp_loss_index: 0, 
2024-09-18 20:33:06,681 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:387] - INFO: Policy parameter learned solely on the preference data dpo: [7.36985641 3.57160649 3.61403484 3.77031168].
2024-09-18 20:33:07,017 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Uniform reward: 3.8844, 3.8844, 3.2699
2024-09-18 20:33:07,018 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Optimal reward: 3.9240, 3.9240, 3.4065
2024-09-18 20:33:07,019 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Policy reward: 3.5941, 3.8552, 3.2400
2024-09-18 20:33:07,019 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Reward Error: 0.0841, 0.0175, 0.0489
2024-09-18 20:33:07,699 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:416] - INFO: Optimal reward: 3.9240, 3.9240, 3.4065
Known param reward: [[3.924014091491699, 3.5108532905578613, 3.372161388397217], [3.5108532905578613, 3.924014091491699, 3.199089765548706], [3.8835723400115967, 3.6450908184051514, 3.40653657913208]], Known param reward error: [[0.0, 0.10529034588068371, 0.010090950129653801], [0.10529034588068371, 0.0, 0.060896693390630634], [0.010306219737536355, 0.0710811089316237, 0.0]].
