2024-09-18 20:37:47,633 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log_dpo/2024_09_18_20_28_18/swapped_noise0.3_[1,0.3,1]_2029
2024-09-18 20:37:47,635 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2029
2024-09-18 20:37:47,636 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-09-18 20:37:47,796 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.5113, l2 distance: 10.3776, acc: 0.79.
2024-09-18 20:37:47,796 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-18 20:37:47,797 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [4.3593504  3.3275761  6.76851117 3.1285225 ]
2024-09-18 20:37:48,008 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.5742, 3.8625, 3.2288
2024-09-18 20:37:49,455 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:947] - INFO: Iteration:  0, train_loss:  19.2416, val_loss:  19.5532, grad_norm: 0.4498, reward_err: 0.0527, 0.0292, 0.0207, KL_dist: 0.2882, 0.2057, 0.1975, param: [3.84500065 3.5849848  4.68136855 3.82097366]train_grp_loss: [20.80126843 17.58693637 19.58071249], val_grp_loss: [20.74347231 17.42564218 20.25526383], train_hist_grp_loss: [20.81374023 17.61397215 19.60328577], cur_train_grp_loss: [20.81374023 17.61397215 19.60328577],max_reward_err:  0.0527, max_reward_err_index: 0, max_kl_dist:  0.2882, max_kl_dist_index: 0, max_train_grp_loss:  20.8013, max_train_grp_loss_index: 0, max_val_grp_loss:  20.7435, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  20.8137, max_cur_train_grp_loss_index: 0, 
2024-09-18 20:37:52,696 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:1040] - INFO: Iteration:  99, train_loss:  18.1462, val_loss:  18.5991, grad_norm: 0.2334, reward_err: 0.0717, 0.0123, 0.0345, KL_dist: 0.6838, 0.3515, 0.5202, param: [5.76360237 4.24396089 7.19427112 4.05162423]train_grp_loss: [20.06118319 16.26321699 18.09173086], val_grp_loss: [19.925636   16.59239349 19.04825797], train_hist_grp_loss: [2037.22253759 1677.05776523 1874.828723  ], cur_train_grp_loss: [20.06528633 16.26862761 18.10140875],max_reward_err:  0.0717, max_reward_err_index: 0, max_kl_dist:  0.6838, max_kl_dist_index: 0, max_train_grp_loss:  20.0612, max_train_grp_loss_index: 0, max_val_grp_loss:  19.9256, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  20.0653, max_cur_train_grp_loss_index: 0, 
2024-09-18 20:37:52,924 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:387] - INFO: Policy parameter learned solely on the preference data dpo: [5.76360237 4.24396089 7.19427112 4.05162423].
2024-09-18 20:37:53,268 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Uniform reward: 3.8485, 3.8485, 3.2335
2024-09-18 20:37:53,269 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Optimal reward: 3.8941, 3.8941, 3.3780
2024-09-18 20:37:53,269 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Policy reward: 3.6149, 3.8460, 3.2614
2024-09-18 20:37:53,270 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Reward Error: 0.0717, 0.0123, 0.0345
2024-09-18 20:37:53,973 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:416] - INFO: Optimal reward: 3.8941, 3.8941, 3.3780
Known param reward: [[3.894106388092041, 3.4839439392089844, 3.341844081878662], [3.4839439392089844, 3.894106388092041, 3.171762704849243], [3.8587565422058105, 3.6140236854553223, 3.3780486583709717]], Known param reward error: [[0.0, 0.10532903007922702, 0.010717600648703753], [0.10532903007922702, 0.0, 0.06106660216706521], [0.009077781232256088, 0.0719247690543833, 0.0]].
