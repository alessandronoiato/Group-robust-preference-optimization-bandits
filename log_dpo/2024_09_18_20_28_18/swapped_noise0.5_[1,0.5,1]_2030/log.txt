2024-09-18 20:31:47,975 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log_dpo/2024_09_18_20_28_18/swapped_noise0.5_[1,0.5,1]_2030
2024-09-18 20:31:47,977 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2030
2024-09-18 20:31:47,978 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-09-18 20:31:48,139 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.5211, l2 distance: 8.2067, acc: 0.78.
2024-09-18 20:31:48,139 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-18 20:31:48,140 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [3.37196976 3.35883333 5.6739704  3.17762949]
2024-09-18 20:31:48,343 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.5758, 3.8158, 3.2448
2024-09-18 20:31:49,751 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:947] - INFO: Iteration:  0, train_loss:  20.9816, val_loss:  21.3134, grad_norm: 0.7219, reward_err: 0.0651, 0.0609, 0.0447, KL_dist: 0.1174, 0.1293, 0.0853, param: [0.28288063 2.54843589 3.3480452  2.50165009]train_grp_loss: [22.3886464  19.5458391  22.12874921], val_grp_loss: [22.81718721 18.58547176 22.42031472], train_hist_grp_loss: [22.42501709 19.61526256 22.16291878], cur_train_grp_loss: [22.42501709 19.61526256 22.16291878],max_reward_err:  0.0651, max_reward_err_index: 0, max_kl_dist:  0.1293, max_kl_dist_index: 1, max_train_grp_loss:  22.3886, max_train_grp_loss_index: 0, max_val_grp_loss:  22.8172, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  22.4250, max_cur_train_grp_loss_index: 0, 
2024-09-18 20:31:53,025 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:1040] - INFO: Iteration:  99, train_loss:  18.6124, val_loss:  18.7052, grad_norm: 0.3014, reward_err: 0.0670, 0.0316, 0.0351, KL_dist: 0.4369, 0.2912, 0.3263, param: [3.20147481 4.20660187 6.21961881 4.10120337]train_grp_loss: [20.3695832  16.77061956 20.18800534], val_grp_loss: [21.20739957 14.81682389 19.86927755], train_hist_grp_loss: [2119.44082223 1772.27778128 2098.96854079], cur_train_grp_loss: [20.37987214 16.77833246 20.19827209],max_reward_err:  0.0670, max_reward_err_index: 0, max_kl_dist:  0.4369, max_kl_dist_index: 0, max_train_grp_loss:  20.3696, max_train_grp_loss_index: 0, max_val_grp_loss:  21.2074, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  20.3799, max_cur_train_grp_loss_index: 0, 
2024-09-18 20:31:53,255 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:387] - INFO: Policy parameter learned solely on the preference data dpo: [3.20147481 4.20660187 6.21961881 4.10120337].
2024-09-18 20:31:53,599 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Uniform reward: 3.8388, 3.8388, 3.2321
2024-09-18 20:31:53,600 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Optimal reward: 3.8833, 3.8833, 3.3901
2024-09-18 20:31:53,600 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Policy reward: 3.6231, 3.7605, 3.2713
2024-09-18 20:31:53,601 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Reward Error: 0.0670, 0.0316, 0.0351
2024-09-18 20:31:54,283 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:416] - INFO: Optimal reward: 3.8833, 3.8833, 3.3901
Known param reward: [[3.883310317993164, 3.4867608547210693, 3.3494973182678223], [3.4867608547210693, 3.883310317993164, 3.1918535232543945], [3.8442142009735107, 3.598407745361328, 3.390115261077881]], Known param reward error: [[0.0, 0.1021163468277821, 0.011981286676708506], [0.1021163468277821, 0.0, 0.05848230002671041], [0.010067729287176206, 0.07336590416474088, 0.0]].
