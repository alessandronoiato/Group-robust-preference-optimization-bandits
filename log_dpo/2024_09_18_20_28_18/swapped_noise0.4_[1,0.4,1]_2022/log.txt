2024-09-18 20:32:25,149 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log_dpo/2024_09_18_20_28_18/swapped_noise0.4_[1,0.4,1]_2022
2024-09-18 20:32:25,151 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2022
2024-09-18 20:32:25,151 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-09-18 20:32:25,313 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.4879, l2 distance: 12.6795, acc: 0.82.
2024-09-18 20:32:25,314 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-18 20:32:25,315 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [6.75502214 3.97653476 5.79379738 4.90833845]
2024-09-18 20:32:25,523 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.6743, 3.8038, 3.2594
2024-09-18 20:32:26,974 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:947] - INFO: Iteration:  0, train_loss:  21.7590, val_loss:  22.4073, grad_norm: 0.7626, reward_err: 0.0198, 0.1039, 0.0274, KL_dist: 0.0403, 0.3101, 0.0619, param: [1.99762396 4.48691609 0.06026887 2.33200341]train_grp_loss: [21.89753189 21.5046226  22.09178126], val_grp_loss: [21.98245558 23.04869695 22.16425915], train_hist_grp_loss: [21.93314628 21.58652294 22.1430964 ], cur_train_grp_loss: [21.93314628 21.58652294 22.1430964 ],max_reward_err:  0.1039, max_reward_err_index: 1, max_kl_dist:  0.3101, max_kl_dist_index: 1, max_train_grp_loss:  22.0918, max_train_grp_loss_index: 2, max_val_grp_loss:  23.0487, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  22.1431, max_cur_train_grp_loss_index: 2, 
2024-09-18 20:32:30,202 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:1040] - INFO: Iteration:  99, train_loss:  18.5031, val_loss:  19.2581, grad_norm: 0.4096, reward_err: 0.0408, 0.0344, 0.0142, KL_dist: 0.3648, 0.3190, 0.2832, param: [5.43448679 4.61533711 3.99053629 4.34080547]train_grp_loss: [19.5764206  17.43066502 18.61492764], val_grp_loss: [20.53552163 17.59502912 19.70840313], train_hist_grp_loss: [2059.40519083 1899.36175356 2016.39192894], cur_train_grp_loss: [19.59120849 17.44687175 18.63820846],max_reward_err:  0.0408, max_reward_err_index: 0, max_kl_dist:  0.3648, max_kl_dist_index: 0, max_train_grp_loss:  19.5764, max_train_grp_loss_index: 0, max_val_grp_loss:  20.5355, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  19.5912, max_cur_train_grp_loss_index: 0, 
2024-09-18 20:32:30,438 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:387] - INFO: Policy parameter learned solely on the preference data dpo: [5.43448679 4.61533711 3.99053629 4.34080547].
2024-09-18 20:32:30,781 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Uniform reward: 3.8352, 3.8352, 3.1931
2024-09-18 20:32:30,782 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Optimal reward: 3.8672, 3.8672, 3.3262
2024-09-18 20:32:30,783 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Policy reward: 3.7095, 3.7343, 3.2788
2024-09-18 20:32:30,783 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Reward Error: 0.0408, 0.0344, 0.0142
2024-09-18 20:32:31,484 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:416] - INFO: Optimal reward: 3.8672, 3.8672, 3.3262
Known param reward: [[3.867177724838257, 3.538572311401367, 3.2763869762420654], [3.538572311401367, 3.867177724838257, 3.1662933826446533], [3.823817253112793, 3.633922815322876, 3.3261606693267822]], Known param reward error: [[0.0, 0.08497292775718847, 0.01496430811166769], [0.08497292775718847, 0.0, 0.04806360924064627], [0.011212433151692661, 0.060316573509725795, 0.0]].
