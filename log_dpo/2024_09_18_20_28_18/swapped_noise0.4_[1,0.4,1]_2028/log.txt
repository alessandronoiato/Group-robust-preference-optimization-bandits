2024-09-18 20:34:16,522 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log_dpo/2024_09_18_20_28_18/swapped_noise0.4_[1,0.4,1]_2028
2024-09-18 20:34:16,524 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2028
2024-09-18 20:34:16,525 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-09-18 20:34:16,691 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.5013, l2 distance: 13.1473, acc: 0.80.
2024-09-18 20:34:16,692 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-18 20:34:16,693 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [6.95011815 4.29889072 6.20277518 4.38213871]
2024-09-18 20:34:16,905 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.5639, 3.7646, 3.1600
2024-09-18 20:34:18,361 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:947] - INFO: Iteration:  0, train_loss:  21.2339, val_loss:  21.3958, grad_norm: 0.7123, reward_err: 0.0413, 0.0895, 0.0148, KL_dist: 0.1101, 0.2482, 0.0528, param: [2.99318736 0.23841168 2.36785567 4.77352107]train_grp_loss: [22.46275857 19.56105565 21.74751959], val_grp_loss: [21.88234795 20.59905939 21.60606878], train_hist_grp_loss: [22.49188951 19.64307774 21.78446554], cur_train_grp_loss: [22.49188951 19.64307774 21.78446554],max_reward_err:  0.0895, max_reward_err_index: 1, max_kl_dist:  0.2482, max_kl_dist_index: 1, max_train_grp_loss:  22.4628, max_train_grp_loss_index: 0, max_val_grp_loss:  21.8823, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  22.4919, max_cur_train_grp_loss_index: 0, 
2024-09-18 20:34:21,619 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:1040] - INFO: Iteration:  99, train_loss:  18.6818, val_loss:  18.8946, grad_norm: 0.3416, reward_err: 0.0469, 0.0306, 0.0174, KL_dist: 0.4466, 0.3528, 0.3391, param: [5.52869968 3.52829608 4.93889139 5.3082321 ]train_grp_loss: [20.69972588 16.04180742 19.31327306], val_grp_loss: [19.57509011 17.95926581 19.02442049], train_hist_grp_loss: [2144.81380796 1729.78430197 2038.69050525], cur_train_grp_loss: [20.70985445 16.05303308 19.32913454],max_reward_err:  0.0469, max_reward_err_index: 0, max_kl_dist:  0.4466, max_kl_dist_index: 0, max_train_grp_loss:  20.6997, max_train_grp_loss_index: 0, max_val_grp_loss:  19.5751, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  20.7099, max_cur_train_grp_loss_index: 0, 
2024-09-18 20:34:21,850 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:387] - INFO: Policy parameter learned solely on the preference data dpo: [5.52869968 3.52829608 4.93889139 5.3082321 ].
2024-09-18 20:34:22,193 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Uniform reward: 3.7723, 3.7723, 3.1239
2024-09-18 20:34:22,194 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Optimal reward: 3.8153, 3.8153, 3.2617
2024-09-18 20:34:22,194 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Policy reward: 3.6365, 3.6984, 3.2048
2024-09-18 20:34:22,195 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Reward Error: 0.0469, 0.0306, 0.0174
2024-09-18 20:34:22,892 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:416] - INFO: Optimal reward: 3.8153, 3.8153, 3.2617
Known param reward: [[3.815298318862915, 3.4180736541748047, 3.2313497066497803], [3.4180736541748047, 3.815298318862915, 3.058016777038574], [3.7792916297912598, 3.547971248626709, 3.2616615295410156]], Known param reward error: [[0.0, 0.10411365809174691, 0.00929336861495278], [0.10411365809174691, 0.0, 0.06243589368731908], [0.009437450511703749, 0.07006714754506493, 0.0]].
