2024-09-18 20:37:10,182 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log_dpo/2024_09_18_20_28_18/swapped_noise0.3_[1,0.3,1]_2027
2024-09-18 20:37:10,184 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2027
2024-09-18 20:37:10,184 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-09-18 20:37:10,346 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.5030, l2 distance: 12.0541, acc: 0.81.
2024-09-18 20:37:10,346 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-18 20:37:10,347 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [6.32296269 3.05508145 6.41888649 4.05651239]
2024-09-18 20:37:10,553 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.5164, 3.7309, 3.1230
2024-09-18 20:37:11,989 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:947] - INFO: Iteration:  0, train_loss:  19.9103, val_loss:  20.1393, grad_norm: 0.6064, reward_err: 0.0848, 0.0208, 0.0488, KL_dist: 0.3731, 0.1226, 0.2368, param: [4.19119638 0.34107025 4.72574166 3.23188607]train_grp_loss: [22.12370454 16.84012831 20.95814265], val_grp_loss: [22.03288089 16.5677056  21.87597975], train_hist_grp_loss: [22.15488003 16.88315394 20.99420731], cur_train_grp_loss: [22.15488003 16.88315394 20.99420731],max_reward_err:  0.0848, max_reward_err_index: 0, max_kl_dist:  0.3731, max_kl_dist_index: 0, max_train_grp_loss:  22.1237, max_train_grp_loss_index: 0, max_val_grp_loss:  22.0329, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  22.1549, max_cur_train_grp_loss_index: 0, 
2024-09-18 20:37:15,206 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:1040] - INFO: Iteration:  99, train_loss:  18.1832, val_loss:  18.2004, grad_norm: 0.2694, reward_err: 0.0665, 0.0162, 0.0335, KL_dist: 0.6782, 0.3631, 0.5108, param: [6.18459916 2.56692032 6.85137874 4.87764123]train_grp_loss: [20.26532862 15.55261909 18.70365949], val_grp_loss: [20.07764203 14.62955013 19.95269532], train_hist_grp_loss: [2105.02253232 1589.2473011  1967.67601613], cur_train_grp_loss: [20.27589298 15.55248403 18.71741511],max_reward_err:  0.0665, max_reward_err_index: 0, max_kl_dist:  0.6782, max_kl_dist_index: 0, max_train_grp_loss:  20.2653, max_train_grp_loss_index: 0, max_val_grp_loss:  20.0776, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  20.2759, max_cur_train_grp_loss_index: 0, 
2024-09-18 20:37:15,431 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:387] - INFO: Policy parameter learned solely on the preference data dpo: [6.18459916 2.56692032 6.85137874 4.87764123].
2024-09-18 20:37:15,771 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Uniform reward: 3.7264, 3.7264, 3.0887
2024-09-18 20:37:15,772 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Optimal reward: 3.7644, 3.7644, 3.2276
2024-09-18 20:37:15,772 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Policy reward: 3.5141, 3.7033, 3.1196
2024-09-18 20:37:15,773 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Reward Error: 0.0665, 0.0162, 0.0335
2024-09-18 20:37:16,464 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:416] - INFO: Optimal reward: 3.7644, 3.7644, 3.2276
Known param reward: [[3.7643983364105225, 3.4167792797088623, 3.185643196105957], [3.4167792797088623, 3.7643983364105225, 3.0518436431884766], [3.725473642349243, 3.5370585918426514, 3.2276272773742676]], Known param reward error: [[0.0, 0.09234385568056709, 0.013007722906117384], [0.09234385568056709, 0.0, 0.05446218509120859], [0.010340216571871954, 0.06039205319186466, 0.0]].
