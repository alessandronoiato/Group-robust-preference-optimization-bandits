2024-09-18 20:28:41,569 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log_dpo/2024_09_18_20_28_18/swapped_noise0.5_[1,0.5,1]_2022
2024-09-18 20:28:41,571 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2022
2024-09-18 20:28:41,572 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-09-18 20:28:41,741 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.4500, l2 distance: 16.7322, acc: 0.80.
2024-09-18 20:28:41,742 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-18 20:28:41,743 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [9.385783   4.87832338 6.31300798 4.61071713]
2024-09-18 20:28:41,954 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.6061, 3.8367, 3.2033
2024-09-18 20:28:43,431 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:947] - INFO: Iteration:  0, train_loss:  19.2111, val_loss:  19.8922, grad_norm: 0.6099, reward_err: 0.0319, 0.0358, 0.0090, KL_dist: 0.1632, 0.1750, 0.1070, param: [3.01180529 3.10080223 3.80750083 3.91167301]train_grp_loss: [20.82385941 16.9913815  21.04885658], val_grp_loss: [21.13122591 17.50910098 21.06724377], train_hist_grp_loss: [20.85208304 17.03995747 21.07771956], cur_train_grp_loss: [20.85208304 17.03995747 21.07771956],max_reward_err:  0.0358, max_reward_err_index: 1, max_kl_dist:  0.1750, max_kl_dist_index: 1, max_train_grp_loss:  21.0489, max_train_grp_loss_index: 2, max_val_grp_loss:  21.1312, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  21.0777, max_cur_train_grp_loss_index: 2, 
2024-09-18 20:28:46,679 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:1040] - INFO: Iteration:  99, train_loss:  17.1018, val_loss:  18.0991, grad_norm: 0.3353, reward_err: 0.0462, 0.0167, 0.0174, KL_dist: 0.6146, 0.4030, 0.4826, param: [6.37429498 4.5937159  6.31499264 4.60081189]train_grp_loss: [19.04645776 14.48155632 19.16317202], val_grp_loss: [19.66540603 15.48571381 19.19316482], train_hist_grp_loss: [1981.50082478 1546.99333411 1999.16149605], cur_train_grp_loss: [19.05732563 14.49276153 19.1753022 ],max_reward_err:  0.0462, max_reward_err_index: 0, max_kl_dist:  0.6146, max_kl_dist_index: 0, max_train_grp_loss:  19.1632, max_train_grp_loss_index: 2, max_val_grp_loss:  19.6654, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  19.1753, max_cur_train_grp_loss_index: 2, 
2024-09-18 20:28:46,910 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:387] - INFO: Policy parameter learned solely on the preference data dpo: [6.37429498 4.5937159  6.31499264 4.60081189].
2024-09-18 20:28:47,249 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Uniform reward: 3.8487, 3.8487, 3.2033
2024-09-18 20:28:47,250 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Optimal reward: 3.8787, 3.8787, 3.3327
2024-09-18 20:28:47,251 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Policy reward: 3.6993, 3.8139, 3.2746
2024-09-18 20:28:47,251 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Reward Error: 0.0462, 0.0167, 0.0174
2024-09-18 20:28:47,939 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:416] - INFO: Optimal reward: 3.8787, 3.8787, 3.3327
Known param reward: [[3.878673791885376, 3.5492217540740967, 3.282655954360962], [3.5492217540740967, 3.878673791885376, 3.170855760574341], [3.8372855186462402, 3.6475391387939453, 3.3327279090881348]], Known param reward error: [[0.0, 0.08493935182188567, 0.015024315243566644], [0.08493935182188567, 0.0, 0.04857046627550332], [0.01067072805290424, 0.05959115550655239, 0.0]].
