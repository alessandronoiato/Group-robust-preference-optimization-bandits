2024-09-17 23:22:55,092 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:198] - INFO: Logging to log_dpo/2024_09_17_23_21_16/swapped_noise0.7_[0.7,0.7,0.7]_2026
2024-09-17 23:22:55,094 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: (IB) Seed: 2026
2024-09-17 23:22:55,094 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Data: 300
2024-09-17 23:22:55,254 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:296] - INFO: MLE reward loss: 0.5423, l2 distance: 8.6591, acc: 0.77.
2024-09-17 23:22:55,255 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-17 23:22:55,256 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: MLE reward parameter: [4.43045691 3.35973106 5.3283573  3.47844623]
2024-09-17 23:22:55,453 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:313] - INFO: Learned oracle reward: 3.6055, 3.8040, 3.2127
2024-09-17 23:22:56,753 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:947] - INFO: Iteration:  0, train_loss:  21.6070, val_loss:  21.7063, grad_norm: 0.6672, reward_err: 0.0814, 0.0147, 0.0449, KL_dist: 0.1505, 0.0249, 0.0780, param: [1.72649339 1.86602826 3.42427139 1.58703495]train_grp_loss: [23.53696091 18.0671332  23.2546556 ], val_grp_loss: [23.62858349 18.18391773 23.17932276], train_hist_grp_loss: [23.56208042 18.14328198 23.28617432], cur_train_grp_loss: [23.56208042 18.14328198 23.28617432],max_reward_err:  0.0814, max_reward_err_index: 0, max_kl_dist:  0.1505, max_kl_dist_index: 0, max_train_grp_loss:  23.5370, max_train_grp_loss_index: 0, max_val_grp_loss:  23.6286, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  23.5621, max_cur_train_grp_loss_index: 0, 
2024-09-17 23:22:59,887 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:1040] - INFO: Iteration:  99, train_loss:  19.5770, val_loss:  19.7530, grad_norm: 0.2845, reward_err: 0.0627, 0.0320, 0.0281, KL_dist: 0.3638, 0.2429, 0.2669, param: [3.8589836  3.74949046 5.5188303  4.11931697]train_grp_loss: [22.14953907 15.2035659  21.40241438], val_grp_loss: [22.2587397  15.34378519 21.49198798], train_hist_grp_loss: [2271.41844953 1615.22135077 2217.97048173], cur_train_grp_loss: [22.15648073 15.21069896 21.41272278],max_reward_err:  0.0627, max_reward_err_index: 0, max_kl_dist:  0.3638, max_kl_dist_index: 0, max_train_grp_loss:  22.1495, max_train_grp_loss_index: 0, max_val_grp_loss:  22.2587, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  22.1565, max_cur_train_grp_loss_index: 0, 
2024-09-17 23:23:00,109 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:386] - INFO: Policy parameter learned solely on the preference data dpo: [3.8589836  3.74949046 5.5188303  4.11931697].
2024-09-17 23:23:00,431 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:397] - INFO: Uniform reward: 3.8335, 3.8335, 3.1932
2024-09-17 23:23:00,432 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Optimal reward: 3.8720, 3.8720, 3.3164
2024-09-17 23:23:00,432 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Policy reward: 3.6292, 3.7481, 3.2231
2024-09-17 23:23:00,433 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Reward Error: 0.0627, 0.0320, 0.0281
2024-09-17 23:23:01,100 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:415] - INFO: Optimal reward: 3.8720, 3.8720, 3.3164
Known param reward: [[3.871964454650879, 3.4825620651245117, 3.283604145050049], [3.4825620651245117, 3.871964454650879, 3.1281747817993164], [3.8297793865203857, 3.6000421047210693, 3.316359758377075]], Known param reward error: [[0.0, 0.10056972218808197, 0.00987697828749917], [0.10056972218808197, 0.0, 0.0567444397738835], [0.010895003976552992, 0.07022852433554373, 0.0]].
