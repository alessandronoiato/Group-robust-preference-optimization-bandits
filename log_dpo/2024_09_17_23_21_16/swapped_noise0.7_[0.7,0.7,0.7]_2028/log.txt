2024-09-17 23:23:33,169 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:198] - INFO: Logging to log_dpo/2024_09_17_23_21_16/swapped_noise0.7_[0.7,0.7,0.7]_2028
2024-09-17 23:23:33,171 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: (IB) Seed: 2028
2024-09-17 23:23:33,172 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Data: 300
2024-09-17 23:23:33,341 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:296] - INFO: MLE reward loss: 0.4966, l2 distance: 15.2791, acc: 0.78.
2024-09-17 23:23:33,342 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-17 23:23:33,343 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: MLE reward parameter: [6.8041789  4.08605626 8.32789205 4.25371169]
2024-09-17 23:23:33,551 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:313] - INFO: Learned oracle reward: 3.5940, 3.8655, 3.2275
2024-09-17 23:23:34,824 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:947] - INFO: Iteration:  0, train_loss:  20.8734, val_loss:  20.1562, grad_norm: 0.5837, reward_err: 0.0490, 0.0581, 0.0328, KL_dist: 0.2643, 0.2680, 0.2423, param: [0.47680922 3.53557831 5.03173589 4.40876094]train_grp_loss: [21.56737922 18.88027393 21.9370121 ], val_grp_loss: [21.89489142 16.59251803 21.89641665], train_hist_grp_loss: [21.58029874 18.96180942 21.95152211], cur_train_grp_loss: [21.58029874 18.96180942 21.95152211],max_reward_err:  0.0581, max_reward_err_index: 1, max_kl_dist:  0.2680, max_kl_dist_index: 1, max_train_grp_loss:  21.9370, max_train_grp_loss_index: 2, max_val_grp_loss:  21.8964, max_val_grp_loss_index: 2, max_cur_train_grp_loss:  21.9515, max_cur_train_grp_loss_index: 2, 
2024-09-17 23:23:37,963 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:1040] - INFO: Iteration:  99, train_loss:  18.7741, val_loss:  18.2188, grad_norm: 0.3512, reward_err: 0.0746, 0.0173, 0.0441, KL_dist: 0.7069, 0.3380, 0.5719, param: [3.65215208 3.78308005 8.23030147 4.54357625]train_grp_loss: [20.69847583 14.03811539 20.94163948], val_grp_loss: [21.20994077 12.59186569 20.69600462], train_hist_grp_loss: [2108.43938011 1606.99846651 2138.74123473], cur_train_grp_loss: [20.70423893 14.06464003 20.94841839],max_reward_err:  0.0746, max_reward_err_index: 0, max_kl_dist:  0.7069, max_kl_dist_index: 0, max_train_grp_loss:  20.9416, max_train_grp_loss_index: 2, max_val_grp_loss:  21.2099, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  20.9484, max_cur_train_grp_loss_index: 2, 
2024-09-17 23:23:38,188 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:386] - INFO: Policy parameter learned solely on the preference data dpo: [3.65215208 3.78308005 8.23030147 4.54357625].
2024-09-17 23:23:38,512 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:397] - INFO: Uniform reward: 3.8595, 3.8595, 3.2317
2024-09-17 23:23:38,513 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Optimal reward: 3.8937, 3.8937, 3.3654
2024-09-17 23:23:38,513 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Policy reward: 3.6034, 3.8265, 3.2169
2024-09-17 23:23:38,514 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Reward Error: 0.0746, 0.0173, 0.0441
2024-09-17 23:23:39,199 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:415] - INFO: Optimal reward: 3.8937, 3.8937, 3.3654
Known param reward: [[3.8937318325042725, 3.480532169342041, 3.329375982284546], [3.480532169342041, 3.8937318325042725, 3.148448944091797], [3.859982490539551, 3.6322221755981445, 3.3654303550720215]], Known param reward error: [[0.0, 0.1061191887209346, 0.010713153737719826], [0.1061191887209346, 0.0, 0.06447360013057858], [0.008667608201208769, 0.06716170197523252, 0.0]].
