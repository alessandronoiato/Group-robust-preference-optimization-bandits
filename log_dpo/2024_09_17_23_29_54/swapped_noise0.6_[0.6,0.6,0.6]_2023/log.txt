2024-09-17 23:30:36,198 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:198] - INFO: Logging to log_dpo/2024_09_17_23_29_54/swapped_noise0.6_[0.6,0.6,0.6]_2023
2024-09-17 23:30:36,200 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: (IB) Seed: 2023
2024-09-17 23:30:36,200 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Data: 300
2024-09-17 23:30:36,358 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:296] - INFO: MLE reward loss: 0.5541, l2 distance: 9.0828, acc: 0.72.
2024-09-17 23:30:36,359 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-17 23:30:36,359 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: MLE reward parameter: [5.45722274 2.96957708 5.11155783 1.87329973]
2024-09-17 23:30:36,560 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:313] - INFO: Learned oracle reward: 3.4911, 3.8151, 3.1132
2024-09-17 23:30:37,818 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:947] - INFO: Iteration:  0, train_loss:  21.0203, val_loss:  20.6925, grad_norm: 0.4433, reward_err: 0.0361, 0.0540, 0.0121, KL_dist: 0.2054, 0.2775, 0.1531, param: [2.98159685 3.92398772 4.20624404 4.47714823]train_grp_loss: [22.64975117 17.94036943 22.75996168], val_grp_loss: [21.82200386 17.95749522 22.26465429], train_hist_grp_loss: [22.64927304 17.9940658  22.76246292], cur_train_grp_loss: [22.64927304 17.9940658  22.76246292],max_reward_err:  0.0540, max_reward_err_index: 1, max_kl_dist:  0.2775, max_kl_dist_index: 1, max_train_grp_loss:  22.7600, max_train_grp_loss_index: 2, max_val_grp_loss:  22.2647, max_val_grp_loss_index: 2, max_cur_train_grp_loss:  22.7625, max_cur_train_grp_loss_index: 2, 
2024-09-17 23:30:40,913 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:1040] - INFO: Iteration:  99, train_loss:  19.8530, val_loss:  19.5329, grad_norm: 0.2557, reward_err: 0.0702, 0.0142, 0.0332, KL_dist: 0.5580, 0.2944, 0.4157, param: [5.36286007 4.23119561 6.34795937 3.50401876]train_grp_loss: [22.75909414 14.61732126 22.66541138], val_grp_loss: [21.55362827 15.10948867 21.88593986], train_hist_grp_loss: [2269.6446088  1604.23108732 2269.39563757], cur_train_grp_loss: [22.75771661 14.63706526 22.66541541],max_reward_err:  0.0702, max_reward_err_index: 0, max_kl_dist:  0.5580, max_kl_dist_index: 0, max_train_grp_loss:  22.7591, max_train_grp_loss_index: 0, max_val_grp_loss:  21.8859, max_val_grp_loss_index: 2, max_cur_train_grp_loss:  22.7577, max_cur_train_grp_loss_index: 0, 
2024-09-17 23:30:41,128 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:386] - INFO: Policy parameter learned solely on the preference data dpo: [5.36286007 4.23119561 6.34795937 3.50401876].
2024-09-17 23:30:41,468 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:397] - INFO: Uniform reward: 3.7949, 3.7949, 3.1453
2024-09-17 23:30:41,468 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Optimal reward: 3.8294, 3.8294, 3.2691
2024-09-17 23:30:41,469 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Policy reward: 3.5607, 3.7749, 3.1606
2024-09-17 23:30:41,469 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Reward Error: 0.0702, 0.0142, 0.0332
2024-09-17 23:30:42,134 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:415] - INFO: Optimal reward: 3.8294, 3.8294, 3.2691
Known param reward: [[3.8294012546539307, 3.4349207878112793, 3.23325252532959], [3.4349207878112793, 3.8294012546539307, 3.072456121444702], [3.788132905960083, 3.56136417388916, 3.26906156539917]], Known param reward error: [[0.0, 0.10301361508231428, 0.010953920369256675], [0.10301361508231428, 0.0, 0.060141248496328396], [0.010776710495849343, 0.0699945142700888, 0.0]].
