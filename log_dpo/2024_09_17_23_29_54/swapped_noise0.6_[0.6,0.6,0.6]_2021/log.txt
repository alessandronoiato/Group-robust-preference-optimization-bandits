2024-09-17 23:29:58,339 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:198] - INFO: Logging to log_dpo/2024_09_17_23_29_54/swapped_noise0.6_[0.6,0.6,0.6]_2021
2024-09-17 23:29:58,340 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: (IB) Seed: 2021
2024-09-17 23:29:58,341 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Data: 300
2024-09-17 23:29:58,507 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:296] - INFO: MLE reward loss: 0.4951, l2 distance: 13.1445, acc: 0.76.
2024-09-17 23:29:58,508 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-17 23:29:58,509 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: MLE reward parameter: [4.92528682 2.82562179 8.10314816 4.49028275]
2024-09-17 23:29:58,723 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:313] - INFO: Learned oracle reward: 3.5340, 3.8361, 3.1483
2024-09-17 23:30:00,026 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:947] - INFO: Iteration:  0, train_loss:  20.3216, val_loss:  20.5693, grad_norm: 0.6683, reward_err: 0.0848, 0.0235, 0.0441, KL_dist: 0.3209, 0.1212, 0.2016, param: [4.15044042 3.52675914 4.51508556 0.91007267]train_grp_loss: [23.07203725 15.43299802 22.82965755], val_grp_loss: [23.18796012 16.69299508 22.03924955], train_hist_grp_loss: [23.09021018 15.52665439 22.84748434], cur_train_grp_loss: [23.09021018 15.52665439 22.84748434],max_reward_err:  0.0848, max_reward_err_index: 0, max_kl_dist:  0.3209, max_kl_dist_index: 0, max_train_grp_loss:  23.0720, max_train_grp_loss_index: 0, max_val_grp_loss:  23.1880, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  23.0902, max_cur_train_grp_loss_index: 0, 
2024-09-17 23:30:03,164 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:1040] - INFO: Iteration:  99, train_loss:  18.0726, val_loss:  18.7442, grad_norm: 0.3175, reward_err: 0.0853, 0.0074, 0.0454, KL_dist: 0.6759, 0.3201, 0.5127, param: [5.99228102 3.27114612 7.24648047 4.13317463]train_grp_loss: [21.91602051 11.10519086 21.7277958 ], val_grp_loss: [22.28142045 13.57922376 20.65552931], train_hist_grp_loss: [2241.80246505 1271.44036391 2219.95566278], cur_train_grp_loss: [21.92318427 11.12120389 21.7342833 ],max_reward_err:  0.0853, max_reward_err_index: 0, max_kl_dist:  0.6759, max_kl_dist_index: 0, max_train_grp_loss:  21.9160, max_train_grp_loss_index: 0, max_val_grp_loss:  22.2814, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  21.9232, max_cur_train_grp_loss_index: 0, 
2024-09-17 23:30:03,387 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:386] - INFO: Policy parameter learned solely on the preference data dpo: [5.99228102 3.27114612 7.24648047 4.13317463].
2024-09-17 23:30:03,721 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:397] - INFO: Uniform reward: 3.8597, 3.8597, 3.2149
2024-09-17 23:30:03,722 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Optimal reward: 3.8945, 3.8945, 3.3287
2024-09-17 23:30:03,723 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Policy reward: 3.5622, 3.8655, 3.1776
2024-09-17 23:30:03,723 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Reward Error: 0.0853, 0.0074, 0.0454
2024-09-17 23:30:04,405 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:415] - INFO: Optimal reward: 3.8945, 3.8945, 3.3287
Known param reward: [[3.894500255584717, 3.4684839248657227, 3.3039445877075195], [3.4684839248657227, 3.894500255584717, 3.1122233867645264], [3.8594319820404053, 3.600018262863159, 3.328740119934082]], Known param reward error: [[0.0, 0.10938921626929832, 0.007448924017250562], [0.10938921626929832, 0.0, 0.06504464913705647], [0.009004563164175836, 0.07561483461177597, 0.0]].
