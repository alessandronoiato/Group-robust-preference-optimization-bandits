2024-09-18 00:15:59,647 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:198] - INFO: Logging to log_dpo/2024_09_18_00_15_00/swapped_noise0.3_[0.3,0.3,1]_2024
2024-09-18 00:15:59,649 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: (IB) Seed: 2024
2024-09-18 00:15:59,650 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Data: 300
2024-09-18 00:15:59,814 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:296] - INFO: MLE reward loss: 0.5484, l2 distance: 11.7613, acc: 0.72.
2024-09-18 00:15:59,814 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-18 00:15:59,815 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: MLE reward parameter: [8.04989099 2.27718778 3.76647858 1.25812534]
2024-09-18 00:16:00,022 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:313] - INFO: Learned oracle reward: 3.4363, 3.9127, 3.1172
2024-09-18 00:16:01,297 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:947] - INFO: Iteration:  0, train_loss:  21.8630, val_loss:  21.6149, grad_norm: 0.4939, reward_err: 0.0610, 0.0447, 0.0300, KL_dist: 0.1651, 0.1174, 0.0960, param: [2.27847124 1.73016801 3.92981806 3.61288769]train_grp_loss: [23.88354905 19.44306618 21.91661373], val_grp_loss: [24.12919296 18.95278557 21.61354875], train_hist_grp_loss: [23.88910596 19.49252191 21.93820478], cur_train_grp_loss: [23.88910596 19.49252191 21.93820478],max_reward_err:  0.0610, max_reward_err_index: 0, max_kl_dist:  0.1651, max_kl_dist_index: 0, max_train_grp_loss:  23.8835, max_train_grp_loss_index: 0, max_val_grp_loss:  24.1292, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  23.8891, max_cur_train_grp_loss_index: 0, 
2024-09-18 00:16:04,393 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:1040] - INFO: Iteration:  99, train_loss:  20.2540, val_loss:  20.1791, grad_norm: 0.3224, reward_err: 0.0840, 0.0040, 0.0431, KL_dist: 0.5509, 0.1841, 0.3879, param: [5.61570438 2.53044364 5.86413488 3.17236457]train_grp_loss: [23.56403986 16.29721108 20.33541252], val_grp_loss: [23.94256004 15.91449828 20.4397287 ], train_hist_grp_loss: [2369.54368175 1765.93605145 2106.17899499], cur_train_grp_loss: [23.56564225 16.31634145 20.34704734],max_reward_err:  0.0840, max_reward_err_index: 0, max_kl_dist:  0.5509, max_kl_dist_index: 0, max_train_grp_loss:  23.5640, max_train_grp_loss_index: 0, max_val_grp_loss:  23.9426, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  23.5656, max_cur_train_grp_loss_index: 0, 
2024-09-18 00:16:04,616 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:386] - INFO: Policy parameter learned solely on the preference data dpo: [5.61570438 2.53044364 5.86413488 3.17236457].
2024-09-18 00:16:04,951 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:397] - INFO: Uniform reward: 3.8827, 3.8827, 3.2643
2024-09-18 00:16:04,952 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Optimal reward: 3.9217, 3.9217, 3.3993
2024-09-18 00:16:04,952 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Policy reward: 3.5923, 3.9061, 3.2528
2024-09-18 00:16:04,952 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Reward Error: 0.0840, 0.0040, 0.0431
2024-09-18 00:16:05,641 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:415] - INFO: Optimal reward: 3.9217, 3.9217, 3.3993
Known param reward: [[3.9217183589935303, 3.5069820880889893, 3.3640332221984863], [3.5069820880889893, 3.9217183589935303, 3.1911284923553467], [3.880511999130249, 3.6409873962402344, 3.399339199066162]], Known param reward error: [[0.0, 0.10575371124074777, 0.010386129421087117], [0.10575371124074777, 0.0, 0.06125034735221873], [0.01050722058323853, 0.07158366232738414, 0.0]].
