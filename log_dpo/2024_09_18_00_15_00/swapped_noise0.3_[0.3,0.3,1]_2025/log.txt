2024-09-18 00:16:17,622 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:198] - INFO: Logging to log_dpo/2024_09_18_00_15_00/swapped_noise0.3_[0.3,0.3,1]_2025
2024-09-18 00:16:17,624 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: (IB) Seed: 2025
2024-09-18 00:16:17,624 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Data: 300
2024-09-18 00:16:17,787 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:296] - INFO: MLE reward loss: 0.5538, l2 distance: 8.9714, acc: 0.73.
2024-09-18 00:16:17,788 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-18 00:16:17,789 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: MLE reward parameter: [5.6201857  2.02979985 4.80944882 3.0171891 ]
2024-09-18 00:16:17,998 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:313] - INFO: Learned oracle reward: 3.5606, 3.8633, 3.1831
2024-09-18 00:16:19,285 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:947] - INFO: Iteration:  0, train_loss:  22.0675, val_loss:  22.1782, grad_norm: 0.6162, reward_err: 0.0999, 0.0021, 0.0598, KL_dist: 0.2324, 0.0065, 0.1247, param: [3.15107832 1.33561112 2.78754243 0.48769193]train_grp_loss: [24.28921524 19.28524302 23.14412383], val_grp_loss: [24.34429797 19.6537552  22.74681181], train_hist_grp_loss: [24.29975791 19.35439776 23.17200655], cur_train_grp_loss: [24.29975791 19.35439776 23.17200655],max_reward_err:  0.0999, max_reward_err_index: 0, max_kl_dist:  0.2324, max_kl_dist_index: 0, max_train_grp_loss:  24.2892, max_train_grp_loss_index: 0, max_val_grp_loss:  24.3443, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  24.2998, max_cur_train_grp_loss_index: 0, 
2024-09-18 00:16:22,385 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:1040] - INFO: Iteration:  99, train_loss:  20.0231, val_loss:  20.2595, grad_norm: 0.3172, reward_err: 0.0855, 0.0023, 0.0472, KL_dist: 0.5577, 0.1565, 0.3872, param: [5.81544903 2.0100222  5.32016189 2.85148651]train_grp_loss: [23.66112081 15.91332652 21.27563791], val_grp_loss: [23.80222652 16.78616429 20.52224513], train_hist_grp_loss: [2392.57279345 1719.96142408 2210.41808138], cur_train_grp_loss: [23.66463739 15.92674755 21.28795992],max_reward_err:  0.0855, max_reward_err_index: 0, max_kl_dist:  0.5577, max_kl_dist_index: 0, max_train_grp_loss:  23.6611, max_train_grp_loss_index: 0, max_val_grp_loss:  23.8022, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  23.6646, max_cur_train_grp_loss_index: 0, 
2024-09-18 00:16:22,609 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:386] - INFO: Policy parameter learned solely on the preference data dpo: [5.81544903 2.0100222  5.32016189 2.85148651].
2024-09-18 00:16:22,944 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:397] - INFO: Uniform reward: 3.8385, 3.8385, 3.1882
2024-09-18 00:16:22,944 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Optimal reward: 3.8795, 3.8795, 3.3318
2024-09-18 00:16:22,945 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Policy reward: 3.5477, 3.8705, 3.1745
2024-09-18 00:16:22,945 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Reward Error: 0.0855, 0.0023, 0.0472
2024-09-18 00:16:23,627 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:415] - INFO: Optimal reward: 3.8795, 3.8795, 3.3318
Known param reward: [[3.87953782081604, 3.4939897060394287, 3.290055751800537], [3.4939897060394287, 3.87953782081604, 3.1354916095733643], [3.8410425186157227, 3.6315650939941406, 3.3318350315093994]], Known param reward error: [[0.0, 0.09937990878911275, 0.01253942026353427], [0.09937990878911275, 0.0, 0.058929514840681346], [0.009922651609108454, 0.06391811042319977, 0.0]].
