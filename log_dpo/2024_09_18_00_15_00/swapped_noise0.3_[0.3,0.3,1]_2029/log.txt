2024-09-18 00:17:31,183 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:198] - INFO: Logging to log_dpo/2024_09_18_00_15_00/swapped_noise0.3_[0.3,0.3,1]_2029
2024-09-18 00:17:31,185 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: (IB) Seed: 2029
2024-09-18 00:17:31,185 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Data: 300
2024-09-18 00:17:31,349 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:296] - INFO: MLE reward loss: 0.6009, l2 distance: 5.9842, acc: 0.70.
2024-09-18 00:17:31,350 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-18 00:17:31,351 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: MLE reward parameter: [3.17823797 1.67370896 4.32981238 1.29270305]
2024-09-18 00:17:31,558 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:313] - INFO: Learned oracle reward: 3.4971, 3.8739, 3.1784
2024-09-18 00:17:32,805 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:947] - INFO: Iteration:  0, train_loss:  22.2109, val_loss:  21.6825, grad_norm: 0.4093, reward_err: 0.0789, 0.0260, 0.0443, KL_dist: 0.1892, 0.0570, 0.1108, param: [1.80811987 2.78930689 4.00806995 1.34085406]train_grp_loss: [24.38109934 20.70397204 21.81264861], val_grp_loss: [24.4733935  18.33350376 22.00356159], train_hist_grp_loss: [24.38270833 20.72911199 21.83444989], cur_train_grp_loss: [24.38270833 20.72911199 21.83444989],max_reward_err:  0.0789, max_reward_err_index: 0, max_kl_dist:  0.1892, max_kl_dist_index: 0, max_train_grp_loss:  24.3811, max_train_grp_loss_index: 0, max_val_grp_loss:  24.4734, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  24.3827, max_cur_train_grp_loss_index: 0, 
2024-09-18 00:17:35,916 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:1040] - INFO: Iteration:  99, train_loss:  21.2732, val_loss:  20.5093, grad_norm: 0.2207, reward_err: 0.0878, 0.0038, 0.0494, KL_dist: 0.4705, 0.1131, 0.3275, param: [3.77842509 2.86717643 6.11635844 2.16576627]train_grp_loss: [24.3550237  19.48460951 20.30489691], val_grp_loss: [24.44843761 16.07761472 20.67701129], train_hist_grp_loss: [2435.19756063 1994.64783368 2098.20825153], cur_train_grp_loss: [24.3545333  19.48924874 20.31524221],max_reward_err:  0.0878, max_reward_err_index: 0, max_kl_dist:  0.4705, max_kl_dist_index: 0, max_train_grp_loss:  24.3550, max_train_grp_loss_index: 0, max_val_grp_loss:  24.4484, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  24.3545, max_cur_train_grp_loss_index: 0, 
2024-09-18 00:17:36,137 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:386] - INFO: Policy parameter learned solely on the preference data dpo: [3.77842509 2.86717643 6.11635844 2.16576627].
2024-09-18 00:17:36,471 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:397] - INFO: Uniform reward: 3.8327, 3.8327, 3.2256
2024-09-18 00:17:36,472 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Optimal reward: 3.8777, 3.8777, 3.3695
2024-09-18 00:17:36,472 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Policy reward: 3.5372, 3.8628, 3.2029
2024-09-18 00:17:36,473 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Reward Error: 0.0878, 0.0038, 0.0494
2024-09-18 00:17:37,155 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:415] - INFO: Optimal reward: 3.8777, 3.8777, 3.3695
Known param reward: [[3.877681255340576, 3.4682672023773193, 3.333303689956665], [3.4682672023773193, 3.877681255340576, 3.161881923675537], [3.841872215270996, 3.599954605102539, 3.3694965839385986]], Known param reward error: [[0.0, 0.10558218326980516, 0.010741335710044788], [0.10558218326980516, 0.0, 0.06161592840090703], [0.009234652801919114, 0.071621835821481, 0.0]].
