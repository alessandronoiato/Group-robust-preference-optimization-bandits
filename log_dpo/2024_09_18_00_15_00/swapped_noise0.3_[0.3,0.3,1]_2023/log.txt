2024-09-18 00:15:41,889 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:198] - INFO: Logging to log_dpo/2024_09_18_00_15_00/swapped_noise0.3_[0.3,0.3,1]_2023
2024-09-18 00:15:41,891 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: (IB) Seed: 2023
2024-09-18 00:15:41,891 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Data: 300
2024-09-18 00:15:42,050 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:296] - INFO: MLE reward loss: 0.5558, l2 distance: 9.0221, acc: 0.72.
2024-09-18 00:15:42,051 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-18 00:15:42,052 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: MLE reward parameter: [6.19584802 2.72908814 3.85848297 3.05831559]
2024-09-18 00:15:42,258 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:313] - INFO: Learned oracle reward: 3.4972, 3.7813, 3.1032
2024-09-18 00:15:43,526 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:947] - INFO: Iteration:  0, train_loss:  22.6741, val_loss:  22.7700, grad_norm: 0.6496, reward_err: 0.0533, 0.0320, 0.0206, KL_dist: 0.0798, 0.0413, 0.0297, param: [1.81220093 1.64864684 1.71288788 1.09963475]train_grp_loss: [24.42162161 20.28633051 23.50755564], val_grp_loss: [24.07037639 20.93324763 23.11918481], train_hist_grp_loss: [24.43224325 20.37166958 23.53423703], cur_train_grp_loss: [24.43224325 20.37166958 23.53423703],max_reward_err:  0.0533, max_reward_err_index: 0, max_kl_dist:  0.0798, max_kl_dist_index: 0, max_train_grp_loss:  24.4216, max_train_grp_loss_index: 0, max_val_grp_loss:  24.0704, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  24.4322, max_cur_train_grp_loss_index: 0, 
2024-09-18 00:15:46,583 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:1040] - INFO: Iteration:  99, train_loss:  20.3647, val_loss:  20.5848, grad_norm: 0.3407, reward_err: 0.0710, 0.0123, 0.0344, KL_dist: 0.3653, 0.1325, 0.2457, param: [5.12940574 2.88590575 4.21084819 2.93372253]train_grp_loss: [23.84132646 15.82306209 21.78753582], val_grp_loss: [23.13379583 17.4768444  20.83206511], train_hist_grp_loss: [2407.52881948 1759.34120724 2253.74383252], cur_train_grp_loss: [23.84410305 15.84367443 21.79826675],max_reward_err:  0.0710, max_reward_err_index: 0, max_kl_dist:  0.3653, max_kl_dist_index: 0, max_train_grp_loss:  23.8413, max_train_grp_loss_index: 0, max_val_grp_loss:  23.1338, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  23.8441, max_cur_train_grp_loss_index: 0, 
2024-09-18 00:15:46,801 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:386] - INFO: Policy parameter learned solely on the preference data dpo: [5.12940574 2.88590575 4.21084819 2.93372253].
2024-09-18 00:15:47,130 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:397] - INFO: Uniform reward: 3.7823, 3.7823, 3.1340
2024-09-18 00:15:47,130 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Optimal reward: 3.8164, 3.8164, 3.2560
2024-09-18 00:15:47,131 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Policy reward: 3.5454, 3.7694, 3.1441
2024-09-18 00:15:47,131 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Reward Error: 0.0710, 0.0123, 0.0344
2024-09-18 00:15:47,806 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:415] - INFO: Optimal reward: 3.8164, 3.8164, 3.2560
Known param reward: [[3.816397190093994, 3.425919532775879, 3.2214560508728027], [3.425919532775879, 3.816397190093994, 3.061397075653076], [3.77667236328125, 3.5491819381713867, 3.2560200691223145]], Known param reward error: [[0.0, 0.10231578053030119, 0.010615419289730827], [0.10231578053030119, 0.0, 0.05977327821621825], [0.01040898649539299, 0.07001767337430258, 0.0]].
