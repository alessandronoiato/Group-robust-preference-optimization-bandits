2024-09-18 00:17:13,124 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:198] - INFO: Logging to log_dpo/2024_09_18_00_15_00/swapped_noise0.3_[0.3,0.3,1]_2028
2024-09-18 00:17:13,126 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: (IB) Seed: 2028
2024-09-18 00:17:13,127 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Data: 300
2024-09-18 00:17:13,290 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:296] - INFO: MLE reward loss: 0.6022, l2 distance: 6.5058, acc: 0.70.
2024-09-18 00:17:13,291 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-18 00:17:13,291 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: MLE reward parameter: [4.32841582 2.65008307 3.99886397 2.4333316 ]
2024-09-18 00:17:13,494 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:313] - INFO: Learned oracle reward: 3.6247, 3.8508, 3.2489
2024-09-18 00:17:14,761 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:947] - INFO: Iteration:  0, train_loss:  22.7218, val_loss:  22.6291, grad_norm: 0.4247, reward_err: 0.0458, 0.0633, 0.0208, KL_dist: 0.1167, 0.1845, 0.0645, param: [3.52170165 1.43427489 1.91868484 4.33267366]train_grp_loss: [24.09003118 22.29894644 21.3507405 ], val_grp_loss: [23.98537667 22.20926067 21.56968557], train_hist_grp_loss: [24.08917848 22.33854142 21.37199834], cur_train_grp_loss: [24.08917848 22.33854142 21.37199834],max_reward_err:  0.0633, max_reward_err_index: 1, max_kl_dist:  0.1845, max_kl_dist_index: 1, max_train_grp_loss:  24.0900, max_train_grp_loss_index: 0, max_val_grp_loss:  23.9854, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  24.0892, max_cur_train_grp_loss_index: 0, 
2024-09-18 00:17:17,866 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:1040] - INFO: Iteration:  99, train_loss:  21.6430, val_loss:  21.5962, grad_norm: 0.2483, reward_err: 0.0630, 0.0179, 0.0309, KL_dist: 0.3619, 0.1910, 0.2510, param: [5.43755836 2.99975854 3.95122957 3.89787416]train_grp_loss: [24.21168316 20.15491387 19.75555511], val_grp_loss: [23.88034273 20.42223508 20.28740292], train_hist_grp_loss: [2414.56038706 2101.62993822 2049.49111791], cur_train_grp_loss: [24.21030244 20.16505966 19.76760042],max_reward_err:  0.0630, max_reward_err_index: 0, max_kl_dist:  0.3619, max_kl_dist_index: 0, max_train_grp_loss:  24.2117, max_train_grp_loss_index: 0, max_val_grp_loss:  23.8803, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  24.2103, max_cur_train_grp_loss_index: 0, 
2024-09-18 00:17:18,087 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:386] - INFO: Policy parameter learned solely on the preference data dpo: [5.43755836 2.99975854 3.95122957 3.89787416].
2024-09-18 00:17:18,414 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:397] - INFO: Uniform reward: 3.8548, 3.8548, 3.2274
2024-09-18 00:17:18,415 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Optimal reward: 3.8897, 3.8897, 3.3617
2024-09-18 00:17:18,415 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Policy reward: 3.6447, 3.8202, 3.2577
2024-09-18 00:17:18,416 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Reward Error: 0.0630, 0.0179, 0.0309
2024-09-18 00:17:19,094 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:415] - INFO: Optimal reward: 3.8897, 3.8897, 3.3617
Known param reward: [[3.8896820545196533, 3.4789624214172363, 3.324706554412842], [3.4789624214172363, 3.8896820545196533, 3.1460585594177246], [3.855863332748413, 3.632194757461548, 3.3616816997528076]], Known param reward error: [[0.0, 0.10559208370904696, 0.010999002476256063], [0.10559208370904696, 0.0, 0.06414145049810584], [0.00869446944434552, 0.06619751780455053, 0.0]].
