2024-09-18 00:17:50,208 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:198] - INFO: Logging to log_dpo/2024_09_18_00_15_00/swapped_noise0.3_[0.3,0.3,1]_2030
2024-09-18 00:17:50,210 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: (IB) Seed: 2030
2024-09-18 00:17:50,210 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Data: 300
2024-09-18 00:17:50,374 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:296] - INFO: MLE reward loss: 0.5370, l2 distance: 9.6501, acc: 0.76.
2024-09-18 00:17:50,375 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-18 00:17:50,376 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: MLE reward parameter: [5.67778576 2.25753769 5.48532197 2.33243305]
2024-09-18 00:17:50,586 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:313] - INFO: Learned oracle reward: 3.5670, 3.8970, 3.2444
2024-09-18 00:17:51,878 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:947] - INFO: Iteration:  0, train_loss:  21.2885, val_loss:  21.8809, grad_norm: 0.5752, reward_err: 0.0748, 0.0667, 0.0391, KL_dist: 0.1734, 0.1402, 0.0859, param: [2.40568964 0.0877641  3.30651815 3.66813667]train_grp_loss: [24.11839783 18.12743179 22.08091634], val_grp_loss: [24.06453547 19.25208073 22.14323068], train_hist_grp_loss: [24.12526736 18.18292702 22.11329843], cur_train_grp_loss: [24.12526736 18.18292702 22.11329843],max_reward_err:  0.0748, max_reward_err_index: 0, max_kl_dist:  0.1734, max_kl_dist_index: 0, max_train_grp_loss:  24.1184, max_train_grp_loss_index: 0, max_val_grp_loss:  24.0645, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  24.1253, max_cur_train_grp_loss_index: 0, 
2024-09-18 00:17:55,036 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:1040] - INFO: Iteration:  99, train_loss:  19.4327, val_loss:  19.9198, grad_norm: 0.3120, reward_err: 0.0831, 0.0155, 0.0436, KL_dist: 0.5775, 0.2051, 0.4024, param: [5.32164923 1.62036985 5.92499351 4.02310302]train_grp_loss: [23.79331486 15.31060403 19.89801441], val_grp_loss: [23.60880901 15.69005109 20.15235425], train_hist_grp_loss: [2391.30089044 1640.95814806 2086.86079433], cur_train_grp_loss: [23.79433393 15.32281808 19.91254461],max_reward_err:  0.0831, max_reward_err_index: 0, max_kl_dist:  0.5775, max_kl_dist_index: 0, max_train_grp_loss:  23.7933, max_train_grp_loss_index: 0, max_val_grp_loss:  23.6088, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  23.7943, max_cur_train_grp_loss_index: 0, 
2024-09-18 00:17:55,270 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:386] - INFO: Policy parameter learned solely on the preference data dpo: [5.32164923 1.62036985 5.92499351 4.02310302].
2024-09-18 00:17:55,599 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:397] - INFO: Uniform reward: 3.8586, 3.8586, 3.2436
2024-09-18 00:17:55,600 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Optimal reward: 3.9020, 3.9020, 3.3991
2024-09-18 00:17:55,600 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Policy reward: 3.5776, 3.8414, 3.2508
2024-09-18 00:17:55,600 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Reward Error: 0.0831, 0.0155, 0.0436
2024-09-18 00:17:56,293 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:415] - INFO: Optimal reward: 3.9020, 3.9020, 3.3991
Known param reward: [[3.902012586593628, 3.5148375034332275, 3.3579766750335693], [3.5148375034332275, 3.902012586593628, 3.205984354019165], [3.8625452518463135, 3.624565362930298, 3.399076461791992]], Known param reward error: [[0.0, 0.09922445778125893, 0.012091456964976615], [0.09922445778125893, 0.0, 0.05680722688745549], [0.010114609799802972, 0.07110362088953062, 0.0]].
