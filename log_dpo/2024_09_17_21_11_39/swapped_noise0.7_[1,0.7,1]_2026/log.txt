2024-09-17 21:13:16,518 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:198] - INFO: Logging to log_dpo/2024_09_17_21_11_39/swapped_noise0.7_[1,0.7,1]_2026
2024-09-17 21:13:16,520 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: (IB) Seed: 2026
2024-09-17 21:13:16,520 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Data: 300
2024-09-17 21:13:16,677 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:296] - INFO: MLE reward loss: 0.4755, l2 distance: 16.9014, acc: 0.77.
2024-09-17 21:13:16,678 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-17 21:13:16,679 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: MLE reward parameter: [7.0226657  4.42818104 9.53176052 3.17686003]
2024-09-17 21:13:16,874 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:313] - INFO: Learned oracle reward: 3.4968, 3.8612, 3.1627
2024-09-17 21:13:18,156 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:947] - INFO: Iteration:  0, train_loss:  21.4115, val_loss:  20.7123, grad_norm: 0.6784, reward_err: 0.0241, 0.0847, 0.0099, KL_dist: 0.0467, 0.1930, 0.0211, param: [2.48408247 4.04123574 1.52122029 1.63736339]train_grp_loss: [22.24294769 20.19388699 21.79114013], val_grp_loss: [22.02831174 18.06631266 21.8950487 ], train_hist_grp_loss: [22.26915666 20.26973315 21.82685403], cur_train_grp_loss: [22.26915666 20.26973315 21.82685403],max_reward_err:  0.0847, max_reward_err_index: 1, max_kl_dist:  0.1930, max_kl_dist_index: 1, max_train_grp_loss:  22.2429, max_train_grp_loss_index: 0, max_val_grp_loss:  22.0283, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  22.2692, max_cur_train_grp_loss_index: 0, 
2024-09-17 21:13:21,140 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:1040] - INFO: Iteration:  99, train_loss:  18.5762, val_loss:  17.6439, grad_norm: 0.4110, reward_err: 0.0533, 0.0198, 0.0236, KL_dist: 0.4735, 0.2893, 0.3451, param: [5.65923003 4.73397197 5.35424385 3.14209698]train_grp_loss: [20.56725465 15.78132916 19.35522853], val_grp_loss: [20.24528998 12.92040676 19.49206281], train_hist_grp_loss: [2129.48304598 1762.26786464 2044.35549268], cur_train_grp_loss: [20.5775572  15.80533775 19.37169423],max_reward_err:  0.0533, max_reward_err_index: 0, max_kl_dist:  0.4735, max_kl_dist_index: 0, max_train_grp_loss:  20.5673, max_train_grp_loss_index: 0, max_val_grp_loss:  20.2453, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  20.5776, max_cur_train_grp_loss_index: 0, 
2024-09-17 21:13:21,355 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:386] - INFO: Policy parameter learned solely on the preference data dpo: [5.65923003 4.73397197 5.35424385 3.14209698].
2024-09-17 21:13:21,676 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:397] - INFO: Uniform reward: 3.8338, 3.8338, 3.2190
2024-09-17 21:13:21,677 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Optimal reward: 3.8731, 3.8731, 3.3639
2024-09-17 21:13:21,677 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Policy reward: 3.6665, 3.7964, 3.2845
2024-09-17 21:13:21,678 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Reward Error: 0.0533, 0.0198, 0.0236
2024-09-17 21:13:22,336 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:415] - INFO: Optimal reward: 3.8731, 3.8731, 3.3639
Known param reward: [[3.873142719268799, 3.4625096321105957, 3.3238730430603027], [3.4625096321105957, 3.873142719268799, 3.1438493728637695], [3.8371264934539795, 3.6077330112457275, 3.363903284072876]], Known param reward error: [[0.0, 0.10602064445374364, 0.011899938146885801], [0.10602064445374364, 0.0, 0.06541624197431568], [0.009298966866271003, 0.0685256721118651, 0.0]].
