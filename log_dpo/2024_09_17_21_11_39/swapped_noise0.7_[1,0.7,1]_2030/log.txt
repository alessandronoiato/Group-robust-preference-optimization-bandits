2024-09-17 21:14:30,748 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:198] - INFO: Logging to log_dpo/2024_09_17_21_11_39/swapped_noise0.7_[1,0.7,1]_2030
2024-09-17 21:14:30,750 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: (IB) Seed: 2030
2024-09-17 21:14:30,751 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Data: 300
2024-09-17 21:14:30,917 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:296] - INFO: MLE reward loss: 0.5028, l2 distance: 14.4583, acc: 0.80.
2024-09-17 21:14:30,918 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-17 21:14:30,918 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: MLE reward parameter: [7.494746   3.1680416  7.18686853 4.41994426]
2024-09-17 21:14:31,119 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:313] - INFO: Learned oracle reward: 3.6021, 3.8710, 3.2761
2024-09-17 21:14:32,413 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:947] - INFO: Iteration:  0, train_loss:  22.1803, val_loss:  22.0327, grad_norm: 0.6773, reward_err: 0.0036, 0.1167, 0.0042, KL_dist: 0.0076, 0.2584, 0.0078, param: [1.37047962 1.50399505 1.1472084  4.0420616 ]train_grp_loss: [22.47679435 21.5584074  22.55671776], val_grp_loss: [22.39821711 21.06507364 22.5062877 ], train_hist_grp_loss: [22.49389855 21.64198547 22.58856225], cur_train_grp_loss: [22.49389855 21.64198547 22.58856225],max_reward_err:  0.1167, max_reward_err_index: 1, max_kl_dist:  0.2584, max_kl_dist_index: 1, max_train_grp_loss:  22.5567, max_train_grp_loss_index: 2, max_val_grp_loss:  22.5063, max_val_grp_loss_index: 2, max_cur_train_grp_loss:  22.5886, max_cur_train_grp_loss_index: 2, 
2024-09-17 21:14:35,473 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:1040] - INFO: Iteration:  99, train_loss:  19.3760, val_loss:  18.8202, grad_norm: 0.4060, reward_err: 0.0558, 0.0316, 0.0219, KL_dist: 0.3978, 0.2466, 0.2763, param: [5.11985073 2.73202582 4.50666851 4.63504328]train_grp_loss: [21.50382781 16.57611982 20.39882493], val_grp_loss: [20.72046365 15.0322801  20.18871221], train_hist_grp_loss: [2190.26453119 1867.86724393 2136.01441253], cur_train_grp_loss: [21.50868931 16.60425428 20.41326912],max_reward_err:  0.0558, max_reward_err_index: 0, max_kl_dist:  0.3978, max_kl_dist_index: 0, max_train_grp_loss:  21.5038, max_train_grp_loss_index: 0, max_val_grp_loss:  20.7205, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  21.5087, max_cur_train_grp_loss_index: 0, 
2024-09-17 21:14:35,688 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:386] - INFO: Policy parameter learned solely on the preference data dpo: [5.11985073 2.73202582 4.50666851 4.63504328].
2024-09-17 21:14:36,006 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:397] - INFO: Uniform reward: 3.8520, 3.8520, 3.2425
2024-09-17 21:14:36,006 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Optimal reward: 3.8957, 3.8957, 3.3999
2024-09-17 21:14:36,007 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Policy reward: 3.6783, 3.7725, 3.3254
2024-09-17 21:14:36,007 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Reward Error: 0.0558, 0.0316, 0.0219
2024-09-17 21:14:36,676 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:415] - INFO: Optimal reward: 3.8957, 3.8957, 3.3999
Known param reward: [[3.895703077316284, 3.5065040588378906, 3.358201503753662], [3.5065040588378906, 3.895703077316284, 3.206737756729126], [3.8558998107910156, 3.6177587509155273, 3.399937152862549]], Known param reward error: [[0.0, 0.09990469262008268, 0.012275417818752249], [0.09990469262008268, 0.0, 0.056824402171893156], [0.010217222856904351, 0.07134638366541791, 0.0]].
