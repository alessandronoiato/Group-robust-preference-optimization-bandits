2024-09-17 16:25:43,981 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:198] - INFO: Logging to log_dpo/2024_09_17_16_24_45/swapped_noise1.0_[1,1,1]_2024
2024-09-17 16:25:43,983 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: (IB) Seed: 2024
2024-09-17 16:25:43,983 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Data: 300
2024-09-17 16:25:44,147 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:296] - INFO: MLE reward loss: 0.3356, l2 distance: 38.9673, acc: 0.85.
2024-09-17 16:25:44,148 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-17 16:25:44,149 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: MLE reward parameter: [17.27970071  8.4454928  15.8117603   7.63032288]
2024-09-17 16:25:44,352 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:313] - INFO: Learned oracle reward: 3.4756, 3.7525, 3.0863
2024-09-17 16:25:45,617 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:947] - INFO: Iteration:  0, train_loss:  22.0800, val_loss:  22.3063, grad_norm: 0.8751, reward_err: 0.0021, 0.1300, 0.0211, KL_dist: 0.0128, 0.3590, 0.0464, param: [0.9946068  4.74847767 0.49825704 2.07024756]train_grp_loss: [22.32186166 21.4282462  22.39678155], val_grp_loss: [22.14910735 22.41608454 22.35359669], train_hist_grp_loss: [22.3547992  21.58897946 22.44432204], cur_train_grp_loss: [22.3547992  21.58897946 22.44432204],max_reward_err:  0.1300, max_reward_err_index: 1, max_kl_dist:  0.3590, max_kl_dist_index: 1, max_train_grp_loss:  22.3968, max_train_grp_loss_index: 2, max_val_grp_loss:  22.4161, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  22.4443, max_cur_train_grp_loss_index: 2, 
2024-09-17 16:25:48,646 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:1040] - INFO: Iteration:  99, train_loss:  17.3079, val_loss:  17.9253, grad_norm: 0.5366, reward_err: 0.0506, 0.0383, 0.0218, KL_dist: 0.4983, 0.3995, 0.3741, param: [5.93704286 5.84612469 5.0204244  2.60519743]train_grp_loss: [20.14464141 11.9357932  19.07569816], val_grp_loss: [20.58528768 13.00210158 19.80845663], train_hist_grp_loss: [2110.38056014 1591.97672409 2057.34623777], cur_train_grp_loss: [20.15867432 11.98825097 19.09878677],max_reward_err:  0.0506, max_reward_err_index: 0, max_kl_dist:  0.4983, max_kl_dist_index: 0, max_train_grp_loss:  20.1446, max_train_grp_loss_index: 0, max_val_grp_loss:  20.5853, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  20.1587, max_cur_train_grp_loss_index: 0, 
2024-09-17 16:25:48,874 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:386] - INFO: Policy parameter learned solely on the preference data dpo: [5.93704286 5.84612469 5.0204244  2.60519743].
2024-09-17 16:25:49,211 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:397] - INFO: Uniform reward: 3.7209, 3.7209, 3.0767
2024-09-17 16:25:49,212 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Optimal reward: 3.7640, 3.7640, 3.2194
2024-09-17 16:25:49,213 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Policy reward: 3.5735, 3.6199, 3.1492
2024-09-17 16:25:49,213 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Reward Error: 0.0506, 0.0383, 0.0218
2024-09-17 16:25:49,909 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:415] - INFO: Optimal reward: 3.7640, 3.7640, 3.2194
Known param reward: [[3.763953685760498, 3.410576581954956, 3.186079502105713], [3.410576581954956, 3.763953685760498, 3.0397133827209473], [3.730111837387085, 3.5351030826568604, 3.21937894821167]], Known param reward error: [[0.0, 0.0938845515401561, 0.010343437862279155], [0.0938845515401561, 0.0, 0.05580752324622267], [0.008991037403419968, 0.06080058954216355, 0.0]].
