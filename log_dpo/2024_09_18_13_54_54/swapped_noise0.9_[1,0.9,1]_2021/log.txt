2024-09-18 13:58:04,535 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log_dpo/2024_09_18_13_54_54/swapped_noise0.9_[1,0.9,1]_2021
2024-09-18 13:58:04,537 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2021
2024-09-18 13:58:04,537 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-09-18 13:58:04,698 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.4663, l2 distance: 18.0905, acc: 0.74.
2024-09-18 13:58:04,698 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-18 13:58:04,699 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [7.60830304 2.96644436 9.79918051 5.12566951]
2024-09-18 13:58:04,912 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.4399, 3.7688, 3.0673
2024-09-18 13:58:06,208 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:947] - INFO: Iteration:  0, train_loss:  22.6722, val_loss:  21.7983, grad_norm: 0.8776, reward_err: 0.0319, 0.0956, 0.0128, KL_dist: 0.0468, 0.1421, 0.0203, param: [0.92656511 3.14244809 1.98983317 0.68366936]train_grp_loss: [23.60295315 21.46990884 23.02139883], val_grp_loss: [23.0783621  19.5547197  22.87704431], train_hist_grp_loss: [23.61929486 21.64306321 23.05519564], cur_train_grp_loss: [23.61929486 21.64306321 23.05519564],max_reward_err:  0.0956, max_reward_err_index: 1, max_kl_dist:  0.1421, max_kl_dist_index: 1, max_train_grp_loss:  23.6030, max_train_grp_loss_index: 0, max_val_grp_loss:  23.0784, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  23.6193, max_cur_train_grp_loss_index: 0, 
2024-09-18 13:58:09,385 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:1040] - INFO: Iteration:  99, train_loss:  18.5194, val_loss:  17.6472, grad_norm: 0.4565, reward_err: 0.0768, 0.0152, 0.0418, KL_dist: 0.4869, 0.2115, 0.3523, param: [4.42070895 2.8785994  6.20155161 3.7938005 ]train_grp_loss: [22.84177492 12.19741775 20.95703924], val_grp_loss: [21.33002878 11.65062204 20.25683851], train_hist_grp_loss: [2311.79291205 1594.20030115 2183.68724784], cur_train_grp_loss: [22.84393299 12.2438461  20.9690512 ],max_reward_err:  0.0768, max_reward_err_index: 0, max_kl_dist:  0.4869, max_kl_dist_index: 0, max_train_grp_loss:  22.8418, max_train_grp_loss_index: 0, max_val_grp_loss:  21.3300, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  22.8439, max_cur_train_grp_loss_index: 0, 
2024-09-18 13:58:09,619 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:387] - INFO: Policy parameter learned solely on the preference data dpo: [4.42070895 2.8785994  6.20155161 3.7938005 ].
2024-09-18 13:58:09,942 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Uniform reward: 3.7630, 3.7630, 3.1214
2024-09-18 13:58:09,943 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Optimal reward: 3.7946, 3.7946, 3.2447
2024-09-18 13:58:09,943 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Policy reward: 3.5032, 3.7369, 3.1089
2024-09-18 13:58:09,943 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Reward Error: 0.0768, 0.0152, 0.0418
2024-09-18 13:58:10,613 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:416] - INFO: Optimal reward: 3.7946, 3.7946, 3.2447
Known param reward: [[3.7945611476898193, 3.4039535522460938, 3.2116000652313232], [3.4039535522460938, 3.7945611476898193, 3.0445375442504883], [3.760617256164551, 3.530181884765625, 3.244687080383301]], Known param reward error: [[0.0, 0.10293880642338121, 0.010197290010495838], [0.10293880642338121, 0.0, 0.061685312381238463], [0.008945406386700095, 0.06967321190360895, 0.0]].
