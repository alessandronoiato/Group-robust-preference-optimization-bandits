2024-09-18 14:41:47,117 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log_dpo/2024_09_18_13_54_54/swapped_noise0.6_[1,0.6,1]_2026
2024-09-18 14:41:47,118 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2026
2024-09-18 14:41:47,119 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-09-18 14:41:47,275 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.4485, l2 distance: 19.4178, acc: 0.80.
2024-09-18 14:41:47,275 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-18 14:41:47,276 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [ 7.26938793  6.21993296 10.33362814  4.30205527]
2024-09-18 14:41:47,476 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.5664, 3.8388, 3.2173
2024-09-18 14:41:48,756 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:947] - INFO: Iteration:  0, train_loss:  21.2382, val_loss:  21.6202, grad_norm: 0.7442, reward_err: 0.0625, 0.0610, 0.0437, KL_dist: 0.1167, 0.1189, 0.0877, param: [3.32179708 1.97839655 0.33528469 2.90498586]train_grp_loss: [22.64858785 19.27340529 21.77401008], val_grp_loss: [22.8039866  19.37436833 22.53517144], train_hist_grp_loss: [22.68458571 19.352701   21.82477691], cur_train_grp_loss: [22.68458571 19.352701   21.82477691],max_reward_err:  0.0625, max_reward_err_index: 0, max_kl_dist:  0.1189, max_kl_dist_index: 1, max_train_grp_loss:  22.6486, max_train_grp_loss_index: 0, max_val_grp_loss:  22.8040, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  22.6846, max_cur_train_grp_loss_index: 0, 
2024-09-18 14:41:51,885 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:1040] - INFO: Iteration:  99, train_loss:  18.0909, val_loss:  18.5503, grad_norm: 0.4156, reward_err: 0.0559, 0.0261, 0.0287, KL_dist: 0.4631, 0.3189, 0.3589, param: [6.39928836 4.66236477 3.8070007  4.13619375]train_grp_loss: [20.37362539 15.46072212 18.36724868], val_grp_loss: [20.69586129 14.90341915 19.80417936], train_hist_grp_loss: [2135.82165211 1691.47794239 1988.1386465 ], cur_train_grp_loss: [20.38754503 15.47625133 18.38999092],max_reward_err:  0.0559, max_reward_err_index: 0, max_kl_dist:  0.4631, max_kl_dist_index: 0, max_train_grp_loss:  20.3736, max_train_grp_loss_index: 0, max_val_grp_loss:  20.6959, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  20.3875, max_cur_train_grp_loss_index: 0, 
2024-09-18 14:41:52,096 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:387] - INFO: Policy parameter learned solely on the preference data dpo: [6.39928836 4.66236477 3.8070007  4.13619375].
2024-09-18 14:41:52,414 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Uniform reward: 3.8367, 3.8367, 3.2239
2024-09-18 14:41:52,414 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Optimal reward: 3.8763, 3.8763, 3.3712
2024-09-18 14:41:52,415 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Policy reward: 3.6596, 3.7750, 3.2743
2024-09-18 14:41:52,415 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Reward Error: 0.0559, 0.0261, 0.0287
2024-09-18 14:41:53,067 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:416] - INFO: Optimal reward: 3.8763, 3.8763, 3.3712
Known param reward: [[3.8763370513916016, 3.4733924865722656, 3.3310515880584717], [3.4733924865722656, 3.8763370513916016, 3.1582860946655273], [3.8394391536712646, 3.610290050506592, 3.3711864948272705]], Known param reward error: [[0.0, 0.10394982672486625, 0.011905276326415522], [0.10394982672486625, 0.0, 0.0631529583096089], [0.00951875371804694, 0.06863360883169309, 0.0]].
