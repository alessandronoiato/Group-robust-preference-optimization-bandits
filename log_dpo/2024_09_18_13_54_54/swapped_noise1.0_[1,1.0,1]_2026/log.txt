2024-09-18 13:56:31,913 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log_dpo/2024_09_18_13_54_54/swapped_noise1.0_[1,1.0,1]_2026
2024-09-18 13:56:31,915 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2026
2024-09-18 13:56:31,915 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-09-18 13:56:32,074 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.3087, l2 distance: 38.9242, acc: 0.85.
2024-09-18 13:56:32,074 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-18 13:56:32,075 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [15.88878879  8.80170801 16.01295451  9.88039608]
2024-09-18 13:56:32,281 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.5908, 3.8271, 3.2006
2024-09-18 13:56:33,588 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:947] - INFO: Iteration:  0, train_loss:  19.0592, val_loss:  19.5381, grad_norm: 0.8028, reward_err: 0.0309, 0.0495, 0.0063, KL_dist: 0.1148, 0.1770, 0.0693, param: [2.82644357 3.51575362 3.14412398 3.44761109]train_grp_loss: [21.6219995  14.92546941 20.63803494], val_grp_loss: [21.26911305 16.14244384 20.90707529], train_hist_grp_loss: [21.64716571 15.04955095 20.68167399], cur_train_grp_loss: [21.64716571 15.04955095 20.68167399],max_reward_err:  0.0495, max_reward_err_index: 1, max_kl_dist:  0.1770, max_kl_dist_index: 1, max_train_grp_loss:  21.6220, max_train_grp_loss_index: 0, max_val_grp_loss:  21.2691, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  21.6472, max_cur_train_grp_loss_index: 0, 
2024-09-18 13:56:36,785 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:1040] - INFO: Iteration:  99, train_loss:  15.2763, val_loss:  15.9288, grad_norm: 0.4565, reward_err: 0.0650, 0.0141, 0.0285, KL_dist: 0.7729, 0.4562, 0.6057, param: [6.85838664 4.59795224 7.34763899 4.66137591]train_grp_loss: [20.05289821  8.07694569 17.67628749], val_grp_loss: [19.50165092  9.70780367 18.01618978], train_hist_grp_loss: [2072.73351331 1085.37173246 1899.70146837], cur_train_grp_loss: [20.06226483  8.11041188 17.69619203],max_reward_err:  0.0650, max_reward_err_index: 0, max_kl_dist:  0.7729, max_kl_dist_index: 0, max_train_grp_loss:  20.0529, max_train_grp_loss_index: 0, max_val_grp_loss:  19.5017, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  20.0623, max_cur_train_grp_loss_index: 0, 
2024-09-18 13:56:37,008 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:387] - INFO: Policy parameter learned solely on the preference data dpo: [6.85838664 4.59795224 7.34763899 4.66137591].
2024-09-18 13:56:37,334 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Uniform reward: 3.8214, 3.8214, 3.1807
2024-09-18 13:56:37,334 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Optimal reward: 3.8609, 3.8609, 3.3073
2024-09-18 13:56:37,335 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Policy reward: 3.6098, 3.8065, 3.2130
2024-09-18 13:56:37,335 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Reward Error: 0.0650, 0.0141, 0.0285
2024-09-18 13:56:38,012 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:416] - INFO: Optimal reward: 3.8609, 3.8609, 3.3073
Known param reward: [[3.8608756065368652, 3.4840316772460938, 3.274003028869629], [3.4840316772460938, 3.8608756065368652, 3.124580144882202], [3.820035219192505, 3.599329948425293, 3.307262659072876]], Known param reward error: [[0.0, 0.09760581994735479, 0.010056543320502622], [0.09760581994735479, 0.0, 0.055236772225972876], [0.010578011701597771, 0.06774257571747408, 0.0]].
