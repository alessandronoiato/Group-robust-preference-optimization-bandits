2024-09-18 13:57:27,169 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log_dpo/2024_09_18_13_54_54/swapped_noise1.0_[1,1.0,1]_2029
2024-09-18 13:57:27,171 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2029
2024-09-18 13:57:27,171 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-09-18 13:57:27,326 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.3532, l2 distance: 33.1000, acc: 0.81.
2024-09-18 13:57:27,327 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-18 13:57:27,328 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [15.26318978  5.90939445 13.38318868  8.0442321 ]
2024-09-18 13:57:27,528 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.5516, 3.8821, 3.2266
2024-09-18 13:57:28,803 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:947] - INFO: Iteration:  0, train_loss:  21.3701, val_loss:  21.4370, grad_norm: 0.9458, reward_err: 0.1383, 0.0053, 0.0936, KL_dist: 0.2996, 0.0157, 0.1809, param: [2.08524755 0.78919724 3.69240855 0.13937262]train_grp_loss: [24.35397889 17.51522916 22.86546934], val_grp_loss: [24.06492457 16.81481556 23.21879597], train_hist_grp_loss: [24.38834757 17.68110332 22.92039397], cur_train_grp_loss: [24.38834757 17.68110332 22.92039397],max_reward_err:  0.1383, max_reward_err_index: 0, max_kl_dist:  0.2996, max_kl_dist_index: 0, max_train_grp_loss:  24.3540, max_train_grp_loss_index: 0, max_val_grp_loss:  24.0649, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  24.3883, max_cur_train_grp_loss_index: 0, 
2024-09-18 13:57:31,977 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:1040] - INFO: Iteration:  99, train_loss:  16.4099, val_loss:  16.9507, grad_norm: 0.5064, reward_err: 0.0930, 0.0029, 0.0511, KL_dist: 0.7993, 0.3008, 0.5907, param: [6.48868111 2.29323821 7.31482025 3.72061921]train_grp_loss: [22.26648062  8.9875233  19.1801024 ], val_grp_loss: [21.67219363  8.99489888 19.79883443], train_hist_grp_loss: [2315.25095697 1234.17390898 2081.58380922], cur_train_grp_loss: [22.27840072  9.0257622  19.20451006],max_reward_err:  0.0930, max_reward_err_index: 0, max_kl_dist:  0.7993, max_kl_dist_index: 0, max_train_grp_loss:  22.2665, max_train_grp_loss_index: 0, max_val_grp_loss:  21.6722, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  22.2784, max_cur_train_grp_loss_index: 0, 
2024-09-18 13:57:32,203 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:387] - INFO: Policy parameter learned solely on the preference data dpo: [6.48868111 2.29323821 7.31482025 3.72061921].
2024-09-18 13:57:32,527 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Uniform reward: 3.8498, 3.8498, 3.2396
2024-09-18 13:57:32,527 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Optimal reward: 3.8959, 3.8959, 3.3863
2024-09-18 13:57:32,528 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Policy reward: 3.5335, 3.8846, 3.2133
2024-09-18 13:57:32,528 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Reward Error: 0.0930, 0.0029, 0.0511
2024-09-18 13:57:33,197 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:416] - INFO: Optimal reward: 3.8959, 3.8959, 3.3863
Known param reward: [[3.8959105014801025, 3.483445405960083, 3.349421739578247], [3.483445405960083, 3.8959105014801025, 3.177966833114624], [3.861229658126831, 3.6135663986206055, 3.386277914047241]], Known param reward error: [[0.0, 0.10587129641795394, 0.010883978044478947], [0.10587129641795394, 0.0, 0.06151623883807166], [0.008901858330702367, 0.0724719170915839, 0.0]].
