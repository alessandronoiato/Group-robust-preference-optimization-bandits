2024-09-17 16:43:12,179 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:198] - INFO: Logging to log_dpo/2024_09_17_16_43_07/swapped_noise0.9_[1,1,1]_2021
2024-09-17 16:43:12,181 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: (IB) Seed: 2021
2024-09-17 16:43:12,181 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Data: 300
2024-09-17 16:43:12,345 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:296] - INFO: MLE reward loss: 0.3558, l2 distance: 33.1024, acc: 0.82.
2024-09-17 16:43:12,346 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-17 16:43:12,347 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: MLE reward parameter: [13.32826759  7.48737825 15.0322688   7.4309059 ]
2024-09-17 16:43:12,554 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:313] - INFO: Learned oracle reward: 3.5551, 3.8681, 3.1638
2024-09-17 16:43:13,821 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:947] - INFO: Iteration:  0, train_loss:  20.4470, val_loss:  20.2312, grad_norm: 0.8598, reward_err: 0.0634, 0.0581, 0.0288, KL_dist: 0.1248, 0.1097, 0.0558, param: [2.87849015 3.42812422 2.58210452 0.53704304]train_grp_loss: [22.9675198  16.4020049  22.26450646], val_grp_loss: [22.67139457 15.81399756 22.29361026], train_hist_grp_loss: [22.99467598 16.54526611 22.31027286], cur_train_grp_loss: [22.99467598 16.54526611 22.31027286],max_reward_err:  0.0634, max_reward_err_index: 0, max_kl_dist:  0.1248, max_kl_dist_index: 0, max_train_grp_loss:  22.9675, max_train_grp_loss_index: 0, max_val_grp_loss:  22.6714, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  22.9947, max_cur_train_grp_loss_index: 0, 
2024-09-17 16:43:16,814 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:1040] - INFO: Iteration:  99, train_loss:  16.2651, val_loss:  16.1574, grad_norm: 0.4707, reward_err: 0.0821, 0.0054, 0.0422, KL_dist: 0.7051, 0.3367, 0.5339, param: [6.6686057  4.21317974 6.98102027 2.96634201]train_grp_loss: [21.39449052  8.65019644 19.28234385], val_grp_loss: [20.76319493  8.19584109 19.65826502], train_hist_grp_loss: [2204.64411487 1178.02102698 2058.97769639], cur_train_grp_loss: [21.40273104  8.68828539 19.30134505],max_reward_err:  0.0821, max_reward_err_index: 0, max_kl_dist:  0.7051, max_kl_dist_index: 0, max_train_grp_loss:  21.3945, max_train_grp_loss_index: 0, max_val_grp_loss:  20.7632, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  21.4027, max_cur_train_grp_loss_index: 0, 
2024-09-17 16:43:17,027 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:386] - INFO: Policy parameter learned solely on the preference data dpo: [6.6686057  4.21317974 6.98102027 2.96634201].
2024-09-17 16:43:17,347 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:397] - INFO: Uniform reward: 3.8482, 3.8482, 3.1986
2024-09-17 16:43:17,348 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Optimal reward: 3.8836, 3.8836, 3.3119
2024-09-17 16:43:17,348 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Policy reward: 3.5649, 3.8626, 3.1721
2024-09-17 16:43:17,348 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Reward Error: 0.0821, 0.0054, 0.0422
2024-09-17 16:43:18,010 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:415] - INFO: Optimal reward: 3.8836, 3.8836, 3.3119
Known param reward: [[3.8835737705230713, 3.457217216491699, 3.288090705871582], [3.457217216491699, 3.8835737705230713, 3.0940170288085938], [3.8489270210266113, 3.5929198265075684, 3.3118627071380615]], Known param reward error: [[0.0, 0.10978458997418425, 0.007177834158174392], [0.10978458997418425, 0.0, 0.06577738801187161], [0.00892135737434272, 0.07484187534214273, 0.0]].
