2024-09-17 16:44:25,607 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:198] - INFO: Logging to log_dpo/2024_09_17_16_43_07/swapped_noise0.9_[1,1,1]_2025
2024-09-17 16:44:25,608 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: (IB) Seed: 2025
2024-09-17 16:44:25,609 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Data: 300
2024-09-17 16:44:25,767 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:296] - INFO: MLE reward loss: 0.3597, l2 distance: 31.6072, acc: 0.81.
2024-09-17 16:44:25,767 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-17 16:44:25,768 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: MLE reward parameter: [13.00274755  7.23429623 14.54687762  6.41459427]
2024-09-17 16:44:25,970 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:313] - INFO: Learned oracle reward: 3.5469, 3.8252, 3.1158
2024-09-17 16:44:27,216 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:947] - INFO: Iteration:  0, train_loss:  20.3035, val_loss:  20.8838, grad_norm: 0.8827, reward_err: 0.0946, 0.0204, 0.0626, KL_dist: 0.1872, 0.0245, 0.1120, param: [3.93140192 2.06175043 1.60331202 1.24753454]train_grp_loss: [22.91212309 15.98819892 22.76760807], val_grp_loss: [23.11001681 16.79761002 22.63880653], train_hist_grp_loss: [22.95012767 16.1321322  22.80699617], cur_train_grp_loss: [22.95012767 16.1321322  22.80699617],max_reward_err:  0.0946, max_reward_err_index: 0, max_kl_dist:  0.1872, max_kl_dist_index: 0, max_train_grp_loss:  22.9121, max_train_grp_loss_index: 0, max_val_grp_loss:  23.1100, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  22.9501, max_cur_train_grp_loss_index: 0, 
2024-09-17 16:44:30,264 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:1040] - INFO: Iteration:  99, train_loss:  16.1173, val_loss:  16.8547, grad_norm: 0.4542, reward_err: 0.0835, 0.0059, 0.0472, KL_dist: 0.7331, 0.3330, 0.5621, param: [7.89470103 3.62356627 5.80159245 3.30897107]train_grp_loss: [20.69801966  8.56950049 20.4098867 ], val_grp_loss: [21.2656141   9.2797029  19.83683516], train_hist_grp_loss: [2162.1095619  1149.86951228 2140.52899054], cur_train_grp_loss: [20.70998816  8.60354096 20.42317226],max_reward_err:  0.0835, max_reward_err_index: 0, max_kl_dist:  0.7331, max_kl_dist_index: 0, max_train_grp_loss:  20.6980, max_train_grp_loss_index: 0, max_val_grp_loss:  21.2656, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  20.7100, max_cur_train_grp_loss_index: 0, 
2024-09-17 16:44:30,476 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:386] - INFO: Policy parameter learned solely on the preference data dpo: [7.89470103 3.62356627 5.80159245 3.30897107].
2024-09-17 16:44:30,798 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:397] - INFO: Uniform reward: 3.8117, 3.8117, 3.1389
2024-09-17 16:44:30,798 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Optimal reward: 3.8428, 3.8428, 3.2468
2024-09-17 16:44:30,799 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Policy reward: 3.5218, 3.8203, 3.0937
2024-09-17 16:44:30,799 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Reward Error: 0.0835, 0.0059, 0.0472
2024-09-17 16:44:31,455 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:415] - INFO: Optimal reward: 3.8428, 3.8428, 3.2468
Known param reward: [[3.8428120613098145, 3.466555118560791, 3.208935022354126], [3.466555118560791, 3.8428120613098145, 3.0578837394714355], [3.8028461933135986, 3.5883326530456543, 3.246764659881592]], Known param reward error: [[0.0, 0.09791187722586076, 0.01165148740064377], [0.09791187722586076, 0.0, 0.05817511898661749], [0.010400162005995563, 0.06622218422449246, 0.0]].
