2024-09-17 16:45:20,910 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:198] - INFO: Logging to log_dpo/2024_09_17_16_43_07/swapped_noise0.9_[1,1,1]_2028
2024-09-17 16:45:20,913 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: (IB) Seed: 2028
2024-09-17 16:45:20,913 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Data: 300
2024-09-17 16:45:21,081 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:296] - INFO: MLE reward loss: 0.3301, l2 distance: 39.4009, acc: 0.83.
2024-09-17 16:45:21,081 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-17 16:45:21,082 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: MLE reward parameter: [15.25501692 10.32046824 16.71572259  8.98402782]
2024-09-17 16:45:21,287 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:313] - INFO: Learned oracle reward: 3.5948, 3.8326, 3.2226
2024-09-17 16:45:22,550 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:947] - INFO: Iteration:  0, train_loss:  22.4551, val_loss:  22.4943, grad_norm: 0.8867, reward_err: 0.0026, 0.1463, 0.0236, KL_dist: 0.0111, 0.2808, 0.0326, param: [0.56773542 3.70793788 0.59304002 1.5120267 ]train_grp_loss: [22.59059517 22.02420778 22.70413612], val_grp_loss: [22.8429649  21.45763716 23.12638686], train_hist_grp_loss: [22.63777583 22.1783799  22.74848525], cur_train_grp_loss: [22.63777583 22.1783799  22.74848525],max_reward_err:  0.1463, max_reward_err_index: 1, max_kl_dist:  0.2808, max_kl_dist_index: 1, max_train_grp_loss:  22.7041, max_train_grp_loss_index: 2, max_val_grp_loss:  23.1264, max_val_grp_loss_index: 2, max_cur_train_grp_loss:  22.7485, max_cur_train_grp_loss_index: 2, 
2024-09-17 16:45:25,521 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:1040] - INFO: Iteration:  99, train_loss:  17.5461, val_loss:  17.5655, grad_norm: 0.5474, reward_err: 0.0442, 0.0277, 0.0162, KL_dist: 0.4086, 0.3170, 0.3047, param: [5.17198748 4.87390902 5.01044561 3.87969625]train_grp_loss: [19.49498867 12.75063609 19.74035263], val_grp_loss: [20.51214572 12.16332185 19.61170976], train_hist_grp_loss: [2085.49897098 1668.96787309 2105.25251276], cur_train_grp_loss: [19.51478913 12.80447812 19.75977883],max_reward_err:  0.0442, max_reward_err_index: 0, max_kl_dist:  0.4086, max_kl_dist_index: 0, max_train_grp_loss:  19.7404, max_train_grp_loss_index: 2, max_val_grp_loss:  20.5121, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  19.7598, max_cur_train_grp_loss_index: 2, 
2024-09-17 16:45:25,733 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:386] - INFO: Policy parameter learned solely on the preference data dpo: [5.17198748 4.87390902 5.01044561 3.87969625].
2024-09-17 16:45:26,047 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:397] - INFO: Uniform reward: 3.8293, 3.8293, 3.2023
2024-09-17 16:45:26,047 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Optimal reward: 3.8660, 3.8660, 3.3397
2024-09-17 16:45:26,048 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Policy reward: 3.6950, 3.7589, 3.2857
2024-09-17 16:45:26,048 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Reward Error: 0.0442, 0.0277, 0.0162
2024-09-17 16:45:26,704 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:415] - INFO: Optimal reward: 3.8660, 3.8660, 3.3397
Known param reward: [[3.866020441055298, 3.4563794136047363, 3.3043456077575684], [3.4563794136047363, 3.866020441055298, 3.1246166229248047], [3.832627058029175, 3.6058900356292725, 3.3396692276000977]], Known param reward error: [[0.0, 0.10595935373242435, 0.010576981561707841], [0.10595935373242435, 0.0, 0.06439338449988677], [0.008637663337601945, 0.0672863502384944, 0.0]].
