2024-09-17 23:49:10,109 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:198] - INFO: Logging to log_dpo/2024_09_17_23_47_28/swapped_noise0.5_[0.5,0.5,0.5]_2026
2024-09-17 23:49:10,111 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: (IB) Seed: 2026
2024-09-17 23:49:10,111 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Data: 300
2024-09-17 23:49:10,273 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:296] - INFO: MLE reward loss: 0.5775, l2 distance: 6.1091, acc: 0.69.
2024-09-17 23:49:10,274 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-17 23:49:10,275 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: MLE reward parameter: [4.15899603 2.50783879 3.82970656 2.36927035]
2024-09-17 23:49:10,483 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:313] - INFO: Learned oracle reward: 3.5929, 3.8208, 3.2009
2024-09-17 23:49:11,751 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:947] - INFO: Iteration:  0, train_loss:  21.2191, val_loss:  20.9538, grad_norm: 0.4544, reward_err: 0.0927, 0.0006, 0.0504, KL_dist: 0.3660, 0.0460, 0.2288, param: [4.13989129 1.46614168 4.57518985 1.94915446]train_grp_loss: [23.71391786 16.14713585 23.88209024], val_grp_loss: [23.11148942 16.70412798 23.13638197], train_hist_grp_loss: [23.72749394 16.18502481 23.89178556], cur_train_grp_loss: [23.72749394 16.18502481 23.89178556],max_reward_err:  0.0927, max_reward_err_index: 0, max_kl_dist:  0.3660, max_kl_dist_index: 0, max_train_grp_loss:  23.8821, max_train_grp_loss_index: 2, max_val_grp_loss:  23.1364, max_val_grp_loss_index: 2, max_cur_train_grp_loss:  23.8918, max_cur_train_grp_loss_index: 2, 
2024-09-17 23:49:14,842 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:1040] - INFO: Iteration:  99, train_loss:  20.3029, val_loss:  20.2708, grad_norm: 0.1858, reward_err: 0.0736, 0.0091, 0.0344, KL_dist: 0.5180, 0.2141, 0.3710, param: [5.51113412 3.26820897 5.80964391 3.30480281]train_grp_loss: [22.95069214 14.72093378 23.34294862], val_grp_loss: [22.28142002 16.26044075 22.35774442], train_hist_grp_loss: [2326.37958006 1519.40720672 2356.29806915], cur_train_grp_loss: [22.9546081  14.7245424  23.34566616],max_reward_err:  0.0736, max_reward_err_index: 0, max_kl_dist:  0.5180, max_kl_dist_index: 0, max_train_grp_loss:  23.3429, max_train_grp_loss_index: 2, max_val_grp_loss:  22.3577, max_val_grp_loss_index: 2, max_cur_train_grp_loss:  23.3457, max_cur_train_grp_loss_index: 2, 
2024-09-17 23:49:15,063 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:386] - INFO: Policy parameter learned solely on the preference data dpo: [5.51113412 3.26820897 5.80964391 3.30480281].
2024-09-17 23:49:15,391 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:397] - INFO: Uniform reward: 3.8293, 3.8293, 3.1865
2024-09-17 23:49:15,392 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Optimal reward: 3.8673, 3.8673, 3.3083
2024-09-17 23:49:15,393 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Policy reward: 3.5828, 3.8320, 3.1945
2024-09-17 23:49:15,393 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Reward Error: 0.0736, 0.0091, 0.0344
2024-09-17 23:49:16,072 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:415] - INFO: Optimal reward: 3.8673, 3.8673, 3.3083
Known param reward: [[3.8672773838043213, 3.4776079654693604, 3.2754199504852295], [3.4776079654693604, 3.8672773838043213, 3.11952543258667], [3.824310302734375, 3.597230911254883, 3.3083386421203613]], Known param reward error: [[0.0, 0.10076065915696872, 0.009950218280566882], [0.10076065915696872, 0.0, 0.05707191130007124], [0.011110421313425073, 0.06982857595898335, 0.0]].
