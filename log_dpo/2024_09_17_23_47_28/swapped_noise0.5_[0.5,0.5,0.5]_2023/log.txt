2024-09-17 23:48:10,105 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:198] - INFO: Logging to log_dpo/2024_09_17_23_47_28/swapped_noise0.5_[0.5,0.5,0.5]_2023
2024-09-17 23:48:10,107 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: (IB) Seed: 2023
2024-09-17 23:48:10,107 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Data: 300
2024-09-17 23:48:10,268 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:296] - INFO: MLE reward loss: 0.6000, l2 distance: 6.9758, acc: 0.68.
2024-09-17 23:48:10,269 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-17 23:48:10,269 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: MLE reward parameter: [4.704559   1.42187438 3.82459342 1.41318075]
2024-09-17 23:48:10,473 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:313] - INFO: Learned oracle reward: 3.4662, 3.8699, 3.1016
2024-09-17 23:48:11,729 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:947] - INFO: Iteration:  0, train_loss:  22.2866, val_loss:  20.8989, grad_norm: 0.4129, reward_err: 0.0601, 0.0248, 0.0274, KL_dist: 0.1940, 0.0820, 0.1095, param: [3.25311433 1.91670886 3.80262976 3.12484709]train_grp_loss: [23.85812708 20.27892849 22.87872644], val_grp_loss: [23.36911831 15.94966921 22.89323192], train_hist_grp_loss: [23.85391999 20.32521596 22.88524274], cur_train_grp_loss: [23.85391999 20.32521596 22.88524274],max_reward_err:  0.0601, max_reward_err_index: 0, max_kl_dist:  0.1940, max_kl_dist_index: 0, max_train_grp_loss:  23.8581, max_train_grp_loss_index: 0, max_val_grp_loss:  23.3691, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  23.8539, max_cur_train_grp_loss_index: 0, 
2024-09-17 23:48:14,898 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:1040] - INFO: Iteration:  99, train_loss:  21.3180, val_loss:  19.8064, grad_norm: 0.2272, reward_err: 0.0936, 0.0005, 0.0538, KL_dist: 0.5354, 0.1450, 0.3719, param: [5.50200451 2.10838673 5.7280163  2.40225334]train_grp_loss: [24.18309592 17.63045567 22.42840074], val_grp_loss: [23.43514247 12.68112544 22.60414031], train_hist_grp_loss: [2403.16144175 1872.77173018 2263.09787829], cur_train_grp_loss: [24.18063143 17.64457407 22.43152143],max_reward_err:  0.0936, max_reward_err_index: 0, max_kl_dist:  0.5354, max_kl_dist_index: 0, max_train_grp_loss:  24.1831, max_train_grp_loss_index: 0, max_val_grp_loss:  23.4351, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  24.1806, max_cur_train_grp_loss_index: 0, 
2024-09-17 23:48:15,133 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:386] - INFO: Policy parameter learned solely on the preference data dpo: [5.50200451 2.10838673 5.7280163  2.40225334].
2024-09-17 23:48:15,473 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:397] - INFO: Uniform reward: 3.8276, 3.8276, 3.1817
2024-09-17 23:48:15,474 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Optimal reward: 3.8701, 3.8701, 3.3139
2024-09-17 23:48:15,474 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Policy reward: 3.5077, 3.8682, 3.1356
2024-09-17 23:48:15,475 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Reward Error: 0.0936, 0.0005, 0.0538
2024-09-17 23:48:16,192 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:415] - INFO: Optimal reward: 3.8701, 3.8701, 3.3139
Known param reward: [[3.8700804710388184, 3.487717866897583, 3.2859814167022705], [3.487717866897583, 3.8700804710388184, 3.1208972930908203], [3.8352792263031006, 3.614060401916504, 3.3138818740844727]], Known param reward error: [[0.0, 0.09879965210092917, 0.008419267325245327], [0.09879965210092917, 0.0, 0.058235202196809825], [0.008992382715591524, 0.06615368105087303, 0.0]].
