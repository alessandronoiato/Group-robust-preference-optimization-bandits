2024-09-17 23:50:24,801 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:198] - INFO: Logging to log_dpo/2024_09_17_23_47_28/swapped_noise0.5_[0.5,0.5,0.5]_2030
2024-09-17 23:50:24,803 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: (IB) Seed: 2030
2024-09-17 23:50:24,803 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Data: 300
2024-09-17 23:50:24,966 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:296] - INFO: MLE reward loss: 0.5651, l2 distance: 8.6546, acc: 0.71.
2024-09-17 23:50:24,967 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-17 23:50:24,968 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: MLE reward parameter: [3.20649073 2.66360047 6.14834338 1.01478806]
2024-09-17 23:50:25,174 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:313] - INFO: Learned oracle reward: 3.3575, 3.7861, 3.0373
2024-09-17 23:50:26,440 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:947] - INFO: Iteration:  0, train_loss:  22.4320, val_loss:  22.4941, grad_norm: 0.6125, reward_err: 0.0994, 0.0186, 0.0647, KL_dist: 0.1786, 0.0241, 0.1031, param: [3.3024663  1.59918091 1.29109181 0.5350933 ]train_grp_loss: [24.0579574  19.30201676 24.21363069], val_grp_loss: [23.94717058 19.65815138 23.74972564], train_hist_grp_loss: [24.07543909 19.37819638 24.22869748], cur_train_grp_loss: [24.07543909 19.37819638 24.22869748],max_reward_err:  0.0994, max_reward_err_index: 0, max_kl_dist:  0.1786, max_kl_dist_index: 0, max_train_grp_loss:  24.2136, max_train_grp_loss_index: 2, max_val_grp_loss:  23.9472, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  24.2287, max_cur_train_grp_loss_index: 2, 
2024-09-17 23:50:29,540 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:1040] - INFO: Iteration:  99, train_loss:  20.4423, val_loss:  20.6224, grad_norm: 0.3129, reward_err: 0.0823, 0.0164, 0.0442, KL_dist: 0.4444, 0.1542, 0.2988, param: [5.50263779 3.54287026 4.44410641 1.17663027]train_grp_loss: [23.02170046 15.42913988 23.3169473 ], val_grp_loss: [23.05328663 16.1375043  22.46069607], train_hist_grp_loss: [2345.77606678 1695.22537884 2369.52076018], cur_train_grp_loss: [23.02750224 15.44686349 23.32201752],max_reward_err:  0.0823, max_reward_err_index: 0, max_kl_dist:  0.4444, max_kl_dist_index: 0, max_train_grp_loss:  23.3169, max_train_grp_loss_index: 2, max_val_grp_loss:  23.0533, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  23.3220, max_cur_train_grp_loss_index: 2, 
2024-09-17 23:50:29,762 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:386] - INFO: Policy parameter learned solely on the preference data dpo: [5.50263779 3.54287026 4.44410641 1.17663027].
2024-09-17 23:50:30,095 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:397] - INFO: Uniform reward: 3.7613, 3.7613, 3.1505
2024-09-17 23:50:30,095 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Optimal reward: 3.7992, 3.7992, 3.2896
2024-09-17 23:50:30,096 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Policy reward: 3.4867, 3.7369, 3.1442
2024-09-17 23:50:30,096 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Reward Error: 0.0823, 0.0164, 0.0442
2024-09-17 23:50:30,777 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:415] - INFO: Optimal reward: 3.7992, 3.7992, 3.2896
Known param reward: [[3.7992148399353027, 3.425678014755249, 3.2561442852020264], [3.425678014755249, 3.7992148399353027, 3.103405237197876], [3.7646615505218506, 3.5522572994232178, 3.289585590362549]], Known param reward error: [[0.0, 0.09831947939706792, 0.010165810933296573], [0.09831947939706792, 0.0, 0.05659690196543988], [0.009094850085930008, 0.06500225728647933, 0.0]].
