2024-09-18 20:04:53,403 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log_dpo/2024_09_18_19_49_22/swapped_noise0.6_[1,0.6,1]_2030
2024-09-18 20:04:53,405 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2030
2024-09-18 20:04:53,406 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-09-18 20:04:53,568 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.4961, l2 distance: 10.5890, acc: 0.77.
2024-09-18 20:04:53,569 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-18 20:04:53,569 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [5.36923291 3.75606204 5.9084699  3.85520782]
2024-09-18 20:04:53,778 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.5727, 3.7607, 3.2144
2024-09-18 20:04:55,206 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:947] - INFO: Iteration:  0, train_loss:  21.0261, val_loss:  21.2530, grad_norm: 0.7941, reward_err: 0.1010, 0.0387, 0.0734, KL_dist: 0.2337, 0.0640, 0.1750, param: [0.26349808 1.72591816 4.14805633 2.24771809]train_grp_loss: [23.21751386 18.86791155 22.58333968], val_grp_loss: [22.78014001 18.04216559 22.7160414 ], train_hist_grp_loss: [23.25187788 18.95897697 22.62498624], cur_train_grp_loss: [23.25187788 18.95897697 22.62498624],max_reward_err:  0.1010, max_reward_err_index: 0, max_kl_dist:  0.2337, max_kl_dist_index: 0, max_train_grp_loss:  23.2175, max_train_grp_loss_index: 0, max_val_grp_loss:  22.7801, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  23.2519, max_cur_train_grp_loss_index: 0, 
2024-09-18 20:04:58,443 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:1040] - INFO: Iteration:  99, train_loss:  18.1341, val_loss:  18.1645, grad_norm: 0.3386, reward_err: 0.0820, 0.0242, 0.0482, KL_dist: 0.5476, 0.2745, 0.4169, param: [3.70014543 3.34252459 6.9273244  4.44272141]train_grp_loss: [21.31055536 15.0909288  20.14073469], val_grp_loss: [20.6737548  13.27995595 20.17852259], train_hist_grp_loss: [2208.91814758 1642.39212777 2116.53590386], cur_train_grp_loss: [21.32024309 15.1028979  20.15433238],max_reward_err:  0.0820, max_reward_err_index: 0, max_kl_dist:  0.5476, max_kl_dist_index: 0, max_train_grp_loss:  21.3106, max_train_grp_loss_index: 0, max_val_grp_loss:  20.6738, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  21.3202, max_cur_train_grp_loss_index: 0, 
2024-09-18 20:04:58,674 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:387] - INFO: Policy parameter learned solely on the preference data dpo: [3.70014543 3.34252459 6.9273244  4.44272141].
2024-09-18 20:04:59,013 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Uniform reward: 3.7751, 3.7751, 3.1646
2024-09-18 20:04:59,014 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Optimal reward: 3.8138, 3.8138, 3.3081
2024-09-18 20:04:59,015 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Policy reward: 3.5009, 3.7215, 3.1487
2024-09-18 20:04:59,015 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Reward Error: 0.0820, 0.0242, 0.0482
2024-09-18 20:04:59,692 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:416] - INFO: Optimal reward: 3.8138, 3.8138, 3.3081
Known param reward: [[3.8138465881347656, 3.439753770828247, 3.273068904876709], [3.439753770828247, 3.8138465881347656, 3.121405839920044], [3.7787630558013916, 3.5612988471984863, 3.308058500289917]], Known param reward error: [[0.0, 0.09808806113763369, 0.010577078794145125], [0.09808806113763369, 0.0, 0.05642362743993641], [0.009198988874519018, 0.06621864175711184, 0.0]].
