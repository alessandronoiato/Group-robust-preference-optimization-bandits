2024-09-18 19:55:09,327 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log_dpo/2024_09_18_19_49_22/swapped_noise0.9_[1,0.9,1]_2029
2024-09-18 19:55:09,329 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2029
2024-09-18 19:55:09,330 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-09-18 19:55:09,493 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.3922, l2 distance: 23.9064, acc: 0.84.
2024-09-18 19:55:09,494 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-18 19:55:09,495 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [ 9.06453268  6.49602515 11.99559379  5.81513793]
2024-09-18 19:55:09,703 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.5470, 3.8297, 3.1719
2024-09-18 19:55:11,152 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:947] - INFO: Iteration:  0, train_loss:  18.6082, val_loss:  18.8687, grad_norm: 0.7174, reward_err: 0.0807, 0.0217, 0.0437, KL_dist: 0.3097, 0.1136, 0.2013, param: [4.99570206 3.44399351 3.30654411 1.77814616]train_grp_loss: [22.14693622 14.30968045 21.10323061], val_grp_loss: [21.629599   13.20330435 21.40579528], train_hist_grp_loss: [22.17476473 14.38933171 21.13831542], cur_train_grp_loss: [22.17476473 14.38933171 21.13831542],max_reward_err:  0.0807, max_reward_err_index: 0, max_kl_dist:  0.3097, max_kl_dist_index: 0, max_train_grp_loss:  22.1469, max_train_grp_loss_index: 0, max_val_grp_loss:  21.6296, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  22.1748, max_cur_train_grp_loss_index: 0, 
2024-09-18 19:55:14,373 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:1040] - INFO: Iteration:  99, train_loss:  15.9044, val_loss:  16.3419, grad_norm: 0.3629, reward_err: 0.0815, 0.0068, 0.0419, KL_dist: 0.8376, 0.4207, 0.6484, param: [7.79512544 4.29840015 6.85539599 3.91958603]train_grp_loss: [20.56307589 10.30091774 19.01350816], val_grp_loss: [19.94377324  9.38275454 19.22932114], train_hist_grp_loss: [2121.78096517 1187.27769191 1989.59696696], cur_train_grp_loss: [20.57147714 10.31912353 19.02538491],max_reward_err:  0.0815, max_reward_err_index: 0, max_kl_dist:  0.8376, max_kl_dist_index: 0, max_train_grp_loss:  20.5631, max_train_grp_loss_index: 0, max_val_grp_loss:  19.9438, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  20.5715, max_cur_train_grp_loss_index: 0, 
2024-09-18 19:55:14,604 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:387] - INFO: Policy parameter learned solely on the preference data dpo: [7.79512544 4.29840015 6.85539599 3.91958603].
2024-09-18 19:55:14,941 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Uniform reward: 3.8215, 3.8215, 3.1846
2024-09-18 19:55:14,942 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Optimal reward: 3.8606, 3.8606, 3.3138
2024-09-18 19:55:14,943 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Policy reward: 3.5458, 3.8343, 3.1750
2024-09-18 19:55:14,943 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Reward Error: 0.0815, 0.0068, 0.0419
2024-09-18 19:55:15,619 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:416] - INFO: Optimal reward: 3.8606, 3.8606, 3.3138
Known param reward: [[3.860621452331543, 3.4612629413604736, 3.285645008087158], [3.4612629413604736, 3.860621452331543, 3.115248203277588], [3.8245344161987305, 3.578054666519165, 3.3138341903686523]], Known param reward error: [[0.0, 0.1034440998430149, 0.008506515613672933], [0.1034440998430149, 0.0, 0.0599263498663379], [0.009347468167597338, 0.07319204674722188, 0.0]].
