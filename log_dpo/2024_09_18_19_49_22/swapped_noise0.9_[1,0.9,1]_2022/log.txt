2024-09-18 19:52:50,926 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log_dpo/2024_09_18_19_49_22/swapped_noise0.9_[1,0.9,1]_2022
2024-09-18 19:52:50,928 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2022
2024-09-18 19:52:50,929 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-09-18 19:52:51,090 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.3535, l2 distance: 28.4868, acc: 0.85.
2024-09-18 19:52:51,091 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-18 19:52:51,091 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [12.5384091   6.91815982 12.54481599  6.12893569]
2024-09-18 19:52:51,300 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.5601, 3.8531, 3.1999
2024-09-18 19:52:52,745 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:947] - INFO: Iteration:  0, train_loss:  21.9529, val_loss:  22.2384, grad_norm: 1.0853, reward_err: 0.1016, 0.0000, 0.0583, KL_dist: 0.1531, 0.0320, 0.0805, param: [1.79856307 0.6369817  1.84846548 0.57368089]train_grp_loss: [23.95582863 19.44031347 23.56460749], val_grp_loss: [24.04721667 19.39370144 23.49071916], train_hist_grp_loss: [24.00466224 19.64278484 23.62904422], cur_train_grp_loss: [24.00466224 19.64278484 23.62904422],max_reward_err:  0.1016, max_reward_err_index: 0, max_kl_dist:  0.1531, max_kl_dist_index: 0, max_train_grp_loss:  23.9558, max_train_grp_loss_index: 0, max_val_grp_loss:  24.0472, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  24.0047, max_cur_train_grp_loss_index: 0, 
2024-09-18 19:52:55,985 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:1040] - INFO: Iteration:  99, train_loss:  15.9047, val_loss:  16.8068, grad_norm: 0.5290, reward_err: 0.0837, 0.0044, 0.0434, KL_dist: 0.6862, 0.2756, 0.5037, param: [6.5776647  3.75582716 6.37224068 2.67809074]train_grp_loss: [21.16699678  9.50145587 19.59598973], val_grp_loss: [21.29985824 10.14188669 19.49575366], train_hist_grp_loss: [2231.9620365  1333.25324473 2129.67861153], cur_train_grp_loss: [21.18167954  9.54359409 19.61962682],max_reward_err:  0.0837, max_reward_err_index: 0, max_kl_dist:  0.6862, max_kl_dist_index: 0, max_train_grp_loss:  21.1670, max_train_grp_loss_index: 0, max_val_grp_loss:  21.2999, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  21.1817, max_cur_train_grp_loss_index: 0, 
2024-09-18 19:52:56,214 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:387] - INFO: Policy parameter learned solely on the preference data dpo: [6.5776647  3.75582716 6.37224068 2.67809074].
2024-09-18 19:52:56,551 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Uniform reward: 3.8376, 3.8376, 3.2077
2024-09-18 19:52:56,552 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Optimal reward: 3.8707, 3.8707, 3.3351
2024-09-18 19:52:56,552 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Policy reward: 3.5467, 3.8536, 3.1903
2024-09-18 19:52:56,553 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Reward Error: 0.0837, 0.0044, 0.0434
2024-09-18 19:52:57,229 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:416] - INFO: Optimal reward: 3.8707, 3.8707, 3.3351
Known param reward: [[3.870741367340088, 3.47579288482666, 3.3037049770355225], [3.47579288482666, 3.870741367340088, 3.1393208503723145], [3.836113214492798, 3.5835537910461426, 3.3351211547851562]], Known param reward error: [[0.0, 0.10203432496055144, 0.009419801048174388], [0.10203432496055144, 0.0, 0.05870860317380433], [0.008946129322788094, 0.07419446277582117, 0.0]].
