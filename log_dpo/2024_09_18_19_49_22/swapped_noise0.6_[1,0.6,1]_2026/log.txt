2024-09-18 20:03:38,563 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log_dpo/2024_09_18_19_49_22/swapped_noise0.6_[1,0.6,1]_2026
2024-09-18 20:03:38,565 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2026
2024-09-18 20:03:38,566 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-09-18 20:03:38,730 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.4897, l2 distance: 13.8904, acc: 0.75.
2024-09-18 20:03:38,730 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-18 20:03:38,731 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [7.98825619 2.69900213 6.4400013  3.59401665]
2024-09-18 20:03:38,941 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.4928, 3.8618, 3.1795
2024-09-18 20:03:40,374 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:947] - INFO: Iteration:  0, train_loss:  20.2250, val_loss:  19.8541, grad_norm: 0.5692, reward_err: 0.0242, 0.0413, 0.0047, KL_dist: 0.1144, 0.1807, 0.0665, param: [2.81430128 3.50363912 3.12594326 3.44197332]train_grp_loss: [21.48438373 18.33108493 21.16124437], val_grp_loss: [21.46829113 16.72135393 20.98318427], train_hist_grp_loss: [21.49791849 18.38963987 21.1844673 ], cur_train_grp_loss: [21.49791849 18.38963987 21.1844673 ],max_reward_err:  0.0413, max_reward_err_index: 1, max_kl_dist:  0.1807, max_kl_dist_index: 1, max_train_grp_loss:  21.4844, max_train_grp_loss_index: 0, max_val_grp_loss:  21.4683, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  21.4979, max_cur_train_grp_loss_index: 0, 
2024-09-18 20:03:43,637 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:1040] - INFO: Iteration:  99, train_loss:  18.2372, val_loss:  17.8231, grad_norm: 0.3425, reward_err: 0.0622, 0.0118, 0.0291, KL_dist: 0.5762, 0.2946, 0.4228, param: [6.0466653  3.57130318 5.99402805 4.22410754]train_grp_loss: [20.72988123 14.67978193 19.62268442], val_grp_loss: [20.57634063 13.08918776 19.20700348], train_hist_grp_loss: [2103.67067241 1625.20878243 2030.20929978], cur_train_grp_loss: [20.73357733 14.70177902 19.63271849],max_reward_err:  0.0622, max_reward_err_index: 0, max_kl_dist:  0.5762, max_kl_dist_index: 0, max_train_grp_loss:  20.7299, max_train_grp_loss_index: 0, max_val_grp_loss:  20.5763, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  20.7336, max_cur_train_grp_loss_index: 0, 
2024-09-18 20:03:43,869 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:387] - INFO: Policy parameter learned solely on the preference data dpo: [6.0466653  3.57130318 5.99402805 4.22410754].
2024-09-18 20:03:44,207 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Uniform reward: 3.8294, 3.8294, 3.2249
2024-09-18 20:03:44,208 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Optimal reward: 3.8697, 3.8697, 3.3747
2024-09-18 20:03:44,209 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Policy reward: 3.6288, 3.8242, 3.2763
2024-09-18 20:03:44,209 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Reward Error: 0.0622, 0.0118, 0.0291
2024-09-18 20:03:44,893 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:416] - INFO: Optimal reward: 3.8697, 3.8697, 3.3747
Known param reward: [[3.869661331176758, 3.4677367210388184, 3.334665060043335], [3.4677367210388184, 3.869661331176758, 3.163583993911743], [3.832443952560425, 3.602559804916382, 3.3746607303619385]], Known param reward error: [[0.0, 0.1038655778219524, 0.011851760373646185], [0.1038655778219524, 0.0, 0.06254754279478546], [0.00961773536006451, 0.06902452266517878, 0.0]].
