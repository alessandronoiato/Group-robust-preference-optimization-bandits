2024-09-18 20:01:08,386 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log_dpo/2024_09_18_19_49_22/swapped_noise0.7_[1,0.7,1]_2028
2024-09-18 20:01:08,388 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2028
2024-09-18 20:01:08,389 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-09-18 20:01:08,552 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.4872, l2 distance: 13.0978, acc: 0.77.
2024-09-18 20:01:08,553 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-18 20:01:08,554 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [6.46691538 3.95756071 6.43337544 5.0747662 ]
2024-09-18 20:01:08,762 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.6532, 3.8141, 3.2658
2024-09-18 20:01:10,194 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:947] - INFO: Iteration:  0, train_loss:  20.8848, val_loss:  21.0665, grad_norm: 0.7537, reward_err: 0.1049, 0.0424, 0.0788, KL_dist: 0.3145, 0.0862, 0.2444, param: [5.02291554 2.95209326 0.32183253 1.40250232]train_grp_loss: [22.81258096 18.09742963 22.01401503], val_grp_loss: [22.89015105 17.90458534 22.00029089], train_hist_grp_loss: [22.8444037  18.18868905 22.05811586], cur_train_grp_loss: [22.8444037  18.18868905 22.05811586],max_reward_err:  0.1049, max_reward_err_index: 0, max_kl_dist:  0.3145, max_kl_dist_index: 0, max_train_grp_loss:  22.8126, max_train_grp_loss_index: 0, max_val_grp_loss:  22.8902, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  22.8444, max_cur_train_grp_loss_index: 0, 
2024-09-18 20:01:13,402 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:1040] - INFO: Iteration:  99, train_loss:  18.2368, val_loss:  18.2465, grad_norm: 0.3296, reward_err: 0.0758, 0.0243, 0.0450, KL_dist: 0.5423, 0.3187, 0.4307, param: [7.27850893 4.08179997 3.17475192 4.60334947]train_grp_loss: [21.10038035 14.39009606 19.33151488], val_grp_loss: [20.92994133 13.95520659 19.29054917], train_hist_grp_loss: [2178.68091385 1568.46410913 2047.55036143], cur_train_grp_loss: [21.10845717 14.4015968  19.34726883],max_reward_err:  0.0758, max_reward_err_index: 0, max_kl_dist:  0.5423, max_kl_dist_index: 0, max_train_grp_loss:  21.1004, max_train_grp_loss_index: 0, max_val_grp_loss:  20.9299, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  21.1085, max_cur_train_grp_loss_index: 0, 
2024-09-18 20:01:13,631 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:387] - INFO: Policy parameter learned solely on the preference data dpo: [7.27850893 4.08179997 3.17475192 4.60334947].
2024-09-18 20:01:13,976 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Uniform reward: 3.8371, 3.8371, 3.2123
2024-09-18 20:01:13,977 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Optimal reward: 3.8741, 3.8741, 3.3487
2024-09-18 20:01:13,977 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Policy reward: 3.5804, 3.7800, 3.1981
2024-09-18 20:01:13,978 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Reward Error: 0.0758, 0.0243, 0.0450
2024-09-18 20:01:14,655 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:416] - INFO: Optimal reward: 3.8741, 3.8741, 3.3487
Known param reward: [[3.8741343021392822, 3.4676833152770996, 3.31387996673584], [3.4676833152770996, 3.8741343021392822, 3.1369452476501465], [3.840017557144165, 3.611396074295044, 3.3486669063568115]], Known param reward error: [[0.0, 0.10491401566480076, 0.010388294982380973], [0.10491401566480076, 0.0, 0.0632256550523886], [0.008806288665903515, 0.06781856470467615, 0.0]].
