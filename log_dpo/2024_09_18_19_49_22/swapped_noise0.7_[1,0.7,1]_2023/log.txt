2024-09-18 19:59:36,726 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log_dpo/2024_09_18_19_49_22/swapped_noise0.7_[1,0.7,1]_2023
2024-09-18 19:59:36,728 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2023
2024-09-18 19:59:36,729 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-09-18 19:59:36,890 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.4606, l2 distance: 16.8393, acc: 0.77.
2024-09-18 19:59:36,891 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-18 19:59:36,892 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [9.94263926 2.54922984 6.33285423 4.50745735]
2024-09-18 19:59:37,095 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.4767, 3.8545, 3.0948
2024-09-18 19:59:38,529 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:947] - INFO: Iteration:  0, train_loss:  20.9740, val_loss:  21.0097, grad_norm: 0.8001, reward_err: 0.1247, 0.0060, 0.0896, KL_dist: 0.3339, 0.0241, 0.2262, param: [1.69567431 1.80609005 4.92476606 0.40677959]train_grp_loss: [23.72782719 17.62254638 21.77461134], val_grp_loss: [23.27573664 17.3529766  22.4826905 ], train_hist_grp_loss: [23.76457495 17.7225823  21.82255628], cur_train_grp_loss: [23.76457495 17.7225823  21.82255628],max_reward_err:  0.1247, max_reward_err_index: 0, max_kl_dist:  0.3339, max_kl_dist_index: 0, max_train_grp_loss:  23.7278, max_train_grp_loss_index: 0, max_val_grp_loss:  23.2757, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  23.7646, max_cur_train_grp_loss_index: 0, 
2024-09-18 19:59:41,734 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:1040] - INFO: Iteration:  99, train_loss:  17.7338, val_loss:  17.8912, grad_norm: 0.3884, reward_err: 0.0908, 0.0025, 0.0529, KL_dist: 0.6890, 0.2681, 0.5148, param: [5.62493492 2.92582113 7.43063967 3.18289339]train_grp_loss: [21.61155393 13.02599575 18.83409873], val_grp_loss: [21.50150543 12.71876842 19.6069704 ], train_hist_grp_loss: [2249.10855949 1474.67010526 2009.11722136], cur_train_grp_loss: [21.6229678  13.04400551 18.85142823],max_reward_err:  0.0908, max_reward_err_index: 0, max_kl_dist:  0.6890, max_kl_dist_index: 0, max_train_grp_loss:  21.6116, max_train_grp_loss_index: 0, max_val_grp_loss:  21.5015, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  21.6230, max_cur_train_grp_loss_index: 0, 
2024-09-18 19:59:41,965 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:387] - INFO: Policy parameter learned solely on the preference data dpo: [5.62493492 2.92582113 7.43063967 3.18289339].
2024-09-18 19:59:42,299 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Uniform reward: 3.8219, 3.8219, 3.1727
2024-09-18 19:59:42,300 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Optimal reward: 3.8605, 3.8605, 3.2988
2024-09-18 19:59:42,300 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Policy reward: 3.5099, 3.8510, 3.1242
2024-09-18 19:59:42,301 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Reward Error: 0.0908, 0.0025, 0.0529
2024-09-18 19:59:42,970 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:416] - INFO: Optimal reward: 3.8605, 3.8605, 3.2988
Known param reward: [[3.8605411052703857, 3.4837193489074707, 3.270322322845459], [3.4837193489074707, 3.8605411052703857, 3.110097646713257], [3.825101613998413, 3.5993566513061523, 3.298776388168335]], Known param reward error: [[0.0, 0.09760853364531734, 0.008625642351791921], [0.09760853364531734, 0.0, 0.05719658420370927], [0.009179928488156982, 0.06765488226706512, 0.0]].
