2024-09-18 20:01:45,711 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log_dpo/2024_09_18_19_49_22/swapped_noise0.7_[1,0.7,1]_2030
2024-09-18 20:01:45,713 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2030
2024-09-18 20:01:45,713 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-09-18 20:01:45,875 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.4425, l2 distance: 16.8138, acc: 0.81.
2024-09-18 20:01:45,876 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-18 20:01:45,876 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [7.62750007 3.92484544 9.1161362  3.44860802]
2024-09-18 20:01:46,083 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.4592, 3.8076, 3.1317
2024-09-18 20:01:47,543 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:947] - INFO: Iteration:  0, train_loss:  20.6639, val_loss:  20.0133, grad_norm: 0.8575, reward_err: 0.0689, 0.0642, 0.0478, KL_dist: 0.2155, 0.2131, 0.1744, param: [0.75002002 4.25689515 4.59586187 2.71586809]train_grp_loss: [21.96672743 19.68041366 20.70922961], val_grp_loss: [21.78182418 16.78136642 21.24173566], train_hist_grp_loss: [21.97328394 19.81657316 20.74318128], cur_train_grp_loss: [21.97328394 19.81657316 20.74318128],max_reward_err:  0.0689, max_reward_err_index: 0, max_kl_dist:  0.2155, max_kl_dist_index: 0, max_train_grp_loss:  21.9667, max_train_grp_loss_index: 0, max_val_grp_loss:  21.7818, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  21.9733, max_cur_train_grp_loss_index: 0, 
2024-09-18 20:01:50,779 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:1040] - INFO: Iteration:  99, train_loss:  16.9323, val_loss:  17.4240, grad_norm: 0.4123, reward_err: 0.0995, 0.0048, 0.0615, KL_dist: 0.8472, 0.3072, 0.6493, param: [5.15248723 3.45674527 8.46209394 3.36580956]train_grp_loss: [21.67824076 12.86571911 18.51943182], val_grp_loss: [21.2380292  10.78499183 19.74419098], train_hist_grp_loss: [2178.23484619 1551.9183262  1947.72073757], cur_train_grp_loss: [21.67919254 12.89556489 18.53335152],max_reward_err:  0.0995, max_reward_err_index: 0, max_kl_dist:  0.8472, max_kl_dist_index: 0, max_train_grp_loss:  21.6782, max_train_grp_loss_index: 0, max_val_grp_loss:  21.2380, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  21.6792, max_cur_train_grp_loss_index: 0, 
2024-09-18 20:01:51,014 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:387] - INFO: Policy parameter learned solely on the preference data dpo: [5.15248723 3.45674527 8.46209394 3.36580956].
2024-09-18 20:01:51,346 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Uniform reward: 3.7748, 3.7748, 3.1636
2024-09-18 20:01:51,347 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Optimal reward: 3.8136, 3.8136, 3.3066
2024-09-18 20:01:51,347 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Policy reward: 3.4341, 3.7953, 3.1033
2024-09-18 20:01:51,348 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Reward Error: 0.0995, 0.0048, 0.0615
2024-09-18 20:01:52,022 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:416] - INFO: Optimal reward: 3.8136, 3.8136, 3.3066
Known param reward: [[3.813612222671509, 3.4377872943878174, 3.272095203399658], [3.4377872943878174, 3.813612222671509, 3.118396520614624], [3.779019594192505, 3.5611813068389893, 3.3066372871398926]], Known param reward error: [[0.0, 0.09854828082662763, 0.010446287494118195], [0.09854828082662763, 0.0, 0.056928156970034414], [0.009070830084232083, 0.06619207750904647, 0.0]].
