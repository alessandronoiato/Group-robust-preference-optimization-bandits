2024-09-18 19:54:49,192 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log_dpo/2024_09_18_19_49_22/swapped_noise0.9_[1,0.9,1]_2028
2024-09-18 19:54:49,194 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2028
2024-09-18 19:54:49,195 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-09-18 19:54:49,358 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.4608, l2 distance: 18.2843, acc: 0.77.
2024-09-18 19:54:49,359 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-18 19:54:49,360 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [9.26466518 4.05998357 8.48895322 4.49961667]
2024-09-18 19:54:49,562 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.5334, 3.8532, 3.1743
2024-09-18 19:54:51,004 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:947] - INFO: Iteration:  0, train_loss:  20.7859, val_loss:  20.2779, grad_norm: 0.7068, reward_err: 0.0358, 0.0578, 0.0122, KL_dist: 0.0849, 0.1269, 0.0333, param: [2.33365501 1.41913266 2.69016936 3.62254386]train_grp_loss: [22.74955982 17.83584275 22.15599238], val_grp_loss: [22.06910296 16.74953368 21.81115397], train_hist_grp_loss: [22.76700187 17.93528394 22.18118169], cur_train_grp_loss: [22.76700187 17.93528394 22.18118169],max_reward_err:  0.0578, max_reward_err_index: 1, max_kl_dist:  0.1269, max_kl_dist_index: 1, max_train_grp_loss:  22.7496, max_train_grp_loss_index: 0, max_val_grp_loss:  22.0691, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  22.7670, max_cur_train_grp_loss_index: 0, 
2024-09-18 19:54:54,205 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:1040] - INFO: Iteration:  99, train_loss:  17.9368, val_loss:  16.9428, grad_norm: 0.3904, reward_err: 0.0704, 0.0104, 0.0351, KL_dist: 0.5758, 0.2765, 0.4207, param: [5.96830584 2.99559176 6.07656125 4.14986497]train_grp_loss: [21.81642663 12.108945   20.64199052], val_grp_loss: [20.30317338 10.75451216 19.39187623], train_hist_grp_loss: [2218.79276576 1449.28388079 2128.22229602], cur_train_grp_loss: [21.82065878 12.14008856 20.65056355],max_reward_err:  0.0704, max_reward_err_index: 0, max_kl_dist:  0.5758, max_kl_dist_index: 0, max_train_grp_loss:  21.8164, max_train_grp_loss_index: 0, max_val_grp_loss:  20.3032, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  21.8207, max_cur_train_grp_loss_index: 0, 
2024-09-18 19:54:54,448 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:387] - INFO: Policy parameter learned solely on the preference data dpo: [5.96830584 2.99559176 6.07656125 4.14986497].
2024-09-18 19:54:54,791 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Uniform reward: 3.8289, 3.8289, 3.1992
2024-09-18 19:54:54,792 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Optimal reward: 3.8641, 3.8641, 3.3321
2024-09-18 19:54:54,792 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Policy reward: 3.5919, 3.8241, 3.2151
2024-09-18 19:54:54,793 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Reward Error: 0.0704, 0.0104, 0.0351
2024-09-18 19:54:55,468 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:416] - INFO: Optimal reward: 3.8641, 3.8641, 3.3321
Known param reward: [[3.8641457557678223, 3.4569623470306396, 3.297084093093872], [3.4569623470306396, 3.8641457557678223, 3.1191890239715576], [3.8311407566070557, 3.6006405353546143, 3.3321304321289062]], Known param reward error: [[0.0, 0.10537475407841429, 0.010517697235712045], [0.10537475407841429, 0.0, 0.0639054840423218], [0.00854134425739548, 0.06819236050293563, 0.0]].
