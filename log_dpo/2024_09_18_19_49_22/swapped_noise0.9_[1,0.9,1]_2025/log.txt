2024-09-18 19:53:54,236 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log_dpo/2024_09_18_19_49_22/swapped_noise0.9_[1,0.9,1]_2025
2024-09-18 19:53:54,238 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2025
2024-09-18 19:53:54,238 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-09-18 19:53:54,400 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.3643, l2 distance: 26.6536, acc: 0.83.
2024-09-18 19:53:54,400 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-18 19:53:54,401 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [ 9.74833375  6.51587022 13.42709063  6.40193169]
2024-09-18 19:53:54,608 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.5389, 3.8046, 3.1197
2024-09-18 19:53:56,019 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:947] - INFO: Iteration:  0, train_loss:  18.1034, val_loss:  19.1905, grad_norm: 0.7310, reward_err: 0.0439, 0.0482, 0.0184, KL_dist: 0.2350, 0.2364, 0.1765, param: [4.80439487 3.19259116 2.74701079 4.65713052]train_grp_loss: [21.59274705 13.77204148 20.80240428], val_grp_loss: [20.92404486 15.71492559 20.73416676], train_hist_grp_loss: [21.60924748 13.86869411 20.83310981], cur_train_grp_loss: [21.60924748 13.86869411 20.83310981],max_reward_err:  0.0482, max_reward_err_index: 1, max_kl_dist:  0.2364, max_kl_dist_index: 1, max_train_grp_loss:  21.5927, max_train_grp_loss_index: 0, max_val_grp_loss:  20.9240, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  21.6092, max_cur_train_grp_loss_index: 0, 
2024-09-18 19:53:59,211 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:1040] - INFO: Iteration:  99, train_loss:  15.2549, val_loss:  16.4115, grad_norm: 0.3741, reward_err: 0.0650, 0.0135, 0.0301, KL_dist: 0.7802, 0.4725, 0.6204, param: [7.82156271 4.80161903 6.68159799 4.51338875]train_grp_loss: [20.71563185  8.71081456 18.84877288], val_grp_loss: [19.76688027 10.25735764 18.87694137], train_hist_grp_loss: [2106.44474451 1072.86682726 1969.7893128 ], cur_train_grp_loss: [20.71963256  8.73491533 18.86094645],max_reward_err:  0.0650, max_reward_err_index: 0, max_kl_dist:  0.7802, max_kl_dist_index: 0, max_train_grp_loss:  20.7156, max_train_grp_loss_index: 0, max_val_grp_loss:  19.7669, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  20.7196, max_cur_train_grp_loss_index: 0, 
2024-09-18 19:53:59,454 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:387] - INFO: Policy parameter learned solely on the preference data dpo: [7.82156271 4.80161903 6.68159799 4.51338875].
2024-09-18 19:53:59,792 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Uniform reward: 3.8060, 3.8060, 3.1457
2024-09-18 19:53:59,792 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Optimal reward: 3.8381, 3.8381, 3.2564
2024-09-18 19:53:59,793 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Policy reward: 3.5887, 3.7864, 3.1583
2024-09-18 19:53:59,793 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Reward Error: 0.0650, 0.0135, 0.0301
2024-09-18 19:54:00,470 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:416] - INFO: Optimal reward: 3.8381, 3.8381, 3.2564
Known param reward: [[3.8380610942840576, 3.4578683376312256, 3.2186596393585205], [3.4578683376312256, 3.8380610942840576, 3.066926956176758], [3.7958598136901855, 3.5798747539520264, 3.256373405456543]], Known param reward error: [[0.0, 0.09905854735325735, 0.011581523800319515], [0.09905854735325735, 0.0, 0.05817712703412304], [0.010995468690355538, 0.06726999231891923, 0.0]].
