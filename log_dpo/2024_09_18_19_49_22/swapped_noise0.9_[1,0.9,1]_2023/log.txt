2024-09-18 19:53:11,429 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log_dpo/2024_09_18_19_49_22/swapped_noise0.9_[1,0.9,1]_2023
2024-09-18 19:53:11,431 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2023
2024-09-18 19:53:11,432 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-09-18 19:53:11,594 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.3607, l2 distance: 29.7318, acc: 0.84.
2024-09-18 19:53:11,595 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-18 19:53:11,596 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [12.24983848  7.46889102 13.19746037  7.26665612]
2024-09-18 19:53:11,802 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.5955, 3.8423, 3.1920
2024-09-18 19:53:13,239 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:947] - INFO: Iteration:  0, train_loss:  19.9941, val_loss:  20.4108, grad_norm: 0.9119, reward_err: 0.1077, 0.0124, 0.0719, KL_dist: 0.3342, 0.0299, 0.2186, param: [4.85654065 1.93705174 2.16509419 0.46976307]train_grp_loss: [23.46404881 15.36287606 21.95511741], val_grp_loss: [23.43313164 15.58547842 22.46946739], train_hist_grp_loss: [23.501427   15.50985634 22.00417291], cur_train_grp_loss: [23.501427   15.50985634 22.00417291],max_reward_err:  0.1077, max_reward_err_index: 0, max_kl_dist:  0.3342, max_kl_dist_index: 0, max_train_grp_loss:  23.4640, max_train_grp_loss_index: 0, max_val_grp_loss:  23.4331, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  23.5014, max_cur_train_grp_loss_index: 0, 
2024-09-18 19:53:16,487 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:1040] - INFO: Iteration:  99, train_loss:  15.7477, val_loss:  16.6823, grad_norm: 0.4413, reward_err: 0.0870, 0.0032, 0.0494, KL_dist: 0.8364, 0.3679, 0.6461, param: [8.34798047 3.35169353 6.13464805 3.68861298]train_grp_loss: [21.24809324  8.3922348  18.88957788], val_grp_loss: [21.49976863  9.58741884 19.3670154 ], train_hist_grp_loss: [2217.93967609 1102.73399558 2020.99844148], cur_train_grp_loss: [21.26038859  8.41981001 18.90805451],max_reward_err:  0.0870, max_reward_err_index: 0, max_kl_dist:  0.8364, max_kl_dist_index: 0, max_train_grp_loss:  21.2481, max_train_grp_loss_index: 0, max_val_grp_loss:  21.4998, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  21.2604, max_cur_train_grp_loss_index: 0, 
2024-09-18 19:53:16,718 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:387] - INFO: Policy parameter learned solely on the preference data dpo: [8.34798047 3.35169353 6.13464805 3.68861298].
2024-09-18 19:53:17,054 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Uniform reward: 3.8305, 3.8305, 3.1813
2024-09-18 19:53:17,055 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Optimal reward: 3.8691, 3.8691, 3.3071
2024-09-18 19:53:17,056 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Policy reward: 3.5326, 3.8567, 3.1437
2024-09-18 19:53:17,056 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Reward Error: 0.0870, 0.0032, 0.0494
2024-09-18 19:53:17,733 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:416] - INFO: Optimal reward: 3.8691, 3.8691, 3.3071
Known param reward: [[3.8691489696502686, 3.4901177883148193, 3.2788524627685547], [3.4901177883148193, 3.8691489696502686, 3.1177523136138916], [3.8334453105926514, 3.6074156761169434, 3.3071203231811523]], Known param reward error: [[0.0, 0.09796241610457035, 0.008547575428222254], [0.09796241610457035, 0.0, 0.05726069542734561], [0.00922778092486949, 0.06764621770481564, 0.0]].
