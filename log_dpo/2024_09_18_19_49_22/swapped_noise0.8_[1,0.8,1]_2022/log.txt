2024-09-18 19:56:06,794 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log_dpo/2024_09_18_19_49_22/swapped_noise0.8_[1,0.8,1]_2022
2024-09-18 19:56:06,796 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2022
2024-09-18 19:56:06,797 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-09-18 19:56:06,959 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.4465, l2 distance: 17.2654, acc: 0.79.
2024-09-18 19:56:06,960 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-18 19:56:06,961 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [7.73322927 5.13439292 8.93418526 3.72803641]
2024-09-18 19:56:07,163 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.5959, 3.8329, 3.2039
2024-09-18 19:56:08,580 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:947] - INFO: Iteration:  0, train_loss:  20.8402, val_loss:  21.0043, grad_norm: 0.8355, reward_err: 0.0936, 0.0179, 0.0683, KL_dist: 0.2322, 0.0315, 0.1676, param: [0.62786535 1.87041343 4.33221651 1.57190935]train_grp_loss: [23.50229687 17.45538798 23.10676798], val_grp_loss: [22.71043692 18.1895136  22.45240307], train_hist_grp_loss: [23.53095841 17.57503962 23.1465333 ], cur_train_grp_loss: [23.53095841 17.57503962 23.1465333 ],max_reward_err:  0.0936, max_reward_err_index: 0, max_kl_dist:  0.2322, max_kl_dist_index: 0, max_train_grp_loss:  23.5023, max_train_grp_loss_index: 0, max_val_grp_loss:  22.7104, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  23.5310, max_cur_train_grp_loss_index: 0, 
2024-09-18 19:56:11,776 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:1040] - INFO: Iteration:  99, train_loss:  17.3239, val_loss:  17.5317, grad_norm: 0.4027, reward_err: 0.0746, 0.0134, 0.0433, KL_dist: 0.6302, 0.2969, 0.4891, param: [4.36956098 4.42877339 7.58578259 3.03520712]train_grp_loss: [21.96773554 11.6446212  20.6600421 ], val_grp_loss: [20.56450989 12.98241466 19.59903147], train_hist_grp_loss: [2258.05612238 1388.88756597 2170.81240904], cur_train_grp_loss: [21.97484291 11.67007187 20.67459276],max_reward_err:  0.0746, max_reward_err_index: 0, max_kl_dist:  0.6302, max_kl_dist_index: 0, max_train_grp_loss:  21.9677, max_train_grp_loss_index: 0, max_val_grp_loss:  20.5645, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  21.9748, max_cur_train_grp_loss_index: 0, 
2024-09-18 19:56:12,012 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:387] - INFO: Policy parameter learned solely on the preference data dpo: [4.36956098 4.42877339 7.58578259 3.03520712].
2024-09-18 19:56:12,348 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Uniform reward: 3.8267, 3.8267, 3.1836
2024-09-18 19:56:12,348 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Optimal reward: 3.8586, 3.8586, 3.3169
2024-09-18 19:56:12,349 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Policy reward: 3.5706, 3.8068, 3.1734
2024-09-18 19:56:12,349 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Reward Error: 0.0746, 0.0134, 0.0433
2024-09-18 19:56:13,015 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:416] - INFO: Optimal reward: 3.8586, 3.8586, 3.3169
Known param reward: [[3.8586065769195557, 3.531782627105713, 3.266848564147949], [3.531782627105713, 3.8586065769195557, 3.1579184532165527], [3.8154232501983643, 3.627133369445801, 3.3168587684631348]], Known param reward error: [[0.0, 0.08469999293754285, 0.015077580266813035], [0.08469999293754285, 0.0, 0.04791892761844273], [0.011191430341588746, 0.05998880758103799, 0.0]].
