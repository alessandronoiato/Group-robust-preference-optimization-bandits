2024-09-18 19:58:03,099 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log_dpo/2024_09_18_19_49_22/swapped_noise0.8_[1,0.8,1]_2028
2024-09-18 19:58:03,101 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2028
2024-09-18 19:58:03,102 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-09-18 19:58:03,264 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.4400, l2 distance: 19.1200, acc: 0.80.
2024-09-18 19:58:03,265 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-18 19:58:03,265 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [8.98912891 4.97500646 9.19520574 4.54986022]
2024-09-18 19:58:03,471 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.5665, 3.8513, 3.2064
2024-09-18 19:58:04,905 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:947] - INFO: Iteration:  0, train_loss:  19.9785, val_loss:  19.9887, grad_norm: 0.7069, reward_err: 0.0315, 0.0559, 0.0098, KL_dist: 0.1200, 0.1935, 0.0708, param: [3.50170147 2.37811787 2.39923308 4.30616392]train_grp_loss: [21.86886853 17.07378027 21.42580881], val_grp_loss: [21.54170561 17.22326289 21.02525577], train_hist_grp_loss: [21.88314913 17.17526124 21.45420292], cur_train_grp_loss: [21.88314913 17.17526124 21.45420292],max_reward_err:  0.0559, max_reward_err_index: 1, max_kl_dist:  0.1935, max_kl_dist_index: 1, max_train_grp_loss:  21.8689, max_train_grp_loss_index: 0, max_val_grp_loss:  21.5417, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  21.8831, max_cur_train_grp_loss_index: 0, 
2024-09-18 19:58:08,117 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:1040] - INFO: Iteration:  99, train_loss:  17.1654, val_loss:  17.1169, grad_norm: 0.3831, reward_err: 0.0747, 0.0096, 0.0389, KL_dist: 0.6644, 0.3380, 0.5000, param: [7.02837255 3.76657077 5.9603118  4.17111936]train_grp_loss: [21.11073293 11.40890695 19.5791893 ], val_grp_loss: [20.31823323 11.90969199 18.76344267], train_hist_grp_loss: [2141.11240742 1372.82363523 2038.82473344], cur_train_grp_loss: [21.11410191 11.43794916 19.59093791],max_reward_err:  0.0747, max_reward_err_index: 0, max_kl_dist:  0.6644, max_kl_dist_index: 0, max_train_grp_loss:  21.1107, max_train_grp_loss_index: 0, max_val_grp_loss:  20.3182, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  21.1141, max_cur_train_grp_loss_index: 0, 
2024-09-18 19:58:08,343 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:387] - INFO: Policy parameter learned solely on the preference data dpo: [7.02837255 3.76657077 5.9603118  4.17111936].
2024-09-18 19:58:08,678 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Uniform reward: 3.8341, 3.8341, 3.2091
2024-09-18 19:58:08,679 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Optimal reward: 3.8712, 3.8712, 3.3448
2024-09-18 19:58:08,680 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Policy reward: 3.5820, 3.8341, 3.2149
2024-09-18 19:58:08,680 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Reward Error: 0.0747, 0.0096, 0.0389
2024-09-18 19:58:09,350 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:416] - INFO: Optimal reward: 3.8712, 3.8712, 3.3448
Known param reward: [[3.8711791038513184, 3.4649550914764404, 3.310628890991211], [3.4649550914764404, 3.8711791038513184, 3.1331167221069336], [3.8372890949249268, 3.6086676120758057, 3.3448379039764404]], Known param reward error: [[0.0, 0.10493547352813978, 0.010227405323457027], [0.10493547352813978, 0.0, 0.06329789004657192], [0.00875444096416915, 0.06781176606226975, 0.0]].
