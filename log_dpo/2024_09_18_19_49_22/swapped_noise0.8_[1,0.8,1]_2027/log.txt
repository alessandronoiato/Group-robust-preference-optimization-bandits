2024-09-18 19:57:45,358 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log_dpo/2024_09_18_19_49_22/swapped_noise0.8_[1,0.8,1]_2027
2024-09-18 19:57:45,360 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2027
2024-09-18 19:57:45,361 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-09-18 19:57:45,524 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.3814, l2 distance: 23.7630, acc: 0.85.
2024-09-18 19:57:45,525 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-18 19:57:45,526 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [ 8.88080729  4.95567706 12.33493647  6.36297512]
2024-09-18 19:57:45,732 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.5399, 3.8381, 3.2082
2024-09-18 19:57:47,143 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:947] - INFO: Iteration:  0, train_loss:  22.1045, val_loss:  22.6525, grad_norm: 1.0594, reward_err: 0.0228, 0.0986, 0.0054, KL_dist: 0.0558, 0.1322, 0.0306, param: [1.35268347 0.43705394 0.81103948 2.49681808]train_grp_loss: [23.42692261 20.00597169 23.20801743], val_grp_loss: [23.53803229 21.06168642 23.35099693], train_hist_grp_loss: [23.48600006 20.19275125 23.29134247], cur_train_grp_loss: [23.48600006 20.19275125 23.29134247],max_reward_err:  0.0986, max_reward_err_index: 1, max_kl_dist:  0.1322, max_kl_dist_index: 1, max_train_grp_loss:  23.4269, max_train_grp_loss_index: 0, max_val_grp_loss:  23.5380, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  23.4860, max_cur_train_grp_loss_index: 0, 
2024-09-18 19:57:50,330 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:1040] - INFO: Iteration:  99, train_loss:  16.5577, val_loss:  18.0031, grad_norm: 0.5046, reward_err: 0.0599, 0.0278, 0.0268, KL_dist: 0.4882, 0.3028, 0.3599, param: [4.89008159 3.13737497 6.00610273 4.8386262 ]train_grp_loss: [20.09844464 11.74472673 18.05625402], val_grp_loss: [20.73947653 13.59741975 19.66228782], train_hist_grp_loss: [2146.75928067 1478.72944449 2027.35125373], cur_train_grp_loss: [20.11577411 11.77586206 18.08758544],max_reward_err:  0.0599, max_reward_err_index: 0, max_kl_dist:  0.4882, max_kl_dist_index: 0, max_train_grp_loss:  20.0984, max_train_grp_loss_index: 0, max_val_grp_loss:  20.7395, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  20.1158, max_cur_train_grp_loss_index: 0, 
2024-09-18 19:57:50,566 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:387] - INFO: Policy parameter learned solely on the preference data dpo: [4.89008159 3.13737497 6.00610273 4.8386262 ].
2024-09-18 19:57:50,904 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Uniform reward: 3.8205, 3.8205, 3.2153
2024-09-18 19:57:50,905 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Optimal reward: 3.8664, 3.8664, 3.3644
2024-09-18 19:57:50,905 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Policy reward: 3.6347, 3.7590, 3.2743
2024-09-18 19:57:50,906 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Reward Error: 0.0599, 0.0278, 0.0268
2024-09-18 19:57:51,574 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:416] - INFO: Optimal reward: 3.8664, 3.8664, 3.3644
Known param reward: [[3.866352081298828, 3.466999053955078, 3.324810028076172], [3.466999053955078, 3.866352081298828, 3.1610913276672363], [3.8258588314056396, 3.5992729663848877, 3.364398956298828]], Known param reward error: [[0.0, 0.10328935879258955, 0.011767013584562513], [0.10328935879258955, 0.0, 0.06042910822182941], [0.010473244298947946, 0.06907780494326327, 0.0]].
