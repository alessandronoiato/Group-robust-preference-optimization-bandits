2024-09-18 21:28:35,944 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log_dpo/2024_09_18_21_18_57/swapped_noise0.7_[1,0.7,1]_2022
2024-09-18 21:28:35,946 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2022
2024-09-18 21:28:35,947 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-09-18 21:28:36,107 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.4860, l2 distance: 13.4347, acc: 0.77.
2024-09-18 21:28:36,107 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-18 21:28:36,108 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [6.72509148 2.81764665 7.31992199 3.84579016]
2024-09-18 21:28:36,310 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.5260, 3.8536, 3.1541
2024-09-18 21:28:37,749 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:947] - INFO: Iteration:  0, train_loss:  22.3519, val_loss:  21.9559, grad_norm: 0.8491, reward_err: 0.0728, 0.0907, 0.0519, KL_dist: 0.1046, 0.1267, 0.0754, param: [0.21031749 3.0652578  2.8503471  0.91682942]train_grp_loss: [22.96958385 21.49180268 23.08274072], val_grp_loss: [23.15073794 20.43230542 22.86814547], train_hist_grp_loss: [22.99836804 21.61860231 23.11732753], cur_train_grp_loss: [22.99836804 21.61860231 23.11732753],max_reward_err:  0.0907, max_reward_err_index: 1, max_kl_dist:  0.1267, max_kl_dist_index: 1, max_train_grp_loss:  23.0827, max_train_grp_loss_index: 2, max_val_grp_loss:  23.1507, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  23.1173, max_cur_train_grp_loss_index: 2, 
2024-09-18 21:28:40,956 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:1040] - INFO: Iteration:  99, train_loss:  18.4659, val_loss:  18.0675, grad_norm: 0.4382, reward_err: 0.0851, 0.0083, 0.0488, KL_dist: 0.5235, 0.1992, 0.3830, param: [4.24426781 3.04681874 6.69629301 3.3883657 ]train_grp_loss: [21.28310069 14.86187323 20.92496174], val_grp_loss: [21.56423426 13.83269133 20.14091596], train_hist_grp_loss: [2198.8665035  1749.55047712 2185.40596682], cur_train_grp_loss: [21.2923553  14.89274646 20.93797587],max_reward_err:  0.0851, max_reward_err_index: 0, max_kl_dist:  0.5235, max_kl_dist_index: 0, max_train_grp_loss:  21.2831, max_train_grp_loss_index: 0, max_val_grp_loss:  21.5642, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  21.2924, max_cur_train_grp_loss_index: 0, 
2024-09-18 21:28:41,185 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:387] - INFO: Policy parameter learned solely on the preference data dpo: [4.24426781 3.04681874 6.69629301 3.3883657 ].
2024-09-18 21:28:41,520 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Uniform reward: 3.8305, 3.8305, 3.1896
2024-09-18 21:28:41,521 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Optimal reward: 3.8637, 3.8637, 3.3143
2024-09-18 21:28:41,521 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Policy reward: 3.5349, 3.8317, 3.1527
2024-09-18 21:28:41,522 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Reward Error: 0.0851, 0.0083, 0.0488
2024-09-18 21:28:42,201 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:416] - INFO: Optimal reward: 3.8637, 3.8637, 3.3143
Known param reward: [[3.8637290000915527, 3.4715957641601562, 3.2866311073303223], [3.4715957641601562, 3.8637290000915527, 3.115274667739868], [3.8327977657318115, 3.5883262157440186, 3.3142967224121094]], Known param reward error: [[0.0, 0.10149087472804244, 0.008347356135829738], [0.10149087472804244, 0.0, 0.06004955842559417], [0.008005539301283367, 0.07127901163384089, 0.0]].
