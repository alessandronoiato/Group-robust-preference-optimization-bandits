2024-09-18 21:25:13,723 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log_dpo/2024_09_18_21_18_57/swapped_noise0.8_[1,0.8,1]_2021
2024-09-18 21:25:13,725 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2021
2024-09-18 21:25:13,726 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-09-18 21:25:13,891 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.4314, l2 distance: 20.0523, acc: 0.79.
2024-09-18 21:25:13,892 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-18 21:25:13,893 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [ 8.70855314  5.02440232 10.42407992  3.54741519]
2024-09-18 21:25:14,109 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.4982, 3.8706, 3.1167
2024-09-18 21:25:15,553 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:947] - INFO: Iteration:  0, train_loss:  21.2141, val_loss:  21.2792, grad_norm: 0.8588, reward_err: 0.1174, 0.0414, 0.0891, KL_dist: 0.3254, 0.0559, 0.2523, param: [4.78695643 2.2344401  0.10251004 0.4370719 ]train_grp_loss: [23.5721294  18.21259592 22.82276174], val_grp_loss: [23.16303435 18.62326913 23.01928774], train_hist_grp_loss: [23.61376761 18.32865762 22.86931061], cur_train_grp_loss: [23.61376761 18.32865762 22.86931061],max_reward_err:  0.1174, max_reward_err_index: 0, max_kl_dist:  0.3254, max_kl_dist_index: 0, max_train_grp_loss:  23.5721, max_train_grp_loss_index: 0, max_val_grp_loss:  23.1630, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  23.6138, max_cur_train_grp_loss_index: 0, 
2024-09-18 21:25:18,805 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:1040] - INFO: Iteration:  99, train_loss:  17.3511, val_loss:  17.4920, grad_norm: 0.4363, reward_err: 0.0935, 0.0130, 0.0555, KL_dist: 0.7193, 0.2886, 0.5644, param: [8.18282617 4.11610617 4.21768263 2.61304348]train_grp_loss: [21.20839525 12.47298695 19.903143  ], val_grp_loss: [21.07592962 12.79200301 19.88164489], train_hist_grp_loss: [2218.34573505 1471.28484377 2116.48119335], cur_train_grp_loss: [21.22079702 12.498972   19.92101263],max_reward_err:  0.0935, max_reward_err_index: 0, max_kl_dist:  0.7193, max_kl_dist_index: 0, max_train_grp_loss:  21.2084, max_train_grp_loss_index: 0, max_val_grp_loss:  21.0759, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  21.2208, max_cur_train_grp_loss_index: 0, 
2024-09-18 21:25:19,033 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:387] - INFO: Policy parameter learned solely on the preference data dpo: [8.18282617 4.11610617 4.21768263 2.61304348].
2024-09-18 21:25:19,379 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Uniform reward: 3.8396, 3.8396, 3.1854
2024-09-18 21:25:19,380 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Optimal reward: 3.8758, 3.8758, 3.2982
2024-09-18 21:25:19,381 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Policy reward: 3.5133, 3.8254, 3.1152
2024-09-18 21:25:19,381 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Reward Error: 0.0935, 0.0130, 0.0555
2024-09-18 21:25:20,148 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:416] - INFO: Optimal reward: 3.8758, 3.8758, 3.2982
Known param reward: [[3.875814437866211, 3.457228183746338, 3.2765753269195557], [3.457228183746338, 3.875814437866211, 3.0885965824127197], [3.8413593769073486, 3.579524040222168, 3.298182725906372]], Known param reward error: [[0.0, 0.10799956004868007, 0.006551304394718909], [0.10799956004868007, 0.0, 0.06354594663522048], [0.008889760206846016, 0.07644597087758477, 0.0]].
