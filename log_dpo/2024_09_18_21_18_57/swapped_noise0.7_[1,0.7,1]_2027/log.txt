2024-09-18 21:30:08,353 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log_dpo/2024_09_18_21_18_57/swapped_noise0.7_[1,0.7,1]_2027
2024-09-18 21:30:08,355 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2027
2024-09-18 21:30:08,356 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-09-18 21:30:08,520 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.4740, l2 distance: 14.0690, acc: 0.80.
2024-09-18 21:30:08,521 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-18 21:30:08,522 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [8.04817029 4.05673083 5.77693217 4.47787971]
2024-09-18 21:30:08,729 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.5746, 3.8303, 3.2378
2024-09-18 21:30:10,148 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:947] - INFO: Iteration:  0, train_loss:  21.3038, val_loss:  21.1944, grad_norm: 0.8523, reward_err: 0.1160, 0.0316, 0.0823, KL_dist: 0.3297, 0.0456, 0.2381, param: [0.67025755 0.34586277 4.68923034 2.08913656]train_grp_loss: [23.70047327 18.49096429 21.51423225], val_grp_loss: [23.39826048 18.43958228 22.79858458], train_hist_grp_loss: [23.74415724 18.60206975 21.57461323], cur_train_grp_loss: [23.74415724 18.60206975 21.57461323],max_reward_err:  0.1160, max_reward_err_index: 0, max_kl_dist:  0.3297, max_kl_dist_index: 0, max_train_grp_loss:  23.7005, max_train_grp_loss_index: 0, max_val_grp_loss:  23.3983, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  23.7442, max_cur_train_grp_loss_index: 0, 
2024-09-18 21:30:13,367 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:1040] - INFO: Iteration:  99, train_loss:  17.9497, val_loss:  17.7632, grad_norm: 0.3720, reward_err: 0.0772, 0.0206, 0.0423, KL_dist: 0.5985, 0.2759, 0.4582, param: [4.06501768 3.2486382  7.2309773  4.29294488]train_grp_loss: [21.20995554 14.31772105 17.88501035], val_grp_loss: [20.84902387 13.90489781 20.01150794], train_hist_grp_loss: [2224.04617526 1570.05718963 1942.57415231], cur_train_grp_loss: [21.22319683 14.32809904 17.90605523],max_reward_err:  0.0772, max_reward_err_index: 0, max_kl_dist:  0.5985, max_kl_dist_index: 0, max_train_grp_loss:  21.2100, max_train_grp_loss_index: 0, max_val_grp_loss:  20.8490, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  21.2232, max_cur_train_grp_loss_index: 0, 
2024-09-18 21:30:13,597 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:387] - INFO: Policy parameter learned solely on the preference data dpo: [4.06501768 3.2486382  7.2309773  4.29294488].
2024-09-18 21:30:13,938 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Uniform reward: 3.8291, 3.8291, 3.2263
2024-09-18 21:30:13,939 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Optimal reward: 3.8760, 3.8760, 3.3746
2024-09-18 21:30:13,939 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Policy reward: 3.5769, 3.7960, 3.2319
2024-09-18 21:30:13,940 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Reward Error: 0.0772, 0.0206, 0.0423
2024-09-18 21:30:14,634 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:416] - INFO: Optimal reward: 3.8760, 3.8760, 3.3746
Known param reward: [[3.87601900100708, 3.4725828170776367, 3.3359267711639404], [3.4725828170776367, 3.87601900100708, 3.170760154724121], [3.8373138904571533, 3.5966694355010986, 3.3746371269226074]], Known param reward error: [[0.0, 0.10408519251959839, 0.011470968374596076], [0.10408519251959839, 0.0, 0.060414487404281424], [0.009985789682628044, 0.07207125801844623, 0.0]].
