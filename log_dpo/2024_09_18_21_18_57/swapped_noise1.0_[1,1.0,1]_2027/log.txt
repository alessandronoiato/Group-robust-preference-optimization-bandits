2024-09-18 21:20:53,701 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log_dpo/2024_09_18_21_18_57/swapped_noise1.0_[1,1.0,1]_2027
2024-09-18 21:20:53,703 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2027
2024-09-18 21:20:53,703 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-09-18 21:20:53,863 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.3039, l2 distance: 43.5382, acc: 0.85.
2024-09-18 21:20:53,863 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-18 21:20:53,864 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [15.98532163 11.62149872 18.12217823 10.76721664]
2024-09-18 21:20:54,079 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.5595, 3.7451, 3.1925
2024-09-18 21:20:55,509 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:947] - INFO: Iteration:  0, train_loss:  18.3054, val_loss:  18.8325, grad_norm: 0.7447, reward_err: 0.0304, 0.0596, 0.0129, KL_dist: 0.2068, 0.3635, 0.1749, param: [4.37054055 4.7231829  2.06339822 4.55545449]train_grp_loss: [20.6000823  14.51289891 20.49296714], val_grp_loss: [20.34832074 17.02377141 19.78868568], train_hist_grp_loss: [20.62001875 14.62167162 20.52343979], cur_train_grp_loss: [20.62001875 14.62167162 20.52343979],max_reward_err:  0.0596, max_reward_err_index: 1, max_kl_dist:  0.3635, max_kl_dist_index: 1, max_train_grp_loss:  20.6001, max_train_grp_loss_index: 0, max_val_grp_loss:  20.3483, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  20.6200, max_cur_train_grp_loss_index: 0, 
2024-09-18 21:20:58,729 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:1040] - INFO: Iteration:  99, train_loss:  15.1719, val_loss:  15.3343, grad_norm: 0.4056, reward_err: 0.0662, 0.0181, 0.0322, KL_dist: 0.8321, 0.5318, 0.6629, param: [8.0351021  5.54475298 6.06977104 4.60066727]train_grp_loss: [19.43818353  8.49745043 18.55865853], val_grp_loss: [19.29140024 10.7990075  17.34922085], train_hist_grp_loss: [1992.20566684 1094.84498113 1939.74920555], cur_train_grp_loss: [19.44441584  8.52777376 18.57057803],max_reward_err:  0.0662, max_reward_err_index: 0, max_kl_dist:  0.8321, max_kl_dist_index: 0, max_train_grp_loss:  19.4382, max_train_grp_loss_index: 0, max_val_grp_loss:  19.2914, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  19.4444, max_cur_train_grp_loss_index: 0, 
2024-09-18 21:20:58,978 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:387] - INFO: Policy parameter learned solely on the preference data dpo: [8.0351021  5.54475298 6.06977104 4.60066727].
2024-09-18 21:20:59,335 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Uniform reward: 3.7539, 3.7539, 3.1331
2024-09-18 21:20:59,336 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Optimal reward: 3.7966, 3.7966, 3.2856
2024-09-18 21:20:59,336 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Policy reward: 3.5454, 3.7278, 3.1799
2024-09-18 21:20:59,337 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Reward Error: 0.0662, 0.0181, 0.0322
2024-09-18 21:21:00,037 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:416] - INFO: Optimal reward: 3.7966, 3.7966, 3.2856
Known param reward: [[3.796614646911621, 3.427426815032959, 3.2432873249053955], [3.427426815032959, 3.796614646911621, 3.100863218307495], [3.754006862640381, 3.5487284660339355, 3.2855939865112305]], Known param reward error: [[0.0, 0.0972413231822145, 0.012876411930239072], [0.0972413231822145, 0.0, 0.0562244662493705], [0.011222572800718606, 0.06529137242815256, 0.0]].
