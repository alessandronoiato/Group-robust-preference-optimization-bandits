2024-09-18 21:22:27,148 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log_dpo/2024_09_18_21_18_57/swapped_noise0.9_[1,0.9,1]_2022
2024-09-18 21:22:27,150 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2022
2024-09-18 21:22:27,151 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-09-18 21:22:27,313 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.3535, l2 distance: 28.4868, acc: 0.85.
2024-09-18 21:22:27,314 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-18 21:22:27,315 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [12.5384091   6.91815982 12.54481599  6.12893569]
2024-09-18 21:22:27,523 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.5653, 3.8050, 3.1647
2024-09-18 21:22:28,943 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:947] - INFO: Iteration:  0, train_loss:  20.1530, val_loss:  20.3880, grad_norm: 0.9203, reward_err: 0.0630, 0.0734, 0.0397, KL_dist: 0.1338, 0.1892, 0.0834, param: [3.51984956 4.06851396 1.21916315 0.54584463]train_grp_loss: [22.80886582 17.03822193 21.69494252], val_grp_loss: [22.38579736 17.57039647 22.4176962 ], train_hist_grp_loss: [22.84224792 17.1854306  21.74159668], cur_train_grp_loss: [22.84224792 17.1854306  21.74159668],max_reward_err:  0.0734, max_reward_err_index: 1, max_kl_dist:  0.1892, max_kl_dist_index: 1, max_train_grp_loss:  22.8089, max_train_grp_loss_index: 0, max_val_grp_loss:  22.4177, max_val_grp_loss_index: 2, max_cur_train_grp_loss:  22.8422, max_cur_train_grp_loss_index: 0, 
2024-09-18 21:22:32,148 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:1040] - INFO: Iteration:  99, train_loss:  15.5717, val_loss:  15.8742, grad_norm: 0.4754, reward_err: 0.0710, 0.0185, 0.0384, KL_dist: 0.7506, 0.3892, 0.5837, param: [7.90279538 4.9589595  5.6185128  2.66726603]train_grp_loss: [20.89018939  9.29342619 18.7719794 ], val_grp_loss: [20.30512748  9.94717207 19.58740639], train_hist_grp_loss: [2168.51810345 1237.54815026 2003.31725579], cur_train_grp_loss: [20.90036472  9.32957218 18.78973155],max_reward_err:  0.0710, max_reward_err_index: 0, max_kl_dist:  0.7506, max_kl_dist_index: 0, max_train_grp_loss:  20.8902, max_train_grp_loss_index: 0, max_val_grp_loss:  20.3051, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  20.9004, max_cur_train_grp_loss_index: 0, 
2024-09-18 21:22:32,373 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:387] - INFO: Policy parameter learned solely on the preference data dpo: [7.90279538 4.9589595  5.6185128  2.66726603].
2024-09-18 21:22:32,708 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Uniform reward: 3.7937, 3.7937, 3.1474
2024-09-18 21:22:32,708 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Optimal reward: 3.8247, 3.8247, 3.2742
2024-09-18 21:22:32,709 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Policy reward: 3.5532, 3.7539, 3.1484
2024-09-18 21:22:32,709 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Reward Error: 0.0710, 0.0185, 0.0384
2024-09-18 21:22:33,381 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:416] - INFO: Optimal reward: 3.8247, 3.8247, 3.2742
Known param reward: [[3.8246958255767822, 3.493746519088745, 3.228804111480713], [3.493746519088745, 3.8246958255767822, 3.1130502223968506], [3.7828567028045654, 3.5981593132019043, 3.274172782897949]], Known param reward error: [[0.0, 0.08652957557432123, 0.013856529397046912], [0.08652957557432123, 0.0, 0.049210158163519424], [0.010939202666111954, 0.059229942119832533, 0.0]].
