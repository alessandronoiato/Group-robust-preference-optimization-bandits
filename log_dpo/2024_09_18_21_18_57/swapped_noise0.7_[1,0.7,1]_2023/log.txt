2024-09-18 21:28:54,768 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log_dpo/2024_09_18_21_18_57/swapped_noise0.7_[1,0.7,1]_2023
2024-09-18 21:28:54,770 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2023
2024-09-18 21:28:54,770 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-09-18 21:28:54,935 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.4606, l2 distance: 16.8393, acc: 0.77.
2024-09-18 21:28:54,936 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-18 21:28:54,937 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [9.94263926 2.54922984 6.33285423 4.50745735]
2024-09-18 21:28:55,148 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.5010, 3.8601, 3.0995
2024-09-18 21:28:56,567 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:947] - INFO: Iteration:  0, train_loss:  20.9173, val_loss:  21.0920, grad_norm: 0.7338, reward_err: 0.0125, 0.0907, 0.0021, KL_dist: 0.0382, 0.2498, 0.0220, param: [2.1823221  1.60931769 1.91719667 4.79945238]train_grp_loss: [21.97058758 19.56322607 21.39179437], val_grp_loss: [22.01783364 19.83379162 22.09929351], train_hist_grp_loss: [21.98852627 19.66347386 21.42791517], cur_train_grp_loss: [21.98852627 19.66347386 21.42791517],max_reward_err:  0.0907, max_reward_err_index: 1, max_kl_dist:  0.2498, max_kl_dist_index: 1, max_train_grp_loss:  21.9706, max_train_grp_loss_index: 0, max_val_grp_loss:  22.0993, max_val_grp_loss_index: 2, max_cur_train_grp_loss:  21.9885, max_cur_train_grp_loss_index: 0, 
2024-09-18 21:28:59,806 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:1040] - INFO: Iteration:  99, train_loss:  17.8328, val_loss:  18.2357, grad_norm: 0.4053, reward_err: 0.0682, 0.0195, 0.0340, KL_dist: 0.5363, 0.3018, 0.4007, param: [6.38019249 2.51853723 5.27650875 4.87676941]train_grp_loss: [20.92963994 13.93123493 19.04272288], val_grp_loss: [21.20001183 14.41800497 20.90493358], train_hist_grp_loss: [2136.30020391 1623.93348838 2007.16123267], cur_train_grp_loss: [20.93525673 13.96000137 19.05763356],max_reward_err:  0.0682, max_reward_err_index: 0, max_kl_dist:  0.5363, max_kl_dist_index: 0, max_train_grp_loss:  20.9296, max_train_grp_loss_index: 0, max_val_grp_loss:  21.2000, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  20.9353, max_cur_train_grp_loss_index: 0, 
2024-09-18 21:29:00,038 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:387] - INFO: Policy parameter learned solely on the preference data dpo: [6.38019249 2.51853723 5.27650875 4.87676941].
2024-09-18 21:29:00,380 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Uniform reward: 3.8283, 3.8283, 3.1664
2024-09-18 21:29:00,381 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Optimal reward: 3.8661, 3.8661, 3.2904
2024-09-18 21:29:00,381 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Policy reward: 3.6023, 3.7906, 3.1786
2024-09-18 21:29:00,382 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Reward Error: 0.0682, 0.0195, 0.0340
2024-09-18 21:29:01,071 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:416] - INFO: Optimal reward: 3.8661, 3.8661, 3.2904
Known param reward: [[3.8660781383514404, 3.4902846813201904, 3.2660531997680664], [3.4902846813201904, 3.8660781383514404, 3.1010468006134033], [3.830267906188965, 3.6122817993164062, 3.2904317378997803]], Known param reward error: [[0.0, 0.09720275782928033, 0.00740891775717986], [0.09720275782928033, 0.0, 0.05755625777158889], [0.009262676769835195, 0.06564697607049845, 0.0]].
