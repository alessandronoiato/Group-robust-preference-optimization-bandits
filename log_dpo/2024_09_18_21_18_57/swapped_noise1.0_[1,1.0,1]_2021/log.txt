2024-09-18 21:19:01,746 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log_dpo/2024_09_18_21_18_57/swapped_noise1.0_[1,1.0,1]_2021
2024-09-18 21:19:01,748 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2021
2024-09-18 21:19:01,749 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-09-18 21:19:01,920 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.3566, l2 distance: 29.5613, acc: 0.82.
2024-09-18 21:19:01,921 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-18 21:19:01,921 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [12.9300958   5.57206545 13.55993407  6.18568546]
2024-09-18 21:19:02,131 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.5204, 3.8718, 3.1349
2024-09-18 21:19:03,684 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:947] - INFO: Iteration:  0, train_loss:  20.8267, val_loss:  19.8838, grad_norm: 0.9426, reward_err: 0.0146, 0.0876, 0.0059, KL_dist: 0.0526, 0.2592, 0.0478, param: [1.54740742 3.11539833 2.62596725 4.4494472 ]train_grp_loss: [21.70048804 19.9762781  20.76844319], val_grp_loss: [21.43229233 17.66529335 21.40669648], train_hist_grp_loss: [21.70447552 20.17023927 20.8049118 ], cur_train_grp_loss: [21.70447552 20.17023927 20.8049118 ],max_reward_err:  0.0876, max_reward_err_index: 1, max_kl_dist:  0.2592, max_kl_dist_index: 1, max_train_grp_loss:  21.7005, max_train_grp_loss_index: 0, max_val_grp_loss:  21.4323, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  21.7045, max_cur_train_grp_loss_index: 0, 
2024-09-18 21:19:06,902 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:1040] - INFO: Iteration:  99, train_loss:  15.9276, val_loss:  15.5490, grad_norm: 0.4991, reward_err: 0.0840, 0.0039, 0.0434, KL_dist: 0.7258, 0.3419, 0.5536, param: [6.5240249  3.63429961 7.25669117 3.72331589]train_grp_loss: [21.5824886   9.29066924 18.38273064], val_grp_loss: [20.41705418  8.82651352 19.67839682], train_hist_grp_loss: [2160.8951693  1364.04824756 1943.12904786], cur_train_grp_loss: [21.58212859  9.3444819  18.39808623],max_reward_err:  0.0840, max_reward_err_index: 0, max_kl_dist:  0.7258, max_kl_dist_index: 0, max_train_grp_loss:  21.5825, max_train_grp_loss_index: 0, max_val_grp_loss:  20.4171, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  21.5821, max_cur_train_grp_loss_index: 0, 
2024-09-18 21:19:07,130 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:387] - INFO: Policy parameter learned solely on the preference data dpo: [6.5240249  3.63429961 7.25669117 3.72331589].
2024-09-18 21:19:07,472 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Uniform reward: 3.8396, 3.8396, 3.1854
2024-09-18 21:19:07,473 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Optimal reward: 3.8758, 3.8758, 3.2982
2024-09-18 21:19:07,474 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Policy reward: 3.5502, 3.8609, 3.1552
2024-09-18 21:19:07,474 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Reward Error: 0.0840, 0.0039, 0.0434
2024-09-18 21:19:08,177 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:416] - INFO: Optimal reward: 3.8758, 3.8758, 3.2982
Known param reward: [[3.875814437866211, 3.457228183746338, 3.2765753269195557], [3.457228183746338, 3.875814437866211, 3.0885965824127197], [3.8413593769073486, 3.579524040222168, 3.298182725906372]], Known param reward error: [[0.0, 0.10799956004868007, 0.006551304394718909], [0.10799956004868007, 0.0, 0.06354594663522048], [0.008889760206846016, 0.07644597087758477, 0.0]].
