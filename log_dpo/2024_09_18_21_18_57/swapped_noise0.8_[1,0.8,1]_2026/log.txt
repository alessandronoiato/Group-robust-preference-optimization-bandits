2024-09-18 21:26:46,043 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log_dpo/2024_09_18_21_18_57/swapped_noise0.8_[1,0.8,1]_2026
2024-09-18 21:26:46,045 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2026
2024-09-18 21:26:46,045 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-09-18 21:26:46,207 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.4346, l2 distance: 16.8897, acc: 0.82.
2024-09-18 21:26:46,208 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-18 21:26:46,209 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [7.57155055 3.81137211 8.78806046 5.02984248]
2024-09-18 21:26:46,425 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.5364, 3.8049, 3.1354
2024-09-18 21:26:47,859 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:947] - INFO: Iteration:  0, train_loss:  19.8715, val_loss:  20.8245, grad_norm: 0.7663, reward_err: 0.0704, 0.0694, 0.0509, KL_dist: 0.2179, 0.2011, 0.1912, param: [0.08988663 2.27671306 4.45357044 4.09436652]train_grp_loss: [21.81838383 16.65560538 22.02397229], val_grp_loss: [21.74573772 19.70355506 21.35771843], train_hist_grp_loss: [21.85159828 16.74924612 22.07079416], cur_train_grp_loss: [21.85159828 16.74924612 22.07079416],max_reward_err:  0.0704, max_reward_err_index: 0, max_kl_dist:  0.2179, max_kl_dist_index: 0, max_train_grp_loss:  22.0240, max_train_grp_loss_index: 2, max_val_grp_loss:  21.7457, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  22.0708, max_cur_train_grp_loss_index: 2, 
2024-09-18 21:26:51,075 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:1040] - INFO: Iteration:  99, train_loss:  16.7933, val_loss:  17.6455, grad_norm: 0.3850, reward_err: 0.0764, 0.0328, 0.0426, KL_dist: 0.6659, 0.3795, 0.5361, param: [3.9565159  3.31923862 7.90609949 5.25909385]train_grp_loss: [19.9370512  12.08581422 19.08078157], val_grp_loss: [19.97168733 14.87573794 18.8414713 ], train_hist_grp_loss: [2071.12118867 1384.64640441 2035.27637925], cur_train_grp_loss: [19.9467944  12.10532567 19.09875986],max_reward_err:  0.0764, max_reward_err_index: 0, max_kl_dist:  0.6659, max_kl_dist_index: 0, max_train_grp_loss:  19.9371, max_train_grp_loss_index: 0, max_val_grp_loss:  19.9717, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  19.9468, max_cur_train_grp_loss_index: 0, 
2024-09-18 21:26:51,304 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:387] - INFO: Policy parameter learned solely on the preference data dpo: [3.9565159  3.31923862 7.90609949 5.25909385].
2024-09-18 21:26:51,648 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Uniform reward: 3.7897, 3.7897, 3.1396
2024-09-18 21:26:51,649 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Optimal reward: 3.8304, 3.8304, 3.2622
2024-09-18 21:26:51,649 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Policy reward: 3.5377, 3.7046, 3.1231
2024-09-18 21:26:51,650 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Reward Error: 0.0764, 0.0328, 0.0426
2024-09-18 21:26:52,345 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:416] - INFO: Optimal reward: 3.8304, 3.8304, 3.2622
Known param reward: [[3.8303539752960205, 3.4527127742767334, 3.2332265377044678], [3.4527127742767334, 3.8303539752960205, 3.0769858360290527], [3.7932167053222656, 3.5765700340270996, 3.2621729373931885]], Known param reward error: [[0.0, 0.09859172375579256, 0.008873349219754073], [0.09859172375579256, 0.0, 0.056768020861616024], [0.009695519059928348, 0.06625600216212596, 0.0]].
