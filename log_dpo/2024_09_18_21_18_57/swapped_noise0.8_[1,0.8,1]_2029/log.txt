2024-09-18 21:27:39,924 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log_dpo/2024_09_18_21_18_57/swapped_noise0.8_[1,0.8,1]_2029
2024-09-18 21:27:39,926 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2029
2024-09-18 21:27:39,926 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-09-18 21:27:40,085 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.4324, l2 distance: 19.3716, acc: 0.80.
2024-09-18 21:27:40,086 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-18 21:27:40,087 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [9.58392379 4.98630681 8.74612656 4.6942155 ]
2024-09-18 21:27:40,294 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.5422, 3.8224, 3.1983
2024-09-18 21:27:41,769 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:947] - INFO: Iteration:  0, train_loss:  23.5764, val_loss:  23.6211, grad_norm: 1.0168, reward_err: 0.0073, 0.1533, 0.0293, KL_dist: 0.0458, 0.3131, 0.0650, param: [0.1857822  0.26738667 0.32480934 3.71585696]train_grp_loss: [23.51363292 23.55688763 23.83596139], val_grp_loss: [23.42801401 23.84938432 23.54881027], train_hist_grp_loss: [23.54314869 23.74584397 23.89793805], cur_train_grp_loss: [23.54314869 23.74584397 23.89793805],max_reward_err:  0.1533, max_reward_err_index: 1, max_kl_dist:  0.3131, max_kl_dist_index: 1, max_train_grp_loss:  23.8360, max_train_grp_loss_index: 2, max_val_grp_loss:  23.8494, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  23.8979, max_cur_train_grp_loss_index: 2, 
2024-09-18 21:27:45,000 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:1040] - INFO: Iteration:  99, train_loss:  17.9116, val_loss:  17.6044, grad_norm: 0.5307, reward_err: 0.0665, 0.0181, 0.0300, KL_dist: 0.4569, 0.2138, 0.3173, param: [5.32783133 2.45250873 5.11865674 4.10787595]train_grp_loss: [21.83646446 13.39931303 19.87013604], val_grp_loss: [20.98498727 13.18597968 19.94508778], train_hist_grp_loss: [2252.78440643 1747.35157785 2159.69596732], cur_train_grp_loss: [21.84522144 13.44759336 19.89493059],max_reward_err:  0.0665, max_reward_err_index: 0, max_kl_dist:  0.4569, max_kl_dist_index: 0, max_train_grp_loss:  21.8365, max_train_grp_loss_index: 0, max_val_grp_loss:  20.9850, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  21.8452, max_cur_train_grp_loss_index: 0, 
2024-09-18 21:27:45,222 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:387] - INFO: Policy parameter learned solely on the preference data dpo: [5.32783133 2.45250873 5.11865674 4.10787595].
2024-09-18 21:27:45,560 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Uniform reward: 3.7974, 3.7974, 3.1819
2024-09-18 21:27:45,561 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Optimal reward: 3.8436, 3.8436, 3.3299
2024-09-18 21:27:45,562 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Policy reward: 3.5881, 3.7739, 3.2300
2024-09-18 21:27:45,562 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Reward Error: 0.0665, 0.0181, 0.0300
2024-09-18 21:27:46,229 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:416] - INFO: Optimal reward: 3.8436, 3.8436, 3.3299
Known param reward: [[3.843637228012085, 3.444669008255005, 3.2935516834259033], [3.444669008255005, 3.843637228012085, 3.1286234855651855], [3.807432174682617, 3.5788300037384033, 3.3299360275268555]], Known param reward error: [[0.0, 0.10379965540177291, 0.010926439367057394], [0.10379965540177291, 0.0, 0.06045537821072942], [0.009419477224751747, 0.06889495770927345, 0.0]].
