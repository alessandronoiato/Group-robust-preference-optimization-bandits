2024-09-18 21:19:38,292 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log_dpo/2024_09_18_21_18_57/swapped_noise1.0_[1,1.0,1]_2023
2024-09-18 21:19:38,294 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2023
2024-09-18 21:19:38,295 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-09-18 21:19:38,467 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.3431, l2 distance: 35.5343, acc: 0.83.
2024-09-18 21:19:38,468 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-18 21:19:38,469 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [15.61298457  7.73326877 14.20212669  8.81141422]
2024-09-18 21:19:38,681 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.5207, 3.7738, 3.1140
2024-09-18 21:19:40,145 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:947] - INFO: Iteration:  0, train_loss:  21.3187, val_loss:  22.4731, grad_norm: 0.9019, reward_err: 0.0081, 0.1155, 0.0143, KL_dist: 0.0133, 0.3445, 0.0268, param: [0.76855171 1.25795719 1.45300465 4.99773171]train_grp_loss: [22.22342636 19.91007849 22.29950209], val_grp_loss: [22.21902754 22.69049695 22.513159  ], train_hist_grp_loss: [22.25133684 20.06730339 22.3385873 ], cur_train_grp_loss: [22.25133684 20.06730339 22.3385873 ],max_reward_err:  0.1155, max_reward_err_index: 1, max_kl_dist:  0.3445, max_kl_dist_index: 1, max_train_grp_loss:  22.2995, max_train_grp_loss_index: 2, max_val_grp_loss:  22.6905, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  22.3386, max_cur_train_grp_loss_index: 2, 
2024-09-18 21:19:43,367 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:1040] - INFO: Iteration:  99, train_loss:  16.5715, val_loss:  17.0606, grad_norm: 0.5101, reward_err: 0.0608, 0.0307, 0.0269, KL_dist: 0.5458, 0.3684, 0.4125, param: [5.42589177 2.67873128 6.13261736 5.49707098]train_grp_loss: [20.59230742 10.77133474 19.85595604], val_grp_loss: [20.75958541 12.66465819 19.73145652], train_hist_grp_loss: [2127.27933666 1458.06451064 2090.82180444], cur_train_grp_loss: [20.60112523 10.82082278 19.87066344],max_reward_err:  0.0608, max_reward_err_index: 0, max_kl_dist:  0.5458, max_kl_dist_index: 0, max_train_grp_loss:  20.5923, max_train_grp_loss_index: 0, max_val_grp_loss:  20.7596, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  20.6011, max_cur_train_grp_loss_index: 0, 
2024-09-18 21:19:43,593 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:387] - INFO: Policy parameter learned solely on the preference data dpo: [5.42589177 2.67873128 6.13261736 5.49707098].
2024-09-18 21:19:43,937 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Uniform reward: 3.7649, 3.7649, 3.1065
2024-09-18 21:19:43,938 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Optimal reward: 3.7986, 3.7986, 3.2301
2024-09-18 21:19:43,939 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Policy reward: 3.5677, 3.6821, 3.1433
2024-09-18 21:19:43,940 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Reward Error: 0.0608, 0.0307, 0.0269
2024-09-18 21:19:44,629 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:416] - INFO: Optimal reward: 3.7986, 3.7986, 3.2301
Known param reward: [[3.798638105392456, 3.4322617053985596, 3.1943700313568115], [3.4322617053985596, 3.798638105392456, 3.0506064891815186], [3.7604806423187256, 3.5411648750305176, 3.2300760746002197]], Known param reward error: [[0.0, 0.09644940892731985, 0.011054242197013106], [0.09644940892731985, 0.0, 0.05556203051375927], [0.010045037725379274, 0.06778040529747638, 0.0]].
