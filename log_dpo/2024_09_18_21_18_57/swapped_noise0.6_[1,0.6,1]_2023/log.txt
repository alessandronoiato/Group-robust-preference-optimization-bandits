2024-09-18 21:32:00,828 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log_dpo/2024_09_18_21_18_57/swapped_noise0.6_[1,0.6,1]_2023
2024-09-18 21:32:00,830 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2023
2024-09-18 21:32:00,830 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-09-18 21:32:00,991 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.4901, l2 distance: 13.7110, acc: 0.77.
2024-09-18 21:32:00,991 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-18 21:32:00,992 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [8.67865662 2.73331006 5.03288862 3.70226044]
2024-09-18 21:32:01,201 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.5026, 3.8542, 3.0974
2024-09-18 21:32:02,626 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:947] - INFO: Iteration:  0, train_loss:  21.5905, val_loss:  21.4423, grad_norm: 0.7847, reward_err: 0.1076, 0.0182, 0.0720, KL_dist: 0.2172, 0.0287, 0.1268, param: [1.80710125 0.13614178 3.67317931 1.80028077]train_grp_loss: [23.7723906  18.8741536  22.36694429], val_grp_loss: [23.73357384 18.61546082 23.17872439], train_hist_grp_loss: [23.81156471 18.96489726 22.41612673], cur_train_grp_loss: [23.81156471 18.96489726 22.41612673],max_reward_err:  0.1076, max_reward_err_index: 0, max_kl_dist:  0.2172, max_kl_dist_index: 0, max_train_grp_loss:  23.7724, max_train_grp_loss_index: 0, max_val_grp_loss:  23.7336, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  23.8116, max_cur_train_grp_loss_index: 0, 
2024-09-18 21:32:05,860 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:1040] - INFO: Iteration:  99, train_loss:  18.4504, val_loss:  18.1759, grad_norm: 0.3846, reward_err: 0.0783, 0.0037, 0.0416, KL_dist: 0.5596, 0.2262, 0.4047, param: [5.72596821 2.35458444 6.14591137 3.63562002]train_grp_loss: [21.48249044 14.76698797 19.31590063], val_grp_loss: [21.83065937 13.6514     20.98594848], train_hist_grp_loss: [2244.06478778 1629.05337791 2062.68356265], cur_train_grp_loss: [21.49510788 14.7825357  19.33417735],max_reward_err:  0.0783, max_reward_err_index: 0, max_kl_dist:  0.5596, max_kl_dist_index: 0, max_train_grp_loss:  21.4825, max_train_grp_loss_index: 0, max_val_grp_loss:  21.8307, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  21.4951, max_cur_train_grp_loss_index: 0, 
2024-09-18 21:32:06,089 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:387] - INFO: Policy parameter learned solely on the preference data dpo: [5.72596821 2.35458444 6.14591137 3.63562002].
2024-09-18 21:32:06,425 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Uniform reward: 3.8283, 3.8283, 3.1664
2024-09-18 21:32:06,426 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Optimal reward: 3.8661, 3.8661, 3.2904
2024-09-18 21:32:06,426 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Policy reward: 3.5635, 3.8516, 3.1536
2024-09-18 21:32:06,427 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Reward Error: 0.0783, 0.0037, 0.0416
2024-09-18 21:32:07,099 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:416] - INFO: Optimal reward: 3.8661, 3.8661, 3.2904
Known param reward: [[3.8660781383514404, 3.4902846813201904, 3.2660531997680664], [3.4902846813201904, 3.8660781383514404, 3.1010468006134033], [3.830267906188965, 3.6122817993164062, 3.2904317378997803]], Known param reward error: [[0.0, 0.09720275782928033, 0.00740891775717986], [0.09720275782928033, 0.0, 0.05755625777158889], [0.009262676769835195, 0.06564697607049845, 0.0]].
