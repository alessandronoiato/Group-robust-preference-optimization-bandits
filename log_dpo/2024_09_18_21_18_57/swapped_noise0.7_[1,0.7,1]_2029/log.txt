2024-09-18 21:30:46,885 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log_dpo/2024_09_18_21_18_57/swapped_noise0.7_[1,0.7,1]_2029
2024-09-18 21:30:46,887 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2029
2024-09-18 21:30:46,888 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-09-18 21:30:47,053 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.4360, l2 distance: 17.6893, acc: 0.78.
2024-09-18 21:30:47,054 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-18 21:30:47,055 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [8.45198418 4.08444303 9.00463429 3.74875698]
2024-09-18 21:30:47,269 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.5268, 3.8528, 3.1773
2024-09-18 21:30:48,755 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:947] - INFO: Iteration:  0, train_loss:  21.6884, val_loss:  21.2377, grad_norm: 0.8918, reward_err: 0.0270, 0.0885, 0.0204, KL_dist: 0.0574, 0.2309, 0.0607, param: [0.24473742 2.79998233 2.63093063 3.62173163]train_grp_loss: [22.35440978 21.01441306 21.72969447], val_grp_loss: [22.03555547 20.00004923 22.11614208], train_hist_grp_loss: [22.37265479 21.17171083 21.75353945], cur_train_grp_loss: [22.37265479 21.17171083 21.75353945],max_reward_err:  0.0885, max_reward_err_index: 1, max_kl_dist:  0.2309, max_kl_dist_index: 1, max_train_grp_loss:  22.3544, max_train_grp_loss_index: 0, max_val_grp_loss:  22.1161, max_val_grp_loss_index: 2, max_cur_train_grp_loss:  22.3727, max_cur_train_grp_loss_index: 0, 
2024-09-18 21:30:52,078 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:1040] - INFO: Iteration:  99, train_loss:  17.2868, val_loss:  17.6185, grad_norm: 0.4708, reward_err: 0.0796, 0.0098, 0.0418, KL_dist: 0.6379, 0.2670, 0.4758, param: [4.87646887 3.42181178 7.15285081 3.61904314]train_grp_loss: [21.41481493 12.24764114 20.27628301], val_grp_loss: [20.60455832 13.14127443 20.55829734], train_hist_grp_loss: [2178.22951657 1582.72802875 2089.59018095], cur_train_grp_loss: [21.41884996 12.29193981 20.28478504],max_reward_err:  0.0796, max_reward_err_index: 0, max_kl_dist:  0.6379, max_kl_dist_index: 0, max_train_grp_loss:  21.4148, max_train_grp_loss_index: 0, max_val_grp_loss:  20.6046, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  21.4188, max_cur_train_grp_loss_index: 0, 
2024-09-18 21:30:52,309 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:387] - INFO: Policy parameter learned solely on the preference data dpo: [4.87646887 3.42181178 7.15285081 3.61904314].
2024-09-18 21:30:52,644 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Uniform reward: 3.8140, 3.8140, 3.1855
2024-09-18 21:30:52,644 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Optimal reward: 3.8587, 3.8587, 3.3276
2024-09-18 21:30:52,645 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Policy reward: 3.5517, 3.8211, 3.1886
2024-09-18 21:30:52,645 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Reward Error: 0.0796, 0.0098, 0.0418
2024-09-18 21:30:53,311 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:416] - INFO: Optimal reward: 3.8587, 3.8587, 3.3276
Known param reward: [[3.8587026596069336, 3.4686262607574463, 3.2998154163360596], [3.4686262607574463, 3.8587026596069336, 3.134716510772705], [3.824064016342163, 3.5878939628601074, 3.327615261077881]], Known param reward error: [[0.0, 0.1010900380930679, 0.008354284543344824], [0.1010900380930679, 0.0, 0.05796906648477505], [0.0089767588540494, 0.07018128128442322, 0.0]].
