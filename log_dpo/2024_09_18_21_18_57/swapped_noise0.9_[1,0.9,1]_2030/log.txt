2024-09-18 21:24:56,183 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log_dpo/2024_09_18_21_18_57/swapped_noise0.9_[1,0.9,1]_2030
2024-09-18 21:24:56,184 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2030
2024-09-18 21:24:56,185 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-09-18 21:24:56,351 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.4282, l2 distance: 17.0495, acc: 0.80.
2024-09-18 21:24:56,352 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-18 21:24:56,353 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [7.37774022 3.69856674 9.52307453 3.50330935]
2024-09-18 21:24:56,561 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.4295, 3.7893, 3.0852
2024-09-18 21:24:57,993 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:947] - INFO: Iteration:  0, train_loss:  22.4932, val_loss:  22.5111, grad_norm: 1.0815, reward_err: 0.0038, 0.1322, 0.0052, KL_dist: 0.0144, 0.2647, 0.0146, param: [1.22720766 0.82972031 0.7904796  3.92805251]train_grp_loss: [22.87401313 22.12587244 22.74121003], val_grp_loss: [22.85624085 22.05722501 22.77206458], train_hist_grp_loss: [22.90449134 22.33425356 22.77532727], cur_train_grp_loss: [22.90449134 22.33425356 22.77532727],max_reward_err:  0.1322, max_reward_err_index: 1, max_kl_dist:  0.2647, max_kl_dist_index: 1, max_train_grp_loss:  22.8740, max_train_grp_loss_index: 0, max_val_grp_loss:  22.8562, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  22.9045, max_cur_train_grp_loss_index: 0, 
2024-09-18 21:25:01,223 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:1040] - INFO: Iteration:  99, train_loss:  16.8297, val_loss:  17.0799, grad_norm: 0.4907, reward_err: 0.0683, 0.0080, 0.0324, KL_dist: 0.5750, 0.2348, 0.4149, param: [5.92856966 3.02639466 5.91802616 3.60267835]train_grp_loss: [21.32583688 12.14526921 20.77787648], val_grp_loss: [21.03389712 11.90063443 20.01025363], train_hist_grp_loss: [2193.01652034 1595.50574122 2159.44439868], cur_train_grp_loss: [21.33257768 12.18661386 20.78852396],max_reward_err:  0.0683, max_reward_err_index: 0, max_kl_dist:  0.5750, max_kl_dist_index: 0, max_train_grp_loss:  21.3258, max_train_grp_loss_index: 0, max_val_grp_loss:  21.0339, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  21.3326, max_cur_train_grp_loss_index: 0, 
2024-09-18 21:25:01,450 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:387] - INFO: Policy parameter learned solely on the preference data dpo: [5.92856966 3.02639466 5.91802616 3.60267835].
2024-09-18 21:25:01,790 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Uniform reward: 3.7571, 3.7571, 3.1335
2024-09-18 21:25:01,791 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Optimal reward: 3.7951, 3.7951, 3.2723
2024-09-18 21:25:01,791 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Policy reward: 3.5358, 3.7647, 3.1663
2024-09-18 21:25:01,792 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Reward Error: 0.0683, 0.0080, 0.0324
2024-09-18 21:25:02,497 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:416] - INFO: Optimal reward: 3.7951, 3.7951, 3.2723
Known param reward: [[3.795067548751831, 3.433345317840576, 3.2372632026672363], [3.433345317840576, 3.795067548751831, 3.092838764190674], [3.760380268096924, 3.5445938110351562, 3.2722654342651367]], Known param reward error: [[0.0, 0.09531377933713528, 0.010696635802028375], [0.09531377933713528, 0.0, 0.05483255367844489], [0.009140095718801002, 0.0659998101480575, 0.0]].
