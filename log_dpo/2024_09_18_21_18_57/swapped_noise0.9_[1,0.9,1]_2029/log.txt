2024-09-18 21:24:37,357 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log_dpo/2024_09_18_21_18_57/swapped_noise0.9_[1,0.9,1]_2029
2024-09-18 21:24:37,359 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2029
2024-09-18 21:24:37,359 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-09-18 21:24:37,521 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.3922, l2 distance: 23.9064, acc: 0.84.
2024-09-18 21:24:37,522 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-18 21:24:37,523 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [ 9.06453268  6.49602515 11.99559379  5.81513793]
2024-09-18 21:24:37,735 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.5441, 3.8076, 3.1936
2024-09-18 21:24:39,190 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:947] - INFO: Iteration:  0, train_loss:  21.6548, val_loss:  21.6948, grad_norm: 0.9690, reward_err: 0.0705, 0.0731, 0.0478, KL_dist: 0.1121, 0.1176, 0.0720, param: [2.88098507 2.93170116 0.5193931  0.56191181]train_grp_loss: [23.34942893 19.6548274  22.66400681], val_grp_loss: [23.14935343 19.69574364 22.83962996], train_hist_grp_loss: [23.39176443 19.81218457 22.71637944], cur_train_grp_loss: [23.39176443 19.81218457 22.71637944],max_reward_err:  0.0731, max_reward_err_index: 1, max_kl_dist:  0.1176, max_kl_dist_index: 1, max_train_grp_loss:  23.3494, max_train_grp_loss_index: 0, max_val_grp_loss:  23.1494, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  23.3918, max_cur_train_grp_loss_index: 0, 
2024-09-18 21:24:42,438 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:1040] - INFO: Iteration:  99, train_loss:  16.7515, val_loss:  16.7434, grad_norm: 0.4865, reward_err: 0.0723, 0.0127, 0.0360, KL_dist: 0.5965, 0.2896, 0.4415, param: [6.74553686 4.08774444 5.17459474 3.51342503]train_grp_loss: [20.95383244 11.69302775 19.56867541], val_grp_loss: [20.68510582 11.57860536 19.23867453], train_hist_grp_loss: [2194.13470328 1482.29332586 2087.16664056], cur_train_grp_loss: [20.9664153  11.72948791 19.58610697],max_reward_err:  0.0723, max_reward_err_index: 0, max_kl_dist:  0.5965, max_kl_dist_index: 0, max_train_grp_loss:  20.9538, max_train_grp_loss_index: 0, max_val_grp_loss:  20.6851, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  20.9664, max_cur_train_grp_loss_index: 0, 
2024-09-18 21:24:42,669 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:387] - INFO: Policy parameter learned solely on the preference data dpo: [6.74553686 4.08774444 5.17459474 3.51342503].
2024-09-18 21:24:43,015 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Uniform reward: 3.7915, 3.7915, 3.1756
2024-09-18 21:24:43,015 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Optimal reward: 3.8379, 3.8379, 3.3243
2024-09-18 21:24:43,016 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Policy reward: 3.5606, 3.7893, 3.2045
2024-09-18 21:24:43,016 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Reward Error: 0.0723, 0.0127, 0.0360
2024-09-18 21:24:43,749 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:416] - INFO: Optimal reward: 3.8379, 3.8379, 3.3243
Known param reward: [[3.8379180431365967, 3.442539930343628, 3.28834867477417], [3.442539930343628, 3.8379180431365967, 3.1252236366271973], [3.802189826965332, 3.574620246887207, 3.324342966079712]], Known param reward error: [[0.0, 0.10301890461158467, 0.010827490326002337], [0.10301890461158467, 0.0, 0.05989734858414128], [0.00930927022664226, 0.06860433007949422, 0.0]].
