2024-09-18 21:23:40,402 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log_dpo/2024_09_18_21_18_57/swapped_noise0.9_[1,0.9,1]_2026
2024-09-18 21:23:40,404 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2026
2024-09-18 21:23:40,404 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-09-18 21:23:40,562 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.3801, l2 distance: 24.0384, acc: 0.83.
2024-09-18 21:23:40,563 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-18 21:23:40,563 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [11.01885555  4.26191254 10.61306472  7.05320076]
2024-09-18 21:23:40,769 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.5336, 3.8034, 3.1353
2024-09-18 21:23:42,213 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:947] - INFO: Iteration:  0, train_loss:  18.4383, val_loss:  19.0966, grad_norm: 0.7686, reward_err: 0.0641, 0.0304, 0.0306, KL_dist: 0.2051, 0.1006, 0.1229, param: [4.204273   1.99842072 2.90421553 3.381817  ]train_grp_loss: [21.56161594 13.54884139 21.23132825], val_grp_loss: [21.76254542 15.63929163 21.1692636 ], train_hist_grp_loss: [21.597599   13.64318591 21.27040756], cur_train_grp_loss: [21.597599   13.64318591 21.27040756],max_reward_err:  0.0641, max_reward_err_index: 0, max_kl_dist:  0.2051, max_kl_dist_index: 0, max_train_grp_loss:  21.5616, max_train_grp_loss_index: 0, max_val_grp_loss:  21.7625, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  21.5976, max_cur_train_grp_loss_index: 0, 
2024-09-18 21:23:45,447 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:1040] - INFO: Iteration:  99, train_loss:  15.4665, val_loss:  16.1070, grad_norm: 0.3708, reward_err: 0.0709, 0.0100, 0.0341, KL_dist: 0.7563, 0.4133, 0.5854, param: [7.5925022  3.28076444 6.43537894 4.96766081]train_grp_loss: [19.54422932  9.18660692 18.85923953], val_grp_loss: [19.98234317 11.28536489 18.61373758], train_hist_grp_loss: [2037.13412472 1083.04194336 1986.92341217], cur_train_grp_loss: [19.55459191  9.20427498 18.87307182],max_reward_err:  0.0709, max_reward_err_index: 0, max_kl_dist:  0.7563, max_kl_dist_index: 0, max_train_grp_loss:  19.5442, max_train_grp_loss_index: 0, max_val_grp_loss:  19.9823, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  19.5546, max_cur_train_grp_loss_index: 0, 
2024-09-18 21:23:45,673 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:387] - INFO: Policy parameter learned solely on the preference data dpo: [7.5925022  3.28076444 6.43537894 4.96766081].
2024-09-18 21:23:46,007 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Uniform reward: 3.7897, 3.7897, 3.1396
2024-09-18 21:23:46,008 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Optimal reward: 3.8304, 3.8304, 3.2622
2024-09-18 21:23:46,009 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Policy reward: 3.5589, 3.7922, 3.1508
2024-09-18 21:23:46,009 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Reward Error: 0.0709, 0.0100, 0.0341
2024-09-18 21:23:46,681 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:416] - INFO: Optimal reward: 3.8304, 3.8304, 3.2622
Known param reward: [[3.8303539752960205, 3.4527127742767334, 3.2332265377044678], [3.4527127742767334, 3.8303539752960205, 3.0769858360290527], [3.7932167053222656, 3.5765700340270996, 3.2621729373931885]], Known param reward error: [[0.0, 0.09859172375579256, 0.008873349219754073], [0.09859172375579256, 0.0, 0.056768020861616024], [0.009695519059928348, 0.06625600216212596, 0.0]].
