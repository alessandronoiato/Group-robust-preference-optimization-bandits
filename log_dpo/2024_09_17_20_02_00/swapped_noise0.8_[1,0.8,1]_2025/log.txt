2024-09-17 20:03:18,974 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:198] - INFO: Logging to log_dpo/2024_09_17_20_02_00/swapped_noise0.8_[1,0.8,1]_2025
2024-09-17 20:03:18,976 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: (IB) Seed: 2025
2024-09-17 20:03:18,977 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Data: 300
2024-09-17 20:03:19,134 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:296] - INFO: MLE reward loss: 0.3985, l2 distance: 24.2772, acc: 0.81.
2024-09-17 20:03:19,135 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-17 20:03:19,136 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: MLE reward parameter: [10.86841933  4.80239218 11.99051813  3.51685172]
2024-09-17 20:03:19,337 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:313] - INFO: Learned oracle reward: 3.4933, 3.8668, 3.1227
2024-09-17 20:03:20,633 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:947] - INFO: Iteration:  0, train_loss:  20.5184, val_loss:  20.1611, grad_norm: 0.8241, reward_err: 0.0210, 0.0692, 0.0073, KL_dist: 0.1052, 0.2697, 0.0817, param: [1.7227938  4.62462011 3.41640224 3.1346246 ]train_grp_loss: [21.45388877 19.41098371 20.89824686], val_grp_loss: [21.47066734 17.94020484 20.99804846], train_hist_grp_loss: [21.46246065 19.55933438 20.92975139], cur_train_grp_loss: [21.46246065 19.55933438 20.92975139],max_reward_err:  0.0692, max_reward_err_index: 1, max_kl_dist:  0.2697, max_kl_dist_index: 1, max_train_grp_loss:  21.4539, max_train_grp_loss_index: 0, max_val_grp_loss:  21.4707, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  21.4625, max_cur_train_grp_loss_index: 0, 
2024-09-17 20:03:23,711 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:1040] - INFO: Iteration:  99, train_loss:  16.6218, val_loss:  17.2656, grad_norm: 0.4585, reward_err: 0.0839, 0.0089, 0.0467, KL_dist: 0.7951, 0.3630, 0.6013, param: [6.0207362  4.64029971 7.69588349 2.26005429]train_grp_loss: [20.9481634  11.1728506  18.75392256], val_grp_loss: [21.3352591  11.28346346 19.03667691], train_hist_grp_loss: [2116.04544307 1453.50487303 1971.17902002], cur_train_grp_loss: [20.95096873 11.2145123  18.76843181],max_reward_err:  0.0839, max_reward_err_index: 0, max_kl_dist:  0.7951, max_kl_dist_index: 0, max_train_grp_loss:  20.9482, max_train_grp_loss_index: 0, max_val_grp_loss:  21.3353, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  20.9510, max_cur_train_grp_loss_index: 0, 
2024-09-17 20:03:23,927 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:386] - INFO: Policy parameter learned solely on the preference data dpo: [6.0207362  4.64029971 7.69588349 2.26005429].
2024-09-17 20:03:24,253 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:397] - INFO: Uniform reward: 3.8283, 3.8283, 3.1728
2024-09-17 20:03:24,253 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Optimal reward: 3.8685, 3.8685, 3.3122
2024-09-17 20:03:24,254 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Policy reward: 3.5438, 3.8340, 3.1574
2024-09-17 20:03:24,254 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Reward Error: 0.0839, 0.0089, 0.0467
2024-09-17 20:03:24,921 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:415] - INFO: Optimal reward: 3.8685, 3.8685, 3.3122
Known param reward: [[3.8684823513031006, 3.4799795150756836, 3.271944284439087], [3.4799795150756836, 3.8684823513031006, 3.1135053634643555], [3.832144021987915, 3.6156766414642334, 3.312178611755371]], Known param reward error: [[0.0, 0.10042771323398944, 0.012147390594663916], [0.10042771323398944, 0.0, 0.059982649361328924], [0.009393432880195242, 0.06535010034457296, 0.0]].
