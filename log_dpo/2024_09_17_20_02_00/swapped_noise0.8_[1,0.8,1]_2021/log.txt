2024-09-17 20:02:04,767 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:198] - INFO: Logging to log_dpo/2024_09_17_20_02_00/swapped_noise0.8_[1,0.8,1]_2021
2024-09-17 20:02:04,769 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: (IB) Seed: 2021
2024-09-17 20:02:04,769 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Data: 300
2024-09-17 20:02:04,930 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:296] - INFO: MLE reward loss: 0.4323, l2 distance: 20.8234, acc: 0.81.
2024-09-17 20:02:04,931 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-17 20:02:04,931 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: MLE reward parameter: [ 6.19093621  5.23578827 12.25371113  4.32454036]
2024-09-17 20:02:05,137 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:313] - INFO: Learned oracle reward: 3.4904, 3.8706, 3.1036
2024-09-17 20:02:06,417 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:947] - INFO: Iteration:  0, train_loss:  20.0522, val_loss:  19.8394, grad_norm: 0.6415, reward_err: 0.0250, 0.0802, 0.0097, KL_dist: 0.1033, 0.2825, 0.0855, param: [3.33122201 5.00023768 1.93491959 2.96461948]train_grp_loss: [21.2666119  17.8449059  21.21359221], val_grp_loss: [21.63024957 16.75136627 21.15491972], train_hist_grp_loss: [21.28574132 17.91732757 21.24301955], cur_train_grp_loss: [21.28574132 17.91732757 21.24301955],max_reward_err:  0.0802, max_reward_err_index: 1, max_kl_dist:  0.2825, max_kl_dist_index: 1, max_train_grp_loss:  21.2666, max_train_grp_loss_index: 0, max_val_grp_loss:  21.6302, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  21.2857, max_cur_train_grp_loss_index: 0, 
2024-09-17 20:02:09,498 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:1040] - INFO: Iteration:  99, train_loss:  17.5348, val_loss:  17.2855, grad_norm: 0.3858, reward_err: 0.0599, 0.0225, 0.0252, KL_dist: 0.5313, 0.3568, 0.4081, param: [5.71314016 5.21556596 6.22755652 3.48079474]train_grp_loss: [20.11163481 13.55026863 19.22619361], val_grp_loss: [20.93849028 11.67218822 19.27033738], train_hist_grp_loss: [2060.07717809 1535.89991364 2011.12473223], cur_train_grp_loss: [20.11819548 13.57438596 19.23952623],max_reward_err:  0.0599, max_reward_err_index: 0, max_kl_dist:  0.5313, max_kl_dist_index: 0, max_train_grp_loss:  20.1116, max_train_grp_loss_index: 0, max_val_grp_loss:  20.9385, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  20.1182, max_cur_train_grp_loss_index: 0, 
2024-09-17 20:02:09,717 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:386] - INFO: Policy parameter learned solely on the preference data dpo: [5.71314016 5.21556596 6.22755652 3.48079474].
2024-09-17 20:02:10,047 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:397] - INFO: Uniform reward: 3.8512, 3.8512, 3.2031
2024-09-17 20:02:10,048 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Optimal reward: 3.8864, 3.8864, 3.3152
2024-09-17 20:02:10,048 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Policy reward: 3.6534, 3.7991, 3.2317
2024-09-17 20:02:10,049 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Reward Error: 0.0599, 0.0225, 0.0252
2024-09-17 20:02:10,732 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:415] - INFO: Optimal reward: 3.8864, 3.8864, 3.3152
Known param reward: [[3.8863613605499268, 3.458714246749878, 3.291393280029297], [3.458714246749878, 3.8863613605499268, 3.0966663360595703], [3.851715087890625, 3.5921897888183594, 3.315164804458618]], Known param reward error: [[0.0, 0.11003791828033614, 0.007170540781969749], [0.11003791828033614, 0.0, 0.06590878019252189], [0.008914835612301181, 0.07569331424444319, 0.0]].
