2024-09-17 20:03:01,189 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:198] - INFO: Logging to log_dpo/2024_09_17_20_02_00/swapped_noise0.8_[1,0.8,1]_2024
2024-09-17 20:03:01,191 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: (IB) Seed: 2024
2024-09-17 20:03:01,191 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Data: 300
2024-09-17 20:03:01,355 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:296] - INFO: MLE reward loss: 0.3901, l2 distance: 29.9953, acc: 0.82.
2024-09-17 20:03:01,356 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-17 20:03:01,356 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: MLE reward parameter: [13.0897178   7.38539327 12.98844152  6.48402242]
2024-09-17 20:03:01,562 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:313] - INFO: Learned oracle reward: 3.6340, 3.9123, 3.3016
2024-09-17 20:03:02,866 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:947] - INFO: Iteration:  0, train_loss:  19.6371, val_loss:  19.5043, grad_norm: 0.7098, reward_err: 0.0668, 0.0383, 0.0316, KL_dist: 0.2608, 0.1486, 0.1600, param: [3.44493898 1.31851745 4.41067571 4.0250569 ]train_grp_loss: [21.46070933 15.54740125 21.31890822], val_grp_loss: [21.90352052 15.25661744 21.14433958], train_hist_grp_loss: [21.49276008 15.64088894 21.35017894], cur_train_grp_loss: [21.49276008 15.64088894 21.35017894],max_reward_err:  0.0668, max_reward_err_index: 0, max_kl_dist:  0.2608, max_kl_dist_index: 0, max_train_grp_loss:  21.4607, max_train_grp_loss_index: 0, max_val_grp_loss:  21.9035, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  21.4928, max_cur_train_grp_loss_index: 0, 
2024-09-17 20:03:05,909 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:1040] - INFO: Iteration:  99, train_loss:  16.8558, val_loss:  16.9443, grad_norm: 0.3813, reward_err: 0.0745, 0.0113, 0.0357, KL_dist: 0.7663, 0.3894, 0.5876, param: [6.53215219 4.06281444 7.49381624 4.30819786]train_grp_loss: [19.43576693 11.03986467 19.26099583], val_grp_loss: [20.31096067 11.35985033 18.89051746], train_hist_grp_loss: [2031.16650038 1275.93945271 2016.71529268], cur_train_grp_loss: [19.44811627 11.05826562 19.27429408],max_reward_err:  0.0745, max_reward_err_index: 0, max_kl_dist:  0.7663, max_kl_dist_index: 0, max_train_grp_loss:  19.4358, max_train_grp_loss_index: 0, max_val_grp_loss:  20.3110, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  19.4481, max_cur_train_grp_loss_index: 0, 
2024-09-17 20:03:06,127 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:386] - INFO: Policy parameter learned solely on the preference data dpo: [6.53215219 4.06281444 7.49381624 4.30819786].
2024-09-17 20:03:06,446 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:397] - INFO: Uniform reward: 3.8988, 3.8988, 3.2898
2024-09-17 20:03:06,447 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Optimal reward: 3.9394, 3.9394, 3.4305
2024-09-17 20:03:06,448 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Policy reward: 3.6457, 3.8948, 3.3079
2024-09-17 20:03:06,448 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Reward Error: 0.0745, 0.0113, 0.0357
2024-09-17 20:03:07,123 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:415] - INFO: Optimal reward: 3.9394, 3.9394, 3.4305
Known param reward: [[3.939390182495117, 3.527578830718994, 3.3940188884735107], [3.527578830718994, 3.939390182495117, 3.225066661834717], [3.8967127799987793, 3.6586339473724365, 3.4304511547088623]], Known param reward error: [[0.0, 0.10453682745264177, 0.010620255060429077], [0.10453682745264177, 0.0, 0.059870985946621415], [0.010833504811474914, 0.07126895842159414, 0.0]].
