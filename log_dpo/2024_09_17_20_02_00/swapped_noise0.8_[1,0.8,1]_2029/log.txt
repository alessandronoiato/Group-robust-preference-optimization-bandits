2024-09-17 20:04:34,348 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:198] - INFO: Logging to log_dpo/2024_09_17_20_02_00/swapped_noise0.8_[1,0.8,1]_2029
2024-09-17 20:04:34,350 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: (IB) Seed: 2029
2024-09-17 20:04:34,351 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Data: 300
2024-09-17 20:04:34,510 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:296] - INFO: MLE reward loss: 0.4258, l2 distance: 19.9334, acc: 0.82.
2024-09-17 20:04:34,511 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-17 20:04:34,512 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: MLE reward parameter: [ 6.68259565  4.92300711 10.70711077  6.60526297]
2024-09-17 20:04:34,709 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:313] - INFO: Learned oracle reward: 3.5992, 3.8198, 3.2522
2024-09-17 20:04:35,996 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:947] - INFO: Iteration:  0, train_loss:  18.9171, val_loss:  19.9076, grad_norm: 0.6551, reward_err: 0.0411, 0.0493, 0.0145, KL_dist: 0.1571, 0.1921, 0.0992, param: [2.82899551 3.09268904 3.72523362 3.97984398]train_grp_loss: [21.5883503  15.11135352 20.66228229], val_grp_loss: [21.4565479  16.72998291 21.21521999], train_hist_grp_loss: [21.60874573 15.18215338 20.69479662], cur_train_grp_loss: [21.60874573 15.18215338 20.69479662],max_reward_err:  0.0493, max_reward_err_index: 1, max_kl_dist:  0.1921, max_kl_dist_index: 1, max_train_grp_loss:  21.5884, max_train_grp_loss_index: 0, max_val_grp_loss:  21.4565, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  21.6087, max_cur_train_grp_loss_index: 0, 
2024-09-17 20:04:39,507 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:1040] - INFO: Iteration:  99, train_loss:  16.6842, val_loss:  17.8107, grad_norm: 0.3288, reward_err: 0.0656, 0.0366, 0.0314, KL_dist: 0.6326, 0.4567, 0.4947, param: [5.15525971 3.36462671 7.11189279 6.0455244 ]train_grp_loss: [20.42167173 11.8496948  18.56422749], val_grp_loss: [20.09976371 13.41087242 19.47866092], train_hist_grp_loss: [2090.36013842 1306.82864666 1948.13924561], cur_train_grp_loss: [20.42777499 11.86226253 18.5775239 ],max_reward_err:  0.0656, max_reward_err_index: 0, max_kl_dist:  0.6326, max_kl_dist_index: 0, max_train_grp_loss:  20.4217, max_train_grp_loss_index: 0, max_val_grp_loss:  20.0998, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  20.4278, max_cur_train_grp_loss_index: 0, 
2024-09-17 20:04:39,735 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:386] - INFO: Policy parameter learned solely on the preference data dpo: [5.15525971 3.36462671 7.11189279 6.0455244 ].
2024-09-17 20:04:40,079 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:397] - INFO: Uniform reward: 3.8490, 3.8490, 3.2390
2024-09-17 20:04:40,080 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Optimal reward: 3.8955, 3.8955, 3.3866
2024-09-17 20:04:40,081 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Policy reward: 3.6400, 3.7529, 3.2803
2024-09-17 20:04:40,081 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Reward Error: 0.0656, 0.0366, 0.0314
2024-09-17 20:04:40,786 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:415] - INFO: Optimal reward: 3.8955, 3.8955, 3.3866
Known param reward: [[3.895524024963379, 3.484661340713501, 3.3502304553985596], [3.484661340713501, 3.895524024963379, 3.1791486740112305], [3.8603501319885254, 3.6147823333740234, 3.3865811824798584]], Known param reward error: [[0.0, 0.10547045317060787, 0.010733753340789734], [0.10547045317060787, 0.0, 0.06125130250583078], [0.009029309728152473, 0.07206776027828365, 0.0]].
