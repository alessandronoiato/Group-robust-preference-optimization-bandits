2024-09-17 16:52:37,314 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:198] - INFO: Logging to log_dpo/2024_09_17_16_51_39/swapped_noise0.9_[0.9,0.9,0.9]_2024
2024-09-17 16:52:37,316 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: (IB) Seed: 2024
2024-09-17 16:52:37,316 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Data: 300
2024-09-17 16:52:37,479 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:296] - INFO: MLE reward loss: 0.4066, l2 distance: 28.7373, acc: 0.81.
2024-09-17 16:52:37,480 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-17 16:52:37,481 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: MLE reward parameter: [14.24027005  6.3970464   9.82226597  8.22786162]
2024-09-17 16:52:37,686 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:313] - INFO: Learned oracle reward: 3.6310, 3.8990, 3.2923
2024-09-17 16:52:38,946 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:947] - INFO: Iteration:  0, train_loss:  19.4771, val_loss:  19.3283, grad_norm: 0.6289, reward_err: 0.0536, 0.0384, 0.0217, KL_dist: 0.2815, 0.2061, 0.1912, param: [4.75997981 4.36928145 3.59650179 2.72476418]train_grp_loss: [21.31195161 15.77996617 20.81124294], val_grp_loss: [21.34648186 15.40209353 21.12639215], train_hist_grp_loss: [21.3304266  15.86111759 20.83589129], cur_train_grp_loss: [21.3304266  15.86111759 20.83589129],max_reward_err:  0.0536, max_reward_err_index: 0, max_kl_dist:  0.2815, max_kl_dist_index: 0, max_train_grp_loss:  21.3120, max_train_grp_loss_index: 0, max_val_grp_loss:  21.3465, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  21.3304, max_cur_train_grp_loss_index: 0, 
2024-09-17 16:52:41,952 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:1040] - INFO: Iteration:  99, train_loss:  17.1091, val_loss:  17.1885, grad_norm: 0.3706, reward_err: 0.0734, 0.0154, 0.0356, KL_dist: 0.8073, 0.4493, 0.6353, param: [8.15827999 4.31268021 6.06213138 5.02044009]train_grp_loss: [20.02729355 11.42706632 19.06112862], val_grp_loss: [20.21258164 11.6663165  19.53372151], train_hist_grp_loss: [2060.57842257 1317.41752811 1985.549703  ], cur_train_grp_loss: [20.03619406 11.4478817  19.07353759],max_reward_err:  0.0734, max_reward_err_index: 0, max_kl_dist:  0.8073, max_kl_dist_index: 0, max_train_grp_loss:  20.0273, max_train_grp_loss_index: 0, max_val_grp_loss:  20.2126, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  20.0362, max_cur_train_grp_loss_index: 0, 
2024-09-17 16:52:42,167 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:386] - INFO: Policy parameter learned solely on the preference data dpo: [8.15827999 4.31268021 6.06213138 5.02044009].
2024-09-17 16:52:42,490 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:397] - INFO: Uniform reward: 3.9048, 3.9048, 3.2946
2024-09-17 16:52:42,490 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Optimal reward: 3.9454, 3.9454, 3.4341
2024-09-17 16:52:42,491 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Policy reward: 3.6559, 3.8845, 3.3118
2024-09-17 16:52:42,491 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Reward Error: 0.0734, 0.0154, 0.0356
2024-09-17 16:52:43,154 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:415] - INFO: Optimal reward: 3.9454, 3.9454, 3.4341
Known param reward: [[3.945406436920166, 3.5262372493743896, 3.3988354206085205], [3.5262372493743896, 3.945406436920166, 3.223421812057495], [3.903231143951416, 3.661907434463501, 3.434112548828125]], Known param reward error: [[0.0, 0.10624233377410544, 0.010272560295568254], [0.10624233377410544, 0.0, 0.06135230973793422], [0.010689720727903654, 0.07185546203903087, 0.0]].
