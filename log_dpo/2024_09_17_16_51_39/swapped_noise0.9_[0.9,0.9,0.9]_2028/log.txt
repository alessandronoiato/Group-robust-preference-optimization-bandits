2024-09-17 16:53:50,225 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:198] - INFO: Logging to log_dpo/2024_09_17_16_51_39/swapped_noise0.9_[0.9,0.9,0.9]_2028
2024-09-17 16:53:50,226 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: (IB) Seed: 2028
2024-09-17 16:53:50,227 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Data: 300
2024-09-17 16:53:50,389 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:296] - INFO: MLE reward loss: 0.4741, l2 distance: 19.2396, acc: 0.79.
2024-09-17 16:53:50,390 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-17 16:53:50,391 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: MLE reward parameter: [8.42647805 5.36700919 9.64277876 4.57490743]
2024-09-17 16:53:50,592 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:313] - INFO: Learned oracle reward: 3.5174, 3.8014, 3.1298
2024-09-17 16:53:51,859 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:947] - INFO: Iteration:  0, train_loss:  19.4607, val_loss:  18.4998, grad_norm: 0.5016, reward_err: 0.0501, 0.0234, 0.0197, KL_dist: 0.3475, 0.2385, 0.2463, param: [4.48715729 4.25227734 4.8681691  3.32340851]train_grp_loss: [21.58890923 14.98945003 21.09960844], val_grp_loss: [20.80440848 13.74766375 20.64013851], train_hist_grp_loss: [21.59354893 15.05025587 21.11611737], cur_train_grp_loss: [21.59354893 15.05025587 21.11611737],max_reward_err:  0.0501, max_reward_err_index: 0, max_kl_dist:  0.3475, max_kl_dist_index: 0, max_train_grp_loss:  21.5889, max_train_grp_loss_index: 0, max_val_grp_loss:  20.8044, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  21.5935, max_cur_train_grp_loss_index: 0, 
2024-09-17 16:53:54,894 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:1040] - INFO: Iteration:  99, train_loss:  17.9397, val_loss:  16.8203, grad_norm: 0.2950, reward_err: 0.0789, 0.0069, 0.0416, KL_dist: 0.8486, 0.4472, 0.6566, param: [7.00969986 4.69251027 7.72482499 3.50290713]train_grp_loss: [21.29230772 11.48986349 19.93443892], val_grp_loss: [20.0644355  10.28667234 19.68098385], train_hist_grp_loss: [2142.16845881 1293.57012663 2046.22512214], cur_train_grp_loss: [21.29418799 11.50800134 19.94265893],max_reward_err:  0.0789, max_reward_err_index: 0, max_kl_dist:  0.8486, max_kl_dist_index: 0, max_train_grp_loss:  21.2923, max_train_grp_loss_index: 0, max_val_grp_loss:  20.0644, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  21.2942, max_cur_train_grp_loss_index: 0, 
2024-09-17 16:53:55,109 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:386] - INFO: Policy parameter learned solely on the preference data dpo: [7.00969986 4.69251027 7.72482499 3.50290713].
2024-09-17 16:53:55,428 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:397] - INFO: Uniform reward: 3.7831, 3.7831, 3.1349
2024-09-17 16:53:55,429 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Optimal reward: 3.8247, 3.8247, 3.2704
2024-09-17 16:53:55,429 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Policy reward: 3.5230, 3.7983, 3.1343
2024-09-17 16:53:55,430 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Reward Error: 0.0789, 0.0069, 0.0416
2024-09-17 16:53:56,089 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:415] - INFO: Optimal reward: 3.8247, 3.8247, 3.2704
Known param reward: [[3.824658155441284, 3.426182508468628, 3.241102933883667], [3.426182508468628, 3.824658155441284, 3.0655112266540527], [3.789510726928711, 3.5579817295074463, 3.270369529724121]], Known param reward error: [[0.0, 0.10418595094721103, 0.008949018015992507], [0.10418595094721103, 0.0, 0.06264072032476085], [0.009189691492446068, 0.06972555849323195, 0.0]].
