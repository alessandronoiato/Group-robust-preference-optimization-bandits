2024-09-17 16:53:13,729 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:198] - INFO: Logging to log_dpo/2024_09_17_16_51_39/swapped_noise0.9_[0.9,0.9,0.9]_2026
2024-09-17 16:53:13,731 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: (IB) Seed: 2026
2024-09-17 16:53:13,732 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Data: 300
2024-09-17 16:53:13,896 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:296] - INFO: MLE reward loss: 0.3836, l2 distance: 29.1451, acc: 0.82.
2024-09-17 16:53:13,897 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-17 16:53:13,898 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: MLE reward parameter: [10.80791185  8.65766294 13.38592939  7.07766337]
2024-09-17 16:53:14,100 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:313] - INFO: Learned oracle reward: 3.6124, 3.8313, 3.2472
2024-09-17 16:53:15,370 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:947] - INFO: Iteration:  0, train_loss:  19.3514, val_loss:  19.8077, grad_norm: 0.6931, reward_err: 0.0600, 0.0491, 0.0364, KL_dist: 0.1997, 0.1942, 0.1464, param: [1.65901379 4.28460218 4.56668064 2.5336649 ]train_grp_loss: [21.55310248 15.19365    21.35926515], val_grp_loss: [21.74179624 16.18422059 21.28971986], train_hist_grp_loss: [21.57618411 15.2842449  21.3890143 ], cur_train_grp_loss: [21.57618411 15.2842449  21.3890143 ],max_reward_err:  0.0600, max_reward_err_index: 0, max_kl_dist:  0.1997, max_kl_dist_index: 0, max_train_grp_loss:  21.5531, max_train_grp_loss_index: 0, max_val_grp_loss:  21.7418, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  21.5762, max_cur_train_grp_loss_index: 0, 
2024-09-17 16:53:18,392 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:1040] - INFO: Iteration:  99, train_loss:  16.5492, val_loss:  16.9158, grad_norm: 0.3916, reward_err: 0.0733, 0.0149, 0.0421, KL_dist: 0.7238, 0.4243, 0.5703, param: [5.13150057 5.35811444 8.06595929 3.80348838]train_grp_loss: [20.12850039 10.18564502 19.38842256], val_grp_loss: [20.15428819 11.21243745 19.04544738], train_hist_grp_loss: [2073.75857358 1222.12457143 2025.80571956], cur_train_grp_loss: [20.13683525 10.21048816 19.40121659],max_reward_err:  0.0733, max_reward_err_index: 0, max_kl_dist:  0.7238, max_kl_dist_index: 0, max_train_grp_loss:  20.1285, max_train_grp_loss_index: 0, max_val_grp_loss:  20.1543, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  20.1368, max_cur_train_grp_loss_index: 0, 
2024-09-17 16:53:18,607 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:386] - INFO: Policy parameter learned solely on the preference data dpo: [5.13150057 5.35811444 8.06595929 3.80348838].
2024-09-17 16:53:18,925 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:397] - INFO: Uniform reward: 3.8338, 3.8338, 3.2190
2024-09-17 16:53:18,926 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Optimal reward: 3.8731, 3.8731, 3.3639
2024-09-17 16:53:18,927 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Policy reward: 3.5891, 3.8155, 3.2222
2024-09-17 16:53:18,927 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Reward Error: 0.0733, 0.0149, 0.0421
2024-09-17 16:53:19,592 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:415] - INFO: Optimal reward: 3.8731, 3.8731, 3.3639
Known param reward: [[3.873142719268799, 3.4625096321105957, 3.3238730430603027], [3.4625096321105957, 3.873142719268799, 3.1438493728637695], [3.8371264934539795, 3.6077330112457275, 3.363903284072876]], Known param reward error: [[0.0, 0.10602064445374364, 0.011899938146885801], [0.10602064445374364, 0.0, 0.06541624197431568], [0.009298966866271003, 0.0685256721118651, 0.0]].
