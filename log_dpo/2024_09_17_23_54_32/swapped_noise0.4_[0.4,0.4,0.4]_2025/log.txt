2024-09-17 23:55:49,768 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:198] - INFO: Logging to log_dpo/2024_09_17_23_54_32/swapped_noise0.4_[0.4,0.4,0.4]_2025
2024-09-17 23:55:49,770 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: (IB) Seed: 2025
2024-09-17 23:55:49,770 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Data: 300
2024-09-17 23:55:49,934 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:296] - INFO: MLE reward loss: 0.5644, l2 distance: 7.1605, acc: 0.70.
2024-09-17 23:55:49,935 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-17 23:55:49,936 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: MLE reward parameter: [4.16061983 3.00918294 4.66723627 1.95463813]
2024-09-17 23:55:50,145 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:313] - INFO: Learned oracle reward: 3.6139, 3.8500, 3.2304
2024-09-17 23:55:51,436 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:947] - INFO: Iteration:  0, train_loss:  21.0403, val_loss:  21.5683, grad_norm: 0.4267, reward_err: 0.0294, 0.0493, 0.0067, KL_dist: 0.1288, 0.1954, 0.0783, param: [2.6808969  4.08033535 3.3584043  2.8539697 ]train_grp_loss: [22.90511414 18.0289567  22.71757159], val_grp_loss: [23.63342485 18.01768037 23.17381454], train_hist_grp_loss: [22.90700397 18.06670215 22.72870917], cur_train_grp_loss: [22.90700397 18.06670215 22.72870917],max_reward_err:  0.0493, max_reward_err_index: 1, max_kl_dist:  0.1954, max_kl_dist_index: 1, max_train_grp_loss:  22.9051, max_train_grp_loss_index: 0, max_val_grp_loss:  23.6334, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  22.9070, max_cur_train_grp_loss_index: 0, 
2024-09-17 23:55:54,563 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:1040] - INFO: Iteration:  99, train_loss:  20.0258, val_loss:  20.5903, grad_norm: 0.2278, reward_err: 0.0566, 0.0206, 0.0240, KL_dist: 0.4541, 0.2644, 0.3277, param: [4.88224609 4.43661178 5.53035887 3.10222514]train_grp_loss: [22.8938491  15.91572551 22.00873283], val_grp_loss: [23.61833368 15.59025742 22.73769966], train_hist_grp_loss: [2287.81784892 1678.18700628 2231.64124353], cur_train_grp_loss: [22.89298621 15.92659503 22.01310996],max_reward_err:  0.0566, max_reward_err_index: 0, max_kl_dist:  0.4541, max_kl_dist_index: 0, max_train_grp_loss:  22.8938, max_train_grp_loss_index: 0, max_val_grp_loss:  23.6183, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  22.8930, max_cur_train_grp_loss_index: 0, 
2024-09-17 23:55:54,792 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:386] - INFO: Policy parameter learned solely on the preference data dpo: [4.88224609 4.43661178 5.53035887 3.10222514].
2024-09-17 23:55:55,124 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:397] - INFO: Uniform reward: 3.8477, 3.8477, 3.2022
2024-09-17 23:55:55,125 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Optimal reward: 3.8884, 3.8884, 3.3468
2024-09-17 23:55:55,126 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Policy reward: 3.6684, 3.8084, 3.2666
2024-09-17 23:55:55,126 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Reward Error: 0.0566, 0.0206, 0.0240
2024-09-17 23:55:55,820 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:415] - INFO: Optimal reward: 3.8884, 3.8884, 3.3468
Known param reward: [[3.8883774280548096, 3.499903678894043, 3.3037302494049072], [3.499903678894043, 3.8883774280548096, 3.1488685607910156], [3.8492772579193115, 3.6396799087524414, 3.346843719482422]], Known param reward error: [[0.0, 0.09990638932268042, 0.012881829476095764], [0.09990638932268042, 0.0, 0.05915279447885975], [0.010055651967679024, 0.06395920249613757, 0.0]].
