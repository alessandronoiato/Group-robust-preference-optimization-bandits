2024-09-17 23:55:31,165 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:198] - INFO: Logging to log_dpo/2024_09_17_23_54_32/swapped_noise0.4_[0.4,0.4,0.4]_2024
2024-09-17 23:55:31,167 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: (IB) Seed: 2024
2024-09-17 23:55:31,168 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Data: 300
2024-09-17 23:55:31,336 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:296] - INFO: MLE reward loss: 0.6096, l2 distance: 4.5804, acc: 0.66.
2024-09-17 23:55:31,340 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-17 23:55:31,344 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: MLE reward parameter: [3.43667079 3.05372886 2.69231502 2.26156934]
2024-09-17 23:55:31,549 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:313] - INFO: Learned oracle reward: 3.7110, 3.7675, 3.3133
2024-09-17 23:55:32,827 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:947] - INFO: Iteration:  0, train_loss:  23.2732, val_loss:  22.9849, grad_norm: 0.5182, reward_err: 0.0472, 0.0567, 0.0175, KL_dist: 0.0728, 0.0682, 0.0294, param: [1.2892365  1.95640045 1.79086921 0.80396894]train_grp_loss: [24.24010108 20.87288896 24.36373308], val_grp_loss: [24.20491925 20.65653312 24.0585368 ], train_hist_grp_loss: [24.25547846 20.92983312 24.37595688], cur_train_grp_loss: [24.25547846 20.92983312 24.37595688],max_reward_err:  0.0567, max_reward_err_index: 1, max_kl_dist:  0.0728, max_kl_dist_index: 0, max_train_grp_loss:  24.3637, max_train_grp_loss_index: 2, max_val_grp_loss:  24.2049, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  24.3760, max_cur_train_grp_loss_index: 2, 
2024-09-17 23:55:35,923 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:1040] - INFO: Iteration:  99, train_loss:  21.9116, val_loss:  21.3834, grad_norm: 0.2503, reward_err: 0.0316, 0.0488, 0.0068, KL_dist: 0.1243, 0.1771, 0.0726, param: [3.07155441 3.99758978 3.10159182 2.76408564]train_grp_loss: [23.29310104 18.28578397 23.63779872], val_grp_loss: [23.24850281 17.74511458 23.10222869], train_hist_grp_loss: [2369.82819989 1924.28267005 2394.3082398 ], cur_train_grp_loss: [23.29868024 18.29538487 23.64182813],max_reward_err:  0.0488, max_reward_err_index: 1, max_kl_dist:  0.1771, max_kl_dist_index: 1, max_train_grp_loss:  23.6378, max_train_grp_loss_index: 2, max_val_grp_loss:  23.2485, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  23.6418, max_cur_train_grp_loss_index: 2, 
2024-09-17 23:55:36,142 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:386] - INFO: Policy parameter learned solely on the preference data dpo: [3.07155441 3.99758978 3.10159182 2.76408564].
2024-09-17 23:55:36,473 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:397] - INFO: Uniform reward: 3.8650, 3.8650, 3.2436
2024-09-17 23:55:36,474 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Optimal reward: 3.9035, 3.9035, 3.3772
2024-09-17 23:55:36,474 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Policy reward: 3.7801, 3.7129, 3.3540
2024-09-17 23:55:36,475 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Reward Error: 0.0316, 0.0488, 0.0068
2024-09-17 23:55:37,150 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:415] - INFO: Optimal reward: 3.9035, 3.9035, 3.3772
Known param reward: [[3.903468370437622, 3.4978456497192383, 3.3427646160125732], [3.4978456497192383, 3.903468370437622, 3.172839879989624], [3.863295316696167, 3.63002347946167, 3.377150297164917]], Known param reward error: [[0.0, 0.10391341295098261, 0.010181862850821349], [0.10391341295098261, 0.0, 0.06049787518986332], [0.010291630398673176, 0.07005177576097432, 0.0]].
