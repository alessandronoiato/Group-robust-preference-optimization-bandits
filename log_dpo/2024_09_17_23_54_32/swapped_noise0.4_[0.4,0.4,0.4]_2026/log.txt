2024-09-17 23:56:09,300 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:198] - INFO: Logging to log_dpo/2024_09_17_23_54_32/swapped_noise0.4_[0.4,0.4,0.4]_2026
2024-09-17 23:56:09,302 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: (IB) Seed: 2026
2024-09-17 23:56:09,303 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Data: 300
2024-09-17 23:56:09,470 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:296] - INFO: MLE reward loss: 0.6199, l2 distance: 4.9196, acc: 0.62.
2024-09-17 23:56:09,470 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-17 23:56:09,471 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: MLE reward parameter: [3.69886944 1.37782594 2.86087464 2.30933931]
2024-09-17 23:56:09,682 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:313] - INFO: Learned oracle reward: 3.5716, 3.8418, 3.1854
2024-09-17 23:56:10,946 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:947] - INFO: Iteration:  0, train_loss:  22.5248, val_loss:  21.4814, grad_norm: 0.3053, reward_err: 0.0760, 0.0218, 0.0379, KL_dist: 0.1920, 0.0450, 0.1034, param: [2.69300228 1.57814691 3.78138966 2.54678732]train_grp_loss: [23.73362857 19.83141555 24.0683802 ], val_grp_loss: [23.67437872 17.14769616 23.53588451], train_hist_grp_loss: [23.73926726 19.84810999 24.07380434], cur_train_grp_loss: [23.73926726 19.84810999 24.07380434],max_reward_err:  0.0760, max_reward_err_index: 0, max_kl_dist:  0.1920, max_kl_dist_index: 0, max_train_grp_loss:  24.0684, max_train_grp_loss_index: 2, max_val_grp_loss:  23.6744, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  24.0738, max_cur_train_grp_loss_index: 2, 
2024-09-17 23:56:14,063 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:1040] - INFO: Iteration:  99, train_loss:  21.9952, val_loss:  20.6852, grad_norm: 0.1695, reward_err: 0.0730, 0.0220, 0.0346, KL_dist: 0.3448, 0.1442, 0.2270, param: [4.25413286 2.02133068 4.86486618 3.67984909]train_grp_loss: [23.38263072 18.94162289 23.72649958], val_grp_loss: [23.26208238 15.59187077 23.10022019], train_hist_grp_loss: [2353.31830539 1930.0268006  2387.41475205], cur_train_grp_loss: [23.38470095 18.94605265 23.72857157],max_reward_err:  0.0730, max_reward_err_index: 0, max_kl_dist:  0.3448, max_kl_dist_index: 0, max_train_grp_loss:  23.7265, max_train_grp_loss_index: 2, max_val_grp_loss:  23.2621, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  23.7286, max_cur_train_grp_loss_index: 2, 
2024-09-17 23:56:14,290 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:386] - INFO: Policy parameter learned solely on the preference data dpo: [4.25413286 2.02133068 4.86486618 3.67984909].
2024-09-17 23:56:14,625 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:397] - INFO: Uniform reward: 3.8381, 3.8381, 3.1940
2024-09-17 23:56:14,625 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Optimal reward: 3.8761, 3.8761, 3.3159
2024-09-17 23:56:14,626 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Policy reward: 3.5932, 3.7909, 3.2012
2024-09-17 23:56:14,626 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Reward Error: 0.0730, 0.0220, 0.0346
2024-09-17 23:56:15,314 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:415] - INFO: Optimal reward: 3.8761, 3.8761, 3.3159
Known param reward: [[3.8760921955108643, 3.486328125, 3.2829432487487793], [3.486328125, 3.8760921955108643, 3.1273369789123535], [3.833125114440918, 3.6059510707855225, 3.3158624172210693]], Known param reward error: [[0.0, 0.10055593387646287, 0.009927784790262397], [0.10055593387646287, 0.0, 0.05685562746198428], [0.011085154558425894, 0.06969419484866962, 0.0]].
