2024-09-17 23:54:54,348 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:198] - INFO: Logging to log_dpo/2024_09_17_23_54_32/swapped_noise0.4_[0.4,0.4,0.4]_2022
2024-09-17 23:54:54,350 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: (IB) Seed: 2022
2024-09-17 23:54:54,350 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Data: 300
2024-09-17 23:54:54,512 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:296] - INFO: MLE reward loss: 0.5475, l2 distance: 10.3595, acc: 0.71.
2024-09-17 23:54:54,513 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-17 23:54:54,514 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: MLE reward parameter: [5.96863949 2.15703066 5.80559139 2.23504415]
2024-09-17 23:54:54,724 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:313] - INFO: Learned oracle reward: 3.4939, 3.8664, 3.1421
2024-09-17 23:54:55,994 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:947] - INFO: Iteration:  0, train_loss:  21.3332, val_loss:  22.3538, grad_norm: 0.5208, reward_err: 0.0366, 0.0485, 0.0127, KL_dist: 0.1862, 0.2423, 0.1332, param: [2.82565462 4.01174241 4.14246312 3.98374044]train_grp_loss: [23.44574431 17.69505466 22.92682123], val_grp_loss: [23.18060117 21.33139002 22.59658725], train_hist_grp_loss: [23.44561474 17.77234363 22.92995269], cur_train_grp_loss: [23.44561474 17.77234363 22.92995269],max_reward_err:  0.0485, max_reward_err_index: 1, max_kl_dist:  0.2423, max_kl_dist_index: 1, max_train_grp_loss:  23.4457, max_train_grp_loss_index: 0, max_val_grp_loss:  23.1806, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  23.4456, max_cur_train_grp_loss_index: 0, 
2024-09-17 23:54:59,120 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:1040] - INFO: Iteration:  99, train_loss:  19.7477, val_loss:  21.1931, grad_norm: 0.2980, reward_err: 0.0804, 0.0068, 0.0424, KL_dist: 0.6275, 0.2633, 0.4621, param: [5.48549375 3.08543209 6.84721604 3.75756301]train_grp_loss: [23.53220772 13.0824393  22.74875067], val_grp_loss: [23.31185216 18.10762967 22.28781779], train_hist_grp_loss: [2347.9684946  1503.52091295 2282.22703244], cur_train_grp_loss: [23.53097848 13.10897658 22.74968747],max_reward_err:  0.0804, max_reward_err_index: 0, max_kl_dist:  0.6275, max_kl_dist_index: 0, max_train_grp_loss:  23.5322, max_train_grp_loss_index: 0, max_val_grp_loss:  23.3119, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  23.5310, max_cur_train_grp_loss_index: 0, 
2024-09-17 23:54:59,342 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:386] - INFO: Policy parameter learned solely on the preference data dpo: [5.48549375 3.08543209 6.84721604 3.75756301].
2024-09-17 23:54:59,677 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:397] - INFO: Uniform reward: 3.8338, 3.8338, 3.1967
2024-09-17 23:54:59,678 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Optimal reward: 3.8674, 3.8674, 3.3244
2024-09-17 23:54:59,678 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Policy reward: 3.5567, 3.8412, 3.1835
2024-09-17 23:54:59,679 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Reward Error: 0.0804, 0.0068, 0.0424
2024-09-17 23:55:00,366 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:415] - INFO: Optimal reward: 3.8674, 3.8674, 3.3244
Known param reward: [[3.8674325942993164, 3.479376792907715, 3.2942817211151123], [3.479376792907715, 3.8674325942993164, 3.131351947784424], [3.834221601486206, 3.589629888534546, 3.324373483657837]], Known param reward error: [[0.0, 0.10033938328068204, 0.009051859753620217], [0.10033938328068204, 0.0, 0.058062530224801887], [0.008587348842760469, 0.07183129866936996, 0.0]].
