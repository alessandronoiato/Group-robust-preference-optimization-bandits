2024-09-17 19:45:45,464 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:198] - INFO: Logging to log_dpo/2024_09_17_19_44_46/swapped_noise0.9_[1,0.9,1]_2024
2024-09-17 19:45:45,466 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: (IB) Seed: 2024
2024-09-17 19:45:45,467 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Data: 300
2024-09-17 19:45:45,632 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:296] - INFO: MLE reward loss: 0.3501, l2 distance: 38.4647, acc: 0.84.
2024-09-17 19:45:45,633 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-17 19:45:45,634 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: MLE reward parameter: [14.13744683 11.70596164 14.60772417 11.37070021]
2024-09-17 19:45:45,831 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:313] - INFO: Learned oracle reward: 3.7274, 3.8371, 3.3621
2024-09-17 19:45:47,114 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:947] - INFO: Iteration:  0, train_loss:  19.9595, val_loss:  20.2627, grad_norm: 0.7351, reward_err: 0.0702, 0.0365, 0.0430, KL_dist: 0.2060, 0.1058, 0.1482, param: [1.23464812 2.69334862 4.5547819  2.9036377 ]train_grp_loss: [22.57409587 15.11626138 21.49638513], val_grp_loss: [22.08739358 16.64562341 21.87497695], train_hist_grp_loss: [22.60157711 15.21276969 21.54013911], cur_train_grp_loss: [22.60157711 15.21276969 21.54013911],max_reward_err:  0.0702, max_reward_err_index: 0, max_kl_dist:  0.2060, max_kl_dist_index: 0, max_train_grp_loss:  22.5741, max_train_grp_loss_index: 0, max_val_grp_loss:  22.0874, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  22.6016, max_cur_train_grp_loss_index: 0, 
2024-09-17 19:45:50,116 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:1040] - INFO: Iteration:  99, train_loss:  16.7729, val_loss:  17.3234, grad_norm: 0.4234, reward_err: 0.0630, 0.0249, 0.0299, KL_dist: 0.6436, 0.4260, 0.5148, param: [4.83603009 4.80383197 7.53886059 5.01586041]train_grp_loss: [20.85460904 10.02564409 18.47467051], val_grp_loss: [19.93825052 12.47190966 19.32046256], train_hist_grp_loss: [2159.30089355 1205.11430884 1983.09239052], cur_train_grp_loss: [20.86474991 10.04929106 18.49535477],max_reward_err:  0.0630, max_reward_err_index: 0, max_kl_dist:  0.6436, max_kl_dist_index: 0, max_train_grp_loss:  20.8546, max_train_grp_loss_index: 0, max_val_grp_loss:  19.9383, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  20.8647, max_cur_train_grp_loss_index: 0, 
2024-09-17 19:45:50,328 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:386] - INFO: Policy parameter learned solely on the preference data dpo: [4.83603009 4.80383197 7.53886059 5.01586041].
2024-09-17 19:45:50,648 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:397] - INFO: Uniform reward: 3.8988, 3.8988, 3.2898
2024-09-17 19:45:50,648 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Optimal reward: 3.9394, 3.9394, 3.4305
2024-09-17 19:45:50,649 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Policy reward: 3.6913, 3.8413, 3.3278
2024-09-17 19:45:50,649 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Reward Error: 0.0630, 0.0249, 0.0299
2024-09-17 19:45:51,322 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:415] - INFO: Optimal reward: 3.9394, 3.9394, 3.4305
Known param reward: [[3.939390182495117, 3.527578830718994, 3.3940188884735107], [3.527578830718994, 3.939390182495117, 3.225066661834717], [3.8967127799987793, 3.6586339473724365, 3.4304511547088623]], Known param reward error: [[0.0, 0.10453682745264177, 0.010620255060429077], [0.10453682745264177, 0.0, 0.059870985946621415], [0.010833504811474914, 0.07126895842159414, 0.0]].
