2024-09-17 19:45:09,103 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:198] - INFO: Logging to log_dpo/2024_09_17_19_44_46/swapped_noise0.9_[1,0.9,1]_2022
2024-09-17 19:45:09,105 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: (IB) Seed: 2022
2024-09-17 19:45:09,105 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Data: 300
2024-09-17 19:45:09,269 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:296] - INFO: MLE reward loss: 0.3352, l2 distance: 43.9297, acc: 0.84.
2024-09-17 19:45:09,270 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-17 19:45:09,271 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: MLE reward parameter: [19.08965865  8.96320989 17.85715783  8.46320643]
2024-09-17 19:45:09,478 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:313] - INFO: Learned oracle reward: 3.5953, 3.8576, 3.2072
2024-09-17 19:45:10,766 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:947] - INFO: Iteration:  0, train_loss:  21.6868, val_loss:  21.5871, grad_norm: 0.8990, reward_err: 0.1021, 0.0465, 0.0791, KL_dist: 0.2411, 0.0667, 0.1850, param: [0.13306079 2.49205784 4.21813736 0.73801612]train_grp_loss: [22.42470987 19.5751623  23.07604823], val_grp_loss: [23.28633736 18.5782931  22.85423405], train_hist_grp_loss: [22.46721938 19.73515825 23.11415473], cur_train_grp_loss: [22.46721938 19.73515825 23.11415473],max_reward_err:  0.1021, max_reward_err_index: 0, max_kl_dist:  0.2411, max_kl_dist_index: 0, max_train_grp_loss:  23.0760, max_train_grp_loss_index: 2, max_val_grp_loss:  23.2863, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  23.1142, max_cur_train_grp_loss_index: 2, 
2024-09-17 19:45:13,749 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:1040] - INFO: Iteration:  99, train_loss:  16.9971, val_loss:  17.2909, grad_norm: 0.5111, reward_err: 0.0837, 0.0093, 0.0518, KL_dist: 0.7537, 0.2916, 0.5912, param: [4.39372067 2.92074363 8.4194998  3.77399326]train_grp_loss: [19.59334732 10.95116772 20.51469741], val_grp_loss: [21.62232626 10.69070738 19.47393357], train_hist_grp_loss: [2084.63822155 1443.03591864 2165.22789965], cur_train_grp_loss: [19.61193798 10.99352606 20.5316944 ],max_reward_err:  0.0837, max_reward_err_index: 0, max_kl_dist:  0.7537, max_kl_dist_index: 0, max_train_grp_loss:  20.5147, max_train_grp_loss_index: 2, max_val_grp_loss:  21.6223, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  20.5317, max_cur_train_grp_loss_index: 2, 
2024-09-17 19:45:13,962 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:386] - INFO: Policy parameter learned solely on the preference data dpo: [4.39372067 2.92074363 8.4194998  3.77399326].
2024-09-17 19:45:14,284 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:397] - INFO: Uniform reward: 3.8425, 3.8425, 3.1988
2024-09-17 19:45:14,285 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Optimal reward: 3.8738, 3.8738, 3.3306
2024-09-17 19:45:14,285 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Policy reward: 3.5495, 3.8379, 3.1581
2024-09-17 19:45:14,286 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Reward Error: 0.0837, 0.0093, 0.0518
2024-09-17 19:45:14,945 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:415] - INFO: Optimal reward: 3.8738, 3.8738, 3.3306
Known param reward: [[3.873821496963501, 3.54714035987854, 3.280407190322876], [3.54714035987854, 3.873821496963501, 3.172149896621704], [3.830048084259033, 3.6424906253814697, 3.330552816390991]], Known param reward error: [[0.0, 0.08433045697666511, 0.015056247065450643], [0.08433045697666511, 0.0, 0.04756054880430737], [0.011299801175345743, 0.059716450993769384, 0.0]].
