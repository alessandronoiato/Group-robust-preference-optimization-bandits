2024-09-17 19:45:27,883 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:198] - INFO: Logging to log_dpo/2024_09_17_19_44_46/swapped_noise0.9_[1,0.9,1]_2023
2024-09-17 19:45:27,885 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: (IB) Seed: 2023
2024-09-17 19:45:27,885 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Data: 300
2024-09-17 19:45:28,050 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:296] - INFO: MLE reward loss: 0.3326, l2 distance: 37.6787, acc: 0.83.
2024-09-17 19:45:28,051 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-17 19:45:28,052 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: MLE reward parameter: [16.21120855  9.23974655 14.14981402 10.0338779 ]
2024-09-17 19:45:28,254 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:313] - INFO: Learned oracle reward: 3.5473, 3.7617, 3.1429
2024-09-17 19:45:29,558 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:947] - INFO: Iteration:  0, train_loss:  19.7707, val_loss:  20.0904, grad_norm: 0.8221, reward_err: 0.0222, 0.0737, 0.0059, KL_dist: 0.0900, 0.2717, 0.0652, param: [2.99421008 4.86955368 2.22802484 2.7276694 ]train_grp_loss: [21.54168299 17.20761767 20.7769841 ], val_grp_loss: [21.43844876 17.75595536 21.1352069 ], train_hist_grp_loss: [21.56620834 17.34346105 20.81270565], cur_train_grp_loss: [21.56620834 17.34346105 20.81270565],max_reward_err:  0.0737, max_reward_err_index: 1, max_kl_dist:  0.2717, max_kl_dist_index: 1, max_train_grp_loss:  21.5417, max_train_grp_loss_index: 0, max_val_grp_loss:  21.4384, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  21.5662, max_cur_train_grp_loss_index: 0, 
2024-09-17 19:45:32,521 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:1040] - INFO: Iteration:  99, train_loss:  16.0127, val_loss:  16.9583, grad_norm: 0.4397, reward_err: 0.0609, 0.0184, 0.0264, KL_dist: 0.6934, 0.4407, 0.5461, param: [7.08190127 4.81638971 6.18819399 4.65094695]train_grp_loss: [20.05659607 10.01567428 18.47313175], val_grp_loss: [20.07946076 12.4948168  18.44441638], train_hist_grp_loss: [2068.65356695 1288.41853089 1947.85476493], cur_train_grp_loss: [20.06508211 10.04940957 18.48758771],max_reward_err:  0.0609, max_reward_err_index: 0, max_kl_dist:  0.6934, max_kl_dist_index: 0, max_train_grp_loss:  20.0566, max_train_grp_loss_index: 0, max_val_grp_loss:  20.0795, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  20.0651, max_cur_train_grp_loss_index: 0, 
2024-09-17 19:45:32,734 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:386] - INFO: Policy parameter learned solely on the preference data dpo: [7.08190127 4.81638971 6.18819399 4.65094695].
2024-09-17 19:45:33,056 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:397] - INFO: Uniform reward: 3.7726, 3.7726, 3.1245
2024-09-17 19:45:33,056 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Optimal reward: 3.8074, 3.8074, 3.2472
2024-09-17 19:45:33,057 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Policy reward: 3.5756, 3.7372, 3.1615
2024-09-17 19:45:33,057 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Reward Error: 0.0609, 0.0184, 0.0264
2024-09-17 19:45:33,721 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:415] - INFO: Optimal reward: 3.8074, 3.8074, 3.2472
Known param reward: [[3.8073642253875732, 3.4191784858703613, 3.213675022125244], [3.4191784858703613, 3.8073642253875732, 3.0531070232391357], [3.768303871154785, 3.5439467430114746, 3.2471864223480225]], Known param reward error: [[0.0, 0.10195655485986405, 0.010320134376068995], [0.10195655485986405, 0.0, 0.05976848072940296], [0.010259158809218447, 0.06918631020894353, 0.0]].
