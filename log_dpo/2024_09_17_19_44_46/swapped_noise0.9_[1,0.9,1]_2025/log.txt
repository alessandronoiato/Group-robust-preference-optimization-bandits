2024-09-17 19:46:04,394 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:198] - INFO: Logging to log_dpo/2024_09_17_19_44_46/swapped_noise0.9_[1,0.9,1]_2025
2024-09-17 19:46:04,396 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: (IB) Seed: 2025
2024-09-17 19:46:04,396 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Data: 300
2024-09-17 19:46:04,572 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:296] - INFO: MLE reward loss: 0.3878, l2 distance: 26.1556, acc: 0.81.
2024-09-17 19:46:04,573 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-17 19:46:04,574 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: MLE reward parameter: [11.51788074  5.11842328 12.13433964  6.23296411]
2024-09-17 19:46:04,780 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:313] - INFO: Learned oracle reward: 3.5453, 3.8260, 3.1153
2024-09-17 19:46:06,059 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:947] - INFO: Iteration:  0, train_loss:  19.9547, val_loss:  20.0918, grad_norm: 0.8114, reward_err: 0.0966, 0.0071, 0.0619, KL_dist: 0.2263, 0.0174, 0.1350, param: [4.26564152 1.73704446 2.26466284 1.63670704]train_grp_loss: [22.58699346 15.71464988 22.31006544], val_grp_loss: [22.82065594 15.10129319 22.22592555], train_hist_grp_loss: [22.62049828 15.8299382  22.34930198], cur_train_grp_loss: [22.62049828 15.8299382  22.34930198],max_reward_err:  0.0966, max_reward_err_index: 0, max_kl_dist:  0.2263, max_kl_dist_index: 0, max_train_grp_loss:  22.5870, max_train_grp_loss_index: 0, max_val_grp_loss:  22.8207, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  22.6205, max_cur_train_grp_loss_index: 0, 
2024-09-17 19:46:09,090 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:1040] - INFO: Iteration:  99, train_loss:  16.3012, val_loss:  16.4169, grad_norm: 0.4322, reward_err: 0.0872, 0.0019, 0.0498, KL_dist: 0.7943, 0.3422, 0.6051, param: [8.00327202 2.92602207 6.34569431 3.38308401]train_grp_loss: [20.55429027  9.70904892 19.81105022], val_grp_loss: [21.11890157  8.32925664 19.60777773], train_hist_grp_loss: [2141.78930595 1208.17026263 2089.61062702], cur_train_grp_loss: [20.56599542  9.73618303 19.82649698],max_reward_err:  0.0872, max_reward_err_index: 0, max_kl_dist:  0.7943, max_kl_dist_index: 0, max_train_grp_loss:  20.5543, max_train_grp_loss_index: 0, max_val_grp_loss:  21.1189, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  20.5660, max_cur_train_grp_loss_index: 0, 
2024-09-17 19:46:09,309 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:386] - INFO: Policy parameter learned solely on the preference data dpo: [8.00327202 2.92602207 6.34569431 3.38308401].
2024-09-17 19:46:09,637 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:397] - INFO: Uniform reward: 3.8117, 3.8117, 3.1389
2024-09-17 19:46:09,638 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Optimal reward: 3.8428, 3.8428, 3.2468
2024-09-17 19:46:09,638 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Policy reward: 3.5078, 3.8354, 3.0850
2024-09-17 19:46:09,639 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Reward Error: 0.0872, 0.0019, 0.0498
2024-09-17 19:46:10,317 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:415] - INFO: Optimal reward: 3.8428, 3.8428, 3.2468
Known param reward: [[3.8428120613098145, 3.466555118560791, 3.208935022354126], [3.466555118560791, 3.8428120613098145, 3.0578837394714355], [3.8028461933135986, 3.5883326530456543, 3.246764659881592]], Known param reward error: [[0.0, 0.09791187722586076, 0.01165148740064377], [0.09791187722586076, 0.0, 0.05817511898661749], [0.010400162005995563, 0.06622218422449246, 0.0]].
