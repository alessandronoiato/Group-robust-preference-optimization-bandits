2024-09-18 22:04:57,798 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log_dpo/2024_09_18_21_50_05/swapped_noise0.6_[1,0.6,1]_2028
2024-09-18 22:04:57,800 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2028
2024-09-18 22:04:57,800 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-09-18 22:04:57,963 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.5162, l2 distance: 11.4215, acc: 0.77.
2024-09-18 22:04:57,963 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-18 22:04:57,964 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [4.65646533 3.49803522 7.38419958 2.36698542]
2024-09-18 22:04:58,175 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.5114, 3.8516, 3.1541
2024-09-18 22:04:59,610 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:947] - INFO: Iteration:  0, train_loss:  20.0791, val_loss:  19.0595, grad_norm: 0.4901, reward_err: 0.0617, 0.0437, 0.0332, KL_dist: 0.2401, 0.1767, 0.1582, param: [4.68245336 4.29964425 2.6521291  1.87942283]train_grp_loss: [22.04227329 17.34462978 21.02273933], val_grp_loss: [21.5286477  14.44457245 20.748971  ], train_hist_grp_loss: [22.05281151 17.38302537 21.04859279], cur_train_grp_loss: [22.05281151 17.38302537 21.04859279],max_reward_err:  0.0617, max_reward_err_index: 0, max_kl_dist:  0.2401, max_kl_dist_index: 0, max_train_grp_loss:  22.0423, max_train_grp_loss_index: 0, max_val_grp_loss:  21.5286, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  22.0528, max_cur_train_grp_loss_index: 0, 
2024-09-18 22:05:02,794 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:1040] - INFO: Iteration:  99, train_loss:  18.7261, val_loss:  16.8616, grad_norm: 0.2672, reward_err: 0.0735, 0.0212, 0.0385, KL_dist: 0.6013, 0.3045, 0.4443, param: [6.63528927 4.7678151  5.56923236 2.56376562]train_grp_loss: [21.48688129 15.25882365 19.30306841], val_grp_loss: [20.57348675 10.29106066 19.04574023], train_hist_grp_loss: [2170.6248563  1610.33675313 2006.42597681], cur_train_grp_loss: [21.48932691 15.2691898  19.31439508],max_reward_err:  0.0735, max_reward_err_index: 0, max_kl_dist:  0.6013, max_kl_dist_index: 0, max_train_grp_loss:  21.4869, max_train_grp_loss_index: 0, max_val_grp_loss:  20.5735, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  21.4893, max_cur_train_grp_loss_index: 0, 
2024-09-18 22:05:03,035 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:387] - INFO: Policy parameter learned solely on the preference data dpo: [6.63528927 4.7678151  5.56923236 2.56376562].
2024-09-18 22:05:03,372 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Uniform reward: 3.8289, 3.8289, 3.2018
2024-09-18 22:05:03,373 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Optimal reward: 3.8652, 3.8652, 3.3372
2024-09-18 22:05:03,373 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Policy reward: 3.5811, 3.7833, 3.2089
2024-09-18 22:05:03,374 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Reward Error: 0.0735, 0.0212, 0.0385
2024-09-18 22:05:04,069 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:416] - INFO: Optimal reward: 3.8652, 3.8652, 3.3372
Known param reward: [[3.8651840686798096, 3.4605093002319336, 3.3015952110290527], [3.4605093002319336, 3.8651840686798096, 3.1258203983306885], [3.8319525718688965, 3.6041877269744873, 3.337219715118408]], Known param reward error: [[0.0, 0.10469741188447372, 0.010674905199669023], [0.10469741188447372, 0.0, 0.0633459390851702], [0.00859764922457202, 0.06752494501367125, 0.0]].
