2024-09-18 22:03:45,835 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log_dpo/2024_09_18_21_50_05/swapped_noise0.6_[1,0.6,1]_2024
2024-09-18 22:03:45,837 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2024
2024-09-18 22:03:45,837 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-09-18 22:03:46,001 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.4614, l2 distance: 14.2156, acc: 0.81.
2024-09-18 22:03:46,002 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-18 22:03:46,002 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [7.12777926 3.69118221 7.29367386 4.24080502]
2024-09-18 22:03:46,213 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.5381, 3.7683, 3.1486
2024-09-18 22:03:47,633 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:947] - INFO: Iteration:  0, train_loss:  18.7978, val_loss:  18.8681, grad_norm: 0.6257, reward_err: 0.0489, 0.0193, 0.0201, KL_dist: 0.2504, 0.1290, 0.1560, param: [4.2245897  3.02841678 3.68701795 3.04070248]train_grp_loss: [21.57158617 15.92060317 20.15818271], val_grp_loss: [21.44810186 13.94016673 21.04378225], train_hist_grp_loss: [21.59479419 15.97416341 20.1954156 ], cur_train_grp_loss: [21.59479419 15.97416341 20.1954156 ],max_reward_err:  0.0489, max_reward_err_index: 0, max_kl_dist:  0.2504, max_kl_dist_index: 0, max_train_grp_loss:  21.5716, max_train_grp_loss_index: 0, max_val_grp_loss:  21.4481, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  21.5948, max_cur_train_grp_loss_index: 0, 
2024-09-18 22:03:50,972 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:1040] - INFO: Iteration:  99, train_loss:  16.8920, val_loss:  16.5477, grad_norm: 0.2922, reward_err: 0.0583, 0.0132, 0.0266, KL_dist: 0.6957, 0.4018, 0.5293, param: [6.76636086 3.52929453 6.45507988 4.92472176]train_grp_loss: [20.26833236 13.60986673 17.81261818], val_grp_loss: [20.0314261  10.13702641 19.25682683], train_hist_grp_loss: [2080.34113591 1444.92114372 1882.91264034], cur_train_grp_loss: [20.27507548 13.61814304 17.8271459 ],max_reward_err:  0.0583, max_reward_err_index: 0, max_kl_dist:  0.6957, max_kl_dist_index: 0, max_train_grp_loss:  20.2683, max_train_grp_loss_index: 0, max_val_grp_loss:  20.0314, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  20.2751, max_cur_train_grp_loss_index: 0, 
2024-09-18 22:03:51,203 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:387] - INFO: Policy parameter learned solely on the preference data dpo: [6.76636086 3.52929453 6.45507988 4.92472176].
2024-09-18 22:03:51,548 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Uniform reward: 3.7483, 3.7483, 3.1113
2024-09-18 22:03:51,549 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Optimal reward: 3.7937, 3.7937, 3.2584
2024-09-18 22:03:51,549 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Policy reward: 3.5725, 3.7437, 3.1718
2024-09-18 22:03:51,550 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Reward Error: 0.0583, 0.0132, 0.0266
2024-09-18 22:03:52,242 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:416] - INFO: Optimal reward: 3.7937, 3.7937, 3.2584
Known param reward: [[3.7937493324279785, 3.4302093982696533, 3.224942445755005], [3.4302093982696533, 3.7937493324279785, 3.071303129196167], [3.7626752853393555, 3.56032395362854, 3.2583768367767334]], Known param reward error: [[0.0, 0.09582602916088334, 0.010261057175572927], [0.09582602916088334, 0.0, 0.057413159051800874], [0.008190854051165217, 0.061528940988319736, 0.0]].
