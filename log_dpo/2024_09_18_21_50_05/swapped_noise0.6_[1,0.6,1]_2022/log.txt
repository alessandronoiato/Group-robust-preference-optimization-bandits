2024-09-18 22:03:08,441 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log_dpo/2024_09_18_21_50_05/swapped_noise0.6_[1,0.6,1]_2022
2024-09-18 22:03:08,443 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2022
2024-09-18 22:03:08,443 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-09-18 22:03:08,602 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.4258, l2 distance: 17.8984, acc: 0.79.
2024-09-18 22:03:08,603 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-18 22:03:08,603 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [8.50055629 4.88587613 8.63017399 4.5857094 ]
2024-09-18 22:03:08,811 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.6173, 3.8368, 3.2206
2024-09-18 22:03:10,244 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:947] - INFO: Iteration:  0, train_loss:  18.8997, val_loss:  18.7956, grad_norm: 0.7288, reward_err: 0.0672, 0.0150, 0.0351, KL_dist: 0.2547, 0.0748, 0.1557, param: [4.45881133 1.71704344 3.2332928  2.99671058]train_grp_loss: [21.92464142 15.07553222 21.41517797], val_grp_loss: [22.06422482 13.23494496 21.52048499], train_hist_grp_loss: [21.95633568 15.15374045 21.45452751], cur_train_grp_loss: [21.95633568 15.15374045 21.45452751],max_reward_err:  0.0672, max_reward_err_index: 0, max_kl_dist:  0.2547, max_kl_dist_index: 0, max_train_grp_loss:  21.9246, max_train_grp_loss_index: 0, max_val_grp_loss:  22.0642, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  21.9563, max_cur_train_grp_loss_index: 0, 
2024-09-18 22:03:13,446 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:1040] - INFO: Iteration:  99, train_loss:  16.2791, val_loss:  15.8406, grad_norm: 0.3409, reward_err: 0.0637, 0.0100, 0.0311, KL_dist: 0.7381, 0.3745, 0.5715, param: [7.5570941  4.07016828 6.1895583  3.92205298]train_grp_loss: [20.11136004 11.55474049 19.13533305], val_grp_loss: [20.32380472  8.50193634 19.27028076], train_hist_grp_loss: [2086.29012566 1285.58502682 2008.64093398], cur_train_grp_loss: [20.12106019 11.56780624 19.14781297],max_reward_err:  0.0637, max_reward_err_index: 0, max_kl_dist:  0.7381, max_kl_dist_index: 0, max_train_grp_loss:  20.1114, max_train_grp_loss_index: 0, max_val_grp_loss:  20.3238, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  20.1211, max_cur_train_grp_loss_index: 0, 
2024-09-18 22:03:13,673 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:387] - INFO: Policy parameter learned solely on the preference data dpo: [7.5570941  4.07016828 6.1895583  3.92205298].
2024-09-18 22:03:14,015 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Uniform reward: 3.8345, 3.8345, 3.1912
2024-09-18 22:03:14,016 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Optimal reward: 3.8662, 3.8662, 3.3225
2024-09-18 22:03:14,016 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Policy reward: 3.6199, 3.8275, 3.2193
2024-09-18 22:03:14,017 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Reward Error: 0.0637, 0.0100, 0.0311
2024-09-18 22:03:14,700 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:416] - INFO: Optimal reward: 3.8662, 3.8662, 3.3225
Known param reward: [[3.866189479827881, 3.537107467651367, 3.2731680870056152], [3.537107467651367, 3.866189479827881, 3.16263484954834], [3.823214292526245, 3.6324574947357178, 3.322507381439209]], Known param reward error: [[0.0, 0.08511792137801898, 0.014850018004240361], [0.08511792137801898, 0.0, 0.048118036632206734], [0.011115644364007984, 0.06045538800197879, 0.0]].
