2024-09-18 22:02:31,022 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log_dpo/2024_09_18_21_50_05/swapped_noise0.7_[1,0.7,1]_2030
2024-09-18 22:02:31,024 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2030
2024-09-18 22:02:31,024 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-09-18 22:02:31,189 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.4425, l2 distance: 16.8138, acc: 0.81.
2024-09-18 22:02:31,190 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-18 22:02:31,191 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [7.62750007 3.92484544 9.1161362  3.44860802]
2024-09-18 22:02:31,406 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.4592, 3.8076, 3.1317
2024-09-18 22:02:32,868 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:947] - INFO: Iteration:  0, train_loss:  23.4554, val_loss:  22.1256, grad_norm: 1.0771, reward_err: 0.0058, 0.1266, 0.0333, KL_dist: 0.0249, 0.3851, 0.0736, param: [0.83570155 4.66595969 0.24178786 2.62770147]train_grp_loss: [21.94947186 24.86302896 22.60722197], val_grp_loss: [21.98780832 22.02779852 22.37737074], train_hist_grp_loss: [21.9598347  25.080219   22.65384451], cur_train_grp_loss: [21.9598347  25.080219   22.65384451],max_reward_err:  0.1266, max_reward_err_index: 1, max_kl_dist:  0.3851, max_kl_dist_index: 1, max_train_grp_loss:  24.8630, max_train_grp_loss_index: 1, max_val_grp_loss:  22.3774, max_val_grp_loss_index: 2, max_cur_train_grp_loss:  25.0802, max_cur_train_grp_loss_index: 1, 
2024-09-18 22:02:36,109 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:1040] - INFO: Iteration:  99, train_loss:  17.6115, val_loss:  17.1672, grad_norm: 0.5136, reward_err: 0.0689, 0.0097, 0.0328, KL_dist: 0.5351, 0.2274, 0.3840, param: [6.01859689 3.45750441 5.38581715 3.38593258]train_grp_loss: [21.50731302 14.03376435 19.6183951 ], val_grp_loss: [21.39053431  9.73376385 19.81776211], train_hist_grp_loss: [2166.30648849 1824.54403135 2092.33839422], cur_train_grp_loss: [21.50859357 14.08113104 19.63734352],max_reward_err:  0.0689, max_reward_err_index: 0, max_kl_dist:  0.5351, max_kl_dist_index: 0, max_train_grp_loss:  21.5073, max_train_grp_loss_index: 0, max_val_grp_loss:  21.3905, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  21.5086, max_cur_train_grp_loss_index: 0, 
2024-09-18 22:02:36,337 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:387] - INFO: Policy parameter learned solely on the preference data dpo: [6.01859689 3.45750441 5.38581715 3.38593258].
2024-09-18 22:02:36,681 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Uniform reward: 3.7748, 3.7748, 3.1636
2024-09-18 22:02:36,682 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Optimal reward: 3.8136, 3.8136, 3.3066
2024-09-18 22:02:36,682 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Policy reward: 3.5508, 3.7768, 3.1981
2024-09-18 22:02:36,683 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Reward Error: 0.0689, 0.0097, 0.0328
2024-09-18 22:02:37,407 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:416] - INFO: Optimal reward: 3.8136, 3.8136, 3.3066
Known param reward: [[3.813612222671509, 3.4377872943878174, 3.272095203399658], [3.4377872943878174, 3.813612222671509, 3.118396520614624], [3.779019594192505, 3.5611813068389893, 3.3066372871398926]], Known param reward error: [[0.0, 0.09854828082662763, 0.010446287494118195], [0.09854828082662763, 0.0, 0.056928156970034414], [0.009070830084232083, 0.06619207750904647, 0.0]].
