2024-09-18 22:01:14,294 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log_dpo/2024_09_18_21_50_05/swapped_noise0.7_[1,0.7,1]_2026
2024-09-18 22:01:14,296 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2026
2024-09-18 22:01:14,297 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-09-18 22:01:14,459 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.4813, l2 distance: 14.8904, acc: 0.78.
2024-09-18 22:01:14,460 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-18 22:01:14,460 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [7.67816127 4.45673794 7.13735006 4.03215563]
2024-09-18 22:01:14,666 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.5911, 3.8424, 3.2513
2024-09-18 22:01:16,091 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:947] - INFO: Iteration:  0, train_loss:  19.7022, val_loss:  19.1859, grad_norm: 0.5715, reward_err: 0.0511, 0.0313, 0.0229, KL_dist: 0.2109, 0.1328, 0.1272, param: [4.15958867 3.63299935 3.04866501 2.36009887]train_grp_loss: [21.61721193 16.69338259 21.44145547], val_grp_loss: [21.35269257 14.81741453 21.08435595], train_hist_grp_loss: [21.64030026 16.73913799 21.46943223], cur_train_grp_loss: [21.64030026 16.73913799 21.46943223],max_reward_err:  0.0511, max_reward_err_index: 0, max_kl_dist:  0.2109, max_kl_dist_index: 0, max_train_grp_loss:  21.6172, max_train_grp_loss_index: 0, max_val_grp_loss:  21.3527, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  21.6403, max_cur_train_grp_loss_index: 0, 
2024-09-18 22:01:19,291 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:1040] - INFO: Iteration:  99, train_loss:  17.9455, val_loss:  16.6611, grad_norm: 0.2967, reward_err: 0.0652, 0.0136, 0.0320, KL_dist: 0.6204, 0.3389, 0.4664, param: [6.7773191  4.40130657 5.64979309 3.96509644]train_grp_loss: [20.25269426 14.49584298 19.61190039], val_grp_loss: [19.73834665 10.65639028 19.16501369], train_hist_grp_loss: [2082.59511958 1533.39513605 2041.60750285], cur_train_grp_loss: [20.26028714 14.5048102  19.62368764],max_reward_err:  0.0652, max_reward_err_index: 0, max_kl_dist:  0.6204, max_kl_dist_index: 0, max_train_grp_loss:  20.2527, max_train_grp_loss_index: 0, max_val_grp_loss:  19.7383, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  20.2603, max_cur_train_grp_loss_index: 0, 
2024-09-18 22:01:19,534 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:387] - INFO: Policy parameter learned solely on the preference data dpo: [6.7773191  4.40130657 5.64979309 3.96509644].
2024-09-18 22:01:19,873 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Uniform reward: 3.8296, 3.8296, 3.2253
2024-09-18 22:01:19,874 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Optimal reward: 3.8699, 3.8699, 3.3751
2024-09-18 22:01:19,874 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Policy reward: 3.6175, 3.8173, 3.2673
2024-09-18 22:01:19,875 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Reward Error: 0.0652, 0.0136, 0.0320
2024-09-18 22:01:20,554 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:416] - INFO: Optimal reward: 3.8699, 3.8699, 3.3751
Known param reward: [[3.8699047565460205, 3.4682676792144775, 3.3350672721862793], [3.4682676792144775, 3.8699047565460205, 3.164400100708008], [3.831815481185913, 3.603090763092041, 3.375126361846924]], Known param reward error: [[0.0, 0.10378474474137016, 0.011868915520758028], [0.10378474474137016, 0.0, 0.06243507310452317], [0.009842432244793276, 0.06894588116223231, 0.0]].
