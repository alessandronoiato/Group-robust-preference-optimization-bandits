2024-09-18 21:51:46,644 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log_dpo/2024_09_18_21_50_05/swapped_noise1.0_[1,1.0,1]_2026
2024-09-18 21:51:46,646 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2026
2024-09-18 21:51:46,647 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-09-18 21:51:46,816 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.3205, l2 distance: 37.0255, acc: 0.85.
2024-09-18 21:51:46,817 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-18 21:51:46,818 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [16.29530932  7.55488527 15.66290624  7.13011982]
2024-09-18 21:51:47,033 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.5156, 3.8430, 3.1442
2024-09-18 21:51:48,555 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:947] - INFO: Iteration:  0, train_loss:  18.8333, val_loss:  18.6437, grad_norm: 0.7952, reward_err: 0.0557, 0.0523, 0.0281, KL_dist: 0.2579, 0.2323, 0.1945, param: [2.37715005 3.0268105  5.01492254 4.54055616]train_grp_loss: [20.67957543 15.8401915  20.73616657], val_grp_loss: [21.19666986 13.54913358 20.6446571 ], train_hist_grp_loss: [20.70416697 15.9658578  20.75893242], cur_train_grp_loss: [20.70416697 15.9658578  20.75893242],max_reward_err:  0.0557, max_reward_err_index: 0, max_kl_dist:  0.2579, max_kl_dist_index: 0, max_train_grp_loss:  20.7362, max_train_grp_loss_index: 2, max_val_grp_loss:  21.1967, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  20.7589, max_cur_train_grp_loss_index: 2, 
2024-09-18 21:51:51,793 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:1040] - INFO: Iteration:  99, train_loss:  15.1626, val_loss:  15.7946, grad_norm: 0.4471, reward_err: 0.0838, 0.0049, 0.0447, KL_dist: 0.9562, 0.4529, 0.7493, param: [6.69313283 4.07605538 8.91797364 3.85288076]train_grp_loss: [19.08949008  8.78128394 19.2465063 ], val_grp_loss: [20.21754752  7.5686685  18.72202342], train_hist_grp_loss: [1978.43986329 1167.43533824 1990.06873183], cur_train_grp_loss: [19.09952606  8.81734346 19.25604598],max_reward_err:  0.0838, max_reward_err_index: 0, max_kl_dist:  0.9562, max_kl_dist_index: 0, max_train_grp_loss:  19.2465, max_train_grp_loss_index: 2, max_val_grp_loss:  20.2175, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  19.2560, max_cur_train_grp_loss_index: 2, 
2024-09-18 21:51:52,025 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:387] - INFO: Policy parameter learned solely on the preference data dpo: [6.69313283 4.07605538 8.91797364 3.85288076].
2024-09-18 21:51:52,360 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Uniform reward: 3.8112, 3.8112, 3.1709
2024-09-18 21:51:52,360 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Optimal reward: 3.8518, 3.8518, 3.2974
2024-09-18 21:51:52,361 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Policy reward: 3.5292, 3.8330, 3.1501
2024-09-18 21:51:52,361 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Reward Error: 0.0838, 0.0049, 0.0447
2024-09-18 21:51:53,040 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:416] - INFO: Optimal reward: 3.8518, 3.8518, 3.2974
Known param reward: [[3.8518338203430176, 3.4604334831237793, 3.266357421875], [3.4604334831237793, 3.8518338203430176, 3.1038687229156494], [3.8126895427703857, 3.589339256286621, 3.297445297241211]], Known param reward error: [[0.0, 0.10161402476713881, 0.009427866898116682], [0.10161402476713881, 0.0, 0.058705014602521616], [0.010162504250805377, 0.06814794622500629, 0.0]].
