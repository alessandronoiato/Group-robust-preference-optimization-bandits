2024-09-18 22:02:49,817 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log_dpo/2024_09_18_21_50_05/swapped_noise0.6_[1,0.6,1]_2021
2024-09-18 22:02:49,819 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2021
2024-09-18 22:02:49,820 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-09-18 22:02:49,981 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.4881, l2 distance: 12.8925, acc: 0.78.
2024-09-18 22:02:49,982 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-18 22:02:49,983 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [7.49008496 2.76987425 6.30387609 1.756958  ]
2024-09-18 22:02:50,194 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.4326, 3.8265, 3.0841
2024-09-18 22:02:51,601 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:947] - INFO: Iteration:  0, train_loss:  22.6308, val_loss:  21.5170, grad_norm: 0.8749, reward_err: 0.0029, 0.1172, 0.0219, KL_dist: 0.0463, 0.4215, 0.0915, param: [1.58972602 4.78288195 0.61263037 4.04507777]train_grp_loss: [21.3279136  24.35589553 21.57509488], val_grp_loss: [21.47226201 21.41009551 21.67235424], train_hist_grp_loss: [21.33910039 24.51426569 21.60885871], cur_train_grp_loss: [21.33910039 24.51426569 21.60885871],max_reward_err:  0.1172, max_reward_err_index: 1, max_kl_dist:  0.4215, max_kl_dist_index: 1, max_train_grp_loss:  24.3559, max_train_grp_loss_index: 1, max_val_grp_loss:  21.6724, max_val_grp_loss_index: 2, max_cur_train_grp_loss:  24.5143, max_cur_train_grp_loss_index: 1, 
2024-09-18 22:02:54,788 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:1040] - INFO: Iteration:  99, train_loss:  18.4883, val_loss:  17.3035, grad_norm: 0.4558, reward_err: 0.0660, 0.0120, 0.0319, KL_dist: 0.4714, 0.2190, 0.3367, param: [5.85016052 3.33751953 4.99463555 3.61711601]train_grp_loss: [20.66495781 15.99049634 19.2913975 ], val_grp_loss: [20.89211431 11.06079073 20.11464803], train_hist_grp_loss: [2094.45435778 1933.2890559  2030.93381733], cur_train_grp_loss: [20.66872007 16.03030267 19.30676135],max_reward_err:  0.0660, max_reward_err_index: 0, max_kl_dist:  0.4714, max_kl_dist_index: 0, max_train_grp_loss:  20.6650, max_train_grp_loss_index: 0, max_val_grp_loss:  20.8921, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  20.6687, max_cur_train_grp_loss_index: 0, 
2024-09-18 22:02:55,027 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:387] - INFO: Policy parameter learned solely on the preference data dpo: [5.85016052 3.33751953 4.99463555 3.61711601].
2024-09-18 22:02:55,365 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Uniform reward: 3.7957, 3.7957, 3.1631
2024-09-18 22:02:55,366 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Optimal reward: 3.8296, 3.8296, 3.2923
2024-09-18 22:02:55,366 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Policy reward: 3.5767, 3.7836, 3.1874
2024-09-18 22:02:55,367 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Reward Error: 0.0660, 0.0120, 0.0319
2024-09-18 22:02:56,051 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:416] - INFO: Optimal reward: 3.8296, 3.8296, 3.2923
Known param reward: [[3.8295645713806152, 3.440261125564575, 3.2583417892456055], [3.440261125564575, 3.8295645713806152, 3.092778205871582], [3.7937707901000977, 3.5698022842407227, 3.2923295497894287]], Known param reward error: [[0.0, 0.10165736562464864, 0.010323316675876822], [0.10165736562464864, 0.0, 0.0606109871141574], [0.009346697415161585, 0.06783076307974209, 0.0]].
