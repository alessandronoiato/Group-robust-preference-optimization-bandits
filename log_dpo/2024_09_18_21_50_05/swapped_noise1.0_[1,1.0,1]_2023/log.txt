2024-09-18 21:50:46,541 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log_dpo/2024_09_18_21_50_05/swapped_noise1.0_[1,1.0,1]_2023
2024-09-18 21:50:46,543 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2023
2024-09-18 21:50:46,544 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-09-18 21:50:46,741 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.3431, l2 distance: 35.5343, acc: 0.83.
2024-09-18 21:50:46,742 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-18 21:50:46,743 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [15.61298457  7.73326877 14.20212669  8.81141422]
2024-09-18 21:50:46,953 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.5015, 3.7537, 3.0878
2024-09-18 21:50:48,401 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:947] - INFO: Iteration:  0, train_loss:  20.5928, val_loss:  20.7199, grad_norm: 0.9086, reward_err: 0.0241, 0.0852, 0.0097, KL_dist: 0.0684, 0.2393, 0.0498, param: [1.27484668 4.57720519 3.01917348 2.10789007]train_grp_loss: [21.73213763 18.9490803  21.52376187], val_grp_loss: [21.80018891 18.62894846 21.70408722], train_hist_grp_loss: [21.75479123 19.11742686 21.55717742], cur_train_grp_loss: [21.75479123 19.11742686 21.55717742],max_reward_err:  0.0852, max_reward_err_index: 1, max_kl_dist:  0.2393, max_kl_dist_index: 1, max_train_grp_loss:  21.7321, max_train_grp_loss_index: 0, max_val_grp_loss:  21.8002, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  21.7548, max_cur_train_grp_loss_index: 0, 
2024-09-18 21:50:51,645 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:1040] - INFO: Iteration:  99, train_loss:  16.1183, val_loss:  16.4298, grad_norm: 0.4734, reward_err: 0.0699, 0.0132, 0.0345, KL_dist: 0.6819, 0.3703, 0.5285, param: [5.63134266 4.04984049 7.348789   4.3020118 ]train_grp_loss: [20.43057929  9.97329751 19.46446131], val_grp_loss: [20.03157515 10.01797764 19.18690714], train_hist_grp_loss: [2096.9650687  1357.78751102 2034.61333121], cur_train_grp_loss: [20.4374646  10.01686282 19.47664667],max_reward_err:  0.0699, max_reward_err_index: 0, max_kl_dist:  0.6819, max_kl_dist_index: 0, max_train_grp_loss:  20.4306, max_train_grp_loss_index: 0, max_val_grp_loss:  20.0316, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  20.4375, max_cur_train_grp_loss_index: 0, 
2024-09-18 21:50:51,872 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:387] - INFO: Policy parameter learned solely on the preference data dpo: [5.63134266 4.04984049 7.348789   4.3020118 ].
2024-09-18 21:50:52,219 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Uniform reward: 3.7505, 3.7505, 3.0898
2024-09-18 21:50:52,220 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Optimal reward: 3.7806, 3.7806, 3.2051
2024-09-18 21:50:52,221 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Policy reward: 3.5164, 3.7307, 3.0946
2024-09-18 21:50:52,221 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Reward Error: 0.0699, 0.0132, 0.0345
2024-09-18 21:50:52,904 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:416] - INFO: Optimal reward: 3.7806, 3.7806, 3.2051
Known param reward: [[3.7806432247161865, 3.4037325382232666, 3.1705894470214844], [3.4037325382232666, 3.7806432247161865, 3.017861843109131], [3.7406539916992188, 3.5228474140167236, 3.2050557136535645]], Known param reward error: [[0.0, 0.09969485722134351, 0.010753718409715467], [0.09969485722134351, 0.0, 0.05840580859389936], [0.010577362274106087, 0.06818834663215693, 0.0]].
