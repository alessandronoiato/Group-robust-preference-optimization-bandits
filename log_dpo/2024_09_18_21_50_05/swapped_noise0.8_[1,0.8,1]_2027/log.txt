2024-09-18 21:58:20,383 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log_dpo/2024_09_18_21_50_05/swapped_noise0.8_[1,0.8,1]_2027
2024-09-18 21:58:20,385 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2027
2024-09-18 21:58:20,386 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-09-18 21:58:20,553 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.3814, l2 distance: 23.7630, acc: 0.85.
2024-09-18 21:58:20,554 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-18 21:58:20,555 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [ 8.88080729  4.95567706 12.33493647  6.36297512]
2024-09-18 21:58:20,773 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.5399, 3.8381, 3.2082
2024-09-18 21:58:22,225 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:947] - INFO: Iteration:  0, train_loss:  20.9277, val_loss:  20.8443, grad_norm: 1.0557, reward_err: 0.1279, 0.0061, 0.0825, KL_dist: 0.3002, 0.0115, 0.1744, param: [3.1714331  0.41074722 3.10801959 0.49736071]train_grp_loss: [23.48810143 17.37963214 22.13389059], val_grp_loss: [23.69160656 15.95170578 22.87244775], train_hist_grp_loss: [23.54920731 17.56455197 22.21228308], cur_train_grp_loss: [23.54920731 17.56455197 22.21228308],max_reward_err:  0.1279, max_reward_err_index: 0, max_kl_dist:  0.3002, max_kl_dist_index: 0, max_train_grp_loss:  23.4881, max_train_grp_loss_index: 0, max_val_grp_loss:  23.6916, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  23.5492, max_cur_train_grp_loss_index: 0, 
2024-09-18 21:58:25,461 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:1040] - INFO: Iteration:  99, train_loss:  15.9194, val_loss:  16.2689, grad_norm: 0.4455, reward_err: 0.0807, 0.0075, 0.0427, KL_dist: 0.7371, 0.3190, 0.5537, param: [5.9154183  3.19161435 7.44346071 4.01893918]train_grp_loss: [20.09170937 10.39922705 17.41227136], val_grp_loss: [20.49465048  9.13789437 19.15163101], train_hist_grp_loss: [2148.10827557 1272.49738307 1942.28184613], cur_train_grp_loss: [20.10911967 10.41719048 17.44010327],max_reward_err:  0.0807, max_reward_err_index: 0, max_kl_dist:  0.7371, max_kl_dist_index: 0, max_train_grp_loss:  20.0917, max_train_grp_loss_index: 0, max_val_grp_loss:  20.4947, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  20.1091, max_cur_train_grp_loss_index: 0, 
2024-09-18 21:58:25,689 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:387] - INFO: Policy parameter learned solely on the preference data dpo: [5.9154183  3.19161435 7.44346071 4.01893918].
2024-09-18 21:58:26,035 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Uniform reward: 3.8205, 3.8205, 3.2153
2024-09-18 21:58:26,036 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Optimal reward: 3.8664, 3.8664, 3.3644
2024-09-18 21:58:26,036 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Policy reward: 3.5542, 3.8375, 3.2209
2024-09-18 21:58:26,037 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Reward Error: 0.0807, 0.0075, 0.0427
2024-09-18 21:58:26,733 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:416] - INFO: Optimal reward: 3.8664, 3.8664, 3.3644
Known param reward: [[3.866352081298828, 3.466999053955078, 3.324810028076172], [3.466999053955078, 3.866352081298828, 3.1610913276672363], [3.8258588314056396, 3.5992729663848877, 3.364398956298828]], Known param reward error: [[0.0, 0.10328935879258955, 0.011767013584562513], [0.10328935879258955, 0.0, 0.06042910822182941], [0.010473244298947946, 0.06907780494326327, 0.0]].
