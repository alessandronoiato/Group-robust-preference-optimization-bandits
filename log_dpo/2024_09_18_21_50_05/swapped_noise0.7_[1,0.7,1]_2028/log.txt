2024-09-18 22:01:53,787 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log_dpo/2024_09_18_21_50_05/swapped_noise0.7_[1,0.7,1]_2028
2024-09-18 22:01:53,789 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2028
2024-09-18 22:01:53,790 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-09-18 22:01:53,951 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.4872, l2 distance: 13.0978, acc: 0.77.
2024-09-18 22:01:53,952 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-18 22:01:53,952 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [6.46691538 3.95756071 6.43337544 5.0747662 ]
2024-09-18 22:01:54,159 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.6532, 3.8141, 3.2658
2024-09-18 22:01:55,609 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:947] - INFO: Iteration:  0, train_loss:  23.1672, val_loss:  23.1331, grad_norm: 0.9471, reward_err: 0.0085, 0.1698, 0.0290, KL_dist: 0.0307, 0.4146, 0.0490, param: [0.15974519 4.60263225 0.83195028 0.07094603]train_grp_loss: [23.00552402 23.47106284 22.9334222 ], val_grp_loss: [22.94021556 23.18201921 23.29500232], train_hist_grp_loss: [23.04070851 23.64095306 22.98652823], cur_train_grp_loss: [23.04070851 23.64095306 22.98652823],max_reward_err:  0.1698, max_reward_err_index: 1, max_kl_dist:  0.4146, max_kl_dist_index: 1, max_train_grp_loss:  23.4711, max_train_grp_loss_index: 1, max_val_grp_loss:  23.2950, max_val_grp_loss_index: 2, max_cur_train_grp_loss:  23.6410, max_cur_train_grp_loss_index: 1, 
2024-09-18 22:01:58,849 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:1040] - INFO: Iteration:  99, train_loss:  18.7861, val_loss:  18.3508, grad_norm: 0.4367, reward_err: 0.0287, 0.0446, 0.0067, KL_dist: 0.2544, 0.3058, 0.1926, param: [3.74979734 4.82694869 4.34481421 4.07139907]train_grp_loss: [21.14559622 15.61508812 19.69144644], val_grp_loss: [20.27785027 14.35465209 19.93591071], train_hist_grp_loss: [2188.39478749 1856.4451831  2107.59300335], cur_train_grp_loss: [21.15404565 15.64617836 19.71055699],max_reward_err:  0.0446, max_reward_err_index: 1, max_kl_dist:  0.3058, max_kl_dist_index: 1, max_train_grp_loss:  21.1456, max_train_grp_loss_index: 0, max_val_grp_loss:  20.2779, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  21.1540, max_cur_train_grp_loss_index: 0, 
2024-09-18 22:01:59,076 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:387] - INFO: Policy parameter learned solely on the preference data dpo: [3.74979734 4.82694869 4.34481421 4.07139907].
2024-09-18 22:01:59,413 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Uniform reward: 3.8371, 3.8371, 3.2123
2024-09-18 22:01:59,414 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Optimal reward: 3.8741, 3.8741, 3.3487
2024-09-18 22:01:59,414 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Policy reward: 3.7631, 3.7013, 3.3263
2024-09-18 22:01:59,415 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Reward Error: 0.0287, 0.0446, 0.0067
2024-09-18 22:02:00,104 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:416] - INFO: Optimal reward: 3.8741, 3.8741, 3.3487
Known param reward: [[3.8741343021392822, 3.4676833152770996, 3.31387996673584], [3.4676833152770996, 3.8741343021392822, 3.1369452476501465], [3.840017557144165, 3.611396074295044, 3.3486669063568115]], Known param reward error: [[0.0, 0.10491401566480076, 0.010388294982380973], [0.10491401566480076, 0.0, 0.0632256550523886], [0.008806288665903515, 0.06781856470467615, 0.0]].
