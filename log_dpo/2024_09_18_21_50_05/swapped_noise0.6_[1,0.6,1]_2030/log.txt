2024-09-18 22:05:33,335 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log_dpo/2024_09_18_21_50_05/swapped_noise0.6_[1,0.6,1]_2030
2024-09-18 22:05:33,337 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2030
2024-09-18 22:05:33,338 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-09-18 22:05:33,500 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.4961, l2 distance: 10.5890, acc: 0.77.
2024-09-18 22:05:33,500 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-18 22:05:33,501 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [5.36923291 3.75606204 5.9084699  3.85520782]
2024-09-18 22:05:33,713 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.5727, 3.7607, 3.2144
2024-09-18 22:05:35,153 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:947] - INFO: Iteration:  0, train_loss:  20.7513, val_loss:  21.1049, grad_norm: 0.7513, reward_err: 0.0039, 0.0833, 0.0030, KL_dist: 0.0276, 0.2755, 0.0305, param: [1.97802683 4.34569563 1.56217434 3.03577784]train_grp_loss: [21.69822928 19.7280751  21.69068766], val_grp_loss: [21.80248948 19.62325133 21.78802398], train_hist_grp_loss: [21.71797815 19.82017155 21.72094828], cur_train_grp_loss: [21.71797815 19.82017155 21.72094828],max_reward_err:  0.0833, max_reward_err_index: 1, max_kl_dist:  0.2755, max_kl_dist_index: 1, max_train_grp_loss:  21.6982, max_train_grp_loss_index: 0, max_val_grp_loss:  21.8025, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  21.7209, max_cur_train_grp_loss_index: 2, 
2024-09-18 22:05:38,394 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:1040] - INFO: Iteration:  99, train_loss:  18.1197, val_loss:  17.7771, grad_norm: 0.3292, reward_err: 0.0477, 0.0293, 0.0172, KL_dist: 0.4113, 0.3293, 0.3084, param: [5.35221157 4.20703606 4.76753525 4.74438667]train_grp_loss: [20.66931614 15.61408767 19.91560838], val_grp_loss: [20.67439922 12.50498441 19.73573892], train_hist_grp_loss: [2107.60655742 1713.64076839 2066.08105771], cur_train_grp_loss: [20.67398269 15.62973415 19.92554346],max_reward_err:  0.0477, max_reward_err_index: 0, max_kl_dist:  0.4113, max_kl_dist_index: 0, max_train_grp_loss:  20.6693, max_train_grp_loss_index: 0, max_val_grp_loss:  20.6744, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  20.6740, max_cur_train_grp_loss_index: 0, 
2024-09-18 22:05:38,623 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:387] - INFO: Policy parameter learned solely on the preference data dpo: [5.35221157 4.20703606 4.76753525 4.74438667].
2024-09-18 22:05:38,960 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Uniform reward: 3.7751, 3.7751, 3.1646
2024-09-18 22:05:38,961 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Optimal reward: 3.8138, 3.8138, 3.3081
2024-09-18 22:05:38,961 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Policy reward: 3.6319, 3.7020, 3.2511
2024-09-18 22:05:38,962 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Reward Error: 0.0477, 0.0293, 0.0172
2024-09-18 22:05:39,649 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:416] - INFO: Optimal reward: 3.8138, 3.8138, 3.3081
Known param reward: [[3.8138465881347656, 3.439753770828247, 3.273068904876709], [3.439753770828247, 3.8138465881347656, 3.121405839920044], [3.7787630558013916, 3.5612988471984863, 3.308058500289917]], Known param reward error: [[0.0, 0.09808806113763369, 0.010577078794145125], [0.09808806113763369, 0.0, 0.05642362743993641], [0.009198988874519018, 0.06621864175711184, 0.0]].
