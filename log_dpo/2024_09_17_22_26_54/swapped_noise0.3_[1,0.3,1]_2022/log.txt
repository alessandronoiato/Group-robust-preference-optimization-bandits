2024-09-17 22:27:17,284 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:198] - INFO: Logging to log_dpo/2024_09_17_22_26_54/swapped_noise0.3_[1,0.3,1]_2022
2024-09-17 22:27:17,285 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: (IB) Seed: 2022
2024-09-17 22:27:17,286 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Data: 300
2024-09-17 22:27:17,444 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:296] - INFO: MLE reward loss: 0.4690, l2 distance: 18.2092, acc: 0.81.
2024-09-17 22:27:17,445 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-17 22:27:17,446 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: MLE reward parameter: [10.22725597  3.87998046  6.967695    4.9739066 ]
2024-09-17 22:27:17,651 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:313] - INFO: Learned oracle reward: 3.5084, 3.8186, 3.1291
2024-09-17 22:27:18,945 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:947] - INFO: Iteration:  0, train_loss:  20.2912, val_loss:  20.2387, grad_norm: 0.5856, reward_err: 0.0131, 0.0725, 0.0009, KL_dist: 0.1143, 0.3236, 0.0967, param: [3.18502903 3.85803589 2.34511014 4.85981407]train_grp_loss: [21.04687447 19.13827831 20.714225  ], val_grp_loss: [21.00968244 19.06303205 20.65593824], train_hist_grp_loss: [21.05023239 19.20922151 20.74136986], cur_train_grp_loss: [21.05023239 19.20922151 20.74136986],max_reward_err:  0.0725, max_reward_err_index: 1, max_kl_dist:  0.3236, max_kl_dist_index: 1, max_train_grp_loss:  21.0469, max_train_grp_loss_index: 0, max_val_grp_loss:  21.0097, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  21.0502, max_cur_train_grp_loss_index: 0, 
2024-09-17 22:27:22,091 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:1040] - INFO: Iteration:  99, train_loss:  18.2163, val_loss:  18.3526, grad_norm: 0.3463, reward_err: 0.0608, 0.0231, 0.0273, KL_dist: 0.5719, 0.3586, 0.4393, param: [6.65840234 3.59203263 5.15523576 5.14234375]train_grp_loss: [20.92702127 15.02384295 18.79954972], val_grp_loss: [20.5587425  15.57680592 18.95986834], train_hist_grp_loss: [2096.08622814 1673.46703105 1966.67401627], cur_train_grp_loss: [20.92691425 15.04583632 18.81305515],max_reward_err:  0.0608, max_reward_err_index: 0, max_kl_dist:  0.5719, max_kl_dist_index: 0, max_train_grp_loss:  20.9270, max_train_grp_loss_index: 0, max_val_grp_loss:  20.5587, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  20.9269, max_cur_train_grp_loss_index: 0, 
2024-09-17 22:27:22,328 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:386] - INFO: Policy parameter learned solely on the preference data dpo: [6.65840234 3.59203263 5.15523576 5.14234375].
2024-09-17 22:27:22,642 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:397] - INFO: Uniform reward: 3.8062, 3.8062, 3.1654
2024-09-17 22:27:22,642 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Optimal reward: 3.8366, 3.8366, 3.2883
2024-09-17 22:27:22,643 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Policy reward: 3.6033, 3.7481, 3.1985
2024-09-17 22:27:22,643 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Reward Error: 0.0608, 0.0231, 0.0273
2024-09-17 22:27:23,304 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:415] - INFO: Optimal reward: 3.8366, 3.8366, 3.2883
Known param reward: [[3.8366410732269287, 3.45465350151062, 3.2577602863311768], [3.45465350151062, 3.8366410732269287, 3.1000757217407227], [3.801785469055176, 3.5611062049865723, 3.288270950317383]], Known param reward error: [[0.0, 0.09956301995042394, 0.009278634409144774], [0.09956301995042394, 0.0, 0.05723227538731126], [0.009084927025096074, 0.0718166914708571, 0.0]].
