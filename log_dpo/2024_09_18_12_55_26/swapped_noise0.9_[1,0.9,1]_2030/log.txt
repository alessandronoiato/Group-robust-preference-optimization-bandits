2024-09-18 13:18:10,463 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log_dpo/2024_09_18_12_55_26/swapped_noise0.9_[1,0.9,1]_2030
2024-09-18 13:18:10,465 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2030
2024-09-18 13:18:10,465 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-09-18 13:18:10,624 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.4341, l2 distance: 23.6252, acc: 0.80.
2024-09-18 13:18:10,625 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-18 13:18:10,626 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [11.04659098  5.03021714 10.54878401  5.92396953]
2024-09-18 13:18:10,834 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.5096, 3.7761, 3.1577
2024-09-18 13:18:12,120 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:947] - INFO: Iteration:  0, train_loss:  22.2981, val_loss:  21.9001, grad_norm: 0.8271, reward_err: 0.0427, 0.1003, 0.0317, KL_dist: 0.0557, 0.1556, 0.0454, param: [2.4521389  1.74220418 0.31916605 3.12390172]train_grp_loss: [22.84740554 21.43287381 22.70588806], val_grp_loss: [22.68865955 20.04051867 22.73812013], train_hist_grp_loss: [22.86363676 21.57978787 22.73875212], cur_train_grp_loss: [22.86363676 21.57978787 22.73875212],max_reward_err:  0.1003, max_reward_err_index: 1, max_kl_dist:  0.1556, max_kl_dist_index: 1, max_train_grp_loss:  22.8474, max_train_grp_loss_index: 0, max_val_grp_loss:  22.7381, max_val_grp_loss_index: 2, max_cur_train_grp_loss:  22.8636, max_cur_train_grp_loss_index: 0, 
2024-09-18 13:18:15,294 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:1040] - INFO: Iteration:  99, train_loss:  18.2065, val_loss:  17.7117, grad_norm: 0.4801, reward_err: 0.0750, 0.0087, 0.0393, KL_dist: 0.5772, 0.2221, 0.4261, param: [6.90601871 3.09306754 4.53811922 3.54492911]train_grp_loss: [21.90891244 12.86042453 20.46515491], val_grp_loss: [21.00206575 11.19289753 20.07590771], train_hist_grp_loss: [2229.76604278 1643.11188266 2146.58993956], cur_train_grp_loss: [21.91382972 12.90638645 20.4802721 ],max_reward_err:  0.0750, max_reward_err_index: 0, max_kl_dist:  0.5772, max_kl_dist_index: 0, max_train_grp_loss:  21.9089, max_train_grp_loss_index: 0, max_val_grp_loss:  21.0021, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  21.9138, max_cur_train_grp_loss_index: 0, 
2024-09-18 13:18:15,533 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:387] - INFO: Policy parameter learned solely on the preference data dpo: [6.90601871 3.09306754 4.53811922 3.54492911].
2024-09-18 13:18:15,851 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Uniform reward: 3.7539, 3.7539, 3.1386
2024-09-18 13:18:15,852 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Optimal reward: 3.7917, 3.7917, 3.2789
2024-09-18 13:18:15,852 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Policy reward: 3.5074, 3.7589, 3.1501
2024-09-18 13:18:15,853 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Reward Error: 0.0750, 0.0087, 0.0393
2024-09-18 13:18:16,516 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:416] - INFO: Optimal reward: 3.7917, 3.7917, 3.2789
Known param reward: [[3.7916831970214844, 3.4254605770111084, 3.243140459060669], [3.4254605770111084, 3.7916831970214844, 3.0971083641052246], [3.7576465606689453, 3.5452187061309814, 3.2788846492767334]], Known param reward error: [[0.0, 0.0965857644167261, 0.010901325920065232], [0.0965857644167261, 0.0, 0.055438450758432616], [0.00897665616665342, 0.065001340587766, 0.0]].
