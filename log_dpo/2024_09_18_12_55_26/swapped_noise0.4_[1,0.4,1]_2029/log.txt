2024-09-18 13:34:36,115 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log_dpo/2024_09_18_12_55_26/swapped_noise0.4_[1,0.4,1]_2029
2024-09-18 13:34:36,117 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2029
2024-09-18 13:34:36,118 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-09-18 13:34:36,282 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.5062, l2 distance: 12.7703, acc: 0.77.
2024-09-18 13:34:36,282 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-18 13:34:36,283 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [5.6354843  3.81766735 7.64960934 2.84511118]
2024-09-18 13:34:36,501 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.5316, 3.8517, 3.2027
2024-09-18 13:34:37,789 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:947] - INFO: Iteration:  0, train_loss:  21.7346, val_loss:  21.5556, grad_norm: 0.6871, reward_err: 0.0576, 0.0671, 0.0416, KL_dist: 0.1442, 0.1734, 0.1253, param: [3.77394804 3.28790746 0.227624   2.86674765]train_grp_loss: [22.37989131 21.21336718 21.69994451], val_grp_loss: [22.0764471  20.76255933 21.76876751], train_hist_grp_loss: [22.39143635 21.29663135 21.74034748], cur_train_grp_loss: [22.39143635 21.29663135 21.74034748],max_reward_err:  0.0671, max_reward_err_index: 1, max_kl_dist:  0.1734, max_kl_dist_index: 1, max_train_grp_loss:  22.3799, max_train_grp_loss_index: 0, max_val_grp_loss:  22.0764, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  22.3914, max_cur_train_grp_loss_index: 0, 
2024-09-18 13:34:41,000 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:1040] - INFO: Iteration:  99, train_loss:  18.9963, val_loss:  19.3132, grad_norm: 0.3852, reward_err: 0.0819, 0.0127, 0.0455, KL_dist: 0.5541, 0.2373, 0.4129, param: [6.95874153 3.7053612  4.20551478 3.41179689]train_grp_loss: [21.69213329 16.78147918 18.89435417], val_grp_loss: [21.05898928 16.99077965 19.71322497], train_hist_grp_loss: [2198.23568125 1854.30571611 2015.71436057], cur_train_grp_loss: [21.69603213 16.80155054 18.91376224],max_reward_err:  0.0819, max_reward_err_index: 0, max_kl_dist:  0.5541, max_kl_dist_index: 0, max_train_grp_loss:  21.6921, max_train_grp_loss_index: 0, max_val_grp_loss:  21.0590, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  21.6960, max_cur_train_grp_loss_index: 0, 
2024-09-18 13:34:41,230 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:387] - INFO: Policy parameter learned solely on the preference data dpo: [6.95874153 3.7053612  4.20551478 3.41179689].
2024-09-18 13:34:41,568 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Uniform reward: 3.8205, 3.8205, 3.2146
2024-09-18 13:34:41,569 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Optimal reward: 3.8668, 3.8668, 3.3614
2024-09-18 13:34:41,569 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Policy reward: 3.5500, 3.8175, 3.2083
2024-09-18 13:34:41,570 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Reward Error: 0.0819, 0.0127, 0.0455
2024-09-18 13:34:42,284 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:416] - INFO: Optimal reward: 3.8668, 3.8668, 3.3614
Known param reward: [[3.8667526245117188, 3.4561731815338135, 3.324531078338623], [3.4561731815338135, 3.8667526245117188, 3.1526591777801514], [3.8306260108947754, 3.5890326499938965, 3.3613686561584473]], Known param reward error: [[0.0, 0.10618197822513974, 0.01095910076757965], [0.10618197822513974, 0.0, 0.062090624304452315], [0.009342882031794137, 0.07182253469159845, 0.0]].
