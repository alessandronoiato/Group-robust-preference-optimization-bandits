2024-09-18 13:28:09,219 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log_dpo/2024_09_18_12_55_26/swapped_noise0.6_[1,0.6,1]_2028
2024-09-18 13:28:09,221 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2028
2024-09-18 13:28:09,221 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-09-18 13:28:09,385 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.5479, l2 distance: 10.6788, acc: 0.76.
2024-09-18 13:28:09,385 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-18 13:28:09,386 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [5.83457493 2.77303332 5.60181542 4.29838515]
2024-09-18 13:28:09,591 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.6137, 3.8197, 3.2373
2024-09-18 13:28:10,862 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:947] - INFO: Iteration:  0, train_loss:  20.2361, val_loss:  18.8826, grad_norm: 0.3118, reward_err: 0.0383, 0.0283, 0.0123, KL_dist: 0.3379, 0.2878, 0.2484, param: [4.60004607 4.17248749 4.71142943 4.37817418]train_grp_loss: [21.55296992 18.54231228 20.18920869], val_grp_loss: [20.68508692 15.89001588 19.86535592], train_hist_grp_loss: [21.55326054 18.56472792 20.19861939], cur_train_grp_loss: [21.55326054 18.56472792 20.19861939],max_reward_err:  0.0383, max_reward_err_index: 0, max_kl_dist:  0.3379, max_kl_dist_index: 0, max_train_grp_loss:  21.5530, max_train_grp_loss_index: 0, max_val_grp_loss:  20.6851, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  21.5533, max_cur_train_grp_loss_index: 0, 
2024-09-18 13:28:14,026 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:1040] - INFO: Iteration:  99, train_loss:  19.6335, val_loss:  18.0815, grad_norm: 0.1887, reward_err: 0.0573, 0.0155, 0.0252, KL_dist: 0.6263, 0.3827, 0.4774, param: [6.3147813  3.95859283 6.34511991 4.82877423]train_grp_loss: [21.56997316 17.19890158 19.50910941], val_grp_loss: [20.3948237  14.50051162 19.08856001], train_hist_grp_loss: [2155.56107086 1776.48024145 1981.98203856], cur_train_grp_loss: [21.5695381  17.20634876 19.51402345],max_reward_err:  0.0573, max_reward_err_index: 0, max_kl_dist:  0.6263, max_kl_dist_index: 0, max_train_grp_loss:  21.5700, max_train_grp_loss_index: 0, max_val_grp_loss:  20.3948, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  21.5695, max_cur_train_grp_loss_index: 0, 
2024-09-18 13:28:14,252 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:387] - INFO: Policy parameter learned solely on the preference data dpo: [6.3147813  3.95859283 6.34511991 4.82877423].
2024-09-18 13:28:14,575 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Uniform reward: 3.8339, 3.8339, 3.2071
2024-09-18 13:28:14,576 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Optimal reward: 3.8707, 3.8707, 3.3444
2024-09-18 13:28:14,577 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Policy reward: 3.6488, 3.8107, 3.2600
2024-09-18 13:28:14,577 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Reward Error: 0.0573, 0.0155, 0.0252
2024-09-18 13:28:15,242 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:416] - INFO: Optimal reward: 3.8707, 3.8707, 3.3444
Known param reward: [[3.870683431625366, 3.460294485092163, 3.3091318607330322], [3.460294485092163, 3.870683431625366, 3.128795862197876], [3.837958335876465, 3.610339403152466, 3.34438419342041]], Known param reward error: [[0.0, 0.10602493171622505, 0.01054075448530458], [0.10602493171622505, 0.0, 0.06446278858950263], [0.008454604032332228, 0.0672604807579362, 0.0]].
