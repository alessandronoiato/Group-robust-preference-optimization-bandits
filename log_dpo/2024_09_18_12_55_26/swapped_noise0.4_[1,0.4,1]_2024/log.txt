2024-09-18 13:33:02,341 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log_dpo/2024_09_18_12_55_26/swapped_noise0.4_[1,0.4,1]_2024
2024-09-18 13:33:02,343 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2024
2024-09-18 13:33:02,343 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-09-18 13:33:02,513 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.4993, l2 distance: 17.5270, acc: 0.79.
2024-09-18 13:33:02,514 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-18 13:33:02,515 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [8.23705571 4.39496946 7.61601428 6.6496933 ]
2024-09-18 13:33:02,727 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.5858, 3.7073, 3.1668
2024-09-18 13:33:04,020 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:947] - INFO: Iteration:  0, train_loss:  21.0270, val_loss:  20.7019, grad_norm: 0.5512, reward_err: 0.0639, 0.0357, 0.0323, KL_dist: 0.2145, 0.0914, 0.1186, param: [3.11344911 0.93646999 3.78330711 3.31130111]train_grp_loss: [22.85820834 17.93771134 21.84375426], val_grp_loss: [22.56481839 17.64652962 21.77768714], train_hist_grp_loss: [22.88058282 17.97736902 21.87395931], cur_train_grp_loss: [22.88058282 17.97736902 21.87395931],max_reward_err:  0.0639, max_reward_err_index: 0, max_kl_dist:  0.2145, max_kl_dist_index: 0, max_train_grp_loss:  22.8582, max_train_grp_loss_index: 0, max_val_grp_loss:  22.5648, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  22.8806, max_cur_train_grp_loss_index: 0, 
2024-09-18 13:33:07,234 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:1040] - INFO: Iteration:  99, train_loss:  19.1680, val_loss:  18.7284, grad_norm: 0.3305, reward_err: 0.0571, 0.0280, 0.0265, KL_dist: 0.5564, 0.3560, 0.4152, param: [5.40203376 2.77923581 6.18248408 5.22086382]train_grp_loss: [21.31085669 16.07400503 19.67724004], val_grp_loss: [20.83035562 15.67929019 19.55705375], train_hist_grp_loss: [2200.50556101 1675.93722207 2066.40477083], cur_train_grp_loss: [21.3214024  16.07992395 19.69274555],max_reward_err:  0.0571, max_reward_err_index: 0, max_kl_dist:  0.5564, max_kl_dist_index: 0, max_train_grp_loss:  21.3109, max_train_grp_loss_index: 0, max_val_grp_loss:  20.8304, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  21.3214, max_cur_train_grp_loss_index: 0, 
2024-09-18 13:33:07,465 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:387] - INFO: Policy parameter learned solely on the preference data dpo: [5.40203376 2.77923581 6.18248408 5.22086382].
2024-09-18 13:33:07,796 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Uniform reward: 3.7439, 3.7439, 3.0964
2024-09-18 13:33:07,796 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Optimal reward: 3.7882, 3.7882, 3.2414
2024-09-18 13:33:07,797 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Policy reward: 3.5720, 3.6822, 3.1556
2024-09-18 13:33:07,797 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Reward Error: 0.0571, 0.0280, 0.0265
2024-09-18 13:33:08,478 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:416] - INFO: Optimal reward: 3.7882, 3.7882, 3.2414
Known param reward: [[3.7881884574890137, 3.4343247413635254, 3.2098934650421143], [3.4343247413635254, 3.7881884574890137, 3.060838222503662], [3.7553627490997314, 3.5580506324768066, 3.2413690090179443]], Known param reward error: [[0.0, 0.093412384335294, 0.009710571023620171], [0.093412384335294, 0.0, 0.055695845185173364], [0.008665278604180274, 0.06075141920598982, 0.0]].
