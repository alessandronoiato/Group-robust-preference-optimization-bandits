2024-09-18 12:56:07,806 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log_dpo/2024_09_18_12_55_26/swapped_noise1.0_[1,1.0,1]_2023
2024-09-18 12:56:07,808 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2023
2024-09-18 12:56:07,808 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-09-18 12:56:07,973 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.3640, l2 distance: 33.1940, acc: 0.79.
2024-09-18 12:56:07,973 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-18 12:56:07,974 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [12.21044287  7.99401411 15.4309833   8.31914459]
2024-09-18 12:56:08,175 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.5753, 3.8283, 3.1796
2024-09-18 12:56:09,455 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:947] - INFO: Iteration:  0, train_loss:  22.1284, val_loss:  21.8888, grad_norm: 0.8964, reward_err: 0.0115, 0.1078, 0.0188, KL_dist: 0.0293, 0.2456, 0.0455, param: [1.93940756 2.69727665 0.18326845 3.71020915]train_grp_loss: [22.35078318 21.57730933 22.51322064], val_grp_loss: [22.09221962 21.24005892 22.30525939], train_hist_grp_loss: [22.3674583  21.74878601 22.55788494], cur_train_grp_loss: [22.3674583  21.74878601 22.55788494],max_reward_err:  0.1078, max_reward_err_index: 1, max_kl_dist:  0.2456, max_kl_dist_index: 1, max_train_grp_loss:  22.5132, max_train_grp_loss_index: 2, max_val_grp_loss:  22.3053, max_val_grp_loss_index: 2, max_cur_train_grp_loss:  22.5579, max_cur_train_grp_loss_index: 2, 
2024-09-18 12:56:12,599 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:1040] - INFO: Iteration:  99, train_loss:  17.2780, val_loss:  17.1113, grad_norm: 0.5262, reward_err: 0.0652, 0.0143, 0.0307, KL_dist: 0.5310, 0.2947, 0.3986, param: [6.26464584 3.54445865 5.4007608  4.32884323]train_grp_loss: [21.45775146 11.34910095 19.51723193], val_grp_loss: [20.20868164 11.17785075 19.7694004 ], train_hist_grp_loss: [2181.26619375 1565.41381583 2084.64567225], cur_train_grp_loss: [21.4617414  11.40592695 19.53703973],max_reward_err:  0.0652, max_reward_err_index: 0, max_kl_dist:  0.5310, max_kl_dist_index: 0, max_train_grp_loss:  21.4578, max_train_grp_loss_index: 0, max_val_grp_loss:  20.2087, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  21.4617, max_cur_train_grp_loss_index: 0, 
2024-09-18 12:56:12,814 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:387] - INFO: Policy parameter learned solely on the preference data dpo: [6.26464584 3.54445865 5.4007608  4.32884323].
2024-09-18 12:56:13,144 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Uniform reward: 3.8165, 3.8165, 3.1738
2024-09-18 12:56:13,144 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Optimal reward: 3.8573, 3.8573, 3.3040
2024-09-18 12:56:13,145 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Policy reward: 3.6057, 3.8021, 3.2027
2024-09-18 12:56:13,145 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Reward Error: 0.0652, 0.0143, 0.0307
2024-09-18 12:56:13,806 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:416] - INFO: Optimal reward: 3.8573, 3.8573, 3.3040
Known param reward: [[3.8573076725006104, 3.4820022583007812, 3.2755494117736816], [3.4820022583007812, 3.8573076725006104, 3.1173529624938965], [3.8217499256134033, 3.595449686050415, 3.3040339946746826]], Known param reward error: [[0.0, 0.09729724617910154, 0.008621153095552695], [0.09729724617910154, 0.0, 0.05650094172204995], [0.00921828122260097, 0.06788620682685609, 0.0]].
