2024-09-18 13:37:42,443 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log_dpo/2024_09_18_12_55_26/swapped_noise0.3_[1,0.3,1]_2029
2024-09-18 13:37:42,445 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2029
2024-09-18 13:37:42,445 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-09-18 13:37:42,610 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.5283, l2 distance: 10.5358, acc: 0.78.
2024-09-18 13:37:42,611 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-18 13:37:42,612 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [6.17680958 2.52010835 5.71404645 2.41442656]
2024-09-18 13:37:42,814 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.4885, 3.8396, 3.1360
2024-09-18 13:37:44,096 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:947] - INFO: Iteration:  0, train_loss:  20.0963, val_loss:  20.2031, grad_norm: 0.4756, reward_err: 0.0639, 0.0213, 0.0287, KL_dist: 0.2957, 0.1483, 0.1955, param: [4.74658836 3.04687391 3.75480251 3.35469111]train_grp_loss: [21.20203632 18.67129425 20.64646401], val_grp_loss: [21.7980251  17.64911224 21.02362563], train_hist_grp_loss: [21.2135987  18.70662584 20.66513899], cur_train_grp_loss: [21.2135987  18.70662584 20.66513899],max_reward_err:  0.0639, max_reward_err_index: 0, max_kl_dist:  0.2957, max_kl_dist_index: 0, max_train_grp_loss:  21.2020, max_train_grp_loss_index: 0, max_val_grp_loss:  21.7980, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  21.2136, max_cur_train_grp_loss_index: 0, 
2024-09-18 13:37:47,260 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:1040] - INFO: Iteration:  99, train_loss:  18.8013, val_loss:  19.3448, grad_norm: 0.2624, reward_err: 0.0868, 0.0041, 0.0462, KL_dist: 0.7449, 0.3045, 0.5578, param: [7.27527735 3.53833366 6.1701124  3.22877887]train_grp_loss: [20.43539727 16.93519727 19.33960528], val_grp_loss: [21.47526724 16.3486335  20.03285873], train_hist_grp_loss: [2077.41047131 1759.40725096 1992.93513282], cur_train_grp_loss: [20.44040735 16.94169804 19.34870464],max_reward_err:  0.0868, max_reward_err_index: 0, max_kl_dist:  0.7449, max_kl_dist_index: 0, max_train_grp_loss:  20.4354, max_train_grp_loss_index: 0, max_val_grp_loss:  21.4753, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  20.4404, max_cur_train_grp_loss_index: 0, 
2024-09-18 13:37:47,487 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:387] - INFO: Policy parameter learned solely on the preference data dpo: [7.27527735 3.53833366 6.1701124  3.22877887].
2024-09-18 13:37:47,814 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Uniform reward: 3.8042, 3.8042, 3.1701
2024-09-18 13:37:47,815 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Optimal reward: 3.8441, 3.8441, 3.3031
2024-09-18 13:37:47,815 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Policy reward: 3.5102, 3.8285, 3.1504
2024-09-18 13:37:47,816 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Reward Error: 0.0868, 0.0041, 0.0462
2024-09-18 13:37:48,492 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:416] - INFO: Optimal reward: 3.8441, 3.8441, 3.3031
Known param reward: [[3.8440520763397217, 3.454845666885376, 3.27467942237854], [3.454845666885376, 3.8440520763397217, 3.1118218898773193], [3.806739330291748, 3.5654454231262207, 3.3031394481658936]], Known param reward error: [[0.0, 0.10124899499929386, 0.008616053374057906], [0.10124899499929386, 0.0, 0.057919915671379094], [0.009706618252555662, 0.07247733581143058, 0.0]].
