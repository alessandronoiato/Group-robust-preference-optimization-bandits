2024-09-18 13:17:51,995 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log_dpo/2024_09_18_12_55_26/swapped_noise0.9_[1,0.9,1]_2029
2024-09-18 13:17:51,997 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2029
2024-09-18 13:17:51,998 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-09-18 13:17:52,161 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.3652, l2 distance: 29.0167, acc: 0.83.
2024-09-18 13:17:52,162 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-18 13:17:52,163 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [13.58728005  5.58538091 11.73484358  7.63338983]
2024-09-18 13:17:52,373 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.5545, 3.8681, 3.2297
2024-09-18 13:17:53,677 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:947] - INFO: Iteration:  0, train_loss:  19.8573, val_loss:  20.2836, grad_norm: 0.8461, reward_err: 0.0480, 0.0366, 0.0215, KL_dist: 0.1143, 0.0933, 0.0578, param: [3.39828224 2.65974019 1.97158904 2.6390082 ]train_grp_loss: [22.07730897 16.25218083 21.81448978], val_grp_loss: [21.96466286 16.66000315 21.9660787 ], train_hist_grp_loss: [22.10476071 16.3861118  21.85712012], cur_train_grp_loss: [22.10476071 16.3861118  21.85712012],max_reward_err:  0.0480, max_reward_err_index: 0, max_kl_dist:  0.1143, max_kl_dist_index: 0, max_train_grp_loss:  22.0773, max_train_grp_loss_index: 0, max_val_grp_loss:  21.9661, max_val_grp_loss_index: 2, max_cur_train_grp_loss:  22.1048, max_cur_train_grp_loss_index: 0, 
2024-09-18 13:17:56,770 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:1040] - INFO: Iteration:  99, train_loss:  15.9250, val_loss:  16.8147, grad_norm: 0.4472, reward_err: 0.0818, 0.0086, 0.0429, KL_dist: 0.7410, 0.3637, 0.5620, param: [7.60091998 3.32665353 5.93586729 4.6081332 ]train_grp_loss: [20.47460026  9.30289886 19.05791153], val_grp_loss: [20.10914175 10.32018905 19.53278199], train_hist_grp_loss: [2114.30232599 1205.01248651 2026.30879384], cur_train_grp_loss: [20.48325814  9.33465345 19.07534579],max_reward_err:  0.0818, max_reward_err_index: 0, max_kl_dist:  0.7410, max_kl_dist_index: 0, max_train_grp_loss:  20.4746, max_train_grp_loss_index: 0, max_val_grp_loss:  20.1091, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  20.4833, max_cur_train_grp_loss_index: 0, 
2024-09-18 13:17:56,988 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:387] - INFO: Policy parameter learned solely on the preference data dpo: [7.60091998 3.32665353 5.93586729 4.6081332 ].
2024-09-18 13:17:57,311 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Uniform reward: 3.8399, 3.8399, 3.2334
2024-09-18 13:17:57,312 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Optimal reward: 3.8872, 3.8872, 3.3828
2024-09-18 13:17:57,312 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Policy reward: 3.5692, 3.8536, 3.2377
2024-09-18 13:17:57,313 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Reward Error: 0.0818, 0.0086, 0.0429
2024-09-18 13:17:57,968 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:416] - INFO: Optimal reward: 3.8872, 3.8872, 3.3828
Known param reward: [[3.8871653079986572, 3.4750781059265137, 3.3463027477264404], [3.4750781059265137, 3.8871653079986572, 3.1734652519226074], [3.8522720336914062, 3.6094093322753906, 3.38283634185791]], Known param reward error: [[0.0, 0.10601226585969672, 0.010799693050301354], [0.10601226585969672, 0.0, 0.06189217235981113], [0.00897653470909785, 0.0714546343454253, 0.0]].
