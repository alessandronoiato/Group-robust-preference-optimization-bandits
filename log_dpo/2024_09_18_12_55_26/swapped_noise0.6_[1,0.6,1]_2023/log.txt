2024-09-18 13:26:33,539 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log_dpo/2024_09_18_12_55_26/swapped_noise0.6_[1,0.6,1]_2023
2024-09-18 13:26:33,541 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2023
2024-09-18 13:26:33,541 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-09-18 13:26:33,702 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.4922, l2 distance: 15.4423, acc: 0.77.
2024-09-18 13:26:33,703 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-18 13:26:33,704 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [7.81608134 4.07221289 7.64012895 4.02565407]
2024-09-18 13:26:33,910 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.5230, 3.7882, 3.1263
2024-09-18 13:26:35,191 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:947] - INFO: Iteration:  0, train_loss:  19.7494, val_loss:  19.6708, grad_norm: 0.5261, reward_err: 0.0517, 0.0420, 0.0203, KL_dist: 0.3040, 0.2429, 0.2118, param: [4.71144912 4.74314343 4.04669184 2.52799592]train_grp_loss: [21.8332363  17.431256   20.14667623], val_grp_loss: [20.9616716  17.38621945 20.66168262], train_hist_grp_loss: [21.83843107 17.48622855 20.16719873], cur_train_grp_loss: [21.83843107 17.48622855 20.16719873],max_reward_err:  0.0517, max_reward_err_index: 0, max_kl_dist:  0.3040, max_kl_dist_index: 0, max_train_grp_loss:  21.8332, max_train_grp_loss_index: 0, max_val_grp_loss:  20.9617, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  21.8384, max_cur_train_grp_loss_index: 0, 
2024-09-18 13:26:38,323 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:1040] - INFO: Iteration:  99, train_loss:  18.2114, val_loss:  18.4064, grad_norm: 0.2834, reward_err: 0.0708, 0.0107, 0.0341, KL_dist: 0.7476, 0.3906, 0.5767, param: [7.29883148 4.28403422 6.45557536 3.9592352 ]train_grp_loss: [21.58693761 14.55437215 18.74443763], val_grp_loss: [20.17182855 15.54417317 19.50992925], train_hist_grp_loss: [2167.73828498 1569.87207724 1937.16003535], cur_train_grp_loss: [21.58768411 14.56788646 18.75395528],max_reward_err:  0.0708, max_reward_err_index: 0, max_kl_dist:  0.7476, max_kl_dist_index: 0, max_train_grp_loss:  21.5869, max_train_grp_loss_index: 0, max_val_grp_loss:  20.1718, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  21.5877, max_cur_train_grp_loss_index: 0, 
2024-09-18 13:26:38,538 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:387] - INFO: Policy parameter learned solely on the preference data dpo: [7.29883148 4.28403422 6.45557536 3.9592352 ].
2024-09-18 13:26:38,853 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Uniform reward: 3.7732, 3.7732, 3.1224
2024-09-18 13:26:38,854 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Optimal reward: 3.8078, 3.8078, 3.2459
2024-09-18 13:26:38,854 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Policy reward: 3.5381, 3.7670, 3.1351
2024-09-18 13:26:38,855 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Reward Error: 0.0708, 0.0107, 0.0341
2024-09-18 13:26:39,521 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:416] - INFO: Optimal reward: 3.8078, 3.8078, 3.2459
Known param reward: [[3.807837963104248, 3.4243876934051514, 3.211453914642334], [3.4243876934051514, 3.807837963104248, 3.0547919273376465], [3.768700122833252, 3.5474116802215576, 3.245870590209961]], Known param reward error: [[0.0, 0.10070025915349037, 0.01060321864692723], [0.10070025915349037, 0.0, 0.05886823197715792], [0.010278231545097027, 0.06839216516198189, 0.0]].
