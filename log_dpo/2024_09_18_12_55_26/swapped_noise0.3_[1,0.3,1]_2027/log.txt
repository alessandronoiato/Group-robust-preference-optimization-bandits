2024-09-18 13:37:04,987 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log_dpo/2024_09_18_12_55_26/swapped_noise0.3_[1,0.3,1]_2027
2024-09-18 13:37:04,989 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2027
2024-09-18 13:37:04,989 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-09-18 13:37:05,151 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.4935, l2 distance: 15.3927, acc: 0.81.
2024-09-18 13:37:05,152 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-18 13:37:05,153 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [7.5757812  4.13887051 6.87684585 5.87984426]
2024-09-18 13:37:05,356 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.6175, 3.7697, 3.2662
2024-09-18 13:37:06,635 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:947] - INFO: Iteration:  0, train_loss:  22.6872, val_loss:  22.5872, grad_norm: 0.7524, reward_err: 0.0503, 0.0902, 0.0337, KL_dist: 0.0618, 0.1420, 0.0408, param: [2.19235163 2.99603369 0.45324862 0.87000833]train_grp_loss: [23.06841447 22.10631014 22.81305913], val_grp_loss: [22.98660273 21.59065572 23.15036338], train_hist_grp_loss: [23.10262436 22.19790493 22.8610659 ], cur_train_grp_loss: [23.10262436 22.19790493 22.8610659 ],max_reward_err:  0.0902, max_reward_err_index: 1, max_kl_dist:  0.1420, max_kl_dist_index: 1, max_train_grp_loss:  23.0684, max_train_grp_loss_index: 0, max_val_grp_loss:  23.1504, max_val_grp_loss_index: 2, max_cur_train_grp_loss:  23.1026, max_cur_train_grp_loss_index: 0, 
2024-09-18 13:37:09,840 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:1040] - INFO: Iteration:  99, train_loss:  19.3649, val_loss:  19.6290, grad_norm: 0.4306, reward_err: 0.0541, 0.0283, 0.0231, KL_dist: 0.3421, 0.2552, 0.2480, param: [5.34887642 3.93150047 3.70909245 4.13341807]train_grp_loss: [20.7481901  17.68119542 19.4539827 ], val_grp_loss: [20.52178913 17.86188465 20.44634712], train_hist_grp_loss: [2178.1464105  1934.88392211 2097.00258962], cur_train_grp_loss: [20.76366855 17.69746542 19.47739562],max_reward_err:  0.0541, max_reward_err_index: 0, max_kl_dist:  0.3421, max_kl_dist_index: 0, max_train_grp_loss:  20.7482, max_train_grp_loss_index: 0, max_val_grp_loss:  20.5218, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  20.7637, max_cur_train_grp_loss_index: 0, 
2024-09-18 13:37:10,060 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:387] - INFO: Policy parameter learned solely on the preference data dpo: [5.34887642 3.93150047 3.70909245 4.13341807].
2024-09-18 13:37:10,387 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Uniform reward: 3.8069, 3.8069, 3.2022
2024-09-18 13:37:10,388 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Optimal reward: 3.8516, 3.8516, 3.3521
2024-09-18 13:37:10,389 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Policy reward: 3.6434, 3.7425, 3.2747
2024-09-18 13:37:10,389 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Reward Error: 0.0541, 0.0283, 0.0231
2024-09-18 13:37:11,064 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:416] - INFO: Optimal reward: 3.8516, 3.8516, 3.3521
Known param reward: [[3.8516299724578857, 3.4543135166168213, 3.311732530593872], [3.4543135166168213, 3.8516299724578857, 3.15214204788208], [3.8093669414520264, 3.581690788269043, 3.3521463871002197]], Known param reward error: [[0.0, 0.10315540658946536, 0.012056113259811346], [0.10315540658946536, 0.0, 0.05966455999290465], [0.010972765117125093, 0.07008440221909046, 0.0]].
