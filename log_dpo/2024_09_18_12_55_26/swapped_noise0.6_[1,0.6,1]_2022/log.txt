2024-09-18 13:24:57,688 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log_dpo/2024_09_18_12_55_26/swapped_noise0.6_[1,0.6,1]_2022
2024-09-18 13:24:57,690 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2022
2024-09-18 13:24:57,691 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-09-18 13:24:57,847 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.4365, l2 distance: 24.4634, acc: 0.77.
2024-09-18 13:24:57,848 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-18 13:24:57,849 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [12.20053812  4.12955839  9.69131822  7.01616498]
2024-09-18 13:24:58,049 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.5748, 3.8395, 3.1822
2024-09-18 13:24:59,332 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:947] - INFO: Iteration:  0, train_loss:  22.1379, val_loss:  22.1645, grad_norm: 0.7371, reward_err: 0.0747, 0.0709, 0.0552, KL_dist: 0.1480, 0.1330, 0.1063, param: [0.34214442 0.28017761 3.35160488 3.20559435]train_grp_loss: [23.07250815 20.09370697 23.27312795], val_grp_loss: [23.08407361 20.44821781 22.86411565], train_hist_grp_loss: [23.10774702 20.18803926 23.30564569], cur_train_grp_loss: [23.10774702 20.18803926 23.30564569],max_reward_err:  0.0747, max_reward_err_index: 0, max_kl_dist:  0.1480, max_kl_dist_index: 0, max_train_grp_loss:  23.2731, max_train_grp_loss_index: 2, max_val_grp_loss:  23.0841, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  23.3056, max_cur_train_grp_loss_index: 2, 
2024-09-18 13:25:02,506 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:1040] - INFO: Iteration:  99, train_loss:  18.6334, val_loss:  18.5403, grad_norm: 0.4693, reward_err: 0.0689, 0.0232, 0.0379, KL_dist: 0.5343, 0.2776, 0.4002, param: [4.46172635 2.09344589 6.78031664 4.67081016]train_grp_loss: [20.63778789 14.35424364 20.96451658], val_grp_loss: [21.11246748 14.43598361 19.8532701 ], train_hist_grp_loss: [2173.08998721 1679.11706153 2201.22728037], cur_train_grp_loss: [20.6544809  14.38695044 20.98088073],max_reward_err:  0.0689, max_reward_err_index: 0, max_kl_dist:  0.5343, max_kl_dist_index: 0, max_train_grp_loss:  20.9645, max_train_grp_loss_index: 2, max_val_grp_loss:  21.1125, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  20.9809, max_cur_train_grp_loss_index: 2, 
2024-09-18 13:25:02,728 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:387] - INFO: Policy parameter learned solely on the preference data dpo: [4.46172635 2.09344589 6.78031664 4.67081016].
2024-09-18 13:25:03,045 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Uniform reward: 3.8381, 3.8381, 3.1923
2024-09-18 13:25:03,045 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Optimal reward: 3.8683, 3.8683, 3.3211
2024-09-18 13:25:03,046 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Policy reward: 3.6017, 3.7787, 3.1953
2024-09-18 13:25:03,046 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Reward Error: 0.0689, 0.0232, 0.0379
2024-09-18 13:25:03,794 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:416] - INFO: Optimal reward: 3.8683, 3.8683, 3.3211
Known param reward: [[3.8683152198791504, 3.5409886837005615, 3.2718687057495117], [3.5409886837005615, 3.8683152198791504, 3.1612870693206787], [3.825526475906372, 3.6363391876220703, 3.3211145401000977]], Known param reward error: [[0.0, 0.08461733792956377, 0.014828104769039877], [0.08461733792956377, 0.0, 0.048124648773661925], [0.011061338474405682, 0.059968233991108726, 0.0]].
