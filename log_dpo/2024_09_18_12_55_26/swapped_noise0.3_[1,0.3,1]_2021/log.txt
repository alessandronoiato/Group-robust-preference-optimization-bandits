2024-09-18 13:35:13,348 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log_dpo/2024_09_18_12_55_26/swapped_noise0.3_[1,0.3,1]_2021
2024-09-18 13:35:13,350 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2021
2024-09-18 13:35:13,351 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-09-18 13:35:13,513 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.5459, l2 distance: 9.5949, acc: 0.76.
2024-09-18 13:35:13,514 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-18 13:35:13,515 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [5.14645297 2.17027301 5.65774903 3.64849919]
2024-09-18 13:35:13,720 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.5048, 3.7725, 3.1313
2024-09-18 13:35:15,016 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:947] - INFO: Iteration:  0, train_loss:  22.3880, val_loss:  21.0730, grad_norm: 0.6627, reward_err: 0.0306, 0.0830, 0.0099, KL_dist: 0.0858, 0.2415, 0.0387, param: [2.6804919  4.74091387 2.43023458 0.70889214]train_grp_loss: [22.10053344 23.23691074 21.75233492], val_grp_loss: [22.13113018 19.28118346 21.8167597 ], train_hist_grp_loss: [22.11924799 23.32164098 21.77721753], cur_train_grp_loss: [22.11924799 23.32164098 21.77721753],max_reward_err:  0.0830, max_reward_err_index: 1, max_kl_dist:  0.2415, max_kl_dist_index: 1, max_train_grp_loss:  23.2369, max_train_grp_loss_index: 1, max_val_grp_loss:  22.1311, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  23.3216, max_cur_train_grp_loss_index: 1, 
2024-09-18 13:35:18,151 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:1040] - INFO: Iteration:  99, train_loss:  19.9729, val_loss:  19.1955, grad_norm: 0.3500, reward_err: 0.0636, 0.0135, 0.0291, KL_dist: 0.4395, 0.2135, 0.3110, param: [5.22361799 3.62504371 5.29097485 3.40438516]train_grp_loss: [20.87306338 19.07337105 20.01960537], val_grp_loss: [21.09645008 16.24318103 20.26826135], train_hist_grp_loss: [2141.23706696 2066.48159512 2080.00759058], cur_train_grp_loss: [20.88092406 19.08991512 20.03160491],max_reward_err:  0.0636, max_reward_err_index: 0, max_kl_dist:  0.4395, max_kl_dist_index: 0, max_train_grp_loss:  20.8731, max_train_grp_loss_index: 0, max_val_grp_loss:  21.0965, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  20.8809, max_cur_train_grp_loss_index: 0, 
2024-09-18 13:35:18,380 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:387] - INFO: Policy parameter learned solely on the preference data dpo: [5.22361799 3.62504371 5.29097485 3.40438516].
2024-09-18 13:35:18,710 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Uniform reward: 3.7839, 3.7839, 3.1489
2024-09-18 13:35:18,711 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Optimal reward: 3.8160, 3.8160, 3.2742
2024-09-18 13:35:18,711 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Policy reward: 3.5733, 3.7647, 3.1788
2024-09-18 13:35:18,712 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Reward Error: 0.0636, 0.0135, 0.0291
2024-09-18 13:35:19,387 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:416] - INFO: Optimal reward: 3.8160, 3.8160, 3.2742
Known param reward: [[3.816042423248291, 3.418431043624878, 3.2406399250030518], [3.418431043624878, 3.816042423248291, 3.0701699256896973], [3.7798354625701904, 3.5481436252593994, 3.2741682529449463]], Known param reward error: [[0.0, 0.10419469584537752, 0.01024025809050513], [0.10419469584537752, 0.0, 0.062305389184493805], [0.00948809176164255, 0.07020330705884838, 0.0]].
