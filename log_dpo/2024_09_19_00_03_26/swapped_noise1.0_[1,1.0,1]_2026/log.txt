2024-09-19 00:05:18,977 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log_dpo/2024_09_19_00_03_26/swapped_noise1.0_[1,1.0,1]_2026
2024-09-19 00:05:18,979 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2026
2024-09-19 00:05:18,980 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-09-19 00:05:19,138 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.3205, l2 distance: 37.0255, acc: 0.85.
2024-09-19 00:05:19,139 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-19 00:05:19,140 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [16.29530932  7.55488527 15.66290624  7.13011982]
2024-09-19 00:05:19,346 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.5156, 3.8430, 3.1442
2024-09-19 00:05:20,753 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:947] - INFO: Iteration:  0, train_loss:  18.8333, val_loss:  18.6437, grad_norm: 0.7952, reward_err: 0.0557, 0.0523, 0.0281, KL_dist: 0.2579, 0.2323, 0.1945, param: [2.37715005 3.0268105  5.01492254 4.54055616]train_grp_loss: [20.67957543 15.8401915  20.73616657], val_grp_loss: [21.19666986 13.54913358 20.6446571 ], train_hist_grp_loss: [20.70416697 15.9658578  20.75893242], cur_train_grp_loss: [20.70416697 15.9658578  20.75893242],max_reward_err:  0.0557, max_reward_err_index: 0, max_kl_dist:  0.2579, max_kl_dist_index: 0, max_train_grp_loss:  20.7362, max_train_grp_loss_index: 2, max_val_grp_loss:  21.1967, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  20.7589, max_cur_train_grp_loss_index: 2, 
2024-09-19 00:05:24,041 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:947] - INFO: Iteration:  100, train_loss:  15.1429, val_loss:  15.7798, grad_norm: 0.4446, reward_err: 0.0838, 0.0049, 0.0447, KL_dist: 0.9625, 0.4561, 0.7545, param: [6.72608499 4.0821986  8.94698555 3.84954511]train_grp_loss: [19.07954041  8.745678   19.23704649], val_grp_loss: [20.21217176  7.54098287 18.70947122], train_hist_grp_loss: [1997.52935337 1176.21662218 2009.31523813], cur_train_grp_loss: [19.08949008  8.78128394 19.2465063 ],max_reward_err:  0.0838, max_reward_err_index: 0, max_kl_dist:  0.9625, max_kl_dist_index: 0, max_train_grp_loss:  19.2370, max_train_grp_loss_index: 2, max_val_grp_loss:  20.2122, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  19.2465, max_cur_train_grp_loss_index: 2, 
2024-09-19 00:05:27,196 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:1040] - INFO: Iteration:  199, train_loss:  13.9755, val_loss:  14.9391, grad_norm: 0.2548, reward_err: 0.0942, 0.0007, 0.0529, KL_dist: 1.4661, 0.7505, 1.1760, param: [ 9.26258476  4.45974485 11.11260868  3.68869443]train_grp_loss: [18.41267852  6.76190204 18.59767547], val_grp_loss: [19.88999895  6.14885493 17.84078676], train_hist_grp_loss: [3849.29510865 1924.42747975 3878.29098102], cur_train_grp_loss: [18.4170924   6.77174716 18.60194227],max_reward_err:  0.0942, max_reward_err_index: 0, max_kl_dist:  1.4661, max_kl_dist_index: 0, max_train_grp_loss:  18.5977, max_train_grp_loss_index: 2, max_val_grp_loss:  19.8900, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  18.6019, max_cur_train_grp_loss_index: 2, 
2024-09-19 00:05:27,418 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:387] - INFO: Policy parameter learned solely on the preference data dpo: [ 9.26258476  4.45974485 11.11260868  3.68869443].
2024-09-19 00:05:27,750 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Uniform reward: 3.8112, 3.8112, 3.1709
2024-09-19 00:05:27,751 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Optimal reward: 3.8518, 3.8518, 3.2974
2024-09-19 00:05:27,752 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Policy reward: 3.4889, 3.8492, 3.1230
2024-09-19 00:05:27,752 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Reward Error: 0.0942, 0.0007, 0.0529
2024-09-19 00:05:28,430 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:416] - INFO: Optimal reward: 3.8518, 3.8518, 3.2974
Known param reward: [[3.8518338203430176, 3.4604334831237793, 3.266357421875], [3.4604334831237793, 3.8518338203430176, 3.1038687229156494], [3.8126895427703857, 3.589339256286621, 3.297445297241211]], Known param reward error: [[0.0, 0.10161402476713881, 0.009427866898116682], [0.10161402476713881, 0.0, 0.058705014602521616], [0.010162504250805377, 0.06814794622500629, 0.0]].
