2024-09-18 15:35:04,510 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log_dpo/2024_09_18_15_16_04/swapped_noise0.4_[1,0.4,1]_2022
2024-09-18 15:35:04,512 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2022
2024-09-18 15:35:04,513 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-09-18 15:35:04,686 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.5095, l2 distance: 12.4525, acc: 0.78.
2024-09-18 15:35:04,687 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-18 15:35:04,688 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [6.66295559 2.62580263 5.92347677 5.08799812]
2024-09-18 15:35:04,908 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.6412, 3.7989, 3.2339
2024-09-18 15:35:06,254 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:947] - INFO: Iteration:  0, train_loss:  19.7845, val_loss:  20.2309, grad_norm: 0.4858, reward_err: 0.0512, 0.0412, 0.0211, KL_dist: 0.2366, 0.1622, 0.1436, param: [3.9367556  1.08583955 3.82614371 4.1868815 ]train_grp_loss: [22.71908788 15.89518648 20.84507824], val_grp_loss: [21.73026411 17.66554703 21.2147209 ], train_hist_grp_loss: [22.73503839 15.92165637 20.87283604], cur_train_grp_loss: [22.73503839 15.92165637 20.87283604],max_reward_err:  0.0512, max_reward_err_index: 0, max_kl_dist:  0.2366, max_kl_dist_index: 0, max_train_grp_loss:  22.7191, max_train_grp_loss_index: 0, max_val_grp_loss:  21.7303, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  22.7350, max_cur_train_grp_loss_index: 0, 
2024-09-18 15:35:09,621 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:1040] - INFO: Iteration:  99, train_loss:  18.5688, val_loss:  18.8283, grad_norm: 0.2394, reward_err: 0.0534, 0.0311, 0.0226, KL_dist: 0.5416, 0.3823, 0.4079, param: [5.99594547 2.11346072 5.81337482 5.70393096]train_grp_loss: [21.80066804 15.02813289 19.00130963], val_grp_loss: [20.34751269 16.52658862 19.54571715], train_hist_grp_loss: [2218.03520248 1527.23093565 1981.64105367], cur_train_grp_loss: [21.8054429  15.02832216 19.01337617],max_reward_err:  0.0534, max_reward_err_index: 0, max_kl_dist:  0.5416, max_kl_dist_index: 0, max_train_grp_loss:  21.8007, max_train_grp_loss_index: 0, max_val_grp_loss:  20.3475, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  21.8054, max_cur_train_grp_loss_index: 0, 
2024-09-18 15:35:09,856 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:387] - INFO: Policy parameter learned solely on the preference data dpo: [5.99594547 2.11346072 5.81337482 5.70393096].
2024-09-18 15:35:10,203 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Uniform reward: 3.8413, 3.8413, 3.1954
2024-09-18 15:35:10,204 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Optimal reward: 3.8718, 3.8718, 3.3255
2024-09-18 15:35:10,204 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Policy reward: 3.6652, 3.7513, 3.2503
2024-09-18 15:35:10,205 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Reward Error: 0.0534, 0.0311, 0.0226
2024-09-18 15:35:10,923 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:416] - INFO: Optimal reward: 3.8718, 3.8718, 3.3255
Known param reward: [[3.8717610836029053, 3.543931722640991, 3.2762246131896973], [3.543931722640991, 3.8717610836029053, 3.1653871536254883], [3.828972101211548, 3.640883684158325, 3.3254706859588623]], Known param reward error: [[0.0, 0.08467189836436118, 0.014808752630746911], [0.08467189836436118, 0.0, 0.04813860877177323], [0.01105155547241043, 0.05963110699737052, 0.0]].
