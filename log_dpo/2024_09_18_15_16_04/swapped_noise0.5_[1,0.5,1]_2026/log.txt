2024-09-18 15:33:11,146 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log_dpo/2024_09_18_15_16_04/swapped_noise0.5_[1,0.5,1]_2026
2024-09-18 15:33:11,148 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2026
2024-09-18 15:33:11,148 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-09-18 15:33:11,306 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.3777, l2 distance: 27.5739, acc: 0.83.
2024-09-18 15:33:11,307 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-18 15:33:11,307 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [12.91962812  7.82453273  9.98957798  7.56196729]
2024-09-18 15:33:11,511 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.6069, 3.8094, 3.2118
2024-09-18 15:33:12,765 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:947] - INFO: Iteration:  0, train_loss:  19.1511, val_loss:  19.9905, grad_norm: 0.7770, reward_err: 0.0742, 0.0233, 0.0371, KL_dist: 0.2234, 0.0764, 0.1339, param: [2.78069353 3.03716901 4.33768491 1.93847742]train_grp_loss: [21.89511852 14.39216133 21.19943298], val_grp_loss: [22.17947155 16.04367235 21.66795983], train_hist_grp_loss: [21.93853644 14.48113157 21.24721731], cur_train_grp_loss: [21.93853644 14.48113157 21.24721731],max_reward_err:  0.0742, max_reward_err_index: 0, max_kl_dist:  0.2234, max_kl_dist_index: 0, max_train_grp_loss:  21.8951, max_train_grp_loss_index: 0, max_val_grp_loss:  22.1795, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  21.9385, max_cur_train_grp_loss_index: 0, 
2024-09-18 15:33:15,949 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:1040] - INFO: Iteration:  99, train_loss:  16.1853, val_loss:  17.6615, grad_norm: 0.3633, reward_err: 0.0579, 0.0259, 0.0224, KL_dist: 0.6315, 0.4336, 0.4951, param: [6.30920076 5.41969343 6.48460803 4.22208539]train_grp_loss: [19.25167039 11.09219941 18.23262355], val_grp_loss: [19.97327377 13.81153671 19.10600417], train_hist_grp_loss: [2037.8221963  1215.5135377  1950.84462734], cur_train_grp_loss: [19.26710852 11.0986051  18.25047679],max_reward_err:  0.0579, max_reward_err_index: 0, max_kl_dist:  0.6315, max_kl_dist_index: 0, max_train_grp_loss:  19.2517, max_train_grp_loss_index: 0, max_val_grp_loss:  19.9733, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  19.2671, max_cur_train_grp_loss_index: 0, 
2024-09-18 15:33:16,175 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:387] - INFO: Policy parameter learned solely on the preference data dpo: [6.30920076 5.41969343 6.48460803 4.22208539].
2024-09-18 15:33:16,498 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Uniform reward: 3.8371, 3.8371, 3.1972
2024-09-18 15:33:16,498 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Optimal reward: 3.8738, 3.8738, 3.3175
2024-09-18 15:33:16,499 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Policy reward: 3.6494, 3.7736, 3.2432
2024-09-18 15:33:16,499 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Reward Error: 0.0579, 0.0259, 0.0224
2024-09-18 15:33:17,165 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:416] - INFO: Optimal reward: 3.8738, 3.8738, 3.3175
Known param reward: [[3.8737521171569824, 3.4834368228912354, 3.283886432647705], [3.4834368228912354, 3.8737521171569824, 3.128574848175049], [3.83065128326416, 3.603095769882202, 3.3174588680267334]], Known param reward error: [[0.0, 0.10075897539675477, 0.010119925133841261], [0.10075897539675477, 0.0, 0.05693635621894995], [0.011126378918756102, 0.06986929960645492, 0.0]].
