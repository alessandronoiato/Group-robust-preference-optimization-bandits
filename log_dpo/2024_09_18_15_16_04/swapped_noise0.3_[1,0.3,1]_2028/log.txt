2024-09-18 15:40:00,637 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log_dpo/2024_09_18_15_16_04/swapped_noise0.3_[1,0.3,1]_2028
2024-09-18 15:40:00,640 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2028
2024-09-18 15:40:00,640 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-09-18 15:40:00,809 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.5490, l2 distance: 9.9924, acc: 0.78.
2024-09-18 15:40:00,810 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-18 15:40:00,811 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [5.82429623 4.04486507 5.13720847 2.31809739]
2024-09-18 15:40:01,016 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.5857, 3.8171, 3.2181
2024-09-18 15:40:02,329 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:947] - INFO: Iteration:  0, train_loss:  21.1504, val_loss:  20.8781, grad_norm: 0.4475, reward_err: 0.0432, 0.0390, 0.0191, KL_dist: 0.1505, 0.1608, 0.0946, param: [3.95332223 2.97532949 2.25908753 3.67340797]train_grp_loss: [21.78873863 20.41947026 21.03861609], val_grp_loss: [21.75079633 19.58401944 21.19247653], train_hist_grp_loss: [21.79813323 20.44919997 21.06276263], cur_train_grp_loss: [21.79813323 20.44919997 21.06276263],max_reward_err:  0.0432, max_reward_err_index: 0, max_kl_dist:  0.1608, max_kl_dist_index: 1, max_train_grp_loss:  21.7887, max_train_grp_loss_index: 0, max_val_grp_loss:  21.7508, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  21.7981, max_cur_train_grp_loss_index: 0, 
2024-09-18 15:40:05,536 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:1040] - INFO: Iteration:  99, train_loss:  19.9134, val_loss:  19.5531, grad_norm: 0.2709, reward_err: 0.0663, 0.0199, 0.0338, KL_dist: 0.4730, 0.2678, 0.3494, param: [6.27034231 4.38535872 4.40722552 3.4652997 ]train_grp_loss: [21.23090981 18.80336912 19.28849867], val_grp_loss: [20.95679297 17.77932527 19.7615024 ], train_hist_grp_loss: [2146.44500659 1945.26437479 2008.90871255], cur_train_grp_loss: [21.23391639 18.81095461 19.30120013],max_reward_err:  0.0663, max_reward_err_index: 0, max_kl_dist:  0.4730, max_kl_dist_index: 0, max_train_grp_loss:  21.2309, max_train_grp_loss_index: 0, max_val_grp_loss:  20.9568, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  21.2339, max_cur_train_grp_loss_index: 0, 
2024-09-18 15:40:05,778 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:387] - INFO: Policy parameter learned solely on the preference data dpo: [6.27034231 4.38535872 4.40722552 3.4652997 ].
2024-09-18 15:40:06,109 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Uniform reward: 3.8431, 3.8431, 3.2160
2024-09-18 15:40:06,109 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Optimal reward: 3.8795, 3.8795, 3.3513
2024-09-18 15:40:06,110 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Policy reward: 3.6221, 3.8022, 3.2380
2024-09-18 15:40:06,110 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Reward Error: 0.0663, 0.0199, 0.0338
2024-09-18 15:40:06,792 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:416] - INFO: Optimal reward: 3.8795, 3.8795, 3.3513
Known param reward: [[3.879473924636841, 3.4689507484436035, 3.3167123794555664], [3.4689507484436035, 3.879473924636841, 3.1360788345336914], [3.846095323562622, 3.6189825534820557, 3.351266622543335]], Known param reward error: [[0.0, 0.10581928997800044, 0.010310800953683814], [0.10581928997800044, 0.0, 0.06421088270390547], [0.00860389880757952, 0.06714605542275165, 0.0]].
