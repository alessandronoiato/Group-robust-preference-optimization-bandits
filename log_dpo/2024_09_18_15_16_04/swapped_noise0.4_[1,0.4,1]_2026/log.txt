2024-09-18 15:36:18,121 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log_dpo/2024_09_18_15_16_04/swapped_noise0.4_[1,0.4,1]_2026
2024-09-18 15:36:18,123 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2026
2024-09-18 15:36:18,123 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-09-18 15:36:18,289 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.3869, l2 distance: 25.0176, acc: 0.85.
2024-09-18 15:36:18,289 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-18 15:36:18,290 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [11.7719549   7.51698126  7.29275761  9.13307926]
2024-09-18 15:36:18,496 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.6344, 3.7376, 3.2152
2024-09-18 15:36:19,783 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:947] - INFO: Iteration:  0, train_loss:  18.8629, val_loss:  20.4552, grad_norm: 0.6855, reward_err: 0.0103, 0.0722, 0.0004, KL_dist: 0.0776, 0.2989, 0.0697, param: [2.70853377 4.25120397 2.13300359 4.16498147]train_grp_loss: [21.01880088 15.05719817 20.54374029], val_grp_loss: [21.0872396  19.40579628 20.79220334], train_hist_grp_loss: [21.0494473  15.1247385  20.58639471], cur_train_grp_loss: [21.0494473  15.1247385  20.58639471],max_reward_err:  0.0722, max_reward_err_index: 1, max_kl_dist:  0.2989, max_kl_dist_index: 1, max_train_grp_loss:  21.0188, max_train_grp_loss_index: 0, max_val_grp_loss:  21.0872, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  21.0494, max_cur_train_grp_loss_index: 0, 
2024-09-18 15:36:22,980 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:1040] - INFO: Iteration:  99, train_loss:  16.2954, val_loss:  18.6338, grad_norm: 0.3613, reward_err: 0.0401, 0.0440, 0.0121, KL_dist: 0.5114, 0.5359, 0.4290, param: [6.2722581  5.39007082 4.73358236 6.12141732]train_grp_loss: [19.09192503 12.04296803 17.74073913], val_grp_loss: [19.44058467 18.00989131 18.37448239], train_hist_grp_loss: [1992.41777576 1313.34999127 1897.43505308], cur_train_grp_loss: [19.10365051 12.05261145 17.758825  ],max_reward_err:  0.0440, max_reward_err_index: 1, max_kl_dist:  0.5359, max_kl_dist_index: 1, max_train_grp_loss:  19.0919, max_train_grp_loss_index: 0, max_val_grp_loss:  19.4406, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  19.1037, max_cur_train_grp_loss_index: 0, 
2024-09-18 15:36:23,206 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:387] - INFO: Policy parameter learned solely on the preference data dpo: [6.2722581  5.39007082 4.73358236 6.12141732].
2024-09-18 15:36:23,534 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Uniform reward: 3.8267, 3.8267, 3.1836
2024-09-18 15:36:23,534 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Optimal reward: 3.8639, 3.8639, 3.3051
2024-09-18 15:36:23,535 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Policy reward: 3.7091, 3.6937, 3.2650
2024-09-18 15:36:23,535 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Reward Error: 0.0401, 0.0440, 0.0121
2024-09-18 15:36:24,213 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:416] - INFO: Optimal reward: 3.8639, 3.8639, 3.3051
Known param reward: [[3.8638525009155273, 3.4816598892211914, 3.271707057952881], [3.4816598892211914, 3.8638525009155273, 3.120657444000244], [3.8214311599731445, 3.5967774391174316, 3.3051488399505615]], Known param reward error: [[0.0, 0.09891490723410809, 0.010118086542263219], [0.09891490723410809, 0.0, 0.055819391163357414], [0.010979027002798687, 0.0691214433612083, 0.0]].
