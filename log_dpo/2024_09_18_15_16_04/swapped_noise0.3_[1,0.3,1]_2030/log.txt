2024-09-18 15:40:39,360 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log_dpo/2024_09_18_15_16_04/swapped_noise0.3_[1,0.3,1]_2030
2024-09-18 15:40:39,362 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2030
2024-09-18 15:40:39,362 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-09-18 15:40:39,526 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.5866, l2 distance: 6.8663, acc: 0.72.
2024-09-18 15:40:39,527 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-18 15:40:39,528 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [3.16007899 1.36960043 5.0322715  2.61134783]
2024-09-18 15:40:39,740 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.5342, 3.8697, 3.2132
2024-09-18 15:40:41,040 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:947] - INFO: Iteration:  0, train_loss:  23.3574, val_loss:  21.6727, grad_norm: 0.6276, reward_err: 0.0369, 0.0806, 0.0234, KL_dist: 0.0808, 0.2731, 0.0715, param: [3.06643869 4.62576372 0.58887947 1.87273423]train_grp_loss: [22.39554758 25.34766102 22.16349534], val_grp_loss: [22.17305906 20.67933678 22.09536949], train_hist_grp_loss: [22.40024273 25.43321307 22.18528755], cur_train_grp_loss: [22.40024273 25.43321307 22.18528755],max_reward_err:  0.0806, max_reward_err_index: 1, max_kl_dist:  0.2731, max_kl_dist_index: 1, max_train_grp_loss:  25.3477, max_train_grp_loss_index: 1, max_val_grp_loss:  22.1731, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  25.4332, max_cur_train_grp_loss_index: 1, 
2024-09-18 15:40:44,307 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:1040] - INFO: Iteration:  99, train_loss:  21.2542, val_loss:  19.8576, grad_norm: 0.3213, reward_err: 0.0592, 0.0170, 0.0258, KL_dist: 0.3402, 0.1628, 0.2259, param: [4.96061793 2.90995794 3.86202444 3.55810298]train_grp_loss: [22.05296388 21.23854071 20.59282572], val_grp_loss: [21.37153155 17.08006771 20.91357118], train_hist_grp_loss: [2221.00462829 2279.23302155 2130.98968777], cur_train_grp_loss: [22.05546484 21.25433501 20.60415729],max_reward_err:  0.0592, max_reward_err_index: 0, max_kl_dist:  0.3402, max_kl_dist_index: 0, max_train_grp_loss:  22.0530, max_train_grp_loss_index: 0, max_val_grp_loss:  21.3715, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  22.0555, max_cur_train_grp_loss_index: 0, 
2024-09-18 15:40:44,540 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:387] - INFO: Policy parameter learned solely on the preference data dpo: [4.96061793 2.90995794 3.86202444 3.55810298].
2024-09-18 15:40:44,879 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Uniform reward: 3.8714, 3.8714, 3.2553
2024-09-18 15:40:44,880 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Optimal reward: 3.9148, 3.9148, 3.4122
2024-09-18 15:40:44,881 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Policy reward: 3.6831, 3.8483, 3.3241
2024-09-18 15:40:44,881 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Reward Error: 0.0592, 0.0170, 0.0258
2024-09-18 15:40:45,578 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:416] - INFO: Optimal reward: 3.9148, 3.9148, 3.4122
Known param reward: [[3.9148213863372803, 3.5198121070861816, 3.370706081390381], [3.5198121070861816, 3.9148213863372803, 3.212374687194824], [3.8760476112365723, 3.641129970550537, 3.4121618270874023]], Known param reward error: [[0.0, 0.10090097101995006, 0.01214940785279455], [0.10090097101995006, 0.0, 0.05855148437174653], [0.009904353551359563, 0.06991159717833506, 0.0]].
