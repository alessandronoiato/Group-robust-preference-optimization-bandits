2024-09-17 22:39:01,263 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:198] - INFO: Logging to log_dpo/2024_09_17_22_38_57/swapped_noise0.2_[1,0.2,1]_2021
2024-09-17 22:39:01,265 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: (IB) Seed: 2021
2024-09-17 22:39:01,265 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Data: 300
2024-09-17 22:39:01,427 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:296] - INFO: MLE reward loss: 0.5466, l2 distance: 8.7600, acc: 0.77.
2024-09-17 22:39:01,428 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-17 22:39:01,429 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: MLE reward parameter: [5.50410659 3.86010232 3.9450506  3.54095361]
2024-09-17 22:39:01,638 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:313] - INFO: Learned oracle reward: 3.6313, 3.7900, 3.2116
2024-09-17 22:39:02,941 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:947] - INFO: Iteration:  0, train_loss:  23.5319, val_loss:  23.4673, grad_norm: 0.8257, reward_err: 0.1185, 0.0128, 0.0827, KL_dist: 0.1568, 0.0723, 0.1029, param: [1.94795225 0.69245775 0.59455853 0.28017524]train_grp_loss: [24.13413265 22.41922594 24.12761354], val_grp_loss: [24.18342266 22.21506412 24.04144168], train_hist_grp_loss: [24.18358538 22.52814958 24.16955798], cur_train_grp_loss: [24.18358538 22.52814958 24.16955798],max_reward_err:  0.1185, max_reward_err_index: 0, max_kl_dist:  0.1568, max_kl_dist_index: 0, max_train_grp_loss:  24.1341, max_train_grp_loss_index: 0, max_val_grp_loss:  24.1834, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  24.1836, max_cur_train_grp_loss_index: 0, 
2024-09-17 22:39:06,073 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:1040] - INFO: Iteration:  99, train_loss:  20.2056, val_loss:  20.1912, grad_norm: 0.3777, reward_err: 0.0592, 0.0292, 0.0276, KL_dist: 0.2398, 0.1614, 0.1661, param: [4.75619598 3.50780077 3.01954271 3.38859102]train_grp_loss: [21.09675782 18.27050098 21.40633193], val_grp_loss: [21.16851372 18.75070371 20.69815941], train_hist_grp_loss: [2239.49840041 1962.00487444 2259.80273143], cur_train_grp_loss: [21.11460616 18.27845056 21.42363306],max_reward_err:  0.0592, max_reward_err_index: 0, max_kl_dist:  0.2398, max_kl_dist_index: 0, max_train_grp_loss:  21.4063, max_train_grp_loss_index: 2, max_val_grp_loss:  21.1685, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  21.4236, max_cur_train_grp_loss_index: 2, 
2024-09-17 22:39:06,306 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:386] - INFO: Policy parameter learned solely on the preference data dpo: [4.75619598 3.50780077 3.01954271 3.38859102].
2024-09-17 22:39:06,635 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:397] - INFO: Uniform reward: 3.8444, 3.8444, 3.1980
2024-09-17 22:39:06,635 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Optimal reward: 3.8791, 3.8791, 3.3108
2024-09-17 22:39:06,636 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Policy reward: 3.6493, 3.7659, 3.2194
2024-09-17 22:39:06,636 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Reward Error: 0.0592, 0.0292, 0.0276
2024-09-17 22:39:07,324 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:415] - INFO: Optimal reward: 3.8791, 3.8791, 3.3108
Known param reward: [[3.8791401386260986, 3.4544191360473633, 3.2859795093536377], [3.4544191360473633, 3.8791401386260986, 3.0945019721984863], [3.844071626663208, 3.585026264190674, 3.3107750415802]], Known param reward error: [[0.0, 0.1094884400668138, 0.007489343708090731], [0.1094884400668138, 0.0, 0.06532400017081465], [0.009040279729443101, 0.07581934756798786, 0.0]].
