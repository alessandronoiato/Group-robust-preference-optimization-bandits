2024-09-17 22:39:39,511 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:198] - INFO: Logging to log_dpo/2024_09_17_22_38_57/swapped_noise0.2_[1,0.2,1]_2023
2024-09-17 22:39:39,513 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: (IB) Seed: 2023
2024-09-17 22:39:39,513 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Data: 300
2024-09-17 22:39:39,673 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:296] - INFO: MLE reward loss: 0.5522, l2 distance: 8.4930, acc: 0.78.
2024-09-17 22:39:39,674 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-17 22:39:39,675 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: MLE reward parameter: [4.88223068 3.3667914  4.99854188 2.79920923]
2024-09-17 22:39:39,876 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:313] - INFO: Learned oracle reward: 3.6164, 3.8226, 3.2108
2024-09-17 22:39:41,163 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:947] - INFO: Iteration:  0, train_loss:  22.2708, val_loss:  22.3728, grad_norm: 0.6482, reward_err: 0.0671, 0.0451, 0.0356, KL_dist: 0.1027, 0.0626, 0.0443, param: [2.80859757 0.83599038 1.69557275 2.65051395]train_grp_loss: [22.68829408 21.60895653 22.57303103], val_grp_loss: [23.47575654 20.88207829 22.70678714], train_hist_grp_loss: [22.72266978 21.66689525 22.60473949], cur_train_grp_loss: [22.72266978 21.66689525 22.60473949],max_reward_err:  0.0671, max_reward_err_index: 0, max_kl_dist:  0.1027, max_kl_dist_index: 0, max_train_grp_loss:  22.6883, max_train_grp_loss_index: 0, max_val_grp_loss:  23.4758, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  22.7227, max_cur_train_grp_loss_index: 0, 
2024-09-17 22:39:44,242 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:1040] - INFO: Iteration:  99, train_loss:  20.0515, val_loss:  20.4785, grad_norm: 0.3274, reward_err: 0.0638, 0.0148, 0.0307, KL_dist: 0.3759, 0.1904, 0.2649, param: [5.34943555 3.49995162 4.36422167 3.35029728]train_grp_loss: [20.43834738 19.30330695 20.48353673], val_grp_loss: [22.17249816 18.8452906  20.39981989], train_hist_grp_loss: [2142.65676908 2007.07754558 2140.35070781], cur_train_grp_loss: [20.45276027 19.30801193 20.49700568],max_reward_err:  0.0638, max_reward_err_index: 0, max_kl_dist:  0.3759, max_kl_dist_index: 0, max_train_grp_loss:  20.4835, max_train_grp_loss_index: 2, max_val_grp_loss:  22.1725, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  20.4970, max_cur_train_grp_loss_index: 2, 
2024-09-17 22:39:44,461 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:386] - INFO: Policy parameter learned solely on the preference data dpo: [5.34943555 3.49995162 4.36422167 3.35029728].
2024-09-17 22:39:44,787 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:397] - INFO: Uniform reward: 3.8257, 3.8257, 3.1790
2024-09-17 22:39:44,788 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Optimal reward: 3.8670, 3.8670, 3.3117
2024-09-17 22:39:44,788 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Policy reward: 3.6202, 3.8098, 3.2099
2024-09-17 22:39:44,789 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Reward Error: 0.0638, 0.0148, 0.0307
2024-09-17 22:39:45,459 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:415] - INFO: Optimal reward: 3.8670, 3.8670, 3.3117
Known param reward: [[3.866978645324707, 3.4890663623809814, 3.2840659618377686], [3.4890663623809814, 3.866978645324707, 3.121250629425049], [3.8343822956085205, 3.608206033706665, 3.311685085296631]], Known param reward error: [[0.0, 0.0977280501408077, 0.00833990030679153], [0.0977280501408077, 0.0, 0.057503793678052764], [0.008429410324154877, 0.06691855201499647, 0.0]].
