2024-09-17 22:40:56,043 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:198] - INFO: Logging to log_dpo/2024_09_17_22_38_57/swapped_noise0.2_[1,0.2,1]_2027
2024-09-17 22:40:56,045 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: (IB) Seed: 2027
2024-09-17 22:40:56,045 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Data: 300
2024-09-17 22:40:56,209 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:296] - INFO: MLE reward loss: 0.4981, l2 distance: 15.2550, acc: 0.78.
2024-09-17 22:40:56,210 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-17 22:40:56,210 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: MLE reward parameter: [5.79906847 4.28403231 8.95760978 4.09462055]
2024-09-17 22:40:56,422 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:313] - INFO: Learned oracle reward: 3.4755, 3.7354, 3.0882
2024-09-17 22:40:57,727 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:947] - INFO: Iteration:  0, train_loss:  21.8080, val_loss:  21.8019, grad_norm: 0.6519, reward_err: 0.0543, 0.0867, 0.0407, KL_dist: 0.1577, 0.2776, 0.1386, param: [3.87181746 4.84916094 0.27088142 1.65599794]train_grp_loss: [22.33487482 21.4673443  21.58128874], val_grp_loss: [21.9158137  21.41249023 22.08349913], train_hist_grp_loss: [22.35655347 21.54548221 21.61316986], cur_train_grp_loss: [22.35655347 21.54548221 21.61316986],max_reward_err:  0.0867, max_reward_err_index: 1, max_kl_dist:  0.2776, max_kl_dist_index: 1, max_train_grp_loss:  22.3349, max_train_grp_loss_index: 0, max_val_grp_loss:  22.0835, max_val_grp_loss_index: 2, max_cur_train_grp_loss:  22.3566, max_cur_train_grp_loss_index: 0, 
2024-09-17 22:41:00,886 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:1040] - INFO: Iteration:  99, train_loss:  19.2395, val_loss:  19.5117, grad_norm: 0.3855, reward_err: 0.0656, 0.0253, 0.0356, KL_dist: 0.5139, 0.3150, 0.3948, param: [6.65199422 4.77529398 4.01300384 3.43110017]train_grp_loss: [20.87884546 17.23579    19.35223515], val_grp_loss: [20.53710004 17.78224312 20.24474424], train_hist_grp_loss: [2152.52166853 1893.48498187 2035.77476331], cur_train_grp_loss: [20.88849367 17.25573152 19.36773908],max_reward_err:  0.0656, max_reward_err_index: 0, max_kl_dist:  0.5139, max_kl_dist_index: 0, max_train_grp_loss:  20.8788, max_train_grp_loss_index: 0, max_val_grp_loss:  20.5371, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  20.8885, max_cur_train_grp_loss_index: 0, 
2024-09-17 22:41:01,129 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:386] - INFO: Policy parameter learned solely on the preference data dpo: [6.65199422 4.77529398 4.01300384 3.43110017].
2024-09-17 22:41:01,467 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:397] - INFO: Uniform reward: 3.7241, 3.7241, 3.0868
2024-09-17 22:41:01,468 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Optimal reward: 3.7658, 3.7658, 3.2313
2024-09-17 22:41:01,468 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Policy reward: 3.5189, 3.6706, 3.1164
2024-09-17 22:41:01,469 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Reward Error: 0.0656, 0.0253, 0.0356
2024-09-17 22:41:02,158 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:415] - INFO: Optimal reward: 3.7658, 3.7658, 3.2313
Known param reward: [[3.7658329010009766, 3.411930561065674, 3.1902992725372314], [3.411930561065674, 3.7658329010009766, 3.0509254932403564], [3.727386713027954, 3.5327694416046143, 3.2313315868377686]], Known param reward error: [[0.0, 0.09397717563124848, 0.012698267942440401], [0.09397717563124848, 0.0, 0.055830263391186144], [0.01020921240631874, 0.06188895405699305, 0.0]].
