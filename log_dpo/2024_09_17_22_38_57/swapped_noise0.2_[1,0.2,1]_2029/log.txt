2024-09-17 22:41:32,935 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:198] - INFO: Logging to log_dpo/2024_09_17_22_38_57/swapped_noise0.2_[1,0.2,1]_2029
2024-09-17 22:41:32,937 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: (IB) Seed: 2029
2024-09-17 22:41:32,938 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Data: 300
2024-09-17 22:41:33,101 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:296] - INFO: MLE reward loss: 0.5089, l2 distance: 11.4229, acc: 0.80.
2024-09-17 22:41:33,101 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-17 22:41:33,102 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: MLE reward parameter: [2.85849314 6.00174256 6.47047469 3.99509683]
2024-09-17 22:41:33,307 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:313] - INFO: Learned oracle reward: 3.6523, 3.6714, 3.2651
2024-09-17 22:41:34,601 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:947] - INFO: Iteration:  0, train_loss:  21.6015, val_loss:  22.0710, grad_norm: 0.8020, reward_err: 0.0908, 0.0094, 0.0524, KL_dist: 0.1714, 0.0182, 0.0877, param: [1.89658671 1.80249574 3.21803027 0.79896536]train_grp_loss: [23.64338638 18.93957525 22.65237074], val_grp_loss: [23.16598558 20.01728201 22.69818682], train_hist_grp_loss: [23.68450404 19.04000503 22.6970911 ], cur_train_grp_loss: [23.68450404 19.04000503 22.6970911 ],max_reward_err:  0.0908, max_reward_err_index: 0, max_kl_dist:  0.1714, max_kl_dist_index: 0, max_train_grp_loss:  23.6434, max_train_grp_loss_index: 0, max_val_grp_loss:  23.1660, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  23.6845, max_cur_train_grp_loss_index: 0, 
2024-09-17 22:41:37,742 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:1040] - INFO: Iteration:  99, train_loss:  18.7468, val_loss:  19.8633, grad_norm: 0.3222, reward_err: 0.0518, 0.0411, 0.0219, KL_dist: 0.3538, 0.3061, 0.2657, param: [3.68467898 5.22666785 5.49618296 3.32377577]train_grp_loss: [21.25418128 15.58755446 19.91158827], val_grp_loss: [20.46001294 19.16954757 19.85141711], train_hist_grp_loss: [2225.01412635 1656.96852371 2108.38343414], cur_train_grp_loss: [21.26712768 15.59052858 19.92780933],max_reward_err:  0.0518, max_reward_err_index: 0, max_kl_dist:  0.3538, max_kl_dist_index: 0, max_train_grp_loss:  21.2542, max_train_grp_loss_index: 0, max_val_grp_loss:  20.4600, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  21.2671, max_cur_train_grp_loss_index: 0, 
2024-09-17 22:41:37,972 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:386] - INFO: Policy parameter learned solely on the preference data dpo: [3.68467898 5.22666785 5.49618296 3.32377577].
2024-09-17 22:41:38,304 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:397] - INFO: Uniform reward: 3.8223, 3.8223, 3.2131
2024-09-17 22:41:38,305 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Optimal reward: 3.8685, 3.8685, 3.3593
2024-09-17 22:41:38,306 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Policy reward: 3.6682, 3.7095, 3.2856
2024-09-17 22:41:38,306 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Reward Error: 0.0518, 0.0411, 0.0219
2024-09-17 22:41:38,991 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:415] - INFO: Optimal reward: 3.8685, 3.8685, 3.3593
Known param reward: [[3.8685142993927, 3.4599270820617676, 3.3229901790618896], [3.4599270820617676, 3.8685142993927, 3.1513752937316895], [3.8328397274017334, 3.5916991233825684, 3.3593173027038574]], Known param reward error: [[0.0, 0.10561863953690821, 0.010813841137521808], [0.10561863953690821, 0.0, 0.06190007975870543], [0.00922177591448148, 0.0715559397191805, 0.0]].
