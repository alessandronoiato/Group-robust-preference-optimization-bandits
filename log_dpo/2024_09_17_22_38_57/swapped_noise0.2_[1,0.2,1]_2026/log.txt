2024-09-17 22:40:37,018 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:198] - INFO: Logging to log_dpo/2024_09_17_22_38_57/swapped_noise0.2_[1,0.2,1]_2026
2024-09-17 22:40:37,020 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: (IB) Seed: 2026
2024-09-17 22:40:37,020 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Data: 300
2024-09-17 22:40:37,183 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:296] - INFO: MLE reward loss: 0.5490, l2 distance: 10.2512, acc: 0.78.
2024-09-17 22:40:37,184 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-17 22:40:37,184 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: MLE reward parameter: [5.79898202 3.57657954 5.58200107 1.55556736]
2024-09-17 22:40:37,385 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:313] - INFO: Learned oracle reward: 3.5362, 3.8537, 3.2055
2024-09-17 22:40:38,699 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:947] - INFO: Iteration:  0, train_loss:  22.2423, val_loss:  21.6571, grad_norm: 0.5648, reward_err: 0.0369, 0.0983, 0.0236, KL_dist: 0.0608, 0.2102, 0.0425, param: [0.72152788 4.07620513 2.72668876 1.40128388]train_grp_loss: [22.2871974  22.46026155 21.95811369], val_grp_loss: [22.1021727  20.62877658 22.1723799 ], train_hist_grp_loss: [22.30822766 22.5110828  21.98155279], cur_train_grp_loss: [22.30822766 22.5110828  21.98155279],max_reward_err:  0.0983, max_reward_err_index: 1, max_kl_dist:  0.2102, max_kl_dist_index: 1, max_train_grp_loss:  22.4603, max_train_grp_loss_index: 1, max_val_grp_loss:  22.1724, max_val_grp_loss_index: 2, max_cur_train_grp_loss:  22.5111, max_cur_train_grp_loss_index: 1, 
2024-09-17 22:40:41,833 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:1040] - INFO: Iteration:  99, train_loss:  20.2690, val_loss:  19.4045, grad_norm: 0.3416, reward_err: 0.0695, 0.0338, 0.0373, KL_dist: 0.3817, 0.2405, 0.2632, param: [3.9794437  4.81608968 5.54279156 1.69196706]train_grp_loss: [20.85383333 19.66329493 20.26652148], val_grp_loss: [20.63628146 16.95786817 20.45058168], train_hist_grp_loss: [2149.36668576 2079.10708035 2103.89440519], cur_train_grp_loss: [20.86347874 19.67647723 20.27872499],max_reward_err:  0.0695, max_reward_err_index: 0, max_kl_dist:  0.3817, max_kl_dist_index: 0, max_train_grp_loss:  20.8538, max_train_grp_loss_index: 0, max_val_grp_loss:  20.6363, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  20.8635, max_cur_train_grp_loss_index: 0, 
2024-09-17 22:40:42,076 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:386] - INFO: Policy parameter learned solely on the preference data dpo: [3.9794437  4.81608968 5.54279156 1.69196706].
2024-09-17 22:40:42,405 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:397] - INFO: Uniform reward: 3.8412, 3.8412, 3.2288
2024-09-17 22:40:42,406 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Optimal reward: 3.8831, 3.8831, 3.3797
2024-09-17 22:40:42,407 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Policy reward: 3.6132, 3.7518, 3.2535
2024-09-17 22:40:42,407 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Reward Error: 0.0695, 0.0338, 0.0373
2024-09-17 22:40:43,090 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:415] - INFO: Optimal reward: 3.8831, 3.8831, 3.3797
Known param reward: [[3.8831357955932617, 3.4835548400878906, 3.33915638923645], [3.4835548400878906, 3.8831357955932617, 3.1674530506134033], [3.8466908931732178, 3.620908498764038, 3.3797338008880615]], Known param reward error: [[0.0, 0.10290161780044664, 0.012006096941998562], [0.10290161780044664, 0.0, 0.0628099024304456], [0.009385430831804306, 0.06752977764177336, 0.0]].
