2024-09-17 22:40:17,230 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:198] - INFO: Logging to log_dpo/2024_09_17_22_38_57/swapped_noise0.2_[1,0.2,1]_2025
2024-09-17 22:40:17,231 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: (IB) Seed: 2025
2024-09-17 22:40:17,232 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Data: 300
2024-09-17 22:40:17,392 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:296] - INFO: MLE reward loss: 0.5266, l2 distance: 10.2154, acc: 0.77.
2024-09-17 22:40:17,393 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-17 22:40:17,393 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: MLE reward parameter: [6.68024438 2.13602835 4.67140896 2.7561983 ]
2024-09-17 22:40:17,599 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:313] - INFO: Learned oracle reward: 3.4986, 3.8543, 3.0837
2024-09-17 22:40:18,894 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:947] - INFO: Iteration:  0, train_loss:  21.5409, val_loss:  21.2656, grad_norm: 0.6616, reward_err: 0.0134, 0.0733, 0.0058, KL_dist: 0.0861, 0.2992, 0.0863, param: [2.98382737 4.69102961 1.63609058 3.86268042]train_grp_loss: [21.11787488 22.14536938 21.25031867], val_grp_loss: [20.85376658 21.99306471 20.87949987], train_hist_grp_loss: [21.13006864 22.23120047 21.27546268], cur_train_grp_loss: [21.13006864 22.23120047 21.27546268],max_reward_err:  0.0733, max_reward_err_index: 1, max_kl_dist:  0.2992, max_kl_dist_index: 1, max_train_grp_loss:  22.1454, max_train_grp_loss_index: 1, max_val_grp_loss:  21.9931, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  22.2312, max_cur_train_grp_loss_index: 1, 
2024-09-17 22:40:22,033 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:1040] - INFO: Iteration:  99, train_loss:  19.1368, val_loss:  19.4893, grad_norm: 0.3463, reward_err: 0.0640, 0.0142, 0.0314, KL_dist: 0.4947, 0.2575, 0.3726, param: [6.52096644 3.67958107 4.72295543 3.76827565]train_grp_loss: [20.4079962  17.70269859 19.57232516], val_grp_loss: [20.54769995 18.36180066 19.68525861], train_hist_grp_loss: [2070.49006282 1944.63081821 2031.5796306 ], cur_train_grp_loss: [20.41192732 17.72207642 19.58339224],max_reward_err:  0.0640, max_reward_err_index: 0, max_kl_dist:  0.4947, max_kl_dist_index: 0, max_train_grp_loss:  20.4080, max_train_grp_loss_index: 0, max_val_grp_loss:  20.5477, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  20.4119, max_cur_train_grp_loss_index: 0, 
2024-09-17 22:40:22,261 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:386] - INFO: Policy parameter learned solely on the preference data dpo: [6.52096644 3.67958107 4.72295543 3.76827565].
2024-09-17 22:40:22,591 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:397] - INFO: Uniform reward: 3.8278, 3.8278, 3.1587
2024-09-17 22:40:22,592 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Optimal reward: 3.8601, 3.8601, 3.2689
2024-09-17 22:40:22,593 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Policy reward: 3.6129, 3.8054, 3.1663
2024-09-17 22:40:22,593 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Reward Error: 0.0640, 0.0142, 0.0314
2024-09-17 22:40:23,273 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:415] - INFO: Optimal reward: 3.8601, 3.8601, 3.2689
Known param reward: [[3.860135793685913, 3.485208511352539, 3.23291015625], [3.485208511352539, 3.860135793685913, 3.0802385807037354], [3.820385217666626, 3.60957407951355, 3.268871545791626]], Known param reward error: [[0.0, 0.09712800335849549, 0.011001163257064349], [0.09712800335849549, 0.0, 0.05770583592700006], [0.010297714418313411, 0.06491007766675233, 0.0]].
