2024-09-18 00:06:16,192 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:198] - INFO: Logging to log_dpo/2024_09_18_00_04_38/swapped_noise0.3_[0.3,0.3,0.3]_2026
2024-09-18 00:06:16,194 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: (IB) Seed: 2026
2024-09-18 00:06:16,194 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Data: 300
2024-09-18 00:06:16,359 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:296] - INFO: MLE reward loss: 0.5844, l2 distance: 6.5700, acc: 0.70.
2024-09-18 00:06:16,360 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-18 00:06:16,361 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: MLE reward parameter: [5.06300368 2.19028036 2.7385319  2.66543984]
2024-09-18 00:06:16,572 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:313] - INFO: Learned oracle reward: 3.5463, 3.8327, 3.1668
2024-09-18 00:06:17,825 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:947] - INFO: Iteration:  0, train_loss:  22.4488, val_loss:  23.4038, grad_norm: 0.5047, reward_err: 0.0103, 0.0909, 0.0005, KL_dist: 0.0202, 0.1860, 0.0066, param: [1.41002466 3.74565267 1.94124311 1.94578004]train_grp_loss: [23.54079506 20.05336469 23.80291214], val_grp_loss: [23.79020399 22.16743708 24.24194541], train_hist_grp_loss: [23.54968782 20.10744196 23.8159115 ], cur_train_grp_loss: [23.54968782 20.10744196 23.8159115 ],max_reward_err:  0.0909, max_reward_err_index: 1, max_kl_dist:  0.1860, max_kl_dist_index: 1, max_train_grp_loss:  23.8029, max_train_grp_loss_index: 2, max_val_grp_loss:  24.2419, max_val_grp_loss_index: 2, max_cur_train_grp_loss:  23.8159, max_cur_train_grp_loss_index: 2, 
2024-09-18 00:06:20,914 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:1040] - INFO: Iteration:  99, train_loss:  21.0349, val_loss:  22.6561, grad_norm: 0.2723, reward_err: 0.0426, 0.0378, 0.0122, KL_dist: 0.2301, 0.2068, 0.1555, param: [4.02963904 3.78164203 3.82192236 3.72292355]train_grp_loss: [23.03153086 17.17847921 22.94824497], val_grp_loss: [23.31533044 20.68165341 23.95137671], train_hist_grp_loss: [2324.1506159  1833.33840454 2332.48446055], cur_train_grp_loss: [23.03415242 17.19254725 22.95379901],max_reward_err:  0.0426, max_reward_err_index: 0, max_kl_dist:  0.2301, max_kl_dist_index: 0, max_train_grp_loss:  23.0315, max_train_grp_loss_index: 0, max_val_grp_loss:  23.9514, max_val_grp_loss_index: 2, max_cur_train_grp_loss:  23.0342, max_cur_train_grp_loss_index: 0, 
2024-09-18 00:06:21,134 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:386] - INFO: Policy parameter learned solely on the preference data dpo: [4.02963904 3.78164203 3.82192236 3.72292355].
2024-09-18 00:06:21,462 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:397] - INFO: Uniform reward: 3.8432, 3.8432, 3.2055
2024-09-18 00:06:21,462 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Optimal reward: 3.8824, 3.8824, 3.3310
2024-09-18 00:06:21,463 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Policy reward: 3.7171, 3.7356, 3.2903
2024-09-18 00:06:21,463 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Reward Error: 0.0426, 0.0378, 0.0122
2024-09-18 00:06:22,144 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:415] - INFO: Optimal reward: 3.8824, 3.8824, 3.3310
Known param reward: [[3.8824145793914795, 3.4862008094787598, 3.297610282897949], [3.4862008094787598, 3.8824145793914795, 3.138624906539917], [3.839902877807617, 3.6102006435394287, 3.3310482501983643]], Known param reward error: [[0.0, 0.10205344169473558, 0.010038271675717638], [0.10205344169473558, 0.0, 0.05776660354499171], [0.01094980989653235, 0.07011459757466626, 0.0]].
