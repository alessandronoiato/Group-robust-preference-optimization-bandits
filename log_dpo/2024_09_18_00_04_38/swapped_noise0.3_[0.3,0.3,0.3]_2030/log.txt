2024-09-18 00:07:30,764 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:198] - INFO: Logging to log_dpo/2024_09_18_00_04_38/swapped_noise0.3_[0.3,0.3,0.3]_2030
2024-09-18 00:07:30,766 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: (IB) Seed: 2030
2024-09-18 00:07:30,767 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Data: 300
2024-09-18 00:07:30,932 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:296] - INFO: MLE reward loss: 0.6041, l2 distance: 6.1695, acc: 0.67.
2024-09-18 00:07:30,933 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-18 00:07:30,934 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: MLE reward parameter: [4.01846157 0.8861833  3.60833406 1.68320097]
2024-09-18 00:07:31,144 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:313] - INFO: Learned oracle reward: 3.4354, 3.7954, 3.1030
2024-09-18 00:07:32,417 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:947] - INFO: Iteration:  0, train_loss:  23.1409, val_loss:  22.8228, grad_norm: 0.5277, reward_err: 0.0294, 0.0742, 0.0208, KL_dist: 0.1011, 0.3050, 0.0996, param: [0.83748837 4.24593237 3.30206893 3.96225831]train_grp_loss: [23.10934624 22.66092939 23.65222677], val_grp_loss: [23.38733254 21.7001909  23.38420964], train_hist_grp_loss: [23.10832693 22.73815562 23.65440334], cur_train_grp_loss: [23.10832693 22.73815562 23.65440334],max_reward_err:  0.0742, max_reward_err_index: 1, max_kl_dist:  0.3050, max_kl_dist_index: 1, max_train_grp_loss:  23.6522, max_train_grp_loss_index: 2, max_val_grp_loss:  23.3873, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  23.6544, max_cur_train_grp_loss_index: 2, 
2024-09-18 00:07:35,553 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:1040] - INFO: Iteration:  99, train_loss:  21.6593, val_loss:  21.5453, grad_norm: 0.2706, reward_err: 0.0798, 0.0291, 0.0459, KL_dist: 0.3505, 0.1572, 0.2414, param: [3.2928343  2.34905602 5.41844652 3.79634519]train_grp_loss: [23.20309951 18.50935642 23.53054738], val_grp_loss: [23.63560045 17.88389735 23.10182767], train_hist_grp_loss: [2315.75621308 2018.64095007 2358.06585384], cur_train_grp_loss: [23.20232419 18.53003133 23.53119495],max_reward_err:  0.0798, max_reward_err_index: 0, max_kl_dist:  0.3505, max_kl_dist_index: 0, max_train_grp_loss:  23.5305, max_train_grp_loss_index: 2, max_val_grp_loss:  23.6356, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  23.5312, max_cur_train_grp_loss_index: 2, 
2024-09-18 00:07:35,779 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:386] - INFO: Policy parameter learned solely on the preference data dpo: [3.2928343  2.34905602 5.41844652 3.79634519].
2024-09-18 00:07:36,108 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:397] - INFO: Uniform reward: 3.7608, 3.7608, 3.1453
2024-09-18 00:07:36,108 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Optimal reward: 3.7986, 3.7986, 3.2836
2024-09-18 00:07:36,109 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Policy reward: 3.4954, 3.6882, 3.1330
2024-09-18 00:07:36,109 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Reward Error: 0.0798, 0.0291, 0.0459
2024-09-18 00:07:36,797 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:415] - INFO: Optimal reward: 3.7986, 3.7986, 3.2836
Known param reward: [[3.798604965209961, 3.430420160293579, 3.2498695850372314], [3.430420160293579, 3.798604965209961, 3.1003451347351074], [3.7635128498077393, 3.557292938232422, 3.283627510070801]], Known param reward error: [[0.0, 0.09692632118592281, 0.01028068041519163], [0.09692632118592281, 0.0, 0.05581704221126515], [0.009238158672359349, 0.0635264864832295, 0.0]].
