2024-09-18 00:05:01,256 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:198] - INFO: Logging to log_dpo/2024_09_18_00_04_38/swapped_noise0.3_[0.3,0.3,0.3]_2022
2024-09-18 00:05:01,258 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: (IB) Seed: 2022
2024-09-18 00:05:01,258 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Data: 300
2024-09-18 00:05:01,425 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:296] - INFO: MLE reward loss: 0.6034, l2 distance: 5.4724, acc: 0.67.
2024-09-18 00:05:01,426 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-18 00:05:01,427 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: MLE reward parameter: [3.2659424  1.84423372 3.9760255  1.5784818 ]
2024-09-18 00:05:01,638 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:313] - INFO: Learned oracle reward: 3.6028, 3.8797, 3.2068
2024-09-18 00:05:02,908 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:947] - INFO: Iteration:  0, train_loss:  22.2839, val_loss:  22.2103, grad_norm: 0.4200, reward_err: 0.0971, 0.0061, 0.0656, KL_dist: 0.2329, 0.0098, 0.1437, param: [1.81337184 1.51489357 4.2626642  1.40263617]train_grp_loss: [24.43461674 17.9032231  24.57632912], val_grp_loss: [23.97666161 18.6289942  24.11234516], train_hist_grp_loss: [24.43860478 17.94698283 24.58089438], cur_train_grp_loss: [24.43860478 17.94698283 24.58089438],max_reward_err:  0.0971, max_reward_err_index: 0, max_kl_dist:  0.2329, max_kl_dist_index: 0, max_train_grp_loss:  24.5763, max_train_grp_loss_index: 2, max_val_grp_loss:  24.1123, max_val_grp_loss_index: 2, max_cur_train_grp_loss:  24.5809, max_cur_train_grp_loss_index: 2, 
2024-09-18 00:05:06,041 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:1040] - INFO: Iteration:  99, train_loss:  21.3682, val_loss:  21.1737, grad_norm: 0.2084, reward_err: 0.0829, 0.0072, 0.0501, KL_dist: 0.4199, 0.1127, 0.2946, param: [3.61613619 2.84844685 6.01007953 2.19433721]train_grp_loss: [24.25704725 15.56067213 24.37145874], val_grp_loss: [23.45430812 16.52985492 23.64887784], train_hist_grp_loss: [2431.96627504 1650.88750496 2444.40691655], cur_train_grp_loss: [24.25748002 15.57259532 24.37197283],max_reward_err:  0.0829, max_reward_err_index: 0, max_kl_dist:  0.4199, max_kl_dist_index: 0, max_train_grp_loss:  24.3715, max_train_grp_loss_index: 2, max_val_grp_loss:  23.6489, max_val_grp_loss_index: 2, max_cur_train_grp_loss:  24.3720, max_cur_train_grp_loss_index: 2, 
2024-09-18 00:05:06,268 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:386] - INFO: Policy parameter learned solely on the preference data dpo: [3.61613619 2.84844685 6.01007953 2.19433721].
2024-09-18 00:05:06,600 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:397] - INFO: Uniform reward: 3.8640, 3.8640, 3.2133
2024-09-18 00:05:06,600 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Optimal reward: 3.8945, 3.8945, 3.3417
2024-09-18 00:05:06,601 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Policy reward: 3.5715, 3.8664, 3.1743
2024-09-18 00:05:06,601 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Reward Error: 0.0829, 0.0072, 0.0501
2024-09-18 00:05:07,296 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:415] - INFO: Optimal reward: 3.8945, 3.8945, 3.3417
Known param reward: [[3.894484758377075, 3.5591492652893066, 3.2951979637145996], [3.5591492652893066, 3.894484758377075, 3.1762964725494385], [3.853400707244873, 3.6607706546783447, 3.3417041301727295]], Known param reward error: [[0.0, 0.08610522672260011, 0.013916901271485703], [0.08610522672260011, 0.0, 0.04949799598647928], [0.01054929051752737, 0.06001155947420493, 0.0]].
