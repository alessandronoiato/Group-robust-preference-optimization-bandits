2024-09-18 00:05:20,089 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:198] - INFO: Logging to log_dpo/2024_09_18_00_04_38/swapped_noise0.3_[0.3,0.3,0.3]_2023
2024-09-18 00:05:20,091 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: (IB) Seed: 2023
2024-09-18 00:05:20,091 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Data: 300
2024-09-18 00:05:20,256 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:296] - INFO: MLE reward loss: 0.6216, l2 distance: 6.5611, acc: 0.64.
2024-09-18 00:05:20,257 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-18 00:05:20,258 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: MLE reward parameter: [4.7065771  0.3900871  1.98714044 2.00890037]
2024-09-18 00:05:20,470 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:313] - INFO: Learned oracle reward: 3.3662, 3.7955, 3.0013
2024-09-18 00:05:21,745 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:947] - INFO: Iteration:  0, train_loss:  22.7826, val_loss:  22.5670, grad_norm: 0.3309, reward_err: 0.0484, 0.0559, 0.0176, KL_dist: 0.1318, 0.1422, 0.0686, param: [2.91152409 1.81852741 3.15457092 3.88732827]train_grp_loss: [24.77904969 19.97789621 23.82133431], val_grp_loss: [23.34210551 20.49769453 23.74040972], train_hist_grp_loss: [24.77852307 20.01013139 23.82039661], cur_train_grp_loss: [24.77852307 20.01013139 23.82039661],max_reward_err:  0.0559, max_reward_err_index: 1, max_kl_dist:  0.1422, max_kl_dist_index: 1, max_train_grp_loss:  24.7790, max_train_grp_loss_index: 0, max_val_grp_loss:  23.7404, max_val_grp_loss_index: 2, max_cur_train_grp_loss:  24.7785, max_cur_train_grp_loss_index: 0, 
2024-09-18 00:05:24,844 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:1040] - INFO: Iteration:  99, train_loss:  22.1325, val_loss:  22.0052, grad_norm: 0.1923, reward_err: 0.0792, 0.0190, 0.0400, KL_dist: 0.3914, 0.1389, 0.2578, param: [4.99710975 1.28218186 4.41455528 3.64195799]train_grp_loss: [24.85474398 18.00042222 23.89591579], val_grp_loss: [23.16218184 19.02573199 23.64969688], train_hist_grp_loss: [2481.39596413 1884.65816167 2386.09974097], cur_train_grp_loss: [24.85391831 18.01214333 23.89535237],max_reward_err:  0.0792, max_reward_err_index: 0, max_kl_dist:  0.3914, max_kl_dist_index: 0, max_train_grp_loss:  24.8547, max_train_grp_loss_index: 0, max_val_grp_loss:  23.6497, max_val_grp_loss_index: 2, max_cur_train_grp_loss:  24.8539, max_cur_train_grp_loss_index: 0, 
2024-09-18 00:05:25,066 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:386] - INFO: Policy parameter learned solely on the preference data dpo: [4.99710975 1.28218186 4.41455528 3.64195799].
2024-09-18 00:05:25,399 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:397] - INFO: Uniform reward: 3.7891, 3.7891, 3.1403
2024-09-18 00:05:25,399 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Optimal reward: 3.8234, 3.8234, 3.2644
2024-09-18 00:05:25,400 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Policy reward: 3.5204, 3.7506, 3.1339
2024-09-18 00:05:25,400 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Reward Error: 0.0792, 0.0190, 0.0400
2024-09-18 00:05:26,076 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:415] - INFO: Optimal reward: 3.8234, 3.8234, 3.2644
Known param reward: [[3.823425769805908, 3.428101062774658, 3.2270522117614746], [3.428101062774658, 3.823425769805908, 3.0676209926605225], [3.7817330360412598, 3.553356885910034, 3.2643818855285645]], Known param reward error: [[0.0, 0.10339541835836875, 0.011435449367176435], [0.10339541835836875, 0.0, 0.06027508415614882], [0.010904549028753582, 0.07063531506970613, 0.0]].
