2024-09-18 00:06:54,188 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:198] - INFO: Logging to log_dpo/2024_09_18_00_04_38/swapped_noise0.3_[0.3,0.3,0.3]_2028
2024-09-18 00:06:54,190 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: (IB) Seed: 2028
2024-09-18 00:06:54,191 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Data: 300
2024-09-18 00:06:54,356 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:296] - INFO: MLE reward loss: 0.6315, l2 distance: 5.0685, acc: 0.66.
2024-09-18 00:06:54,357 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-18 00:06:54,357 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: MLE reward parameter: [3.93030512 1.4260229  2.41114849 1.53842276]
2024-09-18 00:06:54,568 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:313] - INFO: Learned oracle reward: 3.4969, 3.8255, 3.1060
2024-09-18 00:06:55,844 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:947] - INFO: Iteration:  0, train_loss:  23.9292, val_loss:  23.5851, grad_norm: 0.4233, reward_err: 0.0619, 0.0787, 0.0442, KL_dist: 0.0831, 0.1058, 0.0571, param: [0.24571418 1.05373194 2.22439854 2.29207675]train_grp_loss: [24.14626783 23.33318667 24.23487848], val_grp_loss: [24.2842373  22.13179861 24.33220325], train_hist_grp_loss: [24.15242649 23.3777192  24.24170682], cur_train_grp_loss: [24.15242649 23.3777192  24.24170682],max_reward_err:  0.0787, max_reward_err_index: 1, max_kl_dist:  0.1058, max_kl_dist_index: 1, max_train_grp_loss:  24.2349, max_train_grp_loss_index: 2, max_val_grp_loss:  24.3322, max_val_grp_loss_index: 2, max_cur_train_grp_loss:  24.2417, max_cur_train_grp_loss_index: 2, 
2024-09-18 00:06:58,954 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:1040] - INFO: Iteration:  99, train_loss:  22.8331, val_loss:  22.3133, grad_norm: 0.2530, reward_err: 0.0782, 0.0139, 0.0424, KL_dist: 0.2136, 0.0464, 0.1213, param: [2.76457096 1.97378786 4.07903885 2.38039674]train_grp_loss: [23.76789205 20.63729613 23.78226933], val_grp_loss: [23.7071084  19.3448333  23.87633986], train_hist_grp_loss: [2392.9198511  2178.07297603 2398.21105022], cur_train_grp_loss: [23.77007854 20.65270152 23.78521836],max_reward_err:  0.0782, max_reward_err_index: 0, max_kl_dist:  0.2136, max_kl_dist_index: 0, max_train_grp_loss:  23.7823, max_train_grp_loss_index: 2, max_val_grp_loss:  23.8763, max_val_grp_loss_index: 2, max_cur_train_grp_loss:  23.7852, max_cur_train_grp_loss_index: 2, 
2024-09-18 00:06:59,177 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:386] - INFO: Policy parameter learned solely on the preference data dpo: [2.76457096 1.97378786 4.07903885 2.38039674].
2024-09-18 00:06:59,511 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:397] - INFO: Uniform reward: 3.7976, 3.7976, 3.1463
2024-09-18 00:06:59,512 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Optimal reward: 3.8371, 3.8371, 3.2754
2024-09-18 00:06:59,512 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Policy reward: 3.5369, 3.7837, 3.1366
2024-09-18 00:06:59,513 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Reward Error: 0.0782, 0.0139, 0.0424
2024-09-18 00:07:00,188 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:415] - INFO: Optimal reward: 3.8371, 3.8371, 3.2754
Known param reward: [[3.8370602130889893, 3.438476324081421, 3.2456254959106445], [3.438476324081421, 3.8370602130889893, 3.073289155960083], [3.8012948036193848, 3.564321994781494, 3.2754106521606445]], Known param reward error: [[0.0, 0.10387741314246725, 0.009093563956736857], [0.10387741314246725, 0.0, 0.06170874973103933], [0.00932104462359007, 0.07107999436056016, 0.0]].
