2024-09-18 00:07:13,185 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:198] - INFO: Logging to log_dpo/2024_09_18_00_04_38/swapped_noise0.3_[0.3,0.3,0.3]_2029
2024-09-18 00:07:13,187 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: (IB) Seed: 2029
2024-09-18 00:07:13,188 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Data: 300
2024-09-18 00:07:13,352 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:296] - INFO: MLE reward loss: 0.5745, l2 distance: 7.7465, acc: 0.68.
2024-09-18 00:07:13,352 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-18 00:07:13,353 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: MLE reward parameter: [2.96769503 2.35165722 5.74475451 1.46407424]
2024-09-18 00:07:13,557 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:313] - INFO: Learned oracle reward: 3.4892, 3.8780, 3.1686
2024-09-18 00:07:14,814 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:947] - INFO: Iteration:  0, train_loss:  21.7900, val_loss:  22.4507, grad_norm: 0.4897, reward_err: 0.0725, 0.0116, 0.0353, KL_dist: 0.1630, 0.0253, 0.0775, param: [2.58383603 2.12256676 3.20226937 1.44137989]train_grp_loss: [24.52277135 17.80061654 23.68519271], val_grp_loss: [23.88008432 19.21603866 23.91494812], train_hist_grp_loss: [24.525793   17.85323365 23.69662141], cur_train_grp_loss: [24.525793   17.85323365 23.69662141],max_reward_err:  0.0725, max_reward_err_index: 0, max_kl_dist:  0.1630, max_kl_dist_index: 0, max_train_grp_loss:  24.5228, max_train_grp_loss_index: 0, max_val_grp_loss:  23.9149, max_val_grp_loss_index: 2, max_cur_train_grp_loss:  24.5258, max_cur_train_grp_loss_index: 0, 
2024-09-18 00:07:17,919 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:1040] - INFO: Iteration:  99, train_loss:  20.4929, val_loss:  21.4086, grad_norm: 0.2576, reward_err: 0.0833, 0.0066, 0.0442, KL_dist: 0.4682, 0.1458, 0.3218, param: [4.42734036 3.36720038 5.83987498 2.14001774]train_grp_loss: [24.43747947 14.95229689 22.97904288], val_grp_loss: [23.36841749 16.98579905 23.40516519], train_hist_grp_loss: [2445.435742   1611.16748088 2328.19816414], cur_train_grp_loss: [24.4370882  14.96699605 22.98325815],max_reward_err:  0.0833, max_reward_err_index: 0, max_kl_dist:  0.4682, max_kl_dist_index: 0, max_train_grp_loss:  24.4375, max_train_grp_loss_index: 0, max_val_grp_loss:  23.4052, max_val_grp_loss_index: 2, max_cur_train_grp_loss:  24.4371, max_cur_train_grp_loss_index: 0, 
2024-09-18 00:07:18,139 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:386] - INFO: Policy parameter learned solely on the preference data dpo: [4.42734036 3.36720038 5.83987498 2.14001774].
2024-09-18 00:07:18,465 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:397] - INFO: Uniform reward: 3.8435, 3.8435, 3.2360
2024-09-18 00:07:18,466 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Optimal reward: 3.8889, 3.8889, 3.3830
2024-09-18 00:07:18,467 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Policy reward: 3.5651, 3.8631, 3.2333
2024-09-18 00:07:18,467 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Reward Error: 0.0833, 0.0066, 0.0442
2024-09-18 00:07:19,147 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:415] - INFO: Optimal reward: 3.8889, 3.8889, 3.3830
Known param reward: [[3.8888535499572754, 3.4823989868164062, 3.3450193405151367], [3.4823989868164062, 3.8888535499572754, 3.1775741577148438], [3.852006435394287, 3.6119940280914307, 3.382976770401001]], Known param reward error: [[0.0, 0.10451783743446308, 0.011220127261283255], [0.10451783743446308, 0.0, 0.06071653062572163], [0.009475058417510502, 0.07119309542239934, 0.0]].
