2024-09-17 23:00:13,323 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:198] - INFO: Logging to log_dpo/2024_09_17_23_00_08/swapped_noise0.8_[0.8,0.8,0.8]_2021
2024-09-17 23:00:13,324 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: (IB) Seed: 2021
2024-09-17 23:00:13,325 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Data: 300
2024-09-17 23:00:13,490 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:296] - INFO: MLE reward loss: 0.4786, l2 distance: 16.2585, acc: 0.78.
2024-09-17 23:00:13,491 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-17 23:00:13,492 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: MLE reward parameter: [8.85125512 3.67477553 7.24668871 4.26292019]
2024-09-17 23:00:13,692 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:313] - INFO: Learned oracle reward: 3.5287, 3.8752, 3.1509
2024-09-17 23:00:14,969 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:947] - INFO: Iteration:  0, train_loss:  23.4746, val_loss:  23.6169, grad_norm: 0.8336, reward_err: 0.0107, 0.1419, 0.0132, KL_dist: 0.0548, 0.2367, 0.0530, param: [0.60043898 3.09737216 0.38298166 0.06198001]train_grp_loss: [23.85839834 22.60492736 24.0316733 ], val_grp_loss: [23.82971636 23.15381122 23.89705583], train_hist_grp_loss: [23.88964879 22.7391385  24.06925554], cur_train_grp_loss: [23.88964879 22.7391385  24.06925554],max_reward_err:  0.1419, max_reward_err_index: 1, max_kl_dist:  0.2367, max_kl_dist_index: 1, max_train_grp_loss:  24.0317, max_train_grp_loss_index: 2, max_val_grp_loss:  23.8971, max_val_grp_loss_index: 2, max_cur_train_grp_loss:  24.0693, max_cur_train_grp_loss_index: 2, 
2024-09-17 23:00:18,057 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:1040] - INFO: Iteration:  99, train_loss:  19.2834, val_loss:  19.1625, grad_norm: 0.4910, reward_err: 0.0685, 0.0224, 0.0314, KL_dist: 0.3356, 0.1670, 0.2262, param: [4.72329046 3.94950746 4.62600138 2.27239088]train_grp_loss: [21.89107325 14.77721279 21.51913246], val_grp_loss: [21.9730082  14.28013392 21.53608628], train_hist_grp_loss: [2273.95984025 1804.36302852 2263.2131764 ], cur_train_grp_loss: [21.90291514 14.81968713 21.53565042],max_reward_err:  0.0685, max_reward_err_index: 0, max_kl_dist:  0.3356, max_kl_dist_index: 0, max_train_grp_loss:  21.8911, max_train_grp_loss_index: 0, max_val_grp_loss:  21.9730, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  21.9029, max_cur_train_grp_loss_index: 0, 
2024-09-17 23:00:18,274 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:386] - INFO: Policy parameter learned solely on the preference data dpo: [4.72329046 3.94950746 4.62600138 2.27239088].
2024-09-17 23:00:18,596 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:397] - INFO: Uniform reward: 3.8503, 3.8503, 3.2061
2024-09-17 23:00:18,596 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Optimal reward: 3.8851, 3.8851, 3.3189
2024-09-17 23:00:18,597 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Policy reward: 3.6190, 3.7980, 3.2148
2024-09-17 23:00:18,597 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Reward Error: 0.0685, 0.0224, 0.0314
2024-09-17 23:00:19,264 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:415] - INFO: Optimal reward: 3.8851, 3.8851, 3.3189
Known param reward: [[3.88508939743042, 3.4581034183502197, 3.2941160202026367], [3.4581034183502197, 3.88508939743042, 3.1016483306884766], [3.85002064704895, 3.5887107849121094, 3.318911552429199]], Known param reward error: [[0.0, 0.10990377193446481, 0.007470983132531505], [0.10990377193446481, 0.0, 0.06546219093476653], [0.009026497666865538, 0.07628617573493521, 0.0]].
