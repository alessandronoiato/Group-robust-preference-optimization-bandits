2024-09-17 23:02:08,470 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:198] - INFO: Logging to log_dpo/2024_09_17_23_00_08/swapped_noise0.8_[0.8,0.8,0.8]_2027
2024-09-17 23:02:08,472 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: (IB) Seed: 2027
2024-09-17 23:02:08,473 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Data: 300
2024-09-17 23:02:08,631 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:296] - INFO: MLE reward loss: 0.4324, l2 distance: 21.3623, acc: 0.80.
2024-09-17 23:02:08,632 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-17 23:02:08,632 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: MLE reward parameter: [10.83332372  4.64836606  8.49815802  6.36770439]
2024-09-17 23:02:08,839 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:313] - INFO: Learned oracle reward: 3.4927, 3.7291, 3.1055
2024-09-17 23:02:10,110 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:947] - INFO: Iteration:  0, train_loss:  19.6203, val_loss:  19.3698, grad_norm: 0.6330, reward_err: 0.0534, 0.0248, 0.0254, KL_dist: 0.2189, 0.1367, 0.1392, param: [2.95778847 3.52693162 4.33926513 2.65178352]train_grp_loss: [21.86004031 15.15956498 21.26779782], val_grp_loss: [22.01766484 14.72390462 21.4457946 ], train_hist_grp_loss: [21.88098261 15.23263986 21.29791248], cur_train_grp_loss: [21.88098261 15.23263986 21.29791248],max_reward_err:  0.0534, max_reward_err_index: 0, max_kl_dist:  0.2189, max_kl_dist_index: 0, max_train_grp_loss:  21.8600, max_train_grp_loss_index: 0, max_val_grp_loss:  22.0177, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  21.8810, max_cur_train_grp_loss_index: 0, 
2024-09-17 23:02:13,212 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:1040] - INFO: Iteration:  99, train_loss:  17.1844, val_loss:  17.1063, grad_norm: 0.3758, reward_err: 0.0662, 0.0094, 0.0331, KL_dist: 0.7596, 0.3908, 0.5827, param: [6.49330948 4.06751495 7.31395661 4.06047238]train_grp_loss: [20.51673976 11.04458574 19.20510778], val_grp_loss: [20.96875995 10.82993232 19.62632955], train_hist_grp_loss: [2110.09148259 1272.93707175 2012.81577432], cur_train_grp_loss: [20.52504549 11.06535747 19.21911644],max_reward_err:  0.0662, max_reward_err_index: 0, max_kl_dist:  0.7596, max_kl_dist_index: 0, max_train_grp_loss:  20.5167, max_train_grp_loss_index: 0, max_val_grp_loss:  20.9688, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  20.5250, max_cur_train_grp_loss_index: 0, 
2024-09-17 23:02:13,433 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:386] - INFO: Policy parameter learned solely on the preference data dpo: [6.49330948 4.06751495 7.31395661 4.06047238].
2024-09-17 23:02:13,756 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:397] - INFO: Uniform reward: 3.7241, 3.7241, 3.0868
2024-09-17 23:02:13,756 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Optimal reward: 3.7658, 3.7658, 3.2313
2024-09-17 23:02:13,757 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Policy reward: 3.5167, 3.7303, 3.1243
2024-09-17 23:02:13,757 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Reward Error: 0.0662, 0.0094, 0.0331
2024-09-17 23:02:14,425 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:415] - INFO: Optimal reward: 3.7658, 3.7658, 3.2313
Known param reward: [[3.7658329010009766, 3.411930561065674, 3.1902992725372314], [3.411930561065674, 3.7658329010009766, 3.0509254932403564], [3.727386713027954, 3.5327694416046143, 3.2313315868377686]], Known param reward error: [[0.0, 0.09397717563124848, 0.012698267942440401], [0.09397717563124848, 0.0, 0.055830263391186144], [0.01020921240631874, 0.06188895405699305, 0.0]].
