2024-09-17 23:02:27,104 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:198] - INFO: Logging to log_dpo/2024_09_17_23_00_08/swapped_noise0.8_[0.8,0.8,0.8]_2028
2024-09-17 23:02:27,106 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: (IB) Seed: 2028
2024-09-17 23:02:27,106 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Data: 300
2024-09-17 23:02:27,265 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:296] - INFO: MLE reward loss: 0.4703, l2 distance: 18.6595, acc: 0.79.
2024-09-17 23:02:27,266 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-17 23:02:27,267 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: MLE reward parameter: [9.55159483 5.16480276 8.41496352 3.30300138]
2024-09-17 23:02:27,479 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:313] - INFO: Learned oracle reward: 3.5127, 3.8159, 3.1225
2024-09-17 23:02:28,759 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:947] - INFO: Iteration:  0, train_loss:  21.5767, val_loss:  21.5995, grad_norm: 0.6954, reward_err: 0.1057, 0.0282, 0.0692, KL_dist: 0.1919, 0.0421, 0.1075, param: [1.77041476 2.36206812 3.60213186 0.3854709 ]train_grp_loss: [23.15645793 17.81680166 23.22942684], val_grp_loss: [23.2264937  18.22513396 23.20603279], train_hist_grp_loss: [23.18030353 17.91972373 23.25548629], cur_train_grp_loss: [23.18030353 17.91972373 23.25548629],max_reward_err:  0.1057, max_reward_err_index: 0, max_kl_dist:  0.1919, max_kl_dist_index: 0, max_train_grp_loss:  23.2294, max_train_grp_loss_index: 2, max_val_grp_loss:  23.2265, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  23.2555, max_cur_train_grp_loss_index: 2, 
2024-09-17 23:02:31,939 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_dpo_vectorised.py[line:1040] - INFO: Iteration:  99, train_loss:  18.5404, val_loss:  18.5955, grad_norm: 0.4275, reward_err: 0.0967, 0.0028, 0.0569, KL_dist: 0.6868, 0.2548, 0.4988, param: [5.75623102 3.61057327 6.90582966 1.47591884]train_grp_loss: [21.560229   11.646344   21.40952809], val_grp_loss: [21.7272697  12.41299924 21.37221527], train_hist_grp_loss: [2226.71573182 1424.52911449 2222.99304197], cur_train_grp_loss: [21.57069192 11.68049943 21.42215427],max_reward_err:  0.0967, max_reward_err_index: 0, max_kl_dist:  0.6868, max_kl_dist_index: 0, max_train_grp_loss:  21.5602, max_train_grp_loss_index: 0, max_val_grp_loss:  21.7273, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  21.5707, max_cur_train_grp_loss_index: 0, 
2024-09-17 23:02:32,172 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:386] - INFO: Policy parameter learned solely on the preference data dpo: [5.75623102 3.61057327 6.90582966 1.47591884].
2024-09-17 23:02:32,499 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:397] - INFO: Uniform reward: 3.7921, 3.7921, 3.1395
2024-09-17 23:02:32,500 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Optimal reward: 3.8328, 3.8328, 3.2723
2024-09-17 23:02:32,500 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Policy reward: 3.4622, 3.8221, 3.0860
2024-09-17 23:02:32,501 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Reward Error: 0.0967, 0.0028, 0.0569
2024-09-17 23:02:33,176 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:415] - INFO: Optimal reward: 3.8328, 3.8328, 3.2723
Known param reward: [[3.8328447341918945, 3.4360735416412354, 3.2429821491241455], [3.4360735416412354, 3.8328447341918945, 3.0682969093322754], [3.796973705291748, 3.567776918411255, 3.272308111190796]], Known param reward error: [[0.0, 0.1035187230547478, 0.008961858440640128], [0.1035187230547478, 0.0, 0.06234474105932544], [0.0093588525984759, 0.06915694064412076, 0.0]].
