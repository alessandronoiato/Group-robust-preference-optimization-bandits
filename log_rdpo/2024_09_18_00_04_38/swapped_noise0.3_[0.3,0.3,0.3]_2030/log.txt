2024-09-18 00:10:48,062 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:198] - INFO: Logging to log_rdpo/2024_09_18_00_04_38/swapped_noise0.3_[0.3,0.3,0.3]_2030
2024-09-18 00:10:48,064 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: (IB) Seed: 2030
2024-09-18 00:10:48,065 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Data: 300
2024-09-18 00:10:48,246 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:296] - INFO: MLE reward loss: 0.6041, l2 distance: 6.1695, acc: 0.67.
2024-09-18 00:10:48,247 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-18 00:10:48,248 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: MLE reward parameter: [4.01846157 0.8861833  3.60833406 1.68320097]
2024-09-18 00:10:48,463 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:313] - INFO: Learned oracle reward: 3.4354, 3.7954, 3.1030
2024-09-18 00:10:48,721 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-18 00:10:49,889 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  21.0143, val_loss:  20.9513, grad_norm: 0.1759, live_grad: 0.0000, reward_err: 0.1016, 0.0011, 0.0599, KL_dist: 0.9694, 0.3468, 0.7237, param: [7.8407217  1.5372385  7.5204431  3.17228371], weights: [0.33342167 0.33327122 0.33330711], train_wt_loss:  63.0428, val_wt_loss: 62.8540, train_grp_loss: [23.36686248 16.6456848  23.43034994], val_grp_loss: [24.06041487 15.92492427 22.82438655], train_hist_grp_loss: [0.25964412 0.2145109  0.22528003], cur_train_grp_loss: [0.25964412 0.2145109  0.22528003], max_reward_err:  0.1016, max_reward_err_index: 0, max_kl_dist:  0.9694, max_kl_dist_index: 0, max_train_grp_loss:  23.4303, max_train_grp_loss_index: 2, max_val_grp_loss:  24.0604, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2596, max_cur_train_grp_loss_index: 0, 
2024-09-18 00:10:54,181 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  99, train_loss:  21.0149, val_loss:  20.9388, grad_norm: 0.0037,  live_grad: 0.0000, reward_err: 0.1004, 0.0011, 0.0589, KL_dist: 0.9645, 0.3481, 0.7206, param: [7.78121689 1.62920136 7.57463055 3.23217419], weights: [0.3493785 0.3146911 0.3359304], train_wt_loss:  63.0448, val_wt_loss: 62.8164, train_grp_loss: [23.33687846 16.6862197  23.41670327], val_grp_loss: [24.03280828 15.93369494 22.80601446], train_hist_grp_loss: [26.23564651 15.77921098 22.31045925], cur_train_grp_loss: [0.26221562 0.15741301 0.22301758], max_reward_err:  0.1004, max_reward_err_index: 0, max_kl_dist:  0.9645, max_kl_dist_index: 0, max_train_grp_loss:  23.4167, max_train_grp_loss_index: 2, max_val_grp_loss:  24.0328, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2622, max_cur_train_grp_loss_index: 0, 
2024-09-18 00:10:54,401 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:386] - INFO: Policy parameter learned solely on the preference data rdpo: [7.78121689 1.62920136 7.57463055 3.23217419].
2024-09-18 00:10:54,722 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:397] - INFO: Uniform reward: 3.7608, 3.7608, 3.1453
2024-09-18 00:10:54,723 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Optimal reward: 3.7986, 3.7986, 3.2836
2024-09-18 00:10:54,724 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Policy reward: 3.4172, 3.7945, 3.0903
2024-09-18 00:10:54,724 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Reward Error: 0.1004, 0.0011, 0.0589
2024-09-18 00:10:55,400 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:415] - INFO: Optimal reward: 3.7986, 3.7986, 3.2836
Known param reward: [[3.798604965209961, 3.430420160293579, 3.2498695850372314], [3.430420160293579, 3.798604965209961, 3.1003451347351074], [3.7635128498077393, 3.557292938232422, 3.283627510070801]], Known param reward error: [[0.0, 0.09692632118592281, 0.01028068041519163], [0.09692632118592281, 0.0, 0.05581704221126515], [0.009238158672359349, 0.0635264864832295, 0.0]].
