2024-09-18 00:10:07,914 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:198] - INFO: Logging to log_rdpo/2024_09_18_00_04_38/swapped_noise0.3_[0.3,0.3,0.3]_2028
2024-09-18 00:10:07,916 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: (IB) Seed: 2028
2024-09-18 00:10:07,917 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Data: 300
2024-09-18 00:10:08,085 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:296] - INFO: MLE reward loss: 0.6315, l2 distance: 5.0685, acc: 0.66.
2024-09-18 00:10:08,086 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-18 00:10:08,087 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: MLE reward parameter: [3.93030512 1.4260229  2.41114849 1.53842276]
2024-09-18 00:10:08,300 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:313] - INFO: Learned oracle reward: 3.4969, 3.8255, 3.1060
2024-09-18 00:10:08,558 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-18 00:10:09,726 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  22.1654, val_loss:  21.4499, grad_norm: 0.1411, live_grad: 0.0000, reward_err: 0.0909, 0.0023, 0.0535, KL_dist: 0.8114, 0.2854, 0.6225, param: [8.40503939 2.95451701 5.05618238 2.98265022], weights: [0.33319977 0.33338905 0.33341119], train_wt_loss:  66.4963, val_wt_loss: 64.3498, train_grp_loss: [23.67309585 18.96919495 23.35499728], val_grp_loss: [22.99865024 17.73970754 23.61124866], train_hist_grp_loss: [0.20296157 0.25975244 0.26639238], cur_train_grp_loss: [0.20296157 0.25975244 0.26639238], max_reward_err:  0.0909, max_reward_err_index: 0, max_kl_dist:  0.8114, max_kl_dist_index: 0, max_train_grp_loss:  23.6731, max_train_grp_loss_index: 0, max_val_grp_loss:  23.6112, max_val_grp_loss_index: 2, max_cur_train_grp_loss:  0.2664, max_cur_train_grp_loss_index: 2, 
2024-09-18 00:10:14,107 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  99, train_loss:  22.1655, val_loss:  21.4492, grad_norm: 0.0006,  live_grad: 0.0000, reward_err: 0.0904, 0.0023, 0.0532, KL_dist: 0.8126, 0.2868, 0.6239, param: [8.41857671 2.96352926 5.05253568 3.00328988], weights: [0.3255322  0.32957761 0.34489019], train_wt_loss:  66.4964, val_wt_loss: 64.3475, train_grp_loss: [23.66929284 18.97858609 23.35074932], val_grp_loss: [22.9938397  17.74445886 23.6091608 ], train_hist_grp_loss: [19.89584564 21.13089512 25.67231481], cur_train_grp_loss: [0.19890196 0.21087207 0.25660213], max_reward_err:  0.0904, max_reward_err_index: 0, max_kl_dist:  0.8126, max_kl_dist_index: 0, max_train_grp_loss:  23.6693, max_train_grp_loss_index: 0, max_val_grp_loss:  23.6092, max_val_grp_loss_index: 2, max_cur_train_grp_loss:  0.2566, max_cur_train_grp_loss_index: 2, 
2024-09-18 00:10:14,333 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:386] - INFO: Policy parameter learned solely on the preference data rdpo: [8.41857671 2.96352926 5.05253568 3.00328988].
2024-09-18 00:10:14,669 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:397] - INFO: Uniform reward: 3.7976, 3.7976, 3.1463
2024-09-18 00:10:14,670 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Optimal reward: 3.8371, 3.8371, 3.2754
2024-09-18 00:10:14,670 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Policy reward: 3.4900, 3.8282, 3.1011
2024-09-18 00:10:14,671 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Reward Error: 0.0904, 0.0023, 0.0532
2024-09-18 00:10:15,365 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:415] - INFO: Optimal reward: 3.8371, 3.8371, 3.2754
Known param reward: [[3.8370602130889893, 3.438476324081421, 3.2456254959106445], [3.438476324081421, 3.8370602130889893, 3.073289155960083], [3.8012948036193848, 3.564321994781494, 3.2754106521606445]], Known param reward error: [[0.0, 0.10387741314246725, 0.009093563956736857], [0.10387741314246725, 0.0, 0.06170874973103933], [0.00932104462359007, 0.07107999436056016, 0.0]].
