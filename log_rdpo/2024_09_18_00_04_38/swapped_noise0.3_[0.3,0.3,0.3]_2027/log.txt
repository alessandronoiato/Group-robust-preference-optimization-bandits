2024-09-18 00:09:46,802 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:198] - INFO: Logging to log_rdpo/2024_09_18_00_04_38/swapped_noise0.3_[0.3,0.3,0.3]_2027
2024-09-18 00:09:46,804 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: (IB) Seed: 2027
2024-09-18 00:09:46,805 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Data: 300
2024-09-18 00:09:46,970 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:296] - INFO: MLE reward loss: 0.6243, l2 distance: 6.3360, acc: 0.67.
2024-09-18 00:09:46,971 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-18 00:09:46,972 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: MLE reward parameter: [2.60531195 1.15870477 4.64436803 1.17738271]
2024-09-18 00:09:47,183 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:313] - INFO: Learned oracle reward: 3.4112, 3.8579, 3.1219
2024-09-18 00:09:47,435 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-18 00:09:48,617 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  21.8298, val_loss:  20.8375, grad_norm: 0.1502, live_grad: 0.0000, reward_err: 0.1197, 0.0006, 0.0776, KL_dist: 1.1782, 0.3434, 0.9190, param: [ 5.33747569  2.36542264 10.03949369  2.34824049], weights: [0.33330757 0.33339471 0.33329772], train_wt_loss:  65.4895, val_wt_loss: 62.5125, train_grp_loss: [24.83129366 16.75951355 23.25123027], val_grp_loss: [23.42087558 14.37149785 24.53926632], train_hist_grp_loss: [0.23350972 0.25964906 0.23055383], cur_train_grp_loss: [0.23350972 0.25964906 0.23055383], max_reward_err:  0.1197, max_reward_err_index: 0, max_kl_dist:  1.1782, max_kl_dist_index: 0, max_train_grp_loss:  24.8313, max_train_grp_loss_index: 0, max_val_grp_loss:  24.5393, max_val_grp_loss_index: 2, max_cur_train_grp_loss:  0.2596, max_cur_train_grp_loss_index: 1, 
2024-09-18 00:09:52,990 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  99, train_loss:  21.8304, val_loss:  20.8345, grad_norm: 0.0029,  live_grad: 0.0000, reward_err: 0.1204, 0.0006, 0.0785, KL_dist: 1.1800, 0.3397, 0.9238, param: [ 5.17566539  2.4111308  10.10491918  2.39179541], weights: [0.34114227 0.32349185 0.33536588], train_wt_loss:  65.4912, val_wt_loss: 62.5034, train_grp_loss: [24.78552545 16.84210216 23.22665217], val_grp_loss: [23.40812762 14.38721117 24.52771236], train_hist_grp_loss: [23.84936651 18.53679892 22.14161712], cur_train_grp_loss: [0.23832677 0.18506876 0.22120854], max_reward_err:  0.1204, max_reward_err_index: 0, max_kl_dist:  1.1800, max_kl_dist_index: 0, max_train_grp_loss:  24.7855, max_train_grp_loss_index: 0, max_val_grp_loss:  24.5277, max_val_grp_loss_index: 2, max_cur_train_grp_loss:  0.2383, max_cur_train_grp_loss_index: 0, 
2024-09-18 00:09:53,215 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:386] - INFO: Policy parameter learned solely on the preference data rdpo: [ 5.17566539  2.4111308  10.10491918  2.39179541].
2024-09-18 00:09:53,543 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:397] - INFO: Uniform reward: 3.8135, 3.8135, 3.2174
2024-09-18 00:09:53,544 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Optimal reward: 3.8600, 3.8600, 3.3713
2024-09-18 00:09:53,544 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Policy reward: 3.3951, 3.8577, 3.1067
2024-09-18 00:09:53,545 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Reward Error: 0.1204, 0.0006, 0.0785
2024-09-18 00:09:54,229 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:415] - INFO: Optimal reward: 3.8600, 3.8600, 3.3713
Known param reward: [[3.859951972961426, 3.4618985652923584, 3.3295209407806396], [3.4618985652923584, 3.859951972961426, 3.1724629402160645], [3.8154780864715576, 3.5898795127868652, 3.3713200092315674]], Known param reward error: [[0.0, 0.10312392756629911, 0.012398428015279123], [0.10312392756629911, 0.0, 0.05898492829840525], [0.011521875609179402, 0.06996782915082646, 0.0]].
