2024-09-18 00:09:27,761 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:198] - INFO: Logging to log_rdpo/2024_09_18_00_04_38/swapped_noise0.3_[0.3,0.3,0.3]_2026
2024-09-18 00:09:27,763 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: (IB) Seed: 2026
2024-09-18 00:09:27,763 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Data: 300
2024-09-18 00:09:27,929 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:296] - INFO: MLE reward loss: 0.5844, l2 distance: 6.5700, acc: 0.70.
2024-09-18 00:09:27,930 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-18 00:09:27,931 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: MLE reward parameter: [5.06300368 2.19028036 2.7385319  2.66543984]
2024-09-18 00:09:28,138 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:313] - INFO: Learned oracle reward: 3.5463, 3.8327, 3.1668
2024-09-18 00:09:28,372 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-18 00:09:29,535 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  20.2963, val_loss:  22.5554, grad_norm: 0.1682, live_grad: 0.0000, reward_err: 0.0938, 0.0078, 0.0564, KL_dist: 1.0304, 0.4375, 0.8344, param: [10.03973789  3.69602442  4.883337    4.4857844 ], weights: [0.33332902 0.33324503 0.33342595], train_wt_loss:  60.8890, val_wt_loss: 67.6662, train_grp_loss: [22.98640222 15.87439815 22.04268756], val_grp_loss: [23.32849944 20.28306462 24.03117316], train_hist_grp_loss: [0.22428274 0.19908358 0.25336076], cur_train_grp_loss: [0.22428274 0.19908358 0.25336076], max_reward_err:  0.0938, max_reward_err_index: 0, max_kl_dist:  1.0304, max_kl_dist_index: 0, max_train_grp_loss:  22.9864, max_train_grp_loss_index: 0, max_val_grp_loss:  24.0312, max_val_grp_loss_index: 2, max_cur_train_grp_loss:  0.2534, max_cur_train_grp_loss_index: 2, 
2024-09-18 00:09:33,954 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  99, train_loss:  20.2967, val_loss:  22.5703, grad_norm: 0.0028,  live_grad: 0.0000, reward_err: 0.0938, 0.0082, 0.0564, KL_dist: 1.0316, 0.4441, 0.8366, param: [10.05355686  3.76574658  4.8948401   4.53413014], weights: [0.33822955 0.31817074 0.34359971], train_wt_loss:  60.8901, val_wt_loss: 67.7110, train_grp_loss: [22.96631669 15.90605551 22.03223659], val_grp_loss: [23.31343912 20.35195806 24.02309274], train_hist_grp_loss: [21.88787423 15.77420849 23.46312571], cur_train_grp_loss: [0.2187288  0.15748236 0.23438664], max_reward_err:  0.0938, max_reward_err_index: 0, max_kl_dist:  1.0316, max_kl_dist_index: 0, max_train_grp_loss:  22.9663, max_train_grp_loss_index: 0, max_val_grp_loss:  24.0231, max_val_grp_loss_index: 2, max_cur_train_grp_loss:  0.2344, max_cur_train_grp_loss_index: 2, 
2024-09-18 00:09:34,181 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:386] - INFO: Policy parameter learned solely on the preference data rdpo: [10.05355686  3.76574658  4.8948401   4.53413014].
2024-09-18 00:09:34,514 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:397] - INFO: Uniform reward: 3.8432, 3.8432, 3.2055
2024-09-18 00:09:34,514 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Optimal reward: 3.8824, 3.8824, 3.3310
2024-09-18 00:09:34,515 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Policy reward: 3.5183, 3.8505, 3.1432
2024-09-18 00:09:34,515 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Reward Error: 0.0938, 0.0082, 0.0564
2024-09-18 00:09:35,212 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:415] - INFO: Optimal reward: 3.8824, 3.8824, 3.3310
Known param reward: [[3.8824145793914795, 3.4862008094787598, 3.297610282897949], [3.4862008094787598, 3.8824145793914795, 3.138624906539917], [3.839902877807617, 3.6102006435394287, 3.3310482501983643]], Known param reward error: [[0.0, 0.10205344169473558, 0.010038271675717638], [0.10205344169473558, 0.0, 0.05776660354499171], [0.01094980989653235, 0.07011459757466626, 0.0]].
