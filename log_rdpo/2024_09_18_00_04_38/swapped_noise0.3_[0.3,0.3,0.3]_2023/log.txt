2024-09-18 00:08:29,233 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:198] - INFO: Logging to log_rdpo/2024_09_18_00_04_38/swapped_noise0.3_[0.3,0.3,0.3]_2023
2024-09-18 00:08:29,235 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: (IB) Seed: 2023
2024-09-18 00:08:29,235 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Data: 300
2024-09-18 00:08:29,402 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:296] - INFO: MLE reward loss: 0.6216, l2 distance: 6.5611, acc: 0.64.
2024-09-18 00:08:29,403 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-18 00:08:29,404 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: MLE reward parameter: [4.7065771  0.3900871  1.98714044 2.00890037]
2024-09-18 00:08:29,616 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:313] - INFO: Learned oracle reward: 3.3662, 3.7955, 3.0013
2024-09-18 00:08:29,866 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-18 00:08:31,060 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  21.7175, val_loss:  21.7441, grad_norm: 0.1103, live_grad: 0.0000, reward_err: 0.1224, 0.0071, 0.0836, KL_dist: 1.0955, 0.3378, 0.8729, param: [10.08638162  0.70729813  4.06907549  4.01628297], weights: [0.33339264 0.33319597 0.33341139], train_wt_loss:  65.1526, val_wt_loss: 65.2324, train_grp_loss: [24.96216858 16.74182414 23.87669781], val_grp_loss: [22.55560801 18.75429526 23.77817976], train_hist_grp_loss: [0.24778523 0.18877482 0.25340847], cur_train_grp_loss: [0.24778523 0.18877482 0.25340847], max_reward_err:  0.1224, max_reward_err_index: 0, max_kl_dist:  1.0955, max_kl_dist_index: 0, max_train_grp_loss:  24.9622, max_train_grp_loss_index: 0, max_val_grp_loss:  23.7782, max_val_grp_loss_index: 2, max_cur_train_grp_loss:  0.2534, max_cur_train_grp_loss_index: 2, 
2024-09-18 00:08:35,408 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  99, train_loss:  21.7183, val_loss:  21.7449, grad_norm: 0.0034,  live_grad: 0.0000, reward_err: 0.1220, 0.0072, 0.0833, KL_dist: 1.0880, 0.3320, 0.8696, param: [10.08691146  0.75516372  3.90722847  4.07054298], weights: [0.34278028 0.31294516 0.34427457], train_wt_loss:  65.1548, val_wt_loss: 65.2346, train_grp_loss: [24.94326613 16.78580137 23.84952679], val_grp_loss: [22.53016981 18.78514133 23.77825877], train_hist_grp_loss: [24.95108972 15.84492098 25.38607484], cur_train_grp_loss: [0.24943458 0.15835217 0.25372135], max_reward_err:  0.1220, max_reward_err_index: 0, max_kl_dist:  1.0880, max_kl_dist_index: 0, max_train_grp_loss:  24.9433, max_train_grp_loss_index: 0, max_val_grp_loss:  23.7783, max_val_grp_loss_index: 2, max_cur_train_grp_loss:  0.2537, max_cur_train_grp_loss_index: 2, 
2024-09-18 00:08:35,631 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:386] - INFO: Policy parameter learned solely on the preference data rdpo: [10.08691146  0.75516372  3.90722847  4.07054298].
2024-09-18 00:08:35,958 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:397] - INFO: Uniform reward: 3.7891, 3.7891, 3.1403
2024-09-18 00:08:35,959 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Optimal reward: 3.8234, 3.8234, 3.2644
2024-09-18 00:08:35,959 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Policy reward: 3.3569, 3.7959, 2.9923
2024-09-18 00:08:35,960 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Reward Error: 0.1220, 0.0072, 0.0833
2024-09-18 00:08:36,639 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:415] - INFO: Optimal reward: 3.8234, 3.8234, 3.2644
Known param reward: [[3.823425769805908, 3.428101062774658, 3.2270522117614746], [3.428101062774658, 3.823425769805908, 3.0676209926605225], [3.7817330360412598, 3.553356885910034, 3.2643818855285645]], Known param reward error: [[0.0, 0.10339541835836875, 0.011435449367176435], [0.10339541835836875, 0.0, 0.06027508415614882], [0.010904549028753582, 0.07063531506970613, 0.0]].
