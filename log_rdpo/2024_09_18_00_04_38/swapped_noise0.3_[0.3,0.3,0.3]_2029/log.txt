2024-09-18 00:10:29,008 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:198] - INFO: Logging to log_rdpo/2024_09_18_00_04_38/swapped_noise0.3_[0.3,0.3,0.3]_2029
2024-09-18 00:10:29,010 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: (IB) Seed: 2029
2024-09-18 00:10:29,010 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Data: 300
2024-09-18 00:10:29,173 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:296] - INFO: MLE reward loss: 0.5745, l2 distance: 7.7465, acc: 0.68.
2024-09-18 00:10:29,174 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-18 00:10:29,175 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: MLE reward parameter: [2.96769503 2.35165722 5.74475451 1.46407424]
2024-09-18 00:10:29,384 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:313] - INFO: Learned oracle reward: 3.4892, 3.8780, 3.1686
2024-09-18 00:10:29,647 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-18 00:10:30,822 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  19.8808, val_loss:  21.1340, grad_norm: 0.1632, live_grad: 0.0000, reward_err: 0.1101, 0.0012, 0.0697, KL_dist: 1.2550, 0.4425, 1.0003, param: [ 5.62939853  3.77296725 10.83502639  2.4886693 ], weights: [0.33345853 0.33312987 0.33341161], train_wt_loss:  59.6423, val_wt_loss: 63.4020, train_grp_loss: [24.81762961 13.44705508 22.41874127], val_grp_loss: [23.37562406 16.2037479  23.30009873], train_hist_grp_loss: [0.26091269 0.16230212 0.24683981], cur_train_grp_loss: [0.26091269 0.16230212 0.24683981], max_reward_err:  0.1101, max_reward_err_index: 0, max_kl_dist:  1.2550, max_kl_dist_index: 0, max_train_grp_loss:  24.8176, max_train_grp_loss_index: 0, max_val_grp_loss:  23.3756, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2609, max_cur_train_grp_loss_index: 0, 
2024-09-18 00:10:35,127 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  99, train_loss:  19.8814, val_loss:  21.1265, grad_norm: 0.0037,  live_grad: 0.0000, reward_err: 0.1090, 0.0013, 0.0687, KL_dist: 1.2352, 0.4389, 0.9840, param: [ 5.61390789  3.82879809 10.74422173  2.56035171], weights: [0.35228569 0.30592157 0.34179275], train_wt_loss:  59.6442, val_wt_loss: 63.3794, train_grp_loss: [24.79521476 13.47290683 22.41306185], val_grp_loss: [23.35105611 16.22894806 23.2804496 ], train_hist_grp_loss: [26.38710873 12.27573809 23.36331878], cur_train_grp_loss: [0.26378139 0.12247833 0.23347002], max_reward_err:  0.1090, max_reward_err_index: 0, max_kl_dist:  1.2352, max_kl_dist_index: 0, max_train_grp_loss:  24.7952, max_train_grp_loss_index: 0, max_val_grp_loss:  23.3511, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2638, max_cur_train_grp_loss_index: 0, 
2024-09-18 00:10:35,347 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:386] - INFO: Policy parameter learned solely on the preference data rdpo: [ 5.61390789  3.82879809 10.74422173  2.56035171].
2024-09-18 00:10:35,674 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:397] - INFO: Uniform reward: 3.8435, 3.8435, 3.2360
2024-09-18 00:10:35,674 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Optimal reward: 3.8889, 3.8889, 3.3830
2024-09-18 00:10:35,675 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Policy reward: 3.4651, 3.8838, 3.1505
2024-09-18 00:10:35,675 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Reward Error: 0.1090, 0.0013, 0.0687
2024-09-18 00:10:36,357 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:415] - INFO: Optimal reward: 3.8889, 3.8889, 3.3830
Known param reward: [[3.8888535499572754, 3.4823989868164062, 3.3450193405151367], [3.4823989868164062, 3.8888535499572754, 3.1775741577148438], [3.852006435394287, 3.6119940280914307, 3.382976770401001]], Known param reward error: [[0.0, 0.10451783743446308, 0.011220127261283255], [0.10451783743446308, 0.0, 0.06071653062572163], [0.009475058417510502, 0.07119309542239934, 0.0]].
