2024-09-18 00:08:08,593 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:198] - INFO: Logging to log_rdpo/2024_09_18_00_04_38/swapped_noise0.3_[0.3,0.3,0.3]_2022
2024-09-18 00:08:08,595 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: (IB) Seed: 2022
2024-09-18 00:08:08,596 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Data: 300
2024-09-18 00:08:08,761 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:296] - INFO: MLE reward loss: 0.6034, l2 distance: 5.4724, acc: 0.67.
2024-09-18 00:08:08,761 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-18 00:08:08,762 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: MLE reward parameter: [3.2659424  1.84423372 3.9760255  1.5784818 ]
2024-09-18 00:08:08,971 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:313] - INFO: Learned oracle reward: 3.6028, 3.8797, 3.2068
2024-09-18 00:08:09,217 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-18 00:08:10,365 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  21.0135, val_loss:  20.5696, grad_norm: 0.1400, live_grad: 0.0000, reward_err: 0.0809, 0.0022, 0.0456, KL_dist: 0.8182, 0.3352, 0.6219, param: [6.49592488 3.29465214 7.98600548 2.79851856], weights: [0.333428   0.33318052 0.33339148], train_wt_loss:  63.0405, val_wt_loss: 61.7088, train_grp_loss: [24.44757902 14.14587397 24.54800925], val_grp_loss: [23.17453405 15.3633197  23.30014031], train_hist_grp_loss: [0.25194438 0.1776929  0.24098916], cur_train_grp_loss: [0.25194438 0.1776929  0.24098916], max_reward_err:  0.0809, max_reward_err_index: 0, max_kl_dist:  0.8182, max_kl_dist_index: 0, max_train_grp_loss:  24.5480, max_train_grp_loss_index: 2, max_val_grp_loss:  23.3001, max_val_grp_loss_index: 2, max_cur_train_grp_loss:  0.2519, max_cur_train_grp_loss_index: 0, 
2024-09-18 00:08:14,707 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  99, train_loss:  21.0157, val_loss:  20.5856, grad_norm: 0.0062,  live_grad: 0.0000, reward_err: 0.0791, 0.0034, 0.0442, KL_dist: 0.7889, 0.3297, 0.5999, param: [6.34906043 3.40883079 7.87021858 2.93535657], weights: [0.34676078 0.31041764 0.34282158], train_wt_loss:  63.0472, val_wt_loss: 61.7569, train_grp_loss: [24.39317033 14.27518915 24.47836151], val_grp_loss: [23.14199169 15.45212653 23.28927835], train_hist_grp_loss: [25.17629536 14.10464319 24.03379479], cur_train_grp_loss: [0.25148176 0.14132462 0.23999099], max_reward_err:  0.0791, max_reward_err_index: 0, max_kl_dist:  0.7889, max_kl_dist_index: 0, max_train_grp_loss:  24.4784, max_train_grp_loss_index: 2, max_val_grp_loss:  23.2893, max_val_grp_loss_index: 2, max_cur_train_grp_loss:  0.2515, max_cur_train_grp_loss_index: 0, 
2024-09-18 00:08:14,931 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:386] - INFO: Policy parameter learned solely on the preference data rdpo: [6.34906043 3.40883079 7.87021858 2.93535657].
2024-09-18 00:08:15,256 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:397] - INFO: Uniform reward: 3.8640, 3.8640, 3.2133
2024-09-18 00:08:15,257 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Optimal reward: 3.8945, 3.8945, 3.3417
2024-09-18 00:08:15,257 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Policy reward: 3.5863, 3.8813, 3.1940
2024-09-18 00:08:15,258 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Reward Error: 0.0791, 0.0034, 0.0442
2024-09-18 00:08:15,935 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:415] - INFO: Optimal reward: 3.8945, 3.8945, 3.3417
Known param reward: [[3.894484758377075, 3.5591492652893066, 3.2951979637145996], [3.5591492652893066, 3.894484758377075, 3.1762964725494385], [3.853400707244873, 3.6607706546783447, 3.3417041301727295]], Known param reward error: [[0.0, 0.08610522672260011, 0.013916901271485703], [0.08610522672260011, 0.0, 0.04949799598647928], [0.01054929051752737, 0.06001155947420493, 0.0]].
