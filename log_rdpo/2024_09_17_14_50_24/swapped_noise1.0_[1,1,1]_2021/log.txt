2024-09-17 14:50:27,038 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:198] - INFO: Logging to log_rdpo/2024_09_17_14_50_24/swapped_noise1.0_[1,1,1]_2021
2024-09-17 14:50:27,040 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: (IB) Seed: 2021
2024-09-17 14:50:27,041 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Data: 300
2024-09-17 14:50:27,214 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:296] - INFO: MLE reward loss: 0.3566, l2 distance: 29.5613, acc: 0.82.
2024-09-17 14:50:27,215 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-17 14:50:27,216 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: MLE reward parameter: [12.9300958   5.57206545 13.55993407  6.18568546]
2024-09-17 14:50:27,450 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:313] - INFO: Learned oracle reward: 3.5203, 3.8700, 3.1356
2024-09-17 14:50:27,867 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-17 14:50:28,492 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  0.0017, val_loss:  0.0005, grad_norm: 0.0310, live_grad: 0.0000, reward_err: 0.1132, 0.0010, 0.0692, KL_dist: 0.2104, 0.0058, 0.1125, param: [2.9868533  1.21238081 2.67089149 0.51614833], weights: [0.33374103 0.33272764 0.33353132], train_wt_loss:  0.5107, val_wt_loss: 0.5256, train_grp_loss: [0.64781343 0.34361164 0.58492129], val_grp_loss: [0.6346728  0.35784096 0.59480549], train_hist_grp_loss: [0.64786126 0.343753   0.58500575], cur_train_grp_loss: [0.64786126 0.343753   0.58500575], max_reward_err:  0.1132, max_reward_err_index: 0, max_kl_dist:  0.2104, max_kl_dist_index: 0, max_train_grp_loss:  0.6478, max_train_grp_loss_index: 0, max_val_grp_loss:  0.6347, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.6479, max_cur_train_grp_loss_index: 0, 
2024-09-17 14:50:31,257 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  100, train_loss:  0.0017, val_loss:  0.0005, grad_norm: 0.0293, live_grad: 0.0000, reward_err: 0.1090, 0.0006, 0.0654, KL_dist: 0.2164, 0.0041, 0.1161, param: [3.12959541 1.31593879 2.84360564 0.66235894], weights: [0.37461933 0.27441161 0.35096907], train_wt_loss:  0.5159, val_wt_loss: 0.5312, train_grp_loss: [0.64301408 0.33123071 0.57682329], val_grp_loss: [0.62923681 0.34353926 0.58765592], train_hist_grp_loss: [65.1920731  34.06395473 58.6708446 ], cur_train_grp_loss: [0.64306242 0.33133828 0.5769012 ], max_reward_err:  0.1090, max_reward_err_index: 0, max_kl_dist:  0.2164, max_kl_dist_index: 0, max_train_grp_loss:  0.6430, max_train_grp_loss_index: 0, max_val_grp_loss:  0.6292, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.6431, max_cur_train_grp_loss_index: 0, 
2024-09-17 14:50:33,986 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  200, train_loss:  0.0016, val_loss:  0.0005, grad_norm: 0.0278, live_grad: 0.0000, reward_err: 0.1054, 0.0009, 0.0622, KL_dist: 0.2206, 0.0043, 0.1188, param: [3.24640409 1.42663835 2.9909652  0.80952073], weights: [0.4148208  0.22193131 0.3632479 ], train_wt_loss:  0.5236, val_wt_loss: 0.5375, train_grp_loss: [0.63811664 0.32196311 0.56928544], val_grp_loss: [0.62381389 0.33216798 0.58097953], train_hist_grp_loss: [129.25219974  66.70432864 115.97608985], cur_train_grp_loss: [0.63816634 0.32204189 0.56935858], max_reward_err:  0.1054, max_reward_err_index: 0, max_kl_dist:  0.2206, max_kl_dist_index: 0, max_train_grp_loss:  0.6381, max_train_grp_loss_index: 0, max_val_grp_loss:  0.6238, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.6382, max_cur_train_grp_loss_index: 0, 
2024-09-17 14:50:36,720 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  300, train_loss:  0.0016, val_loss:  0.0005, grad_norm: 0.0266, live_grad: 0.0000, reward_err: 0.1000, 0.0012, 0.0575, KL_dist: 0.2230, 0.0061, 0.1205, param: [3.34170196 1.54476492 3.11645088 0.95939734], weights: [0.45327557 0.17660022 0.37012421], train_wt_loss:  0.5323, val_wt_loss: 0.5433, train_grp_loss: [0.63305964 0.31537937 0.56215683], val_grp_loss: [0.61832688 0.32325645 0.57464122], train_hist_grp_loss: [192.81501666  98.55384715 172.54885647], cur_train_grp_loss: [0.6331111  0.31543304 0.56222647], max_reward_err:  0.1000, max_reward_err_index: 0, max_kl_dist:  0.2230, max_kl_dist_index: 0, max_train_grp_loss:  0.6331, max_train_grp_loss_index: 0, max_val_grp_loss:  0.6183, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.6331, max_cur_train_grp_loss_index: 0, 
2024-09-17 14:50:39,464 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  400, train_loss:  0.0016, val_loss:  0.0005, grad_norm: 0.0257, live_grad: 0.0000, reward_err: 0.0957, 0.0013, 0.0537, KL_dist: 0.2237, 0.0091, 0.1213, param: [3.41949627 1.67005821 3.22322696 1.11289412], weights: [0.48930957 0.13879632 0.37189411], train_wt_loss:  0.5412, val_wt_loss: 0.5480, train_grp_loss: [0.62782022 0.31116129 0.55533273], val_grp_loss: [0.61273961 0.31646404 0.56854795], train_hist_grp_loss: [255.86316458 129.86437987 228.42454378], cur_train_grp_loss: [0.62787352 0.3111926  0.55539971], max_reward_err:  0.0957, max_reward_err_index: 0, max_kl_dist:  0.2237, max_kl_dist_index: 0, max_train_grp_loss:  0.6278, max_train_grp_loss_index: 0, max_val_grp_loss:  0.6127, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.6279, max_cur_train_grp_loss_index: 0, 
2024-09-17 14:50:42,207 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  500, train_loss:  0.0016, val_loss:  0.0005, grad_norm: 0.0249, live_grad: 0.0000, reward_err: 0.0904, 0.0024, 0.0492, KL_dist: 0.2231, 0.0135, 0.1214, param: [3.48327606 1.80188234 3.31408977 1.27027265], weights: [0.52262113 0.10816658 0.36921228], train_wt_loss:  0.5497, val_wt_loss: 0.5514, train_grp_loss: [0.62240262 0.3090669  0.5487441 ], val_grp_loss: [0.60704503 0.31154049 0.56263926], train_hist_grp_loss: [318.37843094 160.85999957 283.6299288 ], cur_train_grp_loss: [0.62245762 0.309078   0.54880898], max_reward_err:  0.0904, max_reward_err_index: 0, max_kl_dist:  0.2231, max_kl_dist_index: 0, max_train_grp_loss:  0.6224, max_train_grp_loss_index: 0, max_val_grp_loss:  0.6070, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.6225, max_cur_train_grp_loss_index: 0, 
2024-09-17 14:50:44,937 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  600, train_loss:  0.0016, val_loss:  0.0005, grad_norm: 0.0244, live_grad: 0.0000, reward_err: 0.0863, 0.0031, 0.0457, KL_dist: 0.2214, 0.0192, 0.1210, param: [3.53597093 1.93938368 3.39144594 1.43135384], weights: [0.55319284 0.08390624 0.36290092], train_wt_loss:  0.5573, val_wt_loss: 0.5533, train_grp_loss: [0.61682802 0.30890488 0.54234818], val_grp_loss: [0.60125476 0.30829641 0.55687869], train_hist_grp_loss: [380.34394154 191.74326886 338.18625975], cur_train_grp_loss: [0.61688444 0.30889748 0.54241127], max_reward_err:  0.0863, max_reward_err_index: 0, max_kl_dist:  0.2214, max_kl_dist_index: 0, max_train_grp_loss:  0.6168, max_train_grp_loss_index: 0, max_val_grp_loss:  0.6013, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.6169, max_cur_train_grp_loss_index: 0, 
2024-09-17 14:50:47,779 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  700, train_loss:  0.0016, val_loss:  0.0005, grad_norm: 0.0242, live_grad: 0.0000, reward_err: 0.0822, 0.0046, 0.0423, KL_dist: 0.2190, 0.0261, 0.1204, param: [3.5799667  2.08162118 3.45732271 1.59569228], weights: [0.58118586 0.06501446 0.35379968], train_wt_loss:  0.5640, val_wt_loss: 0.5540, train_grp_loss: [0.61112645 0.31051645 0.53612029], val_grp_loss: [0.59539075 0.30658206 0.55124628], train_hist_grp_loss: [441.74543683 222.69935114 392.11146471], cur_train_grp_loss: [0.61118398 0.31049202 0.53618179], max_reward_err:  0.0822, max_reward_err_index: 0, max_kl_dist:  0.2190, max_kl_dist_index: 0, max_train_grp_loss:  0.6111, max_train_grp_loss_index: 0, max_val_grp_loss:  0.5954, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.6112, max_cur_train_grp_loss_index: 0, 
2024-09-17 14:50:50,601 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  800, train_loss:  0.0016, val_loss:  0.0005, grad_norm: 0.0242, live_grad: 0.0000, reward_err: 0.0766, 0.0065, 0.0378, KL_dist: 0.2162, 0.0344, 0.1197, param: [3.61716001 2.22766139 3.51340203 1.76271148], weights: [0.60684845 0.05047847 0.34267308], train_wt_loss:  0.5698, val_wt_loss: 0.5535, train_grp_loss: [0.60533096 0.3137635  0.53004745], val_grp_loss: [0.58947922 0.30627289 0.54573266], train_hist_grp_loss: [502.57184972 253.89863349 445.42162951], cur_train_grp_loss: [0.60538927 0.31372335 0.53010744], max_reward_err:  0.0766, max_reward_err_index: 0, max_kl_dist:  0.2162, max_kl_dist_index: 0, max_train_grp_loss:  0.6053, max_train_grp_loss_index: 0, max_val_grp_loss:  0.5895, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.6054, max_cur_train_grp_loss_index: 0, 
2024-09-17 14:50:53,352 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  900, train_loss:  0.0016, val_loss:  0.0005, grad_norm: 0.0244, live_grad: 0.0000, reward_err: 0.0731, 0.0092, 0.0351, KL_dist: 0.2132, 0.0439, 0.1190, param: [3.64903172 2.37663878 3.56106739 1.93179885], weights: [0.63045167 0.03938033 0.330168  ], train_wt_loss:  0.5746, val_wt_loss: 0.5521, train_grp_loss: [0.5994738  0.31852135 0.52412357], val_grp_loss: [0.58354665 0.30726046 0.54033464], train_hist_grp_loss: [562.81540246 285.49840139 498.13191538], cur_train_grp_loss: [0.59953258 0.31846668 0.52418209], max_reward_err:  0.0731, max_reward_err_index: 0, max_kl_dist:  0.2132, max_kl_dist_index: 0, max_train_grp_loss:  0.5995, max_train_grp_loss_index: 0, max_val_grp_loss:  0.5835, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.5995, max_cur_train_grp_loss_index: 0, 
2024-09-17 14:50:56,083 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  1000, train_loss:  0.0016, val_loss:  0.0005, grad_norm: 0.0248, live_grad: 0.0000, reward_err: 0.0692, 0.0111, 0.0320, KL_dist: 0.2103, 0.0546, 0.1186, param: [3.67672368 2.5277873  3.60145394 2.10236538], weights: [0.65225155 0.03094328 0.31680517], train_wt_loss:  0.5786, val_wt_loss: 0.5500, train_grp_loss: [0.5935843  0.32467464 0.51834624], val_grp_loss: [0.57761747 0.30944704 0.53505225], train_hist_grp_loss: [622.47140956 317.64395714 550.25707819], cur_train_grp_loss: [0.59364327 0.32460656 0.51840329], max_reward_err:  0.0692, max_reward_err_index: 0, max_kl_dist:  0.2103, max_kl_dist_index: 0, max_train_grp_loss:  0.5936, max_train_grp_loss_index: 0, max_val_grp_loss:  0.5776, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.5936, max_cur_train_grp_loss_index: 0, 
2024-09-17 14:50:58,825 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  1100, train_loss:  0.0016, val_loss:  0.0005, grad_norm: 0.0254, live_grad: 0.0000, reward_err: 0.0647, 0.0159, 0.0286, KL_dist: 0.2074, 0.0665, 0.1186, param: [3.70110956 2.68045107 3.63549575 2.27387819], weights: [0.67247141 0.02453927 0.30298932], train_wt_loss:  0.5819, val_wt_loss: 0.5473, train_grp_loss: [0.58768787 0.3321153  0.51271461], val_grp_loss: [0.57171293 0.31274262 0.52988679], train_hist_grp_loss: [681.53792893 350.46944005 601.81172407], cur_train_grp_loss: [0.5877468  0.33203486 0.51277021], max_reward_err:  0.0647, max_reward_err_index: 0, max_kl_dist:  0.2074, max_kl_dist_index: 0, max_train_grp_loss:  0.5877, max_train_grp_loss_index: 0, max_val_grp_loss:  0.5717, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.5877, max_cur_train_grp_loss_index: 0, 
2024-09-17 14:51:01,560 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  1200, train_loss:  0.0016, val_loss:  0.0005, grad_norm: 0.0261, live_grad: 0.0000, reward_err: 0.0624, 0.0181, 0.0269, KL_dist: 0.2049, 0.0796, 0.1190, param: [3.72285535 2.83408174 3.66396687 2.4458742 ], weights: [0.691297   0.01967603 0.28902697], train_wt_loss:  0.5844, val_wt_loss: 0.5442, train_grp_loss: [0.58180585 0.34074161 0.50722828], val_grp_loss: [0.56585079 0.31706344 0.52483977], train_hist_grp_loss: [740.01535776 384.09850147 652.81040366], cur_train_grp_loss: [0.58186454 0.3406498  0.50728243], max_reward_err:  0.0624, max_reward_err_index: 0, max_kl_dist:  0.2049, max_kl_dist_index: 0, max_train_grp_loss:  0.5818, max_train_grp_loss_index: 0, max_val_grp_loss:  0.5659, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.5819, max_cur_train_grp_loss_index: 0, 
2024-09-17 14:51:04,282 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  1300, train_loss:  0.0016, val_loss:  0.0005, grad_norm: 0.0268, live_grad: 0.0000, reward_err: 0.0592, 0.0214, 0.0245, KL_dist: 0.2027, 0.0938, 0.1199, param: [3.7424686  2.98822851 3.68751542 2.61796198], weights: [0.70887868 0.01597577 0.27514555], train_wt_loss:  0.5864, val_wt_loss: 0.5408, train_grp_loss: [0.57595572 0.35045774 0.50188657], val_grp_loss: [0.56004543 0.32233116 0.51991232], train_hist_grp_loss: [797.90603252 418.64491443 703.26761603], cur_train_grp_loss: [0.57601402 0.35035549 0.50193927], max_reward_err:  0.0592, max_reward_err_index: 0, max_kl_dist:  0.2027, max_kl_dist_index: 0, max_train_grp_loss:  0.5760, max_train_grp_loss_index: 0, max_val_grp_loss:  0.5600, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.5760, max_cur_train_grp_loss_index: 0, 
2024-09-17 14:51:07,003 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  1400, train_loss:  0.0016, val_loss:  0.0005, grad_norm: 0.0277, live_grad: 0.0000, reward_err: 0.0558, 0.0246, 0.0221, KL_dist: 0.2010, 0.1091, 0.1214, param: [3.76033724 3.14252491 3.70669076 2.7898169 ], weights: [0.72533665 0.01315272 0.26151063], train_wt_loss:  0.5878, val_wt_loss: 0.5371, train_grp_loss: [0.57015154 0.36117357 0.49668827], val_grp_loss: [0.5543082  0.32847249 0.51510494], train_hist_grp_loss: [855.21386443 454.21315302 753.19776854], cur_train_grp_loss: [0.57020932 0.36106174 0.49673955], max_reward_err:  0.0558, max_reward_err_index: 0, max_kl_dist:  0.2010, max_kl_dist_index: 0, max_train_grp_loss:  0.5702, max_train_grp_loss_index: 0, max_val_grp_loss:  0.5543, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.5702, max_cur_train_grp_loss_index: 0, 
2024-09-17 14:51:09,755 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  1500, train_loss:  0.0016, val_loss:  0.0005, grad_norm: 0.0286, live_grad: 0.0000, reward_err: 0.0531, 0.0281, 0.0203, KL_dist: 0.1998, 0.1253, 0.1234, param: [3.77675942 3.29667506 3.72196469 2.96117314], weights: [0.74076699 0.01099274 0.24824027], train_wt_loss:  0.5888, val_wt_loss: 0.5333, train_grp_loss: [0.56440449 0.37280444 0.49163163], val_grp_loss: [0.54864791 0.33541884 0.51041744], train_hist_grp_loss: [911.94402394 490.89895188 802.61512041], cur_train_grp_loss: [0.56446165 0.37268387 0.4916815 ], max_reward_err:  0.0531, max_reward_err_index: 0, max_kl_dist:  0.1998, max_kl_dist_index: 0, max_train_grp_loss:  0.5644, max_train_grp_loss_index: 0, max_val_grp_loss:  0.5486, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.5645, max_cur_train_grp_loss_index: 0, 
2024-09-17 14:51:12,516 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  1600, train_loss:  0.0016, val_loss:  0.0005, grad_norm: 0.0296, live_grad: 0.0000, reward_err: 0.0509, 0.0296, 0.0188, KL_dist: 0.1991, 0.1424, 0.1261, param: [3.79196631 3.45044076 3.73374785 3.1318147 ], weights: [0.75524727 0.00933636 0.23541636], train_wt_loss:  0.5893, val_wt_loss: 0.5293, train_grp_loss: [0.55872336 0.38527102 0.4867143 ], val_grp_loss: [0.54307121 0.34310607 0.505849  ], train_hist_grp_loss: [968.10267658 528.78984542 851.53372549], cur_train_grp_loss: [0.55877982 0.38514246 0.48676279], max_reward_err:  0.0509, max_reward_err_index: 0, max_kl_dist:  0.1991, max_kl_dist_index: 0, max_train_grp_loss:  0.5587, max_train_grp_loss_index: 0, max_val_grp_loss:  0.5431, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.5588, max_cur_train_grp_loss_index: 0, 
2024-09-17 14:51:15,254 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  1700, train_loss:  0.0016, val_loss:  0.0005, grad_norm: 0.0305, live_grad: 0.0000, reward_err: 0.0471, 0.0316, 0.0164, KL_dist: 0.1989, 0.1603, 0.1293, param: [3.8061392  3.60363013 3.74240211 3.3015667 ], weights: [0.76884125 0.00806532 0.22309343], train_wt_loss:  0.5893, val_wt_loss: 0.5253, train_grp_loss: [0.55311498 0.39849893 0.48193352], val_grp_loss: [0.53758306 0.35147421 0.50139828], train_hist_grp_loss: [1023.69676706  567.96568216  899.96738191], cur_train_grp_loss: [0.55317068 0.39836311 0.48198066], max_reward_err:  0.0471, max_reward_err_index: 0, max_kl_dist:  0.1989, max_kl_dist_index: 0, max_train_grp_loss:  0.5531, max_train_grp_loss_index: 0, max_val_grp_loss:  0.5376, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.5532, max_cur_train_grp_loss_index: 0, 
2024-09-17 14:51:17,996 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  1800, train_loss:  0.0016, val_loss:  0.0005, grad_norm: 0.0315, live_grad: 0.0000, reward_err: 0.0421, 0.0339, 0.0133, KL_dist: 0.1994, 0.1791, 0.1332, param: [3.81942238 3.75608795 3.74825008 3.47028742], weights: [0.78160252 0.00709222 0.21130525], train_wt_loss:  0.5891, val_wt_loss: 0.5212, train_grp_loss: [0.54758467 0.4124185  0.47728616], val_grp_loss: [0.53218705 0.3604671  0.49706349], train_hist_grp_loss: [1078.73384551  608.49910924  947.92959174], cur_train_grp_loss: [0.54763957 0.4122761  0.47733198], max_reward_err:  0.0421, max_reward_err_index: 0, max_kl_dist:  0.1994, max_kl_dist_index: 0, max_train_grp_loss:  0.5476, max_train_grp_loss_index: 0, max_val_grp_loss:  0.5322, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.5476, max_cur_train_grp_loss_index: 0, 
2024-09-17 14:51:20,724 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  1900, train_loss:  0.0016, val_loss:  0.0005, grad_norm: 0.0325, live_grad: 0.0000, reward_err: 0.0381, 0.0370, 0.0108, KL_dist: 0.2004, 0.1986, 0.1377, param: [3.83193289 3.90768762 3.75158238 3.63786139], weights: [0.79357729 0.00635278 0.20006993], train_wt_loss:  0.5885, val_wt_loss: 0.5171, train_grp_loss: [0.54213651 0.42696438 0.47276883], val_grp_loss: [0.5268857  0.37003208 0.4928425 ], train_hist_grp_loss: [1133.22192962  650.45602306  995.43353101], cur_train_grp_loss: [0.54219057 0.42681602 0.47281337], max_reward_err:  0.0381, max_reward_err_index: 0, max_kl_dist:  0.2004, max_kl_dist_index: 0, max_train_grp_loss:  0.5421, max_train_grp_loss_index: 0, max_val_grp_loss:  0.5269, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.5422, max_cur_train_grp_loss_index: 0, 
2024-09-17 14:51:23,444 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  2000, train_loss:  0.0016, val_loss:  0.0005, grad_norm: 0.0334, live_grad: 0.0000, reward_err: 0.0345, 0.0409, 0.0088, KL_dist: 0.2020, 0.2187, 0.1428, param: [3.84376779 4.05832458 3.75266322 3.80419346], weights: [0.80480625 0.00580006 0.1893937 ], train_wt_loss:  0.5876, val_wt_loss: 0.5130, train_grp_loss: [0.53677363 0.44207514 0.46837801], val_grp_loss: [0.52168072 0.38011964 0.48873297], train_hist_grp_loss: [1187.16939641  693.89598274 1042.49202955], cur_train_grp_loss: [0.53682683 0.44192143 0.4684213 ], max_reward_err:  0.0409, max_reward_err_index: 1, max_kl_dist:  0.2187, max_kl_dist_index: 1, max_train_grp_loss:  0.5368, max_train_grp_loss_index: 0, max_val_grp_loss:  0.5217, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.5368, max_cur_train_grp_loss_index: 0, 
2024-09-17 14:51:26,173 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  2100, train_loss:  0.0016, val_loss:  0.0005, grad_norm: 0.0344, live_grad: 0.0000, reward_err: 0.0324, 0.0450, 0.0076, KL_dist: 0.2042, 0.2395, 0.1485, param: [3.85500986 4.20791085 3.75173486 3.96920377], weights: [0.81532581 0.00540035 0.17927383], train_wt_loss:  0.5864, val_wt_loss: 0.5089, train_grp_loss: [0.53149844 0.4576929  0.46411008], val_grp_loss: [0.51657321 0.39068301 0.48473238], train_hist_grp_loss: [1240.58489829  738.87258376 1089.11755912], cur_train_grp_loss: [0.53155075 0.45753439 0.46415216], max_reward_err:  0.0450, max_reward_err_index: 1, max_kl_dist:  0.2395, max_kl_dist_index: 1, max_train_grp_loss:  0.5315, max_train_grp_loss_index: 0, max_val_grp_loss:  0.5166, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.5316, max_cur_train_grp_loss_index: 0, 
2024-09-17 14:51:28,931 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  2200, train_loss:  0.0016, val_loss:  0.0005, grad_norm: 0.0353, live_grad: 0.0000, reward_err: 0.0311, 0.0474, 0.0069, KL_dist: 0.2070, 0.2608, 0.1548, param: [3.86573195 4.3563704  3.74902129 4.13282332], weights: [0.82516888 0.00513024 0.16970088], train_wt_loss:  0.5849, val_wt_loss: 0.5048, train_grp_loss: [0.52631278 0.47376284 0.4599614 ], val_grp_loss: [0.51156379 0.40167781 0.48083811], train_hist_grp_loss: [1293.47729945  785.43378906 1135.32222881], cur_train_grp_loss: [0.52636419 0.47360008 0.46000231], max_reward_err:  0.0474, max_reward_err_index: 1, max_kl_dist:  0.2608, max_kl_dist_index: 1, max_train_grp_loss:  0.5263, max_train_grp_loss_index: 0, max_val_grp_loss:  0.5116, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.5264, max_cur_train_grp_loss_index: 0, 
2024-09-17 14:51:31,682 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  2300, train_loss:  0.0017, val_loss:  0.0005, grad_norm: 0.0362, live_grad: 0.0000, reward_err: 0.0293, 0.0517, 0.0060, KL_dist: 0.2104, 0.2826, 0.1617, param: [3.87600066 4.50363525 3.74473135 4.29499009], weights: [0.83436507 0.00497456 0.16066037], train_wt_loss:  0.5833, val_wt_loss: 0.5007, train_grp_loss: [0.52121813 0.49023278 0.4559284 ], val_grp_loss: [0.5066528  0.41306163 0.47704752], train_hist_grp_loss: [1345.85562904  833.62221407 1181.11778623], cur_train_grp_loss: [0.52126863 0.49006627 0.45596816], max_reward_err:  0.0517, max_reward_err_index: 1, max_kl_dist:  0.2826, max_kl_dist_index: 1, max_train_grp_loss:  0.5212, max_train_grp_loss_index: 0, max_val_grp_loss:  0.5067, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.5213, max_cur_train_grp_loss_index: 0, 
2024-09-17 14:51:34,399 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  2400, train_loss:  0.0017, val_loss:  0.0005, grad_norm: 0.0371, live_grad: 0.0000, reward_err: 0.0278, 0.0534, 0.0053, KL_dist: 0.2144, 0.3049, 0.1692, param: [3.88587942 4.6496418  3.73906161 4.45564534], weights: [0.84294072 0.00492517 0.1521341 ], train_wt_loss:  0.5814, val_wt_loss: 0.4966, train_grp_loss: [0.5162157  0.50705256 0.45200755], val_grp_loss: [0.50184038 0.42479361 0.47335797], train_hist_grp_loss: [1397.72904913  883.47536071 1226.51562358], cur_train_grp_loss: [0.51626527 0.50688279 0.45204621], max_reward_err:  0.0534, max_reward_err_index: 1, max_kl_dist:  0.3049, max_kl_dist_index: 1, max_train_grp_loss:  0.5162, max_train_grp_loss_index: 0, max_val_grp_loss:  0.5018, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.5163, max_cur_train_grp_loss_index: 0, 
2024-09-17 14:51:37,161 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  2500, train_loss:  0.0017, val_loss:  0.0005, grad_norm: 0.0379, live_grad: 0.0000, reward_err: 0.0272, 0.0545, 0.0051, KL_dist: 0.2189, 0.3276, 0.1773, param: [3.89543134 4.79432734 3.73219925 4.61472992], weights: [0.85091843 0.00498038 0.14410119], train_wt_loss:  0.5794, val_wt_loss: 0.4926, train_grp_loss: [0.51130659 0.52417347 0.44819547], val_grp_loss: [0.49712661 0.43683387 0.46976687], train_hist_grp_loss: [1449.10683617  935.02579321 1271.52678805], cur_train_grp_loss: [0.51135521 0.52400093 0.44823307], max_reward_err:  0.0545, max_reward_err_index: 1, max_kl_dist:  0.3276, max_kl_dist_index: 1, max_train_grp_loss:  0.5242, max_train_grp_loss_index: 1, max_val_grp_loss:  0.4971, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.5240, max_cur_train_grp_loss_index: 1, 
2024-09-17 14:51:39,989 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  2600, train_loss:  0.0017, val_loss:  0.0005, grad_norm: 0.0387, live_grad: 0.0000, reward_err: 0.0243, 0.0561, 0.0039, KL_dist: 0.2240, 0.3507, 0.1858, param: [3.90472226 4.93762627 3.72432505 4.77218025], weights: [0.85831631 0.00514488 0.13653881], train_wt_loss:  0.5772, val_wt_loss: 0.4887, train_grp_loss: [0.50649189 0.54154748 0.44448895], val_grp_loss: [0.4925116  0.44914295 0.46627172], train_hist_grp_loss: [1499.99837564  988.30124488 1316.16199583], cur_train_grp_loss: [0.50653957 0.54137264 0.4445255 ], max_reward_err:  0.0561, max_reward_err_index: 1, max_kl_dist:  0.3507, max_kl_dist_index: 1, max_train_grp_loss:  0.5415, max_train_grp_loss_index: 1, max_val_grp_loss:  0.4925, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.5414, max_cur_train_grp_loss_index: 1, 
2024-09-17 14:51:42,830 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  2700, train_loss:  0.0017, val_loss:  0.0005, grad_norm: 0.0395, live_grad: 0.0000, reward_err: 0.0215, 0.0580, 0.0027, KL_dist: 0.2296, 0.3740, 0.1949, param: [3.91382394 5.07946589 3.71561685 4.92792366], weights: [0.86514686 0.00543041 0.12942274], train_wt_loss:  0.5750, val_wt_loss: 0.4848, train_grp_loss: [0.50177289 0.55912626 0.44088494], val_grp_loss: [0.48799566 0.46168105 0.46287018], train_hist_grp_loss: [1550.41317058 1043.32464017 1360.43164994], cur_train_grp_loss: [0.5018196  0.55894962 0.44092048], max_reward_err:  0.0580, max_reward_err_index: 1, max_kl_dist:  0.3740, max_kl_dist_index: 1, max_train_grp_loss:  0.5591, max_train_grp_loss_index: 1, max_val_grp_loss:  0.4880, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.5589, max_cur_train_grp_loss_index: 1, 
2024-09-17 14:51:45,550 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  2800, train_loss:  0.0017, val_loss:  0.0005, grad_norm: 0.0402, live_grad: 0.0000, reward_err: 0.0192, 0.0606, 0.0020, KL_dist: 0.2358, 0.3976, 0.2045, param: [3.92281812 5.21976123 3.70625377 5.08187257], weights: [0.87141518 0.00585707 0.12272775], train_wt_loss:  0.5726, val_wt_loss: 0.4810, train_grp_loss: [0.49715118 0.57685999 0.43738066], val_grp_loss: [0.4835794  0.47440705 0.45956005], train_hist_grp_loss: [1600.36086605 1100.11400913 1404.3458619 ], cur_train_grp_loss: [0.49719691 0.57668206 0.43741522], max_reward_err:  0.0606, max_reward_err_index: 1, max_kl_dist:  0.3976, max_kl_dist_index: 1, max_train_grp_loss:  0.5769, max_train_grp_loss_index: 1, max_val_grp_loss:  0.4836, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.5767, max_cur_train_grp_loss_index: 1, 
2024-09-17 14:51:48,301 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  2900, train_loss:  0.0018, val_loss:  0.0005, grad_norm: 0.0410, live_grad: 0.0000, reward_err: 0.0178, 0.0624, 0.0015, KL_dist: 0.2424, 0.4215, 0.2146, param: [3.93180159 5.35840831 3.69642157 5.233917  ], weights: [0.87711654 0.00645561 0.11642784], train_wt_loss:  0.5702, val_wt_loss: 0.4772, train_grp_loss: [0.49262893 0.59469574 0.4339736 ], val_grp_loss: [0.47926394 0.48727722 0.45633939], train_hist_grp_loss: [1649.85129299 1158.68226075 1447.91447801], cur_train_grp_loss: [0.49267365 0.59451707 0.4340072 ], max_reward_err:  0.0624, max_reward_err_index: 1, max_kl_dist:  0.4215, max_kl_dist_index: 1, max_train_grp_loss:  0.5947, max_train_grp_loss_index: 1, max_val_grp_loss:  0.4873, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.5945, max_cur_train_grp_loss_index: 1, 
2024-09-17 14:51:51,055 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  3000, train_loss:  0.0018, val_loss:  0.0005, grad_norm: 0.0416, live_grad: 0.0000, reward_err: 0.0161, 0.0624, 0.0010, KL_dist: 0.2495, 0.4454, 0.2251, param: [3.94089309 5.49527525 3.68631969 5.3839144 ], weights: [0.88223284 0.00727089 0.11049627], train_wt_loss:  0.5678, val_wt_loss: 0.4736, train_grp_loss: [0.48820913 0.61257522 0.43066163], val_grp_loss: [0.47505116 0.50024346 0.45320654], train_hist_grp_loss: [1698.89453684 1219.03676697 1491.14711144], cur_train_grp_loss: [0.48825281 0.61239642 0.43069429], max_reward_err:  0.0624, max_reward_err_index: 1, max_kl_dist:  0.4454, max_kl_dist_index: 1, max_train_grp_loss:  0.6126, max_train_grp_loss_index: 1, max_val_grp_loss:  0.5002, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.6124, max_cur_train_grp_loss_index: 1, 
2024-09-17 14:51:53,800 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  3100, train_loss:  0.0018, val_loss:  0.0005, grad_norm: 0.0423, live_grad: 0.0000, reward_err: 0.0153, 0.0639, 0.0008, KL_dist: 0.2571, 0.4694, 0.2360, param: [3.9502427  5.63018996 3.6761709  5.53167563], weights: [0.88672743 0.00836716 0.10490541], train_wt_loss:  0.5654, val_wt_loss: 0.4701, train_grp_loss: [0.483896   0.63043178 0.42744304], val_grp_loss: [0.47094401 0.5132509  0.45016024], train_hist_grp_loss: [1747.50103946 1281.17868682 1534.05318196], cur_train_grp_loss: [0.48393859 0.63025357 0.42747477], max_reward_err:  0.0639, max_reward_err_index: 1, max_kl_dist:  0.4694, max_kl_dist_index: 1, max_train_grp_loss:  0.6304, max_train_grp_loss_index: 1, max_val_grp_loss:  0.5133, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.6303, max_cur_train_grp_loss_index: 1, 
2024-09-17 14:51:56,550 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  3200, train_loss:  0.0018, val_loss:  0.0005, grad_norm: 0.0429, live_grad: 0.0000, reward_err: 0.0146, 0.0658, 0.0006, KL_dist: 0.2652, 0.4935, 0.2473, param: [3.96004519 5.76292292 3.66623465 5.67694532], weights: [0.89053776 0.00983579 0.09962645], train_wt_loss:  0.5631, val_wt_loss: 0.4667, train_grp_loss: [0.47969553 0.64818608 0.42431669], val_grp_loss: [0.46694699 0.52623446 0.44719974], train_hist_grp_loss: [1795.6817466  1345.10192858 1576.64196615], cur_train_grp_loss: [0.47973695 0.64800934 0.4243475 ], max_reward_err:  0.0658, max_reward_err_index: 1, max_kl_dist:  0.4935, max_kl_dist_index: 1, max_train_grp_loss:  0.6482, max_train_grp_loss_index: 1, max_val_grp_loss:  0.5262, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.6480, max_cur_train_grp_loss_index: 1, 
2024-09-17 14:51:59,260 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  3300, train_loss:  0.0018, val_loss:  0.0005, grad_norm: 0.0435, live_grad: 0.0000, reward_err: 0.0141, 0.0684, 0.0005, KL_dist: 0.2736, 0.5174, 0.2589, param: [3.9705588  5.89316284 3.65682581 5.81937397], weights: [0.89356466 0.01180652 0.09462882], train_wt_loss:  0.5610, val_wt_loss: 0.4635, train_grp_loss: [0.47561619 0.66574009 0.42128221], val_grp_loss: [0.46306675 0.53911401 0.44432499], train_hist_grp_loss: [1843.44831894 1410.79160154 1618.92266235], cur_train_grp_loss: [0.47565635 0.66556593 0.4213121 ], max_reward_err:  0.0684, max_reward_err_index: 1, max_kl_dist:  0.5174, max_kl_dist_index: 1, max_train_grp_loss:  0.6657, max_train_grp_loss_index: 1, max_val_grp_loss:  0.5391, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.6656, max_cur_train_grp_loss_index: 1, 
2024-09-17 14:52:01,926 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  3400, train_loss:  0.0018, val_loss:  0.0005, grad_norm: 0.0441, live_grad: 0.0000, reward_err: 0.0118, 0.0699, 0.0002, KL_dist: 0.2824, 0.5411, 0.2708, param: [3.98213214 6.02048198 3.64834124 5.95847823], weights: [0.89565699 0.01446368 0.08987933], train_wt_loss:  0.5592, val_wt_loss: 0.4605, train_grp_loss: [0.47167008 0.68296845 0.41834018], val_grp_loss: [0.45931303 0.55178749 0.44153684], train_hist_grp_loss: [1890.81343308 1478.22174335 1660.90447643], cur_train_grp_loss: [0.47170883 0.68279828 0.41836913], max_reward_err:  0.0699, max_reward_err_index: 1, max_kl_dist:  0.5411, max_kl_dist_index: 1, max_train_grp_loss:  0.6830, max_train_grp_loss_index: 1, max_val_grp_loss:  0.5518, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.6828, max_cur_train_grp_loss_index: 1, 
2024-09-17 14:52:04,632 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  3500, train_loss:  0.0019, val_loss:  0.0005, grad_norm: 0.0446, live_grad: 0.0000, reward_err: 0.0111, 0.0703, 0.0002, KL_dist: 0.2916, 0.5644, 0.2829, param: [3.99524243 6.14428669 3.64129739 6.09358429], weights: [0.89658993 0.01806916 0.0853409 ], train_wt_loss:  0.5579, val_wt_loss: 0.4579, train_grp_loss: [0.46787434 0.69970621 0.41549255], val_grp_loss: [0.45569994 0.56412111 0.43883743], train_hist_grp_loss: [1937.79121005 1547.35201673 1702.59673738], cur_train_grp_loss: [0.46791148 0.69954194 0.41552055], max_reward_err:  0.0703, max_reward_err_index: 1, max_kl_dist:  0.5644, max_kl_dist_index: 1, max_train_grp_loss:  0.6997, max_train_grp_loss_index: 1, max_val_grp_loss:  0.5641, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.6995, max_cur_train_grp_loss_index: 1, 
2024-09-17 14:52:07,334 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  3600, train_loss:  0.0019, val_loss:  0.0005, grad_norm: 0.0450, live_grad: 0.0000, reward_err: 0.0099, 0.0723, 0.0001, KL_dist: 0.3010, 0.5871, 0.2951, param: [4.01054962 6.2637475  3.63638332 6.22374791], weights: [0.896035   0.02299394 0.08097106], train_wt_loss:  0.5573, val_wt_loss: 0.4557, train_grp_loss: [0.46425339 0.71573165 0.41274313], val_grp_loss: [0.45224778 0.57593554 0.4362307 ], train_hist_grp_loss: [1984.39782466 1618.12294758 1744.00905557], cur_train_grp_loss: [0.46428863 0.71557583 0.41277012], max_reward_err:  0.0723, max_reward_err_index: 1, max_kl_dist:  0.5871, max_kl_dist_index: 1, max_train_grp_loss:  0.7157, max_train_grp_loss_index: 1, max_val_grp_loss:  0.5759, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.7156, max_cur_train_grp_loss_index: 1, 
2024-09-17 14:52:10,040 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  3700, train_loss:  0.0019, val_loss:  0.0005, grad_norm: 0.0455, live_grad: 0.0000, reward_err: 0.0088, 0.0735, 0.0001, KL_dist: 0.3107, 0.6089, 0.3073, param: [4.02897121 6.37770182 3.63453388 6.34764349], weights: [0.8935209  0.02975917 0.07671993], train_wt_loss:  0.5576, val_wt_loss: 0.4541, train_grp_loss: [0.46084184 0.73074241 0.41009829], val_grp_loss: [0.44898561 0.58698689 0.43372305], train_hist_grp_loss: [2030.65236879 1690.4491276  1785.15154218], cur_train_grp_loss: [0.46087477 0.73059857 0.41012419], max_reward_err:  0.0735, max_reward_err_index: 1, max_kl_dist:  0.6089, max_kl_dist_index: 1, max_train_grp_loss:  0.7307, max_train_grp_loss_index: 1, max_val_grp_loss:  0.5870, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.7306, max_cur_train_grp_loss_index: 1, 
2024-09-17 14:52:12,815 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  3800, train_loss:  0.0019, val_loss:  0.0005, grad_norm: 0.0458, live_grad: 0.0000, reward_err: 0.0081, 0.0740, 0.0001, KL_dist: 0.3204, 0.6294, 0.3192, param: [4.05178217 6.48452304 3.63702724 6.46341559], weights: [0.88838719 0.03908441 0.0725284 ], train_wt_loss:  0.5594, val_wt_loss: 0.4533, train_grp_loss: [0.45768856 0.74432399 0.40756805], val_grp_loss: [0.44595467 0.59694146 0.43132437], train_hist_grp_loss: [2076.57806323 1764.20965875 1826.0351158 ], cur_train_grp_loss: [0.45771861 0.74419696 0.40759274], max_reward_err:  0.0740, max_reward_err_index: 1, max_kl_dist:  0.6294, max_kl_dist_index: 1, max_train_grp_loss:  0.7443, max_train_grp_loss_index: 1, max_val_grp_loss:  0.5969, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.7442, max_cur_train_grp_loss_index: 1, 
2024-09-17 14:52:15,526 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  3900, train_loss:  0.0019, val_loss:  0.0005, grad_norm: 0.0461, live_grad: 0.0000, reward_err: 0.0076, 0.0749, 0.0001, KL_dist: 0.3303, 0.6481, 0.3308, param: [4.08073915 6.58195471 3.6456064  6.56849284], weights: [0.87974068 0.05193217 0.06832715], train_wt_loss:  0.5631, val_wt_loss: 0.4536, train_grp_loss: [0.45486184 0.75591075 0.40516745], val_grp_loss: [0.4432129  0.60534483 0.42904945], train_hist_grp_loss: [2122.20392913 1839.2350588  1866.67193134], cur_train_grp_loss: [0.45488821 0.75580707 0.40519075], max_reward_err:  0.0749, max_reward_err_index: 1, max_kl_dist:  0.6481, max_kl_dist_index: 1, max_train_grp_loss:  0.7559, max_train_grp_loss_index: 1, max_val_grp_loss:  0.6053, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.7558, max_cur_train_grp_loss_index: 1, 
2024-09-17 14:52:18,342 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  4000, train_loss:  0.0019, val_loss:  0.0005, grad_norm: 0.0463, live_grad: 0.0000, reward_err: 0.0073, 0.0749, 0.0001, KL_dist: 0.3400, 0.6642, 0.3416, param: [4.11821522 6.66692385 3.66261125 6.65938301], weights: [0.86644087 0.06952069 0.06403843], train_wt_loss:  0.5694, val_wt_loss: 0.4554, train_grp_loss: [0.45245532 0.76474451 0.40291852], val_grp_loss: [0.44084019 0.61158924 0.42691986], train_hist_grp_loss: [2167.56702081 1915.29007894 1907.07597583], cur_train_grp_loss: [0.45247692 0.76467283 0.40294016], max_reward_err:  0.0749, max_reward_err_index: 1, max_kl_dist:  0.6642, max_kl_dist_index: 1, max_train_grp_loss:  0.7647, max_train_grp_loss_index: 1, max_val_grp_loss:  0.6116, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.7647, max_cur_train_grp_loss_index: 1, 
2024-09-17 14:52:21,070 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  4100, train_loss:  0.0019, val_loss:  0.0005, grad_norm: 0.0463, live_grad: 0.0000, reward_err: 0.0073, 0.0749, 0.0001, KL_dist: 0.3494, 0.6769, 0.3514, param: [4.16730292 6.73538034 3.69108107 6.73150767], weights: [0.84716716 0.09324901 0.05958384], train_wt_loss:  0.5788, val_wt_loss: 0.4588, train_grp_loss: [0.45059353 0.76984488 0.40085264], val_grp_loss: [0.43894349 0.61489116 0.42496626], train_hist_grp_loss: [2212.71524818 1992.05278697 1947.26388084], cur_train_grp_loss: [0.45060896 0.76981612 0.40087226], max_reward_err:  0.0749, max_reward_err_index: 1, max_kl_dist:  0.6769, max_kl_dist_index: 1, max_train_grp_loss:  0.7698, max_train_grp_loss_index: 1, max_val_grp_loss:  0.6149, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.7698, max_cur_train_grp_loss_index: 1, 
2024-09-17 14:52:23,777 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  4200, train_loss:  0.0019, val_loss:  0.0005, grad_norm: 0.0462, live_grad: 0.0000, reward_err: 0.0078, 0.0749, 0.0001, KL_dist: 0.3584, 0.6849, 0.3597, param: [4.23179725 6.78226642 3.73474223 6.77920188], weights: [0.82064726 0.12445089 0.05490185], train_wt_loss:  0.5918, val_wt_loss: 0.4640, train_grp_loss: [0.44943402 0.77002064 0.39901319], val_grp_loss: [0.43765938 0.61430308 0.42323096], train_hist_grp_loss: [2257.71061599 2069.09239874 1987.25598868], cur_train_grp_loss: [0.44944154 0.77004753 0.39903028], max_reward_err:  0.0749, max_reward_err_index: 1, max_kl_dist:  0.6849, max_kl_dist_index: 1, max_train_grp_loss:  0.7700, max_train_grp_loss_index: 1, max_val_grp_loss:  0.6143, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.7700, max_cur_train_grp_loss_index: 1, 
2024-09-17 14:52:26,501 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  4300, train_loss:  0.0019, val_loss:  0.0005, grad_norm: 0.0459, live_grad: 0.0000, reward_err: 0.0082, 0.0740, 0.0001, KL_dist: 0.3669, 0.6871, 0.3661, param: [4.31592071 6.80178558 3.79774849 6.79607687], weights: [0.78611582 0.16390745 0.04997673], train_wt_loss:  0.6078, val_wt_loss: 0.4708, train_grp_loss: [0.4491612  0.76396725 0.39745743], val_grp_loss: [0.43715004 0.60879597 0.42176987], train_hist_grp_loss: [2302.63231591 2145.85209725 2027.07765707], cur_train_grp_loss: [0.44915891 0.76406278 0.39747136], max_reward_err:  0.0740, max_reward_err_index: 1, max_kl_dist:  0.6871, max_kl_dist_index: 1, max_train_grp_loss:  0.7640, max_train_grp_loss_index: 1, max_val_grp_loss:  0.6088, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.7641, max_cur_train_grp_loss_index: 1, 
2024-09-17 14:52:29,234 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  4400, train_loss:  0.0019, val_loss:  0.0005, grad_norm: 0.0454, live_grad: 0.0000, reward_err: 0.0096, 0.0718, 0.0001, KL_dist: 0.3751, 0.6825, 0.3706, param: [4.42365443 6.78815495 3.88404124 6.77594784], weights: [0.74395625 0.21117223 0.04487152], train_wt_loss:  0.6254, val_wt_loss: 0.4781, train_grp_loss: [0.44996618 0.75049319 0.39625611], val_grp_loss: [0.43758759 0.59744629 0.42065202], train_hist_grp_loss: [2347.57855068 2221.64773501 2066.76065847], cur_train_grp_loss: [0.44995222 0.75066764 0.39626611], max_reward_err:  0.0718, max_reward_err_index: 1, max_kl_dist:  0.6825, max_kl_dist_index: 1, max_train_grp_loss:  0.7505, max_train_grp_loss_index: 1, max_val_grp_loss:  0.5974, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.7507, max_cur_train_grp_loss_index: 1, 
2024-09-17 14:52:31,965 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  4500, train_loss:  0.0019, val_loss:  0.0005, grad_norm: 0.0445, live_grad: 0.0000, reward_err: 0.0120, 0.0699, 0.0002, KL_dist: 0.3832, 0.6703, 0.3731, param: [4.55767946 6.73688217 3.99633088 6.71433893], weights: [0.69624188 0.26401307 0.03974504], train_wt_loss:  0.6418, val_wt_loss: 0.4842, train_grp_loss: [0.45200988 0.72886895 0.39548795], val_grp_loss: [0.4391238  0.57972003 0.41995421], train_hist_grp_loss: [2392.66550623 2295.69565577 2106.34430764], cur_train_grp_loss: [0.45198295 0.72912604 0.39549323], max_reward_err:  0.0699, max_reward_err_index: 1, max_kl_dist:  0.6703, max_kl_dist_index: 1, max_train_grp_loss:  0.7289, max_train_grp_loss_index: 1, max_val_grp_loss:  0.5797, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.7291, max_cur_train_grp_loss_index: 1, 
2024-09-17 14:52:34,789 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  4600, train_loss:  0.0018, val_loss:  0.0005, grad_norm: 0.0434, live_grad: 0.0000, reward_err: 0.0149, 0.0650, 0.0007, KL_dist: 0.3919, 0.6509, 0.3745, param: [4.71822946 6.64626667 4.13498396 6.61016206], weights: [0.64672001 0.318451   0.03482898], train_wt_loss:  0.6533, val_wt_loss: 0.4872, train_grp_loss: [0.45537647 0.69919234 0.39522697], val_grp_loss: [0.44184973 0.55576344 0.41974867], train_hist_grp_loss: [2438.02205211 2367.17756873 2145.87569564], cur_train_grp_loss: [0.45533625 0.69952613 0.39522688], max_reward_err:  0.0650, max_reward_err_index: 1, max_kl_dist:  0.6509, max_kl_dist_index: 1, max_train_grp_loss:  0.6992, max_train_grp_loss_index: 1, max_val_grp_loss:  0.5558, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.6995, max_cur_train_grp_loss_index: 1, 
2024-09-17 14:52:37,611 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  4700, train_loss:  0.0018, val_loss:  0.0005, grad_norm: 0.0419, live_grad: 0.0000, reward_err: 0.0177, 0.0624, 0.0016, KL_dist: 0.4020, 0.6254, 0.3756, param: [4.90240797 6.51848905 4.29734502 6.46679883], weights: [0.60000917 0.36962772 0.03036311], train_wt_loss:  0.6572, val_wt_loss: 0.4854, train_grp_loss: [0.46003404 0.66258273 0.39552365], val_grp_loss: [0.44575878 0.52654555 0.42008451], train_hist_grp_loss: [2483.77997103 2435.33511162 2185.40832254], cur_train_grp_loss: [0.4599815  0.66297708 0.39551786], max_reward_err:  0.0624, max_reward_err_index: 1, max_kl_dist:  0.6254, max_kl_dist_index: 1, max_train_grp_loss:  0.6626, max_train_grp_loss_index: 1, max_val_grp_loss:  0.5265, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.6630, max_cur_train_grp_loss_index: 1, 
2024-09-17 14:52:40,317 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  4800, train_loss:  0.0017, val_loss:  0.0005, grad_norm: 0.0402, live_grad: 0.0000, reward_err: 0.0220, 0.0588, 0.0032, KL_dist: 0.4145, 0.5959, 0.3776, param: [5.10440802 6.35970227 4.47791635 6.29194934], weights: [0.56037862 0.41309908 0.0265223 ], train_wt_loss:  0.6523, val_wt_loss: 0.4787, train_grp_loss: [0.46582111 0.62106206 0.39638538], val_grp_loss: [0.45072949 0.49374017 0.42096876], train_hist_grp_loss: [2530.06141612 2499.56889707 2224.99874606], cur_train_grp_loss: [0.46575847 0.62149345 0.39637408], max_reward_err:  0.0588, max_reward_err_index: 1, max_kl_dist:  0.5959, max_kl_dist_index: 1, max_train_grp_loss:  0.6211, max_train_grp_loss_index: 1, max_val_grp_loss:  0.4937, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.6215, max_cur_train_grp_loss_index: 1, 
2024-09-17 14:52:43,030 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  4900, train_loss:  0.0017, val_loss:  0.0004, grad_norm: 0.0382, live_grad: 0.0000, reward_err: 0.0264, 0.0542, 0.0048, KL_dist: 0.4297, 0.5648, 0.3816, param: [5.31657065 6.17905947 4.66934514 6.09628932], weights: [0.53082287 0.44579954 0.02337759], train_wt_loss:  0.6398, val_wt_loss: 0.4680, train_grp_loss: [0.47246518 0.57715604 0.39776442], val_grp_loss: [0.45653556 0.4593834  0.42235466], train_hist_grp_loss: [2576.96662476 2559.51072448 2264.70158511], cur_train_grp_loss: [0.47239559 0.57759837 0.39774836], max_reward_err:  0.0542, max_reward_err_index: 1, max_kl_dist:  0.5648, max_kl_dist_index: 1, max_train_grp_loss:  0.5772, max_train_grp_loss_index: 1, max_val_grp_loss:  0.4594, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.5776, max_cur_train_grp_loss_index: 1, 
2024-09-17 14:52:45,789 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  5000, train_loss:  0.0016, val_loss:  0.0004, grad_norm: 0.0361, live_grad: 0.0000, reward_err: 0.0295, 0.0504, 0.0062, KL_dist: 0.4478, 0.5345, 0.3881, param: [5.53077115 5.98716381 4.86373772 5.89160439], weights: [0.51282163 0.46627479 0.02090357], train_wt_loss:  0.6225, val_wt_loss: 0.4554, train_grp_loss: [0.47962361 0.53340117 0.39955863], val_grp_loss: [0.46287774 0.42546736 0.42414254], train_hist_grp_loss: [2624.56472178 2615.04942778 2304.56393034], cur_train_grp_loss: [0.47955068 0.53383045 0.39953908], max_reward_err:  0.0504, max_reward_err_index: 1, max_kl_dist:  0.5345, max_kl_dist_index: 1, max_train_grp_loss:  0.5334, max_train_grp_loss_index: 1, max_val_grp_loss:  0.4629, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.5338, max_cur_train_grp_loss_index: 1, 
2024-09-17 14:52:48,510 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  5100, train_loss:  0.0016, val_loss:  0.0004, grad_norm: 0.0340, live_grad: 0.0000, reward_err: 0.0331, 0.0441, 0.0081, KL_dist: 0.4683, 0.5070, 0.3971, param: [5.73958974 5.79455834 5.05378552 5.68913515], weights: [0.50662048 0.47436741 0.01901211], train_wt_loss:  0.6039, val_wt_loss: 0.4429, train_grp_loss: [0.48693061 0.49195027 0.40162433], val_grp_loss: [0.46942451 0.39362992 0.4261924 ], train_hist_grp_loss: [2672.88904544 2666.31104247 2344.62045575], cur_train_grp_loss: [0.48685798 0.49234771 0.40160286], max_reward_err:  0.0441, max_reward_err_index: 1, max_kl_dist:  0.5070, max_kl_dist_index: 1, max_train_grp_loss:  0.4920, max_train_grp_loss_index: 1, max_val_grp_loss:  0.4694, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4923, max_cur_train_grp_loss_index: 1, 
2024-09-17 14:52:51,194 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  5200, train_loss:  0.0015, val_loss:  0.0004, grad_norm: 0.0319, live_grad: 0.0000, reward_err: 0.0402, 0.0379, 0.0123, KL_dist: 0.4903, 0.4833, 0.4083, param: [5.93700473 5.61063078 5.23344937 5.49850341], weights: [0.51164909 0.4707637  0.01758721], train_wt_loss:  0.5869, val_wt_loss: 0.4324, train_grp_loss: [0.49403761 0.45436745 0.40379614], val_grp_loss: [0.47585012 0.36500878 0.42834338], train_hist_grp_loss: [2721.93691744 2713.60864134 2384.89021477], cur_train_grp_loss: [0.49396858 0.45472054 0.40377445], max_reward_err:  0.0402, max_reward_err_index: 0, max_kl_dist:  0.4903, max_kl_dist_index: 0, max_train_grp_loss:  0.4940, max_train_grp_loss_index: 0, max_val_grp_loss:  0.4759, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4940, max_cur_train_grp_loss_index: 0, 
2024-09-17 14:52:53,880 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  5300, train_loss:  0.0015, val_loss:  0.0004, grad_norm: 0.0299, live_grad: 0.0000, reward_err: 0.0454, 0.0328, 0.0156, KL_dist: 0.5128, 0.4642, 0.4209, param: [6.11862893 5.44300536 5.39821618 5.32721889], weights: [0.52682617 0.45666497 0.01650886], train_wt_loss:  0.5737, val_wt_loss: 0.4253, train_grp_loss: [0.50064175 0.42159975 0.40590793], val_grp_loss: [0.48186381 0.34024097 0.43043399], train_hist_grp_loss: [2771.67287909 2757.38081584 2425.37552122], cur_train_grp_loss: [0.50057904 0.42190185 0.40588762], max_reward_err:  0.0454, max_reward_err_index: 0, max_kl_dist:  0.5128, max_kl_dist_index: 0, max_train_grp_loss:  0.5006, max_train_grp_loss_index: 0, max_val_grp_loss:  0.4819, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.5006, max_cur_train_grp_loss_index: 0, 
2024-09-17 14:52:56,596 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  5400, train_loss:  0.0015, val_loss:  0.0004, grad_norm: 0.0281, live_grad: 0.0000, reward_err: 0.0486, 0.0307, 0.0176, KL_dist: 0.5347, 0.4496, 0.4342, param: [6.28164227 5.29732183 5.54506904 5.18059466], weights: [0.55070418 0.43362996 0.01566586], train_wt_loss:  0.5655, val_wt_loss: 0.4219, train_grp_loss: [0.50650243 0.39406269 0.40781044], val_grp_loss: [0.48722859 0.31954967 0.43231917], train_hist_grp_loss: [2822.03417371 2798.13354969 2466.06278461], cur_train_grp_loss: [0.50644813 0.39431186 0.40779288], max_reward_err:  0.0486, max_reward_err_index: 0, max_kl_dist:  0.5347, max_kl_dist_index: 0, max_train_grp_loss:  0.5065, max_train_grp_loss_index: 0, max_val_grp_loss:  0.4872, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.5064, max_cur_train_grp_loss_index: 0, 
2024-09-17 14:52:59,301 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  5500, train_loss:  0.0015, val_loss:  0.0004, grad_norm: 0.0266, live_grad: 0.0000, reward_err: 0.0526, 0.0278, 0.0204, KL_dist: 0.5552, 0.4394, 0.4473, param: [6.42457875 5.17726326 5.67231642 5.06189175], weights: [0.58152339 0.40351443 0.01496218], train_wt_loss:  0.5624, val_wt_loss: 0.4224, train_grp_loss: [0.51144843 0.37177362 0.40938347], val_grp_loss: [0.49177092 0.30286234 0.43388211], train_hist_grp_loss: [2872.93739336 2836.39349868 2506.92484858], cur_train_grp_loss: [0.51140389 0.37197118 0.40936968], max_reward_err:  0.0526, max_reward_err_index: 0, max_kl_dist:  0.5552, max_kl_dist_index: 0, max_train_grp_loss:  0.5114, max_train_grp_loss_index: 0, max_val_grp_loss:  0.4918, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.5114, max_cur_train_grp_loss_index: 0, 
2024-09-17 14:53:02,033 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  5600, train_loss:  0.0014, val_loss:  0.0004, grad_norm: 0.0254, live_grad: 0.0000, reward_err: 0.0577, 0.0272, 0.0239, KL_dist: 0.5735, 0.4331, 0.4596, param: [6.54707423 5.08472464 5.77937827 4.97257074], weights: [0.6172685  0.36841099 0.0143205 ], train_wt_loss:  0.5638, val_wt_loss: 0.4259, train_grp_loss: [0.5153778  0.35448646 0.41054236], val_grp_loss: [0.49538288 0.28992312 0.43504057], train_hist_grp_loss: [2924.28546073 2872.67496504 2547.92426545], cur_train_grp_loss: [0.51534371 0.3546358  0.41053301], max_reward_err:  0.0577, max_reward_err_index: 0, max_kl_dist:  0.5735, max_kl_dist_index: 0, max_train_grp_loss:  0.5154, max_train_grp_loss_index: 0, max_val_grp_loss:  0.4954, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.5153, max_cur_train_grp_loss_index: 0, 
2024-09-17 14:53:04,746 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  5700, train_loss:  0.0014, val_loss:  0.0004, grad_norm: 0.0244, live_grad: 0.0000, reward_err: 0.0586, 0.0245, 0.0244, KL_dist: 0.5894, 0.4302, 0.4708, param: [6.6496253  5.02005879 5.86657318 4.91258791], weights: [0.6557885  0.33052699 0.01368451], train_wt_loss:  0.5689, val_wt_loss: 0.4319, train_grp_loss: [0.51825272 0.34180375 0.41123937], val_grp_loss: [0.49801864 0.28038196 0.43574814], train_hist_grp_loss: [2975.97433973 2907.45933878 2589.01695737], cur_train_grp_loss: [0.51822918 0.34190929 0.41123476], max_reward_err:  0.0586, max_reward_err_index: 0, max_kl_dist:  0.5894, max_kl_dist_index: 0, max_train_grp_loss:  0.5183, max_train_grp_loss_index: 0, max_val_grp_loss:  0.4980, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.5182, max_cur_train_grp_loss_index: 0, 
2024-09-17 14:53:07,458 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  5800, train_loss:  0.0014, val_loss:  0.0004, grad_norm: 0.0238, live_grad: 0.0000, reward_err: 0.0597, 0.0241, 0.0253, KL_dist: 0.6025, 0.4301, 0.4805, param: [6.73337134 4.98236753 5.93491619 4.88071038], weights: [0.69498403 0.29199636 0.01301961], train_wt_loss:  0.5761, val_wt_loss: 0.4391, train_grp_loss: [0.5200904  0.33325871 0.41146082], val_grp_loss: [0.49968658 0.27385668 0.43599162], train_hist_grp_loss: [3027.89902434 2941.18427159 2630.15579579], cur_train_grp_loss: [0.52007699 0.33332527 0.41146093], max_reward_err:  0.0597, max_reward_err_index: 0, max_kl_dist:  0.6025, max_kl_dist_index: 0, max_train_grp_loss:  0.5201, max_train_grp_loss_index: 0, max_val_grp_loss:  0.4997, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.5201, max_cur_train_grp_loss_index: 0, 
2024-09-17 14:53:10,191 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  5900, train_loss:  0.0014, val_loss:  0.0004, grad_norm: 0.0234, live_grad: 0.0000, reward_err: 0.0597, 0.0222, 0.0253, KL_dist: 0.6129, 0.4325, 0.4887, param: [6.79989672 4.96981722 5.98592441 4.87483738], weights: [0.73301596 0.25467271 0.01231133], train_wt_loss:  0.5844, val_wt_loss: 0.4468, train_grp_loss: [0.52095128 0.32836979 0.41122132], val_grp_loss: [0.50043824 0.26997143 0.43578534], train_hist_grp_loss: [3079.95847564 2974.23965271 2671.29374152], cur_train_grp_loss: [0.52094723 0.32840213 0.41122589], max_reward_err:  0.0597, max_reward_err_index: 0, max_kl_dist:  0.6129, max_kl_dist_index: 0, max_train_grp_loss:  0.5210, max_train_grp_loss_index: 0, max_val_grp_loss:  0.5004, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.5209, max_cur_train_grp_loss_index: 0, 
2024-09-17 14:53:12,922 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  6000, train_loss:  0.0014, val_loss:  0.0004, grad_norm: 0.0232, live_grad: 0.0000, reward_err: 0.0607, 0.0214, 0.0260, KL_dist: 0.6209, 0.4368, 0.4955, param: [6.85105094 4.97995657 6.02143112 4.89231236], weights: [0.76846954 0.21996907 0.01156139], train_wt_loss:  0.5926, val_wt_loss: 0.4541, train_grp_loss: [0.52092599 0.32667342 0.41055637], val_grp_loss: [0.5003557  0.26837755 0.43516406], train_hist_grp_loss: [3132.05930352 3006.96790507 2712.3863151 ], cur_train_grp_loss: [0.52093028 0.32667602 0.41056497], max_reward_err:  0.0607, max_reward_err_index: 0, max_kl_dist:  0.6209, max_kl_dist_index: 0, max_train_grp_loss:  0.5209, max_train_grp_loss_index: 0, max_val_grp_loss:  0.5004, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.5209, max_cur_train_grp_loss_index: 0, 
2024-09-17 14:53:15,656 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  6100, train_loss:  0.0014, val_loss:  0.0004, grad_norm: 0.0233, live_grad: 0.0000, reward_err: 0.0603, 0.0219, 0.0257, KL_dist: 0.6266, 0.4429, 0.5010, param: [6.8887909  5.01001011 6.04341599 4.93020558], weights: [0.8004282  0.18878958 0.01078222], train_wt_loss:  0.6000, val_wt_loss: 0.4606, train_grp_loss: [0.52012248 0.32774166 0.40951463], val_grp_loss: [0.49953905 0.26876253 0.43417537], train_hist_grp_loss: [3184.11813954 3039.66676013 2753.39330137], cur_train_grp_loss: [0.52013399 0.32771859 0.40952674], max_reward_err:  0.0603, max_reward_err_index: 0, max_kl_dist:  0.6266, max_kl_dist_index: 0, max_train_grp_loss:  0.5201, max_train_grp_loss_index: 0, max_val_grp_loss:  0.4995, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.5201, max_cur_train_grp_loss_index: 0, 
2024-09-17 14:53:18,472 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  6200, train_loss:  0.0014, val_loss:  0.0004, grad_norm: 0.0235, live_grad: 0.0000, reward_err: 0.0600, 0.0235, 0.0255, KL_dist: 0.6305, 0.4506, 0.5055, param: [6.91505286 5.05712362 6.05386333 4.98554726], weights: [0.8284509  0.16155768 0.00999142], train_wt_loss:  0.6060, val_wt_loss: 0.4659, train_grp_loss: [0.5186549  0.33118982 0.40815105], val_grp_loss: [0.49809541 0.27085202 0.43287298], train_hist_grp_loss: [3236.06280059 3072.59326286 2794.2797148 ], cur_train_grp_loss: [0.51867249 0.33114471 0.4081661 ], max_reward_err:  0.0600, max_reward_err_index: 0, max_kl_dist:  0.6305, max_kl_dist_index: 0, max_train_grp_loss:  0.5187, max_train_grp_loss_index: 0, max_val_grp_loss:  0.4981, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.5187, max_cur_train_grp_loss_index: 0, 
2024-09-17 14:53:21,183 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  6300, train_loss:  0.0014, val_loss:  0.0004, grad_norm: 0.0238, live_grad: 0.0000, reward_err: 0.0597, 0.0243, 0.0253, KL_dist: 0.6329, 0.4595, 0.5091, param: [6.93165963 5.11854665 6.05465673 5.05549932], weights: [0.85248123 0.13831155 0.00920722], train_wt_loss:  0.6106, val_wt_loss: 0.4698, train_grp_loss: [0.51663505 0.33667809 0.40652138], val_grp_loss: [0.49613039 0.274408   0.43131138], train_hist_grp_loss: [3287.83246195 3105.9682154  2835.01614183], cur_train_grp_loss: [0.51665764 0.33661412 0.40653881], max_reward_err:  0.0597, max_reward_err_index: 0, max_kl_dist:  0.6329, max_kl_dist_index: 0, max_train_grp_loss:  0.5166, max_train_grp_loss_index: 0, max_val_grp_loss:  0.4961, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.5167, max_cur_train_grp_loss_index: 0, 
2024-09-17 14:53:23,915 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  6400, train_loss:  0.0014, val_loss:  0.0004, grad_norm: 0.0243, live_grad: 0.0000, reward_err: 0.0587, 0.0248, 0.0246, KL_dist: 0.6341, 0.4697, 0.5121, param: [6.94026359 5.19175006 6.04751226 5.13746424], weights: [0.87272857 0.11882589 0.00844555], train_wt_loss:  0.6137, val_wt_loss: 0.4725, train_grp_loss: [0.51416671 0.34390951 0.4046784 ], val_grp_loss: [0.49374244 0.27922508 0.42954218], train_hist_grp_loss: [3339.37711723 3139.9805858  2875.5786219 ], cur_train_grp_loss: [0.5141933  0.34382945 0.40469772], max_reward_err:  0.0587, max_reward_err_index: 0, max_kl_dist:  0.6341, max_kl_dist_index: 0, max_train_grp_loss:  0.5142, max_train_grp_loss_index: 0, max_val_grp_loss:  0.4937, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.5142, max_cur_train_grp_loss_index: 0, 
2024-09-17 14:53:26,694 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  6500, train_loss:  0.0014, val_loss:  0.0004, grad_norm: 0.0249, live_grad: 0.0000, reward_err: 0.0575, 0.0269, 0.0238, KL_dist: 0.6344, 0.4809, 0.5147, param: [6.94232055 5.27448654 6.03394588 5.22913954], weights: [0.88955475 0.10272661 0.00771863], train_wt_loss:  0.6154, val_wt_loss: 0.4741, train_grp_loss: [0.51134247 0.35262617 0.40266978], val_grp_loss: [0.49101963 0.28512624 0.42761191], train_hist_grp_loss: [3390.65660057 3174.79161612 2915.94823254], cur_train_grp_loss: [0.5113722  0.35253241 0.40269054], max_reward_err:  0.0575, max_reward_err_index: 0, max_kl_dist:  0.6344, max_kl_dist_index: 0, max_train_grp_loss:  0.5113, max_train_grp_loss_index: 0, max_val_grp_loss:  0.4910, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.5114, max_cur_train_grp_loss_index: 0, 
2024-09-17 14:53:29,461 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  6600, train_loss:  0.0014, val_loss:  0.0004, grad_norm: 0.0256, live_grad: 0.0000, reward_err: 0.0566, 0.0275, 0.0232, KL_dist: 0.6342, 0.4931, 0.5170, param: [6.93908712 5.36480788 6.01526719 5.3285308 ], weights: [0.90338462 0.08958065 0.00703473], train_wt_loss:  0.6159, val_wt_loss: 0.4746, train_grp_loss: [0.50824268 0.36260445 0.40053709], val_grp_loss: [0.48803845 0.29195849 0.42556116], train_hist_grp_loss: [3441.63940192 3210.53849603 2956.11051946], cur_train_grp_loss: [0.50827481 0.36249909 0.40055891], max_reward_err:  0.0566, max_reward_err_index: 0, max_kl_dist:  0.6342, max_kl_dist_index: 0, max_train_grp_loss:  0.5082, max_train_grp_loss_index: 0, max_val_grp_loss:  0.4880, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.5083, max_cur_train_grp_loss_index: 0, 
2024-09-17 14:53:32,205 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  6700, train_loss:  0.0014, val_loss:  0.0004, grad_norm: 0.0263, live_grad: 0.0000, reward_err: 0.0537, 0.0278, 0.0213, KL_dist: 0.6336, 0.5061, 0.5193, param: [6.93163335 5.4610531  5.99259046 5.43393706], weights: [0.91464496 0.0789565  0.00639854], train_wt_loss:  0.6154, val_wt_loss: 0.4744, train_grp_loss: [0.50493564 0.37365011 0.39831568], val_grp_loss: [0.48486401 0.29958883 0.42342442], train_hist_grp_loss: [3492.30144381 3247.33754857 2996.05487621], cur_train_grp_loss: [0.50496954 0.37353495 0.39833823], max_reward_err:  0.0537, max_reward_err_index: 0, max_kl_dist:  0.6336, max_kl_dist_index: 0, max_train_grp_loss:  0.5049, max_train_grp_loss_index: 0, max_val_grp_loss:  0.4849, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.5050, max_cur_train_grp_loss_index: 0, 
2024-09-17 14:53:34,952 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  6800, train_loss:  0.0015, val_loss:  0.0004, grad_norm: 0.0270, live_grad: 0.0000, reward_err: 0.0509, 0.0290, 0.0193, KL_dist: 0.6328, 0.5199, 0.5216, param: [6.92086391 5.56182006 5.96685565 5.54392056], weights: [0.92372858 0.07045951 0.00581191], train_wt_loss:  0.6141, val_wt_loss: 0.4734, train_grp_loss: [0.50147872 0.3855934  0.39603515], val_grp_loss: [0.4815509  0.30790052 0.42123052], train_hist_grp_loss: [3542.62492697 3285.2869239  3035.77394161], cur_train_grp_loss: [0.50151387 0.38547003 0.39605816], max_reward_err:  0.0509, max_reward_err_index: 0, max_kl_dist:  0.6328, max_kl_dist_index: 0, max_train_grp_loss:  0.5015, max_train_grp_loss_index: 0, max_val_grp_loss:  0.4816, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.5015, max_cur_train_grp_loss_index: 0, 
2024-09-17 14:53:37,752 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  6900, train_loss:  0.0015, val_loss:  0.0004, grad_norm: 0.0278, live_grad: 0.0000, reward_err: 0.0490, 0.0303, 0.0181, KL_dist: 0.6320, 0.5344, 0.5241, param: [6.9075427  5.66592933 5.93885361 5.65726928], weights: [0.93097672 0.06374874 0.00527454], train_wt_loss:  0.6122, val_wt_loss: 0.4719, train_grp_loss: [0.49791974 0.39828454 0.39371995], val_grp_loss: [0.47814462 0.31678978 0.4190033 ], train_hist_grp_loss: [3592.59730316 3324.46882283 3075.26305327], cur_train_grp_loss: [0.4979557  0.39815438 0.39374321], max_reward_err:  0.0490, max_reward_err_index: 0, max_kl_dist:  0.6320, max_kl_dist_index: 0, max_train_grp_loss:  0.4979, max_train_grp_loss_index: 0, max_val_grp_loss:  0.4781, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4980, max_cur_train_grp_loss_index: 0, 
2024-09-17 14:53:40,492 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  7000, train_loss:  0.0015, val_loss:  0.0004, grad_norm: 0.0285, live_grad: 0.0000, reward_err: 0.0482, 0.0311, 0.0176, KL_dist: 0.6312, 0.5495, 0.5267, param: [6.89231789 5.77238616 5.90925212 5.77295796], weights: [0.93667333 0.05854194 0.00478472], train_wt_loss:  0.6098, val_wt_loss: 0.4701, train_grp_loss: [0.49429855 0.41158957 0.39139024], val_grp_loss: [0.47468301 0.32616287 0.41676233], train_hist_grp_loss: [3642.2103991  3364.95128452 3114.51977483], cur_train_grp_loss: [0.49433496 0.41145389 0.39141355], max_reward_err:  0.0482, max_reward_err_index: 0, max_kl_dist:  0.6312, max_kl_dist_index: 0, max_train_grp_loss:  0.4943, max_train_grp_loss_index: 0, max_val_grp_loss:  0.4747, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4943, max_cur_train_grp_loss_index: 0, 
2024-09-17 14:53:43,233 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  7100, train_loss:  0.0015, val_loss:  0.0004, grad_norm: 0.0293, live_grad: 0.0000, reward_err: 0.0475, 0.0320, 0.0171, KL_dist: 0.6307, 0.5652, 0.5296, param: [6.87574561 5.88034409 5.87862046 5.89011069], weights: [0.94104615 0.05461404 0.00433981], train_wt_loss:  0.6070, val_wt_loss: 0.4679, train_grp_loss: [0.49064853 0.42538653 0.38906256], val_grp_loss: [0.47119764 0.33593341 0.41452372], train_hist_grp_loss: [3691.45969387 3406.78957544 3153.54350057], cur_train_grp_loss: [0.49068508 0.4252465  0.38908578], max_reward_err:  0.0475, max_reward_err_index: 0, max_kl_dist:  0.6307, max_kl_dist_index: 0, max_train_grp_loss:  0.4906, max_train_grp_loss_index: 0, max_val_grp_loss:  0.4712, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4907, max_cur_train_grp_loss_index: 0, 
2024-09-17 14:53:45,934 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  7200, train_loss:  0.0015, val_loss:  0.0004, grad_norm: 0.0301, live_grad: 0.0000, reward_err: 0.0448, 0.0332, 0.0154, KL_dist: 0.6304, 0.5812, 0.5328, param: [6.85831149 5.98907126 5.84745203 6.00796647], weights: [0.94427074 0.05179262 0.00393664], train_wt_loss:  0.6040, val_wt_loss: 0.4655, train_grp_loss: [0.48699795 0.43956191 0.38675063], val_grp_loss: [0.46771519 0.34601994 0.41230074], train_hist_grp_loss: [3740.34374095 3450.02721307 3192.33513416], cur_train_grp_loss: [0.48703438 0.43941864 0.38677363], max_reward_err:  0.0448, max_reward_err_index: 0, max_kl_dist:  0.6304, max_kl_dist_index: 0, max_train_grp_loss:  0.4870, max_train_grp_loss_index: 0, max_val_grp_loss:  0.4677, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4870, max_cur_train_grp_loss_index: 0, 
2024-09-17 14:53:48,724 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  7300, train_loss:  0.0015, val_loss:  0.0004, grad_norm: 0.0308, live_grad: 0.0000, reward_err: 0.0435, 0.0345, 0.0146, KL_dist: 0.6305, 0.5977, 0.5363, param: [6.84045016 6.09792023 5.81618458 6.12584809], weights: [0.94647558 0.0499526  0.00357182], train_wt_loss:  0.6009, val_wt_loss: 0.4629, train_grp_loss: [0.48337124 0.45400745 0.38446593], val_grp_loss: [0.46425858 0.35634368 0.41010453], train_hist_grp_loss: [3788.86372139 3494.69665057 3230.89683463], cur_train_grp_loss: [0.48340732 0.453862   0.38448861], max_reward_err:  0.0435, max_reward_err_index: 0, max_kl_dist:  0.6305, max_kl_dist_index: 0, max_train_grp_loss:  0.4834, max_train_grp_loss_index: 0, max_val_grp_loss:  0.4643, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4834, max_cur_train_grp_loss_index: 0, 
2024-09-17 14:53:51,505 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  7400, train_loss:  0.0015, val_loss:  0.0004, grad_norm: 0.0316, live_grad: 0.0000, reward_err: 0.0423, 0.0369, 0.0139, KL_dist: 0.6309, 0.6144, 0.5402, param: [6.82256291 6.20630058 5.78521857 6.24313375], weights: [0.94774667 0.04901138 0.00324195], train_wt_loss:  0.5977, val_wt_loss: 0.4603, train_grp_loss: [0.47979008 0.46861687 0.38221825], val_grp_loss: [0.460848   0.36682621 0.40794457], train_hist_grp_loss: [3837.02311361 3540.81963913 3269.23182158], cur_train_grp_loss: [0.4798256  0.46847031 0.38224052], max_reward_err:  0.0423, max_reward_err_index: 0, max_kl_dist:  0.6309, max_kl_dist_index: 0, max_train_grp_loss:  0.4798, max_train_grp_loss_index: 0, max_val_grp_loss:  0.4608, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4798, max_cur_train_grp_loss_index: 0, 
2024-09-17 14:53:54,317 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  7500, train_loss:  0.0015, val_loss:  0.0004, grad_norm: 0.0323, live_grad: 0.0000, reward_err: 0.0399, 0.0381, 0.0125, KL_dist: 0.6317, 0.6313, 0.5445, param: [6.80503399 6.31365389 5.75493394 6.35923096], weights: [0.9481312  0.04892512 0.00294368], train_wt_loss:  0.5946, val_wt_loss: 0.4577, train_grp_loss: [0.47627435 0.48328276 0.38001623], val_grp_loss: [0.45750189 0.37738729 0.40582917], train_hist_grp_loss: [3884.8274677  3588.40727354 3307.34423272], cur_train_grp_loss: [0.47630912 0.48313618 0.380038  ], max_reward_err:  0.0399, max_reward_err_index: 0, max_kl_dist:  0.6317, max_kl_dist_index: 0, max_train_grp_loss:  0.4833, max_train_grp_loss_index: 1, max_val_grp_loss:  0.4575, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4831, max_cur_train_grp_loss_index: 1, 
2024-09-17 14:53:57,082 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  7600, train_loss:  0.0016, val_loss:  0.0004, grad_norm: 0.0330, live_grad: 0.0000, reward_err: 0.0375, 0.0395, 0.0110, KL_dist: 0.6329, 0.6483, 0.5490, param: [6.7882462  6.4194301  5.72570601 6.4735517 ], weights: [0.94763986 0.04968629 0.00267386], train_wt_loss:  0.5915, val_wt_loss: 0.4551, train_grp_loss: [0.47284312 0.49789327 0.37786773], val_grp_loss: [0.45423778 0.38794237 0.40376593], train_hist_grp_loss: [3932.28427428 3637.45971532 3345.23902729], cur_train_grp_loss: [0.47287695 0.49774782 0.37788892], max_reward_err:  0.0395, max_reward_err_index: 1, max_kl_dist:  0.6483, max_kl_dist_index: 1, max_train_grp_loss:  0.4979, max_train_grp_loss_index: 1, max_val_grp_loss:  0.4542, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4977, max_cur_train_grp_loss_index: 1, 
2024-09-17 14:53:59,835 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  7700, train_loss:  0.0016, val_loss:  0.0004, grad_norm: 0.0337, live_grad: 0.0000, reward_err: 0.0356, 0.0423, 0.0098, KL_dist: 0.6345, 0.6653, 0.5539, param: [6.77259623 6.52306453 5.69792098 6.58548801], weights: [0.94624788 0.0513226  0.00242952], train_wt_loss:  0.5887, val_wt_loss: 0.4526, train_grp_loss: [0.46951543 0.51232856 0.37578027], val_grp_loss: [0.45107307 0.39840009 0.40176211], train_hist_grp_loss: [3979.40292173 3687.96557618 3382.92193117], cur_train_grp_loss: [0.46954813 0.5121855  0.37580082], max_reward_err:  0.0423, max_reward_err_index: 1, max_kl_dist:  0.6653, max_kl_dist_index: 1, max_train_grp_loss:  0.5123, max_train_grp_loss_index: 1, max_val_grp_loss:  0.4511, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.5122, max_cur_train_grp_loss_index: 1, 
2024-09-17 14:54:02,658 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  7800, train_loss:  0.0016, val_loss:  0.0004, grad_norm: 0.0343, live_grad: 0.0000, reward_err: 0.0345, 0.0445, 0.0092, KL_dist: 0.6366, 0.6821, 0.5591, param: [6.75851027 6.62395469 5.67199157 6.69438719], weights: [0.94389495 0.05389711 0.00220794], train_wt_loss:  0.5861, val_wt_loss: 0.4502, train_grp_loss: [0.46631117 0.52645703 0.3737614 ], val_grp_loss: [0.44802584 0.40865934 0.39982497], train_hist_grp_loss: [4026.19473844 3739.90093529 3420.39942051], cur_train_grp_loss: [0.46634253 0.52631774 0.37378123], max_reward_err:  0.0445, max_reward_err_index: 1, max_kl_dist:  0.6821, max_kl_dist_index: 1, max_train_grp_loss:  0.5265, max_train_grp_loss_index: 1, max_val_grp_loss:  0.4480, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.5263, max_cur_train_grp_loss_index: 1, 
2024-09-17 14:54:05,403 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  7900, train_loss:  0.0016, val_loss:  0.0004, grad_norm: 0.0349, live_grad: 0.0000, reward_err: 0.0331, 0.0471, 0.0083, KL_dist: 0.6391, 0.6987, 0.5646, param: [6.74646021 6.72143642 5.64837315 6.7995263 ], weights: [0.94048428 0.05750911 0.00200662], train_wt_loss:  0.5838, val_wt_loss: 0.4479, train_grp_loss: [0.46325195 0.54013111 0.37181906], val_grp_loss: [0.44511563 0.41860615 0.39796217], train_hist_grp_loss: [4072.67311952 3793.22795676 3457.67874252], cur_train_grp_loss: [0.46328175 0.53999715 0.37183808], max_reward_err:  0.0471, max_reward_err_index: 1, max_kl_dist:  0.6987, max_kl_dist_index: 1, max_train_grp_loss:  0.5401, max_train_grp_loss_index: 1, max_val_grp_loss:  0.4451, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.5400, max_cur_train_grp_loss_index: 1, 
2024-09-17 14:54:08,157 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  8000, train_loss:  0.0016, val_loss:  0.0004, grad_norm: 0.0354, live_grad: 0.0000, reward_err: 0.0321, 0.0477, 0.0078, KL_dist: 0.6421, 0.7148, 0.5704, param: [6.73698036 6.81475924 5.62758022 6.90008557], weights: [0.93588165 0.06229508 0.00182327], train_wt_loss:  0.5820, val_wt_loss: 0.4459, train_grp_loss: [0.46036192 0.5531828  0.36996195], val_grp_loss: [0.44236425 0.42811032 0.39618209], train_hist_grp_loss: [4118.85373907 3847.89307467 3494.76797282], cur_train_grp_loss: [0.46038989 0.55305597 0.36998007], max_reward_err:  0.0477, max_reward_err_index: 1, max_kl_dist:  0.7148, max_kl_dist_index: 1, max_train_grp_loss:  0.5532, max_train_grp_loss_index: 1, max_val_grp_loss:  0.4424, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.5531, max_cur_train_grp_loss_index: 1, 
2024-09-17 14:54:10,901 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  8100, train_loss:  0.0016, val_loss:  0.0004, grad_norm: 0.0359, live_grad: 0.0000, reward_err: 0.0301, 0.0485, 0.0067, KL_dist: 0.6455, 0.7304, 0.5763, param: [6.73068423 6.90306132 5.610203   6.99512171], weights: [0.92991546 0.06842871 0.00165584], train_wt_loss:  0.5807, val_wt_loss: 0.4442, train_grp_loss: [0.45766866 0.56541914 0.3681999 ], val_grp_loss: [0.43979654 0.43702196 0.39449423], train_hist_grp_loss: [4164.75484932 3903.82472503 3531.67610996], cur_train_grp_loss: [0.45769452 0.56530151 0.36821702], max_reward_err:  0.0485, max_reward_err_index: 1, max_kl_dist:  0.7304, max_kl_dist_index: 1, max_train_grp_loss:  0.5654, max_train_grp_loss_index: 1, max_val_grp_loss:  0.4398, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.5653, max_cur_train_grp_loss_index: 1, 
2024-09-17 14:54:13,638 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  8200, train_loss:  0.0016, val_loss:  0.0004, grad_norm: 0.0363, live_grad: 0.0000, reward_err: 0.0297, 0.0509, 0.0065, KL_dist: 0.6493, 0.7451, 0.5824, param: [6.7282799  6.98534586 5.59692259 7.083543  ], weights: [0.92237941 0.07611812 0.00150247], train_wt_loss:  0.5800, val_wt_loss: 0.4428, train_grp_loss: [0.45520401 0.57661805 0.36654425], val_grp_loss: [0.4374412  0.44516841 0.39290954], train_hist_grp_loss: [4210.39766487 3960.93063768 3568.41320699], cur_train_grp_loss: [0.45522741 0.576512   0.36656024], max_reward_err:  0.0509, max_reward_err_index: 1, max_kl_dist:  0.7451, max_kl_dist_index: 1, max_train_grp_loss:  0.5766, max_train_grp_loss_index: 1, max_val_grp_loss:  0.4452, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.5765, max_cur_train_grp_loss_index: 1, 
2024-09-17 14:54:16,343 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  8300, train_loss:  0.0016, val_loss:  0.0004, grad_norm: 0.0367, live_grad: 0.0000, reward_err: 0.0291, 0.0513, 0.0062, KL_dist: 0.6535, 0.7587, 0.5886, param: [6.73058148 7.06046201 5.5885223  7.1640899 ], weights: [0.91304064 0.08559782 0.00136154], train_wt_loss:  0.5800, val_wt_loss: 0.4417, train_grp_loss: [0.45300475 0.58652545 0.36500817], val_grp_loss: [0.43533141 0.4523521  0.39144074], train_hist_grp_loss: [4255.8068238  4019.09476602 3604.9905392 ], cur_train_grp_loss: [0.45302529 0.58643369 0.36502289], max_reward_err:  0.0513, max_reward_err_index: 1, max_kl_dist:  0.7587, max_kl_dist_index: 1, max_train_grp_loss:  0.5865, max_train_grp_loss_index: 1, max_val_grp_loss:  0.4524, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.5864, max_cur_train_grp_loss_index: 1, 
2024-09-17 14:54:19,102 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  8400, train_loss:  0.0017, val_loss:  0.0004, grad_norm: 0.0370, live_grad: 0.0000, reward_err: 0.0289, 0.0522, 0.0061, KL_dist: 0.6582, 0.7710, 0.5948, param: [6.73851216 7.12709597 5.58589112 7.23532771], weights: [0.90165638 0.09711199 0.00123162], train_wt_loss:  0.5809, val_wt_loss: 0.4411, train_grp_loss: [0.45111297 0.59485497 0.36360697], val_grp_loss: [0.4335052  0.45835057 0.39010266], train_hist_grp_loss: [4301.01090394 4078.17404311 3641.42080332], cur_train_grp_loss: [0.45113021 0.5947805  0.36362026], max_reward_err:  0.0522, max_reward_err_index: 1, max_kl_dist:  0.7710, max_kl_dist_index: 1, max_train_grp_loss:  0.5949, max_train_grp_loss_index: 1, max_val_grp_loss:  0.4584, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.5948, max_cur_train_grp_loss_index: 1, 
2024-09-17 14:54:21,893 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  8500, train_loss:  0.0017, val_loss:  0.0004, grad_norm: 0.0372, live_grad: 0.0000, reward_err: 0.0286, 0.0526, 0.0060, KL_dist: 0.6633, 0.7817, 0.6010, param: [6.75309271 7.18378039 5.59001305 7.29566043], weights: [0.88800292 0.11088556 0.00111152], train_wt_loss:  0.5826, val_wt_loss: 0.4408, train_grp_loss: [0.44957591 0.60129227 0.36235822], val_grp_loss: [0.43200542 0.46292011 0.38891228], train_hist_grp_loss: [4346.04295181 4137.9953194  3677.71833814], cur_train_grp_loss: [0.44958936 0.60123834 0.36236989], max_reward_err:  0.0526, max_reward_err_index: 1, max_kl_dist:  0.7817, max_kl_dist_index: 1, max_train_grp_loss:  0.6013, max_train_grp_loss_index: 1, max_val_grp_loss:  0.4629, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.6012, max_cur_train_grp_loss_index: 1, 
2024-09-17 14:54:24,675 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  8600, train_loss:  0.0017, val_loss:  0.0004, grad_norm: 0.0373, live_grad: 0.0000, reward_err: 0.0286, 0.0526, 0.0060, KL_dist: 0.6688, 0.7905, 0.6070, param: [6.77540753 7.22893278 5.60193506 7.34337784], weights: [0.87191954 0.12708018 0.00100028], train_wt_loss:  0.5851, val_wt_loss: 0.4410, train_grp_loss: [0.44844486 0.60550637 0.36128161], val_grp_loss: [0.43087878 0.46580499 0.38788865], train_hist_grp_loss: [4390.94095199 4198.35305772 3713.89934662], cur_train_grp_loss: [0.44845399 0.60547632 0.36129145], max_reward_err:  0.0526, max_reward_err_index: 1, max_kl_dist:  0.7905, max_kl_dist_index: 1, max_train_grp_loss:  0.6055, max_train_grp_loss_index: 1, max_val_grp_loss:  0.4658, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.6055, max_cur_train_grp_loss_index: 1, 
2024-09-17 14:54:27,460 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  8700, train_loss:  0.0017, val_loss:  0.0004, grad_norm: 0.0374, live_grad: 0.0000, reward_err: 0.0286, 0.0526, 0.0060, KL_dist: 0.6748, 0.7971, 0.6129, param: [6.80654024 7.26093417 5.62270575 7.37674789], weights: [0.85336711 0.14573569 0.00089721], train_wt_loss:  0.5884, val_wt_loss: 0.4416, train_grp_loss: [0.44777281 0.60717033 0.36039843], val_grp_loss: [0.4301739  0.46675393 0.3870524 ], train_hist_grp_loss: [4435.74812817 4259.00860686 3749.98208716], cur_train_grp_loss: [0.44777709 0.60716732 0.36040624], max_reward_err:  0.0526, max_reward_err_index: 1, max_kl_dist:  0.7971, max_kl_dist_index: 1, max_train_grp_loss:  0.6072, max_train_grp_loss_index: 1, max_val_grp_loss:  0.4668, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.6072, max_cur_train_grp_loss_index: 1, 
2024-09-17 14:54:30,240 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  8800, train_loss:  0.0017, val_loss:  0.0004, grad_norm: 0.0373, live_grad: 0.0000, reward_err: 0.0286, 0.0526, 0.0060, KL_dist: 0.6813, 0.8012, 0.6185, param: [6.84747399 7.27825624 5.65327997 7.39416265], weights: [8.32494460e-01 1.66703690e-01 8.01850656e-04], train_wt_loss:  0.5922, val_wt_loss: 0.4423, train_grp_loss: [0.44761054 0.6059926  0.35973053], val_grp_loss: [0.42993782 0.46554499 0.38642466], train_hist_grp_loss: [4480.51293299 4319.69206875 3785.98698611], cur_train_grp_loss: [0.44760948 0.60601924 0.35973607], max_reward_err:  0.0526, max_reward_err_index: 1, max_kl_dist:  0.8012, max_kl_dist_index: 1, max_train_grp_loss:  0.6060, max_train_grp_loss_index: 1, max_val_grp_loss:  0.4655, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.6060, max_cur_train_grp_loss_index: 1, 
2024-09-17 14:54:32,987 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  8900, train_loss:  0.0017, val_loss:  0.0004, grad_norm: 0.0370, live_grad: 0.0000, reward_err: 0.0289, 0.0522, 0.0061, KL_dist: 0.6883, 0.8027, 0.6239, param: [6.89895922 7.27963606 5.69439199 7.39433487], weights: [8.09697946e-01 1.89588044e-01 7.14010028e-04], train_wt_loss:  0.5962, val_wt_loss: 0.4431, train_grp_loss: [0.44800104 0.60175776 0.3592985 ], val_grp_loss: [0.43021112 0.46201749 0.38602535], train_hist_grp_loss: [4525.28856417 4380.10778966 3821.93660977], cur_train_grp_loss: [0.44799429 0.60181567 0.35930159], max_reward_err:  0.0522, max_reward_err_index: 1, max_kl_dist:  0.8027, max_kl_dist_index: 1, max_train_grp_loss:  0.6018, max_train_grp_loss_index: 1, max_val_grp_loss:  0.4620, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.6018, max_cur_train_grp_loss_index: 1, 
2024-09-17 14:54:35,738 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  9000, train_loss:  0.0016, val_loss:  0.0004, grad_norm: 0.0367, live_grad: 0.0000, reward_err: 0.0291, 0.0513, 0.0062, KL_dist: 0.6959, 0.8014, 0.6292, param: [6.96136403 7.26428212 5.74641123 7.37652475], weights: [7.85652509e-01 2.13713836e-01 6.33655558e-04], train_wt_loss:  0.5998, val_wt_loss: 0.4436, train_grp_loss: [0.44897285 0.59437138 0.3591193 ], val_grp_loss: [0.43102183 0.45610682 0.38587087], train_hist_grp_loss: [4570.13186212 4439.94419317 3857.85542717], cur_train_grp_loss: [0.44896021 0.59446077 0.3591198 ], max_reward_err:  0.0513, max_reward_err_index: 1, max_kl_dist:  0.8014, max_kl_dist_index: 1, max_train_grp_loss:  0.5944, max_train_grp_loss_index: 1, max_val_grp_loss:  0.4561, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.5945, max_cur_train_grp_loss_index: 1, 
2024-09-17 14:54:38,497 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  9100, train_loss:  0.0016, val_loss:  0.0004, grad_norm: 0.0362, live_grad: 0.0000, reward_err: 0.0299, 0.0500, 0.0066, KL_dist: 0.7041, 0.7975, 0.6344, param: [7.03453533 7.23207768 5.80920746 7.34075657], weights: [7.61293354e-01 2.38145797e-01 5.60849132e-04], train_wt_loss:  0.6027, val_wt_loss: 0.4437, train_grp_loss: [0.45053306 0.58389993 0.35920332], val_grp_loss: [0.43237903 0.44787464 0.38597121], train_hist_grp_loss: [4615.10151365 4498.88794473 3893.76930315], cur_train_grp_loss: [0.45051459 0.58401925 0.35920117], max_reward_err:  0.0500, max_reward_err_index: 1, max_kl_dist:  0.7975, max_kl_dist_index: 1, max_train_grp_loss:  0.5839, max_train_grp_loss_index: 1, max_val_grp_loss:  0.4479, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.5840, max_cur_train_grp_loss_index: 1, 
2024-09-17 14:54:41,270 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  9200, train_loss:  0.0016, val_loss:  0.0004, grad_norm: 0.0356, live_grad: 0.0000, reward_err: 0.0320, 0.0481, 0.0079, KL_dist: 0.7132, 0.7911, 0.6396, param: [7.11770683 7.18373511 5.88205982 7.28797288], weights: [7.37739145e-01 2.61765222e-01 4.95633329e-04], train_wt_loss:  0.6042, val_wt_loss: 0.4430, train_grp_loss: [0.4526616  0.57059416 0.35955138], val_grp_loss: [0.43426733 0.43752552 0.3863271 ], train_hist_grp_loss: [4660.25560922 4556.64137952 3929.70469112], cur_train_grp_loss: [0.45263764 0.57073996 0.35954662], max_reward_err:  0.0481, max_reward_err_index: 1, max_kl_dist:  0.7911, max_kl_dist_index: 1, max_train_grp_loss:  0.5706, max_train_grp_loss_index: 1, max_val_grp_loss:  0.4375, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.5707, max_cur_train_grp_loss_index: 1, 
2024-09-17 14:54:44,033 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  9300, train_loss:  0.0016, val_loss:  0.0004, grad_norm: 0.0349, live_grad: 0.0000, reward_err: 0.0337, 0.0471, 0.0088, KL_dist: 0.7230, 0.7828, 0.6449, param: [7.20948487 7.12085701 5.96363963 7.22007906], weights: [7.16168126e-01 2.83393945e-01 4.37929604e-04], train_wt_loss:  0.6042, val_wt_loss: 0.4416, train_grp_loss: [0.45530826 0.5548867  0.36015221], val_grp_loss: [0.43664372 0.42540293 0.38692757], train_hist_grp_loss: [4705.64875099 4612.94105178 3965.68754555], cur_train_grp_loss: [0.45527946 0.55505385 0.36014502], max_reward_err:  0.0471, max_reward_err_index: 1, max_kl_dist:  0.7828, max_kl_dist_index: 1, max_train_grp_loss:  0.5549, max_train_grp_loss_index: 1, max_val_grp_loss:  0.4366, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.5551, max_cur_train_grp_loss_index: 1, 
2024-09-17 14:54:46,782 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  9400, train_loss:  0.0016, val_loss:  0.0004, grad_norm: 0.0340, live_grad: 0.0000, reward_err: 0.0363, 0.0430, 0.0104, KL_dist: 0.7336, 0.7730, 0.6506, param: [7.307925   7.04587981 6.05207987 7.13985595], weights: [6.97677298e-01 3.01935231e-01 3.87471362e-04], train_wt_loss:  0.6026, val_wt_loss: 0.4394, train_grp_loss: [0.4583933  0.53736119 0.36098112], val_grp_loss: [0.4394376  0.41196283 0.38774864], train_hist_grp_loss: [4751.32903663 4667.5746222  4001.74203577], cur_train_grp_loss: [0.45836061 0.53754325 0.36097182], max_reward_err:  0.0430, max_reward_err_index: 1, max_kl_dist:  0.7730, max_kl_dist_index: 1, max_train_grp_loss:  0.5374, max_train_grp_loss_index: 1, max_val_grp_loss:  0.4394, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.5375, max_cur_train_grp_loss_index: 1, 
2024-09-17 14:54:49,584 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  9500, train_loss:  0.0016, val_loss:  0.0004, grad_norm: 0.0331, live_grad: 0.0000, reward_err: 0.0380, 0.0395, 0.0115, KL_dist: 0.7450, 0.7623, 0.6566, param: [7.41068665 6.96190582 6.14512023 7.05075396], weights: [6.83160192e-01 3.16496020e-01 3.43787457e-04], train_wt_loss:  0.5996, val_wt_loss: 0.4367, train_grp_loss: [0.46181198 0.51869818 0.36200015], val_grp_loss: [0.44255434 0.39772977 0.38875349], train_hist_grp_loss: [4797.33530079 4720.3934301  4037.88919627], cur_train_grp_loss: [0.46177653 0.5188881  0.36198918], max_reward_err:  0.0395, max_reward_err_index: 1, max_kl_dist:  0.7623, max_kl_dist_index: 1, max_train_grp_loss:  0.5187, max_train_grp_loss_index: 1, max_val_grp_loss:  0.4426, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.5189, max_cur_train_grp_loss_index: 1, 
2024-09-17 14:54:52,347 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  9600, train_loss:  0.0015, val_loss:  0.0004, grad_norm: 0.0322, live_grad: 0.0000, reward_err: 0.0406, 0.0381, 0.0129, KL_dist: 0.7570, 0.7514, 0.6630, param: [7.5152332  6.87245801 6.240297   6.95661167], weights: [6.73228139e-01 3.26465628e-01 3.06233142e-04], train_wt_loss:  0.5956, val_wt_loss: 0.4337, train_grp_loss: [0.46544191 0.49961011 0.36315989], val_grp_loss: [0.44588168 0.38324549 0.38989425], train_hist_grp_loss: [4843.69495921 4771.31900012 4074.14567683], cur_train_grp_loss: [0.46540499 0.4998008  0.36314778], max_reward_err:  0.0406, max_reward_err_index: 0, max_kl_dist:  0.7570, max_kl_dist_index: 0, max_train_grp_loss:  0.4996, max_train_grp_loss_index: 1, max_val_grp_loss:  0.4459, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4998, max_cur_train_grp_loss_index: 1, 
2024-09-17 14:54:55,134 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  9700, train_loss:  0.0015, val_loss:  0.0004, grad_norm: 0.0312, live_grad: 0.0000, reward_err: 0.0438, 0.0351, 0.0149, KL_dist: 0.7694, 0.7408, 0.6699, param: [7.61903701 6.78120542 6.33513981 6.86135463], weights: [6.68181131e-01 3.31544817e-01 2.74051259e-04], train_wt_loss:  0.5911, val_wt_loss: 0.4308, train_grp_loss: [0.46915215 0.48077871 0.36440271], val_grp_loss: [0.44929793 0.36902072 0.39111513], train_hist_grp_loss: [4890.42268828 4820.34305876 4110.52274781], cur_train_grp_loss: [0.46911508 0.48096369 0.36439007], max_reward_err:  0.0438, max_reward_err_index: 0, max_kl_dist:  0.7694, max_kl_dist_index: 0, max_train_grp_loss:  0.4808, max_train_grp_loss_index: 1, max_val_grp_loss:  0.4493, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4810, max_cur_train_grp_loss_index: 1, 
2024-09-17 14:54:57,907 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  9800, train_loss:  0.0015, val_loss:  0.0004, grad_norm: 0.0303, live_grad: 0.0000, reward_err: 0.0444, 0.0332, 0.0153, KL_dist: 0.7820, 0.7309, 0.6770, param: [7.71975606 6.69170403 6.42734327 6.76872249], weights: [6.68018980e-01 3.31734577e-01 2.46442416e-04], train_wt_loss:  0.5868, val_wt_loss: 0.4284, train_grp_loss: [0.47281238 0.46280578 0.36566685], val_grp_loss: [0.45268049 0.35549859 0.39235639], train_hist_grp_loss: [4937.52002686 4867.52188647 4147.02567616], cur_train_grp_loss: [0.47277644 0.46297954 0.36565431], max_reward_err:  0.0444, max_reward_err_index: 0, max_kl_dist:  0.7820, max_kl_dist_index: 0, max_train_grp_loss:  0.4728, max_train_grp_loss_index: 0, max_val_grp_loss:  0.4527, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4728, max_cur_train_grp_loss_index: 0, 
2024-09-17 14:55:00,695 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  9900, train_loss:  0.0015, val_loss:  0.0004, grad_norm: 0.0294, live_grad: 0.0000, reward_err: 0.0469, 0.0324, 0.0168, KL_dist: 0.7945, 0.7223, 0.6844, param: [7.81536308 6.60718406 6.51489479 6.68205501], weights: [6.72477571e-01 3.27299801e-01 2.22627684e-04], train_wt_loss:  0.5830, val_wt_loss: 0.4267, train_grp_loss: [0.47630106 0.44618231 0.36689082], val_grp_loss: [0.45591372 0.343033   0.39355855], train_hist_grp_loss: [4984.97585418 4912.96663551 4183.65353025], cur_train_grp_loss: [0.47626738 0.44634055 0.36687897], max_reward_err:  0.0469, max_reward_err_index: 0, max_kl_dist:  0.7945, max_kl_dist_index: 0, max_train_grp_loss:  0.4763, max_train_grp_loss_index: 0, max_val_grp_loss:  0.4559, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4763, max_cur_train_grp_loss_index: 0, 
2024-09-17 14:55:03,511 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  10000, train_loss:  0.0015, val_loss:  0.0004, grad_norm: 0.0285, live_grad: 0.0000, reward_err: 0.0482, 0.0311, 0.0176, KL_dist: 0.8065, 0.7150, 0.6917, param: [7.9042226  6.53039806 6.59615361 6.60414792], weights: [6.81077476e-01 3.18720628e-01 2.01895336e-04], train_wt_loss:  0.5801, val_wt_loss: 0.4259, train_grp_loss: [0.47951185 0.43127602 0.36801743], val_grp_loss: [0.45889531 0.33188161 0.39466632], train_hist_grp_loss: [5032.76760294 4956.83149076 4220.39941082], cur_train_grp_loss: [0.47948142 0.43141567 0.36800682], max_reward_err:  0.0482, max_reward_err_index: 0, max_kl_dist:  0.8065, max_kl_dist_index: 0, max_train_grp_loss:  0.4795, max_train_grp_loss_index: 0, max_val_grp_loss:  0.4589, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4795, max_cur_train_grp_loss_index: 0, 
2024-09-17 14:55:06,261 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  10100, train_loss:  0.0015, val_loss:  0.0004, grad_norm: 0.0278, live_grad: 0.0000, reward_err: 0.0494, 0.0309, 0.0185, KL_dist: 0.8179, 0.7093, 0.6990, param: [7.98512145 6.46353086 6.66988571 6.53717594], weights: [6.93177773e-01 3.06638597e-01 1.83629871e-04], train_wt_loss:  0.5783, val_wt_loss: 0.4260, train_grp_loss: [0.48235805 0.41833364 0.36899716], val_grp_loss: [0.46154088 0.32221007 0.39563181], train_hist_grp_loss: [5080.86301655 4999.30135188 4257.25105547], cur_train_grp_loss: [0.48233162 0.41845281 0.36898823], max_reward_err:  0.0494, max_reward_err_index: 0, max_kl_dist:  0.8179, max_kl_dist_index: 0, max_train_grp_loss:  0.4824, max_train_grp_loss_index: 0, max_val_grp_loss:  0.4615, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4823, max_cur_train_grp_loss_index: 0, 
2024-09-17 14:55:09,047 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  10200, train_loss:  0.0014, val_loss:  0.0004, grad_norm: 0.0271, live_grad: 0.0000, reward_err: 0.0507, 0.0296, 0.0194, KL_dist: 0.8285, 0.7053, 0.7059, param: [8.05726304 6.40816496 6.73526328 6.4826727 ], weights: [7.08032275e-01 2.91800399e-01 1.67325295e-04], train_wt_loss:  0.5777, val_wt_loss: 0.4270, train_grp_loss: [0.48477496 0.40749314 0.36979047], val_grp_loss: [0.46378661 0.31410343 0.39641682], train_hist_grp_loss: [5129.22224547 5040.580278   4294.19172904], cur_train_grp_loss: [0.48475307 0.40759092 0.36978357], max_reward_err:  0.0507, max_reward_err_index: 0, max_kl_dist:  0.8285, max_kl_dist_index: 0, max_train_grp_loss:  0.4848, max_train_grp_loss_index: 0, max_val_grp_loss:  0.4638, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4848, max_cur_train_grp_loss_index: 0, 
2024-09-17 14:55:11,802 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  10300, train_loss:  0.0014, val_loss:  0.0004, grad_norm: 0.0266, live_grad: 0.0000, reward_err: 0.0525, 0.0283, 0.0207, KL_dist: 0.8380, 0.7028, 0.7124, param: [8.12023598 6.36529149 6.79183863 6.44155558], weights: [7.24846677e-01 2.75000737e-01 1.52585869e-04], train_wt_loss:  0.5781, val_wt_loss: 0.4288, train_grp_loss: [0.48672039 0.39880121 0.37036911], val_grp_loss: [0.46559005 0.30758097 0.39699403], train_hist_grp_loss: [5177.80008676 5080.88144921 4331.2012948 ], cur_train_grp_loss: [0.48670336 0.39887753 0.37036445], max_reward_err:  0.0525, max_reward_err_index: 0, max_kl_dist:  0.8380, max_kl_dist_index: 0, max_train_grp_loss:  0.4867, max_train_grp_loss_index: 0, max_val_grp_loss:  0.4656, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4867, max_cur_train_grp_loss_index: 0, 
2024-09-17 14:55:14,595 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  10400, train_loss:  0.0014, val_loss:  0.0004, grad_norm: 0.0262, live_grad: 0.0000, reward_err: 0.0545, 0.0278, 0.0220, KL_dist: 0.8464, 0.7018, 0.7184, param: [8.17396616 6.33535643 6.83950072 6.41418323], weights: [7.42834038e-01 2.57026844e-01 1.39117593e-04], train_wt_loss:  0.5793, val_wt_loss: 0.4311, train_grp_loss: [0.4881736  0.39223235 0.37071624], val_grp_loss: [0.46692936 0.3026116  0.39734718], train_hist_grp_loss: [5226.54819467 5120.41898258 4368.25735828], cur_train_grp_loss: [0.48816152 0.39228776 0.37071394], max_reward_err:  0.0545, max_reward_err_index: 0, max_kl_dist:  0.8464, max_kl_dist_index: 0, max_train_grp_loss:  0.4882, max_train_grp_loss_index: 0, max_val_grp_loss:  0.4669, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4882, max_cur_train_grp_loss_index: 0, 
2024-09-17 14:55:17,420 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  10500, train_loss:  0.0014, val_loss:  0.0004, grad_norm: 0.0259, live_grad: 0.0000, reward_err: 0.0553, 0.0278, 0.0225, KL_dist: 0.8536, 0.7023, 0.7238, param: [8.21865978 6.31833134 6.87842132 6.40043508], weights: [7.61264374e-01 2.38608913e-01 1.26713497e-04], train_wt_loss:  0.5811, val_wt_loss: 0.4337, train_grp_loss: [0.48913303 0.3877073  0.37082583], val_grp_loss: [0.46780134 0.29912808 0.39747046], train_hist_grp_loss: [5275.41712226 5159.40163842 4405.33638552], cur_train_grp_loss: [0.48912585 0.38774279 0.37082591], max_reward_err:  0.0553, max_reward_err_index: 0, max_kl_dist:  0.8536, max_kl_dist_index: 0, max_train_grp_loss:  0.4891, max_train_grp_loss_index: 0, max_val_grp_loss:  0.4678, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4891, max_cur_train_grp_loss_index: 0, 
2024-09-17 14:55:20,224 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  10600, train_loss:  0.0014, val_loss:  0.0004, grad_norm: 0.0257, live_grad: 0.0000, reward_err: 0.0559, 0.0278, 0.0230, KL_dist: 0.8597, 0.7041, 0.7287, param: [8.25474301 6.31379896 6.90899644 6.39980272], weights: [7.79503525e-01 2.20381239e-01 1.15235601e-04], train_wt_loss:  0.5832, val_wt_loss: 0.4365, train_grp_loss: [0.48961322 0.38510921 0.37070122], val_grp_loss: [0.46821853 0.29703907 0.39736711], train_hist_grp_loss: [5324.35809153 5198.02826557 4442.41471628], cur_train_grp_loss: [0.48961071 0.3851261  0.37070359], max_reward_err:  0.0559, max_reward_err_index: 0, max_kl_dist:  0.8597, max_kl_dist_index: 0, max_train_grp_loss:  0.4896, max_train_grp_loss_index: 0, max_val_grp_loss:  0.4682, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4896, max_cur_train_grp_loss_index: 0, 
2024-09-17 14:55:23,002 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  10700, train_loss:  0.0014, val_loss:  0.0004, grad_norm: 0.0256, live_grad: 0.0000, reward_err: 0.0559, 0.0278, 0.0230, KL_dist: 0.8647, 0.7072, 0.7330, param: [8.28280286 6.32104406 6.93178794 6.4114844 ], weights: [7.97037653e-01 2.02857750e-01 1.04596185e-04], train_wt_loss:  0.5853, val_wt_loss: 0.4391, train_grp_loss: [0.48964127 0.38429718 0.37035337], val_grp_loss: [0.46820587 0.29623877 0.39704778], train_hist_grp_loss: [5373.32443004 5236.48473755 4479.46941762], cur_train_grp_loss: [0.48964311 0.38429695 0.3703579 ], max_reward_err:  0.0559, max_reward_err_index: 0, max_kl_dist:  0.8647, max_kl_dist_index: 0, max_train_grp_loss:  0.4896, max_train_grp_loss_index: 0, max_val_grp_loss:  0.4682, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4896, max_cur_train_grp_loss_index: 0, 
2024-09-17 14:55:25,782 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  10800, train_loss:  0.0014, val_loss:  0.0004, grad_norm: 0.0256, live_grad: 0.0000, reward_err: 0.0559, 0.0278, 0.0230, KL_dist: 0.8686, 0.7114, 0.7368, param: [8.30353295 6.33914166 6.94746911 6.43447504], weights: [8.13482215e-01 1.86423044e-01 9.47405708e-05], train_wt_loss:  0.5873, val_wt_loss: 0.4415, train_grp_loss: [0.48925331 0.38511691 0.3697989 ], val_grp_loss: [0.46779725 0.29661424 0.39652855], train_hist_grp_loss: [5422.27265132 5274.94209726 4516.47894923], cur_train_grp_loss: [0.48925911 0.38510115 0.3698054 ], max_reward_err:  0.0559, max_reward_err_index: 0, max_kl_dist:  0.8686, max_kl_dist_index: 0, max_train_grp_loss:  0.4893, max_train_grp_loss_index: 0, max_val_grp_loss:  0.4678, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4893, max_cur_train_grp_loss_index: 0, 
2024-09-17 14:55:28,556 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  10900, train_loss:  0.0014, val_loss:  0.0004, grad_norm: 0.0257, live_grad: 0.0000, reward_err: 0.0555, 0.0278, 0.0227, KL_dist: 0.8717, 0.7167, 0.7402, param: [8.31768672 6.36703635 6.95677713 6.46764608], weights: [8.28577047e-01 1.71337320e-01 8.56329003e-05], train_wt_loss:  0.5889, val_wt_loss: 0.4436, train_grp_loss: [0.48849119 0.38740867 0.36905824], val_grp_loss: [0.46703234 0.29805057 0.39582922], train_hist_grp_loss: [5471.16319096 5313.55563281 4553.42363617], cur_train_grp_loss: [0.48850052 0.387379   0.36906649], max_reward_err:  0.0555, max_reward_err_index: 0, max_kl_dist:  0.8717, max_kl_dist_index: 0, max_train_grp_loss:  0.4885, max_train_grp_loss_index: 0, max_val_grp_loss:  0.4670, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4885, max_cur_train_grp_loss_index: 0, 
2024-09-17 14:55:31,371 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  11000, train_loss:  0.0014, val_loss:  0.0004, grad_norm: 0.0259, live_grad: 0.0000, reward_err: 0.0548, 0.0278, 0.0222, KL_dist: 0.8740, 0.7228, 0.7432, param: [8.32603951 6.40360867 6.96047429 6.5098117 ], weights: [8.42171208e-01 1.57751546e-01 7.72455942e-05], train_wt_loss:  0.5902, val_wt_loss: 0.4452, train_grp_loss: [0.4873997  0.391013   0.36815393], val_grp_loss: [0.46595381 0.3004344  0.39497162], train_hist_grp_loss: [5519.960836   5352.46463362 4590.28596333], cur_train_grp_loss: [0.4874121  0.39097098 0.3681637 ], max_reward_err:  0.0548, max_reward_err_index: 0, max_kl_dist:  0.8740, max_kl_dist_index: 0, max_train_grp_loss:  0.4874, max_train_grp_loss_index: 0, max_val_grp_loss:  0.4660, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4874, max_cur_train_grp_loss_index: 0, 
2024-09-17 14:55:34,132 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  11100, train_loss:  0.0014, val_loss:  0.0004, grad_norm: 0.0262, live_grad: 0.0000, reward_err: 0.0545, 0.0280, 0.0220, KL_dist: 0.8756, 0.7298, 0.7459, param: [8.32935998 6.44772676 6.95931845 6.55977986], weights: [8.54202016e-01 1.45728431e-01 6.95524518e-05], train_wt_loss:  0.5911, val_wt_loss: 0.4464, train_grp_loss: [0.48602429 0.39577435 0.36710929], val_grp_loss: [0.46460511 0.30365603 0.39397831], train_hist_grp_loss: [5568.63490121 5391.79261244 4627.05071849], cur_train_grp_loss: [0.48603931 0.3957215  0.36712035], max_reward_err:  0.0545, max_reward_err_index: 0, max_kl_dist:  0.8756, max_kl_dist_index: 0, max_train_grp_loss:  0.4860, max_train_grp_loss_index: 0, max_val_grp_loss:  0.4646, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4860, max_cur_train_grp_loss_index: 0, 
2024-09-17 14:55:36,940 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  11200, train_loss:  0.0014, val_loss:  0.0004, grad_norm: 0.0265, live_grad: 0.0000, reward_err: 0.0525, 0.0286, 0.0207, KL_dist: 0.8767, 0.7375, 0.7484, param: [8.3283903  6.49828353 6.95404236 6.61638859], weights: [8.64672353e-01 1.35265122e-01 6.25248437e-05], train_wt_loss:  0.5915, val_wt_loss: 0.4472, train_grp_loss: [0.48440949 0.4015433  0.36594739], val_grp_loss: [0.46302889 0.30761053 0.39287163], train_hist_grp_loss: [5617.15921181 5431.64781855 4663.70501629], cur_train_grp_loss: [0.48442668 0.40148109 0.36595952], max_reward_err:  0.0525, max_reward_err_index: 0, max_kl_dist:  0.8767, max_kl_dist_index: 0, max_train_grp_loss:  0.4844, max_train_grp_loss_index: 0, max_val_grp_loss:  0.4630, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4844, max_cur_train_grp_loss_index: 0, 
2024-09-17 14:55:39,727 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  11300, train_loss:  0.0014, val_loss:  0.0004, grad_norm: 0.0269, live_grad: 0.0000, reward_err: 0.0521, 0.0293, 0.0204, KL_dist: 0.8774, 0.7459, 0.7507, param: [8.32383404 6.55422068 6.94534089 6.67852917], weights: [8.73629266e-01 1.26314604e-01 5.61302139e-05], train_wt_loss:  0.5915, val_wt_loss: 0.4475, train_grp_loss: [0.48259776 0.40817749 0.36469036], val_grp_loss: [0.46126587 0.31219807 0.39167298], train_hist_grp_loss: [5665.51195066 5472.12390503 4700.23823618], cur_train_grp_loss: [0.48261672 0.40810732 0.36470333], max_reward_err:  0.0521, max_reward_err_index: 0, max_kl_dist:  0.8774, max_kl_dist_index: 0, max_train_grp_loss:  0.4826, max_train_grp_loss_index: 0, max_val_grp_loss:  0.4613, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4826, max_cur_train_grp_loss_index: 0, 
2024-09-17 14:55:42,496 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  11400, train_loss:  0.0014, val_loss:  0.0004, grad_norm: 0.0273, live_grad: 0.0000, reward_err: 0.0507, 0.0298, 0.0194, KL_dist: 0.8779, 0.7549, 0.7530, param: [8.31635034 6.61454177 6.93386468 6.74515832], weights: [8.81145654e-01 1.18804014e-01 5.03321004e-05], train_wt_loss:  0.5911, val_wt_loss: 0.4475, train_grp_loss: [0.48062894 0.41554174 0.36335894], val_grp_loss: [0.45935423 0.3173237  0.39040243], train_hist_grp_loss: [5713.67542085 5513.30064649 4736.64190418], cur_train_grp_loss: [0.48064928 0.41546491 0.36337255], max_reward_err:  0.0507, max_reward_err_index: 0, max_kl_dist:  0.8779, max_kl_dist_index: 0, max_train_grp_loss:  0.4806, max_train_grp_loss_index: 0, max_val_grp_loss:  0.4594, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4806, max_cur_train_grp_loss_index: 0, 
2024-09-17 14:55:45,304 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  11500, train_loss:  0.0015, val_loss:  0.0004, grad_norm: 0.0277, live_grad: 0.0000, reward_err: 0.0498, 0.0302, 0.0188, KL_dist: 0.8781, 0.7644, 0.7552, param: [8.30655289 6.67831684 6.9202187  6.81530198], weights: [8.87305741e-01 1.12649168e-01 4.50910000e-05], train_wt_loss:  0.5904, val_wt_loss: 0.4471, train_grp_loss: [0.47853996 0.42350746 0.36197228], val_grp_loss: [0.45732935 0.32289678 0.3890785 ], train_hist_grp_loss: [5761.63576546 5555.24463204 4772.90954317], cur_train_grp_loss: [0.47856133 0.42342524 0.36198636], max_reward_err:  0.0498, max_reward_err_index: 0, max_kl_dist:  0.8781, max_kl_dist_index: 0, max_train_grp_loss:  0.4785, max_train_grp_loss_index: 0, max_val_grp_loss:  0.4573, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4786, max_cur_train_grp_loss_index: 0, 
2024-09-17 14:55:48,157 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  11600, train_loss:  0.0015, val_loss:  0.0004, grad_norm: 0.0281, live_grad: 0.0000, reward_err: 0.0487, 0.0311, 0.0180, KL_dist: 0.8782, 0.7742, 0.7574, param: [8.29501237 6.74468074 6.90496453 6.8880528 ], weights: [8.92194306e-01 1.07765329e-01 4.03655850e-05], train_wt_loss:  0.5895, val_wt_loss: 0.4465, train_grp_loss: [0.47636485 0.4319517  0.36054792], val_grp_loss: [0.45522379 0.32883015 0.38771813], train_hist_grp_loss: [5809.38267632 5598.00988054 4809.03651098], cur_train_grp_loss: [0.47638692 0.43186528 0.3605623 ], max_reward_err:  0.0487, max_reward_err_index: 0, max_kl_dist:  0.8782, max_kl_dist_index: 0, max_train_grp_loss:  0.4764, max_train_grp_loss_index: 0, max_val_grp_loss:  0.4552, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4764, max_cur_train_grp_loss_index: 0, 
2024-09-17 14:55:50,986 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  11700, train_loss:  0.0015, val_loss:  0.0004, grad_norm: 0.0286, live_grad: 0.0000, reward_err: 0.0482, 0.0311, 0.0176, KL_dist: 0.8784, 0.7844, 0.7597, param: [8.28226131 6.81282713 6.88862492 6.96256351], weights: [8.95889176e-01 1.04074710e-01 3.61139513e-05], train_wt_loss:  0.5883, val_wt_loss: 0.4457, train_grp_loss: [0.47413498 0.44075587 0.35910183], val_grp_loss: [0.4530675  0.33503914 0.38633676], train_hist_grp_loss: [5856.90911456 5641.63834316 4845.01984017], cur_train_grp_loss: [0.47415745 0.44066643 0.35911635], max_reward_err:  0.0482, max_reward_err_index: 0, max_kl_dist:  0.8784, max_kl_dist_index: 0, max_train_grp_loss:  0.4741, max_train_grp_loss_index: 0, max_val_grp_loss:  0.4531, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4742, max_cur_train_grp_loss_index: 0, 
2024-09-17 14:55:53,811 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  11800, train_loss:  0.0015, val_loss:  0.0004, grad_norm: 0.0290, live_grad: 0.0000, reward_err: 0.0473, 0.0318, 0.0170, KL_dist: 0.8785, 0.7949, 0.7620, param: [8.26880031 6.8819998  6.87168996 7.03803742], weights: [8.98456388e-01 1.01511318e-01 3.22947200e-05], train_wt_loss:  0.5870, val_wt_loss: 0.4446, train_grp_loss: [0.47187936 0.44980435 0.35764856], val_grp_loss: [0.45088811 0.34144055 0.38494843], train_hist_grp_loss: [5904.21105824 5686.16027113 4880.85808881], cur_train_grp_loss: [0.47190195 0.44971303 0.35766308], max_reward_err:  0.0473, max_reward_err_index: 0, max_kl_dist:  0.8785, max_kl_dist_index: 0, max_train_grp_loss:  0.4719, max_train_grp_loss_index: 0, max_val_grp_loss:  0.4509, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4719, max_cur_train_grp_loss_index: 0, 
2024-09-17 14:55:56,580 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  11900, train_loss:  0.0015, val_loss:  0.0004, grad_norm: 0.0295, live_grad: 0.0000, reward_err: 0.0460, 0.0324, 0.0162, KL_dist: 0.8788, 0.8055, 0.7645, param: [8.25510509 6.95148241 6.85462399 7.11371755], weights: [8.99947369e-01 1.00023763e-01 2.88679154e-05], train_wt_loss:  0.5857, val_wt_loss: 0.4435, train_grp_loss: [0.46962504 0.45898294 0.35620144], val_grp_loss: [0.44871129 0.3479515  0.38356603], train_hist_grp_loss: [5951.2872863  5731.59443689 4916.55120843], cur_train_grp_loss: [0.4696475  0.45889089 0.35621584], max_reward_err:  0.0460, max_reward_err_index: 0, max_kl_dist:  0.8788, max_kl_dist_index: 0, max_train_grp_loss:  0.4696, max_train_grp_loss_index: 0, max_val_grp_loss:  0.4487, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4696, max_cur_train_grp_loss_index: 0, 
2024-09-17 14:55:59,395 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  12000, train_loss:  0.0015, val_loss:  0.0004, grad_norm: 0.0299, live_grad: 0.0000, reward_err: 0.0456, 0.0332, 0.0160, KL_dist: 0.8792, 0.8162, 0.7672, param: [8.24163373 7.02058757 6.83787282 7.18887515], weights: [9.00397670e-01 9.95765339e-02 2.57956039e-05], train_wt_loss:  0.5843, val_wt_loss: 0.4423, train_grp_loss: [0.46739756 0.46817743 0.3547728 ], val_grp_loss: [0.44656119 0.35448837 0.38220145], train_hist_grp_loss: [5998.13920359 5777.94820474 4952.10043208], cur_train_grp_loss: [0.46741962 0.46808579 0.35478696], max_reward_err:  0.0456, max_reward_err_index: 0, max_kl_dist:  0.8792, max_kl_dist_index: 0, max_train_grp_loss:  0.4682, max_train_grp_loss_index: 1, max_val_grp_loss:  0.4466, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4681, max_cur_train_grp_loss_index: 1, 
2024-09-17 14:56:02,188 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  12100, train_loss:  0.0015, val_loss:  0.0004, grad_norm: 0.0303, live_grad: 0.0000, reward_err: 0.0444, 0.0334, 0.0153, KL_dist: 0.8798, 0.8269, 0.7699, param: [8.22883374 7.088646   6.8218707  7.2627983 ], weights: [8.99826879e-01 1.00150079e-01 2.30423176e-05], train_wt_loss:  0.5830, val_wt_loss: 0.4410, train_grp_loss: [0.46522131 0.4772721  0.35337417], val_grp_loss: [0.4444608  0.36096582 0.38086582], train_hist_grp_loss: [6044.77070846 5825.21745439 4987.50818388], cur_train_grp_loss: [0.46524274 0.47718204 0.35338797], max_reward_err:  0.0444, max_reward_err_index: 0, max_kl_dist:  0.8798, max_kl_dist_index: 0, max_train_grp_loss:  0.4773, max_train_grp_loss_index: 1, max_val_grp_loss:  0.4445, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4772, max_cur_train_grp_loss_index: 1, 
2024-09-17 14:56:05,023 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  12200, train_loss:  0.0015, val_loss:  0.0004, grad_norm: 0.0307, live_grad: 0.0000, reward_err: 0.0440, 0.0347, 0.0150, KL_dist: 0.8807, 0.8375, 0.7729, param: [8.21714855 7.15499644 6.80704682 7.33478136], weights: [8.98239536e-01 1.01739888e-01 2.05752961e-05], train_wt_loss:  0.5818, val_wt_loss: 0.4397, train_grp_loss: [0.46311999 0.4861485  0.35201649], val_grp_loss: [0.44243238 0.36729583 0.3795697 ], train_hist_grp_loss: [6091.18810175 5873.38636809 5022.77801007], cur_train_grp_loss: [0.46314055 0.48606121 0.35202983], max_reward_err:  0.0440, max_reward_err_index: 0, max_kl_dist:  0.8807, max_kl_dist_index: 0, max_train_grp_loss:  0.4861, max_train_grp_loss_index: 1, max_val_grp_loss:  0.4424, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4861, max_cur_train_grp_loss_index: 1, 
2024-09-17 14:56:07,834 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  12300, train_loss:  0.0015, val_loss:  0.0004, grad_norm: 0.0311, live_grad: 0.0000, reward_err: 0.0438, 0.0353, 0.0149, KL_dist: 0.8818, 0.8478, 0.7760, param: [8.20702299 7.21897669 6.79383075 7.40411582], weights: [8.95627032e-01 1.04354603e-01 1.83645892e-05], train_wt_loss:  0.5808, val_wt_loss: 0.4385, train_grp_loss: [0.46111694 0.49468437 0.3507103 ], val_grp_loss: [0.44049775 0.37338702 0.37832326], train_hist_grp_loss: [6137.40003364 5922.4271015  5057.91453   ], cur_train_grp_loss: [0.4611364  0.4946011  0.35072307], max_reward_err:  0.0438, max_reward_err_index: 0, max_kl_dist:  0.8818, max_kl_dist_index: 0, max_train_grp_loss:  0.4947, max_train_grp_loss_index: 1, max_val_grp_loss:  0.4405, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4946, max_cur_train_grp_loss_index: 1, 
2024-09-17 14:56:10,604 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  12400, train_loss:  0.0015, val_loss:  0.0004, grad_norm: 0.0315, live_grad: 0.0000, reward_err: 0.0438, 0.0369, 0.0149, KL_dist: 0.8833, 0.8579, 0.7792, param: [8.19890735 7.27991674 6.78265655 7.47008336], weights: [8.91970571e-01 1.08013046e-01 1.63830562e-05], train_wt_loss:  0.5799, val_wt_loss: 0.4373, train_grp_loss: [0.45923543 0.50275304 0.34946592], val_grp_loss: [0.43867862 0.37914425 0.37713648], train_hist_grp_loss: [6183.41748282 5972.29937021 5092.92340525], cur_train_grp_loss: [0.45925357 0.50267509 0.34947802], max_reward_err:  0.0438, max_reward_err_index: 0, max_kl_dist:  0.8833, max_kl_dist_index: 0, max_train_grp_loss:  0.5028, max_train_grp_loss_index: 1, max_val_grp_loss:  0.4387, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.5027, max_cur_train_grp_loss_index: 1, 
2024-09-17 14:56:13,368 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  12500, train_loss:  0.0015, val_loss:  0.0004, grad_norm: 0.0318, live_grad: 0.0000, reward_err: 0.0416, 0.0377, 0.0136, KL_dist: 0.8850, 0.8675, 0.7826, param: [8.19325928 7.3371346  6.77396487 7.53195201], weights: [8.87245423e-01 1.12739971e-01 1.46062942e-05], train_wt_loss:  0.5793, val_wt_loss: 0.4362, train_grp_loss: [0.45749886 0.51022338 0.34829357], val_grp_loss: [0.43699677 0.38446864 0.37601922], train_hist_grp_loss: [6229.2537598  6022.94999903 5127.81132343], cur_train_grp_loss: [0.45751543 0.51015208 0.34830491], max_reward_err:  0.0416, max_reward_err_index: 0, max_kl_dist:  0.8850, max_kl_dist_index: 0, max_train_grp_loss:  0.5102, max_train_grp_loss_index: 1, max_val_grp_loss:  0.4370, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.5102, max_cur_train_grp_loss_index: 1, 
2024-09-17 14:56:16,168 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  12600, train_loss:  0.0015, val_loss:  0.0004, grad_norm: 0.0321, live_grad: 0.0000, reward_err: 0.0406, 0.0377, 0.0129, KL_dist: 0.8871, 0.8765, 0.7861, param: [8.19054302 7.38993599 6.76820233 7.58897653], weights: [8.81426696e-01 1.18560292e-01 1.30125179e-05], train_wt_loss:  0.5790, val_wt_loss: 0.4352, train_grp_loss: [0.45593078 0.51696046 0.34720346], val_grp_loss: [0.43547408 0.38925819 0.37498132], train_hist_grp_loss: [6274.92452313 6074.31250146 5162.58599237], cur_train_grp_loss: [0.45594555 0.51689717 0.34721392], max_reward_err:  0.0406, max_reward_err_index: 0, max_kl_dist:  0.8871, max_kl_dist_index: 0, max_train_grp_loss:  0.5170, max_train_grp_loss_index: 1, max_val_grp_loss:  0.4355, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.5169, max_cur_train_grp_loss_index: 1, 
2024-09-17 14:56:18,975 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  12700, train_loss:  0.0015, val_loss:  0.0004, grad_norm: 0.0323, live_grad: 0.0000, reward_err: 0.0406, 0.0383, 0.0129, KL_dist: 0.8895, 0.8848, 0.7897, param: [8.19122485 7.43761894 6.76581741 7.64040437], weights: [8.74496852e-01 1.25491566e-01 1.15824084e-05], train_wt_loss:  0.5789, val_wt_loss: 0.4344, train_grp_loss: [0.45455486 0.52282734 0.34620575], val_grp_loss: [0.43413252 0.39340922 0.37403262], train_hist_grp_loss: [6320.44779384 6126.30677944 5197.25613914], cur_train_grp_loss: [0.45456759 0.52277342 0.34621524], max_reward_err:  0.0406, max_reward_err_index: 0, max_kl_dist:  0.8895, max_kl_dist_index: 0, max_train_grp_loss:  0.5228, max_train_grp_loss_index: 1, max_val_grp_loss:  0.4341, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.5228, max_cur_train_grp_loss_index: 1, 
2024-09-17 14:56:21,759 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  12800, train_loss:  0.0016, val_loss:  0.0004, grad_norm: 0.0325, live_grad: 0.0000, reward_err: 0.0397, 0.0386, 0.0124, KL_dist: 0.8923, 0.8924, 0.7934, param: [8.19576418 7.4794847  6.76725213 7.68548848], weights: [8.66455012e-01 1.33534689e-01 1.02989406e-05], train_wt_loss:  0.5791, val_wt_loss: 0.4337, train_grp_loss: [0.45339449 0.52768808 0.34531056], val_grp_loss: [0.43299384 0.39681875 0.37318289], train_hist_grp_loss: [6365.84394928 6178.8390594  5231.83150642], cur_train_grp_loss: [0.45340495 0.52764489 0.34531897], max_reward_err:  0.0397, max_reward_err_index: 0, max_kl_dist:  0.8924, max_kl_dist_index: 1, max_train_grp_loss:  0.5277, max_train_grp_loss_index: 1, max_val_grp_loss:  0.4330, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.5276, max_cur_train_grp_loss_index: 1, 
2024-09-17 14:56:24,550 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  12900, train_loss:  0.0016, val_loss:  0.0004, grad_norm: 0.0327, live_grad: 0.0000, reward_err: 0.0397, 0.0390, 0.0124, KL_dist: 0.8955, 0.8990, 0.7972, param: [8.2045993  7.5148559  6.77292858 7.72350823], weights: [8.57327791e-01 1.42663062e-01 9.14719478e-06], train_wt_loss:  0.5797, val_wt_loss: 0.4331, train_grp_loss: [0.45247227 0.53141229 0.34452775], val_grp_loss: [0.43207907 0.39938806 0.37244166], train_hist_grp_loss: [6411.13567318 6231.80220379 5266.32283714], cur_train_grp_loss: [0.45248024 0.53138107 0.34453499], max_reward_err:  0.0397, max_reward_err_index: 0, max_kl_dist:  0.8990, max_kl_dist_index: 1, max_train_grp_loss:  0.5314, max_train_grp_loss_index: 1, max_val_grp_loss:  0.4321, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.5314, max_cur_train_grp_loss_index: 1, 
2024-09-17 14:56:27,315 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  13000, train_loss:  0.0016, val_loss:  0.0004, grad_norm: 0.0327, live_grad: 0.0000, reward_err: 0.0394, 0.0390, 0.0123, KL_dist: 0.8991, 0.9046, 0.8011, param: [8.2181276  7.5431029  6.78323016 7.75379908], weights: [8.47180946e-01 1.52810940e-01 8.11415111e-06], train_wt_loss:  0.5804, val_wt_loss: 0.4326, train_grp_loss: [0.45180915 0.53388116 0.34386664], val_grp_loss: [0.43140775 0.40102742 0.37181794], train_hist_grp_loss: [6456.34783589 6285.0765525  5300.74183645], cur_train_grp_loss: [0.45181444 0.53386304 0.34387262], max_reward_err:  0.0394, max_reward_err_index: 0, max_kl_dist:  0.9046, max_kl_dist_index: 1, max_train_grp_loss:  0.5339, max_train_grp_loss_index: 1, max_val_grp_loss:  0.4314, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.5339, max_cur_train_grp_loss_index: 1, 
2024-09-17 14:56:30,105 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  13100, train_loss:  0.0016, val_loss:  0.0004, grad_norm: 0.0328, live_grad: 0.0000, reward_err: 0.0394, 0.0390, 0.0123, KL_dist: 0.9031, 0.9091, 0.8051, param: [8.23668049 7.56367796 6.79847767 7.77579073], weights: [8.36130514e-01 1.63862297e-01 7.18846906e-06], train_wt_loss:  0.5814, val_wt_loss: 0.4322, train_grp_loss: [0.45142333 0.53499509 0.34333561], val_grp_loss: [0.43099697 0.40166189 0.37131982], train_hist_grp_loss: [6501.50727663 6338.5314471  5335.1010991 ], cur_train_grp_loss: [0.45142577 0.53499092 0.34334025], max_reward_err:  0.0394, max_reward_err_index: 0, max_kl_dist:  0.9091, max_kl_dist_index: 1, max_train_grp_loss:  0.5350, max_train_grp_loss_index: 1, max_val_grp_loss:  0.4310, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.5350, max_cur_train_grp_loss_index: 1, 
2024-09-17 14:56:32,907 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  13200, train_loss:  0.0016, val_loss:  0.0004, grad_norm: 0.0327, live_grad: 0.0000, reward_err: 0.0394, 0.0390, 0.0123, KL_dist: 0.9076, 0.9124, 0.8090, param: [8.2604944  7.57615591 6.81890161 7.78905189], weights: [8.24351587e-01 1.75642053e-01 6.36024995e-06], train_wt_loss:  0.5825, val_wt_loss: 0.4318, train_grp_loss: [0.45132888 0.53468211 0.34294156], val_grp_loss: [0.43086007 0.40123787 0.37095398], train_hist_grp_loss: [6546.64246184 6392.02756316 5369.4139894 ], cur_train_grp_loss: [0.45132835 0.53469245 0.3429448 ], max_reward_err:  0.0394, max_reward_err_index: 0, max_kl_dist:  0.9124, max_kl_dist_index: 1, max_train_grp_loss:  0.5347, max_train_grp_loss_index: 1, max_val_grp_loss:  0.4309, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.5347, max_cur_train_grp_loss_index: 1, 
2024-09-17 14:56:35,697 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  13300, train_loss:  0.0016, val_loss:  0.0004, grad_norm: 0.0326, live_grad: 0.0000, reward_err: 0.0397, 0.0390, 0.0124, KL_dist: 0.9124, 0.9145, 0.8131, param: [8.28968022 7.58027828 6.84461292 7.79333815], weights: [8.12082507e-01 1.87911872e-01 5.62078792e-06], train_wt_loss:  0.5835, val_wt_loss: 0.4315, train_grp_loss: [0.45153426 0.53290672 0.34268928], val_grp_loss: [0.43100528 0.39972972 0.37072505], train_hist_grp_loss: [6591.78300015 6445.42011431 5403.69446301], cur_train_grp_loss: [0.45153071 0.53293173 0.34269109], max_reward_err:  0.0397, max_reward_err_index: 0, max_kl_dist:  0.9145, max_kl_dist_index: 1, max_train_grp_loss:  0.5329, max_train_grp_loss_index: 1, max_val_grp_loss:  0.4310, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.5329, max_cur_train_grp_loss_index: 1, 
2024-09-17 14:56:38,487 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  13400, train_loss:  0.0016, val_loss:  0.0004, grad_norm: 0.0324, live_grad: 0.0000, reward_err: 0.0401, 0.0386, 0.0126, KL_dist: 0.9177, 0.9154, 0.8172, param: [8.32419509 7.57599617 6.87557563 7.78863754], weights: [7.99622450e-01 2.00372588e-01 4.96231875e-06], train_wt_loss:  0.5845, val_wt_loss: 0.4311, train_grp_loss: [0.45204081 0.52967767 0.34258078], val_grp_loss: [0.4314343  0.39714563 0.37063497], train_hist_grp_loss: [6636.95900631 6498.56289592 5437.95682271], cur_train_grp_loss: [0.45203427 0.52971701 0.34258116], max_reward_err:  0.0401, max_reward_err_index: 0, max_kl_dist:  0.9177, max_kl_dist_index: 0, max_train_grp_loss:  0.5297, max_train_grp_loss_index: 1, max_val_grp_loss:  0.4314, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.5297, max_cur_train_grp_loss_index: 1, 
2024-09-17 14:56:41,264 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  13500, train_loss:  0.0015, val_loss:  0.0004, grad_norm: 0.0322, live_grad: 0.0000, reward_err: 0.0406, 0.0381, 0.0129, KL_dist: 0.9235, 0.9151, 0.8213, param: [8.36382057 7.56350592 6.91158567 7.77520737], weights: [7.87321078e-01 2.12674544e-01 4.37778219e-06], train_wt_loss:  0.5852, val_wt_loss: 0.4306, train_grp_loss: [0.4528415  0.52505359 0.34261462], val_grp_loss: [0.43214109 0.39353168 0.37068234], train_hist_grp_loss: [6682.20032387 6551.31301317 5472.21540639], cur_train_grp_loss: [0.45283208 0.52510641 0.3426136 ], max_reward_err:  0.0406, max_reward_err_index: 0, max_kl_dist:  0.9235, max_kl_dist_index: 0, max_train_grp_loss:  0.5251, max_train_grp_loss_index: 1, max_val_grp_loss:  0.4321, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.5251, max_cur_train_grp_loss_index: 1, 
2024-09-17 14:56:44,078 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  13600, train_loss:  0.0015, val_loss:  0.0004, grad_norm: 0.0319, live_grad: 0.0000, reward_err: 0.0412, 0.0377, 0.0133, KL_dist: 0.9297, 0.9138, 0.8256, param: [8.4081517  7.54327176 6.9522598  7.75359562], weights: [7.75560370e-01 2.24435770e-01 3.86061646e-06], train_wt_loss:  0.5857, val_wt_loss: 0.4300, train_grp_loss: [0.45391997 0.51914517 0.34278536], val_grp_loss: [0.43311098 0.38897323 0.3708619 ], train_hist_grp_loss: [6727.53563654 6603.53601015 5506.48421351], cur_train_grp_loss: [0.45390788 0.51921012 0.342783  ], max_reward_err:  0.0412, max_reward_err_index: 0, max_kl_dist:  0.9297, max_kl_dist_index: 0, max_train_grp_loss:  0.5191, max_train_grp_loss_index: 1, max_val_grp_loss:  0.4331, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.5192, max_cur_train_grp_loss_index: 1, 
2024-09-17 14:56:46,884 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  13700, train_loss:  0.0015, val_loss:  0.0004, grad_norm: 0.0316, live_grad: 0.0000, reward_err: 0.0438, 0.0369, 0.0149, KL_dist: 0.9363, 0.9115, 0.8299, param: [8.45660012 7.51602998 6.99703785 7.72464172], weights: [7.64730281e-01 2.35266314e-01 3.40460235e-06], train_wt_loss:  0.5858, val_wt_loss: 0.4293, train_grp_loss: [0.45525028 0.51211309 0.34308318], val_grp_loss: [0.43432028 0.38359297 0.37116416], train_hist_grp_loss: [6772.99151814 6655.11101077 5540.77648537], cur_train_grp_loss: [0.45523584 0.51218833 0.34307962], max_reward_err:  0.0438, max_reward_err_index: 0, max_kl_dist:  0.9363, max_kl_dist_index: 0, max_train_grp_loss:  0.5121, max_train_grp_loss_index: 1, max_val_grp_loss:  0.4343, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.5122, max_cur_train_grp_loss_index: 1, 
2024-09-17 14:56:49,687 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  13800, train_loss:  0.0015, val_loss:  0.0004, grad_norm: 0.0312, live_grad: 0.0000, reward_err: 0.0438, 0.0353, 0.0149, KL_dist: 0.9432, 0.9085, 0.8343, param: [8.50841241 7.48277225 7.04519952 7.68945425], weights: [7.55201339e-01 2.44795657e-01 3.00376779e-06], train_wt_loss:  0.5855, val_wt_loss: 0.4285, train_grp_loss: [0.4567973  0.50416145 0.34349387], val_grp_loss: [0.43573661 0.3775456  0.37157537], train_hist_grp_loss: [6818.59148672 6705.9354288  5575.10426315], cur_train_grp_loss: [0.45678089 0.50424476 0.34348926], max_reward_err:  0.0438, max_reward_err_index: 0, max_kl_dist:  0.9432, max_kl_dist_index: 0, max_train_grp_loss:  0.5042, max_train_grp_loss_index: 1, max_val_grp_loss:  0.4357, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.5042, max_cur_train_grp_loss_index: 1, 
2024-09-17 14:56:52,471 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  13900, train_loss:  0.0015, val_loss:  0.0004, grad_norm: 0.0307, live_grad: 0.0000, reward_err: 0.0440, 0.0344, 0.0150, KL_dist: 0.9504, 0.9049, 0.8389, param: [8.56270263 7.4447081  7.09589488 7.64936641], weights: [7.47297911e-01 2.52699437e-01 2.65235357e-06], train_wt_loss:  0.5848, val_wt_loss: 0.4276, train_grp_loss: [0.45851783 0.49552737 0.34399901], val_grp_loss: [0.43731987 0.37100955 0.37207775], train_hist_grp_loss: [6864.35513546 6755.92882257 5609.47795446], cur_train_grp_loss: [0.45849993 0.49561626 0.34399356], max_reward_err:  0.0440, max_reward_err_index: 0, max_kl_dist:  0.9504, max_kl_dist_index: 0, max_train_grp_loss:  0.4955, max_train_grp_loss_index: 1, max_val_grp_loss:  0.4373, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4956, max_cur_train_grp_loss_index: 1, 
2024-09-17 14:56:55,302 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  14000, train_loss:  0.0015, val_loss:  0.0004, grad_norm: 0.0303, live_grad: 0.0000, reward_err: 0.0444, 0.0334, 0.0153, KL_dist: 0.9579, 0.9010, 0.8435, param: [8.61849569 7.40321023 7.14818521 7.60587376], weights: [7.41275666e-01 2.58721989e-01 2.34483063e-06], train_wt_loss:  0.5839, val_wt_loss: 0.4267, train_grp_loss: [0.4603624  0.48646782 0.3445766 ], val_grp_loss: [0.4390238  0.36417686 0.37265002], train_hist_grp_loss: [6910.29741    6805.0355607  5643.90594191], cur_train_grp_loss: [0.46034352 0.48655966 0.34457054], max_reward_err:  0.0444, max_reward_err_index: 0, max_kl_dist:  0.9579, max_kl_dist_index: 0, max_train_grp_loss:  0.4865, max_train_grp_loss_index: 1, max_val_grp_loss:  0.4390, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4866, max_cur_train_grp_loss_index: 1, 
2024-09-17 14:56:58,140 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  14100, train_loss:  0.0015, val_loss:  0.0004, grad_norm: 0.0298, live_grad: 0.0000, reward_err: 0.0456, 0.0332, 0.0160, KL_dist: 0.9655, 0.8970, 0.8482, param: [8.67477648 7.35974816 7.20108991 7.56056094], weights: [7.37305757e-01 2.62692167e-01 2.07595174e-06], train_wt_loss:  0.5828, val_wt_loss: 0.4259, train_grp_loss: [0.4622775  0.47724547 0.34520193], val_grp_loss: [0.44079813 0.35724233 0.37326834], train_hist_grp_loss: [6956.42808889 6853.22610958 5678.39426561], cur_train_grp_loss: [0.46225818 0.47733765 0.34519552], max_reward_err:  0.0456, max_reward_err_index: 0, max_kl_dist:  0.9655, max_kl_dist_index: 0, max_train_grp_loss:  0.4772, max_train_grp_loss_index: 1, max_val_grp_loss:  0.4408, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4773, max_cur_train_grp_loss_index: 1, 
2024-09-17 14:57:00,915 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  14200, train_loss:  0.0015, val_loss:  0.0004, grad_norm: 0.0293, live_grad: 0.0000, reward_err: 0.0469, 0.0322, 0.0168, KL_dist: 0.9731, 0.8930, 0.8530, param: [8.73053972 7.31581747 7.25363418 7.51502501], weights: [7.3546685e-01 2.6453131e-01 1.8408175e-06], train_wt_loss:  0.5816, val_wt_loss: 0.4252, train_grp_loss: [0.46420812 0.4681151  0.34584869], val_grp_loss: [0.44259082 0.35039336 0.37390728], train_hist_grp_loss: [7002.75150397 6900.49691898 5712.94640587], cur_train_grp_loss: [0.46418892 0.46820515 0.3458422 ], max_reward_err:  0.0469, max_reward_err_index: 0, max_kl_dist:  0.9731, max_kl_dist_index: 0, max_train_grp_loss:  0.4681, max_train_grp_loss_index: 1, max_val_grp_loss:  0.4426, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4682, max_cur_train_grp_loss_index: 1, 
2024-09-17 14:57:03,746 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  14300, train_loss:  0.0015, val_loss:  0.0004, grad_norm: 0.0288, live_grad: 0.0000, reward_err: 0.0482, 0.0315, 0.0176, KL_dist: 0.9807, 0.8893, 0.8577, param: [8.78483552 7.27287114 7.30489316 7.47080289], weights: [7.35744915e-01 2.64253451e-01 1.63493892e-06], train_wt_loss:  0.5804, val_wt_loss: 0.4247, train_grp_loss: [0.46610022 0.45931192 0.3464902 ], val_grp_loss: [0.44435052 0.3438014  0.37454108], train_hist_grp_loss: [7049.26651384 6946.86903457 5747.56318299], cur_train_grp_loss: [0.46608166 0.45939763 0.34648389], max_reward_err:  0.0482, max_reward_err_index: 0, max_kl_dist:  0.9807, max_kl_dist_index: 0, max_train_grp_loss:  0.4661, max_train_grp_loss_index: 0, max_val_grp_loss:  0.4444, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4661, max_cur_train_grp_loss_index: 0, 
2024-09-17 14:57:06,545 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  14400, train_loss:  0.0015, val_loss:  0.0004, grad_norm: 0.0284, live_grad: 0.0000, reward_err: 0.0482, 0.0311, 0.0176, KL_dist: 0.9881, 0.8860, 0.8624, param: [8.83680725 7.23225869 7.35402887 7.42930847], weights: [7.38039743e-01 2.61958803e-01 1.45428380e-06], train_wt_loss:  0.5794, val_wt_loss: 0.4244, train_grp_loss: [0.46790311 0.45104275 0.3471006 ], val_grp_loss: [0.44602877 0.33761566 0.37514477], train_hist_grp_loss: [7095.96672107 6992.38567842 5782.24278021], cur_train_grp_loss: [0.46788568 0.4511222  0.34709473], max_reward_err:  0.0482, max_reward_err_index: 0, max_kl_dist:  0.9881, max_kl_dist_index: 0, max_train_grp_loss:  0.4679, max_train_grp_loss_index: 0, max_val_grp_loss:  0.4460, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4679, max_cur_train_grp_loss_index: 0, 
2024-09-17 14:57:09,319 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  14500, train_loss:  0.0015, val_loss:  0.0004, grad_norm: 0.0280, live_grad: 0.0000, reward_err: 0.0487, 0.0311, 0.0180, KL_dist: 0.9953, 0.8832, 0.8671, param: [8.88571966 7.19517714 7.40031814 7.39178317], weights: [7.42176728e-01 2.57821977e-01 1.29530019e-06], train_wt_loss:  0.5786, val_wt_loss: 0.4245, train_grp_loss: [0.46957136 0.44348027 0.34765604], val_grp_loss: [0.44758191 0.33195927 0.37569531], train_hist_grp_loss: [7142.84090486 7037.10909903 5816.98088517], cur_train_grp_loss: [0.46955548 0.44355192 0.34765083], max_reward_err:  0.0487, max_reward_err_index: 0, max_kl_dist:  0.9953, max_kl_dist_index: 0, max_train_grp_loss:  0.4696, max_train_grp_loss_index: 0, max_val_grp_loss:  0.4476, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4696, max_cur_train_grp_loss_index: 0, 
2024-09-17 14:57:12,107 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  14600, train_loss:  0.0015, val_loss:  0.0004, grad_norm: 0.0276, live_grad: 0.0000, reward_err: 0.0494, 0.0305, 0.0185, KL_dist: 1.0020, 0.8810, 0.8716, param: [8.9309767  7.16263563 7.44317072 7.35926182], weights: [7.47922288e-01 2.52076557e-01 1.15491580e-06], train_wt_loss:  0.5780, val_wt_loss: 0.4248, train_grp_loss: [0.47106633 0.43676038 0.34813554], val_grp_loss: [0.4489726  0.32692774 0.37617246], train_hist_grp_loss: [7189.87362698 7081.11700286 5851.77093546], cur_train_grp_loss: [0.47105234 0.43682305 0.34813118], max_reward_err:  0.0494, max_reward_err_index: 0, max_kl_dist:  1.0020, max_kl_dist_index: 0, max_train_grp_loss:  0.4711, max_train_grp_loss_index: 0, max_val_grp_loss:  0.4490, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4711, max_cur_train_grp_loss_index: 0, 
2024-09-17 14:57:14,914 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  14700, train_loss:  0.0014, val_loss:  0.0004, grad_norm: 0.0273, live_grad: 0.0000, reward_err: 0.0507, 0.0302, 0.0194, KL_dist: 1.0083, 0.8795, 0.8759, param: [8.97212943 7.1354344  7.48213792 7.33255361], weights: [7.55001362e-01 2.44997608e-01 1.03051604e-06], train_wt_loss:  0.5778, val_wt_loss: 0.4253, train_grp_loss: [0.47235709 0.43098207 0.34852176], val_grp_loss: [0.45017078 0.32258937 0.37655945], train_hist_grp_loss: [7237.04596133 7124.4988506  5886.60444676], cur_train_grp_loss: [0.47234528 0.43103495 0.34851841], max_reward_err:  0.0507, max_reward_err_index: 0, max_kl_dist:  1.0083, max_kl_dist_index: 0, max_train_grp_loss:  0.4724, max_train_grp_loss_index: 0, max_val_grp_loss:  0.4502, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4723, max_cur_train_grp_loss_index: 0, 
2024-09-17 14:57:17,744 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  14800, train_loss:  0.0014, val_loss:  0.0004, grad_norm: 0.0270, live_grad: 0.0000, reward_err: 0.0509, 0.0295, 0.0195, KL_dist: 1.0141, 0.8787, 0.8800, param: [9.00887551 7.11415711 7.51691302 7.31223713], weights: [7.63115475e-01 2.36883605e-01 9.19905502e-07], train_wt_loss:  0.5778, val_wt_loss: 0.4262, train_grp_loss: [0.47342095 0.42620936 0.3488014 ], val_grp_loss: [0.45115419 0.31898702 0.37684345], train_hist_grp_loss: [7284.33629505 7167.35224892 5921.47139785], cur_train_grp_loss: [0.47341149 0.42625198 0.34879917], max_reward_err:  0.0509, max_reward_err_index: 0, max_kl_dist:  1.0141, max_kl_dist_index: 0, max_train_grp_loss:  0.4734, max_train_grp_loss_index: 0, max_val_grp_loss:  0.4512, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4734, max_cur_train_grp_loss_index: 0, 
2024-09-17 14:57:20,600 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  14900, train_loss:  0.0014, val_loss:  0.0004, grad_norm: 0.0268, live_grad: 0.0000, reward_err: 0.0517, 0.0295, 0.0200, KL_dist: 1.0194, 0.8787, 0.8838, param: [9.04105161 7.09917492 7.54732475 7.2986672 ], weights: [7.71960029e-01 2.28039150e-01 8.21258786e-07], train_wt_loss:  0.5780, val_wt_loss: 0.4271, train_grp_loss: [0.47424338 0.42247459 0.34896537], val_grp_loss: [0.45190842 0.31614088 0.37701567], train_hist_grp_loss: [7331.72115146 7209.77960647 5956.3606452 ], cur_train_grp_loss: [0.47423638 0.42250676 0.34896432], max_reward_err:  0.0517, max_reward_err_index: 0, max_kl_dist:  1.0194, max_kl_dist_index: 0, max_train_grp_loss:  0.4742, max_train_grp_loss_index: 0, max_val_grp_loss:  0.4519, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4742, max_cur_train_grp_loss_index: 0, 
2024-09-17 14:57:23,420 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  15000, train_loss:  0.0014, val_loss:  0.0004, grad_norm: 0.0266, live_grad: 0.0000, reward_err: 0.0519, 0.0293, 0.0202, KL_dist: 1.0241, 0.8794, 0.8874, param: [9.06862086 7.09065999 7.57332568 7.29199105], weights: [7.81239620e-01 2.18759646e-01 7.33066174e-07], train_wt_loss:  0.5785, val_wt_loss: 0.4282, train_grp_loss: [0.47481762 0.41978246 0.34900868], val_grp_loss: [0.45242653 0.31405167 0.3770713 ], train_hist_grp_loss: [7379.17599113 7251.88516185 5991.2603414 ], cur_train_grp_loss: [0.47481311 0.41980426 0.34900885], max_reward_err:  0.0519, max_reward_err_index: 0, max_kl_dist:  1.0241, max_kl_dist_index: 0, max_train_grp_loss:  0.4748, max_train_grp_loss_index: 0, max_val_grp_loss:  0.4524, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4748, max_cur_train_grp_loss_index: 0, 
2024-09-17 14:57:26,212 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  15100, train_loss:  0.0014, val_loss:  0.0004, grad_norm: 0.0265, live_grad: 0.0000, reward_err: 0.0521, 0.0293, 0.0204, KL_dist: 1.0282, 0.8808, 0.8908, param: [9.09165686 7.08860586 7.59497715 7.2921711 ], weights: [7.90680479e-01 2.09318867e-01 6.54079098e-07], train_wt_loss:  0.5790, val_wt_loss: 0.4293, train_grp_loss: [0.47514399 0.41811446 0.3489302 ], val_grp_loss: [0.45270843 0.31270394 0.37700924], train_hist_grp_loss: [7426.67595573 7293.77243836 6026.15833476], cur_train_grp_loss: [0.47514194 0.41812618 0.34893158], max_reward_err:  0.0521, max_reward_err_index: 0, max_kl_dist:  1.0282, max_kl_dist_index: 0, max_train_grp_loss:  0.4751, max_train_grp_loss_index: 0, max_val_grp_loss:  0.4527, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4751, max_cur_train_grp_loss_index: 0, 
2024-09-17 14:57:29,049 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  15200, train_loss:  0.0014, val_loss:  0.0004, grad_norm: 0.0265, live_grad: 0.0000, reward_err: 0.0521, 0.0293, 0.0204, KL_dist: 1.0317, 0.8830, 0.8938, param: [9.11032604 7.09285215 7.61243227 7.29901167], weights: [8.00039458e-01 1.99959958e-01 5.83259178e-07], train_wt_loss:  0.5796, val_wt_loss: 0.4305, train_grp_loss: [0.4752289  0.41743319 0.34873221], val_grp_loss: [0.45275998 0.31206933 0.37683169], train_hist_grp_loss: [7474.19652875 7335.5421377  6061.04253265], cur_train_grp_loss: [0.47522922 0.41743528 0.34873476], max_reward_err:  0.0521, max_reward_err_index: 0, max_kl_dist:  1.0317, max_kl_dist_index: 0, max_train_grp_loss:  0.4752, max_train_grp_loss_index: 0, max_val_grp_loss:  0.4528, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4752, max_cur_train_grp_loss_index: 0, 
2024-09-17 14:57:31,892 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  15300, train_loss:  0.0014, val_loss:  0.0004, grad_norm: 0.0265, live_grad: 0.0000, reward_err: 0.0521, 0.0293, 0.0204, KL_dist: 1.0347, 0.8858, 0.8966, param: [9.12486961 7.1031112  7.62591849 7.31218722], weights: [8.09109409e-01 1.90890071e-01 5.19733352e-07], train_wt_loss:  0.5802, val_wt_loss: 0.4315, train_grp_loss: [0.47508389 0.4176864  0.34841984], val_grp_loss: [0.452592   0.31210939 0.37654361], train_hist_grp_loss: [7521.71409745 7377.29045441 6095.90121642], cur_train_grp_loss: [0.47508643 0.41767945 0.34842351], max_reward_err:  0.0521, max_reward_err_index: 0, max_kl_dist:  1.0347, max_kl_dist_index: 0, max_train_grp_loss:  0.4751, max_train_grp_loss_index: 0, max_val_grp_loss:  0.4526, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4751, max_cur_train_grp_loss_index: 0, 
2024-09-17 14:57:34,692 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  15400, train_loss:  0.0014, val_loss:  0.0004, grad_norm: 0.0265, live_grad: 0.0000, reward_err: 0.0520, 0.0293, 0.0202, KL_dist: 1.0373, 0.8892, 0.8992, param: [9.13558628 7.11899469 7.63572066 7.33127022], weights: [8.17721166e-01 1.82278371e-01 4.62756447e-07], train_wt_loss:  0.5807, val_wt_loss: 0.4324, train_grp_loss: [0.4747245  0.41881057 0.34800057], val_grp_loss: [0.45221924 0.31277813 0.3761522 ], train_hist_grp_loss: [7569.20640946 7419.10777215 6130.72330137], cur_train_grp_loss: [0.4747291  0.41879524 0.34800526], max_reward_err:  0.0520, max_reward_err_index: 0, max_kl_dist:  1.0373, max_kl_dist_index: 0, max_train_grp_loss:  0.4747, max_train_grp_loss_index: 0, max_val_grp_loss:  0.4522, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4747, max_cur_train_grp_loss_index: 0, 
2024-09-17 14:57:37,492 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  15500, train_loss:  0.0014, val_loss:  0.0004, grad_norm: 0.0266, live_grad: 0.0000, reward_err: 0.0517, 0.0293, 0.0200, KL_dist: 1.0394, 0.8931, 0.9016, param: [9.14281665 7.14003856 7.64216562 7.35575693], weights: [8.25742656e-01 1.74256932e-01 4.11681453e-07], train_wt_loss:  0.5811, val_wt_loss: 0.4332, train_grp_loss: [0.47416931 0.42073392 0.3474836 ], val_grp_loss: [0.45165943 0.3140241  0.37566637], train_hist_grp_loss: [7616.65292533 7461.07769125 6165.49854027], cur_train_grp_loss: [0.47417576 0.42071098 0.34748922], max_reward_err:  0.0517, max_reward_err_index: 0, max_kl_dist:  1.0394, max_kl_dist_index: 0, max_train_grp_loss:  0.4742, max_train_grp_loss_index: 0, max_val_grp_loss:  0.4517, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4742, max_cur_train_grp_loss_index: 0, 
2024-09-17 14:57:40,292 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  15600, train_loss:  0.0014, val_loss:  0.0004, grad_norm: 0.0267, live_grad: 0.0000, reward_err: 0.0517, 0.0295, 0.0200, KL_dist: 1.0411, 0.8976, 0.9039, param: [9.1469295  7.16572522 7.64560868 7.38509021], weights: [8.33075857e-01 1.66923777e-01 3.65937021e-07], train_wt_loss:  0.5814, val_wt_loss: 0.4339, train_grp_loss: [0.47343899 0.42337894 0.34687939], val_grp_loss: [0.45093236 0.31579201 0.37509621], train_hist_grp_loss: [7664.0350744  7503.27633262 6200.2176729 ], cur_train_grp_loss: [0.47344709 0.42334918 0.34688583], max_reward_err:  0.0517, max_reward_err_index: 0, max_kl_dist:  1.0411, max_kl_dist_index: 0, max_train_grp_loss:  0.4734, max_train_grp_loss_index: 0, max_val_grp_loss:  0.4509, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4734, max_cur_train_grp_loss_index: 0, 
2024-09-17 14:57:43,103 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  15700, train_loss:  0.0014, val_loss:  0.0004, grad_norm: 0.0269, live_grad: 0.0000, reward_err: 0.0509, 0.0295, 0.0195, KL_dist: 1.0425, 0.9026, 0.9059, param: [9.14831053 7.19550243 7.64642241 7.41867879], weights: [8.39652341e-01 1.60347334e-01 3.25011153e-07], train_wt_loss:  0.5815, val_wt_loss: 0.4343, train_grp_loss: [0.47255556 0.42666431 0.34619918], val_grp_loss: [0.45005913 0.31802406 0.37445257], train_hist_grp_loss: [7711.33642564 7545.77186283 6234.87252692], cur_train_grp_loss: [0.47256508 0.42662856 0.34620633], max_reward_err:  0.0509, max_reward_err_index: 0, max_kl_dist:  1.0425, max_kl_dist_index: 0, max_train_grp_loss:  0.4726, max_train_grp_loss_index: 0, max_val_grp_loss:  0.4501, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4726, max_cur_train_grp_loss_index: 0, 
2024-09-17 14:57:45,916 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  15800, train_loss:  0.0014, val_loss:  0.0004, grad_norm: 0.0271, live_grad: 0.0000, reward_err: 0.0509, 0.0295, 0.0195, KL_dist: 1.0436, 0.9079, 0.9079, param: [9.1473534  7.22879849 7.64498768 7.45591268], weights: [8.45428145e-01 1.54571567e-01 2.88439869e-07], train_wt_loss:  0.5815, val_wt_loss: 0.4346, train_grp_loss: [0.4715417  0.43050636 0.34545463], val_grp_loss: [0.44906151 0.32066078 0.37374671], train_hist_grp_loss: [7758.54278701 7588.62418942 6269.45607707], cur_train_grp_loss: [0.47155241 0.43046546 0.34546235], max_reward_err:  0.0509, max_reward_err_index: 0, max_kl_dist:  1.0436, max_kl_dist_index: 0, max_train_grp_loss:  0.4715, max_train_grp_loss_index: 0, max_val_grp_loss:  0.4491, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4716, max_cur_train_grp_loss_index: 0, 
2024-09-17 14:57:48,726 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  15900, train_loss:  0.0014, val_loss:  0.0004, grad_norm: 0.0273, live_grad: 0.0000, reward_err: 0.0507, 0.0299, 0.0194, KL_dist: 1.0445, 0.9137, 0.9098, param: [9.144453   7.26503404 7.64168689 7.49617499], weights: [8.50378524e-01 1.49621221e-01 2.55799608e-07], train_wt_loss:  0.5814, val_wt_loss: 0.4347, train_grp_loss: [0.47042028 0.4348201  0.34465748], val_grp_loss: [0.44796143 0.32364176 0.37298996], train_hist_grp_loss: [7805.64224779 7631.884781   6303.96247061], cur_train_grp_loss: [0.47043195 0.43477491 0.34466568], max_reward_err:  0.0507, max_reward_err_index: 0, max_kl_dist:  1.0445, max_kl_dist_index: 0, max_train_grp_loss:  0.4704, max_train_grp_loss_index: 0, max_val_grp_loss:  0.4480, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4704, max_cur_train_grp_loss_index: 0, 
2024-09-17 14:57:51,519 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  16000, train_loss:  0.0015, val_loss:  0.0004, grad_norm: 0.0275, live_grad: 0.0000, reward_err: 0.0498, 0.0305, 0.0188, KL_dist: 1.0452, 0.9197, 0.9117, param: [9.14000069 7.30363057 7.63689917 7.53885051], weights: [8.54493045e-01 1.45506728e-01 2.26702234e-07], train_wt_loss:  0.5811, val_wt_loss: 0.4346, train_grp_loss: [0.46921398 0.43951996 0.34381939], val_grp_loss: [0.44678066 0.32690602 0.37219359], train_hist_grp_loss: [7852.62517766 7675.59657413 6338.38702656], cur_train_grp_loss: [0.46922639 0.43947133 0.34382794], max_reward_err:  0.0498, max_reward_err_index: 0, max_kl_dist:  1.0452, max_kl_dist_index: 0, max_train_grp_loss:  0.4692, max_train_grp_loss_index: 0, max_val_grp_loss:  0.4468, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4692, max_cur_train_grp_loss_index: 0, 
2024-09-17 14:57:54,318 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  16100, train_loss:  0.0015, val_loss:  0.0004, grad_norm: 0.0277, live_grad: 0.0000, reward_err: 0.0491, 0.0305, 0.0182, KL_dist: 1.0458, 0.9260, 0.9135, param: [9.13438109 7.34401627 7.63099715 7.58333145], weights: [8.57771299e-01 1.42228501e-01 2.00791746e-07], train_wt_loss:  0.5808, val_wt_loss: 0.4344, train_grp_loss: [0.46794506 0.44452019 0.34295172], val_grp_loss: [0.4455405  0.33039224 0.37136855], train_hist_grp_loss: [7899.48419489 7719.7939361  6372.72621589], cur_train_grp_loss: [0.46795799 0.44446898 0.34296051], max_reward_err:  0.0491, max_reward_err_index: 0, max_kl_dist:  1.0458, max_kl_dist_index: 0, max_train_grp_loss:  0.4679, max_train_grp_loss_index: 0, max_val_grp_loss:  0.4455, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4680, max_cur_train_grp_loss_index: 0, 
2024-09-17 14:57:57,116 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  16200, train_loss:  0.0015, val_loss:  0.0004, grad_norm: 0.0280, live_grad: 0.0000, reward_err: 0.0482, 0.0311, 0.0176, KL_dist: 1.0464, 0.9324, 0.9153, param: [9.12797031 7.38562967 7.62434506 7.62902101], weights: [8.60219381e-01 1.39780441e-01 1.77742017e-07], train_wt_loss:  0.5803, val_wt_loss: 0.4341, train_grp_loss: [0.46663516 0.44973509 0.34206547], val_grp_loss: [0.44426169 0.33403893 0.37052548], train_hist_grp_loss: [7946.21411403 7764.50266058 6406.97762885], cur_train_grp_loss: [0.4666484  0.44968216 0.34207439], max_reward_err:  0.0482, max_reward_err_index: 0, max_kl_dist:  1.0464, max_kl_dist_index: 0, max_train_grp_loss:  0.4666, max_train_grp_loss_index: 0, max_val_grp_loss:  0.4443, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4666, max_cur_train_grp_loss_index: 0, 
2024-09-17 14:57:59,931 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  16300, train_loss:  0.0015, val_loss:  0.0004, grad_norm: 0.0282, live_grad: 0.0000, reward_err: 0.0482, 0.0311, 0.0176, KL_dist: 1.0470, 0.9390, 0.9172, param: [9.12113496 7.42792159 7.61729782 7.67533525], weights: [8.61847224e-01 1.38152619e-01 1.57255065e-07], train_wt_loss:  0.5799, val_wt_loss: 0.4337, train_grp_loss: [0.46530526 0.45507915 0.34117121], val_grp_loss: [0.44296425 0.33778444 0.36967456], train_hist_grp_loss: [7992.81188135 7809.73998029 6441.13993419], cur_train_grp_loss: [0.46531859 0.45502535 0.34118016], max_reward_err:  0.0482, max_reward_err_index: 0, max_kl_dist:  1.0470, max_kl_dist_index: 0, max_train_grp_loss:  0.4653, max_train_grp_loss_index: 0, max_val_grp_loss:  0.4430, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4653, max_cur_train_grp_loss_index: 0, 
2024-09-17 14:58:02,726 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  16400, train_loss:  0.0015, val_loss:  0.0004, grad_norm: 0.0285, live_grad: 0.0000, reward_err: 0.0482, 0.0311, 0.0176, KL_dist: 1.0476, 0.9456, 0.9191, param: [9.11423182 7.470356   7.61020059 7.72170392], weights: [8.62666767e-01 1.37333094e-01 1.39059562e-07], train_wt_loss:  0.5794, val_wt_loss: 0.4332, train_grp_loss: [0.46397559 0.4604671  0.34027904], val_grp_loss: [0.44166749 0.34156697 0.36882556], train_hist_grp_loss: [8039.27650424 7855.51458794 6475.21283444], cur_train_grp_loss: [0.46398882 0.46041328 0.34028792], max_reward_err:  0.0482, max_reward_err_index: 0, max_kl_dist:  1.0476, max_kl_dist_index: 0, max_train_grp_loss:  0.4640, max_train_grp_loss_index: 0, max_val_grp_loss:  0.4417, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4640, max_cur_train_grp_loss_index: 0, 
2024-09-17 14:58:05,506 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  16500, train_loss:  0.0015, val_loss:  0.0004, grad_norm: 0.0287, live_grad: 0.0000, reward_err: 0.0482, 0.0318, 0.0176, KL_dist: 1.0483, 0.9522, 0.9210, param: [9.10760776 7.51241036 7.60338872 7.76757077], weights: [8.62690946e-01 1.37308931e-01 1.22909398e-07], train_wt_loss:  0.5789, val_wt_loss: 0.4326, train_grp_loss: [0.46266567 0.46581397 0.33939859], val_grp_loss: [0.44038999 0.34532471 0.36798777], train_hist_grp_loss: [8085.6089784  7901.82666344 6509.19701951], cur_train_grp_loss: [0.46267861 0.46576099 0.33940731], max_reward_err:  0.0482, max_reward_err_index: 0, max_kl_dist:  1.0483, max_kl_dist_index: 0, max_train_grp_loss:  0.4658, max_train_grp_loss_index: 1, max_val_grp_loss:  0.4404, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4658, max_cur_train_grp_loss_index: 1, 
2024-09-17 14:58:08,310 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  16600, train_loss:  0.0015, val_loss:  0.0004, grad_norm: 0.0290, live_grad: 0.0000, reward_err: 0.0477, 0.0318, 0.0173, KL_dist: 1.0491, 0.9588, 0.9230, param: [9.10159955 7.55357576 7.5971876  7.81239378], weights: [8.61933449e-01 1.38066442e-01 1.08582220e-07], train_wt_loss:  0.5784, val_wt_loss: 0.4320, train_grp_loss: [0.46139429 0.47103528 0.33853906], val_grp_loss: [0.43914961 0.34899588 0.36717007], train_hist_grp_loss: [8131.81221481 7948.66791206 6543.09412059], cur_train_grp_loss: [0.46140675 0.47098396 0.33854752], max_reward_err:  0.0477, max_reward_err_index: 0, max_kl_dist:  1.0491, max_kl_dist_index: 0, max_train_grp_loss:  0.4710, max_train_grp_loss_index: 1, max_val_grp_loss:  0.4391, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4710, max_cur_train_grp_loss_index: 1, 
2024-09-17 14:58:11,113 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  16700, train_loss:  0.0015, val_loss:  0.0004, grad_norm: 0.0292, live_grad: 0.0000, reward_err: 0.0469, 0.0322, 0.0168, KL_dist: 1.0500, 0.9652, 0.9251, param: [9.09653341 7.5933575  7.59191224 7.85564593], weights: [8.60409192e-01 1.39590712e-01 9.58779106e-08], train_wt_loss:  0.5780, val_wt_loss: 0.4314, train_grp_loss: [0.4601795  0.47604729 0.33770917], val_grp_loss: [0.43796345 0.352519   0.36638088], train_hist_grp_loss: [8177.89096677 7996.02162455 6576.90666472], cur_train_grp_loss: [0.46019131 0.47599848 0.33771729], max_reward_err:  0.0469, max_reward_err_index: 0, max_kl_dist:  1.0500, max_kl_dist_index: 0, max_train_grp_loss:  0.4760, max_train_grp_loss_index: 1, max_val_grp_loss:  0.4380, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4760, max_cur_train_grp_loss_index: 1, 
2024-09-17 14:58:13,904 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  16800, train_loss:  0.0015, val_loss:  0.0004, grad_norm: 0.0294, live_grad: 0.0000, reward_err: 0.0460, 0.0328, 0.0162, KL_dist: 1.0511, 0.9714, 0.9273, param: [9.09272379 7.63127641 7.58786621 7.89681681], weights: [8.58135446e-01 1.41864470e-01 8.46170053e-08], train_wt_loss:  0.5777, val_wt_loss: 0.4307, train_grp_loss: [0.45903857 0.48076755 0.3369172 ], val_grp_loss: [0.43684789 0.35583332 0.3656282 ], train_hist_grp_loss: [8223.85175523 8043.86277664 6610.63802998], cur_train_grp_loss: [0.45904956 0.48072206 0.33692491], max_reward_err:  0.0460, max_reward_err_index: 0, max_kl_dist:  1.0511, max_kl_dist_index: 0, max_train_grp_loss:  0.4808, max_train_grp_loss_index: 1, max_val_grp_loss:  0.4368, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4807, max_cur_train_grp_loss_index: 1, 
2024-09-17 14:58:16,697 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  16900, train_loss:  0.0015, val_loss:  0.0004, grad_norm: 0.0296, live_grad: 0.0000, reward_err: 0.0456, 0.0332, 0.0160, KL_dist: 1.0524, 0.9773, 0.9295, param: [9.09047146 7.66687135 7.58533976 7.93541556], weights: [8.55133562e-01 1.44866363e-01 7.46390877e-08], train_wt_loss:  0.5774, val_wt_loss: 0.4301, train_grp_loss: [0.45798798 0.48511563 0.33617099], val_grp_loss: [0.43581849 0.35887936 0.36491959], train_hist_grp_loss: [8269.70278953 8092.15819099 6644.2924002 ], cur_train_grp_loss: [0.45799799 0.48507425 0.3361782 ], max_reward_err:  0.0456, max_reward_err_index: 0, max_kl_dist:  1.0524, max_kl_dist_index: 0, max_train_grp_loss:  0.4851, max_train_grp_loss_index: 1, max_val_grp_loss:  0.4358, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4851, max_cur_train_grp_loss_index: 1, 
2024-09-17 14:58:19,506 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  17000, train_loss:  0.0015, val_loss:  0.0004, grad_norm: 0.0298, live_grad: 0.0000, reward_err: 0.0456, 0.0332, 0.0160, KL_dist: 1.0540, 0.9829, 0.9318, param: [9.09006038 7.69970321 7.58460704 7.9709755 ], weights: [8.51431187e-01 1.48568747e-01 6.58011704e-08], train_wt_loss:  0.5772, val_wt_loss: 0.4295, train_grp_loss: [0.45704323 0.48901419 0.33547785], val_grp_loss: [0.43488988 0.36159983 0.36426213], train_hist_grp_loss: [8315.45387906 8140.86679018 6677.8747175 ], cur_train_grp_loss: [0.45705211 0.48897768 0.3354845 ], max_reward_err:  0.0456, max_reward_err_index: 0, max_kl_dist:  1.0540, max_kl_dist_index: 0, max_train_grp_loss:  0.4890, max_train_grp_loss_index: 1, max_val_grp_loss:  0.4349, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4890, max_cur_train_grp_loss_index: 1, 
2024-09-17 14:58:22,304 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  17100, train_loss:  0.0015, val_loss:  0.0004, grad_norm: 0.0299, live_grad: 0.0000, reward_err: 0.0456, 0.0332, 0.0160, KL_dist: 1.0557, 0.9881, 0.9343, param: [9.09175345 7.7293606  7.58592196 8.00306055], weights: [8.47064839e-01 1.52935103e-01 5.79760968e-08], train_wt_loss:  0.5772, val_wt_loss: 0.4289, train_grp_loss: [0.45621871 0.49239041 0.33484458], val_grp_loss: [0.43407566 0.36394064 0.36366237], train_hist_grp_loss: [8361.11633033 8189.939973   6711.39063041], cur_train_grp_loss: [0.45622632 0.49235945 0.3348506 ], max_reward_err:  0.0456, max_reward_err_index: 0, max_kl_dist:  1.0557, max_kl_dist_index: 0, max_train_grp_loss:  0.4924, max_train_grp_loss_index: 1, max_val_grp_loss:  0.4341, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4924, max_cur_train_grp_loss_index: 1, 
2024-09-17 14:58:25,090 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  17200, train_loss:  0.0015, val_loss:  0.0004, grad_norm: 0.0300, live_grad: 0.0000, reward_err: 0.0456, 0.0334, 0.0160, KL_dist: 1.0577, 0.9928, 0.9367, param: [9.09578699 7.75546743 7.58951309 8.03127379], weights: [8.42082657e-01 1.57917291e-01 5.10509856e-08], train_wt_loss:  0.5772, val_wt_loss: 0.4284, train_grp_loss: [0.45552744 0.49517768 0.33427731], val_grp_loss: [0.4333881  0.36585228 0.36312625], train_hist_grp_loss: [8406.70282338 8239.32214805 6744.84643485], cur_train_grp_loss: [0.45553366 0.49515292 0.33428264], max_reward_err:  0.0456, max_reward_err_index: 0, max_kl_dist:  1.0577, max_kl_dist_index: 0, max_train_grp_loss:  0.4952, max_train_grp_loss_index: 1, max_val_grp_loss:  0.4334, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4952, max_cur_train_grp_loss_index: 1, 
2024-09-17 14:58:27,925 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  17300, train_loss:  0.0015, val_loss:  0.0004, grad_norm: 0.0301, live_grad: 0.0000, reward_err: 0.0452, 0.0334, 0.0157, KL_dist: 1.0599, 0.9970, 0.9393, param: [9.10236405 7.77769226 7.5955772  8.05526778], weights: [8.36547074e-01 1.63452881e-01 4.49257350e-08], train_wt_loss:  0.5774, val_wt_loss: 0.4278, train_grp_loss: [0.45498078 0.49731772 0.33378144], val_grp_loss: [0.43283793 0.36729142 0.36265897], train_hist_grp_loss: [8452.22726081 8288.95145769 6778.24900498], cur_train_grp_loss: [0.4549855  0.49729969 0.33378603], max_reward_err:  0.0452, max_reward_err_index: 0, max_kl_dist:  1.0599, max_kl_dist_index: 0, max_train_grp_loss:  0.4973, max_train_grp_loss_index: 1, max_val_grp_loss:  0.4328, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4973, max_cur_train_grp_loss_index: 1, 
2024-09-17 14:58:30,719 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  17400, train_loss:  0.0015, val_loss:  0.0004, grad_norm: 0.0302, live_grad: 0.0000, reward_err: 0.0452, 0.0334, 0.0157, KL_dist: 1.0625, 1.0007, 0.9420, param: [9.11164675 7.7957592  7.60427207 8.07475659], weights: [8.30537076e-01 1.69462884e-01 3.95116040e-08], train_wt_loss:  0.5776, val_wt_loss: 0.4274, train_grp_loss: [0.45458806 0.49876283 0.33336145], val_grp_loss: [0.43243399 0.3682226  0.36226489], train_hist_grp_loss: [8497.7045837  8338.76071957 6811.60571092], cur_train_grp_loss: [0.4545912  0.49875195 0.33336526], max_reward_err:  0.0452, max_reward_err_index: 0, max_kl_dist:  1.0625, max_kl_dist_index: 0, max_train_grp_loss:  0.4988, max_train_grp_loss_index: 1, max_val_grp_loss:  0.4324, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4988, max_cur_train_grp_loss_index: 1, 
2024-09-17 14:58:33,512 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  17500, train_loss:  0.0015, val_loss:  0.0004, grad_norm: 0.0302, live_grad: 0.0000, reward_err: 0.0452, 0.0334, 0.0157, KL_dist: 1.0653, 1.0038, 0.9447, param: [9.12374818 7.8094598  7.61570869 8.08952873], weights: [8.24149720e-01 1.75850245e-01 3.47298826e-08], train_wt_loss:  0.5779, val_wt_loss: 0.4269, train_grp_loss: [0.45435617 0.49947828 0.33302078], val_grp_loss: [0.43218283 0.36862007 0.36194732], train_hist_grp_loss: [8543.15054918 8388.67860316 6844.9243207 ], cur_train_grp_loss: [0.45435768 0.49947481 0.33302378], max_reward_err:  0.0452, max_reward_err_index: 0, max_kl_dist:  1.0653, max_kl_dist_index: 0, max_train_grp_loss:  0.4995, max_train_grp_loss_index: 1, max_val_grp_loss:  0.4322, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4995, max_cur_train_grp_loss_index: 1, 
2024-09-17 14:58:36,300 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  17600, train_loss:  0.0015, val_loss:  0.0004, grad_norm: 0.0302, live_grad: 0.0000, reward_err: 0.0452, 0.0334, 0.0157, KL_dist: 1.0683, 1.0063, 0.9475, param: [9.1387243  7.81866521 7.62994351 8.0994603 ], weights: [8.17500499e-01 1.82499470e-01 3.05106635e-08], train_wt_loss:  0.5782, val_wt_loss: 0.4265, train_grp_loss: [0.45428918 0.49944461 0.33276159], val_grp_loss: [0.43208834 0.36846953 0.36170836], train_hist_grp_loss: [8588.58146723 8438.63104306 6878.2128845 ], cur_train_grp_loss: [0.45428902 0.49944868 0.33276378], max_reward_err:  0.0452, max_reward_err_index: 0, max_kl_dist:  1.0683, max_kl_dist_index: 0, max_train_grp_loss:  0.4994, max_train_grp_loss_index: 1, max_val_grp_loss:  0.4321, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4994, max_cur_train_grp_loss_index: 1, 
2024-09-17 14:58:39,093 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  17700, train_loss:  0.0015, val_loss:  0.0004, grad_norm: 0.0301, live_grad: 0.0000, reward_err: 0.0452, 0.0334, 0.0157, KL_dist: 1.0717, 1.0082, 0.9504, param: [9.15656671 7.82333754 7.6469715  8.10452694], weights: [8.10722267e-01 1.89277706e-01 2.67917266e-08], train_wt_loss:  0.5785, val_wt_loss: 0.4260, train_grp_loss: [0.4543879  0.4986597  0.33258463], val_grp_loss: [0.43215141 0.36776961 0.36154872], train_hist_grp_loss: [8634.01389662 8488.54287101 6911.47960025], cur_train_grp_loss: [0.4543861  0.49867123 0.332586  ], max_reward_err:  0.0452, max_reward_err_index: 0, max_kl_dist:  1.0717, max_kl_dist_index: 0, max_train_grp_loss:  0.4987, max_train_grp_loss_index: 1, max_val_grp_loss:  0.4322, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4987, max_cur_train_grp_loss_index: 1, 
2024-09-17 14:58:41,897 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  17800, train_loss:  0.0015, val_loss:  0.0004, grad_norm: 0.0300, live_grad: 0.0000, reward_err: 0.0456, 0.0334, 0.0160, KL_dist: 1.0753, 1.0095, 0.9533, param: [9.17719714 7.82353923 7.6667207  8.10481359], weights: [8.03962502e-01 1.96037475e-01 2.35175454e-08], train_wt_loss:  0.5787, val_wt_loss: 0.4256, train_grp_loss: [0.4546496  0.49714018 0.33248903], val_grp_loss: [0.43236955 0.36653298 0.36146758], train_hist_grp_loss: [8679.46430415 8538.33962528 6944.73266127], cur_train_grp_loss: [0.45464619 0.49715891 0.33248959], max_reward_err:  0.0456, max_reward_err_index: 0, max_kl_dist:  1.0753, max_kl_dist_index: 0, max_train_grp_loss:  0.4971, max_train_grp_loss_index: 1, max_val_grp_loss:  0.4324, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4972, max_cur_train_grp_loss_index: 1, 
2024-09-17 14:58:44,698 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  17900, train_loss:  0.0015, val_loss:  0.0004, grad_norm: 0.0299, live_grad: 0.0000, reward_err: 0.0456, 0.0334, 0.0160, KL_dist: 1.0792, 1.0102, 0.9563, param: [9.20046436 7.81943931 7.68904921 8.10052055], weights: [7.97378881e-01 2.02621099e-01 2.06384211e-08], train_wt_loss:  0.5789, val_wt_loss: 0.4252, train_grp_loss: [0.45506772 0.49492224 0.33247216], val_grp_loss: [0.43273672 0.36478682 0.36146241], train_hist_grp_loss: [8724.94869522 8587.94947279 6977.98008844], cur_train_grp_loss: [0.4550628  0.49494771 0.33247195], max_reward_err:  0.0456, max_reward_err_index: 0, max_kl_dist:  1.0792, max_kl_dist_index: 0, max_train_grp_loss:  0.4949, max_train_grp_loss_index: 1, max_val_grp_loss:  0.4327, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4949, max_cur_train_grp_loss_index: 1, 
2024-09-17 14:58:47,497 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  18000, train_loss:  0.0015, val_loss:  0.0004, grad_norm: 0.0297, live_grad: 0.0000, reward_err: 0.0456, 0.0332, 0.0160, KL_dist: 1.0833, 1.0104, 0.9594, param: [9.22614436 7.81131535 7.71374515 8.09196472], weights: [7.91133363e-01 2.08866618e-01 1.81097478e-08], train_wt_loss:  0.5791, val_wt_loss: 0.4248, train_grp_loss: [0.45563183 0.49206132 0.33252959], val_grp_loss: [0.4332432  0.36257261 0.36152893], train_hist_grp_loss: [8770.48222797 8637.30515842 7011.22955133], cur_train_grp_loss: [0.45562551 0.49209288 0.33252867], max_reward_err:  0.0456, max_reward_err_index: 0, max_kl_dist:  1.0833, max_kl_dist_index: 0, max_train_grp_loss:  0.4921, max_train_grp_loss_index: 1, max_val_grp_loss:  0.4332, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4921, max_cur_train_grp_loss_index: 1, 
2024-09-17 14:58:50,296 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  18100, train_loss:  0.0015, val_loss:  0.0004, grad_norm: 0.0296, live_grad: 0.0000, reward_err: 0.0460, 0.0332, 0.0162, KL_dist: 1.0876, 1.0102, 0.9625, param: [9.25394416 7.79955038 7.74053007 8.07957536], weights: [7.85385178e-01 2.14614806e-01 1.58914051e-08], train_wt_loss:  0.5791, val_wt_loss: 0.4244, train_grp_loss: [0.45632768 0.48863096 0.33265505], val_grp_loss: [0.43387564 0.35994514 0.36166108], train_hist_grp_loss: [8816.078827   8686.34588236 7044.48818447], cur_train_grp_loss: [0.45632013 0.4886678  0.33265348], max_reward_err:  0.0460, max_reward_err_index: 0, max_kl_dist:  1.0876, max_kl_dist_index: 0, max_train_grp_loss:  0.4886, max_train_grp_loss_index: 1, max_val_grp_loss:  0.4339, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4887, max_cur_train_grp_loss_index: 1, 
2024-09-17 14:58:53,086 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  18200, train_loss:  0.0015, val_loss:  0.0004, grad_norm: 0.0294, live_grad: 0.0000, reward_err: 0.0469, 0.0324, 0.0168, KL_dist: 1.0921, 1.0096, 0.9656, param: [9.28350937 7.78462443 7.76906604 8.0638839 ], weights: [7.80283300e-01 2.19716686e-01 1.39472665e-08], train_wt_loss:  0.5790, val_wt_loss: 0.4240, train_grp_loss: [0.45713751 0.48472046 0.3328405 ], val_grp_loss: [0.43461735 0.3569707  0.36185111], train_hist_grp_loss: [8861.7508147  8735.01900138 7077.76240686], cur_train_grp_loss: [0.45712891 0.48476162 0.33283837], max_reward_err:  0.0469, max_reward_err_index: 0, max_kl_dist:  1.0921, max_kl_dist_index: 0, max_train_grp_loss:  0.4847, max_train_grp_loss_index: 1, max_val_grp_loss:  0.4346, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4848, max_cur_train_grp_loss_index: 1, 
2024-09-17 14:58:55,878 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  18300, train_loss:  0.0015, val_loss:  0.0004, grad_norm: 0.0291, live_grad: 0.0000, reward_err: 0.0473, 0.0318, 0.0170, KL_dist: 1.0968, 1.0086, 0.9688, param: [9.31443514 7.76710086 7.79896593 8.04550828], weights: [7.75959097e-01 2.24040891e-01 1.22448092e-08], train_wt_loss:  0.5788, val_wt_loss: 0.4236, train_grp_loss: [0.45804046 0.48043175 0.33307631], val_grp_loss: [0.43544869 0.35372467 0.36208973], train_hist_grp_loss: [8907.50857948 8783.28145678 7111.05775326], cur_train_grp_loss: [0.45803104 0.48047615 0.33307373], max_reward_err:  0.0473, max_reward_err_index: 0, max_kl_dist:  1.0968, max_kl_dist_index: 0, max_train_grp_loss:  0.4804, max_train_grp_loss_index: 1, max_val_grp_loss:  0.4354, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4805, max_cur_train_grp_loss_index: 1, 
2024-09-17 14:58:58,684 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  18400, train_loss:  0.0015, val_loss:  0.0004, grad_norm: 0.0289, live_grad: 0.0000, reward_err: 0.0477, 0.0318, 0.0173, KL_dist: 1.1015, 1.0074, 0.9721, param: [9.34628005 7.74760814 7.82980645 8.02513254], weights: [7.72519802e-01 2.27480187e-01 1.07548033e-08], train_wt_loss:  0.5786, val_wt_loss: 0.4232, train_grp_loss: [0.45901325 0.47587548 0.3333515 ], val_grp_loss: [0.43634764 0.35028859 0.36236632], train_hist_grp_loss: [8953.36029872 8831.10084918 7144.37872653], cur_train_grp_loss: [0.45900326 0.47592199 0.3333486 ], max_reward_err:  0.0477, max_reward_err_index: 0, max_kl_dist:  1.1015, max_kl_dist_index: 0, max_train_grp_loss:  0.4759, max_train_grp_loss_index: 1, max_val_grp_loss:  0.4363, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4759, max_cur_train_grp_loss_index: 1, 
2024-09-17 14:59:01,475 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  18500, train_loss:  0.0015, val_loss:  0.0004, grad_norm: 0.0287, live_grad: 0.0000, reward_err: 0.0482, 0.0315, 0.0176, KL_dist: 1.1064, 1.0061, 0.9753, param: [9.37858166 7.72681832 7.8611431  8.00348306], weights: [7.70043388e-01 2.29956602e-01 9.45105991e-09], train_wt_loss:  0.5782, val_wt_loss: 0.4229, train_grp_loss: [0.46003093 0.47116686 0.33365411], val_grp_loss: [0.43729052 0.34674697 0.36266934], train_hist_grp_loss: [8999.31173184 8878.45610619 7177.72867933], cur_train_grp_loss: [0.46002062 0.47121432 0.33365099], max_reward_err:  0.0482, max_reward_err_index: 0, max_kl_dist:  1.1064, max_kl_dist_index: 0, max_train_grp_loss:  0.4712, max_train_grp_loss_index: 1, max_val_grp_loss:  0.4373, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4712, max_cur_train_grp_loss_index: 1, 
2024-09-17 14:59:04,265 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  18600, train_loss:  0.0015, val_loss:  0.0004, grad_norm: 0.0284, live_grad: 0.0000, reward_err: 0.0482, 0.0311, 0.0176, KL_dist: 1.1112, 1.0047, 0.9786, param: [9.41087305 7.70542348 7.89252584 7.98130305], weights: [7.68575249e-01 2.31424742e-01 8.31021440e-09], train_wt_loss:  0.5779, val_wt_loss: 0.4227, train_grp_loss: [0.46106771 0.46642128 0.33397152], val_grp_loss: [0.43825283 0.34318412 0.36298661], train_hist_grp_loss: [9045.36609439 8925.3377202  7211.10973194], cur_train_grp_loss: [0.46105734 0.46646855 0.33396831], max_reward_err:  0.0482, max_reward_err_index: 0, max_kl_dist:  1.1112, max_kl_dist_index: 0, max_train_grp_loss:  0.4664, max_train_grp_loss_index: 1, max_val_grp_loss:  0.4383, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4665, max_cur_train_grp_loss_index: 1, 
2024-09-17 14:59:07,053 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  18700, train_loss:  0.0015, val_loss:  0.0004, grad_norm: 0.0282, live_grad: 0.0000, reward_err: 0.0482, 0.0311, 0.0176, KL_dist: 1.1160, 1.0034, 0.9818, param: [9.44269885 7.68411194 7.92351455 7.95932695], weights: [7.68126864e-01 2.31873129e-01 7.31153023e-09], train_wt_loss:  0.5775, val_wt_loss: 0.4225, train_grp_loss: [0.46209787 0.46175028 0.33429094], val_grp_loss: [0.43921003 0.33968114 0.36330578], train_hist_grp_loss: [9091.52401902 8971.74756475 7244.52273119], cur_train_grp_loss: [0.46208768 0.46179627 0.33428777], max_reward_err:  0.0482, max_reward_err_index: 0, max_kl_dist:  1.1160, max_kl_dist_index: 0, max_train_grp_loss:  0.4621, max_train_grp_loss_index: 0, max_val_grp_loss:  0.4392, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4621, max_cur_train_grp_loss_index: 0, 
2024-09-17 14:59:09,858 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  18800, train_loss:  0.0015, val_loss:  0.0004, grad_norm: 0.0279, live_grad: 0.0000, reward_err: 0.0482, 0.0308, 0.0176, KL_dist: 1.1207, 1.0022, 0.9850, param: [9.47363007 7.66354539 7.95369336 7.93825637], weights: [7.68676447e-01 2.31323546e-01 6.43670770e-09], train_wt_loss:  0.5772, val_wt_loss: 0.4225, train_grp_loss: [0.46309658 0.45725797 0.33459981], val_grp_loss: [0.44013836 0.33631331 0.36361472], train_hist_grp_loss: [9137.78360367 9017.69832635 7277.96725258], cur_train_grp_loss: [0.46308683 0.45730169 0.33459681], max_reward_err:  0.0482, max_reward_err_index: 0, max_kl_dist:  1.1207, max_kl_dist_index: 0, max_train_grp_loss:  0.4631, max_train_grp_loss_index: 0, max_val_grp_loss:  0.4401, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4631, max_cur_train_grp_loss_index: 0, 
2024-09-17 14:59:12,720 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  18900, train_loss:  0.0015, val_loss:  0.0004, grad_norm: 0.0277, live_grad: 0.0000, reward_err: 0.0482, 0.0305, 0.0176, KL_dist: 1.1253, 1.0012, 0.9881, param: [9.50327673 7.64433859 7.98268295 7.91873885], weights: [7.70171403e-01 2.29828591e-01 5.66969136e-09], train_wt_loss:  0.5769, val_wt_loss: 0.4225, train_grp_loss: [0.46404072 0.45303809 0.33488622], val_grp_loss: [0.44101566 0.33314809 0.36390194], train_hist_grp_loss: [9184.14054183 9063.21261023 7311.44164504], cur_train_grp_loss: [0.46403162 0.45307866 0.33488351], max_reward_err:  0.0482, max_reward_err_index: 0, max_kl_dist:  1.1253, max_kl_dist_index: 0, max_train_grp_loss:  0.4640, max_train_grp_loss_index: 0, max_val_grp_loss:  0.4410, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4640, max_cur_train_grp_loss_index: 0, 
2024-09-17 14:59:15,507 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  19000, train_loss:  0.0015, val_loss:  0.0004, grad_norm: 0.0275, live_grad: 0.0000, reward_err: 0.0492, 0.0305, 0.0182, KL_dist: 1.1297, 1.0004, 0.9912, param: [9.53129795 7.62704229 8.01015045 7.90135039], weights: [7.72532255e-01 2.27467740e-01 4.99647277e-09], train_wt_loss:  0.5767, val_wt_loss: 0.4227, train_grp_loss: [0.4649095  0.44917188 0.33513932], val_grp_loss: [0.44182194 0.33024357 0.36415695], train_hist_grp_loss: [9230.58832559 9108.32179202 7344.94311535], cur_train_grp_loss: [0.46490125 0.44920856 0.33513699], max_reward_err:  0.0492, max_reward_err_index: 0, max_kl_dist:  1.1297, max_kl_dist_index: 0, max_train_grp_loss:  0.4649, max_train_grp_loss_index: 0, max_val_grp_loss:  0.4418, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4649, max_cur_train_grp_loss_index: 0, 
2024-09-17 14:59:18,307 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  19100, train_loss:  0.0015, val_loss:  0.0004, grad_norm: 0.0273, live_grad: 0.0000, reward_err: 0.0495, 0.0302, 0.0184, KL_dist: 1.1339, 0.9999, 0.9941, param: [9.55740905 7.61213018 8.03581651 7.88658241], weights: [7.75657670e-01 2.24342326e-01 4.40488969e-09], train_wt_loss:  0.5765, val_wt_loss: 0.4230, train_grp_loss: [0.46568505 0.44572671 0.33534955], val_grp_loss: [0.44253992 0.32764762 0.36437052], train_hist_grp_loss: [9277.11850845 9153.06469328 7378.46784675], cur_train_grp_loss: [0.4656778  0.4457589  0.33534769], max_reward_err:  0.0495, max_reward_err_index: 0, max_kl_dist:  1.1339, max_kl_dist_index: 0, max_train_grp_loss:  0.4657, max_train_grp_loss_index: 0, max_val_grp_loss:  0.4425, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4657, max_cur_train_grp_loss_index: 0, 
2024-09-17 14:59:21,097 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  19200, train_loss:  0.0014, val_loss:  0.0004, grad_norm: 0.0271, live_grad: 0.0000, reward_err: 0.0505, 0.0302, 0.0192, KL_dist: 1.1378, 0.9997, 0.9970, param: [9.58138576 7.59999012 8.05945966 7.87483324], weights: [7.79430132e-01 2.20569864e-01 3.88442486e-09], train_wt_loss:  0.5764, val_wt_loss: 0.4233, train_grp_loss: [0.4663527  0.44275545 0.33550896], val_grp_loss: [0.44315544 0.3253975  0.36453497], train_hist_grp_loss: [9323.72101293 9197.4861567  7412.01114504], cur_train_grp_loss: [0.4663466  0.44278268 0.33550764], max_reward_err:  0.0505, max_reward_err_index: 0, max_kl_dist:  1.1378, max_kl_dist_index: 0, max_train_grp_loss:  0.4664, max_train_grp_loss_index: 0, max_val_grp_loss:  0.4432, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4663, max_cur_train_grp_loss_index: 0, 
2024-09-17 14:59:23,897 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  19300, train_loss:  0.0014, val_loss:  0.0004, grad_norm: 0.0270, live_grad: 0.0000, reward_err: 0.0509, 0.0299, 0.0195, KL_dist: 1.1415, 0.9999, 0.9997, param: [9.60306574 7.59091943 8.08091795 7.86640396], weights: [7.83721832e-01 2.16278165e-01 3.42600918e-09], train_wt_loss:  0.5764, val_wt_loss: 0.4237, train_grp_loss: [0.46690127 0.44029643 0.3356113 ], val_grp_loss: [0.44365761 0.32351996 0.36464426], train_hist_grp_loss: [9370.38446691 9241.63558982 7445.56760389], cur_train_grp_loss: [0.46689641 0.44031839 0.33561058], max_reward_err:  0.0509, max_reward_err_index: 0, max_kl_dist:  1.1415, max_kl_dist_index: 0, max_train_grp_loss:  0.4669, max_train_grp_loss_index: 0, max_val_grp_loss:  0.4437, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4669, max_cur_train_grp_loss_index: 0, 
2024-09-17 14:59:26,687 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  19400, train_loss:  0.0014, val_loss:  0.0004, grad_norm: 0.0269, live_grad: 0.0000, reward_err: 0.0511, 0.0295, 0.0196, KL_dist: 1.1449, 1.0005, 1.0023, param: [9.62234761 7.58512414 8.10008829 7.86149837], weights: [7.88400382e-01 2.11599615e-01 3.02183390e-09], train_wt_loss:  0.5765, val_wt_loss: 0.4242, train_grp_loss: [0.46732309 0.438374   0.33565213], val_grp_loss: [0.44403893 0.3220317  0.36469411], train_hist_grp_loss: [9417.09655323 9285.56553545 7479.13128146], cur_train_grp_loss: [0.46731952 0.43839052 0.33565204], max_reward_err:  0.0511, max_reward_err_index: 0, max_kl_dist:  1.1449, max_kl_dist_index: 0, max_train_grp_loss:  0.4673, max_train_grp_loss_index: 0, max_val_grp_loss:  0.4440, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4673, max_cur_train_grp_loss_index: 0, 
2024-09-17 14:59:29,482 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  19500, train_loss:  0.0014, val_loss:  0.0004, grad_norm: 0.0268, live_grad: 0.0000, reward_err: 0.0516, 0.0295, 0.0199, KL_dist: 1.1479, 1.0014, 1.0047, param: [9.63918802 7.5827215  8.11692384 7.86022629], weights: [7.93334012e-01 2.06665985e-01 2.66517604e-09], train_wt_loss:  0.5766, val_wt_loss: 0.4247, train_grp_loss: [0.4676139  0.43699941 0.33562878], val_grp_loss: [0.44429518 0.32094011 0.36468193], train_hist_grp_loss: [9463.84435806 9329.33031397 7512.69588002], cur_train_grp_loss: [0.46761165 0.43701044 0.33562934], max_reward_err:  0.0516, max_reward_err_index: 0, max_kl_dist:  1.1479, max_kl_dist_index: 0, max_train_grp_loss:  0.4676, max_train_grp_loss_index: 0, max_val_grp_loss:  0.4443, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4676, max_cur_train_grp_loss_index: 0, 
2024-09-17 14:59:32,274 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  19600, train_loss:  0.0014, val_loss:  0.0004, grad_norm: 0.0267, live_grad: 0.0000, reward_err: 0.0516, 0.0295, 0.0199, KL_dist: 1.1507, 1.0027, 1.0071, param: [9.65359726 7.58374521 8.13142986 7.86260958], weights: [7.98396001e-01 2.01603997e-01 2.35023996e-09], train_wt_loss:  0.5768, val_wt_loss: 0.4253, train_grp_loss: [0.46777272 0.43617199 0.33554032], val_grp_loss: [0.4444253  0.3202441  0.36460681], train_hist_grp_loss: [9510.61470585 9372.98477027 7546.25492162], cur_train_grp_loss: [0.46777178 0.43617759 0.33554153], max_reward_err:  0.0516, max_reward_err_index: 0, max_kl_dist:  1.1507, max_kl_dist_index: 0, max_train_grp_loss:  0.4678, max_train_grp_loss_index: 0, max_val_grp_loss:  0.4444, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4678, max_cur_train_grp_loss_index: 0, 
2024-09-17 14:59:35,074 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  19700, train_loss:  0.0014, val_loss:  0.0004, grad_norm: 0.0267, live_grad: 0.0000, reward_err: 0.0516, 0.0295, 0.0199, KL_dist: 1.1532, 1.0044, 1.0092, param: [9.66563372 7.58815264 8.1436585  7.86859014], weights: [8.03468181e-01 1.96531817e-01 2.07201709e-09], train_wt_loss:  0.5769, val_wt_loss: 0.4258, train_grp_loss: [0.46780151 0.43588047 0.33538738], val_grp_loss: [0.44443108 0.31993516 0.36446937], train_hist_grp_loss: [9557.3944708  9416.58314594 7579.80191368], cur_train_grp_loss: [0.46780185 0.43588079 0.33538922], max_reward_err:  0.0516, max_reward_err_index: 0, max_kl_dist:  1.1532, max_kl_dist_index: 0, max_train_grp_loss:  0.4678, max_train_grp_loss_index: 0, max_val_grp_loss:  0.4444, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4678, max_cur_train_grp_loss_index: 0, 
2024-09-17 14:59:37,879 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  19800, train_loss:  0.0014, val_loss:  0.0004, grad_norm: 0.0267, live_grad: 0.0000, reward_err: 0.0516, 0.0295, 0.0199, KL_dist: 1.1554, 1.0065, 1.0113, param: [9.67539782 7.59583336 8.15370299 7.8780392 ], weights: [8.08443455e-01 1.91556543e-01 1.82616423e-09], train_wt_loss:  0.5771, val_wt_loss: 0.4263, train_grp_loss: [0.46770488 0.43610434 0.33517203], val_grp_loss: [0.44431687 0.31999827 0.36427159], train_hist_grp_loss: [9604.17085796 9460.17808686 7613.33049998], cur_train_grp_loss: [0.46770645 0.43609963 0.33517449], max_reward_err:  0.0516, max_reward_err_index: 0, max_kl_dist:  1.1554, max_kl_dist_index: 0, max_train_grp_loss:  0.4677, max_train_grp_loss_index: 0, max_val_grp_loss:  0.4443, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4677, max_cur_train_grp_loss_index: 0, 
2024-09-17 14:59:40,667 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  19900, train_loss:  0.0014, val_loss:  0.0004, grad_norm: 0.0267, live_grad: 0.0000, reward_err: 0.0516, 0.0295, 0.0199, KL_dist: 1.1573, 1.0089, 1.0132, param: [9.68302565 7.60661839 8.16169154 7.89076715], weights: [8.13227349e-01 1.86772650e-01 1.60890000e-09], train_wt_loss:  0.5772, val_wt_loss: 0.4267, train_grp_loss: [0.46748972 0.43681523 0.33489758], val_grp_loss: [0.44408922 0.32041292 0.36401668], train_hist_grp_loss: [9650.93164913 9503.81978806 7646.83459383], cur_train_grp_loss: [0.46749243 0.43680582 0.33490061], max_reward_err:  0.0516, max_reward_err_index: 0, max_kl_dist:  1.1573, max_kl_dist_index: 0, max_train_grp_loss:  0.4675, max_train_grp_loss_index: 0, max_val_grp_loss:  0.4441, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4675, max_cur_train_grp_loss_index: 0, 
2024-09-17 14:59:43,444 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  19999, train_loss:  0.0014, val_loss:  0.0004, grad_norm: 0.0268,  live_grad: 0.0000, reward_err: 0.0516, 0.0295, 0.0199, KL_dist: 1.1589, 1.0116, 1.0150, param: [9.68863534 7.62013932 8.16772921 7.90636166], weights: [8.17695158e-01 1.82304841e-01 1.41872265e-09], train_wt_loss:  0.5773, val_wt_loss: 0.4271, train_grp_loss: [0.46716857 0.43796445 0.33457191], val_grp_loss: [0.44376035 0.32114507 0.36371213], train_hist_grp_loss: [9697.19824313 9547.11730687 7679.97391986], cur_train_grp_loss: [0.46717232 0.43795075 0.33457545], max_reward_err:  0.0516, max_reward_err_index: 0, max_kl_dist:  1.1589, max_kl_dist_index: 0, max_train_grp_loss:  0.4672, max_train_grp_loss_index: 0, max_val_grp_loss:  0.4438, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4672, max_cur_train_grp_loss_index: 0, 
2024-09-17 14:59:43,697 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:386] - INFO: Policy parameter learned solely on the preference data rdpo: [9.68863534 7.62013932 8.16772921 7.90636166].
2024-09-17 14:59:44,083 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:397] - INFO: Uniform reward: 3.8390, 3.8390, 3.1881
2024-09-17 14:59:44,084 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Optimal reward: 3.8748, 3.8748, 3.3008
2024-09-17 14:59:44,085 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Policy reward: 3.6750, 3.7604, 3.2352
2024-09-17 14:59:44,085 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Reward Error: 0.0516, 0.0295, 0.0199
2024-09-17 14:59:44,842 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:415] - INFO: Optimal reward: 3.8748, 3.8748, 3.3008
Known param reward: [[3.874841064453125, 3.45266552734375, 3.2780400390625], [3.45266552734375, 3.874841064453125, 3.086048095703125], [3.840370361328125, 3.5875849609375, 3.300816650390625]], Known param reward error: [[0.0, 0.1089529944808094, 0.00690029581783329], [0.1089529944808094, 0.0, 0.06506527851587397], [0.008896030198819327, 0.07413364799677712, 0.0]].
