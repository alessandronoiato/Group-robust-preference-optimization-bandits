2024-09-17 14:59:51,168 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:198] - INFO: Logging to log_rdpo/2024_09_17_14_50_24/swapped_noise1.0_[1,1,1]_2022
2024-09-17 14:59:51,170 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: (IB) Seed: 2022
2024-09-17 14:59:51,171 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Data: 300
2024-09-17 14:59:51,345 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:296] - INFO: MLE reward loss: 0.3429, l2 distance: 29.8423, acc: 0.82.
2024-09-17 14:59:51,346 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-17 14:59:51,347 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: MLE reward parameter: [14.11166716  6.22125723 12.16457928  6.6426602 ]
2024-09-17 14:59:51,580 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:313] - INFO: Learned oracle reward: 3.5898, 3.8487, 3.1982
2024-09-17 14:59:51,854 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-17 14:59:52,496 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  0.0016, val_loss:  0.0005, grad_norm: 0.0340, live_grad: 0.0000, reward_err: 0.0561, 0.0380, 0.0266, KL_dist: 0.2609, 0.1621, 0.1673, param: [3.31794486 1.33450947 4.61657226 4.15232748], weights: [0.33360765 0.33292084 0.33347151], train_wt_loss:  0.4689, val_wt_loss: 0.4828, train_grp_loss: [0.56395343 0.35769462 0.52312833], val_grp_loss: [0.55626795 0.36101401 0.52425212], train_hist_grp_loss: [0.56397062 0.35788553 0.52315607], cur_train_grp_loss: [0.56397062 0.35788553 0.52315607], max_reward_err:  0.0561, max_reward_err_index: 0, max_kl_dist:  0.2609, max_kl_dist_index: 0, max_train_grp_loss:  0.5640, max_train_grp_loss_index: 0, max_val_grp_loss:  0.5563, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.5640, max_cur_train_grp_loss_index: 0, 
2024-09-17 14:59:55,294 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  100, train_loss:  0.0015, val_loss:  0.0005, grad_norm: 0.0319, live_grad: 0.0000, reward_err: 0.0563, 0.0337, 0.0265, KL_dist: 0.2776, 0.1583, 0.1804, param: [3.46202106 1.4985238  4.73813468 4.08138701], weights: [0.36167343 0.29143222 0.34689435], train_wt_loss:  0.4652, val_wt_loss: 0.4852, train_grp_loss: [0.56203642 0.34133517 0.52025811], val_grp_loss: [0.55449264 0.34579304 0.52094117], train_hist_grp_loss: [56.86770261 35.27428125 52.69556342], cur_train_grp_loss: [0.56205754 0.34147404 0.52028782], max_reward_err:  0.0563, max_reward_err_index: 0, max_kl_dist:  0.2776, max_kl_dist_index: 0, max_train_grp_loss:  0.5620, max_train_grp_loss_index: 0, max_val_grp_loss:  0.5545, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.5621, max_cur_train_grp_loss_index: 0, 
2024-09-17 14:59:58,092 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  200, train_loss:  0.0015, val_loss:  0.0005, grad_norm: 0.0302, live_grad: 0.0000, reward_err: 0.0563, 0.0326, 0.0264, KL_dist: 0.2917, 0.1586, 0.1920, param: [3.58565162 1.65478321 4.84058924 4.04762121], weights: [0.39024572 0.25091235 0.35884193], train_wt_loss:  0.4648, val_wt_loss: 0.4892, train_grp_loss: [0.55972551 0.32960366 0.51717863], val_grp_loss: [0.5522913  0.33492408 0.51759813], train_hist_grp_loss: [112.96020786  68.79291523 104.57074773], cur_train_grp_loss: [0.55975053 0.32970142 0.5172105 ], max_reward_err:  0.0563, max_reward_err_index: 0, max_kl_dist:  0.2917, max_kl_dist_index: 0, max_train_grp_loss:  0.5597, max_train_grp_loss_index: 0, max_val_grp_loss:  0.5523, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.5598, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:00:00,907 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  300, train_loss:  0.0015, val_loss:  0.0005, grad_norm: 0.0289, live_grad: 0.0000, reward_err: 0.0549, 0.0303, 0.0249, KL_dist: 0.3035, 0.1621, 0.2021, param: [3.69159737 1.80634455 4.92630647 4.045655  ], weights: [0.41836964 0.21306747 0.36856289], train_wt_loss:  0.4664, val_wt_loss: 0.4938, train_grp_loss: [0.55703557 0.32154253 0.51388303], val_grp_loss: [0.54968338 0.32754166 0.51419567], train_hist_grp_loss: [168.80265015 101.32700524 156.12725202], cur_train_grp_loss: [0.55706425 0.32160752 0.51391703], max_reward_err:  0.0549, max_reward_err_index: 0, max_kl_dist:  0.3035, max_kl_dist_index: 0, max_train_grp_loss:  0.5570, max_train_grp_loss_index: 0, max_val_grp_loss:  0.5497, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.5571, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:00:03,720 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  400, train_loss:  0.0015, val_loss:  0.0005, grad_norm: 0.0279, live_grad: 0.0000, reward_err: 0.0549, 0.0289, 0.0249, KL_dist: 0.3131, 0.1680, 0.2109, param: [3.78250374 1.95539423 4.99752945 4.07040652], weights: [0.4453448  0.17898862 0.37566657], train_wt_loss:  0.4691, val_wt_loss: 0.4981, train_grp_loss: [0.55399916 0.31642576 0.51038349], val_grp_loss: [0.54670631 0.32298272 0.51072439], train_hist_grp_loss: [224.35862455 133.20596727 207.34394031], cur_train_grp_loss: [0.5540311  0.31646428 0.51041942], max_reward_err:  0.0549, max_reward_err_index: 0, max_kl_dist:  0.3131, max_kl_dist_index: 0, max_train_grp_loss:  0.5540, max_train_grp_loss_index: 0, max_val_grp_loss:  0.5467, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.5540, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:00:06,562 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  500, train_loss:  0.0015, val_loss:  0.0005, grad_norm: 0.0271, live_grad: 0.0000, reward_err: 0.0533, 0.0292, 0.0236, KL_dist: 0.3210, 0.1760, 0.2186, param: [3.86080281 2.10338343 5.0563186  4.11727165], weights: [0.47073201 0.14920047 0.38006752], train_wt_loss:  0.4723, val_wt_loss: 0.5016, train_grp_loss: [0.55065901 0.31370275 0.50670415], val_grp_loss: [0.54340756 0.32074016 0.50718714], train_hist_grp_loss: [279.5955407  164.69573123 258.20153931], cur_train_grp_loss: [0.55069376 0.31371961 0.50674173], max_reward_err:  0.0533, max_reward_err_index: 0, max_kl_dist:  0.3210, max_kl_dist_index: 0, max_train_grp_loss:  0.5507, max_train_grp_loss_index: 0, max_val_grp_loss:  0.5434, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.5507, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:00:09,368 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  600, train_loss:  0.0015, val_loss:  0.0005, grad_norm: 0.0266, live_grad: 0.0000, reward_err: 0.0524, 0.0296, 0.0228, KL_dist: 0.3275, 0.1857, 0.2256, param: [3.92865855 2.25118998 5.10451862 4.18220283], weights: [0.49432108 0.12377568 0.38190325], train_wt_loss:  0.4756, val_wt_loss: 0.5042, train_grp_loss: [0.54706219 0.31295212 0.50287545], val_grp_loss: [0.53983857 0.32042297 0.50359437], train_hist_grp_loss: [334.48533888 196.01390039 308.68354293], cur_train_grp_loss: [0.54709928 0.312951   0.50291437], max_reward_err:  0.0524, max_reward_err_index: 0, max_kl_dist:  0.3275, max_kl_dist_index: 0, max_train_grp_loss:  0.5471, max_train_grp_loss_index: 0, max_val_grp_loss:  0.5398, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.5471, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:00:12,186 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  700, train_loss:  0.0015, val_loss:  0.0005, grad_norm: 0.0263, live_grad: 0.0000, reward_err: 0.0513, 0.0280, 0.0220, KL_dist: 0.3329, 0.1969, 0.2318, param: [3.98794535 2.39927381 5.14374458 4.26172284], weights: [0.51607694 0.10247485 0.38144821], train_wt_loss:  0.4786, val_wt_loss: 0.5057, train_grp_loss: [0.54325587 0.31384669 0.49892995], val_grp_loss: [0.53605031 0.32172551 0.49996058], train_hist_grp_loss: [389.00470021 227.34085063 358.77662373], cur_train_grp_loss: [0.54329482 0.3138305  0.49896988], max_reward_err:  0.0513, max_reward_err_index: 0, max_kl_dist:  0.3329, max_kl_dist_index: 0, max_train_grp_loss:  0.5433, max_train_grp_loss_index: 0, max_val_grp_loss:  0.5361, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.5433, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:00:14,990 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  800, train_loss:  0.0015, val_loss:  0.0005, grad_norm: 0.0261, live_grad: 0.0000, reward_err: 0.0498, 0.0281, 0.0210, KL_dist: 0.3375, 0.2094, 0.2377, param: [4.04025134 2.54780959 5.17538407 4.35289869], weights: [0.53608127 0.08487801 0.37904072], train_wt_loss:  0.4813, val_wt_loss: 0.5062, train_grp_loss: [0.53928444 0.31612822 0.49489943], val_grp_loss: [0.5320904  0.32440505 0.4963017 ], train_hist_grp_loss: [443.13490304 258.82782915 408.47069012], cur_train_grp_loss: [0.53932484 0.31609926 0.49494006], max_reward_err:  0.0498, max_reward_err_index: 0, max_kl_dist:  0.3375, max_kl_dist_index: 0, max_train_grp_loss:  0.5393, max_train_grp_loss_index: 0, max_val_grp_loss:  0.5321, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.5393, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:00:17,789 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  900, train_loss:  0.0015, val_loss:  0.0005, grad_norm: 0.0260, live_grad: 0.0000, reward_err: 0.0478, 0.0276, 0.0194, KL_dist: 0.3415, 0.2230, 0.2433, param: [4.08689845 2.69679049 5.20061152 4.45329259], weights: [0.55448157 0.07048839 0.37503003], train_wt_loss:  0.4835, val_wt_loss: 0.5059, train_grp_loss: [0.53518792 0.31958944 0.4908131 ], val_grp_loss: [0.52800151 0.3282657  0.49263341], train_hist_grp_loss: [496.86145817 290.60290654 457.75871202], cur_train_grp_loss: [0.53522939 0.31954957 0.49085415], max_reward_err:  0.0478, max_reward_err_index: 0, max_kl_dist:  0.3415, max_kl_dist_index: 0, max_train_grp_loss:  0.5352, max_train_grp_loss_index: 0, max_val_grp_loss:  0.5280, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.5352, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:00:20,595 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  1000, train_loss:  0.0015, val_loss:  0.0005, grad_norm: 0.0261, live_grad: 0.0000, reward_err: 0.0465, 0.0285, 0.0184, KL_dist: 0.3452, 0.2376, 0.2488, param: [4.1289719  2.84610417 5.22040987 4.5609017 ], weights: [0.57145292 0.05880342 0.36974366], train_wt_loss:  0.4854, val_wt_loss: 0.5048, train_grp_loss: [0.53100123 0.32406143 0.48669672], val_grp_loss: [0.52382069 0.33314707 0.4889701 ], train_hist_grp_loss: [550.17362892 322.77541264 506.6364142 ], cur_train_grp_loss: [0.53104344 0.32401218 0.48673795], max_reward_err:  0.0465, max_reward_err_index: 0, max_kl_dist:  0.3452, max_kl_dist_index: 0, max_train_grp_loss:  0.5310, max_train_grp_loss_index: 0, max_val_grp_loss:  0.5238, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.5310, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:00:23,408 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  1100, train_loss:  0.0014, val_loss:  0.0004, grad_norm: 0.0262, live_grad: 0.0000, reward_err: 0.0452, 0.0293, 0.0174, KL_dist: 0.3486, 0.2531, 0.2543, param: [4.1673534  2.99558503 5.23559575 4.67409517], weights: [0.5871726  0.04935666 0.36347074], train_wt_loss:  0.4869, val_wt_loss: 0.5030, train_grp_loss: [0.52675411 0.32940462 0.48257226], val_grp_loss: [0.51957934 0.33891612 0.48532442], train_hist_grp_loss: [603.0639125  355.43930116 555.10191063], cur_train_grp_loss: [0.52679679 0.32934728 0.48261348], max_reward_err:  0.0452, max_reward_err_index: 0, max_kl_dist:  0.3486, max_kl_dist_index: 0, max_train_grp_loss:  0.5268, max_train_grp_loss_index: 0, max_val_grp_loss:  0.5196, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.5268, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:00:26,207 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  1200, train_loss:  0.0015, val_loss:  0.0004, grad_norm: 0.0264, live_grad: 0.0000, reward_err: 0.0452, 0.0304, 0.0174, KL_dist: 0.3520, 0.2694, 0.2599, param: [4.20275403 3.14504816 5.24684494 4.79155365], weights: [0.60180538 0.04173818 0.35645644], train_wt_loss:  0.4881, val_wt_loss: 0.5008, train_grp_loss: [0.52247138 0.33550236 0.47845802], val_grp_loss: [0.51530359 0.34546128 0.48170705], train_hist_grp_loss: [655.52753349 388.67574917 603.15532935], cur_train_grp_loss: [0.52251432 0.33543798 0.47849906], max_reward_err:  0.0452, max_reward_err_index: 0, max_kl_dist:  0.3520, max_kl_dist_index: 0, max_train_grp_loss:  0.5225, max_train_grp_loss_index: 0, max_val_grp_loss:  0.5153, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.5225, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:00:29,022 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  1300, train_loss:  0.0015, val_loss:  0.0004, grad_norm: 0.0266, live_grad: 0.0000, reward_err: 0.0414, 0.0314, 0.0149, KL_dist: 0.3553, 0.2865, 0.2656, param: [4.2357445  3.29430987 5.25471617 4.91221454], weights: [0.61549644 0.03560056 0.348903  ], train_wt_loss:  0.4890, val_wt_loss: 0.4982, train_grp_loss: [0.51817351 0.34225614 0.47436894], val_grp_loss: [0.51101483 0.35268805 0.4781268 ], train_hist_grp_loss: [707.56197855 422.55520029 650.79845814], cur_train_grp_loss: [0.51821651 0.34218564 0.47440966], max_reward_err:  0.0414, max_reward_err_index: 0, max_kl_dist:  0.3553, max_kl_dist_index: 0, max_train_grp_loss:  0.5182, max_train_grp_loss_index: 0, max_val_grp_loss:  0.5110, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.5182, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:00:31,832 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  1400, train_loss:  0.0015, val_loss:  0.0004, grad_norm: 0.0269, live_grad: 0.0000, reward_err: 0.0402, 0.0330, 0.0140, KL_dist: 0.3588, 0.3042, 0.2715, param: [4.26678165 3.44319907 5.25967233 5.03522408], weights: [0.62836923 0.03065672 0.34097404], train_wt_loss:  0.4896, val_wt_loss: 0.4953, train_grp_loss: [0.51387715 0.34958202 0.47031696], val_grp_loss: [0.50673044 0.36051573 0.47459074], train_hist_grp_loss: [759.16658654 457.13899469 698.03442683], cur_train_grp_loss: [0.51392006 0.34950617 0.47035726], max_reward_err:  0.0402, max_reward_err_index: 0, max_kl_dist:  0.3588, max_kl_dist_index: 0, max_train_grp_loss:  0.5139, max_train_grp_loss_index: 0, max_val_grp_loss:  0.5067, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.5139, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:00:34,638 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  1500, train_loss:  0.0015, val_loss:  0.0004, grad_norm: 0.0272, live_grad: 0.0000, reward_err: 0.0380, 0.0337, 0.0124, KL_dist: 0.3624, 0.3226, 0.2777, param: [4.29623093 3.5915627  5.26209854 5.15989693], weights: [0.64052618 0.02667361 0.33280021], train_wt_loss:  0.4900, val_wt_loss: 0.4921, train_grp_loss: [0.50959573 0.35740791 0.46631152], val_grp_loss: [0.50246434 0.36887477 0.47110441], train_hist_grp_loss: [810.3421977  492.48068524 744.86743245], cur_train_grp_loss: [0.50963843 0.35732739 0.46635132], max_reward_err:  0.0380, max_reward_err_index: 0, max_kl_dist:  0.3624, max_kl_dist_index: 0, max_train_grp_loss:  0.5096, max_train_grp_loss_index: 0, max_val_grp_loss:  0.5025, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.5096, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:00:37,444 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  1600, train_loss:  0.0015, val_loss:  0.0004, grad_norm: 0.0275, live_grad: 0.0000, reward_err: 0.0366, 0.0337, 0.0114, KL_dist: 0.3662, 0.3414, 0.2841, param: [4.324385   3.73926728 5.26231734 5.28568239], weights: [0.65205074 0.02346441 0.32448485], train_wt_loss:  0.4902, val_wt_loss: 0.4889, train_grp_loss: [0.50534002 0.36567139 0.46235995], val_grp_loss: [0.49822764 0.3777048  0.46767209], train_hist_grp_loss: [861.09085988 528.62711004 791.30250752], cur_train_grp_loss: [0.50538242 0.36558677 0.46239918], max_reward_err:  0.0366, max_reward_err_index: 0, max_kl_dist:  0.3662, max_kl_dist_index: 0, max_train_grp_loss:  0.5053, max_train_grp_loss_index: 0, max_val_grp_loss:  0.4982, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.5054, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:00:40,261 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  1700, train_loss:  0.0015, val_loss:  0.0004, grad_norm: 0.0279, live_grad: 0.0000, reward_err: 0.0361, 0.0345, 0.0110, KL_dist: 0.3702, 0.3608, 0.2908, param: [4.35147887 3.8861985  5.26060111 5.41213689], weights: [0.66301009 0.02088074 0.31610917], train_wt_loss:  0.4902, val_wt_loss: 0.4855, train_grp_loss: [0.50111863 0.374318   0.45846784], val_grp_loss: [0.49402914 0.38695296 0.46429696], train_hist_grp_loss: [911.41558646 565.61927234 837.34532847], cur_train_grp_loss: [0.50116065 0.3742298  0.45850645], max_reward_err:  0.0361, max_reward_err_index: 0, max_kl_dist:  0.3702, max_kl_dist_index: 0, max_train_grp_loss:  0.5011, max_train_grp_loss_index: 0, max_val_grp_loss:  0.4940, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.5012, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:00:43,070 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  1800, train_loss:  0.0015, val_loss:  0.0004, grad_norm: 0.0282, live_grad: 0.0000, reward_err: 0.0348, 0.0355, 0.0101, KL_dist: 0.3745, 0.3806, 0.2978, param: [4.37770221 4.03225941 5.25718215 5.53890161], weights: [0.67345778 0.01880559 0.30773663], train_wt_loss:  0.4900, val_wt_loss: 0.4820, train_grp_loss: [0.49693837 0.38329987 0.45463939], val_grp_loss: [0.48987576 0.39657255 0.46098134], train_hist_grp_loss: [961.32015926 603.49306566 883.00205957], cur_train_grp_loss: [0.49697995 0.38320853 0.45467735], max_reward_err:  0.0355, max_reward_err_index: 1, max_kl_dist:  0.3806, max_kl_dist_index: 1, max_train_grp_loss:  0.4969, max_train_grp_loss_index: 0, max_val_grp_loss:  0.4899, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4970, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:00:45,865 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  1900, train_loss:  0.0015, val_loss:  0.0005, grad_norm: 0.0286, live_grad: 0.0000, reward_err: 0.0331, 0.0379, 0.0090, KL_dist: 0.3791, 0.4007, 0.3051, param: [4.40320912 4.17736824 5.2522609  5.66568444], weights: [0.68343612 0.01714733 0.29941656], train_wt_loss:  0.4898, val_wt_loss: 0.4785, train_grp_loss: [0.49280465 0.39257453 0.45087768], val_grp_loss: [0.48577295 0.40652195 0.45772683], train_hist_grp_loss: [1010.80896989  642.27987269  928.27922732], cur_train_grp_loss: [0.49284574 0.39248046 0.45091496], max_reward_err:  0.0379, max_reward_err_index: 1, max_kl_dist:  0.4007, max_kl_dist_index: 1, max_train_grp_loss:  0.4928, max_train_grp_loss_index: 0, max_val_grp_loss:  0.4858, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4928, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:00:48,668 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  2000, train_loss:  0.0015, val_loss:  0.0005, grad_norm: 0.0290, live_grad: 0.0000, reward_err: 0.0316, 0.0385, 0.0081, KL_dist: 0.3839, 0.4212, 0.3127, param: [4.42812602 4.32145593 5.24601244 5.79224545], weights: [0.69297828 0.01583465 0.29118708], train_wt_loss:  0.4894, val_wt_loss: 0.4750, train_grp_loss: [0.48872176 0.40210401 0.4471849 ], val_grp_loss: [0.48172497 0.4167637  0.45453447], train_hist_grp_loss: [1059.8868931   682.00705957  973.18362071], cur_train_grp_loss: [0.48876233 0.40200757 0.44722148], max_reward_err:  0.0385, max_reward_err_index: 1, max_kl_dist:  0.4212, max_kl_dist_index: 1, max_train_grp_loss:  0.4887, max_train_grp_loss_index: 0, max_val_grp_loss:  0.4817, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4888, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:00:51,489 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  2100, train_loss:  0.0015, val_loss:  0.0005, grad_norm: 0.0293, live_grad: 0.0000, reward_err: 0.0303, 0.0392, 0.0073, KL_dist: 0.3891, 0.4420, 0.3206, param: [4.45255806 4.46446373 5.23859188 5.91838519], weights: [0.70210996 0.01481266 0.28307738], train_wt_loss:  0.4889, val_wt_loss: 0.4714, train_grp_loss: [0.48469311 0.41185401 0.44356255], val_grp_loss: [0.47773514 0.42726368 0.45140484], train_hist_grp_loss: [1108.55918689  722.69838257 1017.72221269], cur_train_grp_loss: [0.48473312 0.41175552 0.44359843], max_reward_err:  0.0392, max_reward_err_index: 1, max_kl_dist:  0.4420, max_kl_dist_index: 1, max_train_grp_loss:  0.4847, max_train_grp_loss_index: 0, max_val_grp_loss:  0.4777, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4847, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:00:54,297 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  2200, train_loss:  0.0015, val_loss:  0.0005, grad_norm: 0.0297, live_grad: 0.0000, reward_err: 0.0287, 0.0405, 0.0064, KL_dist: 0.3945, 0.4631, 0.3288, param: [4.47659419 4.60634086 5.23013866 6.04393513], weights: [0.71085073 0.01403973 0.27510953], train_wt_loss:  0.4883, val_wt_loss: 0.4679, train_grp_loss: [0.48072142 0.42179318 0.44001163], val_grp_loss: [0.47380609 0.43799046 0.44833822], train_hist_grp_loss: [1156.83141455  764.37431974 1061.90209946], cur_train_grp_loss: [0.48076084 0.42169295 0.44004679], max_reward_err:  0.0405, max_reward_err_index: 1, max_kl_dist:  0.4631, max_kl_dist_index: 1, max_train_grp_loss:  0.4807, max_train_grp_loss_index: 0, max_val_grp_loss:  0.4738, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4808, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:00:57,098 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  2300, train_loss:  0.0015, val_loss:  0.0005, grad_norm: 0.0301, live_grad: 0.0000, reward_err: 0.0282, 0.0410, 0.0061, KL_dist: 0.4002, 0.4843, 0.3372, param: [4.50031147 4.74704236 5.22078015 6.16874985], weights: [0.719215   0.01348516 0.26729984], train_wt_loss:  0.4876, val_wt_loss: 0.4644, train_grp_loss: [0.47680889 0.43189255 0.43653271], val_grp_loss: [0.46993989 0.44891469 0.44533457], train_hist_grp_loss: [1204.70938507  807.05233721 1105.73045433], cur_train_grp_loss: [0.47684772 0.43179085 0.43656714], max_reward_err:  0.0410, max_reward_err_index: 1, max_kl_dist:  0.4843, max_kl_dist_index: 1, max_train_grp_loss:  0.4768, max_train_grp_loss_index: 0, max_val_grp_loss:  0.4699, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4768, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:00:59,917 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  2400, train_loss:  0.0015, val_loss:  0.0005, grad_norm: 0.0304, live_grad: 0.0000, reward_err: 0.0273, 0.0421, 0.0056, KL_dist: 0.4062, 0.5058, 0.3460, param: [4.52377858 4.88652696 5.2106347  6.29270039], weights: [0.7272127  0.01312736 0.25965994], train_wt_loss:  0.4868, val_wt_loss: 0.4610, train_grp_loss: [0.47295737 0.44212495 0.43312608], val_grp_loss: [0.46613822 0.46000856 0.4423937 ], train_hist_grp_loss: [1252.19910891  850.7470969  1149.21449378], cur_train_grp_loss: [0.47299558 0.44202205 0.43315979], max_reward_err:  0.0421, max_reward_err_index: 1, max_kl_dist:  0.5058, max_kl_dist_index: 1, max_train_grp_loss:  0.4730, max_train_grp_loss_index: 0, max_val_grp_loss:  0.4661, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4730, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:01:02,723 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  2500, train_loss:  0.0015, val_loss:  0.0005, grad_norm: 0.0308, live_grad: 0.0000, reward_err: 0.0251, 0.0436, 0.0045, KL_dist: 0.4125, 0.5274, 0.3550, param: [4.54705895 5.02475513 5.19981432 6.41566858], weights: [0.73484971 0.0129527  0.25219759], train_wt_loss:  0.4860, val_wt_loss: 0.4576, train_grp_loss: [0.46916845 0.45246445 0.42979185], val_grp_loss: [0.46240252 0.47124523 0.43951528], train_hist_grp_loss: [1299.30676688  895.47061014 1192.36145379], cur_train_grp_loss: [0.46920602 0.45236061 0.42982483], max_reward_err:  0.0436, max_reward_err_index: 1, max_kl_dist:  0.5274, max_kl_dist_index: 1, max_train_grp_loss:  0.4692, max_train_grp_loss_index: 0, max_val_grp_loss:  0.4712, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.4692, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:01:05,535 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  2600, train_loss:  0.0015, val_loss:  0.0005, grad_norm: 0.0311, live_grad: 0.0000, reward_err: 0.0237, 0.0453, 0.0039, KL_dist: 0.4191, 0.5491, 0.3644, param: [4.5702135  5.161687   5.18842714 6.53754192], weights: [0.74212801 0.01295469 0.2449173 ], train_wt_loss:  0.4852, val_wt_loss: 0.4542, train_grp_loss: [0.46544356 0.46288593 0.42653002], val_grp_loss: [0.45873404 0.48259836 0.43669888], train_hist_grp_loss: [1346.03869052  941.23233929 1235.17857503], cur_train_grp_loss: [0.46548049 0.46278139 0.42656228], max_reward_err:  0.0453, max_reward_err_index: 1, max_kl_dist:  0.5491, max_kl_dist_index: 1, max_train_grp_loss:  0.4654, max_train_grp_loss_index: 0, max_val_grp_loss:  0.4826, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.4655, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:01:08,339 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  2700, train_loss:  0.0015, val_loss:  0.0005, grad_norm: 0.0314, live_grad: 0.0000, reward_err: 0.0231, 0.0461, 0.0035, KL_dist: 0.4259, 0.5710, 0.3739, param: [4.59330335 5.29728033 5.17657972 6.6582087 ], weights: [0.74904558 0.01313366 0.23782076], train_wt_loss:  0.4843, val_wt_loss: 0.4510, train_grp_loss: [0.46178412 0.47336444 0.42334056], val_grp_loss: [0.45513402 0.49404154 0.43394406], train_hist_grp_loss: [1392.4013531   988.03924733 1277.67309598], cur_train_grp_loss: [0.46182039 0.47325945 0.4233721 ], max_reward_err:  0.0461, max_reward_err_index: 1, max_kl_dist:  0.5710, max_kl_dist_index: 1, max_train_grp_loss:  0.4734, max_train_grp_loss_index: 1, max_val_grp_loss:  0.4940, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.4733, max_cur_train_grp_loss_index: 1, 
2024-09-17 15:01:11,153 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  2800, train_loss:  0.0015, val_loss:  0.0005, grad_norm: 0.0318, live_grad: 0.0000, reward_err: 0.0223, 0.0464, 0.0032, KL_dist: 0.4331, 0.5928, 0.3837, param: [4.61639241 5.43148816 5.16437946 6.77755321], weights: [0.75559606 0.01349678 0.23090716], train_wt_loss:  0.4833, val_wt_loss: 0.4478, train_grp_loss: [0.45819159 0.48387473 0.42022348], val_grp_loss: [0.45160372 0.50554773 0.43125036], train_hist_grp_loss: [1438.40137061 1035.89579295 1319.85225336], cur_train_grp_loss: [0.45822717 0.48376955 0.42025429], max_reward_err:  0.0464, max_reward_err_index: 1, max_kl_dist:  0.5928, max_kl_dist_index: 1, max_train_grp_loss:  0.4839, max_train_grp_loss_index: 1, max_val_grp_loss:  0.5055, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.4838, max_cur_train_grp_loss_index: 1, 
2024-09-17 15:01:13,976 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  2900, train_loss:  0.0016, val_loss:  0.0005, grad_norm: 0.0321, live_grad: 0.0000, reward_err: 0.0221, 0.0467, 0.0031, KL_dist: 0.4404, 0.6147, 0.3938, param: [4.63955019 5.56425629 5.15193716 6.89545069], weights: [0.7617681  0.01405848 0.22417342], train_wt_loss:  0.4824, val_wt_loss: 0.4446, train_grp_loss: [0.45466759 0.49439056 0.4171789 ], val_grp_loss: [0.44814459 0.51708855 0.42861739], train_hist_grp_loss: [1484.04551292 1084.80386621 1361.72328979], cur_train_grp_loss: [0.45470249 0.49428546 0.41720899], max_reward_err:  0.0467, max_reward_err_index: 1, max_kl_dist:  0.6147, max_kl_dist_index: 1, max_train_grp_loss:  0.4944, max_train_grp_loss_index: 1, max_val_grp_loss:  0.5171, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.4943, max_cur_train_grp_loss_index: 1, 
2024-09-17 15:01:16,775 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  3000, train_loss:  0.0016, val_loss:  0.0005, grad_norm: 0.0324, live_grad: 0.0000, reward_err: 0.0213, 0.0474, 0.0028, KL_dist: 0.4481, 0.6366, 0.4040, param: [4.66285493 5.69552023 5.13936992 7.01176173], weights: [0.76754446 0.01484133 0.21761421], train_wt_loss:  0.4815, val_wt_loss: 0.4416, train_grp_loss: [0.45121405 0.50488401 0.41420713], val_grp_loss: [0.44475834 0.52863357 0.42604482], train_hist_grp_loss: [1529.34072573 1134.7626568  1403.29346884], cur_train_grp_loss: [0.45124823 0.50477928 0.41423649], max_reward_err:  0.0474, max_reward_err_index: 1, max_kl_dist:  0.6366, max_kl_dist_index: 1, max_train_grp_loss:  0.5049, max_train_grp_loss_index: 1, max_val_grp_loss:  0.5286, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.5048, max_cur_train_grp_loss_index: 1, 
2024-09-17 15:01:19,597 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  3100, train_loss:  0.0016, val_loss:  0.0005, grad_norm: 0.0327, live_grad: 0.0000, reward_err: 0.0196, 0.0481, 0.0022, KL_dist: 0.4559, 0.6585, 0.4145, param: [4.68639716 5.82520155 5.12680448 7.12632587], weights: [0.77290063 0.01587735 0.21122202], train_wt_loss:  0.4806, val_wt_loss: 0.4387, train_grp_loss: [0.44783327 0.51532461 0.41130877], val_grp_loss: [0.44144707 0.54014934 0.42353249], train_hist_grp_loss: [1574.29416462 1185.76844338 1444.57009815], cur_train_grp_loss: [0.44786671 0.51522057 0.41133738], max_reward_err:  0.0481, max_reward_err_index: 1, max_kl_dist:  0.6585, max_kl_dist_index: 1, max_train_grp_loss:  0.5153, max_train_grp_loss_index: 1, max_val_grp_loss:  0.5401, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.5152, max_cur_train_grp_loss_index: 1, 
2024-09-17 15:01:22,420 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  3200, train_loss:  0.0016, val_loss:  0.0005, grad_norm: 0.0329, live_grad: 0.0000, reward_err: 0.0190, 0.0503, 0.0019, KL_dist: 0.4641, 0.6802, 0.4251, param: [4.71028409 5.95320345 5.11438126 7.23895396], weights: [0.77780311 0.01720988 0.20498701], train_wt_loss:  0.4798, val_wt_loss: 0.4359, train_grp_loss: [0.44452813 0.52567827 0.40848476], val_grp_loss: [0.43821346 0.55159831 0.42108039], train_hist_grp_loss: [1618.91324293 1237.81428849 1485.56056172], cur_train_grp_loss: [0.44456079 0.52557529 0.40851263], max_reward_err:  0.0503, max_reward_err_index: 1, max_kl_dist:  0.6802, max_kl_dist_index: 1, max_train_grp_loss:  0.5257, max_train_grp_loss_index: 1, max_val_grp_loss:  0.5516, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.5256, max_cur_train_grp_loss_index: 1, 
2024-09-17 15:01:25,226 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  3300, train_loss:  0.0016, val_loss:  0.0005, grad_norm: 0.0332, live_grad: 0.0000, reward_err: 0.0182, 0.0503, 0.0017, KL_dist: 0.4724, 0.7018, 0.4359, param: [4.73464476 6.0794051  5.10225934 7.34941894], weights: [0.78220704 0.01889616 0.1988968 ], train_wt_loss:  0.4790, val_wt_loss: 0.4332, train_grp_loss: [0.44130224 0.53590606 0.40573657], val_grp_loss: [0.4350609  0.56293737 0.41868878], train_hist_grp_loss: [1663.20569651 1290.88961803 1526.27236294], cur_train_grp_loss: [0.44133409 0.53580455 0.40576367], max_reward_err:  0.0503, max_reward_err_index: 1, max_kl_dist:  0.7018, max_kl_dist_index: 1, max_train_grp_loss:  0.5359, max_train_grp_loss_index: 1, max_val_grp_loss:  0.5629, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.5358, max_cur_train_grp_loss_index: 1, 
2024-09-17 15:01:28,042 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  3400, train_loss:  0.0016, val_loss:  0.0005, grad_norm: 0.0335, live_grad: 0.0000, reward_err: 0.0174, 0.0519, 0.0013, KL_dist: 0.4809, 0.7232, 0.4468, param: [4.75963663 6.20365462 5.09062258 7.45744441], weights: [0.78605324 0.02101054 0.19293622], train_wt_loss:  0.4784, val_wt_loss: 0.4308, train_grp_loss: [0.4381602  0.54596258 0.40306628], val_grp_loss: [0.43199374 0.57411617 0.41635824], train_hist_grp_loss: [1707.17966875 1344.97965865 1566.7131808 ], cur_train_grp_loss: [0.43819119 0.54586303 0.40309259], max_reward_err:  0.0519, max_reward_err_index: 1, max_kl_dist:  0.7232, max_kl_dist_index: 1, max_train_grp_loss:  0.5460, max_train_grp_loss_index: 1, max_val_grp_loss:  0.5741, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.5459, max_cur_train_grp_loss_index: 1, 
2024-09-17 15:01:30,857 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  3500, train_loss:  0.0016, val_loss:  0.0005, grad_norm: 0.0337, live_grad: 0.0000, reward_err: 0.0165, 0.0537, 0.0010, KL_dist: 0.4896, 0.7443, 0.4579, param: [4.7854536  6.32576015 5.07968725 7.5626907 ], weights: [0.78926446 0.02364875 0.1870868 ], train_wt_loss:  0.4780, val_wt_loss: 0.4285, train_grp_loss: [0.43510783 0.55579402 0.40047681], val_grp_loss: [0.42901758 0.58507496 0.41408976], train_hist_grp_loss: [1750.8438209  1400.06469895 1606.89094197], cur_train_grp_loss: [0.43513789 0.55569702 0.40050229], max_reward_err:  0.0537, max_reward_err_index: 1, max_kl_dist:  0.7443, max_kl_dist_index: 1, max_train_grp_loss:  0.5558, max_train_grp_loss_index: 1, max_val_grp_loss:  0.5851, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.5557, max_cur_train_grp_loss_index: 1, 
2024-09-17 15:01:33,693 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  3600, train_loss:  0.0016, val_loss:  0.0005, grad_norm: 0.0339, live_grad: 0.0000, reward_err: 0.0165, 0.0537, 0.0010, KL_dist: 0.4986, 0.7650, 0.4690, param: [4.81233602 6.4454786  5.06971148 7.66473746], weights: [0.79174071 0.02693295 0.18132633], train_wt_loss:  0.4778, val_wt_loss: 0.4264, train_grp_loss: [0.43215258 0.56533573 0.39797208], val_grp_loss: [0.42613958 0.59574188 0.41188484], train_hist_grp_loss: [1794.20747368 1456.11913256 1646.81391289], cur_train_grp_loss: [0.43218162 0.56524199 0.39799669], max_reward_err:  0.0537, max_reward_err_index: 1, max_kl_dist:  0.7650, max_kl_dist_index: 1, max_train_grp_loss:  0.5653, max_train_grp_loss_index: 1, max_val_grp_loss:  0.5957, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.5652, max_cur_train_grp_loss_index: 1, 
2024-09-17 15:01:36,505 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  3700, train_loss:  0.0016, val_loss:  0.0005, grad_norm: 0.0341, live_grad: 0.0000, reward_err: 0.0154, 0.0537, 0.0007, KL_dist: 0.5076, 0.7853, 0.4802, param: [4.84058299 6.56250148 5.06100693 7.76306263], weights: [0.79335386 0.03101788 0.17562827], train_wt_loss:  0.4780, val_wt_loss: 0.4247, train_grp_loss: [0.4293039  0.57450928 0.39555736], val_grp_loss: [0.42336892 0.60602969 0.40974568], train_hist_grp_loss: [1837.28078775 1513.11023346 1686.49081638], cur_train_grp_loss: [0.42933182 0.57441967 0.39558104], max_reward_err:  0.0537, max_reward_err_index: 1, max_kl_dist:  0.7853, max_kl_dist_index: 1, max_train_grp_loss:  0.5745, max_train_grp_loss_index: 1, max_val_grp_loss:  0.6060, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.5744, max_cur_train_grp_loss_index: 1, 
2024-09-17 15:01:39,313 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  3800, train_loss:  0.0016, val_loss:  0.0005, grad_norm: 0.0343, live_grad: 0.0000, reward_err: 0.0152, 0.0545, 0.0006, KL_dist: 0.5169, 0.8051, 0.4914, param: [4.87056715 6.67643735 5.05395284 7.85701707], weights: [0.79394135 0.03609758 0.16996108], train_wt_loss:  0.4785, val_wt_loss: 0.4233, train_grp_loss: [0.42657381 0.58321893 0.39323953], val_grp_loss: [0.42071728 0.61583187 0.40767528], train_hist_grp_loss: [1880.07499196 1570.99660691 1725.9309787 ], cur_train_grp_loss: [0.42660048 0.58313449 0.3932622 ], max_reward_err:  0.0545, max_reward_err_index: 1, max_kl_dist:  0.8051, max_kl_dist_index: 1, max_train_grp_loss:  0.5832, max_train_grp_loss_index: 1, max_val_grp_loss:  0.6158, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.5831, max_cur_train_grp_loss_index: 1, 
2024-09-17 15:01:42,125 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  3900, train_loss:  0.0016, val_loss:  0.0005, grad_norm: 0.0344, live_grad: 0.0000, reward_err: 0.0144, 0.0557, 0.0004, KL_dist: 0.5262, 0.8241, 0.5025, param: [4.90275207 6.78679047 5.04901253 7.94579513], weights: [0.79329994 0.04241225 0.16428781], train_wt_loss:  0.4796, val_wt_loss: 0.4224, train_grp_loss: [0.42397753 0.59134748 0.39102755], val_grp_loss: [0.41819951 0.62501796 0.40567774], train_hist_grp_loss: [1922.60266932 1629.72625828 1765.14451357], cur_train_grp_loss: [0.42400277 0.59126952 0.39104911], max_reward_err:  0.0557, max_reward_err_index: 1, max_kl_dist:  0.8241, max_kl_dist_index: 1, max_train_grp_loss:  0.5913, max_train_grp_loss_index: 1, max_val_grp_loss:  0.6250, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.5913, max_cur_train_grp_loss_index: 1, 
2024-09-17 15:01:44,926 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  4000, train_loss:  0.0016, val_loss:  0.0005, grad_norm: 0.0345, live_grad: 0.0000, reward_err: 0.0144, 0.0557, 0.0004, KL_dist: 0.5356, 0.8422, 0.5135, param: [4.93771159 6.89293574 5.04675189 8.02840209], weights: [0.79118026 0.05025384 0.15856589], train_wt_loss:  0.4814, val_wt_loss: 0.4220, train_grp_loss: [0.42153418 0.59875183 0.38893289], val_grp_loss: [0.41583429 0.63342855 0.40375846], train_hist_grp_loss: [1964.8781109  1689.23422958 1804.14255027], cur_train_grp_loss: [0.42155778 0.59868192 0.38895321], max_reward_err:  0.0557, max_reward_err_index: 1, max_kl_dist:  0.8422, max_kl_dist_index: 1, max_train_grp_loss:  0.5988, max_train_grp_loss_index: 1, max_val_grp_loss:  0.6334, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.5987, max_cur_train_grp_loss_index: 1, 
2024-09-17 15:01:47,737 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  4100, train_loss:  0.0016, val_loss:  0.0005, grad_norm: 0.0346, live_grad: 0.0000, reward_err: 0.0141, 0.0562, 0.0004, KL_dist: 0.5451, 0.8592, 0.5243, param: [4.97614977 6.99409048 5.04785854 8.10362116], weights: [0.78728442 0.05996793 0.15274765], train_wt_loss:  0.4839, val_wt_loss: 0.4222, train_grp_loss: [0.41926758 0.60525843 0.38697008], val_grp_loss: [0.41364497 0.64087016 0.40192449], train_hist_grp_loss: [2006.91774606 1749.43978079 1842.93751224], cur_train_grp_loss: [0.41928928 0.60519846 0.386989  ], max_reward_err:  0.0562, max_reward_err_index: 1, max_kl_dist:  0.8592, max_kl_dist_index: 1, max_train_grp_loss:  0.6053, max_train_grp_loss_index: 1, max_val_grp_loss:  0.6409, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.6052, max_cur_train_grp_loss_index: 1, 
2024-09-17 15:01:50,542 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  4200, train_loss:  0.0017, val_loss:  0.0005, grad_norm: 0.0346, live_grad: 0.0000, reward_err: 0.0141, 0.0560, 0.0004, KL_dist: 0.5547, 0.8749, 0.5349, param: [5.01891824 7.08928557 5.0531588  8.16998533], weights: [0.78126985 0.07194814 0.14678201], train_wt_loss:  0.4874, val_wt_loss: 0.4232, train_grp_loss: [0.41720704 0.61065957 0.38515727], val_grp_loss: [0.41166035 0.64711093 0.40018488], train_hist_grp_loss: [2048.74065235 1810.24315109 1881.54345027], cur_train_grp_loss: [0.41722652 0.6106118  0.38517458], max_reward_err:  0.0560, max_reward_err_index: 1, max_kl_dist:  0.8749, max_kl_dist_index: 1, max_train_grp_loss:  0.6107, max_train_grp_loss_index: 1, max_val_grp_loss:  0.6471, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.6106, max_cur_train_grp_loss_index: 1, 
2024-09-17 15:01:53,356 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  4300, train_loss:  0.0017, val_loss:  0.0005, grad_norm: 0.0346, live_grad: 0.0000, reward_err: 0.0139, 0.0560, 0.0003, KL_dist: 0.5643, 0.8888, 0.5451, param: [5.06702587 7.17734014 5.06362773 8.22576314], weights: [0.77276437 0.08661761 0.14061801], train_wt_loss:  0.4921, val_wt_loss: 0.4251, train_grp_loss: [0.41538801 0.61471181 0.38351669], val_grp_loss: [0.40991527 0.65187864 0.39855105], train_hist_grp_loss: [2090.36913776 1871.52203988 1919.97642912], cur_train_grp_loss: [0.41540487 0.61467885 0.38353216], max_reward_err:  0.0560, max_reward_err_index: 1, max_kl_dist:  0.8888, max_kl_dist_index: 1, max_train_grp_loss:  0.6147, max_train_grp_loss_index: 1, max_val_grp_loss:  0.6519, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.6147, max_cur_train_grp_loss_index: 1, 
2024-09-17 15:01:56,144 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  4400, train_loss:  0.0017, val_loss:  0.0005, grad_norm: 0.0345, live_grad: 0.0000, reward_err: 0.0139, 0.0560, 0.0003, KL_dist: 0.5738, 0.9008, 0.5547, param: [5.12163255 7.25684763 5.08038469 8.26897194], weights: [0.7613981  0.10439103 0.13421087], train_wt_loss:  0.4979, val_wt_loss: 0.4279, train_grp_loss: [0.41385229 0.6171385  0.38207503], val_grp_loss: [0.40845097 0.65486329 0.39703716], train_hist_grp_loss: [2131.82936943 1933.12811381 1958.25495589], cur_train_grp_loss: [0.41386609 0.61712326 0.38208837], max_reward_err:  0.0560, max_reward_err_index: 1, max_kl_dist:  0.9008, max_kl_dist_index: 1, max_train_grp_loss:  0.6171, max_train_grp_loss_index: 1, max_val_grp_loss:  0.6549, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.6171, max_cur_train_grp_loss_index: 1, 
2024-09-17 15:01:58,979 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  4500, train_loss:  0.0017, val_loss:  0.0005, grad_norm: 0.0343, live_grad: 0.0000, reward_err: 0.0139, 0.0558, 0.0003, KL_dist: 0.5833, 0.9104, 0.5638, param: [5.1840166  7.32618429 5.10466452 8.29743644], weights: [0.74685744 0.12561167 0.12753089], train_wt_loss:  0.5051, val_wt_loss: 0.4316, train_grp_loss: [0.41264757 0.61763901 0.38086331], val_grp_loss: [0.40731465 0.65572701 0.39566036], train_hist_grp_loss: [2173.15199479 1994.88407526 1996.40042293], cur_train_grp_loss: [0.41265781 0.61764456 0.38087417], max_reward_err:  0.0558, max_reward_err_index: 1, max_kl_dist:  0.9104, max_kl_dist_index: 1, max_train_grp_loss:  0.6176, max_train_grp_loss_index: 1, max_val_grp_loss:  0.6557, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.6176, max_cur_train_grp_loss_index: 1, 
2024-09-17 15:02:01,785 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  4600, train_loss:  0.0016, val_loss:  0.0005, grad_norm: 0.0341, live_grad: 0.0000, reward_err: 0.0139, 0.0552, 0.0003, KL_dist: 0.5927, 0.9171, 0.5723, param: [5.25550431 7.38355452 5.13775381 8.30891075], weights: [0.72896231 0.15046287 0.12057483], train_wt_loss:  0.5133, val_wt_loss: 0.4362, train_grp_loss: [0.4118259  0.61590721 0.37991621], val_grp_loss: [0.40655797 0.6541244  0.39444078], train_hist_grp_loss: [2214.37266439 2056.58209276 2034.43751544], cur_train_grp_loss: [0.41183204 0.61593654 0.37992425], max_reward_err:  0.0552, max_reward_err_index: 1, max_kl_dist:  0.9171, max_kl_dist_index: 1, max_train_grp_loss:  0.6159, max_train_grp_loss_index: 1, max_val_grp_loss:  0.6541, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.6159, max_cur_train_grp_loss_index: 1, 
2024-09-17 15:02:04,587 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  4700, train_loss:  0.0016, val_loss:  0.0005, grad_norm: 0.0338, live_grad: 0.0000, reward_err: 0.0144, 0.0538, 0.0004, KL_dist: 0.6022, 0.9208, 0.5799, param: [5.33735401 7.42708669 5.18088451 8.30127585], weights: [0.70775835 0.17886397 0.11337768], train_wt_loss:  0.5224, val_wt_loss: 0.4414, train_grp_loss: [0.41144054 0.6116608  0.3792705 ], val_grp_loss: [0.40623419 0.64973504 0.39340114], train_hist_grp_loss: [2255.53232599 2117.98461288 2072.39450787], cur_train_grp_loss: [0.41144206 0.61171651 0.37927534], max_reward_err:  0.0538, max_reward_err_index: 1, max_kl_dist:  0.9208, max_kl_dist_index: 1, max_train_grp_loss:  0.6117, max_train_grp_loss_index: 1, max_val_grp_loss:  0.6497, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.6117, max_cur_train_grp_loss_index: 1, 
2024-09-17 15:02:07,392 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  4800, train_loss:  0.0016, val_loss:  0.0005, grad_norm: 0.0334, live_grad: 0.0000, reward_err: 0.0148, 0.0531, 0.0005, KL_dist: 0.6116, 0.9211, 0.5868, param: [5.430597   7.4549871  5.23508692 8.27280629], weights: [0.68360345 0.21037523 0.10602132], train_wt_loss:  0.5318, val_wt_loss: 0.4468, train_grp_loss: [0.41154138 0.60468024 0.3789624 ], val_grp_loss: [0.40639359 0.64230714 0.39256576], train_hist_grp_loss: [2296.6771324  2178.82860513 2110.30335073], cur_train_grp_loss: [0.41153782 0.60476406 0.3789637 ], max_reward_err:  0.0531, max_reward_err_index: 1, max_kl_dist:  0.9211, max_kl_dist_index: 1, max_train_grp_loss:  0.6047, max_train_grp_loss_index: 1, max_val_grp_loss:  0.6423, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.6048, max_cur_train_grp_loss_index: 1, 
2024-09-17 15:02:10,194 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  4900, train_loss:  0.0016, val_loss:  0.0005, grad_norm: 0.0328, live_grad: 0.0000, reward_err: 0.0156, 0.0525, 0.0007, KL_dist: 0.6212, 0.9177, 0.5930, param: [5.53585477 7.46574486 5.30101891 8.22247212], weights: [0.65721651 0.24414813 0.09863536], train_wt_loss:  0.5408, val_wt_loss: 0.4518, train_grp_loss: [0.41216884 0.5948519  0.3790239 ], val_grp_loss: [0.40707764 0.63170628 0.39195877], train_hist_grp_loss: [2337.85781023 2238.83397285 2148.19944112], cur_train_grp_loss: [0.41215986 0.59496431 0.37902137], max_reward_err:  0.0525, max_reward_err_index: 1, max_kl_dist:  0.9177, max_kl_dist_index: 1, max_train_grp_loss:  0.5949, max_train_grp_loss_index: 1, max_val_grp_loss:  0.6317, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.5950, max_cur_train_grp_loss_index: 1, 
2024-09-17 15:02:13,003 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  5000, train_loss:  0.0016, val_loss:  0.0005, grad_norm: 0.0322, live_grad: 0.0000, reward_err: 0.0164, 0.0517, 0.0009, KL_dist: 0.6310, 0.9109, 0.5985, param: [5.65316942 7.45836035 5.37880516 8.15021362], weights: [0.62965741 0.27895571 0.09138687], train_wt_loss:  0.5485, val_wt_loss: 0.4559, train_grp_loss: [0.4133474  0.58220586 0.37947846], val_grp_loss: [0.40831246 0.61795889 0.39160158], train_hist_grp_loss: [2379.12839248 2297.71610754 2186.12098999], cur_train_grp_loss: [0.41333286 0.58234577 0.37947192], max_reward_err:  0.0517, max_reward_err_index: 1, max_kl_dist:  0.9109, max_kl_dist_index: 1, max_train_grp_loss:  0.5822, max_train_grp_loss_index: 1, max_val_grp_loss:  0.6180, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.5823, max_cur_train_grp_loss_index: 1, 
2024-09-17 15:02:15,814 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  5100, train_loss:  0.0016, val_loss:  0.0005, grad_norm: 0.0315, live_grad: 0.0000, reward_err: 0.0179, 0.0494, 0.0013, KL_dist: 0.6413, 0.9007, 0.6037, param: [5.78189335 7.43255235 5.46792862 8.05711317], weights: [0.60222672 0.31331393 0.08445934], train_wt_loss:  0.5542, val_wt_loss: 0.4583, train_grp_loss: [0.41507987 0.56693725 0.38033674], val_grp_loss: [0.4101031  0.60127751 0.39150994], train_hist_grp_loss: [2420.54432773 2355.20149601 2224.10795333], cur_train_grp_loss: [0.41505986 0.56710187 0.38032616], max_reward_err:  0.0494, max_reward_err_index: 1, max_kl_dist:  0.9007, max_kl_dist_index: 1, max_train_grp_loss:  0.5669, max_train_grp_loss_index: 1, max_val_grp_loss:  0.6013, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.5671, max_cur_train_grp_loss_index: 1, 
2024-09-17 15:02:18,633 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  5200, train_loss:  0.0016, val_loss:  0.0005, grad_norm: 0.0306, live_grad: 0.0000, reward_err: 0.0193, 0.0473, 0.0018, KL_dist: 0.6522, 0.8876, 0.6087, param: [5.92067515 7.38889412 5.56720854 7.94540733], weights: [0.57630561 0.34566834 0.07802605], train_wt_loss:  0.5572, val_wt_loss: 0.4588, train_grp_loss: [0.41734383 0.54940291 0.3815932 ], val_grp_loss: [0.41242972 0.58205852 0.39169081], train_hist_grp_loss: [2462.16011456 2411.04428157 2262.20057386], cur_train_grp_loss: [0.4173187  0.54958795 0.38157873], max_reward_err:  0.0473, max_reward_err_index: 1, max_kl_dist:  0.8876, max_kl_dist_index: 1, max_train_grp_loss:  0.5494, max_train_grp_loss_index: 1, max_val_grp_loss:  0.5821, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.5496, max_cur_train_grp_loss_index: 1, 
2024-09-17 15:02:21,440 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  5300, train_loss:  0.0015, val_loss:  0.0005, grad_norm: 0.0297, live_grad: 0.0000, reward_err: 0.0209, 0.0437, 0.0024, KL_dist: 0.6639, 0.8723, 0.6138, param: [6.0675514  7.328844   5.67487545 7.81832766], weights: [0.55318331 0.37459078 0.07222591], train_wt_loss:  0.5573, val_wt_loss: 0.4571, train_grp_loss: [0.42009109 0.53009252 0.38322442], val_grp_loss: [0.41524669 0.56085062 0.39213999], train_hist_grp_loss: [2504.02672534 2465.0412006  2300.43766203], cur_train_grp_loss: [0.42006145 0.53029257 0.38320638], max_reward_err:  0.0437, max_reward_err_index: 1, max_kl_dist:  0.8723, max_kl_dist_index: 1, max_train_grp_loss:  0.5301, max_train_grp_loss_index: 1, max_val_grp_loss:  0.5609, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.5303, max_cur_train_grp_loss_index: 1, 
2024-09-17 15:02:24,248 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  5400, train_loss:  0.0015, val_loss:  0.0004, grad_norm: 0.0288, live_grad: 0.0000, reward_err: 0.0234, 0.0417, 0.0034, KL_dist: 0.6764, 0.8553, 0.6192, param: [6.22012155 7.25466489 5.78872391 7.679812  ], weights: [0.533922   0.39892951 0.06714849], train_wt_loss:  0.5546, val_wt_loss: 0.4533, train_grp_loss: [0.42325022 0.5095812  0.38518927], val_grp_loss: [0.41848477 0.53830143 0.39284071], train_hist_grp_loss: [2546.18913037 2517.04262952 2338.8547993 ], cur_train_grp_loss: [0.42321687 0.50979027 0.38516815], max_reward_err:  0.0417, max_reward_err_index: 1, max_kl_dist:  0.8553, max_kl_dist_index: 1, max_train_grp_loss:  0.5096, max_train_grp_loss_index: 1, max_val_grp_loss:  0.5383, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.5098, max_cur_train_grp_loss_index: 1, 
2024-09-17 15:02:27,049 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  5500, train_loss:  0.0015, val_loss:  0.0004, grad_norm: 0.0278, live_grad: 0.0000, reward_err: 0.0254, 0.0401, 0.0043, KL_dist: 0.6898, 0.8376, 0.6252, param: [6.37576181 7.16925605 5.90630386 7.53416014], weights: [0.5192872  0.41788223 0.06283057], train_wt_loss:  0.5495, val_wt_loss: 0.4479, train_grp_loss: [0.42673137 0.48847535 0.38743098], val_grp_loss: [0.42205554 0.51509546 0.39376375], train_hist_grp_loss: [2588.68419761 2566.95845268 2377.48265632], cur_train_grp_loss: [0.42669529 0.48868738 0.38740741], max_reward_err:  0.0401, max_reward_err_index: 1, max_kl_dist:  0.8376, max_kl_dist_index: 1, max_train_grp_loss:  0.4885, max_train_grp_loss_index: 1, max_val_grp_loss:  0.5151, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.4887, max_cur_train_grp_loss_index: 1, 
2024-09-17 15:02:29,845 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  5600, train_loss:  0.0015, val_loss:  0.0004, grad_norm: 0.0267, live_grad: 0.0000, reward_err: 0.0271, 0.0370, 0.0051, KL_dist: 0.7039, 0.8197, 0.6319, param: [6.53183155 7.07593697 6.02510924 7.38570732], weights: [0.50974176 0.43099622 0.05926202], train_wt_loss:  0.5428, val_wt_loss: 0.4413, train_grp_loss: [0.43043238 0.46736295 0.38988047], val_grp_loss: [0.42585738 0.49189638 0.39486874], train_hist_grp_loss: [2631.53914871 2614.75865425 2416.34558532], cur_train_grp_loss: [0.43039464 0.4675723  0.38985519], max_reward_err:  0.0370, max_reward_err_index: 1, max_kl_dist:  0.8197, max_kl_dist_index: 1, max_train_grp_loss:  0.4674, max_train_grp_loss_index: 1, max_val_grp_loss:  0.4919, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.4676, max_cur_train_grp_loss_index: 1, 
2024-09-17 15:02:32,650 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  5700, train_loss:  0.0014, val_loss:  0.0004, grad_norm: 0.0257, live_grad: 0.0000, reward_err: 0.0304, 0.0359, 0.0068, KL_dist: 0.7187, 0.8023, 0.6392, param: [6.6858403  6.97822298 6.14273455 7.2385636 ], weights: [0.50548083 0.43812253 0.05639664], train_wt_loss:  0.5351, val_wt_loss: 0.4342, train_grp_loss: [0.43424511 0.44677576 0.39246046], val_grp_loss: [0.42978158 0.46930241 0.39610661], train_hist_grp_loss: [2674.77064151 2660.46949026 2455.46058978], cur_train_grp_loss: [0.43420679 0.44697747 0.39243428], max_reward_err:  0.0359, max_reward_err_index: 1, max_kl_dist:  0.8023, max_kl_dist_index: 1, max_train_grp_loss:  0.4468, max_train_grp_loss_index: 1, max_val_grp_loss:  0.4693, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.4470, max_cur_train_grp_loss_index: 1, 
2024-09-17 15:02:35,452 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  5800, train_loss:  0.0014, val_loss:  0.0004, grad_norm: 0.0247, live_grad: 0.0000, reward_err: 0.0325, 0.0350, 0.0080, KL_dist: 0.7340, 0.7860, 0.6471, param: [6.83556248 6.87962097 6.25698698 7.09643573], weights: [0.50648114 0.43935523 0.05416363], train_wt_loss:  0.5273, val_wt_loss: 0.4272, train_grp_loss: [0.43806113 0.42716563 0.39508978], val_grp_loss: [0.43371827 0.44781819 0.39742256], train_hist_grp_loss: [2718.38446067 2704.16657687 2494.83671675], cur_train_grp_loss: [0.4380233  0.42735563 0.39506351], max_reward_err:  0.0350, max_reward_err_index: 1, max_kl_dist:  0.7860, max_kl_dist_index: 1, max_train_grp_loss:  0.4381, max_train_grp_loss_index: 0, max_val_grp_loss:  0.4478, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.4380, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:02:38,259 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  5900, train_loss:  0.0014, val_loss:  0.0004, grad_norm: 0.0238, live_grad: 0.0000, reward_err: 0.0334, 0.0343, 0.0085, KL_dist: 0.7495, 0.7712, 0.6556, param: [6.97910291 6.78345979 6.36595586 6.96252362], weights: [0.51254525 0.43497747 0.05247728], train_wt_loss:  0.5200, val_wt_loss: 0.4209, train_grp_loss: [0.44177676 0.40889372 0.39768745], val_grp_loss: [0.43756152 0.42784213 0.3987593 ], train_hist_grp_loss: [2762.37574588 2745.96626955 2534.4748724 ], cur_train_grp_loss: [0.44174042 0.40906885 0.39766189], max_reward_err:  0.0343, max_reward_err_index: 1, max_kl_dist:  0.7712, max_kl_dist_index: 1, max_train_grp_loss:  0.4418, max_train_grp_loss_index: 0, max_val_grp_loss:  0.4376, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4417, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:02:41,054 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  6000, train_loss:  0.0014, val_loss:  0.0004, grad_norm: 0.0229, live_grad: 0.0000, reward_err: 0.0349, 0.0334, 0.0094, KL_dist: 0.7649, 0.7583, 0.6645, param: [7.11492407 6.69275889 6.46804832 6.83947294], weights: [0.52333245 0.42542344 0.0512441 ], train_wt_loss:  0.5139, val_wt_loss: 0.4157, train_grp_loss: [0.44529699 0.39222946 0.40017646], val_grp_loss: [0.44121354 0.40966569 0.40006029], train_hist_grp_loss: [2806.72966783 2786.0164756  2574.36803271], cur_train_grp_loss: [0.44526304 0.39238747 0.40015234], max_reward_err:  0.0349, max_reward_err_index: 0, max_kl_dist:  0.7649, max_kl_dist_index: 0, max_train_grp_loss:  0.4453, max_train_grp_loss_index: 0, max_val_grp_loss:  0.4412, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4453, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:02:43,886 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  6100, train_loss:  0.0014, val_loss:  0.0004, grad_norm: 0.0220, live_grad: 0.0000, reward_err: 0.0360, 0.0322, 0.0101, KL_dist: 0.7800, 0.7474, 0.6735, param: [7.24184774 6.61013307 6.56200167 6.72936451], weights: [0.5383775  0.41125463 0.05036787], train_wt_loss:  0.5092, val_wt_loss: 0.4118, train_grp_loss: [0.44853867 0.37735617 0.402487  ], val_grp_loss: [0.44458816 0.39348093 0.40127258], train_hist_grp_loss: [2851.42246156 2824.48771738 2614.50180438], cur_train_grp_loss: [0.44850788 0.37749563 0.40246499], max_reward_err:  0.0360, max_reward_err_index: 0, max_kl_dist:  0.7800, max_kl_dist_index: 0, max_train_grp_loss:  0.4485, max_train_grp_loss_index: 0, max_val_grp_loss:  0.4446, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4485, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:02:46,691 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  6200, train_loss:  0.0014, val_loss:  0.0004, grad_norm: 0.0213, live_grad: 0.0000, reward_err: 0.0364, 0.0313, 0.0104, KL_dist: 0.7945, 0.7386, 0.6826, param: [7.35904097 6.53772926 6.64688088 6.63372595], weights: [0.55710364 0.39314306 0.0497533 ], train_wt_loss:  0.5061, val_wt_loss: 0.4093, train_grp_loss: [0.45143284 0.36438042 0.40455911], val_grp_loss: [0.44761335 0.37939279 0.40234935], train_hist_grp_loss: [2896.42273274 2861.5649612  2654.85528067], cur_train_grp_loss: [0.45140581 0.3645006  0.40453974], max_reward_err:  0.0364, max_reward_err_index: 0, max_kl_dist:  0.7945, max_kl_dist_index: 0, max_train_grp_loss:  0.4514, max_train_grp_loss_index: 0, max_val_grp_loss:  0.4476, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4514, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:02:49,522 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  6300, train_loss:  0.0013, val_loss:  0.0004, grad_norm: 0.0206, live_grad: 0.0000, reward_err: 0.0368, 0.0293, 0.0106, KL_dist: 0.8082, 0.7320, 0.6915, param: [7.46599319 6.4771919  6.72206664 6.5535573 ], weights: [0.57883791 0.37185272 0.04930937], train_wt_loss:  0.5047, val_wt_loss: 0.4083, train_grp_loss: [0.45392619 0.35334333 0.40634459], val_grp_loss: [0.45023302 0.36743349 0.40325173], train_hist_grp_loss: [2941.69295636 2897.44049255 2695.40212813], cur_train_grp_loss: [0.45390338 0.3534441  0.40632828], max_reward_err:  0.0368, max_reward_err_index: 0, max_kl_dist:  0.8082, max_kl_dist_index: 0, max_train_grp_loss:  0.4539, max_train_grp_loss_index: 0, max_val_grp_loss:  0.4502, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4539, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:02:52,344 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  6400, train_loss:  0.0013, val_loss:  0.0004, grad_norm: 0.0200, live_grad: 0.0000, reward_err: 0.0368, 0.0280, 0.0106, KL_dist: 0.8209, 0.7275, 0.7002, param: [7.56248764 6.42965457 6.78723618 6.48936732], weights: [0.60283514 0.34821233 0.04895254], train_wt_loss:  0.5049, val_wt_loss: 0.4085, train_grp_loss: [0.45598183 0.34423234 0.40780825], val_grp_loss: [0.45240787 0.35757721 0.40395015], train_hist_grp_loss: [2987.19108722 2932.30795403 2736.11183143], cur_train_grp_loss: [0.45596352 0.34431407 0.40779529], max_reward_err:  0.0368, max_reward_err_index: 0, max_kl_dist:  0.8209, max_kl_dist_index: 0, max_train_grp_loss:  0.4560, max_train_grp_loss_index: 0, max_val_grp_loss:  0.4524, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4560, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:02:55,146 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  6500, train_loss:  0.0013, val_loss:  0.0004, grad_norm: 0.0196, live_grad: 0.0000, reward_err: 0.0369, 0.0280, 0.0107, KL_dist: 0.8325, 0.7251, 0.7084, param: [7.64856827 6.39575608 6.84233785 6.44121971], weights: [0.62831281 0.32307733 0.04860986], train_wt_loss:  0.5063, val_wt_loss: 0.4097, train_grp_loss: [0.4575791  0.33699278 0.40892825], val_grp_loss: [0.45411538 0.34975394 0.40442485], train_hist_grp_loss: [3032.8721991  2966.35755494 2776.95101662], cur_train_grp_loss: [0.45756543 0.33705617 0.40891879], max_reward_err:  0.0369, max_reward_err_index: 0, max_kl_dist:  0.8325, max_kl_dist_index: 0, max_train_grp_loss:  0.4576, max_train_grp_loss_index: 0, max_val_grp_loss:  0.4541, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4576, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:02:57,944 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  6600, train_loss:  0.0013, val_loss:  0.0004, grad_norm: 0.0192, live_grad: 0.0000, reward_err: 0.0372, 0.0273, 0.0110, KL_dist: 0.8430, 0.7245, 0.7162, param: [7.72450282 6.37567878 6.88755928 6.40878912], weights: [0.65449463 0.29728361 0.04822176], train_wt_loss:  0.5087, val_wt_loss: 0.4117, train_grp_loss: [0.45871265 0.33153845 0.40969563], val_grp_loss: [0.45534891 0.34386188 0.40466577], train_hist_grp_loss: [3078.69006868 2999.77239223 2817.88477023], cur_train_grp_loss: [0.45870359 0.3315845  0.4096897 ], max_reward_err:  0.0372, max_reward_err_index: 0, max_kl_dist:  0.8430, max_kl_dist_index: 0, max_train_grp_loss:  0.4587, max_train_grp_loss_index: 0, max_val_grp_loss:  0.4553, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4587, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:03:00,756 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  6700, train_loss:  0.0013, val_loss:  0.0004, grad_norm: 0.0190, live_grad: 0.0000, reward_err: 0.0381, 0.0273, 0.0116, KL_dist: 0.8524, 0.7258, 0.7235, param: [7.79074234 6.36920553 6.9232898  6.39142599], weights: [0.68065646 0.27159969 0.04774385], train_wt_loss:  0.5118, val_wt_loss: 0.4143, train_grp_loss: [0.45939068 0.32776115 0.41011313], val_grp_loss: [0.45611599 0.33977799 0.40467177], train_hist_grp_loss: [3124.59862568 3032.72578047 2858.87787518], cur_train_grp_loss: [0.4593861  0.32779102 0.41011065], max_reward_err:  0.0381, max_reward_err_index: 0, max_kl_dist:  0.8524, max_kl_dist_index: 0, max_train_grp_loss:  0.4594, max_train_grp_loss_index: 0, max_val_grp_loss:  0.4561, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4594, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:03:03,574 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  6800, train_loss:  0.0013, val_loss:  0.0004, grad_norm: 0.0188, live_grad: 0.0000, reward_err: 0.0383, 0.0269, 0.0117, KL_dist: 0.8606, 0.7287, 0.7303, param: [7.84787882 6.37579009 6.95007859 6.38822729], weights: [0.70616706 0.24668555 0.0471474 ], train_wt_loss:  0.5152, val_wt_loss: 0.4170, train_grp_loss: [0.45963276 0.32553878 0.41019343], val_grp_loss: [0.45643602 0.33736681 0.40444943], train_hist_grp_loss: [3170.55320309 3065.37946403 2899.89589732], cur_train_grp_loss: [0.45963241 0.32555373 0.41019423], max_reward_err:  0.0383, max_reward_err_index: 0, max_kl_dist:  0.8606, max_kl_dist_index: 0, max_train_grp_loss:  0.4596, max_train_grp_loss_index: 0, max_val_grp_loss:  0.4564, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4596, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:03:06,385 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  6900, train_loss:  0.0013, val_loss:  0.0004, grad_norm: 0.0187, live_grad: 0.0000, reward_err: 0.0390, 0.0267, 0.0123, KL_dist: 0.8677, 0.7332, 0.7366, param: [7.8966027  6.39463444 6.96859101 6.39810902], weights: [0.73051671 0.22306482 0.04641847], train_wt_loss:  0.5186, val_wt_loss: 0.4197, train_grp_loss: [0.45946715 0.3247421  0.40995701], val_grp_loss: [0.45633757 0.3364874  0.40401145], train_hist_grp_loss: [3216.51154255 3097.88257364 2940.90607481], cur_train_grp_loss: [0.45947071 0.32474344 0.40996086], max_reward_err:  0.0390, max_reward_err_index: 0, max_kl_dist:  0.8677, max_kl_dist_index: 0, max_train_grp_loss:  0.4595, max_train_grp_loss_index: 0, max_val_grp_loss:  0.4563, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4595, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:03:09,196 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  7000, train_loss:  0.0013, val_loss:  0.0004, grad_norm: 0.0187, live_grad: 0.0000, reward_err: 0.0390, 0.0267, 0.0123, KL_dist: 0.8738, 0.7390, 0.7424, param: [7.93766283 6.42476631 6.97956606 6.41987578], weights: [0.75333046 0.20111372 0.04555583], train_wt_loss:  0.5218, val_wt_loss: 0.4222, train_grp_loss: [0.45892817 0.32524006 0.40942989], val_grp_loss: [0.45585563 0.33699876 0.40337497], train_hist_grp_loss: [3262.43453447 3130.37118747 2981.87798678], cur_train_grp_loss: [0.45893528 0.3252291  0.40943651], max_reward_err:  0.0390, max_reward_err_index: 0, max_kl_dist:  0.8738, max_kl_dist_index: 0, max_train_grp_loss:  0.4589, max_train_grp_loss_index: 0, max_val_grp_loss:  0.4559, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4589, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:03:12,012 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  7100, train_loss:  0.0013, val_loss:  0.0004, grad_norm: 0.0188, live_grad: 0.0000, reward_err: 0.0391, 0.0270, 0.0124, KL_dist: 0.8791, 0.7460, 0.7479, param: [7.97183105 6.46511066 6.98377783 6.45228274], weights: [0.77436599 0.18106594 0.04456807], train_wt_loss:  0.5247, val_wt_loss: 0.4244, train_grp_loss: [0.45805371 0.32690387 0.40864152], val_grp_loss: [0.45502898 0.33876369 0.40255997], train_hist_grp_loss: [3308.28669771 3162.96836243 3022.78400055], cur_train_grp_loss: [0.45806398 0.32688188 0.40865059], max_reward_err:  0.0391, max_reward_err_index: 0, max_kl_dist:  0.8791, max_kl_dist_index: 0, max_train_grp_loss:  0.4581, max_train_grp_loss_index: 0, max_val_grp_loss:  0.4550, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4581, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:03:14,824 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  7200, train_loss:  0.0013, val_loss:  0.0004, grad_norm: 0.0189, live_grad: 0.0000, reward_err: 0.0393, 0.0270, 0.0125, KL_dist: 0.8836, 0.7542, 0.7529, param: [7.99987302 6.51455099 6.98200298 6.49408725], weights: [0.79349951 0.16302993 0.04347056], train_wt_loss:  0.5272, val_wt_loss: 0.4262, train_grp_loss: [0.45688303 0.32960991 0.40762283], val_grp_loss: [0.45389794 0.3416515  0.40158784], train_hist_grp_loss: [3354.03642441 3195.784512   3063.59951636], cur_train_grp_loss: [0.45689608 0.32957808 0.40763406], max_reward_err:  0.0393, max_reward_err_index: 0, max_kl_dist:  0.8836, max_kl_dist_index: 0, max_train_grp_loss:  0.4569, max_train_grp_loss_index: 0, max_val_grp_loss:  0.4539, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4569, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:03:17,645 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  7300, train_loss:  0.0013, val_loss:  0.0004, grad_norm: 0.0191, live_grad: 0.0000, reward_err: 0.0393, 0.0273, 0.0125, KL_dist: 0.8875, 0.7633, 0.7578, param: [8.02252606 6.5719779  6.97499556 6.54408828], weights: [0.81070418 0.14701331 0.0422825 ], train_wt_loss:  0.5291, val_wt_loss: 0.4275, train_grp_loss: [0.45545508 0.33324156 0.40640481], val_grp_loss: [0.45250255 0.34553966 0.4004802 ], train_hist_grp_loss: [3399.65602938 3228.91802215 3104.3030416 ], cur_train_grp_loss: [0.45547051 0.33320103 0.40641787], max_reward_err:  0.0393, max_reward_err_index: 0, max_kl_dist:  0.8875, max_kl_dist_index: 0, max_train_grp_loss:  0.4555, max_train_grp_loss_index: 0, max_val_grp_loss:  0.4525, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4555, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:03:20,444 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  7400, train_loss:  0.0013, val_loss:  0.0004, grad_norm: 0.0193, live_grad: 0.0000, reward_err: 0.0393, 0.0276, 0.0125, KL_dist: 0.8908, 0.7734, 0.7624, param: [8.04048377 6.63632451 6.96346914 6.6011539 ], weights: [0.82602589 0.13294955 0.04102456], train_wt_loss:  0.5305, val_wt_loss: 0.4284, train_grp_loss: [0.45380717 0.33769033 0.40501729], val_grp_loss: [0.45088123 0.3503146  0.399258  ], train_hist_grp_loss: [3445.12164929 3262.45601338 3144.87613268], cur_train_grp_loss: [0.45382462 0.33764213 0.40503191], max_reward_err:  0.0393, max_reward_err_index: 0, max_kl_dist:  0.8908, max_kl_dist_index: 0, max_train_grp_loss:  0.4538, max_train_grp_loss_index: 0, max_val_grp_loss:  0.4509, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4538, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:03:23,256 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  7500, train_loss:  0.0013, val_loss:  0.0004, grad_norm: 0.0195, live_grad: 0.0000, reward_err: 0.0382, 0.0288, 0.0119, KL_dist: 0.8937, 0.7842, 0.7668, param: [8.05438705 6.70658979 6.94808563 6.66423791], weights: [0.83955991 0.12072307 0.03971702], train_wt_loss:  0.5315, val_wt_loss: 0.4288, train_grp_loss: [0.45197417 0.34285619 0.40348826], val_grp_loss: [0.44906992 0.35587193 0.39794098], train_hist_grp_loss: [3490.41303716 3296.47517511 3185.30324314], cur_train_grp_loss: [0.45199331 0.34280129 0.40350416], max_reward_err:  0.0382, max_reward_err_index: 0, max_kl_dist:  0.8937, max_kl_dist_index: 0, max_train_grp_loss:  0.4520, max_train_grp_loss_index: 0, max_val_grp_loss:  0.4491, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4520, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:03:26,116 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  7600, train_loss:  0.0013, val_loss:  0.0004, grad_norm: 0.0198, live_grad: 0.0000, reward_err: 0.0382, 0.0294, 0.0119, KL_dist: 0.8963, 0.7958, 0.7712, param: [8.06481997 6.7818516  6.92944991 6.73238759], weights: [0.8514308  0.11019059 0.03837862], train_wt_loss:  0.5319, val_wt_loss: 0.4289, train_grp_loss: [0.44998805 0.34864758 0.40184338], val_grp_loss: [0.44710157 0.36211613 0.39654728], train_hist_grp_loss: [3535.51329208 3331.04261558 3225.57151246], cur_train_grp_loss: [0.45000857 0.34858685 0.40186033], max_reward_err:  0.0382, max_reward_err_index: 0, max_kl_dist:  0.8963, max_kl_dist_index: 0, max_train_grp_loss:  0.4500, max_train_grp_loss_index: 0, max_val_grp_loss:  0.4471, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4500, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:03:28,927 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  7700, train_loss:  0.0013, val_loss:  0.0004, grad_norm: 0.0201, live_grad: 0.0000, reward_err: 0.0382, 0.0297, 0.0119, KL_dist: 0.8987, 0.8080, 0.7754, param: [8.07230975 6.86127169 6.90810869 6.80474453], weights: [0.86177637 0.10119781 0.03702582], train_wt_loss:  0.5319, val_wt_loss: 0.4286, train_grp_loss: [0.44787768 0.35498091 0.40010583], val_grp_loss: [0.44500592 0.36896001 0.39509327], train_hist_grp_loss: [3580.40855716 3366.21668561 3265.67052416], cur_train_grp_loss: [0.44789932 0.35491515 0.4001236 ], max_reward_err:  0.0382, max_reward_err_index: 0, max_kl_dist:  0.8987, max_kl_dist_index: 0, max_train_grp_loss:  0.4479, max_train_grp_loss_index: 0, max_val_grp_loss:  0.4450, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4479, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:03:31,800 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  7800, train_loss:  0.0013, val_loss:  0.0004, grad_norm: 0.0205, live_grad: 0.0000, reward_err: 0.0383, 0.0310, 0.0120, KL_dist: 0.9008, 0.8207, 0.7797, param: [8.0773294  6.94409486 6.88455257 6.8805407 ], weights: [0.87073596 0.09359146 0.03567258], train_wt_loss:  0.5316, val_wt_loss: 0.4280, train_grp_loss: [0.44566889 0.36177995 0.39829628], val_grp_loss: [0.44280958 0.37632388 0.39359354], train_hist_grp_loss: [3625.08771054 3402.04774784 3305.59205469], cur_train_grp_loss: [0.44569138 0.36170988 0.39831467], max_reward_err:  0.0383, max_reward_err_index: 0, max_kl_dist:  0.9008, max_kl_dist_index: 0, max_train_grp_loss:  0.4457, max_train_grp_loss_index: 0, max_val_grp_loss:  0.4428, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4457, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:03:34,597 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  7900, train_loss:  0.0013, val_loss:  0.0004, grad_norm: 0.0208, live_grad: 0.0000, reward_err: 0.0383, 0.0320, 0.0120, KL_dist: 0.9029, 0.8339, 0.7841, param: [8.08030216 7.02964405 6.85922022 6.95909126], weights: [0.87844233 0.08722738 0.03433028], train_wt_loss:  0.5309, val_wt_loss: 0.4271, train_grp_loss: [0.44338459 0.36897501 0.39643302], val_grp_loss: [0.44053615 0.38413466 0.39206099], train_hist_grp_loss: [3669.54206707 3438.57887301 3345.32982876], cur_train_grp_loss: [0.44340773 0.36890132 0.39645187], max_reward_err:  0.0383, max_reward_err_index: 0, max_kl_dist:  0.9029, max_kl_dist_index: 0, max_train_grp_loss:  0.4434, max_train_grp_loss_index: 0, max_val_grp_loss:  0.4405, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4434, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:03:37,408 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  8000, train_loss:  0.0014, val_loss:  0.0004, grad_norm: 0.0212, live_grad: 0.0000, reward_err: 0.0383, 0.0327, 0.0120, KL_dist: 0.9049, 0.8475, 0.7884, param: [8.08160699 7.11731309 6.83250368 7.03978562], weights: [0.8850166  0.08197546 0.03300794], train_wt_loss:  0.5299, val_wt_loss: 0.4260, train_grp_loss: [0.44104508 0.37650212 0.39453218], val_grp_loss: [0.43820652 0.3923249  0.39050692], train_hist_grp_loss: [3713.76510192 3475.84645267 3384.87929077], cur_train_grp_loss: [0.44106869 0.3764254  0.39455133], max_reward_err:  0.0383, max_reward_err_index: 0, max_kl_dist:  0.9049, max_kl_dist_index: 0, max_train_grp_loss:  0.4410, max_train_grp_loss_index: 0, max_val_grp_loss:  0.4382, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4411, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:03:40,230 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  8100, train_loss:  0.0014, val_loss:  0.0004, grad_norm: 0.0215, live_grad: 0.0000, reward_err: 0.0380, 0.0331, 0.0118, KL_dist: 0.9070, 0.8615, 0.7929, param: [8.08158462 7.20655791 6.80475445 7.12207749], weights: [0.89056532 0.07772226 0.03171242], train_wt_loss:  0.5288, val_wt_loss: 0.4248, train_grp_loss: [0.43866835 0.38430205 0.39260792], val_grp_loss: [0.43583915 0.40083181 0.38894123], train_hist_grp_loss: [3757.75220265 3513.88072333 3424.2373985 ], cur_train_grp_loss: [0.43869225 0.38422288 0.39262724], max_reward_err:  0.0380, max_reward_err_index: 0, max_kl_dist:  0.9070, max_kl_dist_index: 0, max_train_grp_loss:  0.4387, max_train_grp_loss_index: 0, max_val_grp_loss:  0.4358, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4387, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:03:43,041 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  8200, train_loss:  0.0014, val_loss:  0.0004, grad_norm: 0.0219, live_grad: 0.0000, reward_err: 0.0380, 0.0331, 0.0118, KL_dist: 0.9090, 0.8758, 0.7974, param: [8.0805436  7.29688733 6.7762896  7.20547486], weights: [0.89517915 0.07437213 0.03044871], train_wt_loss:  0.5275, val_wt_loss: 0.4235, train_grp_loss: [0.43627037 0.39231947 0.39067274], val_grp_loss: [0.43345043 0.40959629 0.38737259], train_hist_grp_loss: [3801.50045302 3552.70620019 3463.40244178], cur_train_grp_loss: [0.43629441 0.3922384  0.3906921 ], max_reward_err:  0.0380, max_reward_err_index: 0, max_kl_dist:  0.9090, max_kl_dist_index: 0, max_train_grp_loss:  0.4363, max_train_grp_loss_index: 0, max_val_grp_loss:  0.4335, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4363, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:03:45,850 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  8300, train_loss:  0.0014, val_loss:  0.0004, grad_norm: 0.0222, live_grad: 0.0000, reward_err: 0.0380, 0.0333, 0.0118, KL_dist: 0.9112, 0.8903, 0.8021, param: [8.0787664  7.38785355 6.74739797 7.28952998], weights: [0.8989324  0.07184734 0.02922026], train_wt_loss:  0.5261, val_wt_loss: 0.4220, train_grp_loss: [0.43386546 0.40050206 0.3887377 ], val_grp_loss: [0.43105502 0.41856195 0.3858086 ], train_hist_grp_loss: [3845.00844928 3592.34202101 3502.373887  ], cur_train_grp_loss: [0.4338895  0.40041958 0.38875701], max_reward_err:  0.0380, max_reward_err_index: 0, max_kl_dist:  0.9112, max_kl_dist_index: 0, max_train_grp_loss:  0.4339, max_train_grp_loss_index: 0, max_val_grp_loss:  0.4311, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4339, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:03:48,664 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  8400, train_loss:  0.0014, val_loss:  0.0004, grad_norm: 0.0226, live_grad: 0.0000, reward_err: 0.0369, 0.0340, 0.0112, KL_dist: 0.9134, 0.9050, 0.8069, param: [8.07651518 7.47904305 6.71834612 7.37382983], weights: [0.90188324 0.07008758 0.02802918], train_wt_loss:  0.5246, val_wt_loss: 0.4205, train_grp_loss: [0.43146655 0.40879957 0.3868127 ], val_grp_loss: [0.42866613 0.4276742  0.38425601], train_hist_grp_loss: [3888.27614836 3632.80220131 3541.1522471 ], cur_train_grp_loss: [0.43149047 0.40871619 0.38683187], max_reward_err:  0.0369, max_reward_err_index: 0, max_kl_dist:  0.9134, max_kl_dist_index: 0, max_train_grp_loss:  0.4315, max_train_grp_loss_index: 0, max_val_grp_loss:  0.4287, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4315, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:03:51,494 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  8500, train_loss:  0.0014, val_loss:  0.0004, grad_norm: 0.0229, live_grad: 0.0000, reward_err: 0.0369, 0.0352, 0.0112, KL_dist: 0.9158, 0.9197, 0.8118, param: [8.07403743 7.57006756 6.68938397 7.45798693], weights: [0.90407409 0.06904938 0.02687654], train_wt_loss:  0.5230, val_wt_loss: 0.4190, train_grp_loss: [0.42908553 0.41716303 0.38490669], val_grp_loss: [0.42629588 0.43687927 0.38272084], train_hist_grp_loss: [3931.30474681 3674.09580238 3579.73897588], cur_train_grp_loss: [0.42910922 0.41707922 0.38492563], max_reward_err:  0.0369, max_reward_err_index: 0, max_kl_dist:  0.9197, max_kl_dist_index: 1, max_train_grp_loss:  0.4291, max_train_grp_loss_index: 0, max_val_grp_loss:  0.4369, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.4291, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:03:54,297 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  8600, train_loss:  0.0014, val_loss:  0.0004, grad_norm: 0.0233, live_grad: 0.0000, reward_err: 0.0367, 0.0352, 0.0111, KL_dist: 0.9184, 0.9346, 0.8169, param: [8.07157125 7.66055556 6.66075031 7.54163067], weights: [0.90553213 0.06870535 0.02576252], train_wt_loss:  0.5215, val_wt_loss: 0.4175, train_grp_loss: [0.42673351 0.42554382 0.38302791], val_grp_loss: [0.42395554 0.44612334 0.38120857], train_hist_grp_loss: [3974.09658872 3716.22701308 3618.13638527], cur_train_grp_loss: [0.42675685 0.42546009 0.38304653], max_reward_err:  0.0367, max_reward_err_index: 0, max_kl_dist:  0.9346, max_kl_dist_index: 1, max_train_grp_loss:  0.4267, max_train_grp_loss_index: 0, max_val_grp_loss:  0.4461, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.4268, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:03:57,102 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  8700, train_loss:  0.0014, val_loss:  0.0004, grad_norm: 0.0236, live_grad: 0.0000, reward_err: 0.0365, 0.0355, 0.0111, KL_dist: 0.9211, 0.9494, 0.8221, param: [8.06935052 7.75014394 6.63267793 7.62439902], weights: [0.90626981 0.06904355 0.02468663], train_wt_loss:  0.5200, val_wt_loss: 0.4160, train_grp_loss: [0.42442107 0.43389289 0.38118408], val_grp_loss: [0.42165585 0.4553516  0.37972426], train_hist_grp_loss: [4016.65510107 3759.19514591 3656.34758403], cur_train_grp_loss: [0.42444397 0.43380972 0.38120232], max_reward_err:  0.0365, max_reward_err_index: 0, max_kl_dist:  0.9494, max_kl_dist_index: 1, max_train_grp_loss:  0.4339, max_train_grp_loss_index: 1, max_val_grp_loss:  0.4554, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.4338, max_cur_train_grp_loss_index: 1, 
2024-09-17 15:03:59,919 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  8800, train_loss:  0.0014, val_loss:  0.0004, grad_norm: 0.0239, live_grad: 0.0000, reward_err: 0.0365, 0.0361, 0.0111, KL_dist: 0.9240, 0.9642, 0.8274, param: [8.06760986 7.83847004 6.60539873 7.70593048], weights: [0.90628518 0.070067   0.02364782], train_wt_loss:  0.5186, val_wt_loss: 0.4146, train_grp_loss: [0.42215856 0.44215981 0.37938263], val_grp_loss: [0.41940723 0.4645073  0.3782727 ], train_hist_grp_loss: [4058.98475503 3802.99454708 3694.3764367 ], cur_train_grp_loss: [0.4221809  0.44207772 0.37940041], max_reward_err:  0.0365, max_reward_err_index: 0, max_kl_dist:  0.9642, max_kl_dist_index: 1, max_train_grp_loss:  0.4422, max_train_grp_loss_index: 1, max_val_grp_loss:  0.4645, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.4421, max_cur_train_grp_loss_index: 1, 
2024-09-17 15:04:02,747 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  8900, train_loss:  0.0014, val_loss:  0.0004, grad_norm: 0.0242, live_grad: 0.0000, reward_err: 0.0358, 0.0361, 0.0107, KL_dist: 0.9270, 0.9788, 0.8328, param: [8.06658946 7.92516377 6.57914848 7.78585641], weights: [0.90556222 0.07179319 0.02264459], train_wt_loss:  0.5173, val_wt_loss: 0.4133, train_grp_loss: [0.41995627 0.45029198 0.37763083], val_grp_loss: [0.41722009 0.47353081 0.37685854], train_hist_grp_loss: [4101.09105208 3847.61441992 3732.22754141], cur_train_grp_loss: [0.41997796 0.4502115  0.37764808], max_reward_err:  0.0361, max_reward_err_index: 1, max_kl_dist:  0.9788, max_kl_dist_index: 1, max_train_grp_loss:  0.4503, max_train_grp_loss_index: 1, max_val_grp_loss:  0.4735, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.4502, max_cur_train_grp_loss_index: 1, 
2024-09-17 15:04:05,567 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  9000, train_loss:  0.0014, val_loss:  0.0004, grad_norm: 0.0245, live_grad: 0.0000, reward_err: 0.0358, 0.0361, 0.0107, KL_dist: 0.9303, 0.9933, 0.8383, param: [8.06653979 8.00983997 6.55417164 7.86379351], weights: [0.90407113 0.07425375 0.02167512], train_wt_loss:  0.5161, val_wt_loss: 0.4122, train_grp_loss: [0.41782474 0.45823369 0.37593603], val_grp_loss: [0.41510498 0.48235865 0.37548637], train_hist_grp_loss: [4142.98053362 3893.03856101 3769.90622578], cur_train_grp_loss: [0.41784567 0.45815541 0.37595267], max_reward_err:  0.0361, max_reward_err_index: 1, max_kl_dist:  0.9933, max_kl_dist_index: 1, max_train_grp_loss:  0.4582, max_train_grp_loss_index: 1, max_val_grp_loss:  0.4824, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.4582, max_cur_train_grp_loss_index: 1, 
2024-09-17 15:04:08,416 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  9100, train_loss:  0.0014, val_loss:  0.0004, grad_norm: 0.0248, live_grad: 0.0000, reward_err: 0.0343, 0.0364, 0.0099, KL_dist: 0.9338, 1.0075, 0.8440, param: [8.06772615 8.09209095 6.5307258  7.93933663], weights: [0.90176871 0.07749396 0.02073733], train_wt_loss:  0.5151, val_wt_loss: 0.4112, train_grp_loss: [0.41577492 0.46592531 0.37430575], val_grp_loss: [0.41307291 0.49092257 0.3741609 ], train_hist_grp_loss: [4184.6608134  3939.24500933 3807.41855984], cur_train_grp_loss: [0.41579498 0.46584984 0.37432171], max_reward_err:  0.0364, max_reward_err_index: 1, max_kl_dist:  1.0075, max_kl_dist_index: 1, max_train_grp_loss:  0.4659, max_train_grp_loss_index: 1, max_val_grp_loss:  0.4909, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.4658, max_cur_train_grp_loss_index: 1, 
2024-09-17 15:04:11,261 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  9200, train_loss:  0.0014, val_loss:  0.0004, grad_norm: 0.0251, live_grad: 0.0000, reward_err: 0.0332, 0.0367, 0.0093, KL_dist: 0.9375, 1.0213, 0.8497, param: [8.07043291 8.17147935 6.509086   8.01205201], weights: [0.89859897 0.08157205 0.01982898], train_wt_loss:  0.5144, val_wt_loss: 0.4103, train_grp_loss: [0.41381843 0.47330243 0.37274794], val_grp_loss: [0.41113549 0.49914863 0.37288701], train_hist_grp_loss: [4226.14063145 3986.20561067 3844.77138529], cur_train_grp_loss: [0.4138375  0.47323044 0.37276313], max_reward_err:  0.0367, max_reward_err_index: 1, max_kl_dist:  1.0213, max_kl_dist_index: 1, max_train_grp_loss:  0.4733, max_train_grp_loss_index: 1, max_val_grp_loss:  0.4991, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.4732, max_cur_train_grp_loss_index: 1, 
2024-09-17 15:04:14,090 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  9300, train_loss:  0.0014, val_loss:  0.0004, grad_norm: 0.0253, live_grad: 0.0000, reward_err: 0.0328, 0.0370, 0.0091, KL_dist: 0.9414, 1.0346, 0.8555, param: [8.07496737 8.24753156 6.48954851 8.08147114], weights: [0.89449433 0.08655797 0.01894771], train_wt_loss:  0.5139, val_wt_loss: 0.4097, train_grp_loss: [0.41196771 0.48029515 0.371271  ], val_grp_loss: [0.40930518 0.50695637 0.37166988], train_hist_grp_loss: [4267.42992826 4033.88550348 3881.97235989], cur_train_grp_loss: [0.41198565 0.48022737 0.37128534], max_reward_err:  0.0370, max_reward_err_index: 1, max_kl_dist:  1.0346, max_kl_dist_index: 1, max_train_grp_loss:  0.4803, max_train_grp_loss_index: 1, max_val_grp_loss:  0.5070, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.4802, max_cur_train_grp_loss_index: 1, 
2024-09-17 15:04:16,917 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  9400, train_loss:  0.0015, val_loss:  0.0004, grad_norm: 0.0255, live_grad: 0.0000, reward_err: 0.0325, 0.0370, 0.0090, KL_dist: 0.9455, 1.0474, 0.8614, param: [8.08166277 8.31973206 6.47243393 8.14708589], weights: [0.88937748 0.09253137 0.01809114], train_wt_loss:  0.5137, val_wt_loss: 0.4093, train_grp_loss: [0.41023619 0.48682748 0.36988403], val_grp_loss: [0.4075954  0.51425823 0.37051508], train_hist_grp_loss: [4308.53993697 4082.24253841 3919.03001575], cur_train_grp_loss: [0.41025287 0.4867647  0.36989743], max_reward_err:  0.0370, max_reward_err_index: 1, max_kl_dist:  1.0474, max_kl_dist_index: 1, max_train_grp_loss:  0.4868, max_train_grp_loss_index: 1, max_val_grp_loss:  0.5143, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.4868, max_cur_train_grp_loss_index: 1, 
2024-09-17 15:04:19,694 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  9500, train_loss:  0.0015, val_loss:  0.0004, grad_norm: 0.0257, live_grad: 0.0000, reward_err: 0.0323, 0.0370, 0.0089, KL_dist: 0.9498, 1.0596, 0.8673, param: [8.09088012 8.38751948 6.45808904 8.20834531], weights: [0.88316462 0.0995784  0.01725699], train_wt_loss:  0.5138, val_wt_loss: 0.4092, train_grp_loss: [0.40863846 0.49281706 0.36859686], val_grp_loss: [0.40602073 0.5209592  0.36942863], train_hist_grp_loss: [4349.48329009 4131.22665297 3955.95382929], cur_train_grp_loss: [0.40865373 0.49276013 0.3686092 ], max_reward_err:  0.0370, max_reward_err_index: 1, max_kl_dist:  1.0596, max_kl_dist_index: 1, max_train_grp_loss:  0.4928, max_train_grp_loss_index: 1, max_val_grp_loss:  0.5210, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.4928, max_cur_train_grp_loss_index: 1, 
2024-09-17 15:04:22,471 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  9600, train_loss:  0.0015, val_loss:  0.0004, grad_norm: 0.0259, live_grad: 0.0000, reward_err: 0.0320, 0.0374, 0.0088, KL_dist: 0.9544, 1.0710, 0.8732, param: [8.10300819 8.45028498 6.44688698 8.2646552 ], weights: [0.87577017 0.10778674 0.01644309], train_wt_loss:  0.5143, val_wt_loss: 0.4094, train_grp_loss: [0.40719026 0.49817525 0.36742012], val_grp_loss: [0.40459691 0.526957   0.36841709], train_hist_grp_loss: [4390.27413568 4180.77923484 3992.75429969], cur_train_grp_loss: [0.40720395 0.4981251  0.3674313 ], max_reward_err:  0.0374, max_reward_err_index: 1, max_kl_dist:  1.0710, max_kl_dist_index: 1, max_train_grp_loss:  0.4982, max_train_grp_loss_index: 1, max_val_grp_loss:  0.5270, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.4981, max_cur_train_grp_loss_index: 1, 
2024-09-17 15:04:25,263 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  9700, train_loss:  0.0015, val_loss:  0.0004, grad_norm: 0.0260, live_grad: 0.0000, reward_err: 0.0316, 0.0374, 0.0086, KL_dist: 0.9592, 1.0815, 0.8791, param: [8.11846081 8.50737433 6.43922487 8.31538152], weights: [0.86711362 0.11723878 0.0156476 ], train_wt_loss:  0.5152, val_wt_loss: 0.4099, train_grp_loss: [0.40590851 0.50280785 0.36636527], val_grp_loss: [0.40334087 0.53214296 0.36748754], train_hist_grp_loss: [4430.92825519 4230.83252412 4029.44303105], cur_train_grp_loss: [0.40592045 0.50276544 0.36637518], max_reward_err:  0.0374, max_reward_err_index: 1, max_kl_dist:  1.0815, max_kl_dist_index: 1, max_train_grp_loss:  0.5028, max_train_grp_loss_index: 1, max_val_grp_loss:  0.5321, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.5028, max_cur_train_grp_loss_index: 1, 
2024-09-17 15:04:28,043 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  9800, train_loss:  0.0015, val_loss:  0.0004, grad_norm: 0.0261, live_grad: 0.0000, reward_err: 0.0306, 0.0374, 0.0081, KL_dist: 0.9642, 1.0910, 0.8849, param: [8.13767072 8.55809489 6.43551808 8.35985894], weights: [0.85712869 0.12800222 0.01486909], train_wt_loss:  0.5165, val_wt_loss: 0.4108, train_grp_loss: [0.40481111 0.50661661 0.36544453], val_grp_loss: [0.40227054 0.53640376 0.36664762], train_hist_grp_loss: [4471.46317219 4281.30912337 4066.03281157], cur_train_grp_loss: [0.40482111 0.50658293 0.36545303], max_reward_err:  0.0374, max_reward_err_index: 1, max_kl_dist:  1.0910, max_kl_dist_index: 1, max_train_grp_loss:  0.5066, max_train_grp_loss_index: 1, max_val_grp_loss:  0.5364, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.5066, max_cur_train_grp_loss_index: 1, 
2024-09-17 15:04:30,815 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  9900, train_loss:  0.0015, val_loss:  0.0004, grad_norm: 0.0262, live_grad: 0.0000, reward_err: 0.0306, 0.0383, 0.0081, KL_dist: 0.9695, 1.0994, 0.8907, param: [8.16107893 8.60172891 6.43619032 8.39740592], weights: [0.84577491 0.14011842 0.01410667], train_wt_loss:  0.5181, val_wt_loss: 0.4119, train_grp_loss: [0.40391664 0.50950168 0.36467067], val_grp_loss: [0.40140456 0.53962436 0.36590541], train_hist_grp_loss: [4511.89823752 4332.12170536 4102.53768061], cur_train_grp_loss: [0.40392451 0.50947772 0.36467764], max_reward_err:  0.0383, max_reward_err_index: 1, max_kl_dist:  1.0994, max_kl_dist_index: 1, max_train_grp_loss:  0.5095, max_train_grp_loss_index: 1, max_val_grp_loss:  0.5396, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.5095, max_cur_train_grp_loss_index: 1, 
2024-09-17 15:04:33,619 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  10000, train_loss:  0.0015, val_loss:  0.0004, grad_norm: 0.0262, live_grad: 0.0000, reward_err: 0.0306, 0.0387, 0.0081, KL_dist: 0.9751, 1.1064, 0.8964, param: [8.18911883 8.63755462 6.44165863 8.42734752], weights: [0.83305109 0.15358874 0.01336017], train_wt_loss:  0.5201, val_wt_loss: 0.4133, train_grp_loss: [0.40324383 0.51136531 0.36405675], val_grp_loss: [0.40076178 0.54169231 0.3652693 ], train_hist_grp_loss: [4552.25467289 4383.17302714 4138.97297196], cur_train_grp_loss: [0.4032494  0.51135204 0.36406206], max_reward_err:  0.0387, max_reward_err_index: 1, max_kl_dist:  1.1064, max_kl_dist_index: 1, max_train_grp_loss:  0.5114, max_train_grp_loss_index: 1, max_val_grp_loss:  0.5417, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.5114, max_cur_train_grp_loss_index: 1, 
2024-09-17 15:04:36,378 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  10100, train_loss:  0.0015, val_loss:  0.0004, grad_norm: 0.0262, live_grad: 0.0000, reward_err: 0.0306, 0.0387, 0.0081, KL_dist: 0.9808, 1.1122, 0.9020, param: [8.22219479 8.66487577 6.45231321 8.44904642], weights: [0.81900981 0.16835995 0.01263024], train_wt_loss:  0.5225, val_wt_loss: 0.4149, train_grp_loss: [0.40281083 0.51211675 0.36361562], val_grp_loss: [0.40036051 0.5425034  0.36474773], train_hist_grp_loss: [4592.55555167 4434.3563708  4175.3553194 ], cur_train_grp_loss: [0.40281392 0.51211501 0.36361914], max_reward_err:  0.0387, max_reward_err_index: 1, max_kl_dist:  1.1122, max_kl_dist_index: 1, max_train_grp_loss:  0.5121, max_train_grp_loss_index: 1, max_val_grp_loss:  0.5425, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.5121, max_cur_train_grp_loss_index: 1, 
2024-09-17 15:04:39,171 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  10200, train_loss:  0.0015, val_loss:  0.0004, grad_norm: 0.0262, live_grad: 0.0000, reward_err: 0.0308, 0.0383, 0.0083, KL_dist: 0.9869, 1.1164, 0.9075, param: [8.26065557 8.68305952 6.46849207 8.46194175], weights: [0.80377094 0.18431066 0.0119184 ], train_wt_loss:  0.5250, val_wt_loss: 0.4167, train_grp_loss: [0.40263425 0.51167819 0.36335935], val_grp_loss: [0.40021758 0.54196867 0.36434887], train_hist_grp_loss: [4632.82569447 4485.55652994 4211.70260902], cur_train_grp_loss: [0.4026347  0.51168868 0.36336096], max_reward_err:  0.0383, max_reward_err_index: 1, max_kl_dist:  1.1164, max_kl_dist_index: 1, max_train_grp_loss:  0.5117, max_train_grp_loss_index: 1, max_val_grp_loss:  0.5420, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.5117, max_cur_train_grp_loss_index: 1, 
2024-09-17 15:04:41,947 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  10300, train_loss:  0.0015, val_loss:  0.0004, grad_norm: 0.0261, live_grad: 0.0000, reward_err: 0.0316, 0.0374, 0.0087, KL_dist: 0.9933, 1.1190, 0.9128, param: [8.30476387 8.69158147 6.49045212 8.46559383], weights: [0.78753185 0.20124108 0.01122707], train_wt_loss:  0.5276, val_wt_loss: 0.4186, train_grp_loss: [0.40272797 0.50999159 0.36329844], val_grp_loss: [0.40034717 0.54002223 0.36408014], train_hist_grp_loss: [4673.09145802 4536.65143815 4248.03386283], cur_train_grp_loss: [0.40272566 0.51001476 0.36329805], max_reward_err:  0.0374, max_reward_err_index: 1, max_kl_dist:  1.1190, max_kl_dist_index: 1, max_train_grp_loss:  0.5100, max_train_grp_loss_index: 1, max_val_grp_loss:  0.5400, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.5100, max_cur_train_grp_loss_index: 1, 
2024-09-17 15:04:44,740 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  10400, train_loss:  0.0015, val_loss:  0.0004, grad_norm: 0.0259, live_grad: 0.0000, reward_err: 0.0322, 0.0370, 0.0090, KL_dist: 1.0000, 1.1201, 0.9181, param: [8.35466478 8.69007435 6.51833885 8.4597312 ], weights: [0.77057157 0.21886901 0.01055943], train_wt_loss:  0.5301, val_wt_loss: 0.4203, train_grp_loss: [0.40310189 0.50702559 0.36344096], val_grp_loss: [0.40075955 0.53662928 0.36394767], train_hist_grp_loss: [4713.38040122 4587.5144889  4284.3690405 ], cur_train_grp_loss: [0.40309675 0.50706161 0.3634385 ], max_reward_err:  0.0370, max_reward_err_index: 1, max_kl_dist:  1.1201, max_kl_dist_index: 1, max_train_grp_loss:  0.5070, max_train_grp_loss_index: 1, max_val_grp_loss:  0.5366, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.5071, max_cur_train_grp_loss_index: 1, 
2024-09-17 15:04:47,506 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  10500, train_loss:  0.0015, val_loss:  0.0004, grad_norm: 0.0257, live_grad: 0.0000, reward_err: 0.0324, 0.0370, 0.0091, KL_dist: 1.0070, 1.1195, 0.9232, param: [8.41035647 8.67837598 6.55215808 8.44429494], weights: [0.75324672 0.23683409 0.0099192 ], train_wt_loss:  0.5324, val_wt_loss: 0.4219, train_grp_loss: [0.40376062 0.50278177 0.36379163], val_grp_loss: [0.40145975 0.53179334 0.36395573], train_hist_grp_loss: [4753.72082123 4638.01752332 4320.7287509 ], cur_train_grp_loss: [0.40375262 0.50283044 0.36378709], max_reward_err:  0.0370, max_reward_err_index: 1, max_kl_dist:  1.1195, max_kl_dist_index: 1, max_train_grp_loss:  0.5028, max_train_grp_loss_index: 1, max_val_grp_loss:  0.5318, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.5028, max_cur_train_grp_loss_index: 1, 
2024-09-17 15:04:50,271 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  10600, train_loss:  0.0015, val_loss:  0.0004, grad_norm: 0.0255, live_grad: 0.0000, reward_err: 0.0330, 0.0370, 0.0094, KL_dist: 1.0143, 1.1174, 0.9283, param: [8.47166743 8.65657054 6.5917536  8.41947432], weights: [0.73597796 0.25471168 0.00931036], train_wt_loss:  0.5343, val_wt_loss: 0.4232, train_grp_loss: [0.40470231 0.49729932 0.36435096], val_grp_loss: [0.4024464  0.52556145 0.36410606], train_hist_grp_loss: [4794.1411654  4688.03437234 4357.13387286], cur_train_grp_loss: [0.40469151 0.49736005 0.36434434], max_reward_err:  0.0370, max_reward_err_index: 1, max_kl_dist:  1.1174, max_kl_dist_index: 1, max_train_grp_loss:  0.4973, max_train_grp_loss_index: 1, max_val_grp_loss:  0.5256, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.4974, max_cur_train_grp_loss_index: 1, 
2024-09-17 15:04:53,068 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  10700, train_loss:  0.0015, val_loss:  0.0004, grad_norm: 0.0252, live_grad: 0.0000, reward_err: 0.0334, 0.0367, 0.0096, KL_dist: 1.0220, 1.1139, 0.9333, param: [8.53824396 8.6250174  6.63679443 8.38572823], weights: [0.71922785 0.27203542 0.00873673], train_wt_loss:  0.5357, val_wt_loss: 0.4239, train_grp_loss: [0.4059178  0.4906572  0.36511447], val_grp_loss: [0.40371076 0.51802659 0.36439734], train_hist_grp_loss: [4834.66934011 4737.44474856 4393.60509407], cur_train_grp_loss: [0.40590434 0.49072901 0.36510585], max_reward_err:  0.0367, max_reward_err_index: 1, max_kl_dist:  1.1139, max_kl_dist_index: 1, max_train_grp_loss:  0.4907, max_train_grp_loss_index: 1, max_val_grp_loss:  0.5180, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.4907, max_cur_train_grp_loss_index: 1, 
2024-09-17 15:04:55,885 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  10800, train_loss:  0.0014, val_loss:  0.0004, grad_norm: 0.0249, live_grad: 0.0000, reward_err: 0.0344, 0.0367, 0.0102, KL_dist: 1.0301, 1.1090, 0.9383, param: [8.60955075 8.58436258 6.68677426 8.34378828], weights: [0.70347249 0.28832588 0.00820163], train_wt_loss:  0.5364, val_wt_loss: 0.4242, train_grp_loss: [0.40739013 0.48297333 0.36607221], val_grp_loss: [0.40523629 0.50932642 0.36482471], train_hist_grp_loss: [4875.33195135 4786.13820973 4430.16238712], cur_train_grp_loss: [0.40737421 0.48305485 0.36606172], max_reward_err:  0.0367, max_reward_err_index: 1, max_kl_dist:  1.1090, max_kl_dist_index: 1, max_train_grp_loss:  0.4830, max_train_grp_loss_index: 1, max_val_grp_loss:  0.5093, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.4831, max_cur_train_grp_loss_index: 1, 
2024-09-17 15:04:58,736 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  10900, train_loss:  0.0014, val_loss:  0.0004, grad_norm: 0.0245, live_grad: 0.0000, reward_err: 0.0354, 0.0367, 0.0106, KL_dist: 1.0385, 1.1029, 0.9434, param: [8.68488517 8.53553065 6.74102404 8.29464212], weights: [0.68917112 0.30312134 0.00770754], train_wt_loss:  0.5364, val_wt_loss: 0.4239, train_grp_loss: [0.4090946  0.4744006  0.36720859], val_grp_loss: [0.40699854 0.49963836 0.3653795 ], train_hist_grp_loss: [4916.1535236  4834.01788155 4466.82445019], cur_train_grp_loss: [0.4090765  0.47449015 0.3671964 ], max_reward_err:  0.0367, max_reward_err_index: 1, max_kl_dist:  1.1029, max_kl_dist_index: 1, max_train_grp_loss:  0.4744, max_train_grp_loss_index: 1, max_val_grp_loss:  0.4996, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.4745, max_cur_train_grp_loss_index: 1, 
2024-09-17 15:05:01,556 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  11000, train_loss:  0.0014, val_loss:  0.0004, grad_norm: 0.0241, live_grad: 0.0000, reward_err: 0.0360, 0.0363, 0.0111, KL_dist: 1.0472, 1.0960, 0.9485, param: [8.76340419 8.47969701 6.79873645 8.23949842], weights: [0.67673769 0.31600646 0.00725585], train_wt_loss:  0.5358, val_wt_loss: 0.4231, train_grp_loss: [0.41099929 0.46512009 0.36850249], val_grp_loss: [0.40896573 0.48917145 0.36604918], train_hist_grp_loss: [4957.1557476  4881.00364049 4503.60814587], cur_train_grp_loss: [0.41097938 0.46521575 0.36848885], max_reward_err:  0.0363, max_reward_err_index: 1, max_kl_dist:  1.0960, max_kl_dist_index: 1, max_train_grp_loss:  0.4651, max_train_grp_loss_index: 1, max_val_grp_loss:  0.4892, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.4652, max_cur_train_grp_loss_index: 1, 
2024-09-17 15:05:04,347 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  11100, train_loss:  0.0014, val_loss:  0.0004, grad_norm: 0.0237, live_grad: 0.0000, reward_err: 0.0366, 0.0358, 0.0113, KL_dist: 1.0563, 1.0884, 0.9537, param: [8.8441606  8.41824379 6.85899961 8.17973749], weights: [0.66651795 0.32663527 0.00684678], train_wt_loss:  0.5344, val_wt_loss: 0.4217, train_grp_loss: [0.41306612 0.45533244 0.36992781], val_grp_loss: [0.41109964 0.47815595 0.36681753], train_hist_grp_loss: [4998.35680674 4927.03451756 4540.52797322], cur_train_grp_loss: [0.41304479 0.45543214 0.369913  ], max_reward_err:  0.0366, max_reward_err_index: 0, max_kl_dist:  1.0884, max_kl_dist_index: 1, max_train_grp_loss:  0.4553, max_train_grp_loss_index: 1, max_val_grp_loss:  0.4782, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.4554, max_cur_train_grp_loss_index: 1, 
2024-09-17 15:05:07,189 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  11200, train_loss:  0.0014, val_loss:  0.0004, grad_norm: 0.0233, live_grad: 0.0000, reward_err: 0.0370, 0.0358, 0.0115, KL_dist: 1.0655, 1.0804, 0.9590, param: [8.92614455 8.35270394 6.9208362  8.11685309], weights: [0.65877395 0.33474665 0.0064794 ], train_wt_loss:  0.5326, val_wt_loss: 0.4200, train_grp_loss: [0.41525217 0.44524815 0.37145426], val_grp_loss: [0.41335703 0.4668319  0.36766507], train_hist_grp_loss: [5039.77082356 4972.07017658 4577.59560585], cur_train_grp_loss: [0.41522987 0.44534977 0.3714386 ], max_reward_err:  0.0370, max_reward_err_index: 0, max_kl_dist:  1.0804, max_kl_dist_index: 1, max_train_grp_loss:  0.4452, max_train_grp_loss_index: 1, max_val_grp_loss:  0.4668, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.4453, max_cur_train_grp_loss_index: 1, 
2024-09-17 15:05:09,964 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  11300, train_loss:  0.0014, val_loss:  0.0004, grad_norm: 0.0228, live_grad: 0.0000, reward_err: 0.0376, 0.0358, 0.0119, KL_dist: 1.0750, 1.0723, 0.9644, param: [9.00832607 8.28469926 6.9832439  8.05239128], weights: [0.65367615 0.34017212 0.00615173], train_wt_loss:  0.5304, val_wt_loss: 0.4180, train_grp_loss: [0.41751132 0.43507803 0.37304841], val_grp_loss: [0.41569116 0.45543794 0.36856971], train_hist_grp_loss: [5081.40745661 5016.09142381 4614.8195235 ], cur_train_grp_loss: [0.41748852 0.43517948 0.37303225], max_reward_err:  0.0376, max_reward_err_index: 0, max_kl_dist:  1.0750, max_kl_dist_index: 0, max_train_grp_loss:  0.4351, max_train_grp_loss_index: 1, max_val_grp_loss:  0.4554, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.4352, max_cur_train_grp_loss_index: 1, 
2024-09-17 15:05:12,757 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  11400, train_loss:  0.0014, val_loss:  0.0004, grad_norm: 0.0224, live_grad: 0.0000, reward_err: 0.0380, 0.0344, 0.0122, KL_dist: 1.0845, 1.0643, 0.9699, param: [9.08969498 8.21587743 7.0452339  7.9878914 ], weights: [0.65130213 0.34283696 0.00586091], train_wt_loss:  0.5280, val_wt_loss: 0.4160, train_grp_loss: [0.41979595 0.42502458 0.3746749 ], val_grp_loss: [0.4180536  0.44420129 0.36950748], train_hist_grp_loss: [5123.27166441 5059.09980141 4652.20475666], cur_train_grp_loss: [0.41977314 0.4251239  0.3746586 ], max_reward_err:  0.0380, max_reward_err_index: 0, max_kl_dist:  1.0845, max_kl_dist_index: 0, max_train_grp_loss:  0.4250, max_train_grp_loss_index: 1, max_val_grp_loss:  0.4442, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.4251, max_cur_train_grp_loss_index: 1, 
2024-09-17 15:05:15,531 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  11500, train_loss:  0.0014, val_loss:  0.0004, grad_norm: 0.0219, live_grad: 0.0000, reward_err: 0.0383, 0.0342, 0.0124, KL_dist: 1.0940, 1.0566, 0.9755, param: [9.16929572 8.1478527  7.10586495 7.92483299], weights: [0.65164015 0.34275639 0.00560346], train_wt_loss:  0.5256, val_wt_loss: 0.4139, train_grp_loss: [0.42205868 0.41527484 0.37629771], val_grp_loss: [0.4203959  0.43332975 0.37045347], train_hist_grp_loss: [5165.36364126 5101.11638863 4689.75275609], cur_train_grp_loss: [0.42203632 0.41537027 0.37628162], max_reward_err:  0.0383, max_reward_err_index: 0, max_kl_dist:  1.0940, max_kl_dist_index: 0, max_train_grp_loss:  0.4221, max_train_grp_loss_index: 0, max_val_grp_loss:  0.4333, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.4220, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:05:18,294 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  11600, train_loss:  0.0014, val_loss:  0.0004, grad_norm: 0.0215, live_grad: 0.0000, reward_err: 0.0387, 0.0338, 0.0127, KL_dist: 1.1034, 1.0494, 0.9811, param: [9.24625551 8.08215298 7.16427151 7.86459083], weights: [0.65459616 0.34002838 0.00537545], train_wt_loss:  0.5234, val_wt_loss: 0.4120, train_grp_loss: [0.42425392 0.40599509 0.37788142], val_grp_loss: [0.42267128 0.42300586 0.37138273], train_hist_grp_loss: [5207.67891863 5142.17997799 4727.46139032], cur_train_grp_loss: [0.42423244 0.40608507 0.37786589], max_reward_err:  0.0387, max_reward_err_index: 0, max_kl_dist:  1.1034, max_kl_dist_index: 0, max_train_grp_loss:  0.4243, max_train_grp_loss_index: 0, max_val_grp_loss:  0.4230, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.4242, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:05:21,059 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  11700, train_loss:  0.0014, val_loss:  0.0004, grad_norm: 0.0211, live_grad: 0.0000, reward_err: 0.0389, 0.0333, 0.0129, KL_dist: 1.1125, 1.0429, 0.9867, param: [9.31980561 8.02017555 7.21968545 7.80839925], weights: [0.66000287 0.33482436 0.00517277], train_wt_loss:  0.5215, val_wt_loss: 0.4104, train_grp_loss: [0.4263393  0.39732732 0.37939246], val_grp_loss: [0.42483609 0.41338336 0.37227117], train_hist_grp_loss: [5250.20861799 5182.34480947 4765.32506755], cur_train_grp_loss: [0.42631912 0.39741057 0.37937781], max_reward_err:  0.0389, max_reward_err_index: 0, max_kl_dist:  1.1125, max_kl_dist_index: 0, max_train_grp_loss:  0.4263, max_train_grp_loss_index: 0, max_val_grp_loss:  0.4248, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4263, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:05:23,853 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  11800, train_loss:  0.0013, val_loss:  0.0004, grad_norm: 0.0207, live_grad: 0.0000, reward_err: 0.0389, 0.0329, 0.0129, KL_dist: 1.1214, 1.0372, 0.9923, param: [9.38929576 7.96315222 7.27145145 7.75732589], weights: [0.66763035 0.32737841 0.00499125], train_wt_loss:  0.5199, val_wt_loss: 0.4091, train_grp_loss: [0.42827689 0.38938746 0.38080011], val_grp_loss: [0.42685107 0.40458566 0.37309643], train_hist_grp_loss: [5292.9398349  5221.67804054 4803.33497178], cur_train_grp_loss: [0.42825836 0.38946294 0.38078663], max_reward_err:  0.0389, max_reward_err_index: 0, max_kl_dist:  1.1214, max_kl_dist_index: 0, max_train_grp_loss:  0.4283, max_train_grp_loss_index: 0, max_val_grp_loss:  0.4269, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4283, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:05:26,605 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  11900, train_loss:  0.0013, val_loss:  0.0004, grad_norm: 0.0204, live_grad: 0.0000, reward_err: 0.0398, 0.0325, 0.0134, KL_dist: 1.1299, 1.0324, 0.9977, param: [9.45420235 7.91212433 7.31903631 7.71225447], weights: [0.67719794 0.3179752  0.00482686], train_wt_loss:  0.5188, val_wt_loss: 0.4083, train_grp_loss: [0.43003412 0.38226501 0.38207745], val_grp_loss: [0.42868238 0.39670603 0.3738386 ], train_hist_grp_loss: [5335.85612991 5260.25711032 4841.47939758], cur_train_grp_loss: [0.43001753 0.38233196 0.3820654 ], max_reward_err:  0.0398, max_reward_err_index: 0, max_kl_dist:  1.1299, max_kl_dist_index: 0, max_train_grp_loss:  0.4300, max_train_grp_loss_index: 0, max_val_grp_loss:  0.4287, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4300, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:05:29,360 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  12000, train_loss:  0.0013, val_loss:  0.0004, grad_norm: 0.0201, live_grad: 0.0000, reward_err: 0.0411, 0.0319, 0.0143, KL_dist: 1.1380, 1.0286, 1.0031, param: [9.5141311  7.86792756 7.36203288 7.67387605], weights: [0.68838732 0.30693683 0.00467586], train_wt_loss:  0.5181, val_wt_loss: 0.4078, train_grp_loss: [0.43158441 0.37602387 0.38320205], val_grp_loss: [0.43030231 0.3898091  0.37448078], train_hist_grp_loss: [5378.93809921 5298.16713002 4879.74416417], cur_train_grp_loss: [0.43157    0.37608177 0.38319162], max_reward_err:  0.0411, max_reward_err_index: 0, max_kl_dist:  1.1380, max_kl_dist_index: 0, max_train_grp_loss:  0.4316, max_train_grp_loss_index: 0, max_val_grp_loss:  0.4303, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4316, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:05:32,174 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  12100, train_loss:  0.0013, val_loss:  0.0004, grad_norm: 0.0198, live_grad: 0.0000, reward_err: 0.0413, 0.0306, 0.0144, KL_dist: 1.1455, 1.0258, 1.0082, param: [9.5688149  7.83118603 7.40015916 7.64268811], weights: [0.70085663 0.29460851 0.00453486], train_wt_loss:  0.5179, val_wt_loss: 0.4078, train_grp_loss: [0.43290757 0.37070409 0.38415635], val_grp_loss: [0.43168966 0.38393328 0.37500948], train_hist_grp_loss: [5422.16399621 5335.49840282 4918.11308588], cur_train_grp_loss: [0.43289552 0.37075265 0.3841477 ], max_reward_err:  0.0413, max_reward_err_index: 0, max_kl_dist:  1.1455, max_kl_dist_index: 0, max_train_grp_loss:  0.4329, max_train_grp_loss_index: 0, max_val_grp_loss:  0.4317, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4329, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:05:34,979 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  12200, train_loss:  0.0013, val_loss:  0.0004, grad_norm: 0.0196, live_grad: 0.0000, reward_err: 0.0417, 0.0306, 0.0146, KL_dist: 1.1525, 1.0241, 1.0131, param: [9.6181076  7.80231508 7.43325308 7.61900047], weights: [0.7142551  0.28134394 0.00440095], train_wt_loss:  0.5181, val_wt_loss: 0.4080, train_grp_loss: [0.43398988 0.36632415 0.38492792], val_grp_loss: [0.4328299  0.37909374 0.37541488], train_hist_grp_loss: [5465.51037516 5372.34414826 4956.56847461], cur_train_grp_loss: [0.43398028 0.36636329 0.38492113], max_reward_err:  0.0417, max_reward_err_index: 0, max_kl_dist:  1.1525, max_kl_dist_index: 0, max_train_grp_loss:  0.4340, max_train_grp_loss_index: 0, max_val_grp_loss:  0.4328, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4340, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:05:37,753 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  12300, train_loss:  0.0013, val_loss:  0.0004, grad_norm: 0.0194, live_grad: 0.0000, reward_err: 0.0417, 0.0302, 0.0146, KL_dist: 1.1588, 1.0234, 1.0178, param: [9.66197438 7.78153169 7.46126382 7.60294729], weights: [0.72823757 0.26749071 0.00427172], train_wt_loss:  0.5186, val_wt_loss: 0.4086, train_grp_loss: [0.43482384 0.36288376 0.38550936], val_grp_loss: [0.43371497 0.37528574 0.37569076], train_hist_grp_loss: [5508.9527288  5408.79848095 4995.09164994], cur_train_grp_loss: [0.43481674 0.36291355 0.3855045 ], max_reward_err:  0.0417, max_reward_err_index: 0, max_kl_dist:  1.1588, max_kl_dist_index: 0, max_train_grp_loss:  0.4348, max_train_grp_loss_index: 0, max_val_grp_loss:  0.4337, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4348, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:05:40,521 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  12400, train_loss:  0.0013, val_loss:  0.0004, grad_norm: 0.0192, live_grad: 0.0000, reward_err: 0.0417, 0.0300, 0.0146, KL_dist: 1.1646, 1.0237, 1.0223, param: [9.70047963 7.7688712  7.48424021 7.59450382], weights: [0.74247771 0.25337703 0.00414526], train_wt_loss:  0.5194, val_wt_loss: 0.4093, train_grp_loss: [0.43540781 0.36036665 0.3858981 ], val_grp_loss: [0.43434286 0.372488   0.37583447], train_hist_grp_loss: [5552.4660948  5444.95467088 5033.66343353], cur_train_grp_loss: [0.4354032  0.36038734 0.38589517], max_reward_err:  0.0417, max_reward_err_index: 0, max_kl_dist:  1.1646, max_kl_dist_index: 0, max_train_grp_loss:  0.4354, max_train_grp_loss_index: 0, max_val_grp_loss:  0.4343, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4354, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:05:43,304 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  12500, train_loss:  0.0013, val_loss:  0.0004, grad_norm: 0.0191, live_grad: 0.0000, reward_err: 0.0417, 0.0300, 0.0146, KL_dist: 1.1698, 1.0250, 1.0265, param: [9.73377298 7.76420882 7.50231727 7.59350672], weights: [0.75667926 0.23930055 0.00402019], train_wt_loss:  0.5203, val_wt_loss: 0.4102, train_grp_loss: [0.43574535 0.35874355 0.3860959 ], val_grp_loss: [0.43471702 0.37066594 0.37584652], train_hist_grp_loss: [5596.0256098  5480.90369428 5072.264608  ], cur_train_grp_loss: [0.43574317 0.35875548 0.38609485], max_reward_err:  0.0417, max_reward_err_index: 0, max_kl_dist:  1.1698, max_kl_dist_index: 0, max_train_grp_loss:  0.4357, max_train_grp_loss_index: 0, max_val_grp_loss:  0.4347, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4357, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:05:46,147 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  12600, train_loss:  0.0013, val_loss:  0.0004, grad_norm: 0.0191, live_grad: 0.0000, reward_err: 0.0417, 0.0297, 0.0146, KL_dist: 1.1743, 1.0272, 1.0305, param: [9.7620744  7.76728418 7.51570143 7.59967654], weights: [0.77058423 0.22552019 0.00389558], train_wt_loss:  0.5213, val_wt_loss: 0.4111, train_grp_loss: [0.43584449 0.35797491 0.38610829], val_grp_loss: [0.43484554 0.36977474 0.37573027], train_hist_grp_loss: [5639.60699491 5516.7330686  5110.87632453], cur_train_grp_loss: [0.43584465 0.35797851 0.38610906], max_reward_err:  0.0417, max_reward_err_index: 0, max_kl_dist:  1.1743, max_kl_dist_index: 0, max_train_grp_loss:  0.4358, max_train_grp_loss_index: 0, max_val_grp_loss:  0.4348, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4358, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:05:49,060 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  12700, train_loss:  0.0013, val_loss:  0.0004, grad_norm: 0.0191, live_grad: 0.0000, reward_err: 0.0417, 0.0293, 0.0146, KL_dist: 1.1784, 1.0304, 1.0342, param: [9.78565921 7.77772722 7.52465563 7.61264091], weights: [0.78397785 0.21225124 0.00377091], train_wt_loss:  0.5223, val_wt_loss: 0.4120, train_grp_loss: [0.43571694 0.35801345 0.38594395], val_grp_loss: [0.43474037 0.369762   0.37549142], train_hist_grp_loss: [5683.18696276 5552.52595397 5149.48044868], cur_train_grp_loss: [0.43571929 0.35800923 0.38594644], max_reward_err:  0.0417, max_reward_err_index: 0, max_kl_dist:  1.1784, max_kl_dist_index: 0, max_train_grp_loss:  0.4357, max_train_grp_loss_index: 0, max_val_grp_loss:  0.4347, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4357, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:05:52,104 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  12800, train_loss:  0.0013, val_loss:  0.0004, grad_norm: 0.0191, live_grad: 0.0000, reward_err: 0.0417, 0.0300, 0.0146, KL_dist: 1.1819, 1.0343, 1.0377, param: [9.8048437  7.79508378 7.52948483 7.63195717], weights: [0.79669013 0.19966388 0.00364599], train_wt_loss:  0.5232, val_wt_loss: 0.4128, train_grp_loss: [0.4353772  0.35880642 0.38561398], val_grp_loss: [0.4344164  0.37057016 0.37513749], train_hist_grp_loss: [5726.74354154 5588.36049502 5188.059839  ], cur_train_grp_loss: [0.4353816  0.35879494 0.38561806], max_reward_err:  0.0417, max_reward_err_index: 0, max_kl_dist:  1.1819, max_kl_dist_index: 0, max_train_grp_loss:  0.4354, max_train_grp_loss_index: 0, max_val_grp_loss:  0.4344, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4354, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:05:54,916 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  12900, train_loss:  0.0013, val_loss:  0.0004, grad_norm: 0.0192, live_grad: 0.0000, reward_err: 0.0417, 0.0300, 0.0146, KL_dist: 1.1849, 1.0391, 1.0410, param: [9.81997193 7.81883961 7.53052268 7.65713339], weights: [0.80859447 0.18788462 0.00352091], train_wt_loss:  0.5240, val_wt_loss: 0.4135, train_grp_loss: [0.43484182 0.36029756 0.38513127], val_grp_loss: [0.43389067 0.37213835 0.37467741], train_hist_grp_loss: [5770.25631764 5624.3093719  5226.59855822], cur_train_grp_loss: [0.43484808 0.36027938 0.3851368 ], max_reward_err:  0.0417, max_reward_err_index: 0, max_kl_dist:  1.1849, max_kl_dist_index: 0, max_train_grp_loss:  0.4348, max_train_grp_loss_index: 0, max_val_grp_loss:  0.4339, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4348, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:05:57,712 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  13000, train_loss:  0.0013, val_loss:  0.0004, grad_norm: 0.0192, live_grad: 0.0000, reward_err: 0.0417, 0.0300, 0.0146, KL_dist: 1.1876, 1.0445, 1.0442, param: [9.83140419 7.84844181 7.52811982 7.68764697], weights: [0.81960395 0.17700013 0.00339592], train_wt_loss:  0.5246, val_wt_loss: 0.4141, train_grp_loss: [0.43412864 0.36242859 0.38450987], val_grp_loss: [0.4331816  0.37440407 0.37412099], train_hist_grp_loss: [5813.70660214 5660.43952688 5265.08202059], cur_train_grp_loss: [0.43413659 0.3624043  0.38451672], max_reward_err:  0.0417, max_reward_err_index: 0, max_kl_dist:  1.1876, max_kl_dist_index: 0, max_train_grp_loss:  0.4341, max_train_grp_loss_index: 0, max_val_grp_loss:  0.4332, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4341, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:06:00,530 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  13100, train_loss:  0.0013, val_loss:  0.0004, grad_norm: 0.0194, live_grad: 0.0000, reward_err: 0.0417, 0.0306, 0.0146, KL_dist: 1.1898, 1.0506, 1.0472, param: [9.83950739 7.88331699 7.52263403 7.72296033], weights: [0.82966605 0.16706255 0.0032714 ], train_wt_loss:  0.5250, val_wt_loss: 0.4145, train_grp_loss: [0.43325622 0.36514055 0.38376449], val_grp_loss: [0.43230836 0.37730433 0.37347857], train_hist_grp_loss: [5857.07753021 5696.81203282 5303.49708213], cur_train_grp_loss: [0.43326567 0.36511075 0.38377251], max_reward_err:  0.0417, max_reward_err_index: 0, max_kl_dist:  1.1898, max_kl_dist_index: 0, max_train_grp_loss:  0.4333, max_train_grp_loss_index: 0, max_val_grp_loss:  0.4323, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4333, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:06:03,311 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  13200, train_loss:  0.0013, val_loss:  0.0004, grad_norm: 0.0195, live_grad: 0.0000, reward_err: 0.0417, 0.0306, 0.0146, KL_dist: 1.1918, 1.0573, 1.0501, param: [9.84464741 7.92288605 7.51442242 7.76253355], weights: [0.83875657 0.15809564 0.00314779], train_wt_loss:  0.5253, val_wt_loss: 0.4148, train_grp_loss: [0.43224326 0.36837473 0.38291003], val_grp_loss: [0.43129029 0.38077658 0.37276064], train_hist_grp_loss: [5900.35410397 5733.48207115 5341.83208237], cur_train_grp_loss: [0.43225403 0.36833999 0.38291907], max_reward_err:  0.0417, max_reward_err_index: 0, max_kl_dist:  1.1918, max_kl_dist_index: 0, max_train_grp_loss:  0.4322, max_train_grp_loss_index: 0, max_val_grp_loss:  0.4313, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4323, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:06:06,073 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  13300, train_loss:  0.0013, val_loss:  0.0004, grad_norm: 0.0197, live_grad: 0.0000, reward_err: 0.0411, 0.0306, 0.0143, KL_dist: 1.1934, 1.0646, 1.0529, param: [9.84718332 7.96657549 7.50383554 7.8058339 ], weights: [0.84687335 0.15010111 0.00302553], train_wt_loss:  0.5253, val_wt_loss: 0.4149, train_grp_loss: [0.43110829 0.37207327 0.38196126], val_grp_loss: [0.43014656 0.38475931 0.37197767], train_hist_grp_loss: [5943.5231901  5770.49899015 5380.07684685], cur_train_grp_loss: [0.43112019 0.37203418 0.38197117], max_reward_err:  0.0411, max_reward_err_index: 0, max_kl_dist:  1.1934, max_kl_dist_index: 0, max_train_grp_loss:  0.4311, max_train_grp_loss_index: 0, max_val_grp_loss:  0.4301, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4311, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:06:09,022 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  13400, train_loss:  0.0013, val_loss:  0.0004, grad_norm: 0.0198, live_grad: 0.0000, reward_err: 0.0409, 0.0311, 0.0142, KL_dist: 1.1949, 1.0723, 1.0556, param: [9.84746343 8.01382545 7.49121322 7.85234268], weights: [0.85403036 0.14306457 0.00290507], train_wt_loss:  0.5252, val_wt_loss: 0.4149, train_grp_loss: [0.42986932 0.37617968 0.38093255], val_grp_loss: [0.42889579 0.38919237 0.37113983], train_hist_grp_loss: [5986.5734835  5807.90641753 5418.22265967], cur_train_grp_loss: [0.42988216 0.37613678 0.38094319], max_reward_err:  0.0409, max_reward_err_index: 0, max_kl_dist:  1.1949, max_kl_dist_index: 0, max_train_grp_loss:  0.4299, max_train_grp_loss_index: 0, max_val_grp_loss:  0.4289, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4299, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:06:11,903 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  13500, train_loss:  0.0013, val_loss:  0.0004, grad_norm: 0.0200, live_grad: 0.0000, reward_err: 0.0409, 0.0319, 0.0142, KL_dist: 1.1962, 1.0804, 1.0583, param: [9.84582282 8.06409507 7.47688204 7.90155947], weights: [0.86025232 0.13696088 0.0027868 ], train_wt_loss:  0.5249, val_wt_loss: 0.4147, train_grp_loss: [0.42854365 0.38063899 0.37983769], val_grp_loss: [0.42755589 0.39401721 0.37025686], train_hist_grp_loss: [6029.49544694 5845.74240544 5456.26221472], cur_train_grp_loss: [0.42855728 0.38059282 0.37984893], max_reward_err:  0.0409, max_reward_err_index: 0, max_kl_dist:  1.1962, max_kl_dist_index: 0, max_train_grp_loss:  0.4285, max_train_grp_loss_index: 0, max_val_grp_loss:  0.4276, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4286, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:06:14,702 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  13600, train_loss:  0.0013, val_loss:  0.0004, grad_norm: 0.0202, live_grad: 0.0000, reward_err: 0.0409, 0.0323, 0.0142, KL_dist: 1.1974, 1.0889, 1.0610, param: [9.84258217 8.11686532 7.46115409 7.95300439], weights: [0.86557027 0.13175868 0.00267105], train_wt_loss:  0.5244, val_wt_loss: 0.4143, train_grp_loss: [0.4271478  0.38539785 0.37868981], val_grp_loss: [0.42614393 0.39917681 0.36933807], train_hist_grp_loss: [6072.28123573 5884.03958979 5494.18955301], cur_train_grp_loss: [0.42716206 0.38534895 0.37870151], max_reward_err:  0.0409, max_reward_err_index: 0, max_kl_dist:  1.1974, max_kl_dist_index: 0, max_train_grp_loss:  0.4271, max_train_grp_loss_index: 0, max_val_grp_loss:  0.4261, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4272, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:06:17,482 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  13700, train_loss:  0.0013, val_loss:  0.0004, grad_norm: 0.0205, live_grad: 0.0000, reward_err: 0.0409, 0.0325, 0.0142, KL_dist: 1.1984, 1.0977, 1.0637, param: [9.83804762 8.17163999 7.44432671 8.00621869], weights: [0.87001778 0.12742411 0.00255811], train_wt_loss:  0.5239, val_wt_loss: 0.4139, train_grp_loss: [0.42569745 0.39040446 0.37750132], val_grp_loss: [0.42467609 0.40461563 0.36839219], train_hist_grp_loss: [6114.92461468 5922.82534942 5531.99999255], cur_train_grp_loss: [0.42571217 0.39035333 0.37751336], max_reward_err:  0.0409, max_reward_err_index: 0, max_kl_dist:  1.1984, max_kl_dist_index: 0, max_train_grp_loss:  0.4257, max_train_grp_loss_index: 0, max_val_grp_loss:  0.4247, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4257, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:06:20,310 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  13800, train_loss:  0.0013, val_loss:  0.0004, grad_norm: 0.0207, live_grad: 0.0000, reward_err: 0.0396, 0.0329, 0.0134, KL_dist: 1.1995, 1.1067, 1.0664, param: [9.8325114  8.22794519 7.4266831  8.06076398], weights: [0.87362817 0.12392365 0.00244818], train_wt_loss:  0.5232, val_wt_loss: 0.4134, train_grp_loss: [0.4242074  0.39560842 0.37628388], val_grp_loss: [0.42316767 0.41027934 0.36742743], train_hist_grp_loss: [6157.42087329 5962.12195389 5569.69005559], cur_train_grp_loss: [0.42422245 0.39555557 0.37629616], max_reward_err:  0.0396, max_reward_err_index: 0, max_kl_dist:  1.1995, max_kl_dist_index: 0, max_train_grp_loss:  0.4242, max_train_grp_loss_index: 0, max_val_grp_loss:  0.4232, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4242, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:06:23,120 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  13900, train_loss:  0.0014, val_loss:  0.0004, grad_norm: 0.0209, live_grad: 0.0000, reward_err: 0.0392, 0.0333, 0.0131, KL_dist: 1.2005, 1.1159, 1.0691, param: [9.82625306 8.28532767 7.4084935  8.11622059], weights: [0.87643228 0.12122628 0.00234144], train_wt_loss:  0.5225, val_wt_loss: 0.4128, train_grp_loss: [0.4226917  0.40096048 0.37504849], val_grp_loss: [0.42163313 0.41611457 0.3664515 ], train_hist_grp_loss: [6199.76674356 6001.94669156 5607.25739729], cur_train_grp_loss: [0.42270694 0.40090639 0.37506089], max_reward_err:  0.0392, max_reward_err_index: 0, max_kl_dist:  1.2005, max_kl_dist_index: 0, max_train_grp_loss:  0.4227, max_train_grp_loss_index: 0, max_val_grp_loss:  0.4216, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4227, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:06:25,903 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  14000, train_loss:  0.0014, val_loss:  0.0004, grad_norm: 0.0211, live_grad: 0.0000, reward_err: 0.0392, 0.0333, 0.0131, KL_dist: 1.2015, 1.1253, 1.0718, param: [9.81954107 8.34335242 7.39001675 8.17218517], weights: [0.878457   0.11930502 0.00223797], train_wt_loss:  0.5217, val_wt_loss: 0.4122, train_grp_loss: [0.42116364 0.40641228 0.37380547], val_grp_loss: [0.42008615 0.42206863 0.36547161], train_hist_grp_loss: [6241.96032378 6042.31197225 5644.7007386 ], cur_train_grp_loss: [0.42117894 0.40635742 0.37381791], max_reward_err:  0.0392, max_reward_err_index: 0, max_kl_dist:  1.2015, max_kl_dist_index: 0, max_train_grp_loss:  0.4212, max_train_grp_loss_index: 0, max_val_grp_loss:  0.4221, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.4212, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:06:28,670 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  14100, train_loss:  0.0014, val_loss:  0.0004, grad_norm: 0.0213, live_grad: 0.0000, reward_err: 0.0392, 0.0335, 0.0131, KL_dist: 1.2026, 1.1348, 1.0746, param: [9.81263471 8.40159972 7.37150213 8.22826798], weights: [0.87972428 0.11813788 0.00213784], train_wt_loss:  0.5209, val_wt_loss: 0.4115, train_grp_loss: [0.41963589 0.41191602 0.3725646 ], val_grp_loss: [0.41853977 0.42808909 0.36449452], train_hist_grp_loss: [6284.00101042 6083.2254005  5682.0198052 ], cur_train_grp_loss: [0.41965113 0.41186088 0.37257696], max_reward_err:  0.0392, max_reward_err_index: 0, max_kl_dist:  1.2026, max_kl_dist_index: 0, max_train_grp_loss:  0.4196, max_train_grp_loss_index: 0, max_val_grp_loss:  0.4281, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.4197, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:06:31,431 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  14200, train_loss:  0.0014, val_loss:  0.0004, grad_norm: 0.0215, live_grad: 0.0000, reward_err: 0.0392, 0.0342, 0.0131, KL_dist: 1.2037, 1.1442, 1.0775, param: [9.80578601 8.45966198 7.35319129 8.2840899 ], weights: [0.88025055 0.1177084  0.00204105], train_wt_loss:  0.5201, val_wt_loss: 0.4109, train_grp_loss: [0.4181206  0.41742419 0.37133513], val_grp_loss: [0.41700641 0.4341235  0.36352663], train_hist_grp_loss: [6325.88943959 6124.68981781 5719.21527385], cur_train_grp_loss: [0.41813565 0.41736924 0.37134734], max_reward_err:  0.0392, max_reward_err_index: 0, max_kl_dist:  1.2037, max_kl_dist_index: 0, max_train_grp_loss:  0.4181, max_train_grp_loss_index: 0, max_val_grp_loss:  0.4341, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.4181, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:06:34,192 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  14300, train_loss:  0.0014, val_loss:  0.0004, grad_norm: 0.0218, live_grad: 0.0000, reward_err: 0.0392, 0.0342, 0.0131, KL_dist: 1.2050, 1.1537, 1.0804, param: [9.79924171 8.51714049 7.33532015 8.33927941], weights: [0.88004663 0.11800579 0.00194758], train_wt_loss:  0.5194, val_wt_loss: 0.4103, train_grp_loss: [0.41662945 0.42288922 0.37012593], val_grp_loss: [0.41549806 0.44011904 0.36257401], train_hist_grp_loss: [6367.62743859 6166.70331384 5756.28872671], cur_train_grp_loss: [0.41664421 0.42283494 0.37013789], max_reward_err:  0.0392, max_reward_err_index: 0, max_kl_dist:  1.2050, max_kl_dist_index: 0, max_train_grp_loss:  0.4229, max_train_grp_loss_index: 1, max_val_grp_loss:  0.4401, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.4228, max_cur_train_grp_loss_index: 1, 
2024-09-17 15:06:37,017 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  14400, train_loss:  0.0014, val_loss:  0.0004, grad_norm: 0.0220, live_grad: 0.0000, reward_err: 0.0388, 0.0342, 0.0128, KL_dist: 1.2063, 1.1630, 1.0834, param: [9.7932451  8.57364226 7.31812078 8.3934698 ], weights: [0.8791179  0.11902472 0.00185738], train_wt_loss:  0.5187, val_wt_loss: 0.4097, train_grp_loss: [0.41517383 0.42826322 0.3689455 ], val_grp_loss: [0.41402635 0.44602224 0.36164247], train_hist_grp_loss: [6409.21798767 6209.25920799 5793.2426138 ], cur_train_grp_loss: [0.41518817 0.42821009 0.36895713], max_reward_err:  0.0388, max_reward_err_index: 0, max_kl_dist:  1.2063, max_kl_dist_index: 0, max_train_grp_loss:  0.4283, max_train_grp_loss_index: 1, max_val_grp_loss:  0.4460, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.4282, max_cur_train_grp_loss_index: 1, 
2024-09-17 15:06:39,843 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  14500, train_loss:  0.0014, val_loss:  0.0004, grad_norm: 0.0222, live_grad: 0.0000, reward_err: 0.0388, 0.0344, 0.0128, KL_dist: 1.2078, 1.1723, 1.0865, param: [9.78803762 8.62877719 7.30182297 8.4462966 ], weights: [0.87746482 0.12076482 0.00177037], train_wt_loss:  0.5180, val_wt_loss: 0.4091, train_grp_loss: [0.41376485 0.43349776 0.3678021 ], val_grp_loss: [0.41260262 0.45177868 0.36073759], train_hist_grp_loss: [6450.66519139 6252.3460053  5830.08022328], cur_train_grp_loss: [0.41377867 0.43344626 0.36781333], max_reward_err:  0.0388, max_reward_err_index: 0, max_kl_dist:  1.2078, max_kl_dist_index: 0, max_train_grp_loss:  0.4335, max_train_grp_loss_index: 1, max_val_grp_loss:  0.4518, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.4334, max_cur_train_grp_loss_index: 1, 
2024-09-17 15:06:42,618 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  14600, train_loss:  0.0014, val_loss:  0.0004, grad_norm: 0.0224, live_grad: 0.0000, reward_err: 0.0385, 0.0347, 0.0127, KL_dist: 1.2094, 1.1813, 1.0896, param: [9.78386019 8.68215574 7.28665552 8.49739553], weights: [0.8750838  0.12322974 0.00168646], train_wt_loss:  0.5175, val_wt_loss: 0.4087, train_grp_loss: [0.41241349 0.43854366 0.3667038 ], val_grp_loss: [0.41123805 0.45733292 0.35986479], train_hist_grp_loss: [6491.9742586  6295.94733198 5866.80565883], cur_train_grp_loss: [0.41242668 0.4384943  0.36671454], max_reward_err:  0.0385, max_reward_err_index: 0, max_kl_dist:  1.2094, max_kl_dist_index: 0, max_train_grp_loss:  0.4385, max_train_grp_loss_index: 1, max_val_grp_loss:  0.4573, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.4385, max_cur_train_grp_loss_index: 1, 
2024-09-17 15:06:45,374 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  14700, train_loss:  0.0014, val_loss:  0.0004, grad_norm: 0.0225, live_grad: 0.0000, reward_err: 0.0385, 0.0355, 0.0127, KL_dist: 1.2111, 1.1900, 1.0928, param: [9.78095394 8.73338719 7.27284712 8.54640115], weights: [0.87196846 0.12642597 0.00160557], train_wt_loss:  0.5171, val_wt_loss: 0.4083, train_grp_loss: [0.41113061 0.44335098 0.36565852], val_grp_loss: [0.40994367 0.46262837 0.3590294 ], train_hist_grp_loss: [6533.15148949 6340.04185867 5903.42382328], cur_train_grp_loss: [0.41114307 0.44330425 0.36566869], max_reward_err:  0.0385, max_reward_err_index: 0, max_kl_dist:  1.2111, max_kl_dist_index: 0, max_train_grp_loss:  0.4434, max_train_grp_loss_index: 1, max_val_grp_loss:  0.4626, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.4433, max_cur_train_grp_loss_index: 1, 
2024-09-17 15:06:48,139 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  14800, train_loss:  0.0014, val_loss:  0.0004, grad_norm: 0.0227, live_grad: 0.0000, reward_err: 0.0378, 0.0358, 0.0123, KL_dist: 1.2130, 1.1984, 1.0960, param: [9.7795605  8.78207885 7.26062659 8.59294629], weights: [0.86811119 0.13036124 0.00152757], train_wt_loss:  0.5168, val_wt_loss: 0.4081, train_grp_loss: [0.40992702 0.447869   0.36467409], val_grp_loss: [0.40873047 0.4676074  0.35823663], train_hist_grp_loss: [6574.20426762 6384.60322203 5939.94040673], cur_train_grp_loss: [0.40993863 0.44782542 0.36468361], max_reward_err:  0.0378, max_reward_err_index: 0, max_kl_dist:  1.2130, max_kl_dist_index: 0, max_train_grp_loss:  0.4479, max_train_grp_loss_index: 1, max_val_grp_loss:  0.4676, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.4478, max_cur_train_grp_loss_index: 1, 
2024-09-17 15:06:50,898 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  14900, train_loss:  0.0014, val_loss:  0.0004, grad_norm: 0.0228, live_grad: 0.0000, reward_err: 0.0376, 0.0358, 0.0122, KL_dist: 1.2152, 1.2064, 1.0993, param: [9.77992145 8.82783627 7.25022251 8.63666264], weights: [0.86350519 0.13504242 0.00145239], train_wt_loss:  0.5167, val_wt_loss: 0.4079, train_grp_loss: [0.40881347 0.45204646 0.36375824], val_grp_loss: [0.40760935 0.47221162 0.35749163], train_hist_grp_loss: [6615.14105425 6429.59995847 5976.36187772], cur_train_grp_loss: [0.40882412 0.45200654 0.36376704], max_reward_err:  0.0376, max_reward_err_index: 0, max_kl_dist:  1.2152, max_kl_dist_index: 0, max_train_grp_loss:  0.4520, max_train_grp_loss_index: 1, max_val_grp_loss:  0.4722, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.4520, max_cur_train_grp_loss_index: 1, 
2024-09-17 15:06:53,676 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  15000, train_loss:  0.0014, val_loss:  0.0004, grad_norm: 0.0230, live_grad: 0.0000, reward_err: 0.0376, 0.0358, 0.0122, KL_dist: 1.2175, 1.2140, 1.1027, param: [9.78227689 8.87026493 7.24186197 8.67718261], weights: [0.85814696 0.14047313 0.00137991], train_wt_loss:  0.5168, val_wt_loss: 0.4079, train_grp_loss: [0.40780061 0.45583196 0.36291864], val_grp_loss: [0.40659112 0.47638234 0.35679949], train_hist_grp_loss: [6655.97138171 6474.99546675 6012.69547492], cur_train_grp_loss: [0.40781021 0.45579622 0.36292664], max_reward_err:  0.0376, max_reward_err_index: 0, max_kl_dist:  1.2175, max_kl_dist_index: 0, max_train_grp_loss:  0.4558, max_train_grp_loss_index: 1, max_val_grp_loss:  0.4764, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.4558, max_cur_train_grp_loss_index: 1, 
2024-09-17 15:06:56,436 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  15100, train_loss:  0.0014, val_loss:  0.0004, grad_norm: 0.0231, live_grad: 0.0000, reward_err: 0.0376, 0.0358, 0.0122, KL_dist: 1.2200, 1.2210, 1.1061, param: [9.78686299 8.90897337 7.23576826 8.71414277], weights: [0.85203915 0.1466508  0.00131005], train_wt_loss:  0.5170, val_wt_loss: 0.4080, train_grp_loss: [0.40689897 0.45917452 0.36216281], val_grp_loss: [0.40568644 0.48006128 0.35616521], train_hist_grp_loss: [6696.70584183 6520.74801994 6048.94919668], cur_train_grp_loss: [0.4069074  0.45914345 0.36216993], max_reward_err:  0.0376, max_reward_err_index: 0, max_kl_dist:  1.2210, max_kl_dist_index: 1, max_train_grp_loss:  0.4592, max_train_grp_loss_index: 1, max_val_grp_loss:  0.4801, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.4591, max_cur_train_grp_loss_index: 1, 
2024-09-17 15:06:59,204 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  15200, train_loss:  0.0014, val_loss:  0.0004, grad_norm: 0.0232, live_grad: 0.0000, reward_err: 0.0376, 0.0358, 0.0122, KL_dist: 1.2227, 1.2275, 1.1095, param: [9.79390831 8.94357826 7.23215757 8.74718897], weights: [0.84519381 0.15356345 0.00124275], train_wt_loss:  0.5174, val_wt_loss: 0.4082, train_grp_loss: [0.40611876 0.46202445 0.36149809], val_grp_loss: [0.40490567 0.48319162 0.35559368], train_hist_grp_loss: [6737.35606483 6566.81084968 6085.1317854 ], cur_train_grp_loss: [0.40612593 0.46199855 0.36150427], max_reward_err:  0.0376, max_reward_err_index: 0, max_kl_dist:  1.2275, max_kl_dist_index: 1, max_train_grp_loss:  0.4620, max_train_grp_loss_index: 1, max_val_grp_loss:  0.4832, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.4620, max_cur_train_grp_loss_index: 1, 
2024-09-17 15:07:02,023 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  15300, train_loss:  0.0014, val_loss:  0.0004, grad_norm: 0.0232, live_grad: 0.0000, reward_err: 0.0369, 0.0358, 0.0118, KL_dist: 1.2256, 1.2332, 1.1130, param: [9.80362896 8.97371127 7.23123442 8.77598337], weights: [0.8376359  0.16118616 0.00117794], train_wt_loss:  0.5179, val_wt_loss: 0.4086, train_grp_loss: [0.40546978 0.46433449 0.36093151], val_grp_loss: [0.40425874 0.48571928 0.3550896 ], train_hist_grp_loss: [6777.93468372 6613.13232836 6121.25270302], cur_train_grp_loss: [0.40547559 0.46431421 0.36093667], max_reward_err:  0.0369, max_reward_err_index: 0, max_kl_dist:  1.2332, max_kl_dist_index: 1, max_train_grp_loss:  0.4643, max_train_grp_loss_index: 1, max_val_grp_loss:  0.4857, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.4643, max_cur_train_grp_loss_index: 1, 
2024-09-17 15:07:04,777 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  15400, train_loss:  0.0014, val_loss:  0.0004, grad_norm: 0.0233, live_grad: 0.0000, reward_err: 0.0369, 0.0358, 0.0118, KL_dist: 1.2288, 1.2383, 1.1165, param: [9.81622239 8.99902812 7.23318592 8.80021335], weights: [0.82940682 0.1694776  0.00111558], train_wt_loss:  0.5186, val_wt_loss: 0.4090, train_grp_loss: [0.40496113 0.46606113 0.36046965], val_grp_loss: [0.40375489 0.48759453 0.35465743], train_hist_grp_loss: [6818.45527851 6659.6562752  6157.32209375], cur_train_grp_loss: [0.40496549 0.46604688 0.36047373], max_reward_err:  0.0369, max_reward_err_index: 0, max_kl_dist:  1.2383, max_kl_dist_index: 1, max_train_grp_loss:  0.4661, max_train_grp_loss_index: 1, max_val_grp_loss:  0.4876, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.4660, max_cur_train_grp_loss_index: 1, 
2024-09-17 15:07:07,543 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  15500, train_loss:  0.0014, val_loss:  0.0004, grad_norm: 0.0233, live_grad: 0.0000, reward_err: 0.0369, 0.0358, 0.0118, KL_dist: 1.2322, 1.2427, 1.1200, param: [9.83186011 9.01921945 7.23817498 8.81960215], weights: [0.82056764 0.17837668 0.00105568], train_wt_loss:  0.5194, val_wt_loss: 0.4096, train_grp_loss: [0.40460096 0.46716623 0.36011846], val_grp_loss: [0.4034024  0.48877385 0.3543012 ], train_hist_grp_loss: [6858.93229505 6706.32241098 6193.35073025], cur_train_grp_loss: [0.4046038  0.46715837 0.36012141], max_reward_err:  0.0369, max_reward_err_index: 0, max_kl_dist:  1.2427, max_kl_dist_index: 1, max_train_grp_loss:  0.4672, max_train_grp_loss_index: 1, max_val_grp_loss:  0.4888, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.4672, max_cur_train_grp_loss_index: 1, 
2024-09-17 15:07:10,300 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  15600, train_loss:  0.0014, val_loss:  0.0004, grad_norm: 0.0233, live_grad: 0.0000, reward_err: 0.0369, 0.0358, 0.0118, KL_dist: 1.2359, 1.2462, 1.1235, param: [9.85067952 9.03402328 7.2463326  8.83392093], weights: [0.81120183 0.18779996 0.00099821], train_wt_loss:  0.5202, val_wt_loss: 0.4101, train_grp_loss: [0.40439613 0.46761883 0.35988302], val_grp_loss: [0.40320827 0.48922198 0.35402447], train_hist_grp_loss: [6899.38093318 6753.0669817  6229.34993921], cur_train_grp_loss: [0.40439739 0.46761761 0.35988479], max_reward_err:  0.0369, max_reward_err_index: 0, max_kl_dist:  1.2462, max_kl_dist_index: 1, max_train_grp_loss:  0.4676, max_train_grp_loss_index: 1, max_val_grp_loss:  0.4892, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.4676, max_cur_train_grp_loss_index: 1, 
2024-09-17 15:07:13,080 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  15700, train_loss:  0.0014, val_loss:  0.0004, grad_norm: 0.0233, live_grad: 0.0000, reward_err: 0.0369, 0.0358, 0.0118, KL_dist: 1.2398, 1.2489, 1.1270, param: [9.87277526 9.0432386  7.25774973 8.84300161], weights: [0.80141686 0.19763994 0.0009432 ], train_wt_loss:  0.5212, val_wt_loss: 0.4108, train_grp_loss: [0.40435186 0.46739691 0.35976732], val_grp_loss: [0.40317783 0.48891406 0.35383007], train_hist_grp_loss: [6939.81700041 6799.82356431 6265.33150327], cur_train_grp_loss: [0.40435149 0.46740251 0.35976787], max_reward_err:  0.0369, max_reward_err_index: 0, max_kl_dist:  1.2489, max_kl_dist_index: 1, max_train_grp_loss:  0.4674, max_train_grp_loss_index: 1, max_val_grp_loss:  0.4889, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.4674, max_cur_train_grp_loss_index: 1, 
2024-09-17 15:07:15,838 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  15800, train_loss:  0.0014, val_loss:  0.0004, grad_norm: 0.0232, live_grad: 0.0000, reward_err: 0.0373, 0.0358, 0.0120, KL_dist: 1.2439, 1.2508, 1.1306, param: [9.89819063 9.04673924 7.27246921 8.84674985], weights: [0.79134451 0.2077648  0.00089069], train_wt_loss:  0.5221, val_wt_loss: 0.4114, train_grp_loss: [0.40447133 0.46648927 0.35977394], val_grp_loss: [0.40331439 0.4878377  0.35372   ], train_hist_grp_loss: [6980.25672845 6846.52405602 6301.30753681], cur_train_grp_loss: [0.40446932 0.46650175 0.35977326], max_reward_err:  0.0373, max_reward_err_index: 0, max_kl_dist:  1.2508, max_kl_dist_index: 1, max_train_grp_loss:  0.4665, max_train_grp_loss_index: 1, max_val_grp_loss:  0.4878, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.4665, max_cur_train_grp_loss_index: 1, 
2024-09-17 15:07:18,597 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  15900, train_loss:  0.0014, val_loss:  0.0004, grad_norm: 0.0232, live_grad: 0.0000, reward_err: 0.0373, 0.0358, 0.0120, KL_dist: 1.2483, 1.2518, 1.1341, param: [9.92690982 9.044487   7.2904783  8.84515695], weights: [0.78113937 0.21801992 0.00084071], train_wt_loss:  0.5229, val_wt_loss: 0.4120, train_grp_loss: [0.40475534 0.46489712 0.35990385], val_grp_loss: [0.40361884 0.48599476 0.3536952 ], train_hist_grp_loss: [7020.71655258 6893.09983527 6337.29033485], cur_train_grp_loss: [0.40475169 0.46491639 0.35990194], max_reward_err:  0.0373, max_reward_err_index: 0, max_kl_dist:  1.2518, max_kl_dist_index: 1, max_train_grp_loss:  0.4649, max_train_grp_loss_index: 1, max_val_grp_loss:  0.4860, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.4649, max_cur_train_grp_loss_index: 1, 
2024-09-17 15:07:21,379 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  16000, train_loss:  0.0014, val_loss:  0.0004, grad_norm: 0.0231, live_grad: 0.0000, reward_err: 0.0379, 0.0358, 0.0124, KL_dist: 1.2530, 1.2520, 1.1377, param: [9.95885167 9.03654304 7.31170273 8.83830984], weights: [0.77097558 0.22823112 0.0007933 ], train_wt_loss:  0.5237, val_wt_loss: 0.4124, train_grp_loss: [0.40520199 0.46263526 0.3601561 ], val_grp_loss: [0.40408934 0.4834028  0.35375537], train_hist_grp_loss: [7061.21285631 6939.48306612 6373.2921958 ], cur_train_grp_loss: [0.40519673 0.46266111 0.36015298], max_reward_err:  0.0379, max_reward_err_index: 0, max_kl_dist:  1.2530, max_kl_dist_index: 0, max_train_grp_loss:  0.4626, max_train_grp_loss_index: 1, max_val_grp_loss:  0.4834, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.4627, max_cur_train_grp_loss_index: 1, 
2024-09-17 15:07:24,169 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  16100, train_loss:  0.0014, val_loss:  0.0004, grad_norm: 0.0229, live_grad: 0.0000, reward_err: 0.0379, 0.0358, 0.0124, KL_dist: 1.2579, 1.2514, 1.1413, param: [9.9938657  9.02307624 7.33600276 8.82639785], weights: [7.61041603e-01 2.38209891e-01 7.48505571e-04], train_wt_loss:  0.5244, val_wt_loss: 0.4128, train_grp_loss: [0.40580639 0.4597329  0.36052763], val_grp_loss: [0.40472103 0.48009577 0.35389884], train_hist_grp_loss: [7101.76168691 6985.60810241 6409.32522108], cur_train_grp_loss: [0.40579959 0.45976496 0.36052334], max_reward_err:  0.0379, max_reward_err_index: 0, max_kl_dist:  1.2579, max_kl_dist_index: 0, max_train_grp_loss:  0.4597, max_train_grp_loss_index: 1, max_val_grp_loss:  0.4801, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.4598, max_cur_train_grp_loss_index: 1, 
2024-09-17 15:07:26,927 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  16200, train_loss:  0.0014, val_loss:  0.0004, grad_norm: 0.0228, live_grad: 0.0000, reward_err: 0.0379, 0.0358, 0.0124, KL_dist: 1.2630, 1.2500, 1.1448, param: [10.03173095  9.00436768  7.3631719   8.80971555], weights: [7.51533604e-01 2.47760055e-01 7.06340677e-04], train_wt_loss:  0.5248, val_wt_loss: 0.4130, train_grp_loss: [0.40656055 0.45623365 0.36101316], val_grp_loss: [0.4055059  0.47612408 0.35412245], train_hist_grp_loss: [7142.37845037 7031.41293362 6445.40109665], cur_train_grp_loss: [0.4065523  0.45627142 0.36100777], max_reward_err:  0.0379, max_reward_err_index: 0, max_kl_dist:  1.2630, max_kl_dist_index: 0, max_train_grp_loss:  0.4562, max_train_grp_loss_index: 1, max_val_grp_loss:  0.4761, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.4563, max_cur_train_grp_loss_index: 1, 
2024-09-17 15:07:29,682 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  16300, train_loss:  0.0014, val_loss:  0.0004, grad_norm: 0.0226, live_grad: 0.0000, reward_err: 0.0379, 0.0358, 0.0124, KL_dist: 1.2684, 1.2480, 1.1485, param: [10.07215814  8.9808104   7.39293865  8.78866098], weights: [7.42647641e-01 2.56685546e-01 6.66812996e-04], train_wt_loss:  0.5251, val_wt_loss: 0.4131, train_grp_loss: [0.40745332 0.45219498 0.36160506], val_grp_loss: [0.40643271 0.47155379 0.35442143], train_hist_grp_loss: [7183.07759688 7076.84060532 6481.53086362], cur_train_grp_loss: [0.40744375 0.45223782 0.36159865], max_reward_err:  0.0379, max_reward_err_index: 0, max_kl_dist:  1.2684, max_kl_dist_index: 0, max_train_grp_loss:  0.4522, max_train_grp_loss_index: 1, max_val_grp_loss:  0.4716, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.4522, max_cur_train_grp_loss_index: 1, 
2024-09-17 15:07:32,455 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  16400, train_loss:  0.0014, val_loss:  0.0004, grad_norm: 0.0224, live_grad: 0.0000, reward_err: 0.0385, 0.0351, 0.0127, KL_dist: 1.2739, 1.2454, 1.1521, param: [10.11479499  8.95290414  7.4249713   8.76372899], weights: [7.34571472e-01 2.64798625e-01 6.29903318e-04], train_wt_loss:  0.5251, val_wt_loss: 0.4130, train_grp_loss: [0.40847051 0.44768689 0.36229341], val_grp_loss: [0.40748711 0.46646498 0.35478944], train_hist_grp_loss: [7223.87230974 7121.84054322 6517.72468645], cur_train_grp_loss: [0.40845978 0.44773404 0.36228608], max_reward_err:  0.0385, max_reward_err_index: 0, max_kl_dist:  1.2739, max_kl_dist_index: 0, max_train_grp_loss:  0.4477, max_train_grp_loss_index: 1, max_val_grp_loss:  0.4665, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.4477, max_cur_train_grp_loss_index: 1, 
2024-09-17 15:07:35,208 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  16500, train_loss:  0.0014, val_loss:  0.0004, grad_norm: 0.0222, live_grad: 0.0000, reward_err: 0.0385, 0.0347, 0.0127, KL_dist: 1.2796, 1.2423, 1.1558, param: [10.15923479  8.92124504  7.45888573  8.73550014], weights: [7.27476574e-01 2.71927861e-01 5.95565425e-04], train_wt_loss:  0.5249, val_wt_loss: 0.4127, train_grp_loss: [0.40959512 0.44278992 0.36306611], val_grp_loss: [0.40865187 0.46094943 0.35521859], train_hist_grp_loss: [7264.77421151 7166.36971317 6553.99162866], cur_train_grp_loss: [0.40958341 0.44284052 0.36305801], max_reward_err:  0.0385, max_reward_err_index: 0, max_kl_dist:  1.2796, max_kl_dist_index: 0, max_train_grp_loss:  0.4428, max_train_grp_loss_index: 1, max_val_grp_loss:  0.4609, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.4428, max_cur_train_grp_loss_index: 1, 
2024-09-17 15:07:38,000 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  16600, train_loss:  0.0014, val_loss:  0.0004, grad_norm: 0.0220, live_grad: 0.0000, reward_err: 0.0385, 0.0344, 0.0127, KL_dist: 1.2855, 1.2388, 1.1595, param: [10.2050274   8.88651098  7.49425562  8.70462543], weights: [7.21511015e-01 2.77925261e-01 5.63724904e-04], train_wt_loss:  0.5245, val_wt_loss: 0.4123, train_grp_loss: [0.41080772 0.43759272 0.36390912], val_grp_loss: [0.40990721 0.45510765 0.35569957], train_hist_grp_loss: [7305.79310074 7210.39355937 6590.33944581], cur_train_grp_loss: [0.41079523 0.43764587 0.36390039], max_reward_err:  0.0385, max_reward_err_index: 0, max_kl_dist:  1.2855, max_kl_dist_index: 0, max_train_grp_loss:  0.4376, max_train_grp_loss_index: 1, max_val_grp_loss:  0.4551, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.4376, max_cur_train_grp_loss_index: 1, 
2024-09-17 15:07:40,754 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  16700, train_loss:  0.0014, val_loss:  0.0004, grad_norm: 0.0218, live_grad: 0.0000, reward_err: 0.0388, 0.0342, 0.0128, KL_dist: 1.2914, 1.2351, 1.1632, param: [10.25169226  8.84944326  7.5306245   8.67180822], weights: [7.16793648e-01 2.82672072e-01 5.34279986e-04], train_wt_loss:  0.5240, val_wt_loss: 0.4117, train_grp_loss: [0.41208692 0.43218925 0.36480677], val_grp_loss: [0.41123133 0.44904566 0.35622184], train_hist_grp_loss: [7346.93673136 7253.8866781  6626.77440533], cur_train_grp_loss: [0.41207387 0.43224399 0.36479758], max_reward_err:  0.0388, max_reward_err_index: 0, max_kl_dist:  1.2914, max_kl_dist_index: 0, max_train_grp_loss:  0.4322, max_train_grp_loss_index: 1, max_val_grp_loss:  0.4490, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.4322, max_cur_train_grp_loss_index: 1, 
2024-09-17 15:07:43,528 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  16800, train_loss:  0.0014, val_loss:  0.0004, grad_norm: 0.0215, live_grad: 0.0000, reward_err: 0.0392, 0.0342, 0.0131, KL_dist: 1.2974, 1.2311, 1.1669, param: [10.29873235  8.8108257   7.56751891  8.63778404], weights: [7.13409948e-01 2.86082948e-01 5.07104180e-04], train_wt_loss:  0.5233, val_wt_loss: 0.4111, train_grp_loss: [0.41340993 0.42667582 0.36574213], val_grp_loss: [0.41260097 0.44287154 0.3567739 ], train_hist_grp_loss: [7388.21064464 7296.83320255 6663.30114166], cur_train_grp_loss: [0.41339656 0.42673118 0.36573265], max_reward_err:  0.0392, max_reward_err_index: 0, max_kl_dist:  1.2974, max_kl_dist_index: 0, max_train_grp_loss:  0.4267, max_train_grp_loss_index: 1, max_val_grp_loss:  0.4429, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.4267, max_cur_train_grp_loss_index: 1, 
2024-09-17 15:07:46,274 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  16900, train_loss:  0.0014, val_loss:  0.0004, grad_norm: 0.0213, live_grad: 0.0000, reward_err: 0.0392, 0.0338, 0.0131, KL_dist: 1.3034, 1.2272, 1.1707, param: [10.34564843  8.77146259  7.60446181  8.60329987], weights: [7.11409587e-01 2.88108363e-01 4.82050336e-04], train_wt_loss:  0.5225, val_wt_loss: 0.4104, train_grp_loss: [0.41475322 0.42114821 0.36669748], val_grp_loss: [0.41399199 0.43669215 0.35734354], train_hist_grp_loss: [7429.61806045 7339.22689368 6699.92255303], cur_train_grp_loss: [0.41473976 0.42120324 0.36668788], max_reward_err:  0.0392, max_reward_err_index: 0, max_kl_dist:  1.3034, max_kl_dist_index: 0, max_train_grp_loss:  0.4211, max_train_grp_loss_index: 1, max_val_grp_loss:  0.4367, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.4212, max_cur_train_grp_loss_index: 1, 
2024-09-17 15:07:49,041 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  17000, train_loss:  0.0014, val_loss:  0.0004, grad_norm: 0.0211, live_grad: 0.0000, reward_err: 0.0400, 0.0335, 0.0136, KL_dist: 1.3094, 1.2233, 1.1744, param: [10.3919527   8.73215638  7.64098561  8.56909366], weights: [7.10805744e-01 2.88735301e-01 4.58955651e-04], train_wt_loss:  0.5217, val_wt_loss: 0.4097, train_grp_loss: [0.41609309 0.41569892 0.36765475], val_grp_loss: [0.4153801  0.43061004 0.35791821], train_hist_grp_loss: [7471.15983186 7381.07094947 6736.63974469], cur_train_grp_loss: [0.41607978 0.41575273 0.36764522], max_reward_err:  0.0400, max_reward_err_index: 0, max_kl_dist:  1.3094, max_kl_dist_index: 0, max_train_grp_loss:  0.4161, max_train_grp_loss_index: 0, max_val_grp_loss:  0.4306, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.4161, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:07:51,849 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  17100, train_loss:  0.0014, val_loss:  0.0004, grad_norm: 0.0208, live_grad: 0.0000, reward_err: 0.0404, 0.0333, 0.0139, KL_dist: 1.3154, 1.2195, 1.1781, param: [10.43718128  8.69368646  7.67664414  8.53587528], weights: [7.11575979e-01 2.87986374e-01 4.37647175e-04], train_wt_loss:  0.5208, val_wt_loss: 0.4090, train_grp_loss: [0.41740636 0.41041486 0.36859606], val_grp_loss: [0.41674143 0.42472089 0.35848534], train_hist_grp_loss: [7512.83446338 7422.37756015 6773.45202051], cur_train_grp_loss: [0.41739344 0.41046662 0.36858678], max_reward_err:  0.0404, max_reward_err_index: 0, max_kl_dist:  1.3154, max_kl_dist_index: 0, max_train_grp_loss:  0.4174, max_train_grp_loss_index: 0, max_val_grp_loss:  0.4247, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.4174, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:07:54,608 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  17200, train_loss:  0.0014, val_loss:  0.0004, grad_norm: 0.0206, live_grad: 0.0000, reward_err: 0.0409, 0.0329, 0.0142, KL_dist: 1.3212, 1.2160, 1.1818, param: [10.4809051   8.65678974  7.71102315  8.50430952], weights: [7.13664492e-01 2.85917561e-01 4.17947386e-04], train_wt_loss:  0.5201, val_wt_loss: 0.4084, train_grp_loss: [0.41867095 0.4053754  0.36950415], val_grp_loss: [0.41805322 0.41911143 0.35903271], train_hist_grp_loss: [7554.63819071 7463.1672474  6810.35692294], cur_train_grp_loss: [0.41865862 0.40542435 0.36949529], max_reward_err:  0.0409, max_reward_err_index: 0, max_kl_dist:  1.3212, max_kl_dist_index: 0, max_train_grp_loss:  0.4187, max_train_grp_loss_index: 0, max_val_grp_loss:  0.4191, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.4187, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:07:57,369 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  17300, train_loss:  0.0013, val_loss:  0.0004, grad_norm: 0.0204, live_grad: 0.0000, reward_err: 0.0409, 0.0323, 0.0142, KL_dist: 1.3268, 1.2129, 1.1854, param: [10.52273875  8.62214389  7.74374903  8.47500183], weights: [7.16985528e-01 2.82614792e-01 3.99679492e-04], train_wt_loss:  0.5194, val_wt_loss: 0.4079, train_grp_loss: [0.4198664  0.40065088 0.37036285], val_grp_loss: [0.41929431 0.41385788 0.35954875], train_hist_grp_loss: [7596.56511678 7503.46803243 6847.35031892], cur_train_grp_loss: [0.41985485 0.40069636 0.37035456], max_reward_err:  0.0409, max_reward_err_index: 0, max_kl_dist:  1.3268, max_kl_dist_index: 0, max_train_grp_loss:  0.4199, max_train_grp_loss_index: 0, max_val_grp_loss:  0.4193, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4199, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:08:00,138 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  17400, train_loss:  0.0013, val_loss:  0.0004, grad_norm: 0.0202, live_grad: 0.0000, reward_err: 0.0411, 0.0323, 0.0144, KL_dist: 1.3322, 1.2101, 1.1889, param: [10.5623472   8.59035366  7.77449545  8.44848691], weights: [7.21427700e-01 2.78189628e-01 3.82672199e-04], train_wt_loss:  0.5189, val_wt_loss: 0.4075, train_grp_loss: [0.42097429 0.39630159 0.37115744], val_grp_loss: [0.42044567 0.40902501 0.36002284], train_hist_grp_loss: [7638.60739707 7543.31448018 6884.42652725], cur_train_grp_loss: [0.4209637  0.39634305 0.37114986], max_reward_err:  0.0411, max_reward_err_index: 0, max_kl_dist:  1.3322, max_kl_dist_index: 0, max_train_grp_loss:  0.4210, max_train_grp_loss_index: 0, max_val_grp_loss:  0.4204, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4210, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:08:02,919 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  17500, train_loss:  0.0013, val_loss:  0.0004, grad_norm: 0.0200, live_grad: 0.0000, reward_err: 0.0411, 0.0319, 0.0144, KL_dist: 1.3374, 1.2078, 1.1923, param: [10.59945045  8.56194055  7.80298807  8.42522057], weights: [7.26858992e-01 2.72774244e-01 3.66763762e-04], train_wt_loss:  0.5185, val_wt_loss: 0.4072, train_grp_loss: [0.42197868 0.39237729 0.37187501], val_grp_loss: [0.42149072 0.40466567 0.36044556], train_hist_grp_loss: [7680.75546531 7582.74666623 6921.57848152], cur_train_grp_loss: [0.42196919 0.39241429 0.37186825], max_reward_err:  0.0411, max_reward_err_index: 0, max_kl_dist:  1.3374, max_kl_dist_index: 0, max_train_grp_loss:  0.4220, max_train_grp_loss_index: 0, max_val_grp_loss:  0.4215, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4220, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:08:05,677 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  17600, train_loss:  0.0013, val_loss:  0.0004, grad_norm: 0.0199, live_grad: 0.0000, reward_err: 0.0411, 0.0319, 0.0144, KL_dist: 1.3423, 1.2061, 1.1957, param: [10.63382595  8.53733597  7.82900715  8.40557466], weights: [7.33132204e-01 2.66515991e-01 3.51805209e-04], train_wt_loss:  0.5182, val_wt_loss: 0.4071, train_grp_loss: [0.42286627 0.388917   0.37250464], val_grp_loss: [0.42241565 0.40082082 0.3608089 ], train_hist_grp_loss: [7722.99828982 7621.80910957 6958.79792126], cur_train_grp_loss: [0.42285801 0.3889492  0.37249881], max_reward_err:  0.0411, max_reward_err_index: 0, max_kl_dist:  1.3423, max_kl_dist_index: 0, max_train_grp_loss:  0.4229, max_train_grp_loss_index: 0, max_val_grp_loss:  0.4224, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4229, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:08:08,461 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  17700, train_loss:  0.0013, val_loss:  0.0004, grad_norm: 0.0197, live_grad: 0.0000, reward_err: 0.0413, 0.0311, 0.0146, KL_dist: 1.3468, 1.2048, 1.1989, param: [10.66530916  8.51687786  7.8523883   8.38983499], weights: [7.40090582e-01 2.59571756e-01 3.37662676e-04], train_wt_loss:  0.5181, val_wt_loss: 0.4071, train_grp_loss: [0.42362662 0.38594924 0.37303762], val_grp_loss: [0.42320955 0.39751989 0.36110635], train_hist_grp_loss: [7765.32364999 7660.54970927 6996.07560312], cur_train_grp_loss: [0.42361967 0.38597641 0.37303279], max_reward_err:  0.0413, max_reward_err_index: 0, max_kl_dist:  1.3468, max_kl_dist_index: 0, max_train_grp_loss:  0.4236, max_train_grp_loss_index: 0, max_val_grp_loss:  0.4232, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4236, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:08:11,230 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  17800, train_loss:  0.0013, val_loss:  0.0004, grad_norm: 0.0196, live_grad: 0.0000, reward_err: 0.0417, 0.0308, 0.0149, KL_dist: 1.3511, 1.2041, 1.2020, param: [10.69379237  8.50081044  7.8730216   8.37820208], weights: [7.47573370e-01 2.52102411e-01 3.24218848e-04], train_wt_loss:  0.5181, val_wt_loss: 0.4072, train_grp_loss: [0.42425214 0.38349255 0.37346749], val_grp_loss: [0.4238645  0.39478143 0.36133303], train_hist_grp_loss: [7807.7184226  7699.01871677 7033.40152375], cur_train_grp_loss: [0.42424657 0.38351455 0.37346372], max_reward_err:  0.0417, max_reward_err_index: 0, max_kl_dist:  1.3511, max_kl_dist_index: 0, max_train_grp_loss:  0.4243, max_train_grp_loss_index: 0, max_val_grp_loss:  0.4239, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4242, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:08:14,038 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  17900, train_loss:  0.0013, val_loss:  0.0004, grad_norm: 0.0195, live_grad: 0.0000, reward_err: 0.0417, 0.0304, 0.0149, KL_dist: 1.3550, 1.2040, 1.2049, param: [10.71922192  8.48928684  7.89084909  8.37079423], weights: [7.55421043e-01 2.44267583e-01 3.11373553e-04], train_wt_loss:  0.5181, val_wt_loss: 0.4074, train_grp_loss: [0.42473812 0.38155614 0.37379006], val_grp_loss: [0.4243755  0.39261404 0.36148565], train_hist_grp_loss: [7850.16886801 7737.2677689  7070.76514605], cur_train_grp_loss: [0.42473396 0.38157292 0.37378738], max_reward_err:  0.0417, max_reward_err_index: 0, max_kl_dist:  1.3550, max_kl_dist_index: 0, max_train_grp_loss:  0.4247, max_train_grp_loss_index: 0, max_val_grp_loss:  0.4244, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4247, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:08:16,799 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  18000, train_loss:  0.0013, val_loss:  0.0004, grad_norm: 0.0194, live_grad: 0.0000, reward_err: 0.0417, 0.0304, 0.0149, KL_dist: 1.3586, 1.2045, 1.2078, param: [10.7415944   8.48237414  7.90586127  8.36765261], weights: [7.63479958e-01 2.36220998e-01 2.99043572e-04], train_wt_loss:  0.5183, val_wt_loss: 0.4076, train_grp_loss: [0.42508249 0.38014082 0.37400329], val_grp_loss: [0.42474036 0.39101732 0.36156251], train_hist_grp_loss: [7892.66090747 7775.34899993 7108.15562108], cur_train_grp_loss: [0.42507974 0.38015241 0.3740017 ], max_reward_err:  0.0417, max_reward_err_index: 0, max_kl_dist:  1.3586, max_kl_dist_index: 0, max_train_grp_loss:  0.4251, max_train_grp_loss_index: 0, max_val_grp_loss:  0.4247, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4251, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:08:19,554 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  18100, train_loss:  0.0013, val_loss:  0.0004, grad_norm: 0.0194, live_grad: 0.0000, reward_err: 0.0417, 0.0304, 0.0149, KL_dist: 1.3618, 1.2056, 1.2104, param: [10.76095178  8.48006028  7.9180925   8.36874793], weights: [7.71606254e-01 2.28106584e-01 2.87161799e-04], train_wt_loss:  0.5186, val_wt_loss: 0.4079, train_grp_loss: [0.42528572 0.37923988 0.37410719], val_grp_loss: [0.42495949 0.389983   0.36156334], train_hist_grp_loss: [7935.18038392 7813.3142447  7145.56199894], cur_train_grp_loss: [0.42528438 0.37924638 0.37410668], max_reward_err:  0.0417, max_reward_err_index: 0, max_kl_dist:  1.3618, max_kl_dist_index: 0, max_train_grp_loss:  0.4253, max_train_grp_loss_index: 0, max_val_grp_loss:  0.4250, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4253, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:08:22,335 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  18200, train_loss:  0.0013, val_loss:  0.0004, grad_norm: 0.0193, live_grad: 0.0000, reward_err: 0.0417, 0.0304, 0.0149, KL_dist: 1.3647, 1.2071, 1.2130, param: [10.77737607  8.48226239  7.92761594  8.37398816], weights: [7.79668850e-01 2.20055474e-01 2.75675869e-04], train_wt_loss:  0.5188, val_wt_loss: 0.4082, train_grp_loss: [0.42535052 0.37884014 0.37410359], val_grp_loss: [0.42503565 0.38949605 0.36148927], train_hist_grp_loss: [7977.71330023 7851.21433923 7182.97342311], cur_train_grp_loss: [0.42535055 0.37884171 0.37410415], max_reward_err:  0.0417, max_reward_err_index: 0, max_kl_dist:  1.3647, max_kl_dist_index: 0, max_train_grp_loss:  0.4254, max_train_grp_loss_index: 0, max_val_grp_loss:  0.4250, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4254, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:08:25,115 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  18300, train_loss:  0.0013, val_loss:  0.0004, grad_norm: 0.0193, live_grad: 0.0000, reward_err: 0.0417, 0.0304, 0.0149, KL_dist: 1.3673, 1.2093, 1.2154, param: [10.79098363  8.48883587  7.9345381   8.38322684], weights: [7.87551491e-01 2.12183962e-01 2.64546428e-04], train_wt_loss:  0.5191, val_wt_loss: 0.4085, train_grp_loss: [0.42528159 0.3789229  0.37399599], val_grp_loss: [0.42497364 0.38953569 0.36134257], train_hist_grp_loss: [8020.24603083 7889.09852001 7220.37930428], cur_train_grp_loss: [0.42528293 0.37891976 0.37399756], max_reward_err:  0.0417, max_reward_err_index: 0, max_kl_dist:  1.3673, max_kl_dist_index: 0, max_train_grp_loss:  0.4253, max_train_grp_loss_index: 0, max_val_grp_loss:  0.4250, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4253, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:08:27,869 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  18400, train_loss:  0.0013, val_loss:  0.0004, grad_norm: 0.0194, live_grad: 0.0000, reward_err: 0.0417, 0.0304, 0.0149, KL_dist: 1.3696, 1.2119, 1.2177, param: [10.80191943  8.49958388  7.93899335  8.39627166], weights: [7.95153843e-01 2.04592412e-01 2.53745185e-04], train_wt_loss:  0.5193, val_wt_loss: 0.4088, train_grp_loss: [0.42508529 0.37946489 0.37378922], val_grp_loss: [0.42478003 0.39007644 0.36112656], train_hist_grp_loss: [8062.76550411 7927.01391964 7257.76947096], cur_train_grp_loss: [0.42508786 0.37945729 0.37379176], max_reward_err:  0.0417, max_reward_err_index: 0, max_kl_dist:  1.3696, max_kl_dist_index: 0, max_train_grp_loss:  0.4251, max_train_grp_loss_index: 0, max_val_grp_loss:  0.4248, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4251, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:08:30,619 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  18500, train_loss:  0.0013, val_loss:  0.0004, grad_norm: 0.0194, live_grad: 0.0000, reward_err: 0.0417, 0.0304, 0.0149, KL_dist: 1.3716, 1.2150, 1.2198, param: [10.81035157  8.51426658  7.94113855  8.41289277], weights: [8.02391727e-01 1.97365020e-01 2.43252894e-04], train_wt_loss:  0.5195, val_wt_loss: 0.4091, train_grp_loss: [0.42476933 0.38043913 0.3734893 ], val_grp_loss: [0.4244628  0.39108899 0.36084539], train_hist_grp_loss: [8105.25935463 7965.00515289 7295.13429581], cur_train_grp_loss: [0.42477305 0.38042735 0.37349274], max_reward_err:  0.0417, max_reward_err_index: 0, max_kl_dist:  1.3716, max_kl_dist_index: 0, max_train_grp_loss:  0.4248, max_train_grp_loss_index: 0, max_val_grp_loss:  0.4245, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4248, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:08:33,450 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  18600, train_loss:  0.0013, val_loss:  0.0004, grad_norm: 0.0194, live_grad: 0.0000, reward_err: 0.0417, 0.0304, 0.0149, KL_dist: 1.3734, 1.2186, 1.2219, param: [10.81646608  8.53261007  7.9411481   8.43283065], weights: [8.09196612e-01 1.90570330e-01 2.33057386e-04], train_wt_loss:  0.5197, val_wt_loss: 0.4093, train_grp_loss: [0.42434254 0.38181571 0.37310311], val_grp_loss: [0.42403107 0.39254104 0.36050387], train_hist_grp_loss: [8147.71604585 8003.11398534 7332.46479773], cur_train_grp_loss: [0.42434732 0.38180006 0.37310738], max_reward_err:  0.0417, max_reward_err_index: 0, max_kl_dist:  1.3734, max_kl_dist_index: 0, max_train_grp_loss:  0.4243, max_train_grp_loss_index: 0, max_val_grp_loss:  0.4240, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4243, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:08:36,245 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  18700, train_loss:  0.0013, val_loss:  0.0004, grad_norm: 0.0195, live_grad: 0.0000, reward_err: 0.0417, 0.0306, 0.0149, KL_dist: 1.3749, 1.2226, 1.2239, param: [10.82046228  8.55431441  7.93920943  8.45580331], weights: [8.15514537e-01 1.84262312e-01 2.23151761e-04], train_wt_loss:  0.5198, val_wt_loss: 0.4095, train_grp_loss: [0.42381453 0.38356247 0.37263824], val_grp_loss: [0.42349482 0.39439799 0.36010732], train_hist_grp_loss: [8190.12496488 8041.37907512 7369.75272075], cur_train_grp_loss: [0.42382028 0.38354328 0.37264326], max_reward_err:  0.0417, max_reward_err_index: 0, max_kl_dist:  1.3749, max_kl_dist_index: 0, max_train_grp_loss:  0.4238, max_train_grp_loss_index: 0, max_val_grp_loss:  0.4235, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4238, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:09:36,451 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  18800, train_loss:  0.0013, val_loss:  0.0004, grad_norm: 0.0196, live_grad: 0.0000, reward_err: 0.0417, 0.0306, 0.0149, KL_dist: 1.3762, 1.2270, 1.2258, param: [10.82254874  8.57906088  7.93551899  8.48151257], weights: [8.21304615e-01 1.78481853e-01 2.13532778e-04], train_wt_loss:  0.5198, val_wt_loss: 0.4096, train_grp_loss: [0.42319552 0.38564558 0.37210274], val_grp_loss: [0.4228646  0.39662347 0.35966142], train_hist_grp_loss: [8232.47649179 8079.83577787 7406.99059169], cur_train_grp_loss: [0.42320213 0.3856232  0.37210842], max_reward_err:  0.0417, max_reward_err_index: 0, max_kl_dist:  1.3762, max_kl_dist_index: 0, max_train_grp_loss:  0.4232, max_train_grp_loss_index: 0, max_val_grp_loss:  0.4229, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4232, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:09:39,217 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  18900, train_loss:  0.0013, val_loss:  0.0004, grad_norm: 0.0197, live_grad: 0.0000, reward_err: 0.0417, 0.0311, 0.0149, KL_dist: 1.3773, 1.2317, 1.2277, param: [10.82293976  8.60651805  7.93027894  8.50964948], weights: [8.26537311e-01 1.73258490e-01 2.04199501e-04], train_wt_loss:  0.5198, val_wt_loss: 0.4096, train_grp_loss: [0.42249607 0.38803005 0.37150496], val_grp_loss: [0.42215138 0.39917989 0.35917206], train_hist_grp_loss: [8274.76204658 8118.5160046  7444.17175893], cur_train_grp_loss: [0.42250343 0.38800483 0.37151121], max_reward_err:  0.0417, max_reward_err_index: 0, max_kl_dist:  1.3773, max_kl_dist_index: 0, max_train_grp_loss:  0.4225, max_train_grp_loss_index: 0, max_val_grp_loss:  0.4222, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4225, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:09:41,994 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  19000, train_loss:  0.0013, val_loss:  0.0004, grad_norm: 0.0198, live_grad: 0.0000, reward_err: 0.0413, 0.0315, 0.0146, KL_dist: 1.3783, 1.2367, 1.2295, param: [10.82185263  8.63634696  7.92369438  8.53989881], weights: [8.31192613e-01 1.68612235e-01 1.95152209e-04], train_wt_loss:  0.5197, val_wt_loss: 0.4096, train_grp_loss: [0.42172694 0.39068005 0.3708534 ], val_grp_loss: [0.42136631 0.40202876 0.35864526], train_hist_grp_loss: [8316.97411712 8157.44812282 7481.290415  ], cur_train_grp_loss: [0.42173494 0.39065236 0.37086016], max_reward_err:  0.0413, max_reward_err_index: 0, max_kl_dist:  1.3783, max_kl_dist_index: 0, max_train_grp_loss:  0.4217, max_train_grp_loss_index: 0, max_val_grp_loss:  0.4214, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4217, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:09:44,776 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  19100, train_loss:  0.0013, val_loss:  0.0004, grad_norm: 0.0199, live_grad: 0.0000, reward_err: 0.0413, 0.0319, 0.0146, KL_dist: 1.3792, 1.2420, 1.2313, param: [10.81950527  8.66820518  7.91597112  8.57194256], weights: [8.35258233e-01 1.64555376e-01 1.86391549e-04], train_wt_loss:  0.5195, val_wt_loss: 0.4095, train_grp_loss: [0.42089895 0.39355928 0.37015662], val_grp_loss: [0.42052058 0.405131   0.35808704], train_hist_grp_loss: [8359.10627131 8196.65689181 7518.34160575], cur_train_grp_loss: [0.42090749 0.39352947 0.37016378], max_reward_err:  0.0413, max_reward_err_index: 0, max_kl_dist:  1.3792, max_kl_dist_index: 0, max_train_grp_loss:  0.4209, max_train_grp_loss_index: 0, max_val_grp_loss:  0.4205, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4209, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:09:47,521 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  19200, train_loss:  0.0013, val_loss:  0.0004, grad_norm: 0.0200, live_grad: 0.0000, reward_err: 0.0413, 0.0319, 0.0146, KL_dist: 1.3800, 1.2476, 1.2330, param: [10.81611464  8.70175001  7.90731403  8.60546276], weights: [8.38727922e-01 1.61094160e-01 1.77917928e-04], train_wt_loss:  0.5193, val_wt_loss: 0.4094, train_grp_loss: [0.42002287 0.39663113 0.36942308], val_grp_loss: [0.41962534 0.40844714 0.3575034 ], train_hist_grp_loss: [8401.15315694 8236.1634241  7555.32122877], cur_train_grp_loss: [0.42003184 0.39659958 0.36943057], max_reward_err:  0.0413, max_reward_err_index: 0, max_kl_dist:  1.3800, max_kl_dist_index: 0, max_train_grp_loss:  0.4200, max_train_grp_loss_index: 0, max_val_grp_loss:  0.4196, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4200, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:09:50,281 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  19300, train_loss:  0.0013, val_loss:  0.0004, grad_norm: 0.0202, live_grad: 0.0000, reward_err: 0.0413, 0.0323, 0.0146, KL_dist: 1.3807, 1.2533, 1.2347, param: [10.81189537  8.73664079  7.89792583  8.64014348], weights: [8.41599971e-01 1.58230298e-01 1.69731097e-04], train_wt_loss:  0.5190, val_wt_loss: 0.4092, train_grp_loss: [0.41910932 0.39985891 0.36866115], val_grp_loss: [0.41869158 0.41193747 0.35690023], train_hist_grp_loss: [8443.11049184 8275.98516619 7592.22602359], cur_train_grp_loss: [0.41911861 0.39982598 0.36866888], max_reward_err:  0.0413, max_reward_err_index: 0, max_kl_dist:  1.3807, max_kl_dist_index: 0, max_train_grp_loss:  0.4191, max_train_grp_loss_index: 0, max_val_grp_loss:  0.4187, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4191, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:09:53,028 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  19400, train_loss:  0.0013, val_loss:  0.0004, grad_norm: 0.0203, live_grad: 0.0000, reward_err: 0.0413, 0.0323, 0.0146, KL_dist: 1.3814, 1.2591, 1.2365, param: [10.807059    8.77254059  7.88800621  8.67567222], weights: [8.43875929e-01 1.55962242e-01 1.61829910e-04], train_wt_loss:  0.5187, val_wt_loss: 0.4090, train_grp_loss: [0.41816873 0.4032059  0.36787897], val_grp_loss: [0.41773008 0.41556215 0.35628327], train_hist_grp_loss: [8484.97504725 8316.13589293 7629.0535558 ], cur_train_grp_loss: [0.41817824 0.40317196 0.36788687], max_reward_err:  0.0413, max_reward_err_index: 0, max_kl_dist:  1.3814, max_kl_dist_index: 0, max_train_grp_loss:  0.4182, max_train_grp_loss_index: 0, max_val_grp_loss:  0.4177, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4182, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:09:55,777 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  19500, train_loss:  0.0013, val_loss:  0.0004, grad_norm: 0.0204, live_grad: 0.0000, reward_err: 0.0413, 0.0325, 0.0146, KL_dist: 1.3820, 1.2651, 1.2382, param: [10.80181334  8.80911727  7.87775131  8.71174087], weights: [8.45559565e-01 1.54286222e-01 1.54212204e-04], train_wt_loss:  0.5184, val_wt_loss: 0.4087, train_grp_loss: [0.41721131 0.40663547 0.36708451], val_grp_loss: [0.41675137 0.41928128 0.35565811], train_hist_grp_loss: [8526.74462638 8356.62571121 7665.80219694], cur_train_grp_loss: [0.41722093 0.40660089 0.36709249], max_reward_err:  0.0413, max_reward_err_index: 0, max_kl_dist:  1.3820, max_kl_dist_index: 0, max_train_grp_loss:  0.4172, max_train_grp_loss_index: 0, max_val_grp_loss:  0.4193, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.4172, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:09:58,535 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  19600, train_loss:  0.0014, val_loss:  0.0004, grad_norm: 0.0206, live_grad: 0.0000, reward_err: 0.0413, 0.0329, 0.0146, KL_dist: 1.3827, 1.2711, 1.2400, param: [10.79636222  8.84604415  7.8673534   8.74804628], weights: [8.46656093e-01 1.53197032e-01 1.46874794e-04], train_wt_loss:  0.5181, val_wt_loss: 0.4085, train_grp_loss: [0.41624699 0.4101111  0.36628547], val_grp_loss: [0.41576572 0.42305492 0.35503016], train_hist_grp_loss: [8568.41803991 8397.46106989 7702.47110184], cur_train_grp_loss: [0.41625663 0.41007624 0.36629345], max_reward_err:  0.0413, max_reward_err_index: 0, max_kl_dist:  1.3827, max_kl_dist_index: 0, max_train_grp_loss:  0.4162, max_train_grp_loss_index: 0, max_val_grp_loss:  0.4231, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.4163, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:10:01,312 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  19700, train_loss:  0.0014, val_loss:  0.0004, grad_norm: 0.0207, live_grad: 0.0000, reward_err: 0.0411, 0.0333, 0.0144, KL_dist: 1.3833, 1.2772, 1.2418, param: [10.7909052   8.88300039  7.85700065  8.78429062], weights: [8.47171632e-01 1.52688554e-01 1.39813534e-04], train_wt_loss:  0.5177, val_wt_loss: 0.4082, train_grp_loss: [0.41528545 0.41359644 0.36548931], val_grp_loss: [0.4147831  0.42684317 0.35440464], train_hist_grp_loss: [8609.99507974 8438.64477418 7739.06018427], cur_train_grp_loss: [0.41529502 0.41356166 0.36549723], max_reward_err:  0.0411, max_reward_err_index: 0, max_kl_dist:  1.3833, max_kl_dist_index: 0, max_train_grp_loss:  0.4153, max_train_grp_loss_index: 0, max_val_grp_loss:  0.4268, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.4153, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:10:04,115 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  19800, train_loss:  0.0014, val_loss:  0.0004, grad_norm: 0.0208, live_grad: 0.0000, reward_err: 0.0411, 0.0333, 0.0144, KL_dist: 1.3841, 1.2832, 1.2436, param: [10.78563751  8.91967124  7.84687708  8.82018155], weights: [8.47112924e-01 1.52754053e-01 1.33023431e-04], train_wt_loss:  0.5174, val_wt_loss: 0.4079, train_grp_loss: [0.4143361  0.41705534 0.36470325], val_grp_loss: [0.41381317 0.43060616 0.35378657], train_hist_grp_loss: [8651.47649194 8480.1760041  7775.57009203], cur_train_grp_loss: [0.4143455  0.417021   0.36471104], max_reward_err:  0.0411, max_reward_err_index: 0, max_kl_dist:  1.3841, max_kl_dist_index: 0, max_train_grp_loss:  0.4171, max_train_grp_loss_index: 1, max_val_grp_loss:  0.4306, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.4170, max_cur_train_grp_loss_index: 1, 
2024-09-17 15:10:06,991 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  19900, train_loss:  0.0014, val_loss:  0.0004, grad_norm: 0.0210, live_grad: 0.0000, reward_err: 0.0406, 0.0333, 0.0141, KL_dist: 1.3848, 1.2892, 1.2454, param: [10.78074987  8.95574821  7.83716234  8.85543252], weights: [8.46487280e-01 1.53386221e-01 1.26498795e-04], train_wt_loss:  0.5171, val_wt_loss: 0.4077, train_grp_loss: [0.41340806 0.42045193 0.36393426], val_grp_loss: [0.41286533 0.43430419 0.3531808 ], train_hist_grp_loss: [8692.86394919 8522.05033759 7812.00218176], cur_train_grp_loss: [0.41341721 0.42041839 0.36394184], max_reward_err:  0.0406, max_reward_err_index: 0, max_kl_dist:  1.3848, max_kl_dist_index: 0, max_train_grp_loss:  0.4205, max_train_grp_loss_index: 1, max_val_grp_loss:  0.4343, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.4204, max_cur_train_grp_loss_index: 1, 
2024-09-17 15:10:09,778 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  19999, train_loss:  0.0014, val_loss:  0.0004, grad_norm: 0.0211,  live_grad: 0.0000, reward_err: 0.0402, 0.0333, 0.0138, KL_dist: 1.3857, 1.2950, 1.2473, param: [10.77646806  8.99058295  7.82811945  8.88942523], weights: [8.45317338e-01 1.54562367e-01 1.20294791e-04], train_wt_loss:  0.5169, val_wt_loss: 0.4075, train_grp_loss: [0.41251898 0.42371828 0.36319635], val_grp_loss: [0.41195764 0.43786247 0.35259776], train_hist_grp_loss: [8733.74750393 8563.83606219 7847.99529741], cur_train_grp_loss: [0.41252779 0.42368588 0.36320366], max_reward_err:  0.0402, max_reward_err_index: 0, max_kl_dist:  1.3857, max_kl_dist_index: 0, max_train_grp_loss:  0.4237, max_train_grp_loss_index: 1, max_val_grp_loss:  0.4379, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.4237, max_cur_train_grp_loss_index: 1, 
2024-09-17 15:10:10,030 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:386] - INFO: Policy parameter learned solely on the preference data rdpo: [10.77646806  8.99058295  7.82811945  8.88942523].
2024-09-17 15:10:10,421 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:397] - INFO: Uniform reward: 3.8354, 3.8354, 3.1915
2024-09-17 15:10:10,422 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Optimal reward: 3.8668, 3.8668, 3.3221
2024-09-17 15:10:10,423 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Policy reward: 3.7115, 3.7381, 3.2761
2024-09-17 15:10:10,423 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Reward Error: 0.0402, 0.0333, 0.0138
2024-09-17 15:10:11,188 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:415] - INFO: Optimal reward: 3.8668, 3.8668, 3.3221
Known param reward: [[3.8668251953125, 3.5332451171875, 3.27332373046875], [3.5332451171875, 3.8668251953125, 3.158748046875], [3.82422265625, 3.6346572265625, 3.32206298828125]], Known param reward error: [[0.0, 0.08626717301040067, 0.014671382807740363], [0.08626717301040067, 0.0, 0.04916069983692422], [0.011017446331461862, 0.060040978586630156, 0.0]].
