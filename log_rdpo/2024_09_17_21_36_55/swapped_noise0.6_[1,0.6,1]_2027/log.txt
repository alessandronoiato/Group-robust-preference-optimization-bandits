2024-09-17 21:42:00,280 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:198] - INFO: Logging to log_rdpo/2024_09_17_21_36_55/swapped_noise0.6_[1,0.6,1]_2027
2024-09-17 21:42:00,282 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: (IB) Seed: 2027
2024-09-17 21:42:00,283 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Data: 300
2024-09-17 21:42:00,440 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:296] - INFO: MLE reward loss: 0.4381, l2 distance: 23.5455, acc: 0.80.
2024-09-17 21:42:00,441 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-17 21:42:00,442 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: MLE reward parameter: [10.57644988  5.52515933  9.88716849  7.5816798 ]
2024-09-17 21:42:00,642 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:313] - INFO: Learned oracle reward: 3.5609, 3.7305, 3.1644
2024-09-17 21:42:00,883 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-17 21:42:02,051 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  16.3886, val_loss:  16.7232, grad_norm: 0.2573, live_grad: 0.0000, reward_err: 0.0828, 0.0045, 0.0466, KL_dist: 1.7718, 1.0332, 1.4580, param: [10.50263908  4.66479709 12.45803852  6.11973523], weights: [0.33332777 0.33335137 0.33332085], train_wt_loss:  49.1658, val_wt_loss: 50.1695, train_grp_loss: [18.38817271 12.03385687 18.18215211], val_grp_loss: [19.38712582 14.99200399 15.71863793], train_hist_grp_loss: [0.21612943 0.22320876 0.21405334], cur_train_grp_loss: [0.21612943 0.22320876 0.21405334], max_reward_err:  0.0828, max_reward_err_index: 0, max_kl_dist:  1.7718, max_kl_dist_index: 0, max_train_grp_loss:  18.3882, max_train_grp_loss_index: 0, max_val_grp_loss:  19.3871, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2232, max_cur_train_grp_loss_index: 1, 
2024-09-17 21:42:06,273 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  99, train_loss:  16.3896, val_loss:  16.7305, grad_norm: 0.0044,  live_grad: 0.0000, reward_err: 0.0828, 0.0047, 0.0466, KL_dist: 1.7786, 1.0466, 1.4660, param: [10.52072272  4.7775013  12.50089333  6.21610302], weights: [0.33847836 0.32427306 0.33724858], train_wt_loss:  49.1687, val_wt_loss: 50.1914, train_grp_loss: [18.32115449 12.19415807 18.11244241], val_grp_loss: [19.31616008 15.15757704 15.65254736], train_hist_grp_loss: [17.68853233 13.40110746 17.32454323], cur_train_grp_loss: [0.17617136 0.13398384 0.17250606], max_reward_err:  0.0828, max_reward_err_index: 0, max_kl_dist:  1.7786, max_kl_dist_index: 0, max_train_grp_loss:  18.3212, max_train_grp_loss_index: 0, max_val_grp_loss:  19.3162, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.1762, max_cur_train_grp_loss_index: 0, 
2024-09-17 21:42:06,483 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:386] - INFO: Policy parameter learned solely on the preference data rdpo: [10.52072272  4.7775013  12.50089333  6.21610302].
2024-09-17 21:42:06,797 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:397] - INFO: Uniform reward: 3.7386, 3.7386, 3.1050
2024-09-17 21:42:06,798 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Optimal reward: 3.7797, 3.7797, 3.2487
2024-09-17 21:42:06,798 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Policy reward: 3.4669, 3.7621, 3.0972
2024-09-17 21:42:06,799 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Reward Error: 0.0828, 0.0047, 0.0466
2024-09-17 21:42:07,442 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:415] - INFO: Optimal reward: 3.7797, 3.7797, 3.2487
Known param reward: [[3.779723644256592, 3.4200356006622314, 3.2069242000579834], [3.4200356006622314, 3.779723644256592, 3.065584421157837], [3.741098642349243, 3.5430009365081787, 3.248685598373413]], Known param reward error: [[0.0, 0.0951625244191907, 0.012854859927454733], [0.0951625244191907, 0.0, 0.05636161815943446], [0.01021900158389636, 0.06262963381148795, 0.0]].
