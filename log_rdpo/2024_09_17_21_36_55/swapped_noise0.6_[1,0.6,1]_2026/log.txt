2024-09-17 21:41:39,280 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:198] - INFO: Logging to log_rdpo/2024_09_17_21_36_55/swapped_noise0.6_[1,0.6,1]_2026
2024-09-17 21:41:39,282 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: (IB) Seed: 2026
2024-09-17 21:41:39,282 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Data: 300
2024-09-17 21:41:39,439 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:296] - INFO: MLE reward loss: 0.4485, l2 distance: 19.4178, acc: 0.80.
2024-09-17 21:41:39,440 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-17 21:41:39,440 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: MLE reward parameter: [ 7.26938793  6.21993296 10.33362814  4.30205527]
2024-09-17 21:41:39,643 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:313] - INFO: Learned oracle reward: 3.5664, 3.8388, 3.2173
2024-09-17 21:41:39,900 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-17 21:41:41,065 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  16.2876, val_loss:  16.8505, grad_norm: 0.2481, live_grad: 0.0000, reward_err: 0.0857, 0.0053, 0.0494, KL_dist: 1.6318, 0.9898, 1.3411, param: [ 9.45152746  6.91573044 12.44840653  4.56018561], weights: [0.33334255 0.33326111 0.33339634], train_wt_loss:  48.8629, val_wt_loss: 50.5516, train_grp_loss: [18.57586132 15.30575769 14.78660113], val_grp_loss: [19.2233667  14.12535621 16.98816394], train_hist_grp_loss: [0.21604367 0.1916109  0.23217848], cur_train_grp_loss: [0.21604367 0.1916109  0.23217848], max_reward_err:  0.0857, max_reward_err_index: 0, max_kl_dist:  1.6318, max_kl_dist_index: 0, max_train_grp_loss:  18.5759, max_train_grp_loss_index: 0, max_val_grp_loss:  19.2234, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2322, max_cur_train_grp_loss_index: 2, 
2024-09-17 21:41:45,334 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  99, train_loss:  16.2878, val_loss:  16.8528, grad_norm: 0.0017,  live_grad: 0.0000, reward_err: 0.0857, 0.0055, 0.0494, KL_dist: 1.6349, 0.9948, 1.3446, param: [ 9.45066731  6.95226336 12.47358573  4.59226728], weights: [0.33826995 0.32991349 0.33181656], train_wt_loss:  48.8633, val_wt_loss: 50.5583, train_grp_loss: [18.55145725 15.35371381 14.76275558], val_grp_loss: [19.20035468 14.18147859 16.9651145 ], train_hist_grp_loss: [17.71898978 15.21761025 15.79279216], cur_train_grp_loss: [0.17668286 0.15201221 0.15705311], max_reward_err:  0.0857, max_reward_err_index: 0, max_kl_dist:  1.6349, max_kl_dist_index: 0, max_train_grp_loss:  18.5515, max_train_grp_loss_index: 0, max_val_grp_loss:  19.2004, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.1767, max_cur_train_grp_loss_index: 0, 
2024-09-17 21:41:45,544 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:386] - INFO: Policy parameter learned solely on the preference data rdpo: [ 9.45066731  6.95226336 12.47358573  4.59226728].
2024-09-17 21:41:45,853 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:397] - INFO: Uniform reward: 3.8367, 3.8367, 3.2239
2024-09-17 21:41:45,854 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Optimal reward: 3.8763, 3.8763, 3.3712
2024-09-17 21:41:45,854 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Policy reward: 3.5441, 3.8552, 3.2046
2024-09-17 21:41:45,855 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Reward Error: 0.0857, 0.0055, 0.0494
2024-09-17 21:41:46,497 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:415] - INFO: Optimal reward: 3.8763, 3.8763, 3.3712
Known param reward: [[3.8763370513916016, 3.4733924865722656, 3.3310515880584717], [3.4733924865722656, 3.8763370513916016, 3.1582860946655273], [3.8394391536712646, 3.610290050506592, 3.3711864948272705]], Known param reward error: [[0.0, 0.10394982672486625, 0.011905276326415522], [0.10394982672486625, 0.0, 0.0631529583096089], [0.00951875371804694, 0.06863360883169309, 0.0]].
