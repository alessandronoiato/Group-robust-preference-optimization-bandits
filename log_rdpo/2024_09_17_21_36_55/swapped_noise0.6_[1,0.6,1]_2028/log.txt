2024-09-17 21:42:19,603 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:198] - INFO: Logging to log_rdpo/2024_09_17_21_36_55/swapped_noise0.6_[1,0.6,1]_2028
2024-09-17 21:42:19,605 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: (IB) Seed: 2028
2024-09-17 21:42:19,605 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Data: 300
2024-09-17 21:42:19,762 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:296] - INFO: MLE reward loss: 0.5479, l2 distance: 10.6788, acc: 0.76.
2024-09-17 21:42:19,763 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-17 21:42:19,763 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: MLE reward parameter: [5.83457493 2.77303332 5.60181542 4.29838515]
2024-09-17 21:42:19,967 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:313] - INFO: Learned oracle reward: 3.6137, 3.8197, 3.2373
2024-09-17 21:42:20,215 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-17 21:42:21,393 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  19.2847, val_loss:  17.4877, grad_norm: 0.1039, live_grad: 0.0000, reward_err: 0.0812, 0.0070, 0.0436, KL_dist: 1.1505, 0.6503, 0.9102, param: [9.01946865 3.55925859 8.75978446 5.5465703 ], weights: [0.33326001 0.33334385 0.33339615], train_wt_loss:  57.8542, val_wt_loss: 52.4632, train_grp_loss: [21.74281768 16.64924487 18.67685559], val_grp_loss: [20.14140051 13.96635821 18.0690465 ], train_hist_grp_loss: [0.18111984 0.20627475 0.22196285], cur_train_grp_loss: [0.18111984 0.20627475 0.22196285], max_reward_err:  0.0812, max_reward_err_index: 0, max_kl_dist:  1.1505, max_kl_dist_index: 0, max_train_grp_loss:  21.7428, max_train_grp_loss_index: 0, max_val_grp_loss:  20.1414, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2220, max_cur_train_grp_loss_index: 2, 
2024-09-17 21:42:25,639 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  99, train_loss:  19.2848, val_loss:  17.4856, grad_norm: 0.0008,  live_grad: 0.0000, reward_err: 0.0805, 0.0070, 0.0431, KL_dist: 1.1540, 0.6539, 0.9135, param: [8.99515284 3.57365002 8.81945446 5.56318841], weights: [0.33051595 0.33140925 0.33807479], train_wt_loss:  57.8544, val_wt_loss: 52.4569, train_grp_loss: [21.73713426 16.67982072 18.65426557], val_grp_loss: [20.13137609 13.97966125 18.0604661 ], train_hist_grp_loss: [18.26729206 18.53720147 20.5285149 ], cur_train_grp_loss: [0.18266545 0.18532798 0.2049944 ], max_reward_err:  0.0805, max_reward_err_index: 0, max_kl_dist:  1.1540, max_kl_dist_index: 0, max_train_grp_loss:  21.7371, max_train_grp_loss_index: 0, max_val_grp_loss:  20.1314, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2050, max_cur_train_grp_loss_index: 2, 
2024-09-17 21:42:25,851 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:386] - INFO: Policy parameter learned solely on the preference data rdpo: [8.99515284 3.57365002 8.81945446 5.56318841].
2024-09-17 21:42:26,162 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:397] - INFO: Uniform reward: 3.8339, 3.8339, 3.2071
2024-09-17 21:42:26,163 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Optimal reward: 3.8707, 3.8707, 3.3444
2024-09-17 21:42:26,163 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Policy reward: 3.5589, 3.8436, 3.2003
2024-09-17 21:42:26,164 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Reward Error: 0.0805, 0.0070, 0.0431
2024-09-17 21:42:26,813 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:415] - INFO: Optimal reward: 3.8707, 3.8707, 3.3444
Known param reward: [[3.870683431625366, 3.460294485092163, 3.3091318607330322], [3.460294485092163, 3.870683431625366, 3.128795862197876], [3.837958335876465, 3.610339403152466, 3.34438419342041]], Known param reward error: [[0.0, 0.10602493171622505, 0.01054075448530458], [0.10602493171622505, 0.0, 0.06446278858950263], [0.008454604032332228, 0.0672604807579362, 0.0]].
