2024-09-17 21:42:39,236 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:198] - INFO: Logging to log_rdpo/2024_09_17_21_36_55/swapped_noise0.6_[1,0.6,1]_2029
2024-09-17 21:42:39,238 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: (IB) Seed: 2029
2024-09-17 21:42:39,239 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Data: 300
2024-09-17 21:42:39,396 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:296] - INFO: MLE reward loss: 0.4434, l2 distance: 17.1951, acc: 0.83.
2024-09-17 21:42:39,397 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-17 21:42:39,398 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: MLE reward parameter: [8.01407426 6.26485701 7.94707589 3.98137886]
2024-09-17 21:42:39,593 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:313] - INFO: Learned oracle reward: 3.5772, 3.7816, 3.1959
2024-09-17 21:42:39,844 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-17 21:42:41,035 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  16.1362, val_loss:  17.1971, grad_norm: 0.3123, live_grad: 0.0000, reward_err: 0.0916, 0.0093, 0.0513, KL_dist: 1.3566, 0.7390, 1.1010, param: [10.9513091   5.89559601  8.00768897  3.49575907], weights: [0.33339637 0.33321377 0.33338986], train_wt_loss:  48.4087, val_wt_loss: 51.5913, train_grp_loss: [18.88112145 12.16932612 17.99393148], val_grp_loss: [20.11239526 13.54776659 17.54112328], train_hist_grp_loss: [0.23436724 0.17958393 0.23241473], cur_train_grp_loss: [0.23436724 0.17958393 0.23241473], max_reward_err:  0.0916, max_reward_err_index: 0, max_kl_dist:  1.3566, max_kl_dist_index: 0, max_train_grp_loss:  18.8811, max_train_grp_loss_index: 0, max_val_grp_loss:  20.1124, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2344, max_cur_train_grp_loss_index: 0, 
2024-09-17 21:42:45,230 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  99, train_loss:  16.1391, val_loss:  17.1767, grad_norm: 0.0077,  live_grad: 0.0000, reward_err: 0.0910, 0.0091, 0.0508, KL_dist: 1.3668, 0.7604, 1.1112, param: [10.93916198  6.02449266  8.19663966  3.65397041], weights: [0.34457441 0.31539614 0.34002945], train_wt_loss:  48.4173, val_wt_loss: 51.5302, train_grp_loss: [18.77286163 12.36029933 17.89009178], val_grp_loss: [20.01505027 13.71656793 17.43025068], train_hist_grp_loss: [20.06361719 11.21555302 18.7358327 ], cur_train_grp_loss: [0.19972307 0.11234791 0.18636615], max_reward_err:  0.0910, max_reward_err_index: 0, max_kl_dist:  1.3668, max_kl_dist_index: 0, max_train_grp_loss:  18.7729, max_train_grp_loss_index: 0, max_val_grp_loss:  20.0151, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.1997, max_cur_train_grp_loss_index: 0, 
2024-09-17 21:42:45,449 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:386] - INFO: Policy parameter learned solely on the preference data rdpo: [10.93916198  6.02449266  8.19663966  3.65397041].
2024-09-17 21:42:45,761 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:397] - INFO: Uniform reward: 3.8016, 3.8016, 3.1671
2024-09-17 21:42:45,762 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Optimal reward: 3.8414, 3.8414, 3.2997
2024-09-17 21:42:45,762 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Policy reward: 3.4918, 3.8066, 3.1322
2024-09-17 21:42:45,762 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Reward Error: 0.0910, 0.0091, 0.0508
2024-09-17 21:42:46,409 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:415] - INFO: Optimal reward: 3.8414, 3.8414, 3.2997
Known param reward: [[3.8414433002471924, 3.4536936283111572, 3.2716972827911377], [3.4536936283111572, 3.8414433002471924, 3.109083414077759], [3.8053715229034424, 3.562098741531372, 3.2997119426727295]], Known param reward error: [[0.0, 0.10093853836423511, 0.008490031968942185], [0.10093853836423511, 0.0, 0.057771263645687736], [0.009390162635337823, 0.07271864684241072, 0.0]].
