2024-09-17 21:40:07,552 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:198] - INFO: Logging to log_rdpo/2024_09_17_21_36_55/swapped_noise0.6_[1,0.6,1]_2021
2024-09-17 21:40:07,554 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: (IB) Seed: 2021
2024-09-17 21:40:07,554 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Data: 300
2024-09-17 21:40:07,711 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:296] - INFO: MLE reward loss: 0.4643, l2 distance: 15.7244, acc: 0.84.
2024-09-17 21:40:07,712 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-17 21:40:07,713 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: MLE reward parameter: [6.42704862 4.30344058 8.65324586 4.87795712]
2024-09-17 21:40:07,915 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:313] - INFO: Learned oracle reward: 3.4931, 3.7540, 3.1081
2024-09-17 21:40:08,162 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-17 21:40:09,376 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  16.5533, val_loss:  17.5913, grad_norm: 0.2065, live_grad: 0.0000, reward_err: 0.0979, 0.0055, 0.0603, KL_dist: 1.6059, 0.7787, 1.3258, param: [ 7.41255752  3.8978313  12.63737081  5.29583108], weights: [0.33336605 0.33323748 0.33339648], train_wt_loss:  49.6598, val_wt_loss: 52.7739, train_grp_loss: [18.7848606  14.36296039 16.62505656], val_grp_loss: [19.68851557 14.77151763 18.47054949], train_hist_grp_loss: [0.20975087 0.17117695 0.21887839], cur_train_grp_loss: [0.20975087 0.17117695 0.21887839], max_reward_err:  0.0979, max_reward_err_index: 0, max_kl_dist:  1.6059, max_kl_dist_index: 0, max_train_grp_loss:  18.7849, max_train_grp_loss_index: 0, max_val_grp_loss:  19.6885, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2189, max_cur_train_grp_loss_index: 2, 
2024-09-17 21:40:13,658 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  99, train_loss:  16.5542, val_loss:  17.5810, grad_norm: 0.0044,  live_grad: 0.0000, reward_err: 0.0970, 0.0056, 0.0595, KL_dist: 1.6164, 0.7921, 1.3364, param: [ 7.45240162  3.97916291 12.69779188  5.38562688], weights: [0.34030056 0.32367867 0.33602077], train_wt_loss:  49.6625, val_wt_loss: 52.7431, train_grp_loss: [18.7231741  14.48221683 16.56108932], val_grp_loss: [19.62657321 14.85709243 18.40961842], train_hist_grp_loss: [18.77651016 13.76871563 17.51088641], cur_train_grp_loss: [0.18723795 0.1379142  0.17433402], max_reward_err:  0.0970, max_reward_err_index: 0, max_kl_dist:  1.6164, max_kl_dist_index: 0, max_train_grp_loss:  18.7232, max_train_grp_loss_index: 0, max_val_grp_loss:  19.6266, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.1872, max_cur_train_grp_loss_index: 0, 
2024-09-17 21:40:13,874 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:386] - INFO: Policy parameter learned solely on the preference data rdpo: [ 7.45240162  3.97916291 12.69779188  5.38562688].
2024-09-17 21:40:14,192 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:397] - INFO: Uniform reward: 3.7608, 3.7608, 3.1229
2024-09-17 21:40:14,193 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Optimal reward: 3.7925, 3.7925, 3.2476
2024-09-17 21:40:14,193 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Policy reward: 3.4246, 3.7714, 3.0544
2024-09-17 21:40:14,194 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Reward Error: 0.0970, 0.0056, 0.0595
2024-09-17 21:40:14,850 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:415] - INFO: Optimal reward: 3.7925, 3.7925, 3.2476
Known param reward: [[3.792543649673462, 3.4004008769989014, 3.214235782623291], [3.4004008769989014, 3.792543649673462, 3.046867847442627], [3.758143424987793, 3.5266289710998535, 3.247636318206787]], Known param reward error: [[0.0, 0.10339835448125272, 0.010284567701206924], [0.10339835448125272, 0.0, 0.06181987485440376], [0.00907048879678176, 0.07011512671620897, 0.0]].
