2024-09-17 23:34:39,911 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:198] - INFO: Logging to log_rdpo/2024_09_17_23_29_54/swapped_noise0.6_[0.6,0.6,0.6]_2026
2024-09-17 23:34:39,913 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: (IB) Seed: 2026
2024-09-17 23:34:39,914 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Data: 300
2024-09-17 23:34:40,074 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:296] - INFO: MLE reward loss: 0.4928, l2 distance: 14.5766, acc: 0.73.
2024-09-17 23:34:40,075 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-17 23:34:40,076 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: MLE reward parameter: [7.88910347 4.01302492 7.0306487  3.0852475 ]
2024-09-17 23:34:40,280 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:313] - INFO: Learned oracle reward: 3.5461, 3.8569, 3.1705
2024-09-17 23:34:40,661 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-17 23:34:41,846 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  17.4853, val_loss:  19.3088, grad_norm: 0.1749, live_grad: 0.0000, reward_err: 0.0974, 0.0021, 0.0553, KL_dist: 1.4840, 0.7661, 1.1948, param: [11.43601946  5.03634462  8.84760262  3.34132399], weights: [0.33338402 0.33317585 0.33344013], train_wt_loss:  52.4560, val_wt_loss: 57.9263, train_grp_loss: [21.23873227 11.45743915 19.76943596], val_grp_loss: [22.24315212 14.0739932  21.5407137 ], train_hist_grp_loss: [0.21410998 0.15164963 0.23094158], cur_train_grp_loss: [0.21410998 0.15164963 0.23094158], max_reward_err:  0.0974, max_reward_err_index: 0, max_kl_dist:  1.4840, max_kl_dist_index: 0, max_train_grp_loss:  21.2387, max_train_grp_loss_index: 0, max_val_grp_loss:  22.2432, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2309, max_cur_train_grp_loss_index: 2, 
2024-09-17 23:34:46,140 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  99, train_loss:  17.4884, val_loss:  19.3145, grad_norm: 0.0064,  live_grad: 0.0000, reward_err: 0.0951, 0.0023, 0.0528, KL_dist: 1.4767, 0.7796, 1.1883, param: [11.18796381  5.16606134  9.21566103  3.4652231 ], weights: [0.34200746 0.31338725 0.34460528], train_wt_loss:  52.4652, val_wt_loss: 57.9436, train_grp_loss: [21.19047163 11.65558969 19.62024973], val_grp_loss: [22.175003  14.188237  21.5138368], train_hist_grp_loss: [20.21673656 11.4774466  20.9734468 ], cur_train_grp_loss: [0.2018187  0.11538152 0.20874165], max_reward_err:  0.0951, max_reward_err_index: 0, max_kl_dist:  1.4767, max_kl_dist_index: 0, max_train_grp_loss:  21.1905, max_train_grp_loss_index: 0, max_val_grp_loss:  22.1750, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2087, max_cur_train_grp_loss_index: 2, 
2024-09-17 23:34:46,366 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:386] - INFO: Policy parameter learned solely on the preference data rdpo: [11.18796381  5.16606134  9.21566103  3.4652231 ].
2024-09-17 23:34:46,698 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:397] - INFO: Uniform reward: 3.8324, 3.8324, 3.1905
2024-09-17 23:34:46,698 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Optimal reward: 3.8704, 3.8704, 3.3124
2024-09-17 23:34:46,699 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Policy reward: 3.5024, 3.8616, 3.1375
2024-09-17 23:34:46,699 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Reward Error: 0.0951, 0.0023, 0.0528
2024-09-17 23:34:47,387 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:415] - INFO: Optimal reward: 3.8704, 3.8704, 3.3124
Known param reward: [[3.8704123497009277, 3.479184150695801, 3.2794346809387207], [3.479184150695801, 3.8704123497009277, 3.123277425765991], [3.8274452686309814, 3.5988070964813232, 3.3123531341552734]], Known param reward error: [[0.0, 0.10108178758662696, 0.009938086877608145], [0.10108178758662696, 0.0, 0.057081989972515686], [0.011101422067668428, 0.07017475883172805, 0.0]].
