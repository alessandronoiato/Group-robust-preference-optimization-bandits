2024-09-17 23:34:58,128 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:198] - INFO: Logging to log_rdpo/2024_09_17_23_29_54/swapped_noise0.6_[0.6,0.6,0.6]_2027
2024-09-17 23:34:58,130 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: (IB) Seed: 2027
2024-09-17 23:34:58,130 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Data: 300
2024-09-17 23:34:58,298 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:296] - INFO: MLE reward loss: 0.5312, l2 distance: 12.5910, acc: 0.72.
2024-09-17 23:34:58,299 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-17 23:34:58,300 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: MLE reward parameter: [6.59229492 3.67854836 6.67403947 3.4276155 ]
2024-09-17 23:34:58,515 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:313] - INFO: Learned oracle reward: 3.5080, 3.7471, 3.1184
2024-09-17 23:34:58,748 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-17 23:34:59,932 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  18.5748, val_loss:  18.3160, grad_norm: 0.1682, live_grad: 0.0000, reward_err: 0.0821, 0.0025, 0.0460, KL_dist: 1.5286, 0.8326, 1.2357, param: [10.96586039  4.57906329 10.06354453  4.69797188], weights: [0.33336814 0.3332928  0.33333906], train_wt_loss:  55.7245, val_wt_loss: 54.9480, train_grp_loss: [23.34830814 12.05759529 19.49504783], val_grp_loss: [21.6877099  12.26866047 20.78501293], train_hist_grp_loss: [0.22135624 0.19875288 0.21263271], cur_train_grp_loss: [0.22135624 0.19875288 0.21263271], max_reward_err:  0.0821, max_reward_err_index: 0, max_kl_dist:  1.5286, max_kl_dist_index: 0, max_train_grp_loss:  23.3483, max_train_grp_loss_index: 0, max_val_grp_loss:  21.6877, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2214, max_cur_train_grp_loss_index: 0, 
2024-09-17 23:35:04,345 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  99, train_loss:  18.5769, val_loss:  18.3356, grad_norm: 0.0056,  live_grad: 0.0000, reward_err: 0.0794, 0.0031, 0.0435, KL_dist: 1.5152, 0.8385, 1.2266, param: [10.75218545  4.70806468 10.20527107  4.83000489], weights: [0.34764567 0.31775722 0.33459711], train_wt_loss:  55.7307, val_wt_loss: 55.0067, train_grp_loss: [23.2457372  12.23224859 19.45118169], val_grp_loss: [21.63138759 12.42147497 20.75169247], train_hist_grp_loss: [22.39882702 13.40921144 18.5731659 ], cur_train_grp_loss: [0.22352667 0.13440021 0.18525354], max_reward_err:  0.0794, max_reward_err_index: 0, max_kl_dist:  1.5152, max_kl_dist_index: 0, max_train_grp_loss:  23.2457, max_train_grp_loss_index: 0, max_val_grp_loss:  21.6314, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2235, max_cur_train_grp_loss_index: 0, 
2024-09-17 23:35:04,572 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:386] - INFO: Policy parameter learned solely on the preference data rdpo: [10.75218545  4.70806468 10.20527107  4.83000489].
2024-09-17 23:35:04,901 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:397] - INFO: Uniform reward: 3.7290, 3.7290, 3.0905
2024-09-17 23:35:04,902 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Optimal reward: 3.7694, 3.7694, 3.2324
2024-09-17 23:35:04,902 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Policy reward: 3.4702, 3.7577, 3.0917
2024-09-17 23:35:04,903 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Reward Error: 0.0794, 0.0031, 0.0435
2024-09-17 23:35:05,584 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:415] - INFO: Optimal reward: 3.7694, 3.7694, 3.2324
Known param reward: [[3.769418716430664, 3.4166855812072754, 3.190812110900879], [3.4166855812072754, 3.769418716430664, 3.0528886318206787], [3.7305526733398438, 3.537524461746216, 3.2323977947235107]], Known param reward error: [[0.0, 0.09357759425500983, 0.012865274159794106], [0.09357759425500983, 0.0, 0.055534366220599], [0.010310885050102189, 0.06151989792846188, 0.0]].
