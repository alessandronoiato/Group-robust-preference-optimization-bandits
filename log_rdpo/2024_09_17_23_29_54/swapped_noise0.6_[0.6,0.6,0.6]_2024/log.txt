2024-09-17 23:34:00,866 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:198] - INFO: Logging to log_rdpo/2024_09_17_23_29_54/swapped_noise0.6_[0.6,0.6,0.6]_2024
2024-09-17 23:34:00,868 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: (IB) Seed: 2024
2024-09-17 23:34:00,869 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Data: 300
2024-09-17 23:34:01,034 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:296] - INFO: MLE reward loss: 0.5521, l2 distance: 9.4837, acc: 0.72.
2024-09-17 23:34:01,035 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-17 23:34:01,036 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: MLE reward parameter: [6.06856284 3.25328814 4.61692761 2.64067382]
2024-09-17 23:34:01,241 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:313] - INFO: Learned oracle reward: 3.5115, 3.7700, 3.1062
2024-09-17 23:34:01,491 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-17 23:34:02,696 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  19.2415, val_loss:  18.7907, grad_norm: 0.1563, live_grad: 0.0000, reward_err: 0.0839, 0.0041, 0.0501, KL_dist: 1.2336, 0.6375, 0.9889, param: [10.47713344  4.96464577  7.32988239  3.62300197], weights: [0.33337643 0.33325178 0.33337179], train_wt_loss:  57.7246, val_wt_loss: 56.3721, train_grp_loss: [22.39375998 13.00479626 21.43510276], val_grp_loss: [22.7013747  12.55904029 20.89758654], train_hist_grp_loss: [0.22046912 0.18307033 0.21907764], cur_train_grp_loss: [0.22046912 0.18307033 0.21907764], max_reward_err:  0.0839, max_reward_err_index: 0, max_kl_dist:  1.2336, max_kl_dist_index: 0, max_train_grp_loss:  22.3938, max_train_grp_loss_index: 0, max_val_grp_loss:  22.7014, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2205, max_cur_train_grp_loss_index: 0, 
2024-09-17 23:34:06,995 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  99, train_loss:  19.2428, val_loss:  18.7959, grad_norm: 0.0045,  live_grad: 0.0000, reward_err: 0.0822, 0.0047, 0.0486, KL_dist: 1.2220, 0.6469, 0.9804, param: [10.37696217  5.08707527  7.40589574  3.74593952], weights: [0.34177539 0.31949098 0.33873363], train_wt_loss:  57.7285, val_wt_loss: 56.3876, train_grp_loss: [22.32606952 13.1389395  21.39149178], val_grp_loss: [22.64980897 12.68550393 20.84213671], train_hist_grp_loss: [21.30299459 14.56052219 20.40902219], cur_train_grp_loss: [0.21263574 0.14597264 0.20373272], max_reward_err:  0.0822, max_reward_err_index: 0, max_kl_dist:  1.2220, max_kl_dist_index: 0, max_train_grp_loss:  22.3261, max_train_grp_loss_index: 0, max_val_grp_loss:  22.6498, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2126, max_cur_train_grp_loss_index: 0, 
2024-09-17 23:34:07,220 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:386] - INFO: Policy parameter learned solely on the preference data rdpo: [10.37696217  5.08707527  7.40589574  3.74593952].
2024-09-17 23:34:07,550 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:397] - INFO: Uniform reward: 3.7492, 3.7492, 3.0980
2024-09-17 23:34:07,551 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Optimal reward: 3.7932, 3.7932, 3.2404
2024-09-17 23:34:07,551 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Policy reward: 3.4815, 3.7756, 3.0829
2024-09-17 23:34:07,552 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Reward Error: 0.0822, 0.0047, 0.0486
2024-09-17 23:34:08,219 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:415] - INFO: Optimal reward: 3.7932, 3.7932, 3.2404
Known param reward: [[3.7932193279266357, 3.4367012977600098, 3.2102184295654297], [3.4367012977600098, 3.7932193279266357, 3.057360887527466], [3.7612311840057373, 3.562816858291626, 3.240443229675293]], Known param reward error: [[0.0, 0.0939882456945873, 0.009327366032236257], [0.0939882456945873, 0.0, 0.056499166679174574], [0.008432980314476852, 0.06074061363621364, 0.0]].
