2024-09-17 23:34:20,640 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:198] - INFO: Logging to log_rdpo/2024_09_17_23_29_54/swapped_noise0.6_[0.6,0.6,0.6]_2025
2024-09-17 23:34:20,642 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: (IB) Seed: 2025
2024-09-17 23:34:20,643 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Data: 300
2024-09-17 23:34:20,805 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:296] - INFO: MLE reward loss: 0.5578, l2 distance: 7.9530, acc: 0.71.
2024-09-17 23:34:20,806 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-17 23:34:20,807 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: MLE reward parameter: [5.04168534 2.56659103 4.61195466 2.02486437]
2024-09-17 23:34:21,016 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:313] - INFO: Learned oracle reward: 3.5616, 3.8591, 3.1808
2024-09-17 23:34:21,258 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-17 23:34:22,463 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  19.3412, val_loss:  18.8073, grad_norm: 0.1738, live_grad: 0.0000, reward_err: 0.0889, 0.0011, 0.0501, KL_dist: 1.1318, 0.5001, 0.8768, param: [8.94437309 3.79013014 7.90888992 3.05103728], weights: [0.33344753 0.33317155 0.33338092], train_wt_loss:  58.0235, val_wt_loss: 56.4220, train_grp_loss: [22.8011289  15.47553203 20.48314188], val_grp_loss: [22.51406013 12.14511552 21.82226895], train_hist_grp_loss: [0.25317254 0.17037084 0.23319468], cur_train_grp_loss: [0.25317254 0.17037084 0.23319468], max_reward_err:  0.0889, max_reward_err_index: 0, max_kl_dist:  1.1318, max_kl_dist_index: 0, max_train_grp_loss:  22.8011, max_train_grp_loss_index: 0, max_val_grp_loss:  22.5141, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2532, max_cur_train_grp_loss_index: 0, 
2024-09-17 23:34:26,812 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  99, train_loss:  19.3435, val_loss:  18.8032, grad_norm: 0.0069,  live_grad: 0.0000, reward_err: 0.0877, 0.0016, 0.0491, KL_dist: 1.1266, 0.5111, 0.8751, param: [8.91842948 3.96205223 7.94016587 3.19688115], weights: [0.34932011 0.31384107 0.33683883], train_wt_loss:  58.0305, val_wt_loss: 56.4095, train_grp_loss: [22.71344504 15.6142069  20.41484902], val_grp_loss: [22.43176175 12.26708912 21.76814714], train_hist_grp_loss: [24.74286071 14.03265954 21.10444503], cur_train_grp_loss: [0.24689513 0.14065503 0.21046964], max_reward_err:  0.0877, max_reward_err_index: 0, max_kl_dist:  1.1266, max_kl_dist_index: 0, max_train_grp_loss:  22.7134, max_train_grp_loss_index: 0, max_val_grp_loss:  22.4318, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2469, max_cur_train_grp_loss_index: 0, 
2024-09-17 23:34:27,037 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:386] - INFO: Policy parameter learned solely on the preference data rdpo: [8.91842948 3.96205223 7.94016587 3.19688115].
2024-09-17 23:34:27,372 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:397] - INFO: Uniform reward: 3.8342, 3.8342, 3.1825
2024-09-17 23:34:27,373 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Optimal reward: 3.8751, 3.8751, 3.3250
2024-09-17 23:34:27,373 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Policy reward: 3.5353, 3.8690, 3.1618
2024-09-17 23:34:27,374 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Reward Error: 0.0877, 0.0016, 0.0491
2024-09-17 23:34:28,066 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:415] - INFO: Optimal reward: 3.8751, 3.8751, 3.3250
Known param reward: [[3.8750712871551514, 3.489452362060547, 3.283229351043701], [3.489452362060547, 3.8750712871551514, 3.1289710998535156], [3.836576223373413, 3.6257314682006836, 3.3250086307525635]], Known param reward error: [[0.0, 0.09951273061035817, 0.012565164289334858], [0.09951273061035817, 0.0, 0.05895850287001446], [0.009934027255018341, 0.06434457600327614, 0.0]].
