2024-09-17 23:35:20,837 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:198] - INFO: Logging to log_rdpo/2024_09_17_23_29_54/swapped_noise0.6_[0.6,0.6,0.6]_2028
2024-09-17 23:35:20,839 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: (IB) Seed: 2028
2024-09-17 23:35:20,840 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Data: 300
2024-09-17 23:35:21,008 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:296] - INFO: MLE reward loss: 0.5679, l2 distance: 10.7043, acc: 0.69.
2024-09-17 23:35:21,009 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-17 23:35:21,010 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: MLE reward parameter: [6.99370909 3.70566097 4.07167132 1.02776318]
2024-09-17 23:35:21,223 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:313] - INFO: Learned oracle reward: 3.4824, 3.8302, 3.1395
2024-09-17 23:35:21,461 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-17 23:35:22,655 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  19.7114, val_loss:  19.4294, grad_norm: 0.2189, live_grad: 0.0000, reward_err: 0.1151, 0.0169, 0.0776, KL_dist: 1.6343, 0.7569, 1.3511, param: [13.16514226  6.09356266  6.06258374  1.78488417], weights: [0.33320395 0.33341206 0.33338399], train_wt_loss:  59.1342, val_wt_loss: 58.2883, train_grp_loss: [24.51118329 12.82483619 20.24569506], val_grp_loss: [22.40452197 13.98334723 21.5095195 ], train_hist_grp_loss: [0.20305154 0.26548818 0.2570676 ], cur_train_grp_loss: [0.20305154 0.26548818 0.2570676 ], max_reward_err:  0.1151, max_reward_err_index: 0, max_kl_dist:  1.6343, max_kl_dist_index: 0, max_train_grp_loss:  24.5112, max_train_grp_loss_index: 0, max_val_grp_loss:  22.4045, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2655, max_cur_train_grp_loss_index: 1, 
2024-09-17 23:35:27,109 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  99, train_loss:  19.7127, val_loss:  19.4471, grad_norm: 0.0048,  live_grad: 0.0000, reward_err: 0.1129, 0.0175, 0.0756, KL_dist: 1.6317, 0.7652, 1.3518, param: [13.18987047  6.21994535  6.03334559  1.92175101], weights: [0.33814247 0.31801164 0.34384589], train_wt_loss:  59.1381, val_wt_loss: 58.3413, train_grp_loss: [24.4679698  12.94846944 20.18418213], val_grp_loss: [22.36581952 14.12832363 21.46461416], train_hist_grp_loss: [20.57698741 14.43905316 22.24960987], cur_train_grp_loss: [0.2056169  0.14385736 0.2218111 ], max_reward_err:  0.1129, max_reward_err_index: 0, max_kl_dist:  1.6317, max_kl_dist_index: 0, max_train_grp_loss:  24.4680, max_train_grp_loss_index: 0, max_val_grp_loss:  22.3658, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2218, max_cur_train_grp_loss_index: 2, 
2024-09-17 23:35:27,340 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:386] - INFO: Policy parameter learned solely on the preference data rdpo: [13.18987047  6.21994535  6.03334559  1.92175101].
2024-09-17 23:35:27,673 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:397] - INFO: Uniform reward: 3.8644, 3.8644, 3.2369
2024-09-17 23:35:27,674 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Optimal reward: 3.8990, 3.8990, 3.3708
2024-09-17 23:35:27,674 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Policy reward: 3.4590, 3.8308, 3.1159
2024-09-17 23:35:27,675 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Reward Error: 0.1129, 0.0175, 0.0756
2024-09-17 23:35:28,370 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:415] - INFO: Optimal reward: 3.8990, 3.8990, 3.3708
Known param reward: [[3.8990397453308105, 3.4851560592651367, 3.334066867828369], [3.4851560592651367, 3.8990397453308105, 3.152937412261963], [3.8658859729766846, 3.638388156890869, 3.3707845211029053]], Known param reward error: [[0.0, 0.10615015826943262, 0.010892910254174978], [0.10615015826943262, 0.0, 0.06462801388730235], [0.008503060886678156, 0.06685020042488093, 0.0]].
