2024-09-17 23:35:57,635 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:198] - INFO: Logging to log_rdpo/2024_09_17_23_29_54/swapped_noise0.6_[0.6,0.6,0.6]_2030
2024-09-17 23:35:57,636 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: (IB) Seed: 2030
2024-09-17 23:35:57,637 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Data: 300
2024-09-17 23:35:57,800 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:296] - INFO: MLE reward loss: 0.5425, l2 distance: 11.3341, acc: 0.74.
2024-09-17 23:35:57,801 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-17 23:35:57,802 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: MLE reward parameter: [3.12341811 1.68199744 7.99266711 2.47477641]
2024-09-17 23:35:58,012 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:313] - INFO: Learned oracle reward: 3.4449, 3.9070, 3.1365
2024-09-17 23:35:58,260 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-17 23:35:59,439 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  18.7003, val_loss:  18.5134, grad_norm: 0.1718, live_grad: 0.0000, reward_err: 0.1360, 0.0054, 0.0978, KL_dist: 2.0209, 0.6468, 1.6892, param: [ 4.25997473  2.16436062 14.72271908  3.8982928 ], weights: [0.33346409 0.33321527 0.33332064], train_wt_loss:  56.1009, val_wt_loss: 55.5403, train_grp_loss: [20.9538972  15.9511347  19.56543588], val_grp_loss: [22.3071819  10.86889482 22.21199856], train_hist_grp_loss: [0.25438317 0.1797411  0.21135759], cur_train_grp_loss: [0.25438317 0.1797411  0.21135759], max_reward_err:  0.1360, max_reward_err_index: 0, max_kl_dist:  2.0209, max_kl_dist_index: 0, max_train_grp_loss:  20.9539, max_train_grp_loss_index: 0, max_val_grp_loss:  22.3072, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2544, max_cur_train_grp_loss_index: 0, 
2024-09-17 23:36:03,753 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  99, train_loss:  18.7013, val_loss:  18.5077, grad_norm: 0.0045,  live_grad: 0.0000, reward_err: 0.1357, 0.0055, 0.0976, KL_dist: 2.0393, 0.6543, 1.7088, param: [ 4.17680848  2.24951307 14.84880323  3.99068133], weights: [0.34825393 0.32016767 0.33157839], train_wt_loss:  56.1040, val_wt_loss: 55.5232, train_grp_loss: [20.90465018 16.05895061 19.50131977], val_grp_loss: [22.27109582 10.91436489 22.18700714], train_hist_grp_loss: [23.53558441 15.126877   18.62881995], cur_train_grp_loss: [0.23488933 0.15148898 0.18573301], max_reward_err:  0.1357, max_reward_err_index: 0, max_kl_dist:  2.0393, max_kl_dist_index: 0, max_train_grp_loss:  20.9047, max_train_grp_loss_index: 0, max_val_grp_loss:  22.2711, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2349, max_cur_train_grp_loss_index: 0, 
2024-09-17 23:36:03,973 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:386] - INFO: Policy parameter learned solely on the preference data rdpo: [ 4.17680848  2.24951307 14.84880323  3.99068133].
2024-09-17 23:36:04,298 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:397] - INFO: Uniform reward: 3.8811, 3.8811, 3.2645
2024-09-17 23:36:04,298 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Optimal reward: 3.9244, 3.9244, 3.4203
2024-09-17 23:36:04,299 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Policy reward: 3.3919, 3.9027, 3.0864
2024-09-17 23:36:04,299 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Reward Error: 0.1357, 0.0055, 0.0976
2024-09-17 23:36:04,972 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:415] - INFO: Optimal reward: 3.9244, 3.9244, 3.4203
Known param reward: [[3.9244344234466553, 3.531189441680908, 3.3788671493530273], [3.531189441680908, 3.9244344234466553, 3.2225024700164795], [3.8856606483459473, 3.648857831954956, 3.420322895050049]], Known param reward error: [[0.0, 0.10020424329587284, 0.01212041873503141], [0.10020424329587284, 0.0, 0.05783676895531077], [0.00988009249665452, 0.07022071507814179, 0.0]].
