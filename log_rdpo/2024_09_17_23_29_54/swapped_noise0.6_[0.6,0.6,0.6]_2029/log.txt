2024-09-17 23:35:39,841 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:198] - INFO: Logging to log_rdpo/2024_09_17_23_29_54/swapped_noise0.6_[0.6,0.6,0.6]_2029
2024-09-17 23:35:39,842 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: (IB) Seed: 2029
2024-09-17 23:35:39,843 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Data: 300
2024-09-17 23:35:40,008 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:296] - INFO: MLE reward loss: 0.5368, l2 distance: 9.8838, acc: 0.73.
2024-09-17 23:35:40,008 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-17 23:35:40,009 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: MLE reward parameter: [5.56082395 1.95782607 5.53169184 3.60149173]
2024-09-17 23:35:40,216 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:313] - INFO: Learned oracle reward: 3.5145, 3.7955, 3.1473
2024-09-17 23:35:40,470 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-17 23:35:41,648 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  18.6379, val_loss:  19.6689, grad_norm: 0.2464, live_grad: 0.0000, reward_err: 0.0945, 0.0036, 0.0527, KL_dist: 1.2916, 0.6226, 1.0172, param: [8.80965415 2.41269229 9.62543917 4.9299918 ], weights: [0.3334111  0.33322335 0.33336556], train_wt_loss:  55.9138, val_wt_loss: 59.0067, train_grp_loss: [23.24351102 14.12049522 19.30451875], val_grp_loss: [22.7528439  14.16420646 21.5312109 ], train_hist_grp_loss: [0.24791817 0.19159137 0.23425827], cur_train_grp_loss: [0.24791817 0.19159137 0.23425827], max_reward_err:  0.0945, max_reward_err_index: 0, max_kl_dist:  1.2916, max_kl_dist_index: 0, max_train_grp_loss:  23.2435, max_train_grp_loss_index: 0, max_val_grp_loss:  22.7528, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2479, max_cur_train_grp_loss_index: 0, 
2024-09-17 23:35:46,014 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  99, train_loss:  18.6406, val_loss:  19.6527, grad_norm: 0.0070,  live_grad: 0.0000, reward_err: 0.0924, 0.0040, 0.0510, KL_dist: 1.2878, 0.6344, 1.0174, param: [8.78620326 2.61005247 9.66124639 5.09296111], weights: [0.35151002 0.31266284 0.33582714], train_wt_loss:  55.9219, val_wt_loss: 58.9581, train_grp_loss: [23.14174656 14.26803802 19.24356055], val_grp_loss: [22.67076609 14.27928042 21.46294811], train_hist_grp_loss: [24.67531735 12.96403728 20.11114997], cur_train_grp_loss: [0.24620008 0.12969483 0.2004603 ], max_reward_err:  0.0924, max_reward_err_index: 0, max_kl_dist:  1.2878, max_kl_dist_index: 0, max_train_grp_loss:  23.1417, max_train_grp_loss_index: 0, max_val_grp_loss:  22.6708, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2462, max_cur_train_grp_loss_index: 0, 
2024-09-17 23:35:46,238 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:386] - INFO: Policy parameter learned solely on the preference data rdpo: [8.78620326 2.61005247 9.66124639 5.09296111].
2024-09-17 23:35:46,567 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:397] - INFO: Uniform reward: 3.7890, 3.7890, 3.1516
2024-09-17 23:35:46,568 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Optimal reward: 3.8290, 3.8290, 3.2855
2024-09-17 23:35:46,569 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Policy reward: 3.4752, 3.8137, 3.1180
2024-09-17 23:35:46,569 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Reward Error: 0.0924, 0.0040, 0.0510
2024-09-17 23:35:47,253 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:415] - INFO: Optimal reward: 3.8290, 3.8290, 3.2855
Known param reward: [[3.8290088176727295, 3.4431886672973633, 3.2572572231292725], [3.4431886672973633, 3.8290088176727295, 3.095651149749756], [3.7922840118408203, 3.5524039268493652, 3.285464286804199]], Known param reward error: [[0.0, 0.10076240843181646, 0.008585411744762572], [0.10076240843181646, 0.0, 0.05777361142436167], [0.009591204298722537, 0.0722392932465182, 0.0]].
