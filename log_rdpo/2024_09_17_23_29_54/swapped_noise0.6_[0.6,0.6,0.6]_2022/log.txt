2024-09-17 23:33:23,218 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:198] - INFO: Logging to log_rdpo/2024_09_17_23_29_54/swapped_noise0.6_[0.6,0.6,0.6]_2022
2024-09-17 23:33:23,220 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: (IB) Seed: 2022
2024-09-17 23:33:23,220 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Data: 300
2024-09-17 23:33:23,387 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:296] - INFO: MLE reward loss: 0.4972, l2 distance: 15.7924, acc: 0.74.
2024-09-17 23:33:23,388 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-17 23:33:23,389 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: MLE reward parameter: [9.34426871 2.83966746 6.08749348 4.46436597]
2024-09-17 23:33:23,603 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:313] - INFO: Learned oracle reward: 3.5016, 3.8536, 3.1454
2024-09-17 23:33:23,853 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-17 23:33:25,062 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  17.3956, val_loss:  18.8556, grad_norm: 0.2657, live_grad: 0.0000, reward_err: 0.1047, 0.0007, 0.0649, KL_dist: 1.9606, 0.9639, 1.6135, param: [14.13238047  3.40445445  9.0786231   5.21560573], weights: [0.33334833 0.3333505  0.33330117], train_wt_loss:  52.1867, val_wt_loss: 56.5668, train_grp_loss: [22.56652911 10.82702619 18.98221879], val_grp_loss: [21.78817414 14.4738787  20.28365791], train_hist_grp_loss: [0.24314146 0.2437931  0.22899169], cur_train_grp_loss: [0.24314146 0.2437931  0.22899169], max_reward_err:  0.1047, max_reward_err_index: 0, max_kl_dist:  1.9606, max_kl_dist_index: 0, max_train_grp_loss:  22.5665, max_train_grp_loss_index: 0, max_val_grp_loss:  21.7882, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2438, max_cur_train_grp_loss_index: 1, 
2024-09-17 23:33:29,403 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  99, train_loss:  17.3975, val_loss:  18.8594, grad_norm: 0.0063,  live_grad: 0.0000, reward_err: 0.1042, 0.0009, 0.0646, KL_dist: 1.9587, 0.9690, 1.6154, param: [14.17192815  3.55035044  9.01296674  5.35355524], weights: [0.35227667 0.3113879  0.33633543], train_wt_loss:  52.1925, val_wt_loss: 56.5783, train_grp_loss: [22.51855146 10.94731393 18.91441686], val_grp_loss: [21.72883737 14.60291103 20.226741  ], train_hist_grp_loss: [23.25114653 10.91340174 18.62035729], cur_train_grp_loss: [0.23215527 0.10837636 0.18544219], max_reward_err:  0.1042, max_reward_err_index: 0, max_kl_dist:  1.9587, max_kl_dist_index: 0, max_train_grp_loss:  22.5186, max_train_grp_loss_index: 0, max_val_grp_loss:  21.7288, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2322, max_cur_train_grp_loss_index: 0, 
2024-09-17 23:33:29,633 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:386] - INFO: Policy parameter learned solely on the preference data rdpo: [14.17192815  3.55035044  9.01296674  5.35355524].
2024-09-17 23:33:29,968 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:397] - INFO: Uniform reward: 3.8304, 3.8304, 3.1988
2024-09-17 23:33:29,969 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Optimal reward: 3.8653, 3.8653, 3.3311
2024-09-17 23:33:29,969 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Policy reward: 3.4627, 3.8617, 3.1160
2024-09-17 23:33:29,970 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Reward Error: 0.1042, 0.0009, 0.0646
2024-09-17 23:33:30,657 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:415] - INFO: Optimal reward: 3.8653, 3.8653, 3.3311
Known param reward: [[3.8653156757354736, 3.477531671524048, 3.30049467086792], [3.477531671524048, 3.8653156757354736, 3.137904405593872], [3.8325858116149902, 3.5891125202178955, 3.331118106842041]], Known param reward error: [[0.0, 0.10032401923748184, 0.009193140258588025], [0.10032401923748184, 0.0, 0.05800265708121018], [0.008467578554048038, 0.0714568171628113, 0.0]].
