2024-09-17 23:33:40,972 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:198] - INFO: Logging to log_rdpo/2024_09_17_23_29_54/swapped_noise0.6_[0.6,0.6,0.6]_2023
2024-09-17 23:33:40,974 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: (IB) Seed: 2023
2024-09-17 23:33:40,975 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Data: 300
2024-09-17 23:33:41,135 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:296] - INFO: MLE reward loss: 0.5541, l2 distance: 9.0828, acc: 0.72.
2024-09-17 23:33:41,135 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-17 23:33:41,136 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: MLE reward parameter: [5.45722274 2.96957708 5.11155783 1.87329973]
2024-09-17 23:33:41,343 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:313] - INFO: Learned oracle reward: 3.4911, 3.8151, 3.1132
2024-09-17 23:33:41,605 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-17 23:33:42,813 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  19.2464, val_loss:  18.9129, grad_norm: 0.1478, live_grad: 0.0000, reward_err: 0.1011, 0.0012, 0.0592, KL_dist: 1.2604, 0.5857, 0.9897, param: [9.75366585 4.29184964 8.39874988 2.44796037], weights: [0.33337896 0.33318986 0.33343118], train_wt_loss:  57.7391, val_wt_loss: 56.7386, train_grp_loss: [23.12561429 12.41617944 22.82166398], val_grp_loss: [21.42932049 13.62213284 21.62965623], train_hist_grp_loss: [0.22649273 0.16975534 0.24215386], cur_train_grp_loss: [0.22649273 0.16975534 0.24215386], max_reward_err:  0.1011, max_reward_err_index: 0, max_kl_dist:  1.2604, max_kl_dist_index: 0, max_train_grp_loss:  23.1256, max_train_grp_loss_index: 0, max_val_grp_loss:  21.6297, max_val_grp_loss_index: 2, max_cur_train_grp_loss:  0.2422, max_cur_train_grp_loss_index: 2, 
2024-09-17 23:33:47,194 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  99, train_loss:  19.2502, val_loss:  18.8986, grad_norm: 0.0085,  live_grad: 0.0000, reward_err: 0.0969, 0.0019, 0.0556, KL_dist: 1.2379, 0.5870, 0.9747, param: [9.73515653 4.48839881 8.26658121 2.65972858], weights: [0.3441711  0.30763648 0.34819243], train_wt_loss:  57.7506, val_wt_loss: 56.6957, train_grp_loss: [23.02293423 12.60127098 22.73440632], val_grp_loss: [21.33413947 13.7436595  21.56160925], train_hist_grp_loss: [23.07104694 11.84903703 24.23268313], cur_train_grp_loss: [0.23024002 0.11886072 0.24186502], max_reward_err:  0.0969, max_reward_err_index: 0, max_kl_dist:  1.2379, max_kl_dist_index: 0, max_train_grp_loss:  23.0229, max_train_grp_loss_index: 0, max_val_grp_loss:  21.5616, max_val_grp_loss_index: 2, max_cur_train_grp_loss:  0.2419, max_cur_train_grp_loss_index: 2, 
2024-09-17 23:33:47,419 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:386] - INFO: Policy parameter learned solely on the preference data rdpo: [9.73515653 4.48839881 8.26658121 2.65972858].
2024-09-17 23:33:47,747 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:397] - INFO: Uniform reward: 3.7949, 3.7949, 3.1453
2024-09-17 23:33:47,748 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Optimal reward: 3.8294, 3.8294, 3.2691
2024-09-17 23:33:47,748 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Policy reward: 3.4585, 3.8221, 3.0873
2024-09-17 23:33:47,749 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Reward Error: 0.0969, 0.0019, 0.0556
2024-09-17 23:33:48,423 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:415] - INFO: Optimal reward: 3.8294, 3.8294, 3.2691
Known param reward: [[3.8294012546539307, 3.4349207878112793, 3.23325252532959], [3.4349207878112793, 3.8294012546539307, 3.072456121444702], [3.788132905960083, 3.56136417388916, 3.26906156539917]], Known param reward error: [[0.0, 0.10301361508231428, 0.010953920369256675], [0.10301361508231428, 0.0, 0.060141248496328396], [0.010776710495849343, 0.0699945142700888, 0.0]].
