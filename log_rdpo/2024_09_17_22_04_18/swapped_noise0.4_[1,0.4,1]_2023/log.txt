2024-09-17 22:08:13,011 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:198] - INFO: Logging to log_rdpo/2024_09_17_22_04_18/swapped_noise0.4_[1,0.4,1]_2023
2024-09-17 22:08:13,012 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: (IB) Seed: 2023
2024-09-17 22:08:13,013 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Data: 300
2024-09-17 22:08:13,174 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:296] - INFO: MLE reward loss: 0.4525, l2 distance: 18.1721, acc: 0.80.
2024-09-17 22:08:13,175 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-17 22:08:13,175 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: MLE reward parameter: [9.90653594 4.24486875 6.64039083 5.98534533]
2024-09-17 22:08:13,378 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:313] - INFO: Learned oracle reward: 3.5613, 3.8249, 3.1624
2024-09-17 22:08:13,625 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-17 22:08:14,822 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  16.3889, val_loss:  18.3448, grad_norm: 0.2902, live_grad: 0.0000, reward_err: 0.0983, 0.0040, 0.0626, KL_dist: 1.6756, 0.8321, 1.4109, param: [13.56056762  4.2046476   6.87544779  5.5731141 ], weights: [0.33339282 0.33320269 0.33340449], train_wt_loss:  49.1668, val_wt_loss: 55.0344, train_grp_loss: [19.6181425  13.46440758 16.2514473 ], val_grp_loss: [20.49478099 16.21593127 18.39901221], train_hist_grp_loss: [0.24026358 0.18321692 0.24376492], cur_train_grp_loss: [0.24026358 0.18321692 0.24376492], max_reward_err:  0.0983, max_reward_err_index: 0, max_kl_dist:  1.6756, max_kl_dist_index: 0, max_train_grp_loss:  19.6181, max_train_grp_loss_index: 0, max_val_grp_loss:  20.4948, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2438, max_cur_train_grp_loss_index: 2, 
2024-09-17 22:08:19,139 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  99, train_loss:  16.3907, val_loss:  18.3627, grad_norm: 0.0062,  live_grad: 0.0000, reward_err: 0.0978, 0.0042, 0.0623, KL_dist: 1.6896, 0.8464, 1.4269, param: [13.66136439  4.32946597  6.82769683  5.70320148], weights: [0.34342284 0.32093825 0.33563891], train_wt_loss:  49.1722, val_wt_loss: 55.0881, train_grp_loss: [19.51252151 13.64035706 16.1712111 ], val_grp_loss: [20.41755346 16.41611485 18.32979119], train_hist_grp_loss: [19.61044017 12.83906961 17.31778814], cur_train_grp_loss: [0.19513586 0.12866541 0.17204276], max_reward_err:  0.0978, max_reward_err_index: 0, max_kl_dist:  1.6896, max_kl_dist_index: 0, max_train_grp_loss:  19.5125, max_train_grp_loss_index: 0, max_val_grp_loss:  20.4176, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.1951, max_cur_train_grp_loss_index: 0, 
2024-09-17 22:08:19,377 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:386] - INFO: Policy parameter learned solely on the preference data rdpo: [13.66136439  4.32946597  6.82769683  5.70320148].
2024-09-17 22:08:19,702 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:397] - INFO: Uniform reward: 3.8265, 3.8265, 3.1778
2024-09-17 22:08:19,703 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Optimal reward: 3.8671, 3.8671, 3.3081
2024-09-17 22:08:19,703 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Policy reward: 3.4888, 3.8508, 3.1020
2024-09-17 22:08:19,704 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Reward Error: 0.0978, 0.0042, 0.0623
2024-09-17 22:08:20,380 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:415] - INFO: Optimal reward: 3.8671, 3.8671, 3.3081
Known param reward: [[3.867140769958496, 3.49029541015625, 3.2803642749786377], [3.49029541015625, 3.867140769958496, 3.118959903717041], [3.833752155303955, 3.6075756549835205, 3.3081343173980713]], Known param reward error: [[0.0, 0.09744805845438374, 0.00839447245941193], [0.09744805845438374, 0.0, 0.05718462297196584], [0.008633927917472566, 0.06712067918276514, 0.0]].
