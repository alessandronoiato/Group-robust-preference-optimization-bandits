2024-09-17 22:10:28,203 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:198] - INFO: Logging to log_rdpo/2024_09_17_22_04_18/swapped_noise0.4_[1,0.4,1]_2030
2024-09-17 22:10:28,205 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: (IB) Seed: 2030
2024-09-17 22:10:28,206 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Data: 300
2024-09-17 22:10:28,365 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:296] - INFO: MLE reward loss: 0.4881, l2 distance: 13.8543, acc: 0.79.
2024-09-17 22:10:28,366 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-17 22:10:28,366 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: MLE reward parameter: [6.31481093 3.67149309 7.88828903 3.60917669]
2024-09-17 22:10:28,571 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:313] - INFO: Learned oracle reward: 3.4730, 3.7755, 3.1340
2024-09-17 22:10:28,822 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-17 22:10:30,027 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  17.1225, val_loss:  17.4641, grad_norm: 0.2288, live_grad: 0.0000, reward_err: 0.1081, 0.0007, 0.0676, KL_dist: 1.6109, 0.7454, 1.2948, param: [ 8.77202489  4.02219967 12.06749332  3.93635174], weights: [0.33346266 0.33322985 0.33330749], train_wt_loss:  51.3674, val_wt_loss: 52.3923, train_grp_loss: [20.02150251 14.66572368 17.145354  ], val_grp_loss: [19.82853778 14.01534868 18.1596513 ], train_hist_grp_loss: [0.25210593 0.18226648 0.20556351], cur_train_grp_loss: [0.25210593 0.18226648 0.20556351], max_reward_err:  0.1081, max_reward_err_index: 0, max_kl_dist:  1.6109, max_kl_dist_index: 0, max_train_grp_loss:  20.0215, max_train_grp_loss_index: 0, max_val_grp_loss:  19.8285, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2521, max_cur_train_grp_loss_index: 0, 
2024-09-17 22:10:34,409 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  99, train_loss:  17.1241, val_loss:  17.4350, grad_norm: 0.0056,  live_grad: 0.0000, reward_err: 0.1055, 0.0009, 0.0656, KL_dist: 1.6094, 0.7537, 1.2960, param: [ 8.76573526  4.13662239 12.0931299   4.08379008], weights: [0.34979552 0.3212443  0.32896018], train_wt_loss:  51.3723, val_wt_loss: 52.3049, train_grp_loss: [19.92778338 14.83525224 17.05825452], val_grp_loss: [19.7353387  14.1117651  18.08136036], train_hist_grp_loss: [22.47174886 13.95706173 16.33054434], cur_train_grp_loss: [0.22391839 0.13993857 0.16246795], max_reward_err:  0.1055, max_reward_err_index: 0, max_kl_dist:  1.6094, max_kl_dist_index: 0, max_train_grp_loss:  19.9278, max_train_grp_loss_index: 0, max_val_grp_loss:  19.7353, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2239, max_cur_train_grp_loss_index: 0, 
2024-09-17 22:10:34,630 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:386] - INFO: Policy parameter learned solely on the preference data rdpo: [ 8.76573526  4.13662239 12.0931299   4.08379008].
2024-09-17 22:10:34,954 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:397] - INFO: Uniform reward: 3.7556, 3.7556, 3.1458
2024-09-17 22:10:34,954 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Optimal reward: 3.7933, 3.7933, 3.2870
2024-09-17 22:10:34,955 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Policy reward: 3.3930, 3.7898, 3.0713
2024-09-17 22:10:34,955 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Reward Error: 0.1055, 0.0009, 0.0656
2024-09-17 22:10:35,638 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:415] - INFO: Optimal reward: 3.7933, 3.7933, 3.2870
Known param reward: [[3.793292999267578, 3.4222915172576904, 3.2522172927856445], [3.4222915172576904, 3.793292999267578, 3.1010961532592773], [3.759493589401245, 3.5484824180603027, 3.287027359008789]], Known param reward error: [[0.0, 0.0978045940773681, 0.010590135834355084], [0.0978045940773681, 0.0, 0.0565651530827476], [0.008910308239532014, 0.0645377462944582, 0.0]].
