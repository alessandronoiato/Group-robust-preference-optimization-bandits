2024-09-17 22:10:09,115 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:198] - INFO: Logging to log_rdpo/2024_09_17_22_04_18/swapped_noise0.4_[1,0.4,1]_2029
2024-09-17 22:10:09,117 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: (IB) Seed: 2029
2024-09-17 22:10:09,118 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Data: 300
2024-09-17 22:10:09,275 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:296] - INFO: MLE reward loss: 0.5062, l2 distance: 12.7703, acc: 0.77.
2024-09-17 22:10:09,275 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-17 22:10:09,276 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: MLE reward parameter: [5.6354843  3.81766735 7.64960934 2.84511118]
2024-09-17 22:10:09,476 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:313] - INFO: Learned oracle reward: 3.5316, 3.8517, 3.2027
2024-09-17 22:10:09,727 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-17 22:10:10,902 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  17.6190, val_loss:  18.5436, grad_norm: 0.2290, live_grad: 0.0000, reward_err: 0.0948, 0.0021, 0.0549, KL_dist: 1.5638, 0.7476, 1.2718, param: [ 8.09158653  5.03779632 12.19076076  3.8700072 ], weights: [0.33339594 0.33324727 0.33335679], train_wt_loss:  52.8571, val_wt_loss: 55.6308, train_grp_loss: [21.08218679 16.32045973 15.71601199], val_grp_loss: [20.49334176 17.3181817  17.71102148], train_hist_grp_loss: [0.23820677 0.19360574 0.22646195], cur_train_grp_loss: [0.23820677 0.19360574 0.22646195], max_reward_err:  0.0948, max_reward_err_index: 0, max_kl_dist:  1.5638, max_kl_dist_index: 0, max_train_grp_loss:  21.0822, max_train_grp_loss_index: 0, max_val_grp_loss:  20.4933, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2382, max_cur_train_grp_loss_index: 0, 
2024-09-17 22:10:15,136 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  99, train_loss:  17.6202, val_loss:  18.5471, grad_norm: 0.0048,  live_grad: 0.0000, reward_err: 0.0932, 0.0026, 0.0535, KL_dist: 1.5652, 0.7557, 1.2757, param: [ 8.05494977  5.15377207 12.23474928  3.9778951 ], weights: [0.34844007 0.32339627 0.32816366], train_wt_loss:  52.8607, val_wt_loss: 55.6414, train_grp_loss: [20.99737928 16.44948988 15.65489347], val_grp_loss: [20.42180965 17.47329161 17.64891831], train_hist_grp_loss: [22.3977289  14.93894675 16.40235064], cur_train_grp_loss: [0.22338558 0.14952864 0.1630782 ], max_reward_err:  0.0932, max_reward_err_index: 0, max_kl_dist:  1.5652, max_kl_dist_index: 0, max_train_grp_loss:  20.9974, max_train_grp_loss_index: 0, max_val_grp_loss:  20.4218, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2234, max_cur_train_grp_loss_index: 0, 
2024-09-17 22:10:15,364 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:386] - INFO: Policy parameter learned solely on the preference data rdpo: [ 8.05494977  5.15377207 12.23474928  3.9778951 ].
2024-09-17 22:10:15,685 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:397] - INFO: Uniform reward: 3.8205, 3.8205, 3.2146
2024-09-17 22:10:15,685 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Optimal reward: 3.8668, 3.8668, 3.3614
2024-09-17 22:10:15,686 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Policy reward: 3.5065, 3.8566, 3.1815
2024-09-17 22:10:15,686 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Reward Error: 0.0932, 0.0026, 0.0535
2024-09-17 22:10:16,360 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:415] - INFO: Optimal reward: 3.8668, 3.8668, 3.3614
Known param reward: [[3.8667526245117188, 3.4561731815338135, 3.324531078338623], [3.4561731815338135, 3.8667526245117188, 3.1526591777801514], [3.8306260108947754, 3.5890326499938965, 3.3613686561584473]], Known param reward error: [[0.0, 0.10618197822513974, 0.01095910076757965], [0.10618197822513974, 0.0, 0.062090624304452315], [0.009342882031794137, 0.07182253469159845, 0.0]].
