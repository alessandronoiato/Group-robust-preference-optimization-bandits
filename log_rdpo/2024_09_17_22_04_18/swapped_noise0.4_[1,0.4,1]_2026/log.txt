2024-09-17 22:09:12,820 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:198] - INFO: Logging to log_rdpo/2024_09_17_22_04_18/swapped_noise0.4_[1,0.4,1]_2026
2024-09-17 22:09:12,822 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: (IB) Seed: 2026
2024-09-17 22:09:12,823 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Data: 300
2024-09-17 22:09:12,991 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:296] - INFO: MLE reward loss: 0.3869, l2 distance: 25.0176, acc: 0.85.
2024-09-17 22:09:12,992 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-17 22:09:12,993 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: MLE reward parameter: [11.7719549   7.51698126  7.29275761  9.13307926]
2024-09-17 22:09:13,203 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:313] - INFO: Learned oracle reward: 3.6344, 3.7376, 3.2152
2024-09-17 22:09:13,453 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-17 22:09:14,637 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  15.1273, val_loss:  18.0452, grad_norm: 0.2285, live_grad: 0.0000, reward_err: 0.0861, 0.0172, 0.0512, KL_dist: 1.5894, 0.9372, 1.3758, param: [13.32040614  6.0365093   6.01675539  7.09263792], weights: [0.33336909 0.33320004 0.33343088], train_wt_loss:  45.3819, val_wt_loss: 54.1355, train_grp_loss: [17.43482723 12.38874222 15.49227805], val_grp_loss: [18.64375333 19.11569935 16.37511707], train_hist_grp_loss: [0.20047093 0.14974989 0.2190042 ], cur_train_grp_loss: [0.20047093 0.14974989 0.2190042 ], max_reward_err:  0.0861, max_reward_err_index: 0, max_kl_dist:  1.5894, max_kl_dist_index: 0, max_train_grp_loss:  17.4348, max_train_grp_loss_index: 0, max_val_grp_loss:  19.1157, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2190, max_cur_train_grp_loss_index: 2, 
2024-09-17 22:09:18,955 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  99, train_loss:  15.1282, val_loss:  18.0705, grad_norm: 0.0042,  live_grad: 0.0000, reward_err: 0.0861, 0.0177, 0.0512, KL_dist: 1.6031, 0.9537, 1.3894, param: [13.38881543  6.12650355  6.06404827  7.16809666], weights: [0.33815722 0.32405914 0.33778364], train_wt_loss:  45.3846, val_wt_loss: 54.2116, train_grp_loss: [17.37639251 12.51300082 15.42687704], val_grp_loss: [18.58726475 19.32407013 16.31142613], train_hist_grp_loss: [16.61168626 12.35319426 16.50114943], cur_train_grp_loss: [0.16549503 0.12387852 0.16412268], max_reward_err:  0.0861, max_reward_err_index: 0, max_kl_dist:  1.6031, max_kl_dist_index: 0, max_train_grp_loss:  17.3764, max_train_grp_loss_index: 0, max_val_grp_loss:  19.3241, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.1655, max_cur_train_grp_loss_index: 0, 
2024-09-17 22:09:19,175 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:386] - INFO: Policy parameter learned solely on the preference data rdpo: [13.38881543  6.12650355  6.06404827  7.16809666].
2024-09-17 22:09:19,503 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:397] - INFO: Uniform reward: 3.8267, 3.8267, 3.1836
2024-09-17 22:09:19,504 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Optimal reward: 3.8639, 3.8639, 3.3051
2024-09-17 22:09:19,504 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Policy reward: 3.5312, 3.7956, 3.1359
2024-09-17 22:09:19,505 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Reward Error: 0.0861, 0.0177, 0.0512
2024-09-17 22:09:20,216 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:415] - INFO: Optimal reward: 3.8639, 3.8639, 3.3051
Known param reward: [[3.8638525009155273, 3.4816598892211914, 3.271707057952881], [3.4816598892211914, 3.8638525009155273, 3.120657444000244], [3.8214311599731445, 3.5967774391174316, 3.3051488399505615]], Known param reward error: [[0.0, 0.09891490723410809, 0.010118086542263219], [0.09891490723410809, 0.0, 0.055819391163357414], [0.010979027002798687, 0.0691214433612083, 0.0]].
