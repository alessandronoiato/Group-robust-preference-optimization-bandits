2024-09-17 23:51:43,511 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:198] - INFO: Logging to log_rdpo/2024_09_17_23_47_28/swapped_noise0.5_[0.5,0.5,0.5]_2024
2024-09-17 23:51:43,513 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: (IB) Seed: 2024
2024-09-17 23:51:43,513 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Data: 300
2024-09-17 23:51:43,671 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:296] - INFO: MLE reward loss: 0.5864, l2 distance: 8.9433, acc: 0.66.
2024-09-17 23:51:43,671 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-17 23:51:43,672 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: MLE reward parameter: [6.11091272 1.50367009 4.07696737 2.14104551]
2024-09-17 23:51:43,876 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:313] - INFO: Learned oracle reward: 3.4783, 3.9140, 3.1612
2024-09-17 23:51:44,133 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-17 23:51:45,290 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  20.4374, val_loss:  20.0731, grad_norm: 0.1487, live_grad: 0.0000, reward_err: 0.1188, 0.0003, 0.0757, KL_dist: 1.4532, 0.5694, 1.1499, param: [11.33275098  2.34539789  7.33052367  2.96852765], weights: [0.33332398 0.33332226 0.33335377], train_wt_loss:  61.3121, val_wt_loss: 60.2192, train_grp_loss: [22.79561504 14.14237979 23.47485902], val_grp_loss: [23.29348301 14.60097569 22.12232042], train_hist_grp_loss: [0.22128807 0.22077208 0.23022429], cur_train_grp_loss: [0.22128807 0.22077208 0.23022429], max_reward_err:  0.1188, max_reward_err_index: 0, max_kl_dist:  1.4532, max_kl_dist_index: 0, max_train_grp_loss:  23.4749, max_train_grp_loss_index: 2, max_val_grp_loss:  23.2935, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2302, max_cur_train_grp_loss_index: 2, 
2024-09-17 23:51:49,627 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  99, train_loss:  20.4379, val_loss:  20.0639, grad_norm: 0.0027,  live_grad: 0.0000, reward_err: 0.1171, 0.0003, 0.0743, KL_dist: 1.4416, 0.5684, 1.1409, param: [11.28970159  2.42615054  7.34596801  3.05073727], weights: [0.33906429 0.31964918 0.34128653], train_wt_loss:  61.3136, val_wt_loss: 60.1918, train_grp_loss: [22.76952162 14.19504051 23.45720105], val_grp_loss: [23.25055482 14.64905692 22.09190716], train_hist_grp_loss: [21.70218965 15.80562263 22.35545278], cur_train_grp_loss: [0.21685514 0.15771649 0.22340363], max_reward_err:  0.1171, max_reward_err_index: 0, max_kl_dist:  1.4416, max_kl_dist_index: 0, max_train_grp_loss:  23.4572, max_train_grp_loss_index: 2, max_val_grp_loss:  23.2506, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2234, max_cur_train_grp_loss_index: 2, 
2024-09-17 23:51:49,845 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:386] - INFO: Policy parameter learned solely on the preference data rdpo: [11.28970159  2.42615054  7.34596801  3.05073727].
2024-09-17 23:51:50,165 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:397] - INFO: Uniform reward: 3.8766, 3.8766, 3.2606
2024-09-17 23:51:50,166 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Optimal reward: 3.9158, 3.9158, 3.3965
2024-09-17 23:51:50,167 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Policy reward: 3.4572, 3.9145, 3.1443
2024-09-17 23:51:50,167 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Reward Error: 0.1171, 0.0003, 0.0743
2024-09-17 23:51:50,832 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:415] - INFO: Optimal reward: 3.9158, 3.9158, 3.3965
Known param reward: [[3.9157958030700684, 3.5013632774353027, 3.3614559173583984], [3.5013632774353027, 3.9157958030700684, 3.188211441040039], [3.87447190284729, 3.635368585586548, 3.396507501602173]], Known param reward error: [[0.0, 0.1058360921960848, 0.01031989013044728], [0.1058360921960848, 0.0, 0.06132654218013005], [0.010553129504449515, 0.07161436182746289, 0.0]].
