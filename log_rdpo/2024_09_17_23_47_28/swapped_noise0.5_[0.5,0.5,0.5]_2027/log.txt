2024-09-17 23:52:42,173 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:198] - INFO: Logging to log_rdpo/2024_09_17_23_47_28/swapped_noise0.5_[0.5,0.5,0.5]_2027
2024-09-17 23:52:42,175 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: (IB) Seed: 2027
2024-09-17 23:52:42,175 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Data: 300
2024-09-17 23:52:42,332 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:296] - INFO: MLE reward loss: 0.5420, l2 distance: 12.5755, acc: 0.71.
2024-09-17 23:52:42,333 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-17 23:52:42,334 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: MLE reward parameter: [7.79120092 0.77394543 5.17419383 3.27492704]
2024-09-17 23:52:42,537 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:313] - INFO: Learned oracle reward: 3.3567, 3.7492, 2.9984
2024-09-17 23:52:42,791 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-17 23:52:43,922 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  18.7736, val_loss:  18.7625, grad_norm: 0.2281, live_grad: 0.0000, reward_err: 0.1150, 0.0036, 0.0778, KL_dist: 1.8225, 0.8424, 1.4800, param: [13.54280402  1.26385086  8.18606999  4.45140206], weights: [0.33330067 0.33344166 0.33325767], train_wt_loss:  56.3209, val_wt_loss: 56.2874, train_grp_loss: [23.76738491 11.42653387 20.19490057], val_grp_loss: [22.94126823 11.46684517 22.02810555], train_hist_grp_loss: [0.22481107 0.26710292 0.21190757], cur_train_grp_loss: [0.22481107 0.26710292 0.21190757], max_reward_err:  0.1150, max_reward_err_index: 0, max_kl_dist:  1.8225, max_kl_dist_index: 0, max_train_grp_loss:  23.7674, max_train_grp_loss_index: 0, max_val_grp_loss:  22.9413, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2671, max_cur_train_grp_loss_index: 1, 
2024-09-17 23:52:48,205 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  99, train_loss:  18.7749, val_loss:  18.7487, grad_norm: 0.0050,  live_grad: 0.0000, reward_err: 0.1128, 0.0034, 0.0755, KL_dist: 1.8059, 0.8431, 1.4664, param: [13.46190173  1.3741859   8.24861497  4.57373076], weights: [0.34858459 0.31517    0.33624541], train_wt_loss:  56.3247, val_wt_loss: 56.2460, train_grp_loss: [23.73013739 11.53464823 20.14178708], val_grp_loss: [22.89641217 11.51857213 21.97841824], train_hist_grp_loss: [22.83211648 12.75524133 19.22815396], cur_train_grp_loss: [0.2281781  0.12674167 0.19183173], max_reward_err:  0.1128, max_reward_err_index: 0, max_kl_dist:  1.8059, max_kl_dist_index: 0, max_train_grp_loss:  23.7301, max_train_grp_loss_index: 0, max_val_grp_loss:  22.8964, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2282, max_cur_train_grp_loss_index: 0, 
2024-09-17 23:52:48,421 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:386] - INFO: Policy parameter learned solely on the preference data rdpo: [13.46190173  1.3741859   8.24861497  4.57373076].
2024-09-17 23:52:48,743 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:397] - INFO: Uniform reward: 3.7279, 3.7279, 3.0898
2024-09-17 23:52:48,744 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Optimal reward: 3.7684, 3.7684, 3.2302
2024-09-17 23:52:48,744 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Policy reward: 3.3434, 3.7555, 2.9861
2024-09-17 23:52:48,745 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Reward Error: 0.1128, 0.0034, 0.0755
2024-09-17 23:52:49,404 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:415] - INFO: Optimal reward: 3.7684, 3.7684, 3.2302
Known param reward: [[3.7684130668640137, 3.418842077255249, 3.1900854110717773], [3.418842077255249, 3.7684130668640137, 3.053025007247925], [3.7308881282806396, 3.5340662002563477, 3.2301623821258545]], Known param reward error: [[0.0, 0.092763448010138, 0.012407107232702476], [0.092763448010138, 0.0, 0.05483853562846303], [0.00995775620070265, 0.06218714945776474, 0.0]].
