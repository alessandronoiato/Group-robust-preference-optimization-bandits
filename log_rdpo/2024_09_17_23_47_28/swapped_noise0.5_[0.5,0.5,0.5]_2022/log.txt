2024-09-17 23:51:04,670 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:198] - INFO: Logging to log_rdpo/2024_09_17_23_47_28/swapped_noise0.5_[0.5,0.5,0.5]_2022
2024-09-17 23:51:04,672 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: (IB) Seed: 2022
2024-09-17 23:51:04,673 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Data: 300
2024-09-17 23:51:04,836 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:296] - INFO: MLE reward loss: 0.5329, l2 distance: 11.7939, acc: 0.72.
2024-09-17 23:51:04,836 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-17 23:51:04,837 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: MLE reward parameter: [7.30172036 2.2104413  5.10021521 3.8691943 ]
2024-09-17 23:51:05,045 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:313] - INFO: Learned oracle reward: 3.5631, 3.8721, 3.1752
2024-09-17 23:51:05,287 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-17 23:51:06,475 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  18.5817, val_loss:  19.8458, grad_norm: 0.2212, live_grad: 0.0000, reward_err: 0.0955, 0.0018, 0.0603, KL_dist: 1.4408, 0.7409, 1.1732, param: [11.82593522  2.6318344   7.98006055  5.36677347], weights: [0.33340191 0.33324524 0.33335285], train_wt_loss:  55.7451, val_wt_loss: 59.5373, train_grp_loss: [23.61235133 10.79049893 21.51245299], val_grp_loss: [22.68779367 13.82634331 22.82191819], train_hist_grp_loss: [0.24794815 0.20094528 0.2332329 ], cur_train_grp_loss: [0.24794815 0.20094528 0.2332329 ], max_reward_err:  0.0955, max_reward_err_index: 0, max_kl_dist:  1.4408, max_kl_dist_index: 0, max_train_grp_loss:  23.6124, max_train_grp_loss_index: 0, max_val_grp_loss:  22.8219, max_val_grp_loss_index: 2, max_cur_train_grp_loss:  0.2479, max_cur_train_grp_loss_index: 0, 
2024-09-17 23:51:10,730 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  99, train_loss:  18.5844, val_loss:  19.8609, grad_norm: 0.0073,  live_grad: 0.0000, reward_err: 0.0931, 0.0023, 0.0582, KL_dist: 1.4197, 0.7438, 1.1580, param: [11.73143816  2.77382286  7.95045857  5.55179764], weights: [0.35182407 0.30749325 0.34068268], train_wt_loss:  55.7533, val_wt_loss: 59.5828, train_grp_loss: [23.53354739 10.92338728 21.46382238], val_grp_loss: [22.61872855 13.98686861 22.77969733], train_hist_grp_loss: [24.30788099 10.84006819 21.08990534], cur_train_grp_loss: [0.24262242 0.10813771 0.21043463], max_reward_err:  0.0931, max_reward_err_index: 0, max_kl_dist:  1.4197, max_kl_dist_index: 0, max_train_grp_loss:  23.5335, max_train_grp_loss_index: 0, max_val_grp_loss:  22.7797, max_val_grp_loss_index: 2, max_cur_train_grp_loss:  0.2426, max_cur_train_grp_loss_index: 0, 
2024-09-17 23:51:10,958 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:386] - INFO: Policy parameter learned solely on the preference data rdpo: [11.73143816  2.77382286  7.95045857  5.55179764].
2024-09-17 23:51:11,277 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:397] - INFO: Uniform reward: 3.8636, 3.8636, 3.2166
2024-09-17 23:51:11,277 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Optimal reward: 3.8936, 3.8936, 3.3446
2024-09-17 23:51:11,278 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Policy reward: 3.5310, 3.8847, 3.1500
2024-09-17 23:51:11,278 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Reward Error: 0.0931, 0.0023, 0.0582
2024-09-17 23:51:11,950 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:415] - INFO: Optimal reward: 3.8936, 3.8936, 3.3446
Known param reward: [[3.8935821056365967, 3.5598950386047363, 3.297940969467163], [3.5598950386047363, 3.8935821056365967, 3.180600643157959], [3.8519034385681152, 3.663240909576416, 3.3445956707000732]], Known param reward error: [[0.0, 0.08570181852561777, 0.01394927992092528], [0.08570181852561777, 0.0, 0.0490328409436073], [0.010704453107113052, 0.05915919834507256, 0.0]].
