2024-09-17 23:53:39,371 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:198] - INFO: Logging to log_rdpo/2024_09_17_23_47_28/swapped_noise0.5_[0.5,0.5,0.5]_2030
2024-09-17 23:53:39,372 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: (IB) Seed: 2030
2024-09-17 23:53:39,373 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Data: 300
2024-09-17 23:53:39,530 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:296] - INFO: MLE reward loss: 0.5651, l2 distance: 8.6546, acc: 0.71.
2024-09-17 23:53:39,530 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-17 23:53:39,531 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: MLE reward parameter: [3.20649073 2.66360047 6.14834338 1.01478806]
2024-09-17 23:53:39,731 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:313] - INFO: Learned oracle reward: 3.3575, 3.7861, 3.0373
2024-09-17 23:53:39,986 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-17 23:53:41,151 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  19.5327, val_loss:  20.0399, grad_norm: 0.2042, live_grad: 0.0000, reward_err: 0.1216, 0.0018, 0.0816, KL_dist: 1.3593, 0.5025, 1.0867, param: [ 5.95466176  4.27535315 11.2149892   1.57077149], weights: [0.33347496 0.33318264 0.3333424 ], train_wt_loss:  58.5981, val_wt_loss: 60.1198, train_grp_loss: [22.362888   14.00697622 22.7121636 ], val_grp_loss: [23.02754375 15.18783523 21.63332764], train_hist_grp_loss: [0.27051055 0.18281317 0.2307495 ], cur_train_grp_loss: [0.27051055 0.18281317 0.2307495 ], max_reward_err:  0.1216, max_reward_err_index: 0, max_kl_dist:  1.3593, max_kl_dist_index: 0, max_train_grp_loss:  22.7122, max_train_grp_loss_index: 2, max_val_grp_loss:  23.0275, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2705, max_cur_train_grp_loss_index: 0, 
2024-09-17 23:53:45,357 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  99, train_loss:  19.5341, val_loss:  20.0175, grad_norm: 0.0056,  live_grad: 0.0000, reward_err: 0.1209, 0.0019, 0.0810, KL_dist: 1.3577, 0.5055, 1.0879, param: [ 5.90634808  4.38290484 11.25250087  1.69646446], weights: [0.3503563  0.31129953 0.33834417], train_wt_loss:  58.6024, val_wt_loss: 60.0525, train_grp_loss: [22.31317651 14.08433454 22.680244  ], val_grp_loss: [22.99349677 15.19449133 21.59437748], train_hist_grp_loss: [25.11904184 13.29953312 21.63033952], cur_train_grp_loss: [0.25071569 0.13286307 0.21600549], max_reward_err:  0.1209, max_reward_err_index: 0, max_kl_dist:  1.3577, max_kl_dist_index: 0, max_train_grp_loss:  22.6802, max_train_grp_loss_index: 2, max_val_grp_loss:  22.9935, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2507, max_cur_train_grp_loss_index: 0, 
2024-09-17 23:53:45,577 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:386] - INFO: Policy parameter learned solely on the preference data rdpo: [ 5.90634808  4.38290484 11.25250087  1.69646446].
2024-09-17 23:53:45,901 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:397] - INFO: Uniform reward: 3.7613, 3.7613, 3.1505
2024-09-17 23:53:45,902 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Optimal reward: 3.7992, 3.7992, 3.2896
2024-09-17 23:53:45,902 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Policy reward: 3.3398, 3.7920, 3.0232
2024-09-17 23:53:45,903 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Reward Error: 0.1209, 0.0019, 0.0810
2024-09-17 23:53:46,565 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:415] - INFO: Optimal reward: 3.7992, 3.7992, 3.2896
Known param reward: [[3.7992148399353027, 3.425678014755249, 3.2561442852020264], [3.425678014755249, 3.7992148399353027, 3.103405237197876], [3.7646615505218506, 3.5522572994232178, 3.289585590362549]], Known param reward error: [[0.0, 0.09831947939706792, 0.010165810933296573], [0.09831947939706792, 0.0, 0.05659690196543988], [0.009094850085930008, 0.06500225728647933, 0.0]].
