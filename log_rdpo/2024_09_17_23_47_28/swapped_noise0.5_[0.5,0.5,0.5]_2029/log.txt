2024-09-17 23:53:19,935 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:198] - INFO: Logging to log_rdpo/2024_09_17_23_47_28/swapped_noise0.5_[0.5,0.5,0.5]_2029
2024-09-17 23:53:19,936 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: (IB) Seed: 2029
2024-09-17 23:53:19,937 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Data: 300
2024-09-17 23:53:20,096 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:296] - INFO: MLE reward loss: 0.5100, l2 distance: 11.4125, acc: 0.76.
2024-09-17 23:53:20,097 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-17 23:53:20,098 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: MLE reward parameter: [4.40688023 4.68024843 6.93879403 3.39919698]
2024-09-17 23:53:20,303 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:313] - INFO: Learned oracle reward: 3.6078, 3.8321, 3.2611
2024-09-17 23:53:20,555 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-17 23:53:21,695 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  17.9512, val_loss:  19.2143, grad_norm: 0.2149, live_grad: 0.0000, reward_err: 0.0819, 0.0086, 0.0444, KL_dist: 1.1477, 0.6072, 0.9275, param: [ 6.73964939  5.73415175 10.21986171  4.07810347], weights: [0.33344743 0.33315324 0.33339933], train_wt_loss:  53.8536, val_wt_loss: 57.6429, train_grp_loss: [22.53805095 11.80384082 20.50372981], val_grp_loss: [22.44062613 13.26614617 21.59332429], train_hist_grp_loss: [0.25099333 0.16272535 0.23656661], cur_train_grp_loss: [0.25099333 0.16272535 0.23656661], max_reward_err:  0.0819, max_reward_err_index: 0, max_kl_dist:  1.1477, max_kl_dist_index: 0, max_train_grp_loss:  22.5381, max_train_grp_loss_index: 0, max_val_grp_loss:  22.4406, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2510, max_cur_train_grp_loss_index: 0, 
2024-09-17 23:53:26,042 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  99, train_loss:  17.9530, val_loss:  19.2445, grad_norm: 0.0065,  live_grad: 0.0000, reward_err: 0.0795, 0.0090, 0.0423, KL_dist: 1.1482, 0.6217, 0.9308, param: [ 6.74023165  5.86222704 10.23683764  4.20907044], weights: [0.35074919 0.30754205 0.34170876], train_wt_loss:  53.8589, val_wt_loss: 57.7335, train_grp_loss: [22.49799522 11.88574087 20.45460519], val_grp_loss: [22.40489339 13.44763304 21.54610194], train_hist_grp_loss: [23.96742097 10.8214631  21.35615941], cur_train_grp_loss: [0.23934494 0.10804392 0.21307409], max_reward_err:  0.0795, max_reward_err_index: 0, max_kl_dist:  1.1482, max_kl_dist_index: 0, max_train_grp_loss:  22.4980, max_train_grp_loss_index: 0, max_val_grp_loss:  22.4049, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2393, max_cur_train_grp_loss_index: 0, 
2024-09-17 23:53:26,261 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:386] - INFO: Policy parameter learned solely on the preference data rdpo: [ 6.74023165  5.86222704 10.23683764  4.20907044].
2024-09-17 23:53:26,585 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:397] - INFO: Uniform reward: 3.8475, 3.8475, 3.2402
2024-09-17 23:53:26,586 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Optimal reward: 3.8953, 3.8953, 3.3898
2024-09-17 23:53:26,587 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Policy reward: 3.5857, 3.8603, 3.2463
2024-09-17 23:53:26,587 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Reward Error: 0.0795, 0.0090, 0.0423
2024-09-17 23:53:27,268 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:415] - INFO: Optimal reward: 3.8953, 3.8953, 3.3898
Known param reward: [[3.8953254222869873, 3.486448287963867, 3.353602647781372], [3.486448287963867, 3.8953254222869873, 3.1823203563690186], [3.860149383544922, 3.6194307804107666, 3.3897509574890137]], Known param reward error: [[0.0, 0.1049661042396463, 0.01066400162164679], [0.1049661042396463, 0.0, 0.06119346339049376], [0.00903032094335605, 0.07082710992455157, 0.0]].
