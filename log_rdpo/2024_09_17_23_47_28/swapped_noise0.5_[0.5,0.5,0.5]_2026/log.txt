2024-09-17 23:52:24,464 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:198] - INFO: Logging to log_rdpo/2024_09_17_23_47_28/swapped_noise0.5_[0.5,0.5,0.5]_2026
2024-09-17 23:52:24,466 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: (IB) Seed: 2026
2024-09-17 23:52:24,467 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Data: 300
2024-09-17 23:52:24,625 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:296] - INFO: MLE reward loss: 0.5775, l2 distance: 6.1091, acc: 0.69.
2024-09-17 23:52:24,626 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-17 23:52:24,627 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: MLE reward parameter: [4.15899603 2.50783879 3.82970656 2.36927035]
2024-09-17 23:52:24,829 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:313] - INFO: Learned oracle reward: 3.5929, 3.8208, 3.2009
2024-09-17 23:52:25,080 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-17 23:52:26,268 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  20.0614, val_loss:  19.8613, grad_norm: 0.1515, live_grad: 0.0000, reward_err: 0.0771, 0.0067, 0.0376, KL_dist: 0.8557, 0.4203, 0.6607, param: [7.91014875 4.15661215 6.98845015 3.83383343], weights: [0.33337502 0.33315597 0.33346902], train_wt_loss:  60.1841, val_wt_loss: 59.5838, train_grp_loss: [22.65718765 14.45341703 23.18732447], val_grp_loss: [21.82155864 15.91736118 21.93161757], train_hist_grp_loss: [0.22597613 0.16024777 0.25416793], cur_train_grp_loss: [0.22597613 0.16024777 0.25416793], max_reward_err:  0.0771, max_reward_err_index: 0, max_kl_dist:  0.8557, max_kl_dist_index: 0, max_train_grp_loss:  23.1873, max_train_grp_loss_index: 2, max_val_grp_loss:  21.9316, max_val_grp_loss_index: 2, max_cur_train_grp_loss:  0.2542, max_cur_train_grp_loss_index: 2, 
2024-09-17 23:52:30,508 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  99, train_loss:  20.0625, val_loss:  19.8916, grad_norm: 0.0053,  live_grad: 0.0000, reward_err: 0.0757, 0.0083, 0.0364, KL_dist: 0.8462, 0.4260, 0.6547, param: [7.84198797 4.2467249  6.9932929  3.93768137], weights: [0.33762554 0.31415726 0.3482172 ], train_wt_loss:  60.1874, val_wt_loss: 59.6748, train_grp_loss: [22.61478007 14.53158657 23.15428355], val_grp_loss: [21.78970503 16.06742496 21.90194692], train_hist_grp_loss: [21.56887223 14.36450193 24.65777433], cur_train_grp_loss: [0.21538306 0.14386873 0.2463258 ], max_reward_err:  0.0757, max_reward_err_index: 0, max_kl_dist:  0.8462, max_kl_dist_index: 0, max_train_grp_loss:  23.1543, max_train_grp_loss_index: 2, max_val_grp_loss:  21.9019, max_val_grp_loss_index: 2, max_cur_train_grp_loss:  0.2463, max_cur_train_grp_loss_index: 2, 
2024-09-17 23:52:30,733 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:386] - INFO: Policy parameter learned solely on the preference data rdpo: [7.84198797 4.2467249  6.9932929  3.93768137].
2024-09-17 23:52:31,055 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:397] - INFO: Uniform reward: 3.8293, 3.8293, 3.1865
2024-09-17 23:52:31,055 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Optimal reward: 3.8673, 3.8673, 3.3083
2024-09-17 23:52:31,056 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Policy reward: 3.5747, 3.8353, 3.1880
2024-09-17 23:52:31,056 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Reward Error: 0.0757, 0.0083, 0.0364
2024-09-17 23:52:31,723 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:415] - INFO: Optimal reward: 3.8673, 3.8673, 3.3083
Known param reward: [[3.8672773838043213, 3.4776079654693604, 3.2754199504852295], [3.4776079654693604, 3.8672773838043213, 3.11952543258667], [3.824310302734375, 3.597230911254883, 3.3083386421203613]], Known param reward error: [[0.0, 0.10076065915696872, 0.009950218280566882], [0.10076065915696872, 0.0, 0.05707191130007124], [0.011110421313425073, 0.06982857595898335, 0.0]].
