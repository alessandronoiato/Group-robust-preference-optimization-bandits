2024-09-17 23:51:24,501 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:198] - INFO: Logging to log_rdpo/2024_09_17_23_47_28/swapped_noise0.5_[0.5,0.5,0.5]_2023
2024-09-17 23:51:24,503 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: (IB) Seed: 2023
2024-09-17 23:51:24,503 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Data: 300
2024-09-17 23:51:24,664 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:296] - INFO: MLE reward loss: 0.6000, l2 distance: 6.9758, acc: 0.68.
2024-09-17 23:51:24,665 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-17 23:51:24,666 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: MLE reward parameter: [4.704559   1.42187438 3.82459342 1.41318075]
2024-09-17 23:51:24,868 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:313] - INFO: Learned oracle reward: 3.4662, 3.8699, 3.1016
2024-09-17 23:51:25,119 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-17 23:51:26,271 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  20.8554, val_loss:  18.9176, grad_norm: 0.1376, live_grad: 0.0000, reward_err: 0.1095, 0.0002, 0.0685, KL_dist: 1.1252, 0.4572, 0.8662, param: [9.3365075  2.48677903 7.58258595 2.40457067], weights: [0.33337985 0.33322389 0.33339626], train_wt_loss:  62.5663, val_wt_loss: 56.7528, train_grp_loss: [24.57697898 16.34554113 21.98194758], val_grp_loss: [23.40914335 10.191421   22.29559677], train_hist_grp_loss: [0.2385392  0.19174732 0.24346003], cur_train_grp_loss: [0.2385392  0.19174732 0.24346003], max_reward_err:  0.1095, max_reward_err_index: 0, max_kl_dist:  1.1252, max_kl_dist_index: 0, max_train_grp_loss:  24.5770, max_train_grp_loss_index: 0, max_val_grp_loss:  23.4091, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2435, max_cur_train_grp_loss_index: 2, 
2024-09-17 23:51:30,668 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  99, train_loss:  20.8572, val_loss:  18.8838, grad_norm: 0.0058,  live_grad: 0.0000, reward_err: 0.1064, 0.0002, 0.0656, KL_dist: 1.1102, 0.4586, 0.8548, param: [9.21586318 2.63540045 7.67610416 2.51431188], weights: [0.3445857  0.31484356 0.34057074], train_wt_loss:  62.5716, val_wt_loss: 56.6515, train_grp_loss: [24.51082414 16.46249636 21.92604772], val_grp_loss: [23.35125378 10.2183996  22.23106686], train_hist_grp_loss: [24.5375779  15.51088174 23.36558189], cur_train_grp_loss: [0.24511507 0.15529478 0.23326187], max_reward_err:  0.1064, max_reward_err_index: 0, max_kl_dist:  1.1102, max_kl_dist_index: 0, max_train_grp_loss:  24.5108, max_train_grp_loss_index: 0, max_val_grp_loss:  23.3513, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2451, max_cur_train_grp_loss_index: 0, 
2024-09-17 23:51:30,886 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:386] - INFO: Policy parameter learned solely on the preference data rdpo: [9.21586318 2.63540045 7.67610416 2.51431188].
2024-09-17 23:51:31,208 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:397] - INFO: Uniform reward: 3.8276, 3.8276, 3.1817
2024-09-17 23:51:31,209 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Optimal reward: 3.8701, 3.8701, 3.3139
2024-09-17 23:51:31,209 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Policy reward: 3.4582, 3.8694, 3.0964
2024-09-17 23:51:31,210 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Reward Error: 0.1064, 0.0002, 0.0656
2024-09-17 23:51:31,887 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:415] - INFO: Optimal reward: 3.8701, 3.8701, 3.3139
Known param reward: [[3.8700804710388184, 3.487717866897583, 3.2859814167022705], [3.487717866897583, 3.8700804710388184, 3.1208972930908203], [3.8352792263031006, 3.614060401916504, 3.3138818740844727]], Known param reward error: [[0.0, 0.09879965210092917, 0.008419267325245327], [0.09879965210092917, 0.0, 0.058235202196809825], [0.008992382715591524, 0.06615368105087303, 0.0]].
