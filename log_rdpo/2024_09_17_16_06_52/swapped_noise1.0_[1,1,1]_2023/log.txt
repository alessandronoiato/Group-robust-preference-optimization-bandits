2024-09-17 16:07:37,380 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:198] - INFO: Logging to log_rdpo/2024_09_17_16_06_52/swapped_noise1.0_[1,1,1]_2023
2024-09-17 16:07:37,382 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: (IB) Seed: 2023
2024-09-17 16:07:37,383 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Data: 300
2024-09-17 16:07:37,543 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:296] - INFO: MLE reward loss: 0.3640, l2 distance: 33.1940, acc: 0.79.
2024-09-17 16:07:37,544 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-17 16:07:37,545 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: MLE reward parameter: [12.21044287  7.99401411 15.4309833   8.31914459]
2024-09-17 16:07:37,747 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:313] - INFO: Learned oracle reward: 3.5753, 3.8283, 3.1796
2024-09-17 16:07:37,975 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-17 16:07:39,141 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  14.6066, val_loss:  14.7000, grad_norm: 0.2988, live_grad: 0.0000, reward_err: 0.1018, 0.0007, 0.0637, KL_dist: 2.1608, 1.1763, 1.8143, param: [ 9.49712273  4.42807493 15.76875098  5.04876892], weights: [0.33333577 0.33327412 0.33339012], train_wt_loss:  43.8197, val_wt_loss: 44.0999, train_grp_loss: [21.26770405  6.5710972  16.58155136], val_grp_loss: [19.2266999   6.82553381 17.84002684], train_hist_grp_loss: [0.22367458 0.20517723 0.2399775 ], cur_train_grp_loss: [0.22367458 0.20517723 0.2399775 ], max_reward_err:  0.1018, max_reward_err_index: 0, max_kl_dist:  2.1608, max_kl_dist_index: 0, max_train_grp_loss:  21.2677, max_train_grp_loss_index: 0, max_val_grp_loss:  19.2267, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2400, max_cur_train_grp_loss_index: 2, 
2024-09-17 16:07:43,428 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  99, train_loss:  14.6167, val_loss:  14.7007, grad_norm: 0.0143,  live_grad: 0.0000, reward_err: 0.1001, 0.0014, 0.0624, KL_dist: 2.1644, 1.1925, 1.8261, param: [ 9.35502059  4.74376986 15.8818736   5.39091722], weights: [0.35344929 0.30539376 0.34115695], train_wt_loss:  43.8501, val_wt_loss: 44.1020, train_grp_loss: [21.00477465  7.00598401 16.40317488], val_grp_loss: [19.01654644  7.23433345 17.65587385], train_hist_grp_loss: [21.15100535  6.53720082 17.61126717], cur_train_grp_loss: [0.21007497 0.06604897 0.17452145], max_reward_err:  0.1001, max_reward_err_index: 0, max_kl_dist:  2.1644, max_kl_dist_index: 0, max_train_grp_loss:  21.0048, max_train_grp_loss_index: 0, max_val_grp_loss:  19.0165, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2101, max_cur_train_grp_loss_index: 0, 
2024-09-17 16:07:43,644 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:386] - INFO: Policy parameter learned solely on the preference data rdpo: [ 9.35502059  4.74376986 15.8818736   5.39091722].
2024-09-17 16:07:43,963 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:397] - INFO: Uniform reward: 3.8165, 3.8165, 3.1738
2024-09-17 16:07:43,963 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Optimal reward: 3.8573, 3.8573, 3.3040
2024-09-17 16:07:43,964 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Policy reward: 3.4713, 3.8518, 3.0979
2024-09-17 16:07:43,964 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Reward Error: 0.1001, 0.0014, 0.0624
2024-09-17 16:07:44,626 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:415] - INFO: Optimal reward: 3.8573, 3.8573, 3.3040
Known param reward: [[3.8573076725006104, 3.4820022583007812, 3.2755494117736816], [3.4820022583007812, 3.8573076725006104, 3.1173529624938965], [3.8217499256134033, 3.595449686050415, 3.3040339946746826]], Known param reward error: [[0.0, 0.09729724617910154, 0.008621153095552695], [0.09729724617910154, 0.0, 0.05650094172204995], [0.00921828122260097, 0.06788620682685609, 0.0]].
