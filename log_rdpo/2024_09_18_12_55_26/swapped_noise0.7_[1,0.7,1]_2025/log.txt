2024-09-18 13:49:19,290 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log_rdpo/2024_09_18_12_55_26/swapped_noise0.7_[1,0.7,1]_2025
2024-09-18 13:49:19,292 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2025
2024-09-18 13:49:19,293 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-09-18 13:49:19,460 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.4760, l2 distance: 16.8254, acc: 0.80.
2024-09-18 13:49:19,460 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-18 13:49:19,461 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [8.55126918 3.01638194 8.54793343 2.89986961]
2024-09-18 13:49:19,673 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.4837, 3.8683, 3.1163
2024-09-18 13:49:19,922 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-18 13:49:21,119 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  16.6657, val_loss:  16.9586, grad_norm: 0.2365, live_grad: 0.0000, reward_err: 0.1086, 0.0006, 0.0673, KL_dist: 2.0184, 1.0384, 1.6235, param: [12.39377189  3.35823888 11.87278572  3.17004598], weights: [0.33341971 0.33321176 0.33336853], train_wt_loss:  49.9971, val_wt_loss: 50.8757, train_grp_loss: [20.25582721 12.2816872  18.27743078], val_grp_loss: [20.33391184 12.28322621 18.16914589], train_hist_grp_loss: [0.24254782 0.18015918 0.22719429], cur_train_grp_loss: [0.24254782 0.18015918 0.22719429], max_reward_err:  0.1086, max_reward_err_index: 0, max_kl_dist:  2.0184, max_kl_dist_index: 0, max_train_grp_loss:  20.2558, max_train_grp_loss_index: 0, max_val_grp_loss:  20.3339, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2425, max_cur_train_grp_loss_index: 0, 
2024-09-18 13:49:25,581 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  99, train_loss:  16.6699, val_loss:  16.9100, grad_norm: 0.0097,  live_grad: 0.0000, reward_err: 0.1074, 0.0005, 0.0662, KL_dist: 2.0254, 1.0527, 1.6326, param: [12.40731214  3.53889471 11.98812818  3.37480923], weights: [0.34875754 0.31329145 0.33795102], train_wt_loss:  50.0096, val_wt_loss: 50.7301, train_grp_loss: [20.11250892 12.52541341 18.14730461], val_grp_loss: [20.19855579 12.42375003 18.02739264], train_hist_grp_loss: [21.96370958 11.23940607 18.81611142], cur_train_grp_loss: [0.21863023 0.11281799 0.18709938], max_reward_err:  0.1074, max_reward_err_index: 0, max_kl_dist:  2.0254, max_kl_dist_index: 0, max_train_grp_loss:  20.1125, max_train_grp_loss_index: 0, max_val_grp_loss:  20.1986, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2186, max_cur_train_grp_loss_index: 0, 
2024-09-18 13:49:25,804 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:387] - INFO: Policy parameter learned solely on the preference data rdpo: [12.40731214  3.53889471 11.98812818  3.37480923].
2024-09-18 13:49:26,134 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Uniform reward: 3.8283, 3.8283, 3.1728
2024-09-18 13:49:26,134 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Optimal reward: 3.8685, 3.8685, 3.3122
2024-09-18 13:49:26,135 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Policy reward: 3.4531, 3.8667, 3.0930
2024-09-18 13:49:26,135 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Reward Error: 0.1074, 0.0005, 0.0662
2024-09-18 13:49:26,820 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:416] - INFO: Optimal reward: 3.8685, 3.8685, 3.3122
Known param reward: [[3.8684823513031006, 3.4799795150756836, 3.271944284439087], [3.4799795150756836, 3.8684823513031006, 3.1135053634643555], [3.832144021987915, 3.6156766414642334, 3.312178611755371]], Known param reward error: [[0.0, 0.10042771323398944, 0.012147390594663916], [0.10042771323398944, 0.0, 0.059982649361328924], [0.009393432880195242, 0.06535010034457296, 0.0]].
