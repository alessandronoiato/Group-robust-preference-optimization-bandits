2024-09-18 13:48:20,991 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log_rdpo/2024_09_18_12_55_26/swapped_noise0.7_[1,0.7,1]_2022
2024-09-18 13:48:20,993 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2022
2024-09-18 13:48:20,994 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-09-18 13:48:21,162 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.4153, l2 distance: 24.8375, acc: 0.81.
2024-09-18 13:48:21,163 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-18 13:48:21,163 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [ 9.33890593  6.41457949 11.88684832  7.39091614]
2024-09-18 13:48:21,379 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.6614, 3.8281, 3.2443
2024-09-18 13:48:21,630 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-18 13:48:22,844 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  15.5683, val_loss:  16.3565, grad_norm: 0.2956, live_grad: 0.0000, reward_err: 0.0815, 0.0068, 0.0490, KL_dist: 1.8064, 1.0785, 1.5356, param: [ 8.67709731  5.3334854  14.09282269  6.42845463], weights: [0.33338569 0.33325452 0.33335979], train_wt_loss:  46.7050, val_wt_loss: 49.0696, train_grp_loss: [17.93834354 11.39483787 17.44703512], val_grp_loss: [19.3735929  13.23869343 16.50353129], train_hist_grp_loss: [0.24256839 0.20321328 0.23479837], cur_train_grp_loss: [0.24256839 0.20321328 0.23479837], max_reward_err:  0.0815, max_reward_err_index: 0, max_kl_dist:  1.8064, max_kl_dist_index: 0, max_train_grp_loss:  17.9383, max_train_grp_loss_index: 0, max_val_grp_loss:  19.3736, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2426, max_cur_train_grp_loss_index: 0, 
2024-09-18 13:48:27,307 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  99, train_loss:  15.5711, val_loss:  16.3888, grad_norm: 0.0066,  live_grad: 0.0000, reward_err: 0.0798, 0.0080, 0.0474, KL_dist: 1.8125, 1.1028, 1.5445, param: [ 8.75443412  5.52160639 14.10143977  6.61935502], weights: [0.3425868  0.31947675 0.33793646], train_wt_loss:  46.7132, val_wt_loss: 49.1663, train_grp_loss: [17.79920607 11.65217484 17.33264706], val_grp_loss: [19.24138378 13.57624958 16.39112874], train_hist_grp_loss: [18.480308   11.49625259 17.11359177], cur_train_grp_loss: [0.18351134 0.11534174 0.16993915], max_reward_err:  0.0798, max_reward_err_index: 0, max_kl_dist:  1.8125, max_kl_dist_index: 0, max_train_grp_loss:  17.7992, max_train_grp_loss_index: 0, max_val_grp_loss:  19.2414, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.1835, max_cur_train_grp_loss_index: 0, 
2024-09-18 13:48:27,531 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:387] - INFO: Policy parameter learned solely on the preference data rdpo: [ 8.75443412  5.52160639 14.10143977  6.61935502].
2024-09-18 13:48:27,862 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Uniform reward: 3.8491, 3.8491, 3.2014
2024-09-18 13:48:27,863 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Optimal reward: 3.8793, 3.8793, 3.3301
2024-09-18 13:48:27,863 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Policy reward: 3.5696, 3.8484, 3.1722
2024-09-18 13:48:27,864 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Reward Error: 0.0798, 0.0080, 0.0474
2024-09-18 13:48:28,545 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:416] - INFO: Optimal reward: 3.8793, 3.8793, 3.3301
Known param reward: [[3.879298448562622, 3.552269458770752, 3.2809364795684814], [3.552269458770752, 3.879298448562622, 3.1701314449310303], [3.8373265266418457, 3.6485824584960938, 3.3300602436065674]], Known param reward error: [[0.0, 0.08430106477449359, 0.014751614218511329], [0.08430106477449359, 0.0, 0.04802579742591348], [0.010819461940683636, 0.05947363759857518, 0.0]].
