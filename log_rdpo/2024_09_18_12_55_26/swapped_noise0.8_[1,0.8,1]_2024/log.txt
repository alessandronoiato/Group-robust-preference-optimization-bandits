2024-09-18 13:45:41,076 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log_rdpo/2024_09_18_12_55_26/swapped_noise0.8_[1,0.8,1]_2024
2024-09-18 13:45:41,078 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2024
2024-09-18 13:45:41,078 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-09-18 13:45:41,246 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.3901, l2 distance: 29.9953, acc: 0.82.
2024-09-18 13:45:41,247 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-18 13:45:41,248 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [13.0897178   7.38539327 12.98844152  6.48402242]
2024-09-18 13:45:41,461 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.6340, 3.9123, 3.3016
2024-09-18 13:45:41,713 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-18 13:45:42,919 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  15.4655, val_loss:  15.7854, grad_norm: 0.2366, live_grad: 0.0000, reward_err: 0.0951, 0.0007, 0.0519, KL_dist: 1.9444, 1.0763, 1.5869, param: [12.48728499  5.4016518  12.09334499  4.50286648], weights: [0.33336918 0.33326617 0.33336465], train_wt_loss:  46.3964, val_wt_loss: 47.3561, train_grp_loss: [18.02588869 10.19840536 17.41962534], val_grp_loss: [19.60343519 10.67220328 16.84038604], train_hist_grp_loss: [0.20469295 0.17378765 0.20333504], cur_train_grp_loss: [0.20469295 0.17378765 0.20333504], max_reward_err:  0.0951, max_reward_err_index: 0, max_kl_dist:  1.9444, max_kl_dist_index: 0, max_train_grp_loss:  18.0259, max_train_grp_loss_index: 0, max_val_grp_loss:  19.6034, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2047, max_cur_train_grp_loss_index: 0, 
2024-09-18 13:45:47,419 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  99, train_loss:  15.4672, val_loss:  15.7814, grad_norm: 0.0059,  live_grad: 0.0000, reward_err: 0.0940, 0.0009, 0.0510, KL_dist: 1.9530, 1.0910, 1.5965, param: [12.49701581  5.51547465 12.19358079  4.63744873], weights: [0.34020659 0.32151657 0.33827684], train_wt_loss:  46.4015, val_wt_loss: 47.3442, train_grp_loss: [17.93315294 10.41016799 17.33574574], val_grp_loss: [19.51639067 10.83961902 16.75663001], train_hist_grp_loss: [17.15710357 11.50670608 16.58826137], cur_train_grp_loss: [0.17080076 0.11564441 0.16511032], max_reward_err:  0.0940, max_reward_err_index: 0, max_kl_dist:  1.9530, max_kl_dist_index: 0, max_train_grp_loss:  17.9332, max_train_grp_loss_index: 0, max_val_grp_loss:  19.5164, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.1708, max_cur_train_grp_loss_index: 0, 
2024-09-18 13:45:47,650 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:387] - INFO: Policy parameter learned solely on the preference data rdpo: [12.49701581  5.51547465 12.19358079  4.63744873].
2024-09-18 13:45:47,985 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Uniform reward: 3.8988, 3.8988, 3.2898
2024-09-18 13:45:47,986 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Optimal reward: 3.9394, 3.9394, 3.4305
2024-09-18 13:45:47,986 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Policy reward: 3.5692, 3.9357, 3.2557
2024-09-18 13:45:47,987 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Reward Error: 0.0940, 0.0009, 0.0510
2024-09-18 13:45:48,680 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:416] - INFO: Optimal reward: 3.9394, 3.9394, 3.4305
Known param reward: [[3.939390182495117, 3.527578830718994, 3.3940188884735107], [3.527578830718994, 3.939390182495117, 3.225066661834717], [3.8967127799987793, 3.6586339473724365, 3.4304511547088623]], Known param reward error: [[0.0, 0.10453682745264177, 0.010620255060429077], [0.10453682745264177, 0.0, 0.059870985946621415], [0.010833504811474914, 0.07126895842159414, 0.0]].
