2024-09-18 13:52:31,328 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log_rdpo/2024_09_18_12_55_26/swapped_noise0.6_[1,0.6,1]_2025
2024-09-18 13:52:31,330 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2025
2024-09-18 13:52:31,330 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-09-18 13:52:31,494 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.4186, l2 distance: 22.2412, acc: 0.83.
2024-09-18 13:52:31,495 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-18 13:52:31,496 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [10.68681421  4.39154412  9.89498342  5.86496191]
2024-09-18 13:52:31,709 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.5661, 3.8500, 3.1759
2024-09-18 13:52:31,942 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-18 13:52:33,153 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  15.5316, val_loss:  16.4714, grad_norm: 0.2625, live_grad: 0.0000, reward_err: 0.0900, 0.0009, 0.0512, KL_dist: 1.7719, 0.9612, 1.4370, param: [11.86320807  3.98278565 10.76241069  5.06115476], weights: [0.33340978 0.33321604 0.33337418], train_wt_loss:  46.5947, val_wt_loss: 49.4142, train_grp_loss: [18.26752911 11.46735308 17.58745435], val_grp_loss: [20.28468339 12.62563774 16.54334001], train_hist_grp_loss: [0.23458711 0.17646423 0.22391003], cur_train_grp_loss: [0.23458711 0.17646423 0.22391003], max_reward_err:  0.0900, max_reward_err_index: 0, max_kl_dist:  1.7719, max_kl_dist_index: 0, max_train_grp_loss:  18.2675, max_train_grp_loss_index: 0, max_val_grp_loss:  20.2847, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2346, max_cur_train_grp_loss_index: 0, 
2024-09-18 13:52:37,637 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  99, train_loss:  15.5349, val_loss:  16.4691, grad_norm: 0.0087,  live_grad: 0.0000, reward_err: 0.0890, 0.0013, 0.0503, KL_dist: 1.7886, 0.9837, 1.4546, param: [12.00182488  4.14411835 10.78366414  5.22479861], weights: [0.34554984 0.31476703 0.33968312], train_wt_loss:  46.6048, val_wt_loss: 49.4073, train_grp_loss: [18.14507102 11.68096875 17.46952421], val_grp_loss: [20.17876249 12.84607299 16.43235871], train_hist_grp_loss: [19.82707096 10.49665873 18.11470045], cur_train_grp_loss: [0.19724263 0.10521346 0.18011063], max_reward_err:  0.0890, max_reward_err_index: 0, max_kl_dist:  1.7886, max_kl_dist_index: 0, max_train_grp_loss:  18.1451, max_train_grp_loss_index: 0, max_val_grp_loss:  20.1788, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.1972, max_cur_train_grp_loss_index: 0, 
2024-09-18 13:52:37,858 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:387] - INFO: Policy parameter learned solely on the preference data rdpo: [12.00182488  4.14411835 10.78366414  5.22479861].
2024-09-18 13:52:38,183 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Uniform reward: 3.8283, 3.8283, 3.1728
2024-09-18 13:52:38,184 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Optimal reward: 3.8685, 3.8685, 3.3122
2024-09-18 13:52:38,185 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Policy reward: 3.5243, 3.8635, 3.1455
2024-09-18 13:52:38,185 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Reward Error: 0.0890, 0.0013, 0.0503
2024-09-18 13:52:38,863 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:416] - INFO: Optimal reward: 3.8685, 3.8685, 3.3122
Known param reward: [[3.8684823513031006, 3.4799795150756836, 3.271944284439087], [3.4799795150756836, 3.8684823513031006, 3.1135053634643555], [3.832144021987915, 3.6156766414642334, 3.312178611755371]], Known param reward error: [[0.0, 0.10042771323398944, 0.012147390594663916], [0.10042771323398944, 0.0, 0.059982649361328924], [0.009393432880195242, 0.06535010034457296, 0.0]].
