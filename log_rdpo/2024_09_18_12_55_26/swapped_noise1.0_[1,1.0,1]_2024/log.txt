2024-09-18 13:39:20,434 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log_rdpo/2024_09_18_12_55_26/swapped_noise1.0_[1,1.0,1]_2024
2024-09-18 13:39:20,436 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2024
2024-09-18 13:39:20,436 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-09-18 13:39:20,598 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.3356, l2 distance: 38.9673, acc: 0.85.
2024-09-18 13:39:20,599 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-18 13:39:20,599 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [17.27970071  8.4454928  15.8117603   7.63032288]
2024-09-18 13:39:20,808 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.4756, 3.7525, 3.0863
2024-09-18 13:39:21,065 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-18 13:39:22,245 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  14.2034, val_loss:  15.3329, grad_norm: 0.2917, live_grad: 0.0000, reward_err: 0.0910, 0.0004, 0.0539, KL_dist: 2.2845, 1.3386, 1.8775, param: [14.47097672  5.55876432 12.79854097  4.73007604], weights: [0.33330241 0.33339233 0.33330525], train_wt_loss:  42.6101, val_wt_loss: 45.9987, train_grp_loss: [18.3898056   8.01621739 15.3202444 ], val_grp_loss: [19.86814884  8.34887898 17.31047267], train_hist_grp_loss: [0.21290285 0.23987755 0.21375545], cur_train_grp_loss: [0.21290285 0.23987755 0.21375545], max_reward_err:  0.0910, max_reward_err_index: 0, max_kl_dist:  2.2845, max_kl_dist_index: 0, max_train_grp_loss:  18.3898, max_train_grp_loss_index: 0, max_val_grp_loss:  19.8681, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2399, max_cur_train_grp_loss_index: 1, 
2024-09-18 13:39:26,614 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  99, train_loss:  14.2063, val_loss:  15.3511, grad_norm: 0.0069,  live_grad: 0.0000, reward_err: 0.0904, 0.0006, 0.0533, KL_dist: 2.2969, 1.3614, 1.8917, param: [14.53677922  5.74826033 12.86556298  4.92837553], weights: [0.34577862 0.31829684 0.33592454], train_wt_loss:  42.6190, val_wt_loss: 46.0533, train_grp_loss: [18.26790329  8.30507248 15.20300468], val_grp_loss: [19.73714851  8.68378077 17.18755765], train_hist_grp_loss: [17.49490811  9.21347192 14.60368708], cur_train_grp_loss: [0.17399171 0.09224528 0.14480169], max_reward_err:  0.0904, max_reward_err_index: 0, max_kl_dist:  2.2969, max_kl_dist_index: 0, max_train_grp_loss:  18.2679, max_train_grp_loss_index: 0, max_val_grp_loss:  19.7371, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.1740, max_cur_train_grp_loss_index: 0, 
2024-09-18 13:39:26,831 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:387] - INFO: Policy parameter learned solely on the preference data rdpo: [14.53677922  5.74826033 12.86556298  4.92837553].
2024-09-18 13:39:27,153 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Uniform reward: 3.7209, 3.7209, 3.0767
2024-09-18 13:39:27,154 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Optimal reward: 3.7640, 3.7640, 3.2194
2024-09-18 13:39:27,154 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Policy reward: 3.4237, 3.7616, 3.0478
2024-09-18 13:39:27,155 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Reward Error: 0.0904, 0.0006, 0.0533
2024-09-18 13:39:27,831 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:416] - INFO: Optimal reward: 3.7640, 3.7640, 3.2194
Known param reward: [[3.763953685760498, 3.410576581954956, 3.186079502105713], [3.410576581954956, 3.763953685760498, 3.0397133827209473], [3.730111837387085, 3.5351030826568604, 3.21937894821167]], Known param reward error: [[0.0, 0.0938845515401561, 0.010343437862279155], [0.0938845515401561, 0.0, 0.05580752324622267], [0.008991037403419968, 0.06080058954216355, 0.0]].
