2024-09-18 13:44:00,166 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log_rdpo/2024_09_18_12_55_26/swapped_noise0.9_[1,0.9,1]_2029
2024-09-18 13:44:00,168 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2029
2024-09-18 13:44:00,168 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-09-18 13:44:00,334 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.3652, l2 distance: 29.0167, acc: 0.83.
2024-09-18 13:44:00,335 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-18 13:44:00,335 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [13.58728005  5.58538091 11.73484358  7.63338983]
2024-09-18 13:44:00,541 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.5545, 3.8681, 3.2297
2024-09-18 13:44:00,795 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-18 13:44:01,992 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  14.2601, val_loss:  15.0617, grad_norm: 0.2820, live_grad: 0.0000, reward_err: 0.1042, 0.0010, 0.0611, KL_dist: 1.9266, 1.0495, 1.5689, param: [13.1720011   4.4957407  10.93660477  5.19477369], weights: [0.3334374  0.33315013 0.33341247], train_wt_loss:  42.7803, val_wt_loss: 45.1852, train_grp_loss: [19.74669818  7.3698829  16.7828899 ], val_grp_loss: [19.10713355  7.81535884 17.70382022], train_hist_grp_loss: [0.23515703 0.14896465 0.22767833], cur_train_grp_loss: [0.23515703 0.14896465 0.22767833], max_reward_err:  0.1042, max_reward_err_index: 0, max_kl_dist:  1.9266, max_kl_dist_index: 0, max_train_grp_loss:  19.7467, max_train_grp_loss_index: 0, max_val_grp_loss:  19.1071, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2352, max_cur_train_grp_loss_index: 0, 
2024-09-18 13:44:06,467 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  99, train_loss:  14.2681, val_loss:  15.0487, grad_norm: 0.0129,  live_grad: 0.0000, reward_err: 0.1015, 0.0016, 0.0589, KL_dist: 1.9399, 1.0735, 1.5869, param: [13.42793029  4.78256821 10.78607831  5.43802837], weights: [0.3526638  0.30664195 0.34069425], train_wt_loss:  42.8042, val_wt_loss: 45.1460, train_grp_loss: [19.51892096  7.71361743 16.63686312], val_grp_loss: [18.91066064  8.1534238  17.54939233], train_hist_grp_loss: [20.91413636  6.93069555 17.46116158], cur_train_grp_loss: [0.20767296 0.0700896  0.17331641], max_reward_err:  0.1015, max_reward_err_index: 0, max_kl_dist:  1.9399, max_kl_dist_index: 0, max_train_grp_loss:  19.5189, max_train_grp_loss_index: 0, max_val_grp_loss:  18.9107, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2077, max_cur_train_grp_loss_index: 0, 
2024-09-18 13:44:06,688 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:387] - INFO: Policy parameter learned solely on the preference data rdpo: [13.42793029  4.78256821 10.78607831  5.43802837].
2024-09-18 13:44:07,013 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Uniform reward: 3.8399, 3.8399, 3.2334
2024-09-18 13:44:07,014 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Optimal reward: 3.8872, 3.8872, 3.3828
2024-09-18 13:44:07,014 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Policy reward: 3.4928, 3.8811, 3.1836
2024-09-18 13:44:07,015 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Reward Error: 0.1015, 0.0016, 0.0589
2024-09-18 13:44:07,691 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:416] - INFO: Optimal reward: 3.8872, 3.8872, 3.3828
Known param reward: [[3.8871653079986572, 3.4750781059265137, 3.3463027477264404], [3.4750781059265137, 3.8871653079986572, 3.1734652519226074], [3.8522720336914062, 3.6094093322753906, 3.38283634185791]], Known param reward error: [[0.0, 0.10601226585969672, 0.010799693050301354], [0.10601226585969672, 0.0, 0.06189217235981113], [0.00897653470909785, 0.0714546343454253, 0.0]].
