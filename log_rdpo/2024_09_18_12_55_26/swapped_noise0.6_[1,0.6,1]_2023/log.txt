2024-09-18 13:51:54,221 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log_rdpo/2024_09_18_12_55_26/swapped_noise0.6_[1,0.6,1]_2023
2024-09-18 13:51:54,223 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2023
2024-09-18 13:51:54,224 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-09-18 13:51:54,385 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.4922, l2 distance: 15.4423, acc: 0.77.
2024-09-18 13:51:54,385 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-18 13:51:54,386 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [7.81608134 4.07221289 7.64012895 4.02565407]
2024-09-18 13:51:54,589 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.5230, 3.7882, 3.1263
2024-09-18 13:51:54,826 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-18 13:51:56,029 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  17.4871, val_loss:  17.9203, grad_norm: 0.1754, live_grad: 0.0000, reward_err: 0.0878, 0.0015, 0.0480, KL_dist: 1.5540, 0.8330, 1.2596, param: [11.13418652  4.51518981 10.00739275  4.53308761], weights: [0.33339695 0.3332189  0.33338415], train_wt_loss:  52.4614, val_wt_loss: 53.7609, train_grp_loss: [21.79286449 13.62072067 17.26658035], val_grp_loss: [19.60756068 15.86500045 18.32225424], train_hist_grp_loss: [0.21838431 0.16496442 0.21454467], cur_train_grp_loss: [0.21838431 0.16496442 0.21454467], max_reward_err:  0.0878, max_reward_err_index: 0, max_kl_dist:  1.5540, max_kl_dist_index: 0, max_train_grp_loss:  21.7929, max_train_grp_loss_index: 0, max_val_grp_loss:  19.6076, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2184, max_cur_train_grp_loss_index: 0, 
2024-09-18 13:52:00,452 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  99, train_loss:  17.4904, val_loss:  17.9102, grad_norm: 0.0083,  live_grad: 0.0000, reward_err: 0.0862, 0.0018, 0.0467, KL_dist: 1.5509, 0.8449, 1.2609, param: [11.19658937  4.69223957  9.93132915  4.7172806 ], weights: [0.34681973 0.31787139 0.33530888], train_wt_loss:  52.4713, val_wt_loss: 53.7306, train_grp_loss: [21.6378759  13.87388475 17.1565434 ], val_grp_loss: [19.47935439 16.07947769 18.20649213], train_hist_grp_loss: [21.7174993  13.00167326 18.34220191], cur_train_grp_loss: [0.21639448 0.13086065 0.18252824], max_reward_err:  0.0862, max_reward_err_index: 0, max_kl_dist:  1.5509, max_kl_dist_index: 0, max_train_grp_loss:  21.6379, max_train_grp_loss_index: 0, max_val_grp_loss:  19.4794, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2164, max_cur_train_grp_loss_index: 0, 
2024-09-18 13:52:00,671 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:387] - INFO: Policy parameter learned solely on the preference data rdpo: [11.19658937  4.69223957  9.93132915  4.7172806 ].
2024-09-18 13:52:00,993 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Uniform reward: 3.7732, 3.7732, 3.1224
2024-09-18 13:52:00,994 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Optimal reward: 3.8078, 3.8078, 3.2459
2024-09-18 13:52:00,994 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Policy reward: 3.4798, 3.8010, 3.0943
2024-09-18 13:52:00,995 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Reward Error: 0.0862, 0.0018, 0.0467
2024-09-18 13:52:01,674 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:416] - INFO: Optimal reward: 3.8078, 3.8078, 3.2459
Known param reward: [[3.807837963104248, 3.4243876934051514, 3.211453914642334], [3.4243876934051514, 3.807837963104248, 3.0547919273376465], [3.768700122833252, 3.5474116802215576, 3.245870590209961]], Known param reward error: [[0.0, 0.10070025915349037, 0.01060321864692723], [0.10070025915349037, 0.0, 0.05886823197715792], [0.010278231545097027, 0.06839216516198189, 0.0]].
