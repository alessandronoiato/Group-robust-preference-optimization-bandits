2024-09-18 13:51:35,507 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log_rdpo/2024_09_18_12_55_26/swapped_noise0.6_[1,0.6,1]_2022
2024-09-18 13:51:35,509 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2022
2024-09-18 13:51:35,509 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-09-18 13:51:35,674 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.4365, l2 distance: 24.4634, acc: 0.77.
2024-09-18 13:51:35,675 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-18 13:51:35,676 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [12.20053812  4.12955839  9.69131822  7.01616498]
2024-09-18 13:51:35,883 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.5748, 3.8395, 3.1822
2024-09-18 13:51:36,134 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-18 13:51:37,336 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  16.0686, val_loss:  16.9949, grad_norm: 0.2457, live_grad: 0.0000, reward_err: 0.0855, 0.0038, 0.0508, KL_dist: 2.0655, 1.2572, 1.7345, param: [14.73388824  3.9284719  10.8313627   7.32505218], weights: [0.33338676 0.33325895 0.33335429], train_wt_loss:  48.2057, val_wt_loss: 50.9848, train_grp_loss: [17.91965141 12.20951596 18.12940721], val_grp_loss: [19.56934574 15.40979817 15.97578386], train_hist_grp_loss: [0.2382242  0.19988158 0.22848672], cur_train_grp_loss: [0.2382242  0.19988158 0.22848672], max_reward_err:  0.0855, max_reward_err_index: 0, max_kl_dist:  2.0655, max_kl_dist_index: 0, max_train_grp_loss:  18.1294, max_train_grp_loss_index: 2, max_val_grp_loss:  19.5693, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2382, max_cur_train_grp_loss_index: 0, 
2024-09-18 13:51:41,773 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  99, train_loss:  16.0703, val_loss:  17.0187, grad_norm: 0.0059,  live_grad: 0.0000, reward_err: 0.0849, 0.0042, 0.0503, KL_dist: 2.0788, 1.2774, 1.7485, param: [14.79285125  4.05186181 10.90497976  7.47059173], weights: [0.34098754 0.32039597 0.33861649], train_wt_loss:  48.2110, val_wt_loss: 51.0561, train_grp_loss: [17.82937875 12.38700905 18.04468466], val_grp_loss: [19.48488807 15.66755469 15.88764042], train_hist_grp_loss: [18.48174089 12.25291127 17.78396306], cur_train_grp_loss: [0.18381742 0.12262541 0.17691705], max_reward_err:  0.0849, max_reward_err_index: 0, max_kl_dist:  2.0788, max_kl_dist_index: 0, max_train_grp_loss:  18.0447, max_train_grp_loss_index: 2, max_val_grp_loss:  19.4849, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.1838, max_cur_train_grp_loss_index: 0, 
2024-09-18 13:51:41,991 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:387] - INFO: Policy parameter learned solely on the preference data rdpo: [14.79285125  4.05186181 10.90497976  7.47059173].
2024-09-18 13:51:42,328 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Uniform reward: 3.8381, 3.8381, 3.1923
2024-09-18 13:51:42,329 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Optimal reward: 3.8683, 3.8683, 3.3211
2024-09-18 13:51:42,329 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Policy reward: 3.5400, 3.8522, 3.1542
2024-09-18 13:51:42,330 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Reward Error: 0.0849, 0.0042, 0.0503
2024-09-18 13:51:43,004 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:416] - INFO: Optimal reward: 3.8683, 3.8683, 3.3211
Known param reward: [[3.8683152198791504, 3.5409886837005615, 3.2718687057495117], [3.5409886837005615, 3.8683152198791504, 3.1612870693206787], [3.825526475906372, 3.6363391876220703, 3.3211145401000977]], Known param reward error: [[0.0, 0.08461733792956377, 0.014828104769039877], [0.08461733792956377, 0.0, 0.048124648773661925], [0.011061338474405682, 0.059968233991108726, 0.0]].
