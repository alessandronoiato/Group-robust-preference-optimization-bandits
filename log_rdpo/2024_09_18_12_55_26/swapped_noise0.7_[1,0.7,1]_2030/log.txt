2024-09-18 13:50:57,013 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log_rdpo/2024_09_18_12_55_26/swapped_noise0.7_[1,0.7,1]_2030
2024-09-18 13:50:57,015 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2030
2024-09-18 13:50:57,015 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-09-18 13:50:57,186 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.5028, l2 distance: 14.4583, acc: 0.80.
2024-09-18 13:50:57,187 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-18 13:50:57,188 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [7.494746   3.1680416  7.18686853 4.41994426]
2024-09-18 13:50:57,404 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.6021, 3.8710, 3.2761
2024-09-18 13:50:57,675 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-18 13:50:58,893 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  17.7078, val_loss:  16.6170, grad_norm: 0.2258, live_grad: 0.0000, reward_err: 0.0914, 0.0009, 0.0499, KL_dist: 1.6914, 0.8019, 1.3447, param: [11.22805451  3.38552266 10.09049331  4.98488652], weights: [0.3334291  0.33326719 0.33330371], train_wt_loss:  53.1235, val_wt_loss: 49.8510, train_grp_loss: [21.439798   14.03064905 18.2567419 ], val_grp_loss: [19.55956723 11.80030575 17.81240633], train_hist_grp_loss: [0.25274043 0.20416967 0.21512916], cur_train_grp_loss: [0.25274043 0.20416967 0.21512916], max_reward_err:  0.0914, max_reward_err_index: 0, max_kl_dist:  1.6914, max_kl_dist_index: 0, max_train_grp_loss:  21.4398, max_train_grp_loss_index: 0, max_val_grp_loss:  19.5596, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2527, max_cur_train_grp_loss_index: 0, 
2024-09-18 13:51:03,390 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  99, train_loss:  17.7112, val_loss:  16.5979, grad_norm: 0.0080,  live_grad: 0.0000, reward_err: 0.0894, 0.0016, 0.0484, KL_dist: 1.6839, 0.8088, 1.3427, param: [11.38013895  3.54399274  9.89345364  5.1593959 ], weights: [0.3526857  0.31723018 0.33008412], train_wt_loss:  53.1336, val_wt_loss: 49.7937, train_grp_loss: [21.27422317 14.26645479 18.16864474], val_grp_loss: [19.43051603 11.99570555 17.71826117], train_hist_grp_loss: [24.01054892 13.41558326 17.38757458], cur_train_grp_loss: [0.23905512 0.1345657  0.17304322], max_reward_err:  0.0894, max_reward_err_index: 0, max_kl_dist:  1.6839, max_kl_dist_index: 0, max_train_grp_loss:  21.2742, max_train_grp_loss_index: 0, max_val_grp_loss:  19.4305, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2391, max_cur_train_grp_loss_index: 0, 
2024-09-18 13:51:03,613 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:387] - INFO: Policy parameter learned solely on the preference data rdpo: [11.38013895  3.54399274  9.89345364  5.1593959 ].
2024-09-18 13:51:03,947 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Uniform reward: 3.8520, 3.8520, 3.2425
2024-09-18 13:51:03,948 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Optimal reward: 3.8957, 3.8957, 3.3999
2024-09-18 13:51:03,948 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Policy reward: 3.5474, 3.8895, 3.2354
2024-09-18 13:51:03,949 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Reward Error: 0.0894, 0.0016, 0.0484
2024-09-18 13:51:04,647 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:416] - INFO: Optimal reward: 3.8957, 3.8957, 3.3999
Known param reward: [[3.895703077316284, 3.5065040588378906, 3.358201503753662], [3.5065040588378906, 3.895703077316284, 3.206737756729126], [3.8558998107910156, 3.6177587509155273, 3.399937152862549]], Known param reward error: [[0.0, 0.09990469262008268, 0.012275417818752249], [0.09990469262008268, 0.0, 0.056824402171893156], [0.010217222856904351, 0.07134638366541791, 0.0]].
