2024-09-18 13:39:38,422 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log_rdpo/2024_09_18_12_55_26/swapped_noise1.0_[1,1.0,1]_2025
2024-09-18 13:39:38,424 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2025
2024-09-18 13:39:38,425 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-09-18 13:39:38,585 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.3597, l2 distance: 31.6072, acc: 0.81.
2024-09-18 13:39:38,586 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-18 13:39:38,587 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [13.00274755  7.23429623 14.54687762  6.41459427]
2024-09-18 13:39:38,794 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.5469, 3.8252, 3.1158
2024-09-18 13:39:39,050 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-18 13:39:40,223 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  14.4628, val_loss:  14.9123, grad_norm: 0.2942, live_grad: 0.0000, reward_err: 0.0920, 0.0002, 0.0530, KL_dist: 1.7846, 1.0584, 1.4618, param: [11.92582843  4.42489427 12.0261898   4.33152308], weights: [0.33346494 0.33311791 0.33341715], train_wt_loss:  43.3883, val_wt_loss: 44.7369, train_grp_loss: [19.64836894  6.04611199 19.17586793], val_grp_loss: [20.74167535  5.98271522 17.82542621], train_hist_grp_loss: [0.24945791 0.14533452 0.23512367], cur_train_grp_loss: [0.24945791 0.14533452 0.23512367], max_reward_err:  0.0920, max_reward_err_index: 0, max_kl_dist:  1.7846, max_kl_dist_index: 0, max_train_grp_loss:  19.6484, max_train_grp_loss_index: 0, max_val_grp_loss:  20.7417, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2495, max_cur_train_grp_loss_index: 0, 
2024-09-18 13:39:44,572 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  99, train_loss:  14.4768, val_loss:  14.8755, grad_norm: 0.0179,  live_grad: 0.0000, reward_err: 0.0869, 0.0007, 0.0485, KL_dist: 1.7751, 1.0746, 1.4611, param: [11.8061519   4.80614817 12.12267869  4.69361868], weights: [0.35202875 0.30150526 0.346466  ], train_wt_loss:  43.4303, val_wt_loss: 44.6266, train_grp_loss: [19.38033174  6.56434225 18.88038817], val_grp_loss: [20.46245546  6.38741099 17.60092304], train_hist_grp_loss: [21.2513659   5.75882812 19.65855043], cur_train_grp_loss: [0.21068596 0.05908631 0.19467478], max_reward_err:  0.0869, max_reward_err_index: 0, max_kl_dist:  1.7751, max_kl_dist_index: 0, max_train_grp_loss:  19.3803, max_train_grp_loss_index: 0, max_val_grp_loss:  20.4625, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2107, max_cur_train_grp_loss_index: 0, 
2024-09-18 13:39:44,788 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:387] - INFO: Policy parameter learned solely on the preference data rdpo: [11.8061519   4.80614817 12.12267869  4.69361868].
2024-09-18 13:39:45,107 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Uniform reward: 3.8117, 3.8117, 3.1389
2024-09-18 13:39:45,108 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Optimal reward: 3.8428, 3.8428, 3.2468
2024-09-18 13:39:45,108 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Policy reward: 3.5088, 3.8402, 3.0891
2024-09-18 13:39:45,109 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Reward Error: 0.0869, 0.0007, 0.0485
2024-09-18 13:39:45,777 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:416] - INFO: Optimal reward: 3.8428, 3.8428, 3.2468
Known param reward: [[3.8428120613098145, 3.466555118560791, 3.208935022354126], [3.466555118560791, 3.8428120613098145, 3.0578837394714355], [3.8028461933135986, 3.5883326530456543, 3.246764659881592]], Known param reward error: [[0.0, 0.09791187722586076, 0.01165148740064377], [0.09791187722586076, 0.0, 0.05817511898661749], [0.010400162005995563, 0.06622218422449246, 0.0]].
