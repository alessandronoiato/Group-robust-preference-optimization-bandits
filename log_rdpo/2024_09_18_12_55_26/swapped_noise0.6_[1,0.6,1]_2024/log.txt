2024-09-18 13:52:12,505 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log_rdpo/2024_09_18_12_55_26/swapped_noise0.6_[1,0.6,1]_2024
2024-09-18 13:52:12,507 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2024
2024-09-18 13:52:12,507 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-09-18 13:52:12,671 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.4480, l2 distance: 22.3833, acc: 0.81.
2024-09-18 13:52:12,672 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-18 13:52:12,673 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [ 8.64974841  6.83775145 10.10423611  7.40350601]
2024-09-18 13:52:12,878 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.7142, 3.8598, 3.3511
2024-09-18 13:52:13,113 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-18 13:52:14,299 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  16.8492, val_loss:  17.6334, grad_norm: 0.2070, live_grad: 0.0000, reward_err: 0.0777, 0.0097, 0.0389, KL_dist: 1.5209, 0.9393, 1.2586, param: [ 9.46214622  5.75705406 11.63630059  6.37075604], weights: [0.33333446 0.33333746 0.33332808], train_wt_loss:  50.5476, val_wt_loss: 52.9003, train_grp_loss: [18.40340031 14.64996578 17.18009999], val_grp_loss: [19.56599177 16.06113885 17.23920053], train_hist_grp_loss: [0.20638328 0.20728591 0.20447093], cur_train_grp_loss: [0.20638328 0.20728591 0.20447093], max_reward_err:  0.0777, max_reward_err_index: 0, max_kl_dist:  1.5209, max_kl_dist_index: 0, max_train_grp_loss:  18.4034, max_train_grp_loss_index: 0, max_val_grp_loss:  19.5660, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2073, max_cur_train_grp_loss_index: 1, 
2024-09-18 13:52:18,744 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  99, train_loss:  16.8492, val_loss:  17.6369, grad_norm: 0.0006,  live_grad: 0.0000, reward_err: 0.0777, 0.0099, 0.0389, KL_dist: 1.5214, 0.9415, 1.2593, param: [ 9.47446708  5.77353043 11.63274608  6.3866087 ], weights: [0.33597531 0.33190903 0.33211566], train_wt_loss:  50.5477, val_wt_loss: 52.9107, train_grp_loss: [18.39310108 14.67438949 17.16953076], val_grp_loss: [19.55501783 16.09419753 17.22833382], train_hist_grp_loss: [17.55331555 16.33564228 16.39787625], cur_train_grp_loss: [0.17517336 0.16304609 0.16352033], max_reward_err:  0.0777, max_reward_err_index: 0, max_kl_dist:  1.5214, max_kl_dist_index: 0, max_train_grp_loss:  18.3931, max_train_grp_loss_index: 0, max_val_grp_loss:  19.5550, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.1752, max_cur_train_grp_loss_index: 0, 
2024-09-18 13:52:18,967 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:387] - INFO: Policy parameter learned solely on the preference data rdpo: [ 9.47446708  5.77353043 11.63274608  6.3866087 ].
2024-09-18 13:52:19,294 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Uniform reward: 3.9048, 3.9048, 3.2946
2024-09-18 13:52:19,294 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Optimal reward: 3.9454, 3.9454, 3.4341
2024-09-18 13:52:19,295 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Policy reward: 3.6387, 3.9065, 3.3005
2024-09-18 13:52:19,295 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Reward Error: 0.0777, 0.0099, 0.0389
2024-09-18 13:52:19,974 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:416] - INFO: Optimal reward: 3.9454, 3.9454, 3.4341
Known param reward: [[3.945406436920166, 3.5262372493743896, 3.3988354206085205], [3.5262372493743896, 3.945406436920166, 3.223421812057495], [3.903231143951416, 3.661907434463501, 3.434112548828125]], Known param reward error: [[0.0, 0.10624233377410544, 0.010272560295568254], [0.10624233377410544, 0.0, 0.06135230973793422], [0.010689720727903654, 0.07185546203903087, 0.0]].
