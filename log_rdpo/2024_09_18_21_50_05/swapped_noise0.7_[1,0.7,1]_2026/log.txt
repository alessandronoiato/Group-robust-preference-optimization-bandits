2024-09-18 22:17:39,428 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log_rdpo/2024_09_18_21_50_05/swapped_noise0.7_[1,0.7,1]_2026
2024-09-18 22:17:39,430 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2026
2024-09-18 22:17:39,430 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-09-18 22:17:39,593 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.4813, l2 distance: 14.8904, acc: 0.78.
2024-09-18 22:17:39,594 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-18 22:17:39,595 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [7.67816127 4.45673794 7.13735006 4.03215563]
2024-09-18 22:17:39,803 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.5911, 3.8424, 3.2513
2024-09-18 22:17:40,058 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-18 22:17:41,411 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  17.2133, val_loss:  14.6263, grad_norm: 0.1905, live_grad: 0.0000, reward_err: 0.0846, 0.0041, 0.0465, KL_dist: 1.3323, 0.7224, 1.0615, param: [9.97747737 4.86680442 9.42385487 4.79878361], weights: [0.33301233 0.33297485 0.33401281], train_wt_loss:  51.6399, val_wt_loss: 43.8789, train_grp_loss: [19.49983275 14.17207237 17.94090425], val_grp_loss: [18.60380306  7.26531031 17.47697014], train_hist_grp_loss: [0.15681377 0.14555772 0.45679643], cur_train_grp_loss: [0.15681377 0.14555772 0.45679643], max_reward_err:  0.0846, max_reward_err_index: 0, max_kl_dist:  1.3323, max_kl_dist_index: 0, max_train_grp_loss:  19.4998, max_train_grp_loss_index: 0, max_val_grp_loss:  18.6038, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4568, max_cur_train_grp_loss_index: 2, 
2024-09-18 22:17:45,911 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  99, train_loss:  17.2170, val_loss:  14.5739, grad_norm: 0.0093,  live_grad: 0.0000, reward_err: 0.0830, 0.0040, 0.0452, KL_dist: 1.3577, 0.7502, 1.0847, param: [9.88952877 4.99544432 9.79009688 4.9262036 ], weights: [0.30728252 0.30213529 0.39058219], train_wt_loss:  51.6511, val_wt_loss: 43.7218, train_grp_loss: [19.40150745 14.359369   17.79513174], val_grp_loss: [18.50558418  7.33173189 17.35906143], train_hist_grp_loss: [14.11171155 12.42244514 38.09879574], cur_train_grp_loss: [0.14059833 0.12484559 0.37865334], max_reward_err:  0.0830, max_reward_err_index: 0, max_kl_dist:  1.3577, max_kl_dist_index: 0, max_train_grp_loss:  19.4015, max_train_grp_loss_index: 0, max_val_grp_loss:  18.5056, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.3787, max_cur_train_grp_loss_index: 2, 
2024-09-18 22:17:46,139 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:387] - INFO: Policy parameter learned solely on the preference data rdpo: [9.88952877 4.99544432 9.79009688 4.9262036 ].
2024-09-18 22:17:46,474 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Uniform reward: 3.8296, 3.8296, 3.2253
2024-09-18 22:17:46,474 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Optimal reward: 3.8699, 3.8699, 3.3751
2024-09-18 22:17:46,475 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Policy reward: 3.5485, 3.8545, 3.2226
2024-09-18 22:17:46,475 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Reward Error: 0.0830, 0.0040, 0.0452
2024-09-18 22:17:47,177 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:416] - INFO: Optimal reward: 3.8699, 3.8699, 3.3751
Known param reward: [[3.8699047565460205, 3.4682676792144775, 3.3350672721862793], [3.4682676792144775, 3.8699047565460205, 3.164400100708008], [3.831815481185913, 3.603090763092041, 3.375126361846924]], Known param reward error: [[0.0, 0.10378474474137016, 0.011868915520758028], [0.10378474474137016, 0.0, 0.06243507310452317], [0.009842432244793276, 0.06894588116223231, 0.0]].
