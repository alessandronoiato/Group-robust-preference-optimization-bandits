2024-09-18 22:10:13,724 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log_rdpo/2024_09_18_21_50_05/swapped_noise0.9_[1,0.9,1]_2024
2024-09-18 22:10:13,726 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2024
2024-09-18 22:10:13,727 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-09-18 22:10:13,890 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.3578, l2 distance: 26.3512, acc: 0.80.
2024-09-18 22:10:13,891 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-18 22:10:13,892 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [13.34414817  4.47039801 10.55789716  5.99404178]
2024-09-18 22:10:14,097 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.4399, 3.7812, 3.0773
2024-09-18 22:10:14,342 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-18 22:10:15,632 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  13.6589, val_loss:  14.3465, grad_norm: 0.2943, live_grad: 0.0000, reward_err: 0.0959, 0.0001, 0.0576, KL_dist: 1.9528, 1.0615, 1.5760, param: [12.74228289  3.75834346 11.73826257  4.64080856], weights: [0.33302288 0.33283869 0.33413842], train_wt_loss:  40.9767, val_wt_loss: 43.0396, train_grp_loss: [19.95143254  6.88460878 17.57074465], val_grp_loss: [19.49558011  5.89947235 17.18907939], train_hist_grp_loss: [0.18243758 0.12711409 0.5168515 ], cur_train_grp_loss: [0.18243758 0.12711409 0.5168515 ], max_reward_err:  0.0959, max_reward_err_index: 0, max_kl_dist:  1.9528, max_kl_dist_index: 0, max_train_grp_loss:  19.9514, max_train_grp_loss_index: 0, max_val_grp_loss:  19.4956, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.5169, max_cur_train_grp_loss_index: 2, 
2024-09-18 22:10:20,093 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  99, train_loss:  13.6714, val_loss:  14.2769, grad_norm: 0.0198,  live_grad: 0.0000, reward_err: 0.0921, 0.0002, 0.0540, KL_dist: 1.9614, 1.0897, 1.5875, param: [12.40235445  4.04264604 12.2615203   4.9145617 ], weights: [0.31303219 0.27999485 0.40697296], train_wt_loss:  41.0141, val_wt_loss: 42.8307, train_grp_loss: [19.84365858  7.10447747 17.24799135], val_grp_loss: [19.28659333  6.13371792 16.97426075], train_hist_grp_loss: [16.32926717  5.17578539 42.57333832], cur_train_grp_loss: [0.16266188 0.05183805 0.42077143], max_reward_err:  0.0921, max_reward_err_index: 0, max_kl_dist:  1.9614, max_kl_dist_index: 0, max_train_grp_loss:  19.8437, max_train_grp_loss_index: 0, max_val_grp_loss:  19.2866, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4208, max_cur_train_grp_loss_index: 2, 
2024-09-18 22:10:20,314 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:387] - INFO: Policy parameter learned solely on the preference data rdpo: [12.40235445  4.04264604 12.2615203   4.9145617 ].
2024-09-18 22:10:20,641 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Uniform reward: 3.7421, 3.7421, 3.1080
2024-09-18 22:10:20,642 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Optimal reward: 3.7876, 3.7876, 3.2552
2024-09-18 22:10:20,643 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Policy reward: 3.4389, 3.7867, 3.0794
2024-09-18 22:10:20,643 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Reward Error: 0.0921, 0.0002, 0.0540
2024-09-18 22:10:21,324 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:416] - INFO: Optimal reward: 3.7876, 3.7876, 3.2552
Known param reward: [[3.7876079082489014, 3.425462007522583, 3.221684455871582], [3.425462007522583, 3.7876079082489014, 3.069401741027832], [3.755828619003296, 3.553105354309082, 3.2552034854888916]], Known param reward error: [[0.0, 0.09561335531526725, 0.010297061233416388], [0.09561335531526725, 0.0, 0.057078380902862186], [0.008390332372153529, 0.06191310178360972, 0.0]].
