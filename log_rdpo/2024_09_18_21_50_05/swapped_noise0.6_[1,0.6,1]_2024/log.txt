2024-09-18 22:20:19,581 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log_rdpo/2024_09_18_21_50_05/swapped_noise0.6_[1,0.6,1]_2024
2024-09-18 22:20:19,583 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2024
2024-09-18 22:20:19,584 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-09-18 22:20:19,740 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.4614, l2 distance: 14.2156, acc: 0.81.
2024-09-18 22:20:19,740 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-18 22:20:19,741 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [7.12777926 3.69118221 7.29367386 4.24080502]
2024-09-18 22:20:19,941 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.5381, 3.7683, 3.1486
2024-09-18 22:20:20,193 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-18 22:20:21,544 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  16.2059, val_loss:  14.8814, grad_norm: 0.2086, live_grad: 0.0000, reward_err: 0.0805, 0.0033, 0.0454, KL_dist: 1.4301, 0.7803, 1.1487, param: [ 9.00570615  3.95671099 10.89152432  5.3304464 ], weights: [0.33304949 0.33284837 0.33410214], train_wt_loss:  48.6177, val_wt_loss: 44.6441, train_grp_loss: [19.68409627 13.23160731 15.79461328], val_grp_loss: [19.38970417  7.02768425 17.97153387], train_hist_grp_loss: [0.17700651 0.11659973 0.49257111], cur_train_grp_loss: [0.17700651 0.11659973 0.49257111], max_reward_err:  0.0805, max_reward_err_index: 0, max_kl_dist:  1.4301, max_kl_dist_index: 0, max_train_grp_loss:  19.6841, max_train_grp_loss_index: 0, max_val_grp_loss:  19.3897, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4926, max_cur_train_grp_loss_index: 2, 
2024-09-18 22:20:25,991 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  99, train_loss:  16.2120, val_loss:  14.8151, grad_norm: 0.0136,  live_grad: 0.0000, reward_err: 0.0791, 0.0035, 0.0442, KL_dist: 1.4737, 0.8176, 1.1899, param: [ 9.05135288  4.15506727 11.19074245  5.48962464], weights: [0.31363141 0.29432652 0.39204207], train_wt_loss:  48.6361, val_wt_loss: 44.4452, train_grp_loss: [19.54724114 13.42332216 15.60606219], val_grp_loss: [19.26346808  7.10513504 17.82725406], train_hist_grp_loss: [16.09637941  9.74351143 38.41145223], cur_train_grp_loss: [0.16023534 0.09796429 0.38068582], max_reward_err:  0.0791, max_reward_err_index: 0, max_kl_dist:  1.4737, max_kl_dist_index: 0, max_train_grp_loss:  19.5472, max_train_grp_loss_index: 0, max_val_grp_loss:  19.2635, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.3807, max_cur_train_grp_loss_index: 2, 
2024-09-18 22:20:26,210 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:387] - INFO: Policy parameter learned solely on the preference data rdpo: [ 9.05135288  4.15506727 11.19074245  5.48962464].
2024-09-18 22:20:26,533 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Uniform reward: 3.7483, 3.7483, 3.1113
2024-09-18 22:20:26,534 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Optimal reward: 3.7937, 3.7937, 3.2584
2024-09-18 22:20:26,535 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Policy reward: 3.4938, 3.7805, 3.1143
2024-09-18 22:20:26,535 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Reward Error: 0.0791, 0.0035, 0.0442
2024-09-18 22:20:27,210 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:416] - INFO: Optimal reward: 3.7937, 3.7937, 3.2584
Known param reward: [[3.7937493324279785, 3.4302093982696533, 3.224942445755005], [3.4302093982696533, 3.7937493324279785, 3.071303129196167], [3.7626752853393555, 3.56032395362854, 3.2583768367767334]], Known param reward error: [[0.0, 0.09582602916088334, 0.010261057175572927], [0.09582602916088334, 0.0, 0.057413159051800874], [0.008190854051165217, 0.061528940988319736, 0.0]].
