2024-09-18 22:19:20,942 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log_rdpo/2024_09_18_21_50_05/swapped_noise0.6_[1,0.6,1]_2021
2024-09-18 22:19:20,944 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2021
2024-09-18 22:19:20,944 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-09-18 22:19:21,104 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.4881, l2 distance: 12.8925, acc: 0.78.
2024-09-18 22:19:21,105 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-18 22:19:21,106 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [7.49008496 2.76987425 6.30387609 1.756958  ]
2024-09-18 22:19:21,308 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.4326, 3.8265, 3.0841
2024-09-18 22:19:21,577 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-18 22:19:22,907 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  16.7639, val_loss:  15.0545, grad_norm: 0.2916, live_grad: 0.0000, reward_err: 0.1171, 0.0015, 0.0756, KL_dist: 1.6653, 0.7999, 1.3201, param: [11.96573426  3.35066488  9.61307431  2.2347112 ], weights: [0.33301452 0.33309912 0.33388637], train_wt_loss:  50.2917, val_wt_loss: 45.1635, train_grp_loss: [20.2170814  13.24602228 16.92561263], val_grp_loss: [20.76672069  5.83887078 18.78588843], train_hist_grp_loss: [0.1707128  0.19611413 0.43217717], cur_train_grp_loss: [0.1707128  0.19611413 0.43217717], max_reward_err:  0.1171, max_reward_err_index: 0, max_kl_dist:  1.6653, max_kl_dist_index: 0, max_train_grp_loss:  20.2171, max_train_grp_loss_index: 0, max_val_grp_loss:  20.7667, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4322, max_cur_train_grp_loss_index: 2, 
2024-09-18 22:19:27,341 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  99, train_loss:  16.7690, val_loss:  14.9884, grad_norm: 0.0117,  live_grad: 0.0000, reward_err: 0.1176, 0.0011, 0.0764, KL_dist: 1.7039, 0.8266, 1.3570, param: [12.33066137  3.5248893   9.54839351  2.35726868], weights: [0.31838542 0.30175752 0.37985707], train_wt_loss:  50.3070, val_wt_loss: 44.9653, train_grp_loss: [20.08380088 13.45820981 16.75899467], val_grp_loss: [20.66835731  5.84332337 18.67981238], train_hist_grp_loss: [16.13114372 10.76725621 33.78438361], cur_train_grp_loss: [0.16068163 0.10764672 0.33521525], max_reward_err:  0.1176, max_reward_err_index: 0, max_kl_dist:  1.7039, max_kl_dist_index: 0, max_train_grp_loss:  20.0838, max_train_grp_loss_index: 0, max_val_grp_loss:  20.6684, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.3352, max_cur_train_grp_loss_index: 2, 
2024-09-18 22:19:27,564 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:387] - INFO: Policy parameter learned solely on the preference data rdpo: [12.33066137  3.5248893   9.54839351  2.35726868].
2024-09-18 22:19:27,892 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Uniform reward: 3.7957, 3.7957, 3.1631
2024-09-18 22:19:27,893 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Optimal reward: 3.8296, 3.8296, 3.2923
2024-09-18 22:19:27,893 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Policy reward: 3.3791, 3.8252, 3.0407
2024-09-18 22:19:27,894 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Reward Error: 0.1176, 0.0011, 0.0764
2024-09-18 22:19:28,563 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:416] - INFO: Optimal reward: 3.8296, 3.8296, 3.2923
Known param reward: [[3.8295645713806152, 3.440261125564575, 3.2583417892456055], [3.440261125564575, 3.8295645713806152, 3.092778205871582], [3.7937707901000977, 3.5698022842407227, 3.2923295497894287]], Known param reward error: [[0.0, 0.10165736562464864, 0.010323316675876822], [0.10165736562464864, 0.0, 0.0606109871141574], [0.009346697415161585, 0.06783076307974209, 0.0]].
