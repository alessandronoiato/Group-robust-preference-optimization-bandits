2024-09-18 22:22:20,084 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log_rdpo/2024_09_18_21_50_05/swapped_noise0.6_[1,0.6,1]_2030
2024-09-18 22:22:20,086 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2030
2024-09-18 22:22:20,087 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-09-18 22:22:20,244 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.4961, l2 distance: 10.5890, acc: 0.77.
2024-09-18 22:22:20,244 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-18 22:22:20,245 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [5.36923291 3.75606204 5.9084699  3.85520782]
2024-09-18 22:22:20,446 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.5727, 3.7607, 3.2144
2024-09-18 22:22:20,680 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-18 22:22:21,994 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  17.3700, val_loss:  15.8288, grad_norm: 0.2504, live_grad: 0.0000, reward_err: 0.0746, 0.0083, 0.0372, KL_dist: 1.0549, 0.5638, 0.8317, param: [7.94764051 4.49200547 8.75987484 4.93040514], weights: [0.33313868 0.3329211  0.33394022], train_wt_loss:  52.1101, val_wt_loss: 47.4865, train_grp_loss: [20.4526932  14.59045827 18.80713808], val_grp_loss: [20.3785592   8.06822224 18.3878428 ], train_hist_grp_loss: [0.20297176 0.13764008 0.44328466], cur_train_grp_loss: [0.20297176 0.13764008 0.44328466], max_reward_err:  0.0746, max_reward_err_index: 0, max_kl_dist:  1.0549, max_kl_dist_index: 0, max_train_grp_loss:  20.4527, max_train_grp_loss_index: 0, max_val_grp_loss:  20.3786, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4433, max_cur_train_grp_loss_index: 2, 
2024-09-18 22:22:26,520 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  99, train_loss:  17.3781, val_loss:  15.7793, grad_norm: 0.0162,  live_grad: 0.0000, reward_err: 0.0728, 0.0089, 0.0357, KL_dist: 1.0670, 0.5985, 0.8470, param: [8.02078613 4.7607888  8.83308729 5.17626422], weights: [0.3197239  0.29278847 0.38748764], train_wt_loss:  52.1342, val_wt_loss: 47.3378, train_grp_loss: [20.26142384 14.81154092 18.62412983], val_grp_loss: [20.19886904  8.28485308 18.22100771], train_hist_grp_loss: [19.04085207 10.24011208 38.26346698], cur_train_grp_loss: [0.18937837 0.10284006 0.38012516], max_reward_err:  0.0728, max_reward_err_index: 0, max_kl_dist:  1.0670, max_kl_dist_index: 0, max_train_grp_loss:  20.2614, max_train_grp_loss_index: 0, max_val_grp_loss:  20.1989, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.3801, max_cur_train_grp_loss_index: 2, 
2024-09-18 22:22:26,740 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:387] - INFO: Policy parameter learned solely on the preference data rdpo: [8.02078613 4.7607888  8.83308729 5.17626422].
2024-09-18 22:22:27,066 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Uniform reward: 3.7751, 3.7751, 3.1646
2024-09-18 22:22:27,067 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Optimal reward: 3.8138, 3.8138, 3.3081
2024-09-18 22:22:27,068 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Policy reward: 3.5363, 3.7798, 3.1898
2024-09-18 22:22:27,068 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Reward Error: 0.0728, 0.0089, 0.0357
2024-09-18 22:22:27,754 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:416] - INFO: Optimal reward: 3.8138, 3.8138, 3.3081
Known param reward: [[3.8138465881347656, 3.439753770828247, 3.273068904876709], [3.439753770828247, 3.8138465881347656, 3.121405839920044], [3.7787630558013916, 3.5612988471984863, 3.308058500289917]], Known param reward error: [[0.0, 0.09808806113763369, 0.010577078794145125], [0.09808806113763369, 0.0, 0.05642362743993641], [0.009198988874519018, 0.06621864175711184, 0.0]].
