2024-09-18 22:08:13,923 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log_rdpo/2024_09_18_21_50_05/swapped_noise1.0_[1,1.0,1]_2028
2024-09-18 22:08:13,925 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2028
2024-09-18 22:08:13,926 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-09-18 22:08:14,089 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.3651, l2 distance: 26.9971, acc: 0.81.
2024-09-18 22:08:14,089 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-18 22:08:14,090 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [12.46026982  6.25374019 11.11274631  7.09775389]
2024-09-18 22:08:14,302 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.5669, 3.8411, 3.2101
2024-09-18 22:08:14,555 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-18 22:08:15,860 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  14.1809, val_loss:  14.6444, grad_norm: 0.2665, live_grad: 0.0000, reward_err: 0.0910, 0.0018, 0.0511, KL_dist: 1.8079, 1.0315, 1.4748, param: [11.27687639  5.05771448 12.29562599  5.21112383], weights: [0.33317559 0.33298101 0.3338434 ], train_wt_loss:  42.5426, val_wt_loss: 43.9333, train_grp_loss: [20.20595267  6.1447392  16.37069717], val_grp_loss: [19.00998424  7.32656813 16.95432391], train_hist_grp_loss: [0.17534179 0.1169234  0.37557778], cur_train_grp_loss: [0.17534179 0.1169234  0.37557778], max_reward_err:  0.0910, max_reward_err_index: 0, max_kl_dist:  1.8079, max_kl_dist_index: 0, max_train_grp_loss:  20.2060, max_train_grp_loss_index: 0, max_val_grp_loss:  19.0100, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.3756, max_cur_train_grp_loss_index: 2, 
2024-09-18 22:08:20,275 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  99, train_loss:  14.1912, val_loss:  14.6581, grad_norm: 0.0155,  live_grad: 0.0000, reward_err: 0.0888, 0.0024, 0.0492, KL_dist: 1.8104, 1.0636, 1.4823, param: [11.56217081  5.35852526 12.13375879  5.55017693], weights: [0.32814992 0.29751754 0.37433254], train_wt_loss:  42.5737, val_wt_loss: 43.9744, train_grp_loss: [19.96157908  6.5543003  16.17063177], val_grp_loss: [18.7830155   7.79413653 16.79106815], train_hist_grp_loss: [15.47177441  5.67203404 28.63917136], cur_train_grp_loss: [0.15357015 0.05796237 0.28373211], max_reward_err:  0.0888, max_reward_err_index: 0, max_kl_dist:  1.8104, max_kl_dist_index: 0, max_train_grp_loss:  19.9616, max_train_grp_loss_index: 0, max_val_grp_loss:  18.7830, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2837, max_cur_train_grp_loss_index: 2, 
2024-09-18 22:08:20,497 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:387] - INFO: Policy parameter learned solely on the preference data rdpo: [11.56217081  5.35852526 12.13375879  5.55017693].
2024-09-18 22:08:20,827 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Uniform reward: 3.8344, 3.8344, 3.2119
2024-09-18 22:08:20,828 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Optimal reward: 3.8714, 3.8714, 3.3478
2024-09-18 22:08:20,828 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Policy reward: 3.5275, 3.8623, 3.1832
2024-09-18 22:08:20,829 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Reward Error: 0.0888, 0.0024, 0.0492
2024-09-18 22:08:21,514 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:416] - INFO: Optimal reward: 3.8714, 3.8714, 3.3478
Known param reward: [[3.8714330196380615, 3.4622552394866943, 3.31345272064209], [3.4622552394866943, 3.8714330196380615, 3.1356377601623535], [3.8367903232574463, 3.6059677600860596, 3.34783935546875]], Known param reward error: [[0.0, 0.10569155609196644, 0.010271291772255747], [0.10569155609196644, 0.0, 0.06338464089077683], [0.008948287676653118, 0.06857028345974592, 0.0]].
