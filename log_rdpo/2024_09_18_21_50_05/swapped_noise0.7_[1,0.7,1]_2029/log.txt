2024-09-18 22:18:40,248 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log_rdpo/2024_09_18_21_50_05/swapped_noise0.7_[1,0.7,1]_2029
2024-09-18 22:18:40,250 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2029
2024-09-18 22:18:40,251 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-09-18 22:18:40,415 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.4360, l2 distance: 17.6893, acc: 0.78.
2024-09-18 22:18:40,416 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-18 22:18:40,417 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [8.45198418 4.08444303 9.00463429 3.74875698]
2024-09-18 22:18:40,624 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.5361, 3.8741, 3.2061
2024-09-18 22:18:40,889 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-18 22:18:42,252 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  15.5847, val_loss:  15.0668, grad_norm: 0.2618, live_grad: 0.0000, reward_err: 0.1044, 0.0001, 0.0609, KL_dist: 1.7445, 0.8650, 1.4002, param: [10.13807846  4.22380206 12.11796393  3.52534785], weights: [0.33297622 0.33280623 0.33421755], train_wt_loss:  46.7542, val_wt_loss: 45.2005, train_grp_loss: [21.27217909  8.762941   19.32013025], val_grp_loss: [20.04988697  5.44047175 18.69020423], train_hist_grp_loss: [0.17864523 0.12757943 0.55074922], cur_train_grp_loss: [0.17864523 0.12757943 0.55074922], max_reward_err:  0.1044, max_reward_err_index: 0, max_kl_dist:  1.7445, max_kl_dist_index: 0, max_train_grp_loss:  21.2722, max_train_grp_loss_index: 0, max_val_grp_loss:  20.0499, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.5507, max_cur_train_grp_loss_index: 2, 
2024-09-18 22:18:46,753 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  99, train_loss:  15.6001, val_loss:  15.0019, grad_norm: 0.0232,  live_grad: 0.0000, reward_err: 0.1005, 0.0005, 0.0578, KL_dist: 1.7480, 0.8819, 1.4117, param: [ 9.89596481  4.59848751 12.39186688  3.86805204], weights: [0.30624963 0.27854329 0.41520708], train_wt_loss:  46.8002, val_wt_loss: 45.0058, train_grp_loss: [21.02880998  9.1354023  19.01716793], val_grp_loss: [19.8130647   5.71836973 18.49041477], train_hist_grp_loss: [16.41461427  6.93190932 46.85229786], cur_train_grp_loss: [0.16303512 0.0702373  0.46391585], max_reward_err:  0.1005, max_reward_err_index: 0, max_kl_dist:  1.7480, max_kl_dist_index: 0, max_train_grp_loss:  21.0288, max_train_grp_loss_index: 0, max_val_grp_loss:  19.8131, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4639, max_cur_train_grp_loss_index: 2, 
2024-09-18 22:18:46,978 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:387] - INFO: Policy parameter learned solely on the preference data rdpo: [ 9.89596481  4.59848751 12.39186688  3.86805204].
2024-09-18 22:18:47,309 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Uniform reward: 3.8387, 3.8387, 3.2243
2024-09-18 22:18:47,310 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Optimal reward: 3.8841, 3.8841, 3.3675
2024-09-18 22:18:47,310 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Policy reward: 3.4938, 3.8820, 3.1730
2024-09-18 22:18:47,311 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Reward Error: 0.1005, 0.0005, 0.0578
2024-09-18 22:18:47,998 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:416] - INFO: Optimal reward: 3.8841, 3.8841, 3.3675
Known param reward: [[3.884077310562134, 3.4758739471435547, 3.3304951190948486], [3.4758739471435547, 3.884077310562134, 3.1624059677124023], [3.847635269165039, 3.6067681312561035, 3.3674604892730713]], Known param reward error: [[0.0, 0.10509661131320291, 0.010977224616584088], [0.10509661131320291, 0.0, 0.060892925756326766], [0.009382419165034734, 0.07139641081600817, 0.0]].
