2024-09-18 22:18:00,185 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log_rdpo/2024_09_18_21_50_05/swapped_noise0.7_[1,0.7,1]_2027
2024-09-18 22:18:00,187 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2027
2024-09-18 22:18:00,187 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-09-18 22:18:00,349 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.4740, l2 distance: 14.0690, acc: 0.80.
2024-09-18 22:18:00,350 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-18 22:18:00,351 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [8.04817029 4.05673083 5.77693217 4.47787971]
2024-09-18 22:18:00,554 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.5225, 3.7577, 3.1520
2024-09-18 22:18:00,810 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-18 22:18:02,113 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  16.8293, val_loss:  14.5842, grad_norm: 0.2424, live_grad: 0.0000, reward_err: 0.0793, 0.0055, 0.0438, KL_dist: 1.3408, 0.7162, 1.0838, param: [10.7459885   4.71003168  8.28364489  4.95603614], weights: [0.33319784 0.333091   0.33371115], train_wt_loss:  50.4879, val_wt_loss: 43.7526, train_grp_loss: [19.75382672 14.04526351 15.91518129], val_grp_loss: [19.50620902  7.31893787 17.11072239], train_hist_grp_loss: [0.17912995 0.14706004 0.33306683], cur_train_grp_loss: [0.17912995 0.14706004 0.33306683], max_reward_err:  0.0793, max_reward_err_index: 0, max_kl_dist:  1.3408, max_kl_dist_index: 0, max_train_grp_loss:  19.7538, max_train_grp_loss_index: 0, max_val_grp_loss:  19.5062, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.3331, max_cur_train_grp_loss_index: 2, 
2024-09-18 22:18:06,548 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  99, train_loss:  16.8323, val_loss:  14.5331, grad_norm: 0.0078,  live_grad: 0.0000, reward_err: 0.0763, 0.0055, 0.0410, KL_dist: 1.3525, 0.7388, 1.0935, param: [10.63793422  4.82802935  8.62274011  5.04085743], weights: [0.32528286 0.31551716 0.35919998], train_wt_loss:  50.4969, val_wt_loss: 43.5993, train_grp_loss: [19.70556316 14.21061328 15.72903483], val_grp_loss: [19.41843272  7.3682855  16.99321072], train_hist_grp_loss: [15.68122279 12.63301331 25.59963562], cur_train_grp_loss: [0.15639722 0.12686471 0.25372486], max_reward_err:  0.0763, max_reward_err_index: 0, max_kl_dist:  1.3525, max_kl_dist_index: 0, max_train_grp_loss:  19.7056, max_train_grp_loss_index: 0, max_val_grp_loss:  19.4184, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2537, max_cur_train_grp_loss_index: 2, 
2024-09-18 22:18:06,769 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:387] - INFO: Policy parameter learned solely on the preference data rdpo: [10.63793422  4.82802935  8.62274011  5.04085743].
2024-09-18 22:18:07,098 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Uniform reward: 3.7599, 3.7599, 3.1348
2024-09-18 22:18:07,098 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Optimal reward: 3.8017, 3.8017, 3.2811
2024-09-18 22:18:07,099 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Policy reward: 3.5116, 3.7807, 3.1466
2024-09-18 22:18:07,099 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Reward Error: 0.0763, 0.0055, 0.0410
2024-09-18 22:18:07,784 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:416] - INFO: Optimal reward: 3.8017, 3.8017, 3.2811
Known param reward: [[3.8016552925109863, 3.4387340545654297, 3.238321304321289], [3.4387340545654297, 3.8016552925109863, 3.0975143909454346], [3.7612709999084473, 3.561779260635376, 3.281050205230713]], Known param reward error: [[0.0, 0.0954640044983794, 0.013022934193845799], [0.0954640044983794, 0.0, 0.055938130417109135], [0.010622818087187834, 0.06309778594291558, 0.0]].
