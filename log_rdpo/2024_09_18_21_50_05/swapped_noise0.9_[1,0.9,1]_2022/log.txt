2024-09-18 22:09:33,589 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log_rdpo/2024_09_18_21_50_05/swapped_noise0.9_[1,0.9,1]_2022
2024-09-18 22:09:33,591 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2022
2024-09-18 22:09:33,592 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-09-18 22:09:33,754 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.3535, l2 distance: 28.4868, acc: 0.85.
2024-09-18 22:09:33,755 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-18 22:09:33,756 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [12.5384091   6.91815982 12.54481599  6.12893569]
2024-09-18 22:09:33,965 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.5601, 3.8531, 3.1999
2024-09-18 22:09:34,216 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-18 22:09:35,573 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  13.8276, val_loss:  14.0473, grad_norm: 0.3075, live_grad: 0.0000, reward_err: 0.0960, 0.0008, 0.0540, KL_dist: 1.8804, 1.0321, 1.5331, param: [12.69620374  5.4020049  11.11686669  4.03135654], weights: [0.333068   0.33289748 0.33403452], train_wt_loss:  41.4827, val_wt_loss: 42.1420, train_grp_loss: [19.98563402  6.85203006 16.72639016], val_grp_loss: [19.37056704  6.46286412 16.90535167], train_hist_grp_loss: [0.18353414 0.13232229 0.47330093], cur_train_grp_loss: [0.18353414 0.13232229 0.47330093], max_reward_err:  0.0960, max_reward_err_index: 0, max_kl_dist:  1.8804, max_kl_dist_index: 0, max_train_grp_loss:  19.9856, max_train_grp_loss_index: 0, max_val_grp_loss:  19.3706, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4733, max_cur_train_grp_loss_index: 2, 
2024-09-18 22:09:40,022 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  99, train_loss:  13.8377, val_loss:  14.0423, grad_norm: 0.0169,  live_grad: 0.0000, reward_err: 0.0931, 0.0010, 0.0520, KL_dist: 1.9103, 1.0642, 1.5662, param: [13.07980983  5.69400978 10.92886431  4.29311606], weights: [0.3212682  0.28891416 0.38981763], train_wt_loss:  41.5132, val_wt_loss: 42.1268, train_grp_loss: [19.86156015  7.09278228 16.45786296], val_grp_loss: [19.17143593  6.81326117 16.71311715], train_hist_grp_loss: [16.09186872  5.47720079 35.43214085], cur_train_grp_loss: [0.16018465 0.0549607  0.35022899], max_reward_err:  0.0931, max_reward_err_index: 0, max_kl_dist:  1.9103, max_kl_dist_index: 0, max_train_grp_loss:  19.8616, max_train_grp_loss_index: 0, max_val_grp_loss:  19.1714, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.3502, max_cur_train_grp_loss_index: 2, 
2024-09-18 22:09:40,243 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:387] - INFO: Policy parameter learned solely on the preference data rdpo: [13.07980983  5.69400978 10.92886431  4.29311606].
2024-09-18 22:09:40,570 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Uniform reward: 3.8376, 3.8376, 3.2077
2024-09-18 22:09:40,571 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Optimal reward: 3.8707, 3.8707, 3.3351
2024-09-18 22:09:40,571 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Policy reward: 3.5102, 3.8667, 3.1618
2024-09-18 22:09:40,572 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Reward Error: 0.0931, 0.0010, 0.0520
2024-09-18 22:09:41,257 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:416] - INFO: Optimal reward: 3.8707, 3.8707, 3.3351
Known param reward: [[3.870741367340088, 3.47579288482666, 3.3037049770355225], [3.47579288482666, 3.870741367340088, 3.1393208503723145], [3.836113214492798, 3.5835537910461426, 3.3351211547851562]], Known param reward error: [[0.0, 0.10203432496055144, 0.009419801048174388], [0.10203432496055144, 0.0, 0.05870860317380433], [0.008946129322788094, 0.07419446277582117, 0.0]].
