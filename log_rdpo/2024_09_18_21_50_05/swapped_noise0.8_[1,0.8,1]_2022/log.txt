2024-09-18 22:12:49,248 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log_rdpo/2024_09_18_21_50_05/swapped_noise0.8_[1,0.8,1]_2022
2024-09-18 22:12:49,250 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2022
2024-09-18 22:12:49,251 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-09-18 22:12:49,415 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.4465, l2 distance: 17.2654, acc: 0.79.
2024-09-18 22:12:49,416 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-18 22:12:49,416 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [7.73322927 5.13439292 8.93418526 3.72803641]
2024-09-18 22:12:49,620 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.5959, 3.8329, 3.2039
2024-09-18 22:12:49,877 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-18 22:12:51,215 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  16.0317, val_loss:  13.7626, grad_norm: 0.2638, live_grad: 0.0000, reward_err: 0.0731, 0.0034, 0.0380, KL_dist: 1.4795, 0.8301, 1.2026, param: [10.16716003  5.32766621 10.75259767  4.00819465], weights: [0.33304936 0.33290506 0.33404558], train_wt_loss:  48.0950, val_wt_loss: 41.2879, train_grp_loss: [21.69088704  9.55509805 18.87710743], val_grp_loss: [18.9625201   6.13079778 17.12001778], train_hist_grp_loss: [0.18557105 0.14223385 0.48424335], cur_train_grp_loss: [0.18557105 0.14223385 0.48424335], max_reward_err:  0.0731, max_reward_err_index: 0, max_kl_dist:  1.4795, max_kl_dist_index: 0, max_train_grp_loss:  21.6909, max_train_grp_loss_index: 0, max_val_grp_loss:  18.9625, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4842, max_cur_train_grp_loss_index: 2, 
2024-09-18 22:12:55,688 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  99, train_loss:  16.0402, val_loss:  13.7420, grad_norm: 0.0174,  live_grad: 0.0000, reward_err: 0.0713, 0.0042, 0.0365, KL_dist: 1.4869, 0.8573, 1.2142, param: [10.29705051  5.58905726 10.71486738  4.27119468], weights: [0.31644146 0.28668612 0.39687242], train_wt_loss:  48.1206, val_wt_loss: 41.2259, train_grp_loss: [21.51958399  9.79789293 18.71701572], val_grp_loss: [18.77829111  6.38517297 16.95474052], train_hist_grp_loss: [17.43739066  7.56235847 40.08505204], cur_train_grp_loss: [0.1735601  0.07593038 0.39827208], max_reward_err:  0.0713, max_reward_err_index: 0, max_kl_dist:  1.4869, max_kl_dist_index: 0, max_train_grp_loss:  21.5196, max_train_grp_loss_index: 0, max_val_grp_loss:  18.7783, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.3983, max_cur_train_grp_loss_index: 2, 
2024-09-18 22:12:55,910 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:387] - INFO: Policy parameter learned solely on the preference data rdpo: [10.29705051  5.58905726 10.71486738  4.27119468].
2024-09-18 22:12:56,238 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Uniform reward: 3.8267, 3.8267, 3.1836
2024-09-18 22:12:56,238 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Optimal reward: 3.8586, 3.8586, 3.3169
2024-09-18 22:12:56,239 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Policy reward: 3.5834, 3.8424, 3.1959
2024-09-18 22:12:56,239 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Reward Error: 0.0713, 0.0042, 0.0365
2024-09-18 22:12:56,922 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:416] - INFO: Optimal reward: 3.8586, 3.8586, 3.3169
Known param reward: [[3.8586065769195557, 3.531782627105713, 3.266848564147949], [3.531782627105713, 3.8586065769195557, 3.1579184532165527], [3.8154232501983643, 3.627133369445801, 3.3168587684631348]], Known param reward error: [[0.0, 0.08469999293754285, 0.015077580266813035], [0.08469999293754285, 0.0, 0.04791892761844273], [0.011191430341588746, 0.05998880758103799, 0.0]].
