2024-09-18 22:18:19,416 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log_rdpo/2024_09_18_21_50_05/swapped_noise0.7_[1,0.7,1]_2028
2024-09-18 22:18:19,418 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2028
2024-09-18 22:18:19,419 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-09-18 22:18:19,580 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.4872, l2 distance: 13.0978, acc: 0.77.
2024-09-18 22:18:19,580 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-18 22:18:19,581 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [6.46691538 3.95756071 6.43337544 5.0747662 ]
2024-09-18 22:18:19,791 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.6532, 3.8141, 3.2658
2024-09-18 22:18:20,049 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-18 22:18:21,372 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  17.3920, val_loss:  15.4514, grad_norm: 0.3157, live_grad: 0.0000, reward_err: 0.0668, 0.0123, 0.0328, KL_dist: 1.0578, 0.6843, 0.8558, param: [7.86526872 4.57604731 9.07256169 6.17415474], weights: [0.33304661 0.33315312 0.33380027], train_wt_loss:  52.1759, val_wt_loss: 46.3542, train_grp_loss: [20.8437049  13.38790755 17.45743647], val_grp_loss: [18.9007719   9.30834047 17.36619607], train_hist_grp_loss: [0.17723622 0.20921197 0.40327243], cur_train_grp_loss: [0.17723622 0.20921197 0.40327243], max_reward_err:  0.0668, max_reward_err_index: 0, max_kl_dist:  1.0578, max_kl_dist_index: 0, max_train_grp_loss:  20.8437, max_train_grp_loss_index: 0, max_val_grp_loss:  18.9008, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4033, max_cur_train_grp_loss_index: 2, 
2024-09-18 22:18:25,837 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  99, train_loss:  17.3957, val_loss:  15.4267, grad_norm: 0.0104,  live_grad: 0.0000, reward_err: 0.0659, 0.0137, 0.0320, KL_dist: 1.0705, 0.7106, 0.8699, param: [8.00069227 4.75878056 9.08133304 6.33197333], weights: [0.3206762  0.30820442 0.37111938], train_wt_loss:  52.1871, val_wt_loss: 46.2800, train_grp_loss: [20.71289996 13.61583866 17.32361029], val_grp_loss: [18.76811736  9.51133686 17.24907943], train_hist_grp_loss: [16.00163281 12.03477068 30.6108236 ], cur_train_grp_loss: [0.15934042 0.12047221 0.30394779], max_reward_err:  0.0659, max_reward_err_index: 0, max_kl_dist:  1.0705, max_kl_dist_index: 0, max_train_grp_loss:  20.7129, max_train_grp_loss_index: 0, max_val_grp_loss:  18.7681, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.3039, max_cur_train_grp_loss_index: 2, 
2024-09-18 22:18:26,060 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:387] - INFO: Policy parameter learned solely on the preference data rdpo: [8.00069227 4.75878056 9.08133304 6.33197333].
2024-09-18 22:18:26,387 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Uniform reward: 3.8371, 3.8371, 3.2123
2024-09-18 22:18:26,388 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Optimal reward: 3.8741, 3.8741, 3.3487
2024-09-18 22:18:26,388 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Policy reward: 3.6190, 3.8212, 3.2416
2024-09-18 22:18:26,389 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Reward Error: 0.0659, 0.0137, 0.0320
2024-09-18 22:18:27,066 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:416] - INFO: Optimal reward: 3.8741, 3.8741, 3.3487
Known param reward: [[3.8741343021392822, 3.4676833152770996, 3.31387996673584], [3.4676833152770996, 3.8741343021392822, 3.1369452476501465], [3.840017557144165, 3.611396074295044, 3.3486669063568115]], Known param reward error: [[0.0, 0.10491401566480076, 0.010388294982380973], [0.10491401566480076, 0.0, 0.0632256550523886], [0.008806288665903515, 0.06781856470467615, 0.0]].
