2024-09-18 22:12:08,643 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log_rdpo/2024_09_18_21_50_05/swapped_noise0.9_[1,0.9,1]_2030
2024-09-18 22:12:08,645 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2030
2024-09-18 22:12:08,646 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-09-18 22:12:08,809 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.4282, l2 distance: 17.0495, acc: 0.80.
2024-09-18 22:12:08,809 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-18 22:12:08,810 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [7.37774022 3.69856674 9.52307453 3.50330935]
2024-09-18 22:12:09,016 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.4683, 3.8639, 3.1679
2024-09-18 22:12:09,266 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-18 22:12:10,600 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  15.1869, val_loss:  15.2662, grad_norm: 0.3004, live_grad: 0.0000, reward_err: 0.1119, 0.0001, 0.0685, KL_dist: 1.7566, 0.7799, 1.3916, param: [ 9.40893534  3.4215963  11.9308176   3.84361335], weights: [0.33317318 0.33285047 0.33397636], train_wt_loss:  45.5608, val_wt_loss: 45.7985, train_grp_loss: [20.81809581  9.41030686 19.86644373], val_grp_loss: [20.78236935  5.68985987 18.66325074], train_hist_grp_loss: [0.21800882 0.12110253 0.4587879 ], cur_train_grp_loss: [0.21800882 0.12110253 0.4587879 ], max_reward_err:  0.1119, max_reward_err_index: 0, max_kl_dist:  1.7566, max_kl_dist_index: 0, max_train_grp_loss:  20.8181, max_train_grp_loss_index: 0, max_val_grp_loss:  20.7824, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4588, max_cur_train_grp_loss_index: 2, 
2024-09-18 22:12:15,029 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  99, train_loss:  15.2004, val_loss:  15.1789, grad_norm: 0.0224,  live_grad: 0.0000, reward_err: 0.1064, 0.0003, 0.0635, KL_dist: 1.7398, 0.7999, 1.3806, param: [ 9.70214694  3.69398389 11.7453581   4.18418155], weights: [0.32116486 0.28281811 0.39601703], train_wt_loss:  45.6011, val_wt_loss: 45.5368, train_grp_loss: [20.61781601  9.67707397 19.60224043], val_grp_loss: [20.56398118  5.86947491 18.45651897], train_hist_grp_loss: [19.39062283  6.67556038 40.34088523], cur_train_grp_loss: [0.19271048 0.06717939 0.40010506], max_reward_err:  0.1064, max_reward_err_index: 0, max_kl_dist:  1.7398, max_kl_dist_index: 0, max_train_grp_loss:  20.6178, max_train_grp_loss_index: 0, max_val_grp_loss:  20.5640, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4001, max_cur_train_grp_loss_index: 2, 
2024-09-18 22:12:15,250 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:387] - INFO: Policy parameter learned solely on the preference data rdpo: [ 9.70214694  3.69398389 11.7453581   4.18418155].
2024-09-18 22:12:15,580 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Uniform reward: 3.8277, 3.8277, 3.2194
2024-09-18 22:12:15,581 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Optimal reward: 3.8721, 3.8721, 3.3771
2024-09-18 22:12:15,582 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Policy reward: 3.4601, 3.8711, 3.1627
2024-09-18 22:12:15,582 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Reward Error: 0.1064, 0.0003, 0.0635
2024-09-18 22:12:16,256 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:416] - INFO: Optimal reward: 3.8721, 3.8721, 3.3771
Known param reward: [[3.8721461296081543, 3.473419189453125, 3.3377835750579834], [3.473419189453125, 3.8721461296081543, 3.1756153106689453], [3.834397315979004, 3.592139482498169, 3.377051591873169]], Known param reward error: [[0.0, 0.10297311279297687, 0.01162789958841124], [0.10297311279297687, 0.0, 0.05964856494611378], [0.00974880915276057, 0.07231303719891401, 0.0]].
