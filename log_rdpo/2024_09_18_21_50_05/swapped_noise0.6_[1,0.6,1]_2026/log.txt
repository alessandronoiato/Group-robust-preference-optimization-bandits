2024-09-18 22:20:59,557 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log_rdpo/2024_09_18_21_50_05/swapped_noise0.6_[1,0.6,1]_2026
2024-09-18 22:20:59,559 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2026
2024-09-18 22:20:59,560 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-09-18 22:20:59,718 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.4897, l2 distance: 13.8904, acc: 0.75.
2024-09-18 22:20:59,719 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-18 22:20:59,719 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [7.98825619 2.69900213 6.4400013  3.59401665]
2024-09-18 22:20:59,924 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.4928, 3.8618, 3.1795
2024-09-18 22:21:00,173 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-18 22:21:01,489 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  17.0466, val_loss:  15.0650, grad_norm: 0.2213, live_grad: 0.0000, reward_err: 0.1018, 0.0004, 0.0616, KL_dist: 1.6755, 0.8264, 1.3388, param: [12.02466149  3.46270334  9.78929666  4.5263621 ], weights: [0.33297686 0.33300255 0.3340206 ], train_wt_loss:  51.1398, val_wt_loss: 45.1949, train_grp_loss: [20.61562312 12.23435932 18.34206054], val_grp_loss: [20.22888987  6.04892171 17.78273188], train_hist_grp_loss: [0.16019724 0.1679114  0.4731636 ], cur_train_grp_loss: [0.16019724 0.1679114  0.4731636 ], max_reward_err:  0.1018, max_reward_err_index: 0, max_kl_dist:  1.6755, max_kl_dist_index: 0, max_train_grp_loss:  20.6156, max_train_grp_loss_index: 0, max_val_grp_loss:  20.2289, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4732, max_cur_train_grp_loss_index: 2, 
2024-09-18 22:21:05,918 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  99, train_loss:  17.0540, val_loss:  15.0259, grad_norm: 0.0131,  live_grad: 0.0000, reward_err: 0.1005, 0.0006, 0.0599, KL_dist: 1.6678, 0.8485, 1.3317, param: [11.67604809  3.61959673 10.33127506  4.71705423], weights: [0.30953833 0.29713242 0.39332925], train_wt_loss:  51.1619, val_wt_loss: 45.0776, train_grp_loss: [20.48384708 12.51087005 18.09937753], val_grp_loss: [20.10826446  6.16677598 17.6877462 ], train_hist_grp_loss: [14.90360702 10.81320431 38.86011922], cur_train_grp_loss: [0.14844377 0.10876292 0.38514804], max_reward_err:  0.1005, max_reward_err_index: 0, max_kl_dist:  1.6678, max_kl_dist_index: 0, max_train_grp_loss:  20.4838, max_train_grp_loss_index: 0, max_val_grp_loss:  20.1083, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.3851, max_cur_train_grp_loss_index: 2, 
2024-09-18 22:21:06,138 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:387] - INFO: Policy parameter learned solely on the preference data rdpo: [11.67604809  3.61959673 10.33127506  4.71705423].
2024-09-18 22:21:06,461 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Uniform reward: 3.8294, 3.8294, 3.2249
2024-09-18 22:21:06,462 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Optimal reward: 3.8697, 3.8697, 3.3747
2024-09-18 22:21:06,462 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Policy reward: 3.4808, 3.8673, 3.1724
2024-09-18 22:21:06,463 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Reward Error: 0.1005, 0.0006, 0.0599
2024-09-18 22:21:07,132 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:416] - INFO: Optimal reward: 3.8697, 3.8697, 3.3747
Known param reward: [[3.869661331176758, 3.4677367210388184, 3.334665060043335], [3.4677367210388184, 3.869661331176758, 3.163583993911743], [3.832443952560425, 3.602559804916382, 3.3746607303619385]], Known param reward error: [[0.0, 0.1038655778219524, 0.011851760373646185], [0.1038655778219524, 0.0, 0.06254754279478546], [0.00961773536006451, 0.06902452266517878, 0.0]].
