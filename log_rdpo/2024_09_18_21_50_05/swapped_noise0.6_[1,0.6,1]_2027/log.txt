2024-09-18 22:21:19,224 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log_rdpo/2024_09_18_21_50_05/swapped_noise0.6_[1,0.6,1]_2027
2024-09-18 22:21:19,226 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2027
2024-09-18 22:21:19,226 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-09-18 22:21:19,384 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.4811, l2 distance: 13.0261, acc: 0.81.
2024-09-18 22:21:19,385 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-18 22:21:19,386 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [6.28961974 4.34750067 6.93739929 3.90022049]
2024-09-18 22:21:19,590 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.5598, 3.7478, 3.1749
2024-09-18 22:21:19,840 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-18 22:21:21,142 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  17.0056, val_loss:  14.7113, grad_norm: 0.1994, live_grad: 0.0000, reward_err: 0.0775, 0.0051, 0.0412, KL_dist: 1.2774, 0.6937, 1.0247, param: [8.94842134 4.98464457 9.82843764 4.5317189 ], weights: [0.33315261 0.33315917 0.33368822], train_wt_loss:  51.0167, val_wt_loss: 44.1339, train_grp_loss: [20.06342922 14.41195552 15.47642496], val_grp_loss: [19.84291648  7.11059778 17.34864782], train_hist_grp_loss: [0.16674378 0.16871138 0.32738426], cur_train_grp_loss: [0.16674378 0.16871138 0.32738426], max_reward_err:  0.0775, max_reward_err_index: 0, max_kl_dist:  1.2774, max_kl_dist_index: 0, max_train_grp_loss:  20.0634, max_train_grp_loss_index: 0, max_val_grp_loss:  19.8429, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.3274, max_cur_train_grp_loss_index: 2, 
2024-09-18 22:21:25,600 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  99, train_loss:  17.0075, val_loss:  14.6698, grad_norm: 0.0067,  live_grad: 0.0000, reward_err: 0.0771, 0.0051, 0.0409, KL_dist: 1.3002, 0.7149, 1.0460, param: [8.99912412 5.07691032 9.98034743 4.64282444], weights: [0.3261767 0.3167533 0.35707  ], train_wt_loss:  51.0225, val_wt_loss: 44.0093, train_grp_loss: [19.9914804  14.55980315 15.36489164], val_grp_loss: [19.76729472  7.15963707 17.24880061], train_hist_grp_loss: [15.90300966 12.97140692 24.952268  ], cur_train_grp_loss: [0.15866838 0.12998422 0.24783941], max_reward_err:  0.0771, max_reward_err_index: 0, max_kl_dist:  1.3002, max_kl_dist_index: 0, max_train_grp_loss:  19.9915, max_train_grp_loss_index: 0, max_val_grp_loss:  19.7673, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2478, max_cur_train_grp_loss_index: 2, 
2024-09-18 22:21:25,818 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:387] - INFO: Policy parameter learned solely on the preference data rdpo: [8.99912412 5.07691032 9.98034743 4.64282444].
2024-09-18 22:21:26,145 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Uniform reward: 3.7506, 3.7506, 3.1231
2024-09-18 22:21:26,145 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Optimal reward: 3.7912, 3.7912, 3.2668
2024-09-18 22:21:26,146 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Policy reward: 3.4989, 3.7719, 3.1333
2024-09-18 22:21:26,146 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Reward Error: 0.0771, 0.0051, 0.0409
2024-09-18 22:21:26,818 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:416] - INFO: Optimal reward: 3.7912, 3.7912, 3.2668
Known param reward: [[3.791201591491699, 3.43137788772583, 3.2245421409606934], [3.43137788772583, 3.791201591491699, 3.0854053497314453], [3.751282215118408, 3.552793025970459, 3.2667675018310547]], Known param reward error: [[0.0, 0.0949102006533743, 0.012925731888386182], [0.0949102006533743, 0.0, 0.055517312449678204], [0.010529478691631431, 0.06288469757352977, 0.0]].
