2024-09-18 22:19:59,861 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log_rdpo/2024_09_18_21_50_05/swapped_noise0.6_[1,0.6,1]_2023
2024-09-18 22:19:59,863 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2023
2024-09-18 22:19:59,863 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-09-18 22:20:00,020 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.4901, l2 distance: 13.7110, acc: 0.77.
2024-09-18 22:20:00,021 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-18 22:20:00,022 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [8.67865662 2.73331006 5.03288862 3.70226044]
2024-09-18 22:20:00,227 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.4786, 3.8485, 3.0931
2024-09-18 22:20:00,479 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-18 22:20:01,824 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  17.1330, val_loss:  15.4328, grad_norm: 0.1997, live_grad: 0.0000, reward_err: 0.1066, 0.0015, 0.0705, KL_dist: 1.6893, 0.7319, 1.4125, param: [13.60835552  3.63087451  6.31533188  4.24782206], weights: [0.33308658 0.33301085 0.33390256], train_wt_loss:  51.3989, val_wt_loss: 46.2983, train_grp_loss: [20.01242431 13.70678801 17.78760314], val_grp_loss: [21.01366548  6.26376239 19.21790817], train_hist_grp_loss: [0.16837282 0.14563467 0.41304791], cur_train_grp_loss: [0.16837282 0.14563467 0.41304791], max_reward_err:  0.1066, max_reward_err_index: 0, max_kl_dist:  1.6893, max_kl_dist_index: 0, max_train_grp_loss:  20.0124, max_train_grp_loss_index: 0, max_val_grp_loss:  21.0137, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4130, max_cur_train_grp_loss_index: 2, 
2024-09-18 22:20:06,288 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  99, train_loss:  17.1397, val_loss:  15.3306, grad_norm: 0.0121,  live_grad: 0.0000, reward_err: 0.1037, 0.0016, 0.0672, KL_dist: 1.6606, 0.7596, 1.3835, param: [13.40168598  3.80125267  6.8039704   4.43935874], weights: [0.31480192 0.30330073 0.38189735], train_wt_loss:  51.4191, val_wt_loss: 45.9918, train_grp_loss: [19.90576923 13.9545806  17.52090012], val_grp_loss: [20.87916264  6.26560402 19.04464595], train_hist_grp_loss: [15.3688989  11.64701703 34.6897213 ], cur_train_grp_loss: [0.15312989 0.11724199 0.3436023 ], max_reward_err:  0.1037, max_reward_err_index: 0, max_kl_dist:  1.6606, max_kl_dist_index: 0, max_train_grp_loss:  19.9058, max_train_grp_loss_index: 0, max_val_grp_loss:  20.8792, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.3436, max_cur_train_grp_loss_index: 2, 
2024-09-18 22:20:06,510 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:387] - INFO: Policy parameter learned solely on the preference data rdpo: [13.40168598  3.80125267  6.8039704   4.43935874].
2024-09-18 22:20:06,833 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Uniform reward: 3.8219, 3.8219, 3.1727
2024-09-18 22:20:06,834 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Optimal reward: 3.8605, 3.8605, 3.2988
2024-09-18 22:20:06,834 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Policy reward: 3.4602, 3.8544, 3.0770
2024-09-18 22:20:06,835 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Reward Error: 0.1037, 0.0016, 0.0672
2024-09-18 22:20:07,516 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:416] - INFO: Optimal reward: 3.8605, 3.8605, 3.2988
Known param reward: [[3.8605411052703857, 3.4837193489074707, 3.270322322845459], [3.4837193489074707, 3.8605411052703857, 3.110097646713257], [3.825101613998413, 3.5993566513061523, 3.298776388168335]], Known param reward error: [[0.0, 0.09760853364531734, 0.008625642351791921], [0.09760853364531734, 0.0, 0.05719658420370927], [0.009179928488156982, 0.06765488226706512, 0.0]].
