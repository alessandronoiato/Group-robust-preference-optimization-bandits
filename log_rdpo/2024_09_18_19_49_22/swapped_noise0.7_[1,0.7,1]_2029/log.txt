2024-09-18 20:19:01,218 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log_rdpo/2024_09_18_19_49_22/swapped_noise0.7_[1,0.7,1]_2029
2024-09-18 20:19:01,220 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2029
2024-09-18 20:19:01,220 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-09-18 20:19:01,380 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.4360, l2 distance: 17.6893, acc: 0.78.
2024-09-18 20:19:01,380 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-18 20:19:01,381 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [8.45198418 4.08444303 9.00463429 3.74875698]
2024-09-18 20:19:01,583 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.5361, 3.8741, 3.2061
2024-09-18 20:19:01,844 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-18 20:19:03,162 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  15.5847, val_loss:  16.6979, grad_norm: 0.2942, live_grad: 0.0000, reward_err: 0.1044, 0.0001, 0.0609, KL_dist: 1.7445, 0.8650, 1.4002, param: [10.13801457  4.22382478 12.11809239  3.52536898], weights: [0.33294621 0.33279194 0.33426185], train_wt_loss:  46.7542, val_wt_loss: 50.0937, train_grp_loss: [21.27216736  8.76296209 19.32010043], val_grp_loss: [19.58550144 12.04703437 17.93679567], train_hist_grp_loss: [0.18453665 0.13819095 0.57890728], cur_train_grp_loss: [0.18453665 0.13819095 0.57890728], max_reward_err:  0.1044, max_reward_err_index: 0, max_kl_dist:  1.7445, max_kl_dist_index: 0, max_train_grp_loss:  21.2722, max_train_grp_loss_index: 0, max_val_grp_loss:  19.5855, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.5789, max_cur_train_grp_loss_index: 2, 
2024-09-18 20:19:07,628 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  99, train_loss:  15.6001, val_loss:  16.6169, grad_norm: 0.0233,  live_grad: 0.0000, reward_err: 0.1005, 0.0005, 0.0578, KL_dist: 1.7480, 0.8819, 1.4117, param: [ 9.89588212  4.59854352 12.39203064  3.86810305], weights: [0.30621736 0.27852722 0.41525543], train_wt_loss:  46.8002, val_wt_loss: 49.8506, train_grp_loss: [21.02877866  9.13546286 19.01711179], val_grp_loss: [19.35283316 12.29625596 17.71078734], train_hist_grp_loss: [16.42048965  6.94255026 46.88035392], cur_train_grp_loss: [0.16303488 0.07023776 0.46391449], max_reward_err:  0.1005, max_reward_err_index: 0, max_kl_dist:  1.7480, max_kl_dist_index: 0, max_train_grp_loss:  21.0288, max_train_grp_loss_index: 0, max_val_grp_loss:  19.3528, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4639, max_cur_train_grp_loss_index: 2, 
2024-09-18 20:19:07,855 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:387] - INFO: Policy parameter learned solely on the preference data rdpo: [ 9.89588212  4.59854352 12.39203064  3.86810305].
2024-09-18 20:19:08,189 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Uniform reward: 3.8387, 3.8387, 3.2243
2024-09-18 20:19:08,190 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Optimal reward: 3.8841, 3.8841, 3.3675
2024-09-18 20:19:08,191 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Policy reward: 3.4938, 3.8820, 3.1730
2024-09-18 20:19:08,191 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Reward Error: 0.1005, 0.0005, 0.0578
2024-09-18 20:19:08,870 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:416] - INFO: Optimal reward: 3.8841, 3.8841, 3.3675
Known param reward: [[3.884077310562134, 3.4758739471435547, 3.3304951190948486], [3.4758739471435547, 3.884077310562134, 3.1624059677124023], [3.847635269165039, 3.6067681312561035, 3.3674604892730713]], Known param reward error: [[0.0, 0.10509661131320291, 0.010977224616584088], [0.10509661131320291, 0.0, 0.060892925756326766], [0.009382419165034734, 0.07139641081600817, 0.0]].
