2024-09-18 20:14:54,441 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log_rdpo/2024_09_18_19_49_22/swapped_noise0.8_[1,0.8,1]_2029
2024-09-18 20:14:54,443 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2029
2024-09-18 20:14:54,444 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-09-18 20:14:54,610 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.4324, l2 distance: 19.3716, acc: 0.80.
2024-09-18 20:14:54,611 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-18 20:14:54,612 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [9.58392379 4.98630681 8.74612656 4.6942155 ]
2024-09-18 20:14:54,826 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.5700, 3.8666, 3.2374
2024-09-18 20:14:55,122 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-18 20:14:56,509 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  15.7538, val_loss:  15.8613, grad_norm: 0.3281, live_grad: 0.0000, reward_err: 0.1022, 0.0013, 0.0595, KL_dist: 1.6555, 0.8357, 1.3363, param: [12.24948376  4.73479147  9.20207487  3.98866444], weights: [0.33290296 0.33292989 0.33416715], train_wt_loss:  47.2613, val_wt_loss: 47.5840, train_grp_loss: [21.10022891 10.15147818 16.69530173], val_grp_loss: [19.33205648  9.94983757 17.78958939], train_hist_grp_loss: [0.17303837 0.18112485 0.55206534], cur_train_grp_loss: [0.17303837 0.18112485 0.55206534], max_reward_err:  0.1022, max_reward_err_index: 0, max_kl_dist:  1.6555, max_kl_dist_index: 0, max_train_grp_loss:  21.1002, max_train_grp_loss_index: 0, max_val_grp_loss:  19.3321, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.5521, max_cur_train_grp_loss_index: 2, 
2024-09-18 20:15:00,998 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  99, train_loss:  15.7608, val_loss:  15.8238, grad_norm: 0.0151,  live_grad: 0.0000, reward_err: 0.1005, 0.0017, 0.0581, KL_dist: 1.6808, 0.8691, 1.3619, param: [12.39695799  4.98789653  9.33402927  4.19323538], weights: [0.31289367 0.28790014 0.39920619], train_wt_loss:  47.2825, val_wt_loss: 47.4714, train_grp_loss: [20.95528602 10.36378382 16.52997703], val_grp_loss: [19.16487797 10.19317192 17.62213963], train_hist_grp_loss: [16.3125878   7.98761243 40.67405034], cur_train_grp_loss: [0.1624563  0.07970217 0.40321496], max_reward_err:  0.1005, max_reward_err_index: 0, max_kl_dist:  1.6808, max_kl_dist_index: 0, max_train_grp_loss:  20.9553, max_train_grp_loss_index: 0, max_val_grp_loss:  19.1649, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4032, max_cur_train_grp_loss_index: 2, 
2024-09-18 20:15:01,217 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:387] - INFO: Policy parameter learned solely on the preference data rdpo: [12.39695799  4.98789653  9.33402927  4.19323538].
2024-09-18 20:15:01,550 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Uniform reward: 3.8407, 3.8407, 3.2305
2024-09-18 20:15:01,550 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Optimal reward: 3.8871, 3.8871, 3.3768
2024-09-18 20:15:01,551 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Policy reward: 3.4964, 3.8803, 3.1807
2024-09-18 20:15:01,551 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Reward Error: 0.1005, 0.0017, 0.0581
2024-09-18 20:15:02,243 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:416] - INFO: Optimal reward: 3.8871, 3.8871, 3.3768
Known param reward: [[3.887071371078491, 3.4786219596862793, 3.3387703895568848], [3.4786219596862793, 3.887071371078491, 3.172039270401001], [3.850891590118408, 3.6070683002471924, 3.37681245803833]], Known param reward error: [[0.0, 0.10507895852678548, 0.011265674050357196], [0.10507895852678548, 0.0, 0.06064097138408648], [0.00930772232001614, 0.07203445578968372, 0.0]].
