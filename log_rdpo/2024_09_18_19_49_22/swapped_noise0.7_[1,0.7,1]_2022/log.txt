2024-09-18 20:15:56,376 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log_rdpo/2024_09_18_19_49_22/swapped_noise0.7_[1,0.7,1]_2022
2024-09-18 20:15:56,378 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2022
2024-09-18 20:15:56,379 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-09-18 20:15:56,549 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.4860, l2 distance: 13.4347, acc: 0.77.
2024-09-18 20:15:56,549 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-18 20:15:56,550 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [6.72509148 2.81764665 7.31992199 3.84579016]
2024-09-18 20:15:56,762 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.5185, 3.8475, 3.1578
2024-09-18 20:15:57,124 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-18 20:15:58,461 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  16.9518, val_loss:  15.3257, grad_norm: 0.2212, live_grad: 0.0000, reward_err: 0.0964, 0.0011, 0.0548, KL_dist: 1.5027, 0.7619, 1.2005, param: [ 9.67847531  3.26403709 10.92245944  4.8601879 ], weights: [0.33305128 0.33294771 0.33400101], train_wt_loss:  50.8554, val_wt_loss: 45.9771, train_grp_loss: [20.41132636 12.75079786 19.3548806 ], val_grp_loss: [19.35688892  9.32631601 17.76369948], train_hist_grp_loss: [0.17767043 0.14657067 0.46242602], cur_train_grp_loss: [0.17767043 0.14657067 0.46242602], max_reward_err:  0.0964, max_reward_err_index: 0, max_kl_dist:  1.5027, max_kl_dist_index: 0, max_train_grp_loss:  20.4113, max_train_grp_loss_index: 0, max_val_grp_loss:  19.3569, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4624, max_cur_train_grp_loss_index: 2, 
2024-09-18 20:16:02,958 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  99, train_loss:  16.9586, val_loss:  15.3016, grad_norm: 0.0158,  live_grad: 0.0000, reward_err: 0.0940, 0.0014, 0.0526, KL_dist: 1.5122, 0.7853, 1.2126, param: [ 9.78661814  3.48698289 10.97175624  5.09321747], weights: [0.31079121 0.29152272 0.39768607], train_wt_loss:  50.8757, val_wt_loss: 45.9047, train_grp_loss: [20.25428767 12.97652607 19.19298761], val_grp_loss: [19.19268839  9.55482355 17.60863106], train_hist_grp_loss: [16.41357841 10.01324055 41.06773626], cur_train_grp_loss: [0.16335496 0.10057262 0.40839954], max_reward_err:  0.0940, max_reward_err_index: 0, max_kl_dist:  1.5122, max_kl_dist_index: 0, max_train_grp_loss:  20.2543, max_train_grp_loss_index: 0, max_val_grp_loss:  19.1927, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4084, max_cur_train_grp_loss_index: 2, 
2024-09-18 20:16:03,184 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:387] - INFO: Policy parameter learned solely on the preference data rdpo: [ 9.78661814  3.48698289 10.97175624  5.09321747].
2024-09-18 20:16:03,522 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Uniform reward: 3.8288, 3.8288, 3.1923
2024-09-18 20:16:03,523 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Optimal reward: 3.8608, 3.8608, 3.3174
2024-09-18 20:16:03,523 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Policy reward: 3.4979, 3.8553, 3.1428
2024-09-18 20:16:03,524 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Reward Error: 0.0940, 0.0014, 0.0526
2024-09-18 20:16:04,230 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:416] - INFO: Optimal reward: 3.8608, 3.8608, 3.3174
Known param reward: [[3.8608431816101074, 3.4672656059265137, 3.286299705505371], [3.4672656059265137, 3.8608431816101074, 3.1212518215179443], [3.8267719745635986, 3.5796079635620117, 3.3174452781677246]], Known param reward error: [[0.0, 0.10194083446804438, 0.009388420923571552], [0.10194083446804438, 0.0, 0.05913992250028639], [0.008824809878006984, 0.07284295290408836, 0.0]].
