2024-09-18 20:11:46,141 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log_rdpo/2024_09_18_19_49_22/swapped_noise0.9_[1,0.9,1]_2030
2024-09-18 20:11:46,143 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2030
2024-09-18 20:11:46,144 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-09-18 20:11:46,316 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.4282, l2 distance: 17.0495, acc: 0.80.
2024-09-18 20:11:46,317 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-18 20:11:46,318 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [7.37774022 3.69856674 9.52307453 3.50330935]
2024-09-18 20:11:46,531 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.4683, 3.8639, 3.1679
2024-09-18 20:11:46,865 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-18 20:11:48,271 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  15.1869, val_loss:  15.3820, grad_norm: 0.3272, live_grad: 0.0000, reward_err: 0.1119, 0.0001, 0.0685, KL_dist: 1.7566, 0.7799, 1.3916, param: [ 9.40918994  3.42115773 11.93057739  3.84312659], weights: [0.33311692 0.33291444 0.33396864], train_wt_loss:  45.5608, val_wt_loss: 46.1460, train_grp_loss: [20.8184774   9.40993238 19.86670944], val_grp_loss: [19.91729299  7.70263353 17.9833837 ], train_hist_grp_loss: [0.21022996 0.1494304  0.46558594], cur_train_grp_loss: [0.21022996 0.1494304  0.46558594], max_reward_err:  0.1119, max_reward_err_index: 0, max_kl_dist:  1.7566, max_kl_dist_index: 0, max_train_grp_loss:  20.8185, max_train_grp_loss_index: 0, max_val_grp_loss:  19.9173, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4656, max_cur_train_grp_loss_index: 2, 
2024-09-18 20:11:52,808 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  99, train_loss:  15.2003, val_loss:  15.3135, grad_norm: 0.0224,  live_grad: 0.0000, reward_err: 0.1064, 0.0003, 0.0635, KL_dist: 1.7398, 0.7999, 1.3806, param: [ 9.70239246  3.69348631 11.74511406  4.18362474], weights: [0.32111388 0.28287342 0.3960127 ], train_wt_loss:  45.6010, val_wt_loss: 45.9405, train_grp_loss: [20.618245    9.67656438 19.6025504 ], val_grp_loss: [19.68280623  7.92290647 17.81200142], train_hist_grp_loss: [19.38321851  6.70358712 40.34826422], cur_train_grp_loss: [0.19271448 0.06717586 0.40011138], max_reward_err:  0.1064, max_reward_err_index: 0, max_kl_dist:  1.7398, max_kl_dist_index: 0, max_train_grp_loss:  20.6182, max_train_grp_loss_index: 0, max_val_grp_loss:  19.6828, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4001, max_cur_train_grp_loss_index: 2, 
2024-09-18 20:11:53,038 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:387] - INFO: Policy parameter learned solely on the preference data rdpo: [ 9.70239246  3.69348631 11.74511406  4.18362474].
2024-09-18 20:11:53,375 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Uniform reward: 3.8277, 3.8277, 3.2194
2024-09-18 20:11:53,375 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Optimal reward: 3.8721, 3.8721, 3.3771
2024-09-18 20:11:53,376 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Policy reward: 3.4601, 3.8711, 3.1627
2024-09-18 20:11:53,376 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Reward Error: 0.1064, 0.0003, 0.0635
2024-09-18 20:11:54,086 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:416] - INFO: Optimal reward: 3.8721, 3.8721, 3.3771
Known param reward: [[3.8721461296081543, 3.473419189453125, 3.3377835750579834], [3.473419189453125, 3.8721461296081543, 3.1756153106689453], [3.834397315979004, 3.592139482498169, 3.377051591873169]], Known param reward error: [[0.0, 0.10297311279297687, 0.01162789958841124], [0.10297311279297687, 0.0, 0.05964856494611378], [0.00974880915276057, 0.07231303719891401, 0.0]].
