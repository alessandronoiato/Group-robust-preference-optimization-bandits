2024-09-18 20:17:39,290 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log_rdpo/2024_09_18_19_49_22/swapped_noise0.7_[1,0.7,1]_2026
2024-09-18 20:17:39,292 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2026
2024-09-18 20:17:39,293 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-09-18 20:17:39,453 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.4813, l2 distance: 14.8904, acc: 0.78.
2024-09-18 20:17:39,454 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-18 20:17:39,454 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [7.67816127 4.45673794 7.13735006 4.03215563]
2024-09-18 20:17:39,659 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.5911, 3.8424, 3.2513
2024-09-18 20:17:39,889 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-18 20:17:41,245 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  17.2133, val_loss:  17.0689, grad_norm: 0.2219, live_grad: 0.0000, reward_err: 0.0846, 0.0041, 0.0465, KL_dist: 1.3323, 0.7224, 1.0615, param: [9.97745383 4.86674818 9.4239101  4.79873578], weights: [0.33299592 0.33297464 0.33402944], train_wt_loss:  51.6399, val_wt_loss: 51.2066, train_grp_loss: [19.49987009 14.17202072 17.94092093], val_grp_loss: [19.02776146 14.47730638 17.47670544], train_hist_grp_loss: [0.16168277 0.15529079 0.47156984], cur_train_grp_loss: [0.16168277 0.15529079 0.47156984], max_reward_err:  0.0846, max_reward_err_index: 0, max_kl_dist:  1.3323, max_kl_dist_index: 0, max_train_grp_loss:  19.4999, max_train_grp_loss_index: 0, max_val_grp_loss:  19.0278, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4716, max_cur_train_grp_loss_index: 2, 
2024-09-18 20:17:45,762 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  99, train_loss:  17.2170, val_loss:  17.0564, grad_norm: 0.0093,  live_grad: 0.0000, reward_err: 0.0830, 0.0040, 0.0452, KL_dist: 1.3577, 0.7502, 1.0847, param: [9.88950127 4.99539365 9.79017134 4.92616153], weights: [0.30726617 0.30213372 0.39060011], train_wt_loss:  51.6511, val_wt_loss: 51.1693, train_grp_loss: [19.40154067 14.35932326 17.79514161], val_grp_loss: [18.92797761 14.66626039 17.36338853], train_hist_grp_loss: [14.11660591 12.43213606 38.11359731], cur_train_grp_loss: [0.14059857 0.12484519 0.37865355], max_reward_err:  0.0830, max_reward_err_index: 0, max_kl_dist:  1.3577, max_kl_dist_index: 0, max_train_grp_loss:  19.4015, max_train_grp_loss_index: 0, max_val_grp_loss:  18.9280, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.3787, max_cur_train_grp_loss_index: 2, 
2024-09-18 20:17:45,992 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:387] - INFO: Policy parameter learned solely on the preference data rdpo: [9.88950127 4.99539365 9.79017134 4.92616153].
2024-09-18 20:17:46,332 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Uniform reward: 3.8296, 3.8296, 3.2253
2024-09-18 20:17:46,333 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Optimal reward: 3.8699, 3.8699, 3.3751
2024-09-18 20:17:46,333 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Policy reward: 3.5485, 3.8545, 3.2226
2024-09-18 20:17:46,334 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Reward Error: 0.0830, 0.0040, 0.0452
2024-09-18 20:17:47,029 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:416] - INFO: Optimal reward: 3.8699, 3.8699, 3.3751
Known param reward: [[3.8699047565460205, 3.4682676792144775, 3.3350672721862793], [3.4682676792144775, 3.8699047565460205, 3.164400100708008], [3.831815481185913, 3.603090763092041, 3.375126361846924]], Known param reward error: [[0.0, 0.10378474474137016, 0.011868915520758028], [0.10378474474137016, 0.0, 0.06243507310452317], [0.009842432244793276, 0.06894588116223231, 0.0]].
