2024-09-18 20:22:20,781 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log_rdpo/2024_09_18_19_49_22/swapped_noise0.6_[1,0.6,1]_2029
2024-09-18 20:22:20,783 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2029
2024-09-18 20:22:20,783 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-09-18 20:22:20,944 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.4092, l2 distance: 20.9934, acc: 0.79.
2024-09-18 20:22:20,944 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-18 20:22:20,945 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [ 8.9093947   5.69403463 10.38975048  5.04649461]
2024-09-18 20:22:21,153 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.5765, 3.8583, 3.2332
2024-09-18 20:22:21,417 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-18 20:22:22,787 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  15.1740, val_loss:  17.4766, grad_norm: 0.2863, live_grad: 0.0000, reward_err: 0.0923, 0.0019, 0.0503, KL_dist: 1.6232, 0.8650, 1.3107, param: [10.1888302   5.1802228  11.46398364  4.24885879], weights: [0.3329903  0.33280134 0.33420837], train_wt_loss:  45.5220, val_wt_loss: 52.4299, train_grp_loss: [20.2943507   9.19770123 18.01295336], val_grp_loss: [19.60138294 14.7372163  17.75449687], train_hist_grp_loss: [0.17840821 0.12164484 0.54353762], cur_train_grp_loss: [0.17840821 0.12164484 0.54353762], max_reward_err:  0.0923, max_reward_err_index: 0, max_kl_dist:  1.6232, max_kl_dist_index: 0, max_train_grp_loss:  20.2944, max_train_grp_loss_index: 0, max_val_grp_loss:  19.6014, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.5435, max_cur_train_grp_loss_index: 2, 
2024-09-18 20:22:27,290 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  99, train_loss:  15.1845, val_loss:  17.4711, grad_norm: 0.0195,  live_grad: 0.0000, reward_err: 0.0906, 0.0028, 0.0491, KL_dist: 1.6365, 0.8938, 1.3286, param: [10.10235842  5.45929322 11.68173007  4.55380455], weights: [0.30830819 0.28333312 0.4083587 ], train_wt_loss:  45.5536, val_wt_loss: 52.4134, train_grp_loss: [20.09142753  9.49305597 17.7920142 ], val_grp_loss: [19.40402713 15.1615333  17.55458113], train_hist_grp_loss: [15.67845154  7.23079272 43.78305788], cur_train_grp_loss: [0.15576489 0.0729963  0.43401156], max_reward_err:  0.0906, max_reward_err_index: 0, max_kl_dist:  1.6365, max_kl_dist_index: 0, max_train_grp_loss:  20.0914, max_train_grp_loss_index: 0, max_val_grp_loss:  19.4040, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4340, max_cur_train_grp_loss_index: 2, 
2024-09-18 20:22:27,510 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:387] - INFO: Policy parameter learned solely on the preference data rdpo: [10.10235842  5.45929322 11.68173007  4.55380455].
2024-09-18 20:22:27,838 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Uniform reward: 3.8387, 3.8387, 3.2243
2024-09-18 20:22:27,838 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Optimal reward: 3.8841, 3.8841, 3.3675
2024-09-18 20:22:27,839 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Policy reward: 3.5321, 3.8733, 3.2021
2024-09-18 20:22:27,839 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Reward Error: 0.0906, 0.0028, 0.0491
2024-09-18 20:22:28,514 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:416] - INFO: Optimal reward: 3.8841, 3.8841, 3.3675
Known param reward: [[3.884077310562134, 3.4758739471435547, 3.3304951190948486], [3.4758739471435547, 3.884077310562134, 3.1624059677124023], [3.847635269165039, 3.6067681312561035, 3.3674604892730713]], Known param reward error: [[0.0, 0.10509661131320291, 0.010977224616584088], [0.10509661131320291, 0.0, 0.060892925756326766], [0.009382419165034734, 0.07139641081600817, 0.0]].
