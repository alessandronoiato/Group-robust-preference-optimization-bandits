2024-09-18 20:19:40,931 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log_rdpo/2024_09_18_19_49_22/swapped_noise0.6_[1,0.6,1]_2021
2024-09-18 20:19:40,933 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2021
2024-09-18 20:19:40,933 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-09-18 20:19:41,105 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.4881, l2 distance: 12.8925, acc: 0.78.
2024-09-18 20:19:41,106 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-18 20:19:41,106 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [7.49008496 2.76987425 6.30387609 1.756958  ]
2024-09-18 20:19:41,320 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.4326, 3.8265, 3.0841
2024-09-18 20:19:41,574 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-18 20:19:42,903 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  16.7639, val_loss:  17.6461, grad_norm: 0.2974, live_grad: 0.0000, reward_err: 0.1171, 0.0015, 0.0756, KL_dist: 1.6654, 0.8000, 1.3202, param: [11.9667184   3.35128329  9.61273765  2.23520868], weights: [0.33304096 0.3330091  0.33394994], train_wt_loss:  50.2917, val_wt_loss: 52.9384, train_grp_loss: [20.21660624 13.24670436 16.92509657], val_grp_loss: [21.71524224 13.05145196 18.27422623], train_hist_grp_loss: [0.18452587 0.17495796 0.45708701], cur_train_grp_loss: [0.18452587 0.17495796 0.45708701], max_reward_err:  0.1171, max_reward_err_index: 0, max_kl_dist:  1.6654, max_kl_dist_index: 0, max_train_grp_loss:  20.2166, max_train_grp_loss_index: 0, max_val_grp_loss:  21.7152, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4571, max_cur_train_grp_loss_index: 2, 
2024-09-18 20:19:47,368 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  99, train_loss:  16.7690, val_loss:  17.6122, grad_norm: 0.0118,  live_grad: 0.0000, reward_err: 0.1176, 0.0011, 0.0764, KL_dist: 1.7040, 0.8267, 1.3571, param: [12.33166056  3.52555499  9.54811714  2.35779786], weights: [0.31840546 0.30167392 0.37992062], train_wt_loss:  50.3071, val_wt_loss: 52.8365, train_grp_loss: [20.08330527 13.45900637 16.75845154], val_grp_loss: [21.62340858 13.15958702 18.15230667], train_hist_grp_loss: [16.14457241 10.74668392 33.80824504], cur_train_grp_loss: [0.16067767 0.10765308 0.3352044 ], max_reward_err:  0.1176, max_reward_err_index: 0, max_kl_dist:  1.7040, max_kl_dist_index: 0, max_train_grp_loss:  20.0833, max_train_grp_loss_index: 0, max_val_grp_loss:  21.6234, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.3352, max_cur_train_grp_loss_index: 2, 
2024-09-18 20:19:47,594 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:387] - INFO: Policy parameter learned solely on the preference data rdpo: [12.33166056  3.52555499  9.54811714  2.35779786].
2024-09-18 20:19:47,930 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Uniform reward: 3.7957, 3.7957, 3.1631
2024-09-18 20:19:47,931 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Optimal reward: 3.8296, 3.8296, 3.2923
2024-09-18 20:19:47,932 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Policy reward: 3.3791, 3.8252, 3.0407
2024-09-18 20:19:47,932 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Reward Error: 0.1176, 0.0011, 0.0764
2024-09-18 20:19:48,633 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:416] - INFO: Optimal reward: 3.8296, 3.8296, 3.2923
Known param reward: [[3.8295645713806152, 3.440261125564575, 3.2583417892456055], [3.440261125564575, 3.8295645713806152, 3.092778205871582], [3.7937707901000977, 3.5698022842407227, 3.2923295497894287]], Known param reward error: [[0.0, 0.10165736562464864, 0.010323316675876822], [0.10165736562464864, 0.0, 0.0606109871141574], [0.009346697415161585, 0.06783076307974209, 0.0]].
