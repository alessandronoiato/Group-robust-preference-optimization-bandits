2024-09-18 20:06:55,001 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log_rdpo/2024_09_18_19_49_22/swapped_noise1.0_[1,1.0,1]_2026
2024-09-18 20:06:55,003 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2026
2024-09-18 20:06:55,003 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-09-18 20:06:55,171 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.3205, l2 distance: 37.0255, acc: 0.85.
2024-09-18 20:06:55,172 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-18 20:06:55,173 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [16.29530932  7.55488527 15.66290624  7.13011982]
2024-09-18 20:06:55,386 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.5156, 3.8430, 3.1442
2024-09-18 20:06:55,766 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-18 20:06:57,116 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  13.3766, val_loss:  14.6094, grad_norm: 0.2651, live_grad: 0.0000, reward_err: 0.1050, 0.0000, 0.0617, KL_dist: 2.2103, 1.2639, 1.8071, param: [13.77803389  4.59437425 13.07620144  3.86552967], weights: [0.33302154 0.33298425 0.33399421], train_wt_loss:  40.1298, val_wt_loss: 43.8281, train_grp_loss: [17.75179516  6.23045244 18.01556159], val_grp_loss: [19.65952557  6.39590106 16.89293572], train_hist_grp_loss: [0.1500302  0.13883355 0.44167941], cur_train_grp_loss: [0.1500302  0.13883355 0.44167941], max_reward_err:  0.1050, max_reward_err_index: 0, max_kl_dist:  2.2103, max_kl_dist_index: 0, max_train_grp_loss:  18.0156, max_train_grp_loss_index: 2, max_val_grp_loss:  19.6595, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4417, max_cur_train_grp_loss_index: 2, 
2024-09-18 20:07:01,613 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  99, train_loss:  13.3856, val_loss:  14.5702, grad_norm: 0.0168,  live_grad: 0.0000, reward_err: 0.1027, 0.0000, 0.0598, KL_dist: 2.2253, 1.2898, 1.8249, param: [13.80188901  4.88898549 13.26662882  4.12838604], weights: [0.31063084 0.28906351 0.40030565], train_wt_loss:  40.1568, val_wt_loss: 43.7107, train_grp_loss: [17.57758267  6.54457672 17.81596697], val_grp_loss: [19.48078052  6.67057302 16.71281606], train_hist_grp_loss: [12.82494502  5.62906896 38.18726588], cur_train_grp_loss: [0.12738765 0.05687715 0.37910975], max_reward_err:  0.1027, max_reward_err_index: 0, max_kl_dist:  2.2253, max_kl_dist_index: 0, max_train_grp_loss:  17.8160, max_train_grp_loss_index: 2, max_val_grp_loss:  19.4808, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.3791, max_cur_train_grp_loss_index: 2, 
2024-09-18 20:07:01,840 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:387] - INFO: Policy parameter learned solely on the preference data rdpo: [13.80188901  4.88898549 13.26662882  4.12838604].
2024-09-18 20:07:02,180 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Uniform reward: 3.8112, 3.8112, 3.1709
2024-09-18 20:07:02,181 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Optimal reward: 3.8518, 3.8518, 3.2974
2024-09-18 20:07:02,181 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Policy reward: 3.4561, 3.8518, 3.1004
2024-09-18 20:07:02,182 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Reward Error: 0.1027, 0.0000, 0.0598
2024-09-18 20:07:02,879 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:416] - INFO: Optimal reward: 3.8518, 3.8518, 3.2974
Known param reward: [[3.8518338203430176, 3.4604334831237793, 3.266357421875], [3.4604334831237793, 3.8518338203430176, 3.1038687229156494], [3.8126895427703857, 3.589339256286621, 3.297445297241211]], Known param reward error: [[0.0, 0.10161402476713881, 0.009427866898116682], [0.10161402476713881, 0.0, 0.058705014602521616], [0.010162504250805377, 0.06814794622500629, 0.0]].
