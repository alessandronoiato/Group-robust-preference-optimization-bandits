2024-09-18 20:12:06,316 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log_rdpo/2024_09_18_19_49_22/swapped_noise0.8_[1,0.8,1]_2021
2024-09-18 20:12:06,318 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2021
2024-09-18 20:12:06,318 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-09-18 20:12:06,485 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.4314, l2 distance: 20.0523, acc: 0.79.
2024-09-18 20:12:06,485 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-18 20:12:06,486 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [ 8.70855314  5.02440232 10.42407992  3.54741519]
2024-09-18 20:12:06,695 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.4702, 3.8147, 3.1098
2024-09-18 20:12:06,991 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-18 20:12:08,340 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  15.7073, val_loss:  15.5981, grad_norm: 0.2554, live_grad: 0.0000, reward_err: 0.0962, 0.0005, 0.0561, KL_dist: 1.7089, 0.9287, 1.3779, param: [11.49640645  4.79071366 11.29575149  3.78704522], weights: [0.3330536  0.33302064 0.33392576], train_wt_loss:  47.1220, val_wt_loss: 46.7943, train_grp_loss: [19.99797689 10.64750919 17.63021977], val_grp_loss: [19.71291528  9.7115935  17.53765234], train_hist_grp_loss: [0.16882204 0.15892726 0.43034831], cur_train_grp_loss: [0.16882204 0.15892726 0.43034831], max_reward_err:  0.0962, max_reward_err_index: 0, max_kl_dist:  1.7089, max_kl_dist_index: 0, max_train_grp_loss:  19.9980, max_train_grp_loss_index: 0, max_val_grp_loss:  19.7129, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4303, max_cur_train_grp_loss_index: 2, 
2024-09-18 20:12:12,882 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  99, train_loss:  15.7131, val_loss:  15.5747, grad_norm: 0.0139,  live_grad: 0.0000, reward_err: 0.0944, 0.0007, 0.0545, KL_dist: 1.7297, 0.9552, 1.3992, param: [11.53593601  4.98366837 11.48217598  3.99308589], weights: [0.31824736 0.29591451 0.38583814], train_wt_loss:  47.1394, val_wt_loss: 46.7240, train_grp_loss: [19.84822026 10.86554438 17.49434824], val_grp_loss: [19.57072702  9.92956662 17.38546758], train_hist_grp_loss: [15.94954156  8.67370618 35.20844261], cur_train_grp_loss: [0.1587985  0.0869045  0.34991652], max_reward_err:  0.0944, max_reward_err_index: 0, max_kl_dist:  1.7297, max_kl_dist_index: 0, max_train_grp_loss:  19.8482, max_train_grp_loss_index: 0, max_val_grp_loss:  19.5707, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.3499, max_cur_train_grp_loss_index: 2, 
2024-09-18 20:12:13,140 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:387] - INFO: Policy parameter learned solely on the preference data rdpo: [11.53593601  4.98366837 11.48217598  3.99308589].
2024-09-18 20:12:13,485 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Uniform reward: 3.7909, 3.7909, 3.1575
2024-09-18 20:12:13,486 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Optimal reward: 3.8247, 3.8247, 3.2862
2024-09-18 20:12:13,486 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Policy reward: 3.4637, 3.8221, 3.1071
2024-09-18 20:12:13,487 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Reward Error: 0.0944, 0.0007, 0.0545
2024-09-18 20:12:14,224 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:416] - INFO: Optimal reward: 3.8247, 3.8247, 3.2862
Known param reward: [[3.824740409851074, 3.4372060298919678, 3.2528157234191895], [3.4372060298919678, 3.824740409851074, 3.087484836578369], [3.7884345054626465, 3.5667476654052734, 3.2862327098846436]], Known param reward error: [[0.0, 0.10132305422897865, 0.010168782741690603], [0.10132305422897865, 0.0, 0.060478940736138874], [0.00949238392621825, 0.06745366137302018, 0.0]].
