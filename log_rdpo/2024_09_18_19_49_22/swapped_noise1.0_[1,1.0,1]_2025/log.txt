2024-09-18 20:06:33,906 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log_rdpo/2024_09_18_19_49_22/swapped_noise1.0_[1,1.0,1]_2025
2024-09-18 20:06:33,908 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2025
2024-09-18 20:06:33,908 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-09-18 20:06:34,074 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.2984, l2 distance: 38.1703, acc: 0.86.
2024-09-18 20:06:34,074 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-18 20:06:34,075 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [15.30897596  7.8882492  17.26025981  7.68476984]
2024-09-18 20:06:34,288 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.5736, 3.8739, 3.1818
2024-09-18 20:06:34,516 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-18 20:06:35,876 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  12.9688, val_loss:  14.3058, grad_norm: 0.3360, live_grad: 0.0000, reward_err: 0.1068, 0.0003, 0.0675, KL_dist: 2.0539, 1.1076, 1.6863, param: [10.49829693  3.99675156 14.10636186  4.67215544], weights: [0.33305473 0.3329222  0.33402307], train_wt_loss:  38.9063, val_wt_loss: 42.9175, train_grp_loss: [18.30920877  6.36332821 17.03593176], val_grp_loss: [20.12245887  5.52467893 17.06731486], train_hist_grp_loss: [0.18000837 0.14020842 0.47032971], cur_train_grp_loss: [0.18000837 0.14020842 0.47032971], max_reward_err:  0.1068, max_reward_err_index: 0, max_kl_dist:  2.0539, max_kl_dist_index: 0, max_train_grp_loss:  18.3092, max_train_grp_loss_index: 0, max_val_grp_loss:  20.1225, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4703, max_cur_train_grp_loss_index: 2, 
2024-09-18 20:06:40,399 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  99, train_loss:  12.9769, val_loss:  14.2542, grad_norm: 0.0163,  live_grad: 0.0000, reward_err: 0.1056, 0.0005, 0.0664, KL_dist: 2.0735, 1.1383, 1.7076, param: [10.62735647  4.26036076 14.21170444  4.90683906], weights: [0.31887517 0.28929481 0.39183002], train_wt_loss:  38.9308, val_wt_loss: 42.7625, train_grp_loss: [18.13220997  6.60972588 16.87850358], val_grp_loss: [19.95425214  5.72787211 16.88727929], train_hist_grp_loss: [14.84787041  5.11252453 35.45071223], cur_train_grp_loss: [0.14743192 0.05121585 0.35167139], max_reward_err:  0.1056, max_reward_err_index: 0, max_kl_dist:  2.0735, max_kl_dist_index: 0, max_train_grp_loss:  18.1322, max_train_grp_loss_index: 0, max_val_grp_loss:  19.9543, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.3517, max_cur_train_grp_loss_index: 2, 
2024-09-18 20:06:40,628 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:387] - INFO: Policy parameter learned solely on the preference data rdpo: [10.62735647  4.26036076 14.21170444  4.90683906].
2024-09-18 20:06:40,965 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Uniform reward: 3.8481, 3.8481, 3.1906
2024-09-18 20:06:40,965 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Optimal reward: 3.8879, 3.8879, 3.3280
2024-09-18 20:06:40,966 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Policy reward: 3.4773, 3.8858, 3.1070
2024-09-18 20:06:40,966 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Reward Error: 0.1056, 0.0005, 0.0664
2024-09-18 20:06:41,665 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:416] - INFO: Optimal reward: 3.8879, 3.8879, 3.3280
Known param reward: [[3.8879001140594482, 3.5038833618164062, 3.288445234298706], [3.5038833618164062, 3.8879001140594482, 3.1316840648651123], [3.8516592979431152, 3.6378118991851807, 3.328000545501709]], Known param reward error: [[0.0, 0.09877227834489838, 0.011885608389237752], [0.09877227834489838, 0.0, 0.05898931744525938], [0.009321437036223937, 0.06432475308969411, 0.0]].
