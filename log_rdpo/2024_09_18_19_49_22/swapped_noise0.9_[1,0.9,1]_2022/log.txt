2024-09-18 20:09:01,235 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log_rdpo/2024_09_18_19_49_22/swapped_noise0.9_[1,0.9,1]_2022
2024-09-18 20:09:01,237 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2022
2024-09-18 20:09:01,237 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-09-18 20:09:01,407 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.3535, l2 distance: 28.4868, acc: 0.85.
2024-09-18 20:09:01,408 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-18 20:09:01,409 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [12.5384091   6.91815982 12.54481599  6.12893569]
2024-09-18 20:09:01,623 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.5601, 3.8531, 3.1999
2024-09-18 20:09:02,031 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-18 20:09:03,425 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  13.8276, val_loss:  14.9318, grad_norm: 0.3618, live_grad: 0.0000, reward_err: 0.0960, 0.0008, 0.0540, KL_dist: 1.8804, 1.0321, 1.5331, param: [12.69654036  5.40194672 11.11659076  4.03128322], weights: [0.33303546 0.33289789 0.33406666], train_wt_loss:  41.4827, val_wt_loss: 44.7955, train_grp_loss: [19.9857176   6.85197045 16.72633338], val_grp_loss: [20.09195564  8.353053   16.88944316], train_hist_grp_loss: [0.19358599 0.15226965 0.50274562], cur_train_grp_loss: [0.19358599 0.15226965 0.50274562], max_reward_err:  0.0960, max_reward_err_index: 0, max_kl_dist:  1.8804, max_kl_dist_index: 0, max_train_grp_loss:  19.9857, max_train_grp_loss_index: 0, max_val_grp_loss:  20.0920, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.5027, max_cur_train_grp_loss_index: 2, 
2024-09-18 20:09:07,994 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  99, train_loss:  13.8377, val_loss:  14.9647, grad_norm: 0.0169,  live_grad: 0.0000, reward_err: 0.0931, 0.0010, 0.0520, KL_dist: 1.9104, 1.0642, 1.5662, param: [13.08018498  5.69395634 10.92856962  4.29304434], weights: [0.32123509 0.28891263 0.38985228], train_wt_loss:  41.5132, val_wt_loss: 44.8941, train_grp_loss: [19.86164924  7.09271912 16.45779774], val_grp_loss: [19.87908186  8.7826211  16.74134103], train_hist_grp_loss: [16.10198951  5.49710086 35.46145711], cur_train_grp_loss: [0.16018537 0.05496021 0.3502276 ], max_reward_err:  0.0931, max_reward_err_index: 0, max_kl_dist:  1.9104, max_kl_dist_index: 0, max_train_grp_loss:  19.8616, max_train_grp_loss_index: 0, max_val_grp_loss:  19.8791, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.3502, max_cur_train_grp_loss_index: 2, 
2024-09-18 20:09:08,226 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:387] - INFO: Policy parameter learned solely on the preference data rdpo: [13.08018498  5.69395634 10.92856962  4.29304434].
2024-09-18 20:09:08,574 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Uniform reward: 3.8376, 3.8376, 3.2077
2024-09-18 20:09:08,574 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Optimal reward: 3.8707, 3.8707, 3.3351
2024-09-18 20:09:08,575 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Policy reward: 3.5102, 3.8667, 3.1618
2024-09-18 20:09:08,575 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Reward Error: 0.0931, 0.0010, 0.0520
2024-09-18 20:09:09,284 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:416] - INFO: Optimal reward: 3.8707, 3.8707, 3.3351
Known param reward: [[3.870741367340088, 3.47579288482666, 3.3037049770355225], [3.47579288482666, 3.870741367340088, 3.1393208503723145], [3.836113214492798, 3.5835537910461426, 3.3351211547851562]], Known param reward error: [[0.0, 0.10203432496055144, 0.009419801048174388], [0.10203432496055144, 0.0, 0.05870860317380433], [0.008946129322788094, 0.07419446277582117, 0.0]].
