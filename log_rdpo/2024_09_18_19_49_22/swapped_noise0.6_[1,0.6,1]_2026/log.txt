2024-09-18 20:21:19,182 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log_rdpo/2024_09_18_19_49_22/swapped_noise0.6_[1,0.6,1]_2026
2024-09-18 20:21:19,184 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2026
2024-09-18 20:21:19,184 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-09-18 20:21:19,351 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.4897, l2 distance: 13.8904, acc: 0.75.
2024-09-18 20:21:19,352 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-18 20:21:19,353 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [7.98825619 2.69900213 6.4400013  3.59401665]
2024-09-18 20:21:19,565 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.4928, 3.8618, 3.1795
2024-09-18 20:21:19,798 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-18 20:21:21,136 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  17.0466, val_loss:  16.6237, grad_norm: 0.1897, live_grad: 0.0000, reward_err: 0.1018, 0.0004, 0.0616, KL_dist: 1.6755, 0.8263, 1.3388, param: [12.02480201  3.4627118   9.78902325  4.52635339], weights: [0.33300087 0.33301462 0.33398451], train_wt_loss:  51.1398, val_wt_loss: 49.8711, train_grp_loss: [20.61562338 12.23432999 18.34213135], val_grp_loss: [20.1328892  11.67423122 17.42357313], train_hist_grp_loss: [0.15578202 0.15990991 0.45073335], cur_train_grp_loss: [0.15578202 0.15990991 0.45073335], max_reward_err:  0.1018, max_reward_err_index: 0, max_kl_dist:  1.6755, max_kl_dist_index: 0, max_train_grp_loss:  20.6156, max_train_grp_loss_index: 0, max_val_grp_loss:  20.1329, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4507, max_cur_train_grp_loss_index: 2, 
2024-09-18 20:21:25,631 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  99, train_loss:  17.0540, val_loss:  16.5766, grad_norm: 0.0131,  live_grad: 0.0000, reward_err: 0.1005, 0.0006, 0.0599, KL_dist: 1.6678, 0.8485, 1.3317, param: [11.67621392  3.61959391 10.33094918  4.71703105], weights: [0.3095634  0.29714571 0.39329089], train_wt_loss:  51.1619, val_wt_loss: 49.7297, train_grp_loss: [20.48385382 12.51081378 18.09946596], val_grp_loss: [20.03852909 11.82231276 17.25130368], train_hist_grp_loss: [14.89919425 10.80516671 38.83785649], cur_train_grp_loss: [0.14844381 0.10876243 0.38514992], max_reward_err:  0.1005, max_reward_err_index: 0, max_kl_dist:  1.6678, max_kl_dist_index: 0, max_train_grp_loss:  20.4839, max_train_grp_loss_index: 0, max_val_grp_loss:  20.0385, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.3851, max_cur_train_grp_loss_index: 2, 
2024-09-18 20:21:25,857 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:387] - INFO: Policy parameter learned solely on the preference data rdpo: [11.67621392  3.61959391 10.33094918  4.71703105].
2024-09-18 20:21:26,190 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Uniform reward: 3.8294, 3.8294, 3.2249
2024-09-18 20:21:26,190 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Optimal reward: 3.8697, 3.8697, 3.3747
2024-09-18 20:21:26,191 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Policy reward: 3.4808, 3.8673, 3.1724
2024-09-18 20:21:26,191 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Reward Error: 0.1005, 0.0006, 0.0599
2024-09-18 20:21:26,874 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:416] - INFO: Optimal reward: 3.8697, 3.8697, 3.3747
Known param reward: [[3.869661331176758, 3.4677367210388184, 3.334665060043335], [3.4677367210388184, 3.869661331176758, 3.163583993911743], [3.832443952560425, 3.602559804916382, 3.3746607303619385]], Known param reward error: [[0.0, 0.1038655778219524, 0.011851760373646185], [0.1038655778219524, 0.0, 0.06254754279478546], [0.00961773536006451, 0.06902452266517878, 0.0]].
