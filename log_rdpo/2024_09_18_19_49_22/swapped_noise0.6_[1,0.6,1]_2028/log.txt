2024-09-18 20:22:00,684 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log_rdpo/2024_09_18_19_49_22/swapped_noise0.6_[1,0.6,1]_2028
2024-09-18 20:22:00,686 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2028
2024-09-18 20:22:00,686 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-09-18 20:22:00,843 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.5162, l2 distance: 11.4215, acc: 0.77.
2024-09-18 20:22:00,844 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-18 20:22:00,845 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [4.65646533 3.49803522 7.38419958 2.36698542]
2024-09-18 20:22:01,046 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.5114, 3.8516, 3.1541
2024-09-18 20:22:01,292 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-18 20:22:02,604 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  18.0351, val_loss:  17.4853, grad_norm: 0.2044, live_grad: 0.0000, reward_err: 0.1026, 0.0016, 0.0656, KL_dist: 1.3966, 0.5874, 1.1365, param: [ 6.44880221  4.47340007 11.76972807  3.16709899], weights: [0.33309922 0.33307864 0.33382214], train_wt_loss:  54.1052, val_wt_loss: 52.4560, train_grp_loss: [21.55137696 14.37196177 17.27733308], val_grp_loss: [20.5822427  12.44791753 18.87680646], train_hist_grp_loss: [0.17424548 0.16806704 0.39103938], cur_train_grp_loss: [0.17424548 0.16806704 0.39103938], max_reward_err:  0.1026, max_reward_err_index: 0, max_kl_dist:  1.3966, max_kl_dist_index: 0, max_train_grp_loss:  21.5514, max_train_grp_loss_index: 0, max_val_grp_loss:  20.5822, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.3910, max_cur_train_grp_loss_index: 2, 
2024-09-18 20:22:07,032 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  99, train_loss:  18.0385, val_loss:  17.4376, grad_norm: 0.0094,  live_grad: 0.0000, reward_err: 0.1014, 0.0018, 0.0652, KL_dist: 1.4324, 0.6069, 1.1730, param: [ 6.34826987  4.62020938 12.02858334  3.30973892], weights: [0.32147241 0.30976533 0.36876226], train_wt_loss:  54.1155, val_wt_loss: 52.3129, train_grp_loss: [21.45573228 14.56499707 17.13090397], val_grp_loss: [20.47622179 12.50607156 18.79223317], train_hist_grp_loss: [16.55067843 12.84100605 30.27472042], cur_train_grp_loss: [0.1650517  0.1288752  0.30056906], max_reward_err:  0.1014, max_reward_err_index: 0, max_kl_dist:  1.4324, max_kl_dist_index: 0, max_train_grp_loss:  21.4557, max_train_grp_loss_index: 0, max_val_grp_loss:  20.4762, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.3006, max_cur_train_grp_loss_index: 2, 
2024-09-18 20:22:07,250 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:387] - INFO: Policy parameter learned solely on the preference data rdpo: [ 6.34826987  4.62020938 12.02858334  3.30973892].
2024-09-18 20:22:07,573 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Uniform reward: 3.8289, 3.8289, 3.2018
2024-09-18 20:22:07,574 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Optimal reward: 3.8652, 3.8652, 3.3372
2024-09-18 20:22:07,574 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Policy reward: 3.4732, 3.8580, 3.1197
2024-09-18 20:22:07,575 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Reward Error: 0.1014, 0.0018, 0.0652
2024-09-18 20:22:08,250 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:416] - INFO: Optimal reward: 3.8652, 3.8652, 3.3372
Known param reward: [[3.8651840686798096, 3.4605093002319336, 3.3015952110290527], [3.4605093002319336, 3.8651840686798096, 3.1258203983306885], [3.8319525718688965, 3.6041877269744873, 3.337219715118408]], Known param reward error: [[0.0, 0.10469741188447372, 0.010674905199669023], [0.10469741188447372, 0.0, 0.0633459390851702], [0.00859764922457202, 0.06752494501367125, 0.0]].
