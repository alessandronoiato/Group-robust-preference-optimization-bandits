2024-09-18 20:12:28,305 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log_rdpo/2024_09_18_19_49_22/swapped_noise0.8_[1,0.8,1]_2022
2024-09-18 20:12:28,306 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2022
2024-09-18 20:12:28,307 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-09-18 20:12:28,479 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.4465, l2 distance: 17.2654, acc: 0.79.
2024-09-18 20:12:28,480 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-18 20:12:28,481 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [7.73322927 5.13439292 8.93418526 3.72803641]
2024-09-18 20:12:28,693 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.5959, 3.8329, 3.2039
2024-09-18 20:12:28,980 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-18 20:12:30,313 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  16.0317, val_loss:  15.7088, grad_norm: 0.2785, live_grad: 0.0000, reward_err: 0.0731, 0.0034, 0.0380, KL_dist: 1.4795, 0.8301, 1.2026, param: [10.16716331  5.32784362 10.75256294  4.00836695], weights: [0.33305616 0.33287794 0.3340659 ], train_wt_loss:  48.0950, val_wt_loss: 47.1264, train_grp_loss: [21.69076483  9.55525052 18.87701185], val_grp_loss: [19.73324061 10.43591921 17.60063198], train_hist_grp_loss: [0.18976579 0.13624062 0.49247943], cur_train_grp_loss: [0.18976579 0.13624062 0.49247943], max_reward_err:  0.0731, max_reward_err_index: 0, max_kl_dist:  1.4795, max_kl_dist_index: 0, max_train_grp_loss:  21.6908, max_train_grp_loss_index: 0, max_val_grp_loss:  19.7332, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4925, max_cur_train_grp_loss_index: 2, 
2024-09-18 20:12:34,868 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  99, train_loss:  16.0402, val_loss:  15.6986, grad_norm: 0.0174,  live_grad: 0.0000, reward_err: 0.0708, 0.0042, 0.0360, KL_dist: 1.4869, 0.8573, 1.2142, param: [10.29706474  5.58925907 10.71483916  4.27139271], weights: [0.31644555 0.2866613  0.39689315], train_wt_loss:  48.1206, val_wt_loss: 47.0959, train_grp_loss: [21.51944685  9.79809415 18.71690529], val_grp_loss: [19.5593903  10.7090776  17.43669975], train_hist_grp_loss: [17.44148203  7.55649984 40.09307163], cur_train_grp_loss: [0.17355899 0.07593194 0.39826973], max_reward_err:  0.0708, max_reward_err_index: 0, max_kl_dist:  1.4869, max_kl_dist_index: 0, max_train_grp_loss:  21.5194, max_train_grp_loss_index: 0, max_val_grp_loss:  19.5594, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.3983, max_cur_train_grp_loss_index: 2, 
2024-09-18 20:12:35,096 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:387] - INFO: Policy parameter learned solely on the preference data rdpo: [10.29706474  5.58925907 10.71483916  4.27139271].
2024-09-18 20:12:35,435 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Uniform reward: 3.8267, 3.8267, 3.1836
2024-09-18 20:12:35,436 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Optimal reward: 3.8586, 3.8586, 3.3169
2024-09-18 20:12:35,436 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Policy reward: 3.5855, 3.8424, 3.1973
2024-09-18 20:12:35,437 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Reward Error: 0.0708, 0.0042, 0.0360
2024-09-18 20:12:36,139 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:416] - INFO: Optimal reward: 3.8586, 3.8586, 3.3169
Known param reward: [[3.8586065769195557, 3.531782627105713, 3.266848564147949], [3.531782627105713, 3.8586065769195557, 3.1579184532165527], [3.8154232501983643, 3.627133369445801, 3.3168587684631348]], Known param reward error: [[0.0, 0.08469999293754285, 0.015077580266813035], [0.08469999293754285, 0.0, 0.04791892761844273], [0.011191430341588746, 0.05998880758103799, 0.0]].
