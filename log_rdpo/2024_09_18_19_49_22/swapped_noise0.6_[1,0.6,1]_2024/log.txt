2024-09-18 20:20:39,611 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log_rdpo/2024_09_18_19_49_22/swapped_noise0.6_[1,0.6,1]_2024
2024-09-18 20:20:39,613 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2024
2024-09-18 20:20:39,613 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-09-18 20:20:39,779 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.4614, l2 distance: 14.2156, acc: 0.81.
2024-09-18 20:20:39,780 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-18 20:20:39,781 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [7.12777926 3.69118221 7.29367386 4.24080502]
2024-09-18 20:20:39,995 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.5381, 3.7683, 3.1486
2024-09-18 20:20:40,301 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-18 20:20:41,667 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  16.2059, val_loss:  16.8479, grad_norm: 0.2773, live_grad: 0.0000, reward_err: 0.0805, 0.0033, 0.0454, KL_dist: 1.4301, 0.7803, 1.1488, param: [ 9.00570086  3.95664416 10.89167401  5.33039485], weights: [0.3330142 0.3328412 0.3341446], train_wt_loss:  48.6177, val_wt_loss: 50.5436, train_grp_loss: [19.68413808 13.23157181 15.79460745], val_grp_loss: [19.68150026 13.24860333 17.53425541], train_hist_grp_loss: [0.18506223 0.13309953 0.52393062], cur_train_grp_loss: [0.18506223 0.13309953 0.52393062], max_reward_err:  0.0805, max_reward_err_index: 0, max_kl_dist:  1.4301, max_kl_dist_index: 0, max_train_grp_loss:  19.6841, max_train_grp_loss_index: 0, max_val_grp_loss:  19.6815, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.5239, max_cur_train_grp_loss_index: 2, 
2024-09-18 20:20:46,181 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  99, train_loss:  16.2120, val_loss:  16.8483, grad_norm: 0.0136,  live_grad: 0.0000, reward_err: 0.0791, 0.0035, 0.0442, KL_dist: 1.4737, 0.8176, 1.1900, param: [ 9.05135103  4.1550102  11.19093558  5.48958134], weights: [0.31359509 0.29431713 0.39208778], train_wt_loss:  48.6361, val_wt_loss: 50.5449, train_grp_loss: [19.54727637 13.42329774 15.6060396 ], val_grp_loss: [19.55839787 13.52460046 17.39333602], train_hist_grp_loss: [16.10446653  9.7599891  38.44277829], cur_train_grp_loss: [0.16023563 0.09796411 0.38068528], max_reward_err:  0.0791, max_reward_err_index: 0, max_kl_dist:  1.4737, max_kl_dist_index: 0, max_train_grp_loss:  19.5473, max_train_grp_loss_index: 0, max_val_grp_loss:  19.5584, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.3807, max_cur_train_grp_loss_index: 2, 
2024-09-18 20:20:46,404 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:387] - INFO: Policy parameter learned solely on the preference data rdpo: [ 9.05135103  4.1550102  11.19093558  5.48958134].
2024-09-18 20:20:46,738 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Uniform reward: 3.7483, 3.7483, 3.1113
2024-09-18 20:20:46,739 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Optimal reward: 3.7937, 3.7937, 3.2584
2024-09-18 20:20:46,739 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Policy reward: 3.4938, 3.7805, 3.1143
2024-09-18 20:20:46,740 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Reward Error: 0.0791, 0.0035, 0.0442
2024-09-18 20:20:47,427 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:416] - INFO: Optimal reward: 3.7937, 3.7937, 3.2584
Known param reward: [[3.7937493324279785, 3.4302093982696533, 3.224942445755005], [3.4302093982696533, 3.7937493324279785, 3.071303129196167], [3.7626752853393555, 3.56032395362854, 3.2583768367767334]], Known param reward error: [[0.0, 0.09582602916088334, 0.010261057175572927], [0.09582602916088334, 0.0, 0.057413159051800874], [0.008190854051165217, 0.061528940988319736, 0.0]].
