2024-09-18 20:22:41,718 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log_rdpo/2024_09_18_19_49_22/swapped_noise0.6_[1,0.6,1]_2030
2024-09-18 20:22:41,720 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2030
2024-09-18 20:22:41,720 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-09-18 20:22:41,877 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.4961, l2 distance: 10.5890, acc: 0.77.
2024-09-18 20:22:41,878 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-18 20:22:41,879 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [5.36923291 3.75606204 5.9084699  3.85520782]
2024-09-18 20:22:42,086 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.5727, 3.7607, 3.2144
2024-09-18 20:22:42,338 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-18 20:22:43,646 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  17.3700, val_loss:  16.6905, grad_norm: 0.2647, live_grad: 0.0000, reward_err: 0.0746, 0.0083, 0.0372, KL_dist: 1.0549, 0.5638, 0.8317, param: [7.94787027 4.49238223 8.75971587 4.93074498], weights: [0.33315663 0.33287141 0.33397195], train_wt_loss:  52.1101, val_wt_loss: 50.0716, train_grp_loss: [20.45240458 14.59075143 18.806908  ], val_grp_loss: [19.69889443 11.3670993  18.573926  ], train_hist_grp_loss: [0.21730727 0.13165956 0.46173441], cur_train_grp_loss: [0.21730727 0.13165956 0.46173441], max_reward_err:  0.0746, max_reward_err_index: 0, max_kl_dist:  1.0549, max_kl_dist_index: 0, max_train_grp_loss:  20.4524, max_train_grp_loss_index: 0, max_val_grp_loss:  19.6989, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4617, max_cur_train_grp_loss_index: 2, 
2024-09-18 20:22:48,100 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  99, train_loss:  17.3781, val_loss:  16.6717, grad_norm: 0.0162,  live_grad: 0.0000, reward_err: 0.0728, 0.0091, 0.0357, KL_dist: 1.0670, 0.5985, 0.8470, param: [8.02100389 4.76120897 8.83297182 5.17664417], weights: [0.31973761 0.29274303 0.38751936], train_wt_loss:  52.1342, val_wt_loss: 50.0152, train_grp_loss: [20.26110926 14.81191334 18.62386973], val_grp_loss: [19.51598505 11.68489746 18.40633711], train_hist_grp_loss: [19.05490879 10.23435893 38.28142219], cur_train_grp_loss: [0.18937543 0.10284264 0.38011985], max_reward_err:  0.0728, max_reward_err_index: 0, max_kl_dist:  1.0670, max_kl_dist_index: 0, max_train_grp_loss:  20.2611, max_train_grp_loss_index: 0, max_val_grp_loss:  19.5160, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.3801, max_cur_train_grp_loss_index: 2, 
2024-09-18 20:22:48,321 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:387] - INFO: Policy parameter learned solely on the preference data rdpo: [8.02100389 4.76120897 8.83297182 5.17664417].
2024-09-18 20:22:48,647 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Uniform reward: 3.7751, 3.7751, 3.1646
2024-09-18 20:22:48,648 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Optimal reward: 3.8138, 3.8138, 3.3081
2024-09-18 20:22:48,648 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Policy reward: 3.5363, 3.7792, 3.1898
2024-09-18 20:22:48,648 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Reward Error: 0.0728, 0.0091, 0.0357
2024-09-18 20:22:49,330 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:416] - INFO: Optimal reward: 3.8138, 3.8138, 3.3081
Known param reward: [[3.8138465881347656, 3.439753770828247, 3.273068904876709], [3.439753770828247, 3.8138465881347656, 3.121405839920044], [3.7787630558013916, 3.5612988471984863, 3.308058500289917]], Known param reward error: [[0.0, 0.09808806113763369, 0.010577078794145125], [0.09808806113763369, 0.0, 0.05642362743993641], [0.009198988874519018, 0.06621864175711184, 0.0]].
