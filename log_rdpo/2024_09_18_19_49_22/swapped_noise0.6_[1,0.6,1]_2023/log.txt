2024-09-18 20:20:20,734 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log_rdpo/2024_09_18_19_49_22/swapped_noise0.6_[1,0.6,1]_2023
2024-09-18 20:20:20,736 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2023
2024-09-18 20:20:20,737 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-09-18 20:20:20,907 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.4901, l2 distance: 13.7110, acc: 0.77.
2024-09-18 20:20:20,907 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-18 20:20:20,908 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [8.67865662 2.73331006 5.03288862 3.70226044]
2024-09-18 20:20:21,116 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.4786, 3.8485, 3.0931
2024-09-18 20:20:21,375 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-18 20:20:22,726 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  17.1330, val_loss:  18.2366, grad_norm: 0.2592, live_grad: 0.0000, reward_err: 0.1066, 0.0015, 0.0705, KL_dist: 1.6893, 0.7319, 1.4125, param: [13.60823155  3.63042727  6.31534729  4.24740416], weights: [0.33303943 0.33305292 0.33390765], train_wt_loss:  51.3989, val_wt_loss: 54.7097, train_grp_loss: [20.01275625 13.70630311 17.78788765], val_grp_loss: [21.54942653 13.86598655 19.44818022], train_hist_grp_loss: [0.17662238 0.18067553 0.4369804 ], cur_train_grp_loss: [0.17662238 0.18067553 0.4369804 ], max_reward_err:  0.1066, max_reward_err_index: 0, max_kl_dist:  1.6893, max_kl_dist_index: 0, max_train_grp_loss:  20.0128, max_train_grp_loss_index: 0, max_val_grp_loss:  21.5494, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4370, max_cur_train_grp_loss_index: 2, 
2024-09-18 20:20:27,246 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  99, train_loss:  17.1397, val_loss:  18.1524, grad_norm: 0.0121,  live_grad: 0.0000, reward_err: 0.1037, 0.0016, 0.0672, KL_dist: 1.6606, 0.7595, 1.3835, param: [13.40153842  3.80079759  6.80400392  4.43893271], weights: [0.31475778 0.30333739 0.38190482], train_wt_loss:  51.4191, val_wt_loss: 54.4572, train_grp_loss: [19.90610851 13.9540428  17.52118395], val_grp_loss: [21.37440644 13.9655354  19.26916713], train_hist_grp_loss: [15.37740411 11.6816329  34.7142059 ], cur_train_grp_loss: [0.1531325  0.11723747 0.34360787], max_reward_err:  0.1037, max_reward_err_index: 0, max_kl_dist:  1.6606, max_kl_dist_index: 0, max_train_grp_loss:  19.9061, max_train_grp_loss_index: 0, max_val_grp_loss:  21.3744, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.3436, max_cur_train_grp_loss_index: 2, 
2024-09-18 20:20:27,473 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:387] - INFO: Policy parameter learned solely on the preference data rdpo: [13.40153842  3.80079759  6.80400392  4.43893271].
2024-09-18 20:20:27,812 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Uniform reward: 3.8219, 3.8219, 3.1727
2024-09-18 20:20:27,813 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Optimal reward: 3.8605, 3.8605, 3.2988
2024-09-18 20:20:27,814 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Policy reward: 3.4602, 3.8544, 3.0770
2024-09-18 20:20:27,814 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Reward Error: 0.1037, 0.0016, 0.0672
2024-09-18 20:20:28,517 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:416] - INFO: Optimal reward: 3.8605, 3.8605, 3.2988
Known param reward: [[3.8605411052703857, 3.4837193489074707, 3.270322322845459], [3.4837193489074707, 3.8605411052703857, 3.110097646713257], [3.825101613998413, 3.5993566513061523, 3.298776388168335]], Known param reward error: [[0.0, 0.09760853364531734, 0.008625642351791921], [0.09760853364531734, 0.0, 0.05719658420370927], [0.009179928488156982, 0.06765488226706512, 0.0]].
