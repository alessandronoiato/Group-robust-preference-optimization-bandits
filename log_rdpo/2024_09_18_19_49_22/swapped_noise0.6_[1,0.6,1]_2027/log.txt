2024-09-18 20:21:39,972 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log_rdpo/2024_09_18_19_49_22/swapped_noise0.6_[1,0.6,1]_2027
2024-09-18 20:21:39,974 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2027
2024-09-18 20:21:39,974 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-09-18 20:21:40,139 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.4811, l2 distance: 13.0261, acc: 0.81.
2024-09-18 20:21:40,139 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-18 20:21:40,140 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [6.28961974 4.34750067 6.93739929 3.90022049]
2024-09-18 20:21:40,351 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.5598, 3.7478, 3.1749
2024-09-18 20:21:40,587 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-18 20:21:41,938 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  17.0056, val_loss:  16.6458, grad_norm: 0.2441, live_grad: 0.0000, reward_err: 0.0775, 0.0051, 0.0412, KL_dist: 1.2775, 0.6938, 1.0247, param: [8.94848239 4.98504439 9.82879873 4.53218524], weights: [0.33316863 0.33310349 0.33372787], train_wt_loss:  51.0167, val_wt_loss: 49.9375, train_grp_loss: [20.06312124 14.41250233 15.47606377], val_grp_loss: [19.78577906 13.3597083  16.87029345], train_hist_grp_loss: [0.18045281 0.16089873 0.34816626], cur_train_grp_loss: [0.18045281 0.16089873 0.34816626], max_reward_err:  0.0775, max_reward_err_index: 0, max_kl_dist:  1.2775, max_kl_dist_index: 0, max_train_grp_loss:  20.0631, max_train_grp_loss_index: 0, max_val_grp_loss:  19.7858, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.3482, max_cur_train_grp_loss_index: 2, 
2024-09-18 20:21:46,448 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  99, train_loss:  17.0075, val_loss:  16.6351, grad_norm: 0.0068,  live_grad: 0.0000, reward_err: 0.0771, 0.0051, 0.0409, KL_dist: 1.3003, 0.7150, 1.0461, param: [8.99920064 5.07731702 9.9807187  4.64329848], weights: [0.32619032 0.31670072 0.35710896], train_wt_loss:  51.0225, val_wt_loss: 49.9052, train_grp_loss: [19.99116932 14.56039406 15.36452233], val_grp_loss: [19.71028775 13.49206132 16.77822252], train_hist_grp_loss: [15.9164754  12.96409685 24.9724666 ], cur_train_grp_loss: [0.15866591 0.12998949 0.24783345], max_reward_err:  0.0771, max_reward_err_index: 0, max_kl_dist:  1.3003, max_kl_dist_index: 0, max_train_grp_loss:  19.9912, max_train_grp_loss_index: 0, max_val_grp_loss:  19.7103, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2478, max_cur_train_grp_loss_index: 2, 
2024-09-18 20:21:46,672 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:387] - INFO: Policy parameter learned solely on the preference data rdpo: [8.99920064 5.07731702 9.9807187  4.64329848].
2024-09-18 20:21:47,006 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Uniform reward: 3.7506, 3.7506, 3.1231
2024-09-18 20:21:47,007 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Optimal reward: 3.7912, 3.7912, 3.2668
2024-09-18 20:21:47,007 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Policy reward: 3.4989, 3.7719, 3.1333
2024-09-18 20:21:47,008 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Reward Error: 0.0771, 0.0051, 0.0409
2024-09-18 20:21:47,697 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:416] - INFO: Optimal reward: 3.7912, 3.7912, 3.2668
Known param reward: [[3.791201591491699, 3.43137788772583, 3.2245421409606934], [3.43137788772583, 3.791201591491699, 3.0854053497314453], [3.751282215118408, 3.552793025970459, 3.2667675018310547]], Known param reward error: [[0.0, 0.0949102006533743, 0.012925731888386182], [0.0949102006533743, 0.0, 0.055517312449678204], [0.010529478691631431, 0.06288469757352977, 0.0]].
