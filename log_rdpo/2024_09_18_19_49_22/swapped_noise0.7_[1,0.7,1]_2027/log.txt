2024-09-18 20:18:00,302 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log_rdpo/2024_09_18_19_49_22/swapped_noise0.7_[1,0.7,1]_2027
2024-09-18 20:18:00,304 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2027
2024-09-18 20:18:00,304 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-09-18 20:18:00,464 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.4740, l2 distance: 14.0690, acc: 0.80.
2024-09-18 20:18:00,464 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-18 20:18:00,465 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [8.04817029 4.05673083 5.77693217 4.47787971]
2024-09-18 20:18:00,667 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.5225, 3.7577, 3.1520
2024-09-18 20:18:00,914 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-18 20:18:02,239 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  16.8293, val_loss:  16.6777, grad_norm: 0.2553, live_grad: 0.0000, reward_err: 0.0793, 0.0055, 0.0438, KL_dist: 1.3408, 0.7162, 1.0838, param: [10.74561038  4.70990722  8.28424035  4.95589219], weights: [0.33315335 0.33309473 0.33375192], train_wt_loss:  50.4879, val_wt_loss: 50.0332, train_grp_loss: [19.75396453 14.04517182 15.915067  ], val_grp_loss: [20.26731077 12.19970099 17.67739525], train_hist_grp_loss: [0.17803366 0.16043768 0.35754144], cur_train_grp_loss: [0.17803366 0.16043768 0.35754144], max_reward_err:  0.0793, max_reward_err_index: 0, max_kl_dist:  1.3408, max_kl_dist_index: 0, max_train_grp_loss:  19.7540, max_train_grp_loss_index: 0, max_val_grp_loss:  20.2673, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.3575, max_cur_train_grp_loss_index: 2, 
2024-09-18 20:18:06,722 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  99, train_loss:  16.8323, val_loss:  16.6739, grad_norm: 0.0078,  live_grad: 0.0000, reward_err: 0.0763, 0.0055, 0.0410, KL_dist: 1.3525, 0.7388, 1.0935, param: [10.63754481  4.82790971  8.62336885  5.04071576], weights: [0.32523868 0.31551937 0.35924196], train_wt_loss:  50.4969, val_wt_loss: 50.0217, train_grp_loss: [19.70570457 14.21052792 15.72891005], val_grp_loss: [20.21032944 12.34432263 17.57436752], train_hist_grp_loss: [15.68023619 12.64631253 25.62391934], cur_train_grp_loss: [0.15639835 0.12686395 0.25372285], max_reward_err:  0.0763, max_reward_err_index: 0, max_kl_dist:  1.3525, max_kl_dist_index: 0, max_train_grp_loss:  19.7057, max_train_grp_loss_index: 0, max_val_grp_loss:  20.2103, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2537, max_cur_train_grp_loss_index: 2, 
2024-09-18 20:18:06,949 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:387] - INFO: Policy parameter learned solely on the preference data rdpo: [10.63754481  4.82790971  8.62336885  5.04071576].
2024-09-18 20:18:07,295 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Uniform reward: 3.7599, 3.7599, 3.1348
2024-09-18 20:18:07,296 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Optimal reward: 3.8017, 3.8017, 3.2811
2024-09-18 20:18:07,297 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Policy reward: 3.5116, 3.7807, 3.1466
2024-09-18 20:18:07,297 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Reward Error: 0.0763, 0.0055, 0.0410
2024-09-18 20:18:08,020 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:416] - INFO: Optimal reward: 3.8017, 3.8017, 3.2811
Known param reward: [[3.8016552925109863, 3.4387340545654297, 3.238321304321289], [3.4387340545654297, 3.8016552925109863, 3.0975143909454346], [3.7612709999084473, 3.561779260635376, 3.281050205230713]], Known param reward error: [[0.0, 0.0954640044983794, 0.013022934193845799], [0.0954640044983794, 0.0, 0.055938130417109135], [0.010622818087187834, 0.06309778594291558, 0.0]].
