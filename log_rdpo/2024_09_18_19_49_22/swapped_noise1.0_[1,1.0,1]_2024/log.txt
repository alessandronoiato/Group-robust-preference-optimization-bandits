2024-09-18 20:06:13,176 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log_rdpo/2024_09_18_19_49_22/swapped_noise1.0_[1,1.0,1]_2024
2024-09-18 20:06:13,178 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2024
2024-09-18 20:06:13,178 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-09-18 20:06:13,345 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.3279, l2 distance: 34.1898, acc: 0.82.
2024-09-18 20:06:13,345 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-18 20:06:13,346 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [13.14701482  8.44873766 15.31760858  8.28786146]
2024-09-18 20:06:13,559 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.6625, 3.9176, 3.3293
2024-09-18 20:06:13,851 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-18 20:06:15,188 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  13.3407, val_loss:  14.1468, grad_norm: 0.2555, live_grad: 0.0000, reward_err: 0.0959, 0.0009, 0.0541, KL_dist: 2.0544, 1.1165, 1.6867, param: [10.88462629  4.83892943 14.16298328  4.9649163 ], weights: [0.33303926 0.3328212  0.33413954], train_wt_loss:  40.0221, val_wt_loss: 42.4404, train_grp_loss: [20.79863114  5.39401025 17.70235657], val_grp_loss: [19.76389286  5.76582879 16.97765976], train_hist_grp_loss: [0.17711935 0.1116226  0.50695119], cur_train_grp_loss: [0.17711935 0.1116226  0.50695119], max_reward_err:  0.0959, max_reward_err_index: 0, max_kl_dist:  2.0544, max_kl_dist_index: 0, max_train_grp_loss:  20.7986, max_train_grp_loss_index: 0, max_val_grp_loss:  19.7639, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.5070, max_cur_train_grp_loss_index: 2, 
2024-09-18 20:06:19,751 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  99, train_loss:  13.3573, val_loss:  14.1392, grad_norm: 0.0255,  live_grad: 0.0000, reward_err: 0.0929, 0.0018, 0.0517, KL_dist: 2.0404, 1.1324, 1.6828, param: [10.81146933  5.20253073 14.18942474  5.33644716], weights: [0.31480059 0.27694267 0.40825674], train_wt_loss:  40.0718, val_wt_loss: 42.4175, train_grp_loss: [20.51726408  5.76145563 17.43298819], val_grp_loss: [19.52129135  6.19401882 16.76740967], train_hist_grp_loss: [16.9452272   4.1323419  42.94091287], cur_train_grp_loss: [0.16819979 0.04202179 0.42526816], max_reward_err:  0.0929, max_reward_err_index: 0, max_kl_dist:  2.0404, max_kl_dist_index: 0, max_train_grp_loss:  20.5173, max_train_grp_loss_index: 0, max_val_grp_loss:  19.5213, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4253, max_cur_train_grp_loss_index: 2, 
2024-09-18 20:06:19,978 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:387] - INFO: Policy parameter learned solely on the preference data rdpo: [10.81146933  5.20253073 14.18942474  5.33644716].
2024-09-18 20:06:20,345 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Uniform reward: 3.9164, 3.9164, 3.3093
2024-09-18 20:06:20,346 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Optimal reward: 3.9575, 3.9575, 3.4535
2024-09-18 20:06:20,347 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Policy reward: 3.5897, 3.9505, 3.2749
2024-09-18 20:06:20,347 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Reward Error: 0.0929, 0.0018, 0.0517
2024-09-18 20:06:21,043 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:416] - INFO: Optimal reward: 3.9575, 3.9575, 3.4535
Known param reward: [[3.9575352668762207, 3.5510668754577637, 3.4159226417541504], [3.5510668754577637, 3.9575352668762207, 3.2513158321380615], [3.9158573150634766, 3.681488275527954, 3.453465223312378]], Known param reward error: [[0.0, 0.10270745906436166, 0.010870988740468253], [0.10270745906436166, 0.0, 0.058535232904539165], [0.010531290058633277, 0.06975225051276858, 0.0]].
