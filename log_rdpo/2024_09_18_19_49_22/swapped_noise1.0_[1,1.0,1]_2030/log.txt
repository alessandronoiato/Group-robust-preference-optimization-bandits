2024-09-18 20:08:18,949 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log_rdpo/2024_09_18_19_49_22/swapped_noise1.0_[1,1.0,1]_2030
2024-09-18 20:08:18,951 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2030
2024-09-18 20:08:18,951 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-09-18 20:08:19,118 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.3234, l2 distance: 29.0058, acc: 0.84.
2024-09-18 20:08:19,119 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-18 20:08:19,120 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [12.81511744  6.94562577 12.93366958  5.46843   ]
2024-09-18 20:08:19,336 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.5538, 3.8595, 3.2321
2024-09-18 20:08:19,626 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-18 20:08:20,979 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  12.8794, val_loss:  14.7460, grad_norm: 0.3330, live_grad: 0.0000, reward_err: 0.0996, 0.0003, 0.0571, KL_dist: 1.9698, 0.9837, 1.5773, param: [12.27904443  4.79015152 11.2958818   3.49617203], weights: [0.33319507 0.33285513 0.3339498 ], train_wt_loss:  38.6383, val_wt_loss: 44.2380, train_grp_loss: [21.04998389  5.19166821 17.63013306], val_grp_loss: [20.12097213  6.01864921 17.8530228 ], train_hist_grp_loss: [0.20934004 0.10726143 0.43559531], cur_train_grp_loss: [0.20934004 0.10726143 0.43559531], max_reward_err:  0.0996, max_reward_err_index: 0, max_kl_dist:  1.9698, max_kl_dist_index: 0, max_train_grp_loss:  21.0500, max_train_grp_loss_index: 0, max_val_grp_loss:  20.1210, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4356, max_cur_train_grp_loss_index: 2, 
2024-09-18 20:08:25,544 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  99, train_loss:  12.8977, val_loss:  14.7004, grad_norm: 0.0258,  live_grad: 0.0000, reward_err: 0.0945, 0.0007, 0.0528, KL_dist: 1.9494, 0.9996, 1.5673, param: [12.29084443  5.18784494 11.24218034  3.86281759], weights: [0.33002235 0.28188976 0.38808789], train_wt_loss:  38.6931, val_wt_loss: 44.1013, train_grp_loss: [20.75724978  5.5502932  17.32729358], val_grp_loss: [19.85240405  6.39446454 17.61699004], train_hist_grp_loss: [19.55515048  3.79072245 35.76229735], cur_train_grp_loss: [0.1940229  0.03851352 0.35368648], max_reward_err:  0.0945, max_reward_err_index: 0, max_kl_dist:  1.9494, max_kl_dist_index: 0, max_train_grp_loss:  20.7572, max_train_grp_loss_index: 0, max_val_grp_loss:  19.8524, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.3537, max_cur_train_grp_loss_index: 2, 
2024-09-18 20:08:25,773 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:387] - INFO: Policy parameter learned solely on the preference data rdpo: [12.29084443  5.18784494 11.24218034  3.86281759].
2024-09-18 20:08:26,120 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Uniform reward: 3.8314, 3.8314, 3.2209
2024-09-18 20:08:26,120 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Optimal reward: 3.8748, 3.8748, 3.3766
2024-09-18 20:08:26,121 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Policy reward: 3.5086, 3.8722, 3.1982
2024-09-18 20:08:26,121 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Reward Error: 0.0945, 0.0007, 0.0528
2024-09-18 20:08:26,823 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:416] - INFO: Optimal reward: 3.8748, 3.8748, 3.3766
Known param reward: [[3.874847650527954, 3.4763882160186768, 3.337296485900879], [3.4763882160186768, 3.874847650527954, 3.175377130508423], [3.8370981216430664, 3.5955355167388916, 3.3765645027160645]], Known param reward error: [[0.0, 0.102832284117025, 0.011629576980862906], [0.102832284117025, 0.0, 0.059583452958120335], [0.009742196929921686, 0.0720833846850742, 0.0]].
