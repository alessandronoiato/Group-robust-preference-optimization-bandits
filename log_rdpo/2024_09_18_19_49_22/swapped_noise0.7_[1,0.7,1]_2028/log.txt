2024-09-18 20:18:42,397 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log_rdpo/2024_09_18_19_49_22/swapped_noise0.7_[1,0.7,1]_2028
2024-09-18 20:18:42,399 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2028
2024-09-18 20:18:42,400 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-09-18 20:18:42,560 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.4872, l2 distance: 13.0978, acc: 0.77.
2024-09-18 20:18:42,560 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-18 20:18:42,561 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [6.46691538 3.95756071 6.43337544 5.0747662 ]
2024-09-18 20:18:42,762 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.6532, 3.8141, 3.2658
2024-09-18 20:18:43,013 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-18 20:18:44,326 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  17.3920, val_loss:  16.7249, grad_norm: 0.2512, live_grad: 0.0000, reward_err: 0.0668, 0.0123, 0.0328, KL_dist: 1.0577, 0.6844, 0.8558, param: [7.86594246 4.57694217 9.0716238  6.1749901 ], weights: [0.3331149  0.33306572 0.33381938], train_wt_loss:  52.1759, val_wt_loss: 50.1747, train_grp_loss: [20.84290069 13.38910619 17.45689535], val_grp_loss: [19.82179459 12.6631536  17.11622351], train_hist_grp_loss: [0.17572618 0.16096185 0.38698449], cur_train_grp_loss: [0.17572618 0.16096185 0.38698449], max_reward_err:  0.0668, max_reward_err_index: 0, max_kl_dist:  1.0577, max_kl_dist_index: 0, max_train_grp_loss:  20.8429, max_train_grp_loss_index: 0, max_val_grp_loss:  19.8218, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.3870, max_cur_train_grp_loss_index: 2, 
2024-09-18 20:18:48,775 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  99, train_loss:  17.3957, val_loss:  16.7142, grad_norm: 0.0105,  live_grad: 0.0000, reward_err: 0.0659, 0.0137, 0.0320, KL_dist: 1.0704, 0.7107, 0.8699, param: [8.00131993 4.7596934  9.08047488 6.33282213], weights: [0.3207387  0.30812569 0.37113561], train_wt_loss:  52.1872, val_wt_loss: 50.1427, train_grp_loss: [20.71209848 13.61713333 17.32305869], val_grp_loss: [19.7088667  12.88863197 16.99949276], train_hist_grp_loss: [15.99951112 11.98761211 30.59358633], cur_train_grp_loss: [0.15933425 0.12048366 0.30393811], max_reward_err:  0.0659, max_reward_err_index: 0, max_kl_dist:  1.0704, max_kl_dist_index: 0, max_train_grp_loss:  20.7121, max_train_grp_loss_index: 0, max_val_grp_loss:  19.7089, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.3039, max_cur_train_grp_loss_index: 2, 
2024-09-18 20:18:48,994 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:387] - INFO: Policy parameter learned solely on the preference data rdpo: [8.00131993 4.7596934  9.08047488 6.33282213].
2024-09-18 20:18:49,321 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Uniform reward: 3.8371, 3.8371, 3.2123
2024-09-18 20:18:49,322 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Optimal reward: 3.8741, 3.8741, 3.3487
2024-09-18 20:18:49,323 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Policy reward: 3.6190, 3.8212, 3.2416
2024-09-18 20:18:49,323 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Reward Error: 0.0659, 0.0137, 0.0320
2024-09-18 20:18:50,011 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:416] - INFO: Optimal reward: 3.8741, 3.8741, 3.3487
Known param reward: [[3.8741343021392822, 3.4676833152770996, 3.31387996673584], [3.4676833152770996, 3.8741343021392822, 3.1369452476501465], [3.840017557144165, 3.611396074295044, 3.3486669063568115]], Known param reward error: [[0.0, 0.10491401566480076, 0.010388294982380973], [0.10491401566480076, 0.0, 0.0632256550523886], [0.008806288665903515, 0.06781856470467615, 0.0]].
