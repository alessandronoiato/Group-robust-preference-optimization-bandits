2024-09-17 19:55:49,833 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:198] - INFO: Logging to log_rdpo/2024_09_17_19_54_26/swapped_noise0.8_[1,0.8,1]_2025
2024-09-17 19:55:49,835 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: (IB) Seed: 2025
2024-09-17 19:55:49,835 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Data: 300
2024-09-17 19:55:49,991 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:296] - INFO: MLE reward loss: 0.3985, l2 distance: 24.2772, acc: 0.81.
2024-09-17 19:55:49,992 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-17 19:55:49,992 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: MLE reward parameter: [10.86841933  4.80239218 11.99051813  3.51685172]
2024-09-17 19:55:50,193 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:313] - INFO: Learned oracle reward: 3.4933, 3.8668, 3.1227
2024-09-17 19:55:50,448 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-17 19:55:51,609 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  14.7356, val_loss:  15.9968, grad_norm: 0.2747, live_grad: 0.0000, reward_err: 0.1093, 0.0007, 0.0679, KL_dist: 2.1686, 1.1476, 1.7544, param: [12.41736831  4.01152021 13.06704515  2.83982044], weights: [0.33341622 0.33322597 0.33335782], train_wt_loss:  44.2069, val_wt_loss: 47.9905, train_grp_loss: [20.69305934  8.21995452 16.54135117], val_grp_loss: [21.54635465  9.43324921 16.97374424], train_hist_grp_loss: [0.23328762 0.17621022 0.21577063], cur_train_grp_loss: [0.23328762 0.17621022 0.21577063], max_reward_err:  0.1093, max_reward_err_index: 0, max_kl_dist:  2.1686, max_kl_dist_index: 0, max_train_grp_loss:  20.6931, max_train_grp_loss_index: 0, max_val_grp_loss:  21.5464, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2333, max_cur_train_grp_loss_index: 0, 
2024-09-17 19:55:55,841 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  99, train_loss:  14.7422, val_loss:  15.9288, grad_norm: 0.0123,  live_grad: 0.0000, reward_err: 0.1080, 0.0005, 0.0668, KL_dist: 2.1780, 1.1646, 1.7665, param: [12.42209739  4.24126318 13.21156266  3.0884257 ], weights: [0.35586311 0.30696733 0.33716956], train_wt_loss:  44.2266, val_wt_loss: 47.7865, train_grp_loss: [20.52809963  8.5145137  16.38107198], val_grp_loss: [21.37679184  9.56139734 16.81925152], train_hist_grp_loss: [22.41400589  7.63352546 17.01798695], cur_train_grp_loss: [0.22315025 0.07667804 0.16889418], max_reward_err:  0.1080, max_reward_err_index: 0, max_kl_dist:  2.1780, max_kl_dist_index: 0, max_train_grp_loss:  20.5281, max_train_grp_loss_index: 0, max_val_grp_loss:  21.3768, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2232, max_cur_train_grp_loss_index: 0, 
2024-09-17 19:55:56,059 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:386] - INFO: Policy parameter learned solely on the preference data rdpo: [12.42209739  4.24126318 13.21156266  3.0884257 ].
2024-09-17 19:55:56,370 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:397] - INFO: Uniform reward: 3.8283, 3.8283, 3.1728
2024-09-17 19:55:56,370 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Optimal reward: 3.8685, 3.8685, 3.3122
2024-09-17 19:55:56,371 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Policy reward: 3.4508, 3.8664, 3.0911
2024-09-17 19:55:56,371 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Reward Error: 0.1080, 0.0005, 0.0668
2024-09-17 19:55:57,009 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:415] - INFO: Optimal reward: 3.8685, 3.8685, 3.3122
Known param reward: [[3.8684823513031006, 3.4799795150756836, 3.271944284439087], [3.4799795150756836, 3.8684823513031006, 3.1135053634643555], [3.832144021987915, 3.6156766414642334, 3.312178611755371]], Known param reward error: [[0.0, 0.10042771323398944, 0.012147390594663916], [0.10042771323398944, 0.0, 0.059982649361328924], [0.009393432880195242, 0.06535010034457296, 0.0]].
