2024-09-17 19:56:47,621 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:198] - INFO: Logging to log_rdpo/2024_09_17_19_54_26/swapped_noise0.8_[1,0.8,1]_2028
2024-09-17 19:56:47,623 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: (IB) Seed: 2028
2024-09-17 19:56:47,624 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Data: 300
2024-09-17 19:56:47,784 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:296] - INFO: MLE reward loss: 0.4405, l2 distance: 22.8562, acc: 0.81.
2024-09-17 19:56:47,785 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-17 19:56:47,786 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: MLE reward parameter: [10.36401685  5.70809185 10.03667054  6.48371905]
2024-09-17 19:56:47,987 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:313] - INFO: Learned oracle reward: 3.5694, 3.7943, 3.1648
2024-09-17 19:56:48,234 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-17 19:56:49,409 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  16.4094, val_loss:  15.9531, grad_norm: 0.2667, live_grad: 0.0000, reward_err: 0.0883, 0.0022, 0.0491, KL_dist: 1.7564, 1.0422, 1.4459, param: [11.741345    5.05714488 11.33668941  5.67553798], weights: [0.3332567  0.33331671 0.33342659], train_wt_loss:  49.2281, val_wt_loss: 47.8593, train_grp_loss: [20.48371922 12.07400668 15.36911431], val_grp_loss: [18.80212517 11.76502613 16.86841223], train_hist_grp_loss: [0.19969728 0.21770345 0.2506617 ], cur_train_grp_loss: [0.19969728 0.21770345 0.2506617 ], max_reward_err:  0.0883, max_reward_err_index: 0, max_kl_dist:  1.7564, max_kl_dist_index: 0, max_train_grp_loss:  20.4837, max_train_grp_loss_index: 0, max_val_grp_loss:  18.8021, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2507, max_cur_train_grp_loss_index: 2, 
2024-09-17 19:56:53,723 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  99, train_loss:  16.4102, val_loss:  15.9658, grad_norm: 0.0040,  live_grad: 0.0000, reward_err: 0.0877, 0.0024, 0.0486, KL_dist: 1.7595, 1.0533, 1.4505, param: [11.73078271  5.1585624  11.38524083  5.77328205], weights: [0.33764306 0.32563382 0.33672312], train_wt_loss:  49.2307, val_wt_loss: 47.8975, train_grp_loss: [20.40955174 12.23779706 15.30695555], val_grp_loss: [18.73999788 11.9326834  16.81380407], train_hist_grp_loss: [17.21001031 13.58842812 16.93717746], cur_train_grp_loss: [0.171515   0.13595724 0.16821504], max_reward_err:  0.0877, max_reward_err_index: 0, max_kl_dist:  1.7595, max_kl_dist_index: 0, max_train_grp_loss:  20.4096, max_train_grp_loss_index: 0, max_val_grp_loss:  18.7400, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.1715, max_cur_train_grp_loss_index: 0, 
2024-09-17 19:56:53,958 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:386] - INFO: Policy parameter learned solely on the preference data rdpo: [11.73078271  5.1585624  11.38524083  5.77328205].
2024-09-17 19:56:54,281 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:397] - INFO: Uniform reward: 3.7884, 3.7884, 3.1384
2024-09-17 19:56:54,282 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Optimal reward: 3.8291, 3.8291, 3.2716
2024-09-17 19:56:54,282 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Policy reward: 3.4933, 3.8198, 3.1125
2024-09-17 19:56:54,283 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Reward Error: 0.0877, 0.0024, 0.0486
2024-09-17 19:56:54,953 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:415] - INFO: Optimal reward: 3.8291, 3.8291, 3.2716
Known param reward: [[3.8291401863098145, 3.4291751384735107, 3.2418317794799805], [3.4291751384735107, 3.8291401863098145, 3.0657341480255127], [3.792921543121338, 3.5639941692352295, 3.271582841873169]], Known param reward error: [[0.0, 0.10445296551593598, 0.00909378237726491], [0.10445296551593598, 0.0, 0.06292021440294511], [0.009458688224047728, 0.06924427003810199, 0.0]].
