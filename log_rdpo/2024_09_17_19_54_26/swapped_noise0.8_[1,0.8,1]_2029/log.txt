2024-09-17 19:57:06,841 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:198] - INFO: Logging to log_rdpo/2024_09_17_19_54_26/swapped_noise0.8_[1,0.8,1]_2029
2024-09-17 19:57:06,843 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: (IB) Seed: 2029
2024-09-17 19:57:06,844 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Data: 300
2024-09-17 19:57:07,004 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:296] - INFO: MLE reward loss: 0.4258, l2 distance: 19.9334, acc: 0.82.
2024-09-17 19:57:07,005 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-17 19:57:07,006 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: MLE reward parameter: [ 6.68259565  4.92300711 10.70711077  6.60526297]
2024-09-17 19:57:07,211 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:313] - INFO: Learned oracle reward: 3.5992, 3.8198, 3.2522
2024-09-17 19:57:07,475 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-17 19:57:08,664 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  15.6474, val_loss:  16.6361, grad_norm: 0.2184, live_grad: 0.0000, reward_err: 0.0992, 0.0167, 0.0629, KL_dist: 1.9049, 0.8780, 1.6302, param: [ 5.31280113  3.71718474 14.66769344  6.59427386], weights: [0.33345129 0.33314512 0.33340358], train_wt_loss:  46.9421, val_wt_loss: 49.9084, train_grp_loss: [19.83421676 11.25613208 16.57933276], val_grp_loss: [19.62502516 11.10070538 18.62684383], train_hist_grp_loss: [0.22988027 0.13801958 0.2155708 ], cur_train_grp_loss: [0.22988027 0.13801958 0.2155708 ], max_reward_err:  0.0992, max_reward_err_index: 0, max_kl_dist:  1.9049, max_kl_dist_index: 0, max_train_grp_loss:  19.8342, max_train_grp_loss_index: 0, max_val_grp_loss:  19.6250, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2299, max_cur_train_grp_loss_index: 0, 
2024-09-17 19:57:13,029 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  99, train_loss:  15.6512, val_loss:  16.6466, grad_norm: 0.0093,  live_grad: 0.0000, reward_err: 0.0975, 0.0180, 0.0617, KL_dist: 1.9192, 0.8991, 1.6484, param: [ 5.24074002  3.90099004 14.77013075  6.78042968], weights: [0.34947342 0.3140783  0.33644828], train_wt_loss:  46.9535, val_wt_loss: 49.9398, train_grp_loss: [19.69878423 11.48935429 16.4566162 ], val_grp_loss: [19.50606165 11.37501916 18.52958012], train_hist_grp_loss: [21.04891554 10.37039445 17.25060673], cur_train_grp_loss: [0.20957633 0.10442602 0.17143613], max_reward_err:  0.0975, max_reward_err_index: 0, max_kl_dist:  1.9192, max_kl_dist_index: 0, max_train_grp_loss:  19.6988, max_train_grp_loss_index: 0, max_val_grp_loss:  19.5061, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2096, max_cur_train_grp_loss_index: 0, 
2024-09-17 19:57:13,247 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:386] - INFO: Policy parameter learned solely on the preference data rdpo: [ 5.24074002  3.90099004 14.77013075  6.78042968].
2024-09-17 19:57:13,567 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:397] - INFO: Uniform reward: 3.8490, 3.8490, 3.2390
2024-09-17 19:57:13,568 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Optimal reward: 3.8955, 3.8955, 3.3866
2024-09-17 19:57:13,569 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Policy reward: 3.5156, 3.8256, 3.1776
2024-09-17 19:57:13,569 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Reward Error: 0.0975, 0.0180, 0.0617
2024-09-17 19:57:14,246 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:415] - INFO: Optimal reward: 3.8955, 3.8955, 3.3866
Known param reward: [[3.895524024963379, 3.484661340713501, 3.3502304553985596], [3.484661340713501, 3.895524024963379, 3.1791486740112305], [3.8603501319885254, 3.6147823333740234, 3.3865811824798584]], Known param reward error: [[0.0, 0.10547045317060787, 0.010733753340789734], [0.10547045317060787, 0.0, 0.06125130250583078], [0.009029309728152473, 0.07206776027828365, 0.0]].
