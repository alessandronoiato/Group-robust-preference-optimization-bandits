2024-09-17 19:56:28,185 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:198] - INFO: Logging to log_rdpo/2024_09_17_19_54_26/swapped_noise0.8_[1,0.8,1]_2027
2024-09-17 19:56:28,188 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: (IB) Seed: 2027
2024-09-17 19:56:28,188 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Data: 300
2024-09-17 19:56:28,348 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:296] - INFO: MLE reward loss: 0.3697, l2 distance: 34.3998, acc: 0.83.
2024-09-17 19:56:28,348 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-17 19:56:28,349 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: MLE reward parameter: [14.52683191  9.29124578 12.70755341 10.00412013]
2024-09-17 19:56:28,555 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:313] - INFO: Learned oracle reward: 3.6381, 3.7943, 3.2823
2024-09-17 19:56:28,804 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-17 19:56:29,988 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  15.2923, val_loss:  15.6034, grad_norm: 0.2719, live_grad: 0.0000, reward_err: 0.0860, 0.0042, 0.0459, KL_dist: 1.9034, 1.1064, 1.5692, param: [13.25312897  5.84866125 10.92804     5.83839118], weights: [0.33336233 0.33328417 0.3333535 ], train_wt_loss:  45.8768, val_wt_loss: 46.8103, train_grp_loss: [17.9822066  10.11168511 17.1177896 ], val_grp_loss: [18.7873471  11.45229188 16.63243868], train_hist_grp_loss: [0.21877232 0.19532472 0.21612223], cur_train_grp_loss: [0.21877232 0.19532472 0.21612223], max_reward_err:  0.0860, max_reward_err_index: 0, max_kl_dist:  1.9034, max_kl_dist_index: 0, max_train_grp_loss:  17.9822, max_train_grp_loss_index: 0, max_val_grp_loss:  18.7873, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2188, max_cur_train_grp_loss_index: 0, 
2024-09-17 19:56:34,309 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  99, train_loss:  15.2940, val_loss:  15.6312, grad_norm: 0.0056,  live_grad: 0.0000, reward_err: 0.0862, 0.0045, 0.0462, KL_dist: 1.9159, 1.1245, 1.5832, param: [13.37520921  5.97771341 10.9015304   5.97774171], weights: [0.34104532 0.32123262 0.33772205], train_wt_loss:  45.8821, val_wt_loss: 46.8935, train_grp_loss: [17.89187531 10.32232218 17.02973075], val_grp_loss: [18.69741517 11.7002761  16.5530017 ], train_hist_grp_loss: [17.29372708 11.30874233 16.31451196], cur_train_grp_loss: [0.17204593 0.11340837 0.16219629], max_reward_err:  0.0862, max_reward_err_index: 0, max_kl_dist:  1.9159, max_kl_dist_index: 0, max_train_grp_loss:  17.8919, max_train_grp_loss_index: 0, max_val_grp_loss:  18.6974, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.1720, max_cur_train_grp_loss_index: 0, 
2024-09-17 19:56:34,546 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:386] - INFO: Policy parameter learned solely on the preference data rdpo: [13.37520921  5.97771341 10.9015304   5.97774171].
2024-09-17 19:56:34,865 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:397] - INFO: Uniform reward: 3.8228, 3.8228, 3.2184
2024-09-17 19:56:34,866 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Optimal reward: 3.8669, 3.8669, 3.3658
2024-09-17 19:56:34,867 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Policy reward: 3.5336, 3.8495, 3.2102
2024-09-17 19:56:34,867 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Reward Error: 0.0862, 0.0045, 0.0462
2024-09-17 19:56:35,516 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:415] - INFO: Optimal reward: 3.8669, 3.8669, 3.3658
Known param reward: [[3.8669028282165527, 3.4664041996002197, 3.3253726959228516], [3.4664041996002197, 3.8669028282165527, 3.1640493869781494], [3.8246397972106934, 3.594559669494629, 3.3657867908477783]], Known param reward error: [[0.0, 0.10357090581483432, 0.012007324716711247], [0.10357090581483432, 0.0, 0.05993766581358977], [0.01092942669711497, 0.07042927397467878, 0.0]].
