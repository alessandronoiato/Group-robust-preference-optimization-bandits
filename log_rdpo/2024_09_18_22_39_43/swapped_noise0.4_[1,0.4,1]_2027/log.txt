2024-09-18 22:57:09,194 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log_rdpo/2024_09_18_22_39_43/swapped_noise0.4_[1,0.4,1]_2027
2024-09-18 22:57:09,196 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2027
2024-09-18 22:57:09,196 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-09-18 22:57:09,357 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.5246, l2 distance: 10.8519, acc: 0.78.
2024-09-18 22:57:09,357 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-18 22:57:09,358 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [5.8799585  2.6215873  6.27181202 2.45592119]
2024-09-18 22:57:09,563 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.4476, 3.7545, 3.0705
2024-09-18 22:57:09,815 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-18 22:57:11,159 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  18.1707, val_loss:  15.0968, grad_norm: 0.2286, live_grad: 0.0000, reward_err: 0.0902, 0.0004, 0.0533, KL_dist: 1.3892, 0.6756, 1.1033, param: [ 9.20097162  3.8289388  10.4733948   3.55387739], weights: [0.33309011 0.33324791 0.33366198], train_wt_loss:  54.5120, val_wt_loss: 45.2903, train_grp_loss: [18.70133958 17.59661455 18.12923423], val_grp_loss: [20.12678034  6.55584628 18.82532192], train_hist_grp_loss: [0.16476077 0.21212456 0.33629802], cur_train_grp_loss: [0.16476077 0.21212456 0.33629802], max_reward_err:  0.0902, max_reward_err_index: 0, max_kl_dist:  1.3892, max_kl_dist_index: 0, max_train_grp_loss:  18.7013, max_train_grp_loss_index: 0, max_val_grp_loss:  20.1268, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.3363, max_cur_train_grp_loss_index: 2, 
2024-09-18 22:57:15,621 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  100, train_loss:  18.1716, val_loss:  15.0538, grad_norm: 0.0045, live_grad: 0.0000, reward_err: 0.0888, 0.0004, 0.0521, KL_dist: 1.4016, 0.6895, 1.1150, param: [ 9.3067754   3.90852193 10.50711433  3.63731571], weights: [0.31581028 0.31895719 0.36523253], train_wt_loss:  54.5148, val_wt_loss: 45.1613, train_grp_loss: [18.63578551 17.71233117 18.05793813], val_grp_loss: [20.06850056  6.5540277  18.75541931], train_hist_grp_loss: [14.98177561 15.97329737 29.52103188], cur_train_grp_loss: [0.14790852 0.15813473 0.29126914], max_reward_err:  0.0888, max_reward_err_index: 0, max_kl_dist:  1.4016, max_kl_dist_index: 0, max_train_grp_loss:  18.6358, max_train_grp_loss_index: 0, max_val_grp_loss:  20.0685, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2913, max_cur_train_grp_loss_index: 2, 
2024-09-18 22:57:20,016 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  199, train_loss:  18.1748, val_loss:  15.0088, grad_norm: 0.0104,  live_grad: 0.0000, reward_err: 0.0879, 0.0005, 0.0512, KL_dist: 1.4153, 0.7049, 1.1279, param: [ 9.42122755  3.99586118 10.54454208  3.72899052], weights: [0.29819475 0.30449045 0.3973148 ], train_wt_loss:  54.5243, val_wt_loss: 45.0264, train_grp_loss: [18.56427127 17.84425258 17.98021631], val_grp_loss: [20.00473567  6.55780406 18.67920213], train_hist_grp_loss: [29.59680618 31.68609893 58.29501735], cur_train_grp_loss: [0.14734149 0.15931095 0.29001674], max_reward_err:  0.0879, max_reward_err_index: 0, max_kl_dist:  1.4153, max_kl_dist_index: 0, max_train_grp_loss:  18.5643, max_train_grp_loss_index: 0, max_val_grp_loss:  20.0047, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2900, max_cur_train_grp_loss_index: 2, 
2024-09-18 22:57:20,238 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:387] - INFO: Policy parameter learned solely on the preference data rdpo: [ 9.42122755  3.99586118 10.54454208  3.72899052].
2024-09-18 22:57:20,571 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Uniform reward: 3.7233, 3.7233, 3.0838
2024-09-18 22:57:20,572 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Optimal reward: 3.7611, 3.7611, 3.2220
2024-09-18 22:57:20,573 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Policy reward: 3.4304, 3.7590, 3.0569
2024-09-18 22:57:20,573 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Reward Error: 0.0879, 0.0005, 0.0512
2024-09-18 22:57:21,250 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:416] - INFO: Optimal reward: 3.7611, 3.7611, 3.2220
Known param reward: [[3.761061906814575, 3.4177727699279785, 3.179455518722534], [3.4177727699279785, 3.761061906814575, 3.04893159866333], [3.7224037647247314, 3.5345420837402344, 3.2219769954681396]], Known param reward error: [[0.0, 0.0912745244274229, 0.01319732474980855], [0.0912745244274229, 0.0, 0.0537078312626707], [0.010278517888737756, 0.06022762418877369, 0.0]].
