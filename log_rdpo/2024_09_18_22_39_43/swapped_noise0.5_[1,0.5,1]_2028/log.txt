2024-09-18 22:53:22,969 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log_rdpo/2024_09_18_22_39_43/swapped_noise0.5_[1,0.5,1]_2028
2024-09-18 22:53:22,970 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2028
2024-09-18 22:53:22,971 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-09-18 22:53:23,133 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.5129, l2 distance: 11.5183, acc: 0.77.
2024-09-18 22:53:23,134 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-18 22:53:23,135 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [4.82968347 2.91674126 7.37770799 3.19335816]
2024-09-18 22:53:23,341 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.5266, 3.8458, 3.1653
2024-09-18 22:53:23,593 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-18 22:53:24,938 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  17.9187, val_loss:  15.2401, grad_norm: 0.1716, live_grad: 0.0000, reward_err: 0.1002, 0.0029, 0.0643, KL_dist: 1.4419, 0.6170, 1.1808, param: [ 6.31417529  3.59501125 12.05762224  4.17989534], weights: [0.33312354 0.33308428 0.33379218], train_wt_loss:  53.7562, val_wt_loss: 45.7203, train_grp_loss: [21.13257266 14.34540595 17.67296795], val_grp_loss: [20.20870571  7.03011164 17.59656958], train_hist_grp_loss: [0.16877124 0.15698674 0.36928753], cur_train_grp_loss: [0.16877124 0.15698674 0.36928753], max_reward_err:  0.1002, max_reward_err_index: 0, max_kl_dist:  1.4419, max_kl_dist_index: 0, max_train_grp_loss:  21.1326, max_train_grp_loss_index: 0, max_val_grp_loss:  20.2087, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.3693, max_cur_train_grp_loss_index: 2, 
2024-09-18 22:53:29,419 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  100, train_loss:  17.9222, val_loss:  15.2001, grad_norm: 0.0097, live_grad: 0.0000, reward_err: 0.0995, 0.0034, 0.0640, KL_dist: 1.4684, 0.6374, 1.2084, param: [ 6.27442636  3.74604622 12.24418863  4.34255629], weights: [0.31983591 0.30901637 0.37114773], train_wt_loss:  53.7665, val_wt_loss: 45.6004, train_grp_loss: [21.01865759 14.55243467 17.54030852], val_grp_loss: [20.10894772  7.12757967 17.49087348], train_hist_grp_loss: [16.38169709 12.94031344 31.26090686], cur_train_grp_loss: [0.16169103 0.12876282 0.30774895], max_reward_err:  0.0995, max_reward_err_index: 0, max_kl_dist:  1.4684, max_kl_dist_index: 0, max_train_grp_loss:  21.0187, max_train_grp_loss_index: 0, max_val_grp_loss:  20.1089, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.3077, max_cur_train_grp_loss_index: 2, 
2024-09-18 22:53:33,825 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  199, train_loss:  17.9333, val_loss:  15.1610, grad_norm: 0.0222,  live_grad: 0.0000, reward_err: 0.0986, 0.0046, 0.0637, KL_dist: 1.4989, 0.6607, 1.2399, param: [ 6.23781958  3.90759218 12.44991842  4.51628065], weights: [0.30520335 0.28584628 0.40895038], train_wt_loss:  53.8000, val_wt_loss: 45.4829, train_grp_loss: [20.89855674 14.7920385  17.39810167], val_grp_loss: [20.00302013  7.24358556 17.37656036], train_hist_grp_loss: [32.34340565 25.79099634 61.60496186], cur_train_grp_loss: [0.16076774 0.13087991 0.30525599], max_reward_err:  0.0986, max_reward_err_index: 0, max_kl_dist:  1.4989, max_kl_dist_index: 0, max_train_grp_loss:  20.8986, max_train_grp_loss_index: 0, max_val_grp_loss:  20.0030, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.3053, max_cur_train_grp_loss_index: 2, 
2024-09-18 22:53:34,046 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:387] - INFO: Policy parameter learned solely on the preference data rdpo: [ 6.23781958  3.90759218 12.44991842  4.51628065].
2024-09-18 22:53:34,376 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Uniform reward: 3.8289, 3.8289, 3.2018
2024-09-18 22:53:34,377 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Optimal reward: 3.8652, 3.8652, 3.3372
2024-09-18 22:53:34,377 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Policy reward: 3.4840, 3.8474, 3.1247
2024-09-18 22:53:34,378 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Reward Error: 0.0986, 0.0046, 0.0637
2024-09-18 22:53:35,059 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:416] - INFO: Optimal reward: 3.8652, 3.8652, 3.3372
Known param reward: [[3.8651840686798096, 3.4605093002319336, 3.3015952110290527], [3.4605093002319336, 3.8651840686798096, 3.1258203983306885], [3.8319525718688965, 3.6041877269744873, 3.337219715118408]], Known param reward error: [[0.0, 0.10469741188447372, 0.010674905199669023], [0.10469741188447372, 0.0, 0.0633459390851702], [0.00859764922457202, 0.06752494501367125, 0.0]].
