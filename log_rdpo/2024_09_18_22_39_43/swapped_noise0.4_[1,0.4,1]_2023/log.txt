2024-09-18 22:55:29,170 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log_rdpo/2024_09_18_22_39_43/swapped_noise0.4_[1,0.4,1]_2023
2024-09-18 22:55:29,172 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2023
2024-09-18 22:55:29,172 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-09-18 22:55:29,333 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.4814, l2 distance: 15.1900, acc: 0.79.
2024-09-18 22:55:29,334 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-18 22:55:29,335 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [9.60038822 4.4139189  4.42858643 3.54905581]
2024-09-18 22:55:29,544 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.4934, 3.8064, 3.1099
2024-09-18 22:55:29,791 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-18 22:55:31,122 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  16.8408, val_loss:  15.3233, grad_norm: 0.2493, live_grad: 0.0000, reward_err: 0.1070, 0.0104, 0.0725, KL_dist: 1.9887, 0.8462, 1.7191, param: [15.24459463  5.52958108  5.06281398  4.02606764], weights: [0.3330268  0.33307629 0.33389692], train_wt_loss:  50.5223, val_wt_loss: 45.9700, train_grp_loss: [18.32873101 15.2173133  16.83597804], val_grp_loss: [20.74790833  7.24180997 17.96078599], train_hist_grp_loss: [0.17145292 0.18631303 0.43238939], cur_train_grp_loss: [0.17145292 0.18631303 0.43238939], max_reward_err:  0.1070, max_reward_err_index: 0, max_kl_dist:  1.9887, max_kl_dist_index: 0, max_train_grp_loss:  18.3287, max_train_grp_loss_index: 0, max_val_grp_loss:  20.7479, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4324, max_cur_train_grp_loss_index: 2, 
2024-09-18 22:55:35,698 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  100, train_loss:  16.8435, val_loss:  15.2862, grad_norm: 0.0081, live_grad: 0.0000, reward_err: 0.1058, 0.0109, 0.0713, KL_dist: 2.0010, 0.8724, 1.7314, param: [15.31876041  5.70683667  5.19010956  4.15657169], weights: [0.31263794 0.30896228 0.37839978], train_wt_loss:  50.5306, val_wt_loss: 45.8586, train_grp_loss: [18.21978081 15.39911387 16.70584603], val_grp_loss: [20.63131734  7.37557776 17.8359436 ], train_hist_grp_loss: [14.22979805 13.04713955 33.32034544], cur_train_grp_loss: [0.14016103 0.12938753 0.32759265], max_reward_err:  0.1058, max_reward_err_index: 0, max_kl_dist:  2.0010, max_kl_dist_index: 0, max_train_grp_loss:  18.2198, max_train_grp_loss_index: 0, max_val_grp_loss:  20.6313, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.3276, max_cur_train_grp_loss_index: 2, 
2024-09-18 22:55:40,122 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  199, train_loss:  16.8532, val_loss:  15.2509, grad_norm: 0.0192,  live_grad: 0.0000, reward_err: 0.1052, 0.0111, 0.0708, KL_dist: 2.0150, 0.9023, 1.7454, param: [15.40033572  5.90553294  5.33578899  4.30190825], weights: [0.29113514 0.28504198 0.42382288], train_wt_loss:  50.5595, val_wt_loss: 45.7528, train_grp_loss: [18.09903877 15.61720488 16.56122855], val_grp_loss: [20.50141252  7.54328112 17.69669742], train_hist_grp_loss: [28.06019342 25.94508612 65.61300333], cur_train_grp_loss: [0.13923327 0.1312167  0.32476021], max_reward_err:  0.1052, max_reward_err_index: 0, max_kl_dist:  2.0150, max_kl_dist_index: 0, max_train_grp_loss:  18.0990, max_train_grp_loss_index: 0, max_val_grp_loss:  20.5014, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.3248, max_cur_train_grp_loss_index: 2, 
2024-09-18 22:55:40,351 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:387] - INFO: Policy parameter learned solely on the preference data rdpo: [15.40033572  5.90553294  5.33578899  4.30190825].
2024-09-18 22:55:40,693 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Uniform reward: 3.8122, 3.8122, 3.1725
2024-09-18 22:55:40,694 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Optimal reward: 3.8527, 3.8527, 3.3024
2024-09-18 22:55:40,694 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Policy reward: 3.4474, 3.8100, 3.0685
2024-09-18 22:55:40,695 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Reward Error: 0.1052, 0.0111, 0.0708
2024-09-18 22:55:41,391 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:416] - INFO: Optimal reward: 3.8527, 3.8527, 3.3024
Known param reward: [[3.852689266204834, 3.475465774536133, 3.27390193939209], [3.475465774536133, 3.852689266204834, 3.1151528358459473], [3.8164188861846924, 3.5882885456085205, 3.3024346828460693]], Known param reward error: [[0.0, 0.09791173531113566, 0.008639911518065122], [0.09791173531113566, 0.0, 0.0567102350193103], [0.00941430193664968, 0.06862757474774667, 0.0]].
