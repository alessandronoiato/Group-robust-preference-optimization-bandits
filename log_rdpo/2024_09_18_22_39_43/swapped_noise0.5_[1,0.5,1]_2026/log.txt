2024-09-18 22:52:33,698 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log_rdpo/2024_09_18_22_39_43/swapped_noise0.5_[1,0.5,1]_2026
2024-09-18 22:52:33,700 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2026
2024-09-18 22:52:33,700 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-09-18 22:52:33,863 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.5028, l2 distance: 11.6904, acc: 0.77.
2024-09-18 22:52:33,864 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-18 22:52:33,865 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [6.16271418 4.47849874 6.01550773 3.20945473]
2024-09-18 22:52:34,071 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.6186, 3.8173, 3.2213
2024-09-18 22:52:34,327 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-18 22:52:35,630 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  17.6861, val_loss:  15.3843, grad_norm: 0.2213, live_grad: 0.0000, reward_err: 0.0762, 0.0107, 0.0374, KL_dist: 1.1135, 0.6401, 0.8977, param: [9.65614393 5.69954668 7.75663894 4.07787372], weights: [0.33296437 0.33302362 0.33401201], train_wt_loss:  53.0582, val_wt_loss: 46.1530, train_grp_loss: [19.83021001 14.60513013 18.92904103], val_grp_loss: [18.1964404   8.50410731 18.67569838], train_hist_grp_loss: [0.15871384 0.17650935 0.47286135], cur_train_grp_loss: [0.15871384 0.17650935 0.47286135], max_reward_err:  0.0762, max_reward_err_index: 0, max_kl_dist:  1.1135, max_kl_dist_index: 0, max_train_grp_loss:  19.8302, max_train_grp_loss_index: 0, max_val_grp_loss:  18.6757, max_val_grp_loss_index: 2, max_cur_train_grp_loss:  0.4729, max_cur_train_grp_loss_index: 2, 
2024-09-18 22:52:40,111 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  100, train_loss:  17.6895, val_loss:  15.3528, grad_norm: 0.0098, live_grad: 0.0000, reward_err: 0.0780, 0.0116, 0.0393, KL_dist: 1.1433, 0.6654, 0.9273, param: [9.95059459 5.85339058 7.6478489  4.20153835], weights: [0.30457296 0.29990919 0.39551785], train_wt_loss:  53.0685, val_wt_loss: 46.0584, train_grp_loss: [19.72993169 14.78443029 18.80654572], val_grp_loss: [18.10690517  8.60779269 18.58234842], train_hist_grp_loss: [14.49346274 12.95037185 40.62198914], cur_train_grp_loss: [0.1429784  0.12854253 0.40016751], max_reward_err:  0.0780, max_reward_err_index: 0, max_kl_dist:  1.1433, max_kl_dist_index: 0, max_train_grp_loss:  19.7299, max_train_grp_loss_index: 0, max_val_grp_loss:  18.5823, max_val_grp_loss_index: 2, max_cur_train_grp_loss:  0.4002, max_cur_train_grp_loss_index: 2, 
2024-09-18 22:52:44,508 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  199, train_loss:  17.7023, val_loss:  15.3187, grad_norm: 0.0251,  live_grad: 0.0000, reward_err: 0.0809, 0.0132, 0.0422, KL_dist: 1.1808, 0.6966, 0.9646, param: [10.2842089   6.03941015  7.54291372  4.34802854], weights: [0.274317   0.26664934 0.45903367], train_wt_loss:  53.1068, val_wt_loss: 45.9561, train_grp_loss: [19.61300433 15.01633181 18.66394025], val_grp_loss: [17.99839158  8.74535794 18.47050057], train_hist_grp_loss: [28.60715549 25.77216446 80.09107567], cur_train_grp_loss: [0.14213248 0.13055358 0.39713821], max_reward_err:  0.0809, max_reward_err_index: 0, max_kl_dist:  1.1808, max_kl_dist_index: 0, max_train_grp_loss:  19.6130, max_train_grp_loss_index: 0, max_val_grp_loss:  18.4705, max_val_grp_loss_index: 2, max_cur_train_grp_loss:  0.3971, max_cur_train_grp_loss_index: 2, 
2024-09-18 22:52:44,729 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:387] - INFO: Policy parameter learned solely on the preference data rdpo: [10.2842089   6.03941015  7.54291372  4.34802854].
2024-09-18 22:52:45,060 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Uniform reward: 3.8450, 3.8450, 3.2027
2024-09-18 22:52:45,061 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Optimal reward: 3.8809, 3.8809, 3.3197
2024-09-18 22:52:45,062 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Policy reward: 3.5670, 3.8297, 3.1795
2024-09-18 22:52:45,062 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Reward Error: 0.0809, 0.0132, 0.0422
2024-09-18 22:52:45,742 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:416] - INFO: Optimal reward: 3.8809, 3.8809, 3.3197
Known param reward: [[3.880918025970459, 3.483751058578491, 3.287625551223755], [3.483751058578491, 3.880918025970459, 3.126237392425537], [3.8381175994873047, 3.608170986175537, 3.319674015045166]], Known param reward error: [[0.0, 0.10233840672083058, 0.009654099672486998], [0.10233840672083058, 0.0, 0.05826976436329309], [0.011028428376157638, 0.07027900047611002, 0.0]].
