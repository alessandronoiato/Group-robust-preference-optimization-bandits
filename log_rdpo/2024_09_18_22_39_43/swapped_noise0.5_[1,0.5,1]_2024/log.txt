2024-09-18 22:51:44,679 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log_rdpo/2024_09_18_22_39_43/swapped_noise0.5_[1,0.5,1]_2024
2024-09-18 22:51:44,681 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2024
2024-09-18 22:51:44,681 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-09-18 22:51:44,842 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.5287, l2 distance: 9.4697, acc: 0.77.
2024-09-18 22:51:44,843 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-18 22:51:44,843 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [5.62552404 3.20254866 5.14111836 2.94602878]
2024-09-18 22:51:45,051 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.6390, 3.8946, 3.2918
2024-09-18 22:51:45,304 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-18 22:51:46,602 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  18.3684, val_loss:  14.8281, grad_norm: 0.2627, live_grad: 0.0000, reward_err: 0.0857, 0.0042, 0.0448, KL_dist: 1.1210, 0.5621, 0.8828, param: [9.11374525 4.34179291 8.30983896 4.25196818], weights: [0.33295   0.3328796 0.3341704], train_wt_loss:  55.1053, val_wt_loss: 44.4842, train_grp_loss: [20.72785287 16.40133896 17.92067654], val_grp_loss: [19.07086348  7.03986889 18.31123055], train_hist_grp_loss: [0.18527707 0.16412925 0.55114659], cur_train_grp_loss: [0.18527707 0.16412925 0.55114659], max_reward_err:  0.0857, max_reward_err_index: 0, max_kl_dist:  1.1210, max_kl_dist_index: 0, max_train_grp_loss:  20.7279, max_train_grp_loss_index: 0, max_val_grp_loss:  19.0709, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.5511, max_cur_train_grp_loss_index: 2, 
2024-09-18 22:51:51,090 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  100, train_loss:  18.3767, val_loss:  14.7015, grad_norm: 0.0149, live_grad: 0.0000, reward_err: 0.0825, 0.0044, 0.0419, KL_dist: 1.1453, 0.5960, 0.9064, param: [8.91963059 4.55292009 8.82263697 4.43596394], weights: [0.30671891 0.29208829 0.4011928 ], train_wt_loss:  55.1300, val_wt_loss: 44.1044, train_grp_loss: [20.55822083 16.64707464 17.66460114], val_grp_loss: [18.89798482  7.03411487 18.11206634], train_hist_grp_loss: [17.10799787 12.22043745 43.95903518], cur_train_grp_loss: [0.16852482 0.1214909  0.43091126], max_reward_err:  0.0825, max_reward_err_index: 0, max_kl_dist:  1.1453, max_kl_dist_index: 0, max_train_grp_loss:  20.5582, max_train_grp_loss_index: 0, max_val_grp_loss:  18.8980, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4309, max_cur_train_grp_loss_index: 2, 
2024-09-18 22:51:55,487 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  199, train_loss:  18.4070, val_loss:  14.5634, grad_norm: 0.0381,  live_grad: 0.0000, reward_err: 0.0788, 0.0049, 0.0391, KL_dist: 1.1858, 0.6387, 0.9456, param: [8.72512672 4.80035233 9.41651784 4.65291533], weights: [0.27761905 0.25282493 0.46955603], train_wt_loss:  55.2210, val_wt_loss: 43.6903, train_grp_loss: [20.36793678 16.97095031 17.370417  ], val_grp_loss: [18.70027716  7.04950482 17.88264795], train_hist_grp_loss: [33.71560156 24.36034366 86.26938023], cur_train_grp_loss: [0.16696699 0.12384813 0.42374629], max_reward_err:  0.0788, max_reward_err_index: 0, max_kl_dist:  1.1858, max_kl_dist_index: 0, max_train_grp_loss:  20.3679, max_train_grp_loss_index: 0, max_val_grp_loss:  18.7003, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4237, max_cur_train_grp_loss_index: 2, 
2024-09-18 22:51:55,711 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:387] - INFO: Policy parameter learned solely on the preference data rdpo: [8.72512672 4.80035233 9.41651784 4.65291533].
2024-09-18 22:51:56,046 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Uniform reward: 3.8883, 3.8883, 3.2742
2024-09-18 22:51:56,047 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Optimal reward: 3.9280, 3.9280, 3.4116
2024-09-18 22:51:56,047 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Policy reward: 3.6184, 3.9088, 3.2783
2024-09-18 22:51:56,048 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Reward Error: 0.0788, 0.0049, 0.0391
2024-09-18 22:51:56,734 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:416] - INFO: Optimal reward: 3.9280, 3.9280, 3.4116
Known param reward: [[3.927974224090576, 3.5139124393463135, 3.376384735107422], [3.5139124393463135, 3.927974224090576, 3.203280210494995], [3.887371301651001, 3.6481499671936035, 3.4115631580352783]], Known param reward error: [[0.0, 0.10541356972374948, 0.010311526211965462], [0.10541356972374948, 0.0, 0.061052056752844495], [0.010336860713228275, 0.07123882208309525, 0.0]].
