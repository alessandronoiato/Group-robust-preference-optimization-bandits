2024-09-18 22:51:17,180 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log_rdpo/2024_09_18_22_39_43/swapped_noise0.5_[1,0.5,1]_2023
2024-09-18 22:51:17,182 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2023
2024-09-18 22:51:17,183 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-09-18 22:51:17,350 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.4750, l2 distance: 15.0966, acc: 0.80.
2024-09-18 22:51:17,351 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-18 22:51:17,351 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [7.10196517 3.46007026 7.96069143 4.63730604]
2024-09-18 22:51:17,563 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.5018, 3.7549, 3.0914
2024-09-18 22:51:17,820 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-18 22:51:19,866 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  16.7634, val_loss:  14.2369, grad_norm: 0.2888, live_grad: 0.0000, reward_err: 0.0931, 0.0026, 0.0544, KL_dist: 1.5547, 0.8222, 1.2747, param: [ 8.57267418  3.99074137 12.11960871  5.13465062], weights: [0.33305337 0.33296656 0.33398007], train_wt_loss:  50.2903, val_wt_loss: 42.7106, train_grp_loss: [19.74256517 12.92839325 18.11791085], val_grp_loss: [19.94042623  6.04741029 17.18892763], train_hist_grp_loss: [0.18566367 0.15959376 0.46352222], cur_train_grp_loss: [0.18566367 0.15959376 0.46352222], max_reward_err:  0.0931, max_reward_err_index: 0, max_kl_dist:  1.5547, max_kl_dist_index: 0, max_train_grp_loss:  19.7426, max_train_grp_loss_index: 0, max_val_grp_loss:  19.9404, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4635, max_cur_train_grp_loss_index: 2, 
2024-09-18 22:51:24,382 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  100, train_loss:  16.7692, val_loss:  14.1980, grad_norm: 0.0125, live_grad: 0.0000, reward_err: 0.0899, 0.0032, 0.0515, KL_dist: 1.5653, 0.8506, 1.2872, param: [ 8.73451005  4.23004923 12.13734587  5.35466056], weights: [0.3138037  0.30095767 0.38523863], train_wt_loss:  50.3075, val_wt_loss: 42.5940, train_grp_loss: [19.57901458 13.19739338 17.94098353], val_grp_loss: [19.78001516  6.24675611 17.02306097], train_hist_grp_loss: [15.31121466 11.13141514 35.82074678], cur_train_grp_loss: [0.15062113 0.11087723 0.35182087], max_reward_err:  0.0899, max_reward_err_index: 0, max_kl_dist:  1.5653, max_kl_dist_index: 0, max_train_grp_loss:  19.5790, max_train_grp_loss_index: 0, max_val_grp_loss:  19.7800, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.3518, max_cur_train_grp_loss_index: 2, 
2024-09-18 22:51:28,795 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  199, train_loss:  16.7892, val_loss:  14.1664, grad_norm: 0.0301,  live_grad: 0.0000, reward_err: 0.0881, 0.0043, 0.0498, KL_dist: 1.5787, 0.8842, 1.3027, param: [ 8.92503534  4.49799564 12.15457656  5.60270793], weights: [0.29236803 0.27012945 0.43750252], train_wt_loss:  50.3675, val_wt_loss: 42.4991, train_grp_loss: [19.39731988 13.53106339 17.74324011], val_grp_loss: [19.60138631  6.50409325 16.83700378], train_hist_grp_loss: [30.1541942  22.2429843  70.46110073], cur_train_grp_loss: [0.14922506 0.11367485 0.3479481 ], max_reward_err:  0.0881, max_reward_err_index: 0, max_kl_dist:  1.5787, max_kl_dist_index: 0, max_train_grp_loss:  19.3973, max_train_grp_loss_index: 0, max_val_grp_loss:  19.6014, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.3479, max_cur_train_grp_loss_index: 2, 
2024-09-18 22:51:29,019 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:387] - INFO: Policy parameter learned solely on the preference data rdpo: [ 8.92503534  4.49799564 12.15457656  5.60270793].
2024-09-18 22:51:29,350 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Uniform reward: 3.7532, 3.7532, 3.0951
2024-09-18 22:51:29,351 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Optimal reward: 3.7840, 3.7840, 3.2107
2024-09-18 22:51:29,351 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Policy reward: 3.4508, 3.7679, 3.0510
2024-09-18 22:51:29,352 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Reward Error: 0.0881, 0.0043, 0.0498
2024-09-18 22:51:30,047 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:416] - INFO: Optimal reward: 3.7840, 3.7840, 3.2107
Known param reward: [[3.784027576446533, 3.406392812728882, 3.1765923500061035], [3.406392812728882, 3.784027576446533, 3.023632764816284], [3.743748664855957, 3.5277538299560547, 3.210723400115967]], Known param reward error: [[0.0, 0.09979704325312472, 0.010630330257857316], [0.09979704325312472, 0.0, 0.058270555256465], [0.010644455088353476, 0.06772512655183595, 0.0]].
