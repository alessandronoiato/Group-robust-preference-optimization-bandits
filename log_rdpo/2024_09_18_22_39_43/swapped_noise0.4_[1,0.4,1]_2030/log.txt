2024-09-18 22:58:20,820 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log_rdpo/2024_09_18_22_39_43/swapped_noise0.4_[1,0.4,1]_2030
2024-09-18 22:58:20,822 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2030
2024-09-18 22:58:20,823 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-09-18 22:58:20,984 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.4711, l2 distance: 12.8291, acc: 0.77.
2024-09-18 22:58:20,984 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-18 22:58:20,985 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [3.6833524  4.41691365 8.37422007 3.00526584]
2024-09-18 22:58:21,199 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.4800, 3.8293, 3.1678
2024-09-18 22:58:21,463 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-18 22:58:22,777 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  16.5501, val_loss:  15.4726, grad_norm: 0.2942, live_grad: 0.0000, reward_err: 0.1131, 0.0060, 0.0738, KL_dist: 1.4404, 0.5582, 1.1790, param: [ 4.82230457  4.98793881 11.97114006  3.59090782], weights: [0.3331596  0.33286963 0.33397077], train_wt_loss:  49.6503, val_wt_loss: 46.4179, train_grp_loss: [20.26978601 12.43884082 20.50960323], val_grp_loss: [19.49089035  7.81971867 18.72952898], train_hist_grp_loss: [0.21928439 0.13221    0.46246492], cur_train_grp_loss: [0.21928439 0.13221    0.46246492], max_reward_err:  0.1131, max_reward_err_index: 0, max_kl_dist:  1.4404, max_kl_dist_index: 0, max_train_grp_loss:  20.5096, max_train_grp_loss_index: 2, max_val_grp_loss:  19.4909, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4625, max_cur_train_grp_loss_index: 2, 
2024-09-18 22:58:27,309 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  100, train_loss:  16.5658, val_loss:  15.3573, grad_norm: 0.0217, live_grad: 0.0000, reward_err: 0.1073, 0.0078, 0.0679, KL_dist: 1.3613, 0.5903, 1.1064, param: [ 5.39470289  5.29017393 11.5011001   3.89471443], weights: [0.31649643 0.28575601 0.39774756], train_wt_loss:  49.6975, val_wt_loss: 46.0720, train_grp_loss: [20.09312001 12.73554065 20.11969735], val_grp_loss: [19.25407718  8.01498658 18.43328414], train_hist_grp_loss: [19.08338488  8.86602326 41.93394287], cur_train_grp_loss: [0.18780395 0.08841672 0.41069099], max_reward_err:  0.1073, max_reward_err_index: 0, max_kl_dist:  1.3613, max_kl_dist_index: 0, max_train_grp_loss:  20.1197, max_train_grp_loss_index: 2, max_val_grp_loss:  19.2541, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4107, max_cur_train_grp_loss_index: 2, 
2024-09-18 22:58:31,750 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  199, train_loss:  16.6235, val_loss:  15.2512, grad_norm: 0.0552,  live_grad: 0.0000, reward_err: 0.0977, 0.0095, 0.0581, KL_dist: 1.2907, 0.6341, 1.0434, param: [ 6.02799158  5.64822334 10.99825143  4.2614745 ], weights: [0.29570478 0.2425212  0.46177402], train_wt_loss:  49.8706, val_wt_loss: 45.7537, train_grp_loss: [19.88999689 13.15557206 19.68223376], val_grp_loss: [18.9826987   8.31298788 18.10016324], train_hist_grp_loss: [37.58348336 17.75623977 82.15488874], cur_train_grp_loss: [0.18590841 0.09132333 0.40177345], max_reward_err:  0.0977, max_reward_err_index: 0, max_kl_dist:  1.2907, max_kl_dist_index: 0, max_train_grp_loss:  19.8900, max_train_grp_loss_index: 0, max_val_grp_loss:  18.9827, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4018, max_cur_train_grp_loss_index: 2, 
2024-09-18 22:58:31,973 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:387] - INFO: Policy parameter learned solely on the preference data rdpo: [ 6.02799158  5.64822334 10.99825143  4.2614745 ].
2024-09-18 22:58:32,307 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Uniform reward: 3.8314, 3.8314, 3.2257
2024-09-18 22:58:32,307 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Optimal reward: 3.8751, 3.8751, 3.3832
2024-09-18 22:58:32,308 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Policy reward: 3.4966, 3.8383, 3.1865
2024-09-18 22:58:32,308 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Reward Error: 0.0977, 0.0095, 0.0581
2024-09-18 22:58:32,996 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:416] - INFO: Optimal reward: 3.8751, 3.8751, 3.3832
Known param reward: [[3.875110387802124, 3.4832417964935303, 3.3414347171783447], [3.4832417964935303, 3.875110387802124, 3.1878042221069336], [3.835331678390503, 3.593684434890747, 3.3831582069396973]], Known param reward error: [[0.0, 0.1011244976509825, 0.012332704298535996], [0.1011244976509825, 0.0, 0.05774308290757558], [0.010265180970543316, 0.07262398351211756, 0.0]].
