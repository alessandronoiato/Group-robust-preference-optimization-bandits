2024-09-18 22:58:45,751 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log_rdpo/2024_09_18_22_39_43/swapped_noise0.3_[1,0.3,1]_2021
2024-09-18 22:58:45,753 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2021
2024-09-18 22:58:45,753 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-09-18 22:58:45,913 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.5327, l2 distance: 9.2150, acc: 0.78.
2024-09-18 22:58:45,914 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-18 22:58:45,915 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [6.10968104 2.29424698 4.49928353 2.24249985]
2024-09-18 22:58:46,125 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.4996, 3.8765, 3.1218
2024-09-18 22:58:46,381 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-18 22:58:47,708 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  18.3131, val_loss:  15.1640, grad_norm: 0.2291, live_grad: 0.0000, reward_err: 0.1076, 0.0007, 0.0661, KL_dist: 1.2708, 0.5824, 1.0181, param: [10.87749428  3.44833383  7.3913693   3.47167839], weights: [0.33303531 0.33302044 0.33394425], train_wt_loss:  54.9393, val_wt_loss: 45.4919, train_grp_loss: [20.55044912 15.73165649 19.17331467], val_grp_loss: [20.513852    6.51417008 18.9858848 ], train_hist_grp_loss: [0.17869104 0.17422575 0.45124366], cur_train_grp_loss: [0.17869104 0.17422575 0.45124366], max_reward_err:  0.1076, max_reward_err_index: 0, max_kl_dist:  1.2708, max_kl_dist_index: 0, max_train_grp_loss:  20.5504, max_train_grp_loss_index: 0, max_val_grp_loss:  20.5139, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4512, max_cur_train_grp_loss_index: 2, 
2024-09-18 22:58:52,231 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  100, train_loss:  18.3171, val_loss:  15.0736, grad_norm: 0.0115, live_grad: 0.0000, reward_err: 0.1043, 0.0007, 0.0629, KL_dist: 1.2756, 0.6026, 1.0230, param: [10.85096269  3.59677535  7.62420975  3.63009374], weights: [0.31148408 0.30000832 0.3885076 ], train_wt_loss:  54.9514, val_wt_loss: 45.2209, train_grp_loss: [20.44275794 15.90058343 19.04445579], val_grp_loss: [20.38193501  6.50171083 18.8543866 ], train_hist_grp_loss: [16.57735772 12.82355408 38.67380673], cur_train_grp_loss: [0.16355126 0.12718935 0.38091701], max_reward_err:  0.1043, max_reward_err_index: 0, max_kl_dist:  1.2756, max_kl_dist_index: 0, max_train_grp_loss:  20.4428, max_train_grp_loss_index: 0, max_val_grp_loss:  20.3819, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.3809, max_cur_train_grp_loss_index: 2, 
2024-09-18 22:58:56,575 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  199, train_loss:  18.3319, val_loss:  14.9751, grad_norm: 0.0284,  live_grad: 0.0000, reward_err: 0.1018, 0.0008, 0.0603, KL_dist: 1.2833, 0.6273, 1.0306, param: [10.81723105  3.76670206  7.90689439  3.81371248], weights: [0.28772403 0.26767397 0.44460199], train_wt_loss:  54.9957, val_wt_loss: 44.9254, train_grp_loss: [20.32092123 16.11763097 18.8949439 ], val_grp_loss: [20.23025128  6.50311403 18.70290789], train_hist_grp_loss: [32.72133664 25.49812889 76.23910421], cur_train_grp_loss: [0.16257788 0.12892111 0.37793142], max_reward_err:  0.1018, max_reward_err_index: 0, max_kl_dist:  1.2833, max_kl_dist_index: 0, max_train_grp_loss:  20.3209, max_train_grp_loss_index: 0, max_val_grp_loss:  20.2303, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.3779, max_cur_train_grp_loss_index: 2, 
2024-09-18 22:58:56,798 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:387] - INFO: Policy parameter learned solely on the preference data rdpo: [10.81723105  3.76670206  7.90689439  3.81371248].
2024-09-18 22:58:57,138 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Uniform reward: 3.8449, 3.8449, 3.1975
2024-09-18 22:58:57,139 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Optimal reward: 3.8804, 3.8804, 3.3109
2024-09-18 22:58:57,139 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Policy reward: 3.4852, 3.8771, 3.1113
2024-09-18 22:58:57,140 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Reward Error: 0.1018, 0.0008, 0.0603
2024-09-18 22:58:57,825 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:416] - INFO: Optimal reward: 3.8804, 3.8804, 3.3109
Known param reward: [[3.880363702774048, 3.454080104827881, 3.2871222496032715], [3.454080104827881, 3.880363702774048, 3.0933778285980225], [3.845717430114746, 3.5881128311157227, 3.310894012451172]], Known param reward error: [[0.0, 0.10985660896720055, 0.0071798622240708074], [0.10985660896720055, 0.0, 0.0656971147476009], [0.008928614767356305, 0.07531532970721194, 0.0]].
