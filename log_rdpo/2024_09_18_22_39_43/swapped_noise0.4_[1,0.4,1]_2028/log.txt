2024-09-18 22:57:33,156 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log_rdpo/2024_09_18_22_39_43/swapped_noise0.4_[1,0.4,1]_2028
2024-09-18 22:57:33,158 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2028
2024-09-18 22:57:33,158 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-09-18 22:57:33,317 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.5013, l2 distance: 13.1473, acc: 0.80.
2024-09-18 22:57:33,318 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-18 22:57:33,319 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [6.95011815 4.29889072 6.20277518 4.38213871]
2024-09-18 22:57:33,528 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.5639, 3.7646, 3.1600
2024-09-18 22:57:33,781 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-18 22:57:35,088 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  17.7386, val_loss:  15.1743, grad_norm: 0.2319, live_grad: 0.0000, reward_err: 0.0700, 0.0108, 0.0346, KL_dist: 1.2245, 0.7767, 1.0048, param: [9.81178258 5.36824138 8.34268381 5.92184243], weights: [0.33312575 0.33308504 0.33378921], train_wt_loss:  53.2159, val_wt_loss: 45.5230, train_grp_loss: [19.69723198 15.86077679 16.99449223], val_grp_loss: [19.10487788  8.7714948  16.84162716], train_hist_grp_loss: [0.17420511 0.16198416 0.37317017], cur_train_grp_loss: [0.17420511 0.16198416 0.37317017], max_reward_err:  0.0700, max_reward_err_index: 0, max_kl_dist:  1.2245, max_kl_dist_index: 0, max_train_grp_loss:  19.6972, max_train_grp_loss_index: 0, max_val_grp_loss:  19.1049, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.3732, max_cur_train_grp_loss_index: 2, 
2024-09-18 22:57:39,572 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  100, train_loss:  17.7404, val_loss:  15.1479, grad_norm: 0.0061, live_grad: 0.0000, reward_err: 0.0702, 0.0113, 0.0348, KL_dist: 1.2534, 0.8012, 1.0317, param: [9.99658245 5.46169393 8.39732689 6.0272389 ], weights: [0.31755456 0.31423432 0.36821112], train_wt_loss:  53.2213, val_wt_loss: 45.4436, train_grp_loss: [19.63554646 15.9863858  16.89548504], val_grp_loss: [19.03541325  8.86662523 16.74962606], train_hist_grp_loss: [15.30272799 14.25165735 30.10341144], cur_train_grp_loss: [0.15104759 0.14146045 0.29643018], max_reward_err:  0.0702, max_reward_err_index: 0, max_kl_dist:  1.2534, max_kl_dist_index: 0, max_train_grp_loss:  19.6355, max_train_grp_loss_index: 0, max_val_grp_loss:  19.0354, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2964, max_cur_train_grp_loss_index: 2, 
2024-09-18 22:57:44,000 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  199, train_loss:  17.7463, val_loss:  15.1222, grad_norm: 0.0138,  live_grad: 0.0000, reward_err: 0.0694, 0.0113, 0.0342, KL_dist: 1.2857, 0.8282, 1.0617, param: [10.19972264  5.56223539  8.45832727  6.14139365], weights: [0.30128045 0.29557238 0.40314717], train_wt_loss:  53.2388, val_wt_loss: 45.3666, train_grp_loss: [19.56989654 16.13145499 16.78847025], val_grp_loss: [18.96118974  8.97801832 16.65025324], train_hist_grp_loss: [30.23149931 28.31871655 59.35751003], cur_train_grp_loss: [0.15054294 0.14274227 0.29455432], max_reward_err:  0.0694, max_reward_err_index: 0, max_kl_dist:  1.2857, max_kl_dist_index: 0, max_train_grp_loss:  19.5699, max_train_grp_loss_index: 0, max_val_grp_loss:  18.9612, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2946, max_cur_train_grp_loss_index: 2, 
2024-09-18 22:57:44,222 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:387] - INFO: Policy parameter learned solely on the preference data rdpo: [10.19972264  5.56223539  8.45832727  6.14139365].
2024-09-18 22:57:44,557 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Uniform reward: 3.7723, 3.7723, 3.1239
2024-09-18 22:57:44,558 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Optimal reward: 3.8153, 3.8153, 3.2617
2024-09-18 22:57:44,558 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Policy reward: 3.5505, 3.7723, 3.1501
2024-09-18 22:57:44,559 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Reward Error: 0.0694, 0.0113, 0.0342
2024-09-18 22:57:45,248 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:416] - INFO: Optimal reward: 3.8153, 3.8153, 3.2617
Known param reward: [[3.815298318862915, 3.4180736541748047, 3.2313497066497803], [3.4180736541748047, 3.815298318862915, 3.058016777038574], [3.7792916297912598, 3.547971248626709, 3.2616615295410156]], Known param reward error: [[0.0, 0.10411365809174691, 0.00929336861495278], [0.10411365809174691, 0.0, 0.06243589368731908], [0.009437450511703749, 0.07006714754506493, 0.0]].
