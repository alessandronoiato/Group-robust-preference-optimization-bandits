2024-09-18 23:01:44,598 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log_rdpo/2024_09_18_22_39_43/swapped_noise0.3_[1,0.3,1]_2028
2024-09-18 23:01:44,600 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2028
2024-09-18 23:01:44,600 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-09-18 23:01:44,765 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.4759, l2 distance: 14.7351, acc: 0.82.
2024-09-18 23:01:44,765 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-18 23:01:44,766 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [7.47006007 5.63067938 6.50156715 4.14686146]
2024-09-18 23:01:44,971 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.6326, 3.7996, 3.2436
2024-09-18 23:01:45,222 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-18 23:01:46,541 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  17.0359, val_loss:  15.1056, grad_norm: 0.2294, live_grad: 0.0000, reward_err: 0.0855, 0.0110, 0.0491, KL_dist: 1.2690, 0.7219, 1.0319, param: [10.82806515  6.06786563  7.59918613  4.21575746], weights: [0.33309479 0.33311558 0.33378963], train_wt_loss:  51.1076, val_wt_loss: 45.3169, train_grp_loss: [19.39048332 14.44127963 16.80927948], val_grp_loss: [18.63350081  8.82883678 17.42115505], train_hist_grp_loss: [0.16440287 0.17064675 0.37278783], cur_train_grp_loss: [0.16440287 0.17064675 0.37278783], max_reward_err:  0.0855, max_reward_err_index: 0, max_kl_dist:  1.2690, max_kl_dist_index: 0, max_train_grp_loss:  19.3905, max_train_grp_loss_index: 0, max_val_grp_loss:  18.6335, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.3728, max_cur_train_grp_loss_index: 2, 
2024-09-18 23:01:51,056 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  100, train_loss:  17.0386, val_loss:  15.0868, grad_norm: 0.0073, live_grad: 0.0000, reward_err: 0.0863, 0.0114, 0.0501, KL_dist: 1.2990, 0.7483, 1.0617, param: [11.06533673  6.20946773  7.55208678  4.36871654], weights: [0.31861644 0.31227915 0.36910441], train_wt_loss:  51.1157, val_wt_loss: 45.2605, train_grp_loss: [19.28782498 14.63253053 16.6785833 ], val_grp_loss: [18.531333    8.99451488 17.31174024], train_hist_grp_loss: [15.04144389 13.03239285 29.7505994 ], cur_train_grp_loss: [0.148376   0.12947333 0.29263045], max_reward_err:  0.0863, max_reward_err_index: 0, max_kl_dist:  1.2990, max_kl_dist_index: 0, max_train_grp_loss:  19.2878, max_train_grp_loss_index: 0, max_val_grp_loss:  18.5313, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2926, max_cur_train_grp_loss_index: 2, 
2024-09-18 23:01:55,519 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  199, train_loss:  17.0474, val_loss:  15.0708, grad_norm: 0.0167,  live_grad: 0.0000, reward_err: 0.0859, 0.0124, 0.0499, KL_dist: 1.3327, 0.7771, 1.0951, param: [11.32125445  6.35911655  7.50618035  4.53043392], weights: [0.30317034 0.29202399 0.40480566], train_wt_loss:  51.1422, val_wt_loss: 45.2124, train_grp_loss: [19.1805159  14.84916115 16.54022873], val_grp_loss: [18.42429489  9.1803689  17.19621399], train_hist_grp_loss: [29.68976987 25.94388438 58.60099831], cur_train_grp_loss: [0.14755098 0.13138785 0.29020473], max_reward_err:  0.0859, max_reward_err_index: 0, max_kl_dist:  1.3327, max_kl_dist_index: 0, max_train_grp_loss:  19.1805, max_train_grp_loss_index: 0, max_val_grp_loss:  18.4243, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2902, max_cur_train_grp_loss_index: 2, 
2024-09-18 23:01:55,744 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:387] - INFO: Policy parameter learned solely on the preference data rdpo: [11.32125445  6.35911655  7.50618035  4.53043392].
2024-09-18 23:01:56,083 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Uniform reward: 3.8327, 3.8327, 3.2044
2024-09-18 23:01:56,083 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Optimal reward: 3.8689, 3.8689, 3.3386
2024-09-18 23:01:56,084 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Policy reward: 3.5366, 3.8210, 3.1719
2024-09-18 23:01:56,084 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Reward Error: 0.0859, 0.0124, 0.0499
2024-09-18 23:01:56,780 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:416] - INFO: Optimal reward: 3.8689, 3.8689, 3.3386
Known param reward: [[3.8689029216766357, 3.4624440670013428, 3.304152727127075], [3.4624440670013428, 3.8689029216766357, 3.1259868144989014], [3.8354125022888184, 3.6089484691619873, 3.338573932647705]], Known param reward error: [[0.0, 0.10505790993048467, 0.010310152243156], [0.10505790993048467, 0.0, 0.06367602528430706], [0.008656309053447097, 0.0671907405735562, 0.0]].
