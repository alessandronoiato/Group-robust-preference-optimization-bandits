2024-09-18 23:02:10,656 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log_rdpo/2024_09_18_22_39_43/swapped_noise0.3_[1,0.3,1]_2029
2024-09-18 23:02:10,658 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2029
2024-09-18 23:02:10,658 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-09-18 23:02:10,820 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.5113, l2 distance: 10.3776, acc: 0.79.
2024-09-18 23:02:10,821 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-18 23:02:10,822 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [4.3593504  3.3275761  6.76851117 3.1285225 ]
2024-09-18 23:02:11,025 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.5742, 3.8625, 3.2288
2024-09-18 23:02:11,286 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-18 23:02:12,612 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  17.6955, val_loss:  15.2708, grad_norm: 0.1827, live_grad: 0.0000, reward_err: 0.0969, 0.0033, 0.0569, KL_dist: 1.3502, 0.6052, 1.0923, param: [ 6.75033824  4.25056333 11.30957247  4.23743623], weights: [0.33298803 0.33292206 0.33408991], train_wt_loss:  53.0864, val_wt_loss: 45.8123, train_grp_loss: [19.67893462 16.09622968 16.52559663], val_grp_loss: [19.55403067  7.12014161 18.24870902], train_hist_grp_loss: [0.16419739 0.14438363 0.49455942], cur_train_grp_loss: [0.16419739 0.14438363 0.49455942], max_reward_err:  0.0969, max_reward_err_index: 0, max_kl_dist:  1.3502, max_kl_dist_index: 0, max_train_grp_loss:  19.6789, max_train_grp_loss_index: 0, max_val_grp_loss:  19.5540, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4946, max_cur_train_grp_loss_index: 2, 
2024-09-18 23:02:17,122 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  100, train_loss:  17.7019, val_loss:  15.2275, grad_norm: 0.0116, live_grad: 0.0000, reward_err: 0.0979, 0.0037, 0.0586, KL_dist: 1.4137, 0.6334, 1.1559, param: [ 6.47623649  4.41865569 11.79836996  4.42461698], weights: [0.30687705 0.29854818 0.39457478], train_wt_loss:  53.1057, val_wt_loss: 45.6826, train_grp_loss: [19.53440666 16.33463641 16.2715273 ], val_grp_loss: [19.45081874  7.21447003 18.14240196], train_hist_grp_loss: [15.36476212 12.61317621 40.50091232], cur_train_grp_loss: [0.15144133 0.12563042 0.39693251], max_reward_err:  0.0979, max_reward_err_index: 0, max_kl_dist:  1.4137, max_kl_dist_index: 0, max_train_grp_loss:  19.5344, max_train_grp_loss_index: 0, max_val_grp_loss:  19.4508, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.3969, max_cur_train_grp_loss_index: 2, 
2024-09-18 23:02:21,470 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  199, train_loss:  17.7248, val_loss:  15.1875, grad_norm: 0.0287,  live_grad: 0.0000, reward_err: 0.0975, 0.0044, 0.0589, KL_dist: 1.4927, 0.6677, 1.2347, param: [ 6.17895468  4.61065763 12.35584065  4.63974474], weights: [0.27894945 0.26498517 0.45606538], train_wt_loss:  53.1744, val_wt_loss: 45.5626, train_grp_loss: [19.37546626 16.63481714 15.98729194], val_grp_loss: [19.3378004   7.34308512 18.02450327], train_hist_grp_loss: [30.29691762 25.16124787 79.45747774], cur_train_grp_loss: [0.15021047 0.12793397 0.39000787], max_reward_err:  0.0975, max_reward_err_index: 0, max_kl_dist:  1.4927, max_kl_dist_index: 0, max_train_grp_loss:  19.3755, max_train_grp_loss_index: 0, max_val_grp_loss:  19.3378, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.3900, max_cur_train_grp_loss_index: 2, 
2024-09-18 23:02:21,692 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:387] - INFO: Policy parameter learned solely on the preference data rdpo: [ 6.17895468  4.61065763 12.35584065  4.63974474].
2024-09-18 23:02:22,032 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Uniform reward: 3.8485, 3.8485, 3.2335
2024-09-18 23:02:22,033 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Optimal reward: 3.8941, 3.8941, 3.3780
2024-09-18 23:02:22,034 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Policy reward: 3.5145, 3.8769, 3.1792
2024-09-18 23:02:22,034 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Reward Error: 0.0975, 0.0044, 0.0589
2024-09-18 23:02:22,711 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:416] - INFO: Optimal reward: 3.8941, 3.8941, 3.3780
Known param reward: [[3.894106388092041, 3.4839439392089844, 3.341844081878662], [3.4839439392089844, 3.894106388092041, 3.171762704849243], [3.8587565422058105, 3.6140236854553223, 3.3780486583709717]], Known param reward error: [[0.0, 0.10532903007922702, 0.010717600648703753], [0.10532903007922702, 0.0, 0.06106660216706521], [0.009077781232256088, 0.0719247690543833, 0.0]].
