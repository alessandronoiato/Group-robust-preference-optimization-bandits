2024-09-18 22:53:48,088 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log_rdpo/2024_09_18_22_39_43/swapped_noise0.5_[1,0.5,1]_2029
2024-09-18 22:53:48,090 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2029
2024-09-18 22:53:48,091 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-09-18 22:53:48,256 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.4622, l2 distance: 15.7048, acc: 0.76.
2024-09-18 22:53:48,256 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-18 22:53:48,257 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [8.03172364 3.1446329  7.65537172 4.62681821]
2024-09-18 22:53:48,469 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.5601, 3.8681, 3.2290
2024-09-18 22:53:48,742 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-18 22:53:50,109 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  16.4040, val_loss:  15.2748, grad_norm: 0.2242, live_grad: 0.0000, reward_err: 0.0962, 0.0016, 0.0532, KL_dist: 1.5418, 0.7815, 1.2293, param: [10.1246335   3.42847427 10.69618931  4.87608768], weights: [0.33298888 0.3328792  0.33413192], train_wt_loss:  49.2120, val_wt_loss: 45.8243, train_grp_loss: [21.5790478  10.58338302 18.57710721], val_grp_loss: [20.78003001  6.18733926 17.6241048 ], train_hist_grp_loss: [0.16844826 0.13550252 0.51112666], cur_train_grp_loss: [0.16844826 0.13550252 0.51112666], max_reward_err:  0.0962, max_reward_err_index: 0, max_kl_dist:  1.5418, max_kl_dist_index: 0, max_train_grp_loss:  21.5790, max_train_grp_loss_index: 0, max_val_grp_loss:  20.7800, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.5111, max_cur_train_grp_loss_index: 2, 
2024-09-18 22:53:54,652 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  100, train_loss:  16.4144, val_loss:  15.2327, grad_norm: 0.0197, live_grad: 0.0000, reward_err: 0.0922, 0.0020, 0.0500, KL_dist: 1.5490, 0.8071, 1.2412, param: [10.02164508  3.68892576 10.91372586  5.18752119], weights: [0.30751077 0.28259534 0.40989389], train_wt_loss:  49.2431, val_wt_loss: 45.6982, train_grp_loss: [21.39083819 10.86356884 18.35670065], val_grp_loss: [20.57316668  6.50201828 17.43823918], train_hist_grp_loss: [16.82625994  8.37684677 45.56507986], cur_train_grp_loss: [0.16583632 0.08354029 0.4477843 ], max_reward_err:  0.0922, max_reward_err_index: 0, max_kl_dist:  1.5490, max_kl_dist_index: 0, max_train_grp_loss:  21.3908, max_train_grp_loss_index: 0, max_val_grp_loss:  20.5732, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4478, max_cur_train_grp_loss_index: 2, 
2024-09-18 22:53:59,056 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  199, train_loss:  16.4551, val_loss:  15.1955, grad_norm: 0.0520,  live_grad: 0.0000, reward_err: 0.0897, 0.0026, 0.0482, KL_dist: 1.5667, 0.8440, 1.2639, param: [ 9.89624862  4.00536658 11.2171971   5.5679871 ], weights: [0.27724044 0.23537655 0.48738301], train_wt_loss:  49.3652, val_wt_loss: 45.5865, train_grp_loss: [21.16947879 11.26259046 18.08577815], val_grp_loss: [20.32490412  6.92943327 17.21005503], train_hist_grp_loss: [33.16083383 16.79097462 89.57734491], cur_train_grp_loss: [0.16412333 0.0865983  0.44119029], max_reward_err:  0.0897, max_reward_err_index: 0, max_kl_dist:  1.5667, max_kl_dist_index: 0, max_train_grp_loss:  21.1695, max_train_grp_loss_index: 0, max_val_grp_loss:  20.3249, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4412, max_cur_train_grp_loss_index: 2, 
2024-09-18 22:53:59,295 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:387] - INFO: Policy parameter learned solely on the preference data rdpo: [ 9.89624862  4.00536658 11.2171971   5.5679871 ].
2024-09-18 22:53:59,633 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Uniform reward: 3.8386, 3.8386, 3.2274
2024-09-18 22:53:59,634 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Optimal reward: 3.8850, 3.8850, 3.3731
2024-09-18 22:53:59,634 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Policy reward: 3.5363, 3.8749, 3.2107
2024-09-18 22:53:59,635 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Reward Error: 0.0897, 0.0026, 0.0482
2024-09-18 22:54:00,327 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:416] - INFO: Optimal reward: 3.8850, 3.8850, 3.3731
Known param reward: [[3.8849852085113525, 3.4774763584136963, 3.335669994354248], [3.4774763584136963, 3.8849852085113525, 3.1690282821655273], [3.8491885662078857, 3.6059226989746094, 3.3731210231781006]], Known param reward error: [[0.0, 0.10489328227167315, 0.011102782428057319], [0.10489328227167315, 0.0, 0.06050560878491111], [0.009214100024124247, 0.07183103527018941, 0.0]].
