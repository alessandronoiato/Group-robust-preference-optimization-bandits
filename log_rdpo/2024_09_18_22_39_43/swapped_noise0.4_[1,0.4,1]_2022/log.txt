2024-09-18 22:55:03,897 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log_rdpo/2024_09_18_22_39_43/swapped_noise0.4_[1,0.4,1]_2022
2024-09-18 22:55:03,899 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2022
2024-09-18 22:55:03,900 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-09-18 22:55:04,061 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.4879, l2 distance: 12.6795, acc: 0.82.
2024-09-18 22:55:04,062 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-18 22:55:04,063 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [6.75502214 3.97653476 5.79379738 4.90833845]
2024-09-18 22:55:04,266 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.6743, 3.8038, 3.2594
2024-09-18 22:55:04,533 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-18 22:55:05,853 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  17.1514, val_loss:  15.0165, grad_norm: 0.2411, live_grad: 0.0000, reward_err: 0.0636, 0.0097, 0.0306, KL_dist: 1.2284, 0.7577, 1.0091, param: [9.99133228 4.76692941 8.56685331 6.00523269], weights: [0.33305525 0.33299032 0.33395444], train_wt_loss:  51.4541, val_wt_loss: 45.0494, train_grp_loss: [17.67149403 17.33305776 15.28043814], val_grp_loss: [19.99281371  7.94457785 17.39648013], train_hist_grp_loss: [0.17230999 0.15281295 0.44192892], cur_train_grp_loss: [0.17230999 0.15281295 0.44192892], max_reward_err:  0.0636, max_reward_err_index: 0, max_kl_dist:  1.2284, max_kl_dist_index: 0, max_train_grp_loss:  17.6715, max_train_grp_loss_index: 0, max_val_grp_loss:  19.9928, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4419, max_cur_train_grp_loss_index: 2, 
2024-09-18 22:55:10,353 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  100, train_loss:  17.1537, val_loss:  14.9746, grad_norm: 0.0067, live_grad: 0.0000, reward_err: 0.0639, 0.0097, 0.0309, KL_dist: 1.2663, 0.7851, 1.0434, param: [10.23652708  4.83480066  8.64001466  6.11740346], weights: [0.31300114 0.31066788 0.37633098], train_wt_loss:  51.4612, val_wt_loss: 44.9238, train_grp_loss: [17.58367017 17.47171925 15.14669973], val_grp_loss: [19.93624429  7.96718031 17.30160398], train_hist_grp_loss: [14.38907783 13.64083754 32.81529836], cur_train_grp_loss: [0.14181125 0.13542792 0.32230025], max_reward_err:  0.0639, max_reward_err_index: 0, max_kl_dist:  1.2663, max_kl_dist_index: 0, max_train_grp_loss:  17.5837, max_train_grp_loss_index: 0, max_val_grp_loss:  19.9362, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.3223, max_cur_train_grp_loss_index: 2, 
2024-09-18 22:55:14,750 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  199, train_loss:  17.1618, val_loss:  14.9328, grad_norm: 0.0158,  live_grad: 0.0000, reward_err: 0.0633, 0.0098, 0.0306, KL_dist: 1.3092, 0.8158, 1.0823, param: [10.50873046  4.90932688  8.72440013  6.24202239], weights: [0.29212646 0.28841069 0.41946285], train_wt_loss:  51.4854, val_wt_loss: 44.7983, train_grp_loss: [17.48742566 17.63669173 14.99934818], val_grp_loss: [19.87494005  8.0032928  17.19738748], train_hist_grp_loss: [28.39024655 27.11011426 64.56906556], cur_train_grp_loss: [0.14103585 0.13670443 0.31916834], max_reward_err:  0.0633, max_reward_err_index: 0, max_kl_dist:  1.3092, max_kl_dist_index: 0, max_train_grp_loss:  17.6367, max_train_grp_loss_index: 1, max_val_grp_loss:  19.8749, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.3192, max_cur_train_grp_loss_index: 2, 
2024-09-18 22:55:14,974 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:387] - INFO: Policy parameter learned solely on the preference data rdpo: [10.50873046  4.90932688  8.72440013  6.24202239].
2024-09-18 22:55:15,307 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Uniform reward: 3.8352, 3.8352, 3.1931
2024-09-18 22:55:15,308 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Optimal reward: 3.8672, 3.8672, 3.3262
2024-09-18 22:55:15,308 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Policy reward: 3.6225, 3.8291, 3.2242
2024-09-18 22:55:15,309 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Reward Error: 0.0633, 0.0098, 0.0306
2024-09-18 22:55:15,999 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:416] - INFO: Optimal reward: 3.8672, 3.8672, 3.3262
Known param reward: [[3.867177724838257, 3.538572311401367, 3.2763869762420654], [3.538572311401367, 3.867177724838257, 3.1662933826446533], [3.823817253112793, 3.633922815322876, 3.3261606693267822]], Known param reward error: [[0.0, 0.08497292775718847, 0.01496430811166769], [0.08497292775718847, 0.0, 0.04806360924064627], [0.011212433151692661, 0.060316573509725795, 0.0]].
