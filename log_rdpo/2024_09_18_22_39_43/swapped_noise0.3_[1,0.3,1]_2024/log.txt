2024-09-18 22:59:58,601 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log_rdpo/2024_09_18_22_39_43/swapped_noise0.3_[1,0.3,1]_2024
2024-09-18 22:59:58,602 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2024
2024-09-18 22:59:58,603 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-09-18 22:59:58,767 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.5272, l2 distance: 8.9728, acc: 0.77.
2024-09-18 22:59:58,768 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-18 22:59:58,769 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [3.13265196 2.31429868 6.45347979 3.11117788]
2024-09-18 22:59:58,979 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.5829, 3.8743, 3.2326
2024-09-18 22:59:59,229 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-18 23:00:00,541 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  18.1815, val_loss:  15.9527, grad_norm: 0.2711, live_grad: 0.0000, reward_err: 0.0983, 0.0108, 0.0627, KL_dist: 1.2788, 0.5077, 1.0662, param: [ 4.31196141  3.11709394 11.5608018   4.79338486], weights: [0.33294941 0.33292321 0.33412737], train_wt_loss:  54.5445, val_wt_loss: 47.8581, train_grp_loss: [20.51032331 16.11973432 18.14115561], val_grp_loss: [21.0500888   7.46591675 19.19526989], train_hist_grp_loss: [0.17972112 0.17185215 0.53289232], cur_train_grp_loss: [0.17972112 0.17185215 0.53289232], max_reward_err:  0.0983, max_reward_err_index: 0, max_kl_dist:  1.2788, max_kl_dist_index: 0, max_train_grp_loss:  20.5103, max_train_grp_loss_index: 0, max_val_grp_loss:  21.0501, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.5329, max_cur_train_grp_loss_index: 2, 
2024-09-18 23:00:05,048 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  100, train_loss:  18.1902, val_loss:  15.9251, grad_norm: 0.0157, live_grad: 0.0000, reward_err: 0.0994, 0.0142, 0.0644, KL_dist: 1.3536, 0.5385, 1.1440, param: [ 3.98754325  3.32972952 12.02922437  5.00679778], weights: [0.30584549 0.29126179 0.40289272], train_wt_loss:  54.5705, val_wt_loss: 47.7753, train_grp_loss: [20.31922135 16.38631266 17.8824518 ], val_grp_loss: [20.95531401  7.58902424 19.08807119], train_hist_grp_loss: [16.91565507 12.02990048 44.47468528], cur_train_grp_loss: [0.1665677  0.11958585 0.43622493], max_reward_err:  0.0994, max_reward_err_index: 0, max_kl_dist:  1.3536, max_kl_dist_index: 0, max_train_grp_loss:  20.3192, max_train_grp_loss_index: 0, max_val_grp_loss:  20.9553, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4362, max_cur_train_grp_loss_index: 2, 
2024-09-18 23:00:09,442 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  199, train_loss:  18.2219, val_loss:  15.9003, grad_norm: 0.0406,  live_grad: 0.0000, reward_err: 0.0990, 0.0159, 0.0648, KL_dist: 1.4429, 0.5771, 1.2365, param: [ 3.64916031  3.58268796 12.55599426  5.26067027], weights: [0.27572601 0.25116564 0.47310835], train_wt_loss:  54.6656, val_wt_loss: 47.7009, train_grp_loss: [20.10389164 16.7353213  17.58894453], val_grp_loss: [20.84306185  7.75950513 18.9605184 ], train_hist_grp_loss: [33.31954982 23.99004953 87.3112267 ], cur_train_grp_loss: [0.16480495 0.12212616 0.42907568], max_reward_err:  0.0990, max_reward_err_index: 0, max_kl_dist:  1.4429, max_kl_dist_index: 0, max_train_grp_loss:  20.1039, max_train_grp_loss_index: 0, max_val_grp_loss:  20.8431, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4291, max_cur_train_grp_loss_index: 2, 
2024-09-18 23:00:09,667 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:387] - INFO: Policy parameter learned solely on the preference data rdpo: [ 3.64916031  3.58268796 12.55599426  5.26067027].
2024-09-18 23:00:10,002 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Uniform reward: 3.8844, 3.8844, 3.2699
2024-09-18 23:00:10,003 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Optimal reward: 3.9240, 3.9240, 3.4065
2024-09-18 23:00:10,003 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Policy reward: 3.5355, 3.8617, 3.1857
2024-09-18 23:00:10,004 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Reward Error: 0.0990, 0.0159, 0.0648
2024-09-18 23:00:10,687 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:416] - INFO: Optimal reward: 3.9240, 3.9240, 3.4065
Known param reward: [[3.924014091491699, 3.5108532905578613, 3.372161388397217], [3.5108532905578613, 3.924014091491699, 3.199089765548706], [3.8835723400115967, 3.6450908184051514, 3.40653657913208]], Known param reward error: [[0.0, 0.10529034588068371, 0.010090950129653801], [0.10529034588068371, 0.0, 0.060896693390630634], [0.010306219737536355, 0.0710811089316237, 0.0]].
