2024-09-18 22:57:57,693 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log_rdpo/2024_09_18_22_39_43/swapped_noise0.4_[1,0.4,1]_2029
2024-09-18 22:57:57,695 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2029
2024-09-18 22:57:57,696 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-09-18 22:57:57,856 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.4857, l2 distance: 12.7646, acc: 0.79.
2024-09-18 22:57:57,856 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-18 22:57:57,857 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [7.15946892 2.77124874 5.50604859 5.19991595]
2024-09-18 22:57:58,063 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.5372, 3.7691, 3.1625
2024-09-18 22:57:58,314 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-18 22:57:59,618 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  17.0840, val_loss:  15.8337, grad_norm: 0.2859, live_grad: 0.0000, reward_err: 0.0814, 0.0117, 0.0418, KL_dist: 1.2100, 0.7136, 0.9749, param: [9.51352109 3.4891047  8.60909064 6.40141719], weights: [0.33291561 0.33286726 0.33421714], train_wt_loss:  51.2520, val_wt_loss: 47.5012, train_grp_loss: [18.65080755 14.90490151 19.06367212], val_grp_loss: [19.7187682   8.34002268 18.56992314], train_hist_grp_loss: [0.17793281 0.16340928 0.56811962], cur_train_grp_loss: [0.17793281 0.16340928 0.56811962], max_reward_err:  0.0814, max_reward_err_index: 0, max_kl_dist:  1.2100, max_kl_dist_index: 0, max_train_grp_loss:  19.0637, max_train_grp_loss_index: 2, max_val_grp_loss:  19.7188, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.5681, max_cur_train_grp_loss_index: 2, 
2024-09-18 22:58:04,142 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  100, train_loss:  17.0912, val_loss:  15.8057, grad_norm: 0.0133, live_grad: 0.0000, reward_err: 0.0781, 0.0135, 0.0390, KL_dist: 1.2288, 0.7467, 0.9936, param: [9.18579003 3.63107429 9.14527403 6.60173034], weights: [0.29837881 0.28987336 0.41174783], train_wt_loss:  51.2736, val_wt_loss: 47.4171, train_grp_loss: [18.53603214 15.10721696 18.83596659], val_grp_loss: [19.58791794  8.54063688 18.44215622], train_hist_grp_loss: [14.59325914 11.70128799 46.7979859 ], cur_train_grp_loss: [0.14369992 0.11619098 0.45947414], max_reward_err:  0.0781, max_reward_err_index: 0, max_kl_dist:  1.2288, max_kl_dist_index: 0, max_train_grp_loss:  18.8360, max_train_grp_loss_index: 2, max_val_grp_loss:  19.5879, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4595, max_cur_train_grp_loss_index: 2, 
2024-09-18 22:58:08,493 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  199, train_loss:  17.1189, val_loss:  15.7841, grad_norm: 0.0356,  live_grad: 0.0000, reward_err: 0.0785, 0.0157, 0.0397, KL_dist: 1.2653, 0.7893, 1.0299, param: [8.81875542 3.81240964 9.77416518 6.84939848], weights: [0.26121372 0.24733    0.49145628], train_wt_loss:  51.3568, val_wt_loss: 47.3523, train_grp_loss: [18.39890137 15.39073673 18.57136324], val_grp_loss: [19.43358636  8.81596946 18.2902368 ], train_hist_grp_loss: [28.76816286 23.30661895 91.97156854], cur_train_grp_loss: [0.14263893 0.11836423 0.45303001], max_reward_err:  0.0785, max_reward_err_index: 0, max_kl_dist:  1.2653, max_kl_dist_index: 0, max_train_grp_loss:  18.5714, max_train_grp_loss_index: 2, max_val_grp_loss:  19.4336, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4530, max_cur_train_grp_loss_index: 2, 
2024-09-18 22:58:08,716 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:387] - INFO: Policy parameter learned solely on the preference data rdpo: [8.81875542 3.81240964 9.77416518 6.84939848].
2024-09-18 22:58:09,049 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Uniform reward: 3.8007, 3.8007, 3.1641
2024-09-18 22:58:09,050 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Optimal reward: 3.8416, 3.8416, 3.2971
2024-09-18 22:58:09,050 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Policy reward: 3.5400, 3.7813, 3.1661
2024-09-18 22:58:09,051 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Reward Error: 0.0785, 0.0157, 0.0397
2024-09-18 22:58:09,737 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:416] - INFO: Optimal reward: 3.8416, 3.8416, 3.2971
Known param reward: [[3.841620683670044, 3.4525341987609863, 3.2688729763031006], [3.4525341987609863, 3.841620683670044, 3.1046242713928223], [3.8055338859558105, 3.565392255783081, 3.2970616817474365]], Known param reward error: [[0.0, 0.1012818591286188, 0.008549644551810743], [0.1012818591286188, 0.0, 0.05836633612890821], [0.009393638957544952, 0.07190413906848074, 0.0]].
