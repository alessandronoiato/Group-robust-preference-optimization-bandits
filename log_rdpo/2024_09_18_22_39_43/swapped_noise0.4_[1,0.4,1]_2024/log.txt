2024-09-18 22:55:54,161 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log_rdpo/2024_09_18_22_39_43/swapped_noise0.4_[1,0.4,1]_2024
2024-09-18 22:55:54,163 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2024
2024-09-18 22:55:54,163 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-09-18 22:55:54,323 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.5143, l2 distance: 9.9532, acc: 0.78.
2024-09-18 22:55:54,324 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-18 22:55:54,324 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [6.02750083 3.24397078 5.04527759 3.19851879]
2024-09-18 22:55:54,531 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.6302, 3.8888, 3.2825
2024-09-18 22:55:54,784 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-18 22:55:56,112 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  17.9066, val_loss:  15.3410, grad_norm: 0.2619, live_grad: 0.0000, reward_err: 0.0850, 0.0049, 0.0448, KL_dist: 1.1092, 0.5507, 0.8769, param: [9.49311592 4.20776912 7.66315677 4.46172496], weights: [0.33295928 0.33291908 0.33412164], train_wt_loss:  53.7199, val_wt_loss: 46.0230, train_grp_loss: [20.58662492 15.73669934 17.18276121], val_grp_loss: [20.38314559  6.88040715 18.61074948], train_hist_grp_loss: [0.18004338 0.1679695  0.52853374], cur_train_grp_loss: [0.18004338 0.1679695  0.52853374], max_reward_err:  0.0850, max_reward_err_index: 0, max_kl_dist:  1.1092, max_kl_dist_index: 0, max_train_grp_loss:  20.5866, max_train_grp_loss_index: 0, max_val_grp_loss:  20.3831, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.5285, max_cur_train_grp_loss_index: 2, 
2024-09-18 22:56:00,576 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  100, train_loss:  17.9131, val_loss:  15.2624, grad_norm: 0.0148, live_grad: 0.0000, reward_err: 0.0840, 0.0060, 0.0440, KL_dist: 1.1354, 0.5822, 0.9034, param: [9.6833833  4.43225769 7.7303002  4.6524976 ], weights: [0.30908735 0.29321271 0.39769993], train_wt_loss:  53.7393, val_wt_loss: 45.7873, train_grp_loss: [20.44118669 15.94018058 16.98306055], val_grp_loss: [20.22969499  6.96182938 18.45106485], train_hist_grp_loss: [16.99689288 11.72433244 42.20427736], cur_train_grp_loss: [0.16756359 0.11633444 0.41427436], max_reward_err:  0.0840, max_reward_err_index: 0, max_kl_dist:  1.1354, max_kl_dist_index: 0, max_train_grp_loss:  20.4412, max_train_grp_loss_index: 0, max_val_grp_loss:  20.2297, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4143, max_cur_train_grp_loss_index: 2, 
2024-09-18 22:56:04,970 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  199, train_loss:  17.9376, val_loss:  15.1783, grad_norm: 0.0378,  live_grad: 0.0000, reward_err: 0.0811, 0.0068, 0.0418, KL_dist: 1.1704, 0.6216, 0.9382, param: [9.92997151 4.69672759 7.80818151 4.87709128], weights: [0.28229866 0.2549692  0.46273214], train_wt_loss:  53.8128, val_wt_loss: 45.5350, train_grp_loss: [20.27276266 16.21482405 16.74559111], val_grp_loss: [20.05049766  7.08273268 18.26223172], train_hist_grp_loss: [33.51852184 23.33623975 82.93679795], cur_train_grp_loss: [0.16618521 0.11833285 0.40849276], max_reward_err:  0.0811, max_reward_err_index: 0, max_kl_dist:  1.1704, max_kl_dist_index: 0, max_train_grp_loss:  20.2728, max_train_grp_loss_index: 0, max_val_grp_loss:  20.0505, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4085, max_cur_train_grp_loss_index: 2, 
2024-09-18 22:56:05,191 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:387] - INFO: Policy parameter learned solely on the preference data rdpo: [9.92997151 4.69672759 7.80818151 4.87709128].
2024-09-18 22:56:05,523 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Uniform reward: 3.8844, 3.8844, 3.2699
2024-09-18 22:56:05,524 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Optimal reward: 3.9240, 3.9240, 3.4065
2024-09-18 22:56:05,524 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Policy reward: 3.6059, 3.8972, 3.2643
2024-09-18 22:56:05,525 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Reward Error: 0.0811, 0.0068, 0.0418
2024-09-18 22:56:06,203 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:416] - INFO: Optimal reward: 3.9240, 3.9240, 3.4065
Known param reward: [[3.924014091491699, 3.5108532905578613, 3.372161388397217], [3.5108532905578613, 3.924014091491699, 3.199089765548706], [3.8835723400115967, 3.6450908184051514, 3.40653657913208]], Known param reward error: [[0.0, 0.10529034588068371, 0.010090950129653801], [0.10529034588068371, 0.0, 0.060896693390630634], [0.010306219737536355, 0.0710811089316237, 0.0]].
