2024-09-18 22:50:48,893 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log_rdpo/2024_09_18_22_39_43/swapped_noise0.5_[1,0.5,1]_2022
2024-09-18 22:50:48,895 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2022
2024-09-18 22:50:48,896 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-09-18 22:50:49,055 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.4500, l2 distance: 16.7322, acc: 0.80.
2024-09-18 22:50:49,056 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-18 22:50:49,057 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [9.385783   4.87832338 6.31300798 4.61071713]
2024-09-18 22:50:49,260 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.6061, 3.8367, 3.2033
2024-09-18 22:50:49,512 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-18 22:50:50,847 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  16.0766, val_loss:  15.0148, grad_norm: 0.3072, live_grad: 0.0000, reward_err: 0.0841, 0.0068, 0.0516, KL_dist: 1.5828, 0.8635, 1.3276, param: [12.83123163  5.7190777   7.75749535  4.70105639], weights: [0.33303318 0.33292354 0.33404327], train_wt_loss:  48.2299, val_wt_loss: 45.0444, train_grp_loss: [17.71679507 14.02835383 17.37118848], val_grp_loss: [20.41500006  7.40370302 17.41674646], train_hist_grp_loss: [0.18648329 0.15355666 0.48932474], cur_train_grp_loss: [0.18648329 0.15355666 0.48932474], max_reward_err:  0.0841, max_reward_err_index: 0, max_kl_dist:  1.5828, max_kl_dist_index: 0, max_train_grp_loss:  17.7168, max_train_grp_loss_index: 0, max_val_grp_loss:  20.4150, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4893, max_cur_train_grp_loss_index: 2, 
2024-09-18 22:50:55,326 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  100, train_loss:  16.0808, val_loss:  15.0053, grad_norm: 0.0112, live_grad: 0.0000, reward_err: 0.0833, 0.0070, 0.0509, KL_dist: 1.6174, 0.8950, 1.3618, param: [13.0316681   5.90290597  7.79960876  4.84624887], weights: [0.31013799 0.29998035 0.38988166], train_wt_loss:  48.2423, val_wt_loss: 45.0158, train_grp_loss: [17.59020875 14.21006364 17.23296916], val_grp_loss: [20.31718388  7.59226841 17.29578732], train_hist_grp_loss: [14.42498203 11.09494624 37.30757499], cur_train_grp_loss: [0.14186752 0.11013956 0.36669066], max_reward_err:  0.0833, max_reward_err_index: 0, max_kl_dist:  1.6174, max_kl_dist_index: 0, max_train_grp_loss:  17.5902, max_train_grp_loss_index: 0, max_val_grp_loss:  20.3172, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.3667, max_cur_train_grp_loss_index: 2, 
2024-09-18 22:50:59,718 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  199, train_loss:  16.0959, val_loss:  15.0031, grad_norm: 0.0277,  live_grad: 0.0000, reward_err: 0.0836, 0.0084, 0.0513, KL_dist: 1.6584, 0.9323, 1.4023, param: [13.26650375  6.11771354  7.84652511  5.01452966], weights: [0.2851036  0.26762231 0.44727409], train_wt_loss:  48.2876, val_wt_loss: 45.0094, train_grp_loss: [17.44458258 14.44335733 17.0732693 ], val_grp_loss: [20.20486153  7.83516849 17.15671023], train_hist_grp_loss: [28.41266355 22.08507122 73.44456025], cur_train_grp_loss: [0.14069486 0.11194328 0.36329799], max_reward_err:  0.0836, max_reward_err_index: 0, max_kl_dist:  1.6584, max_kl_dist_index: 0, max_train_grp_loss:  17.4446, max_train_grp_loss_index: 0, max_val_grp_loss:  20.2049, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.3633, max_cur_train_grp_loss_index: 2, 
2024-09-18 22:50:59,941 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:387] - INFO: Policy parameter learned solely on the preference data rdpo: [13.26650375  6.11771354  7.84652511  5.01452966].
2024-09-18 22:51:00,276 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Uniform reward: 3.8487, 3.8487, 3.2033
2024-09-18 22:51:00,277 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Optimal reward: 3.8787, 3.8787, 3.3327
2024-09-18 22:51:00,277 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Policy reward: 3.5543, 3.8459, 3.1618
2024-09-18 22:51:00,278 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Reward Error: 0.0836, 0.0084, 0.0513
2024-09-18 22:51:00,960 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:416] - INFO: Optimal reward: 3.8787, 3.8787, 3.3327
Known param reward: [[3.878673791885376, 3.5492217540740967, 3.282655954360962], [3.5492217540740967, 3.878673791885376, 3.170855760574341], [3.8372855186462402, 3.6475391387939453, 3.3327279090881348]], Known param reward error: [[0.0, 0.08493935182188567, 0.015024315243566644], [0.08493935182188567, 0.0, 0.04857046627550332], [0.01067072805290424, 0.05959115550655239, 0.0]].
