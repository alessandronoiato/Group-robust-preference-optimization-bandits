2024-09-18 22:52:58,975 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log_rdpo/2024_09_18_22_39_43/swapped_noise0.5_[1,0.5,1]_2027
2024-09-18 22:52:58,977 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2027
2024-09-18 22:52:58,977 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-09-18 22:52:59,141 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.4829, l2 distance: 13.5092, acc: 0.79.
2024-09-18 22:52:59,141 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-18 22:52:59,142 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [5.67216327 3.4111978  8.28320704 2.40683498]
2024-09-18 22:52:59,354 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.4408, 3.7835, 3.0844
2024-09-18 22:52:59,608 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-18 22:53:00,990 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  16.7949, val_loss:  14.6822, grad_norm: 0.2088, live_grad: 0.0000, reward_err: 0.0977, 0.0005, 0.0606, KL_dist: 1.6511, 0.7547, 1.3406, param: [ 8.15792135  4.14544695 12.61629119  3.46519174], weights: [0.33316126 0.33313751 0.33370122], train_wt_loss:  50.3846, val_wt_loss: 44.0467, train_grp_loss: [19.03876997 14.87671542 15.69970608], val_grp_loss: [20.64345759  5.61741129 17.97757004], train_hist_grp_loss: [0.1711745  0.16404575 0.33311505], cur_train_grp_loss: [0.1711745  0.16404575 0.33311505], max_reward_err:  0.0977, max_reward_err_index: 0, max_kl_dist:  1.6511, max_kl_dist_index: 0, max_train_grp_loss:  19.0388, max_train_grp_loss_index: 0, max_val_grp_loss:  20.6435, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.3331, max_cur_train_grp_loss_index: 2, 
2024-09-18 22:53:05,538 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  100, train_loss:  16.7965, val_loss:  14.6468, grad_norm: 0.0060, live_grad: 0.0000, reward_err: 0.0977, 0.0006, 0.0606, KL_dist: 1.6801, 0.7729, 1.3683, param: [ 8.15764807  4.23408907 12.80407779  3.56127272], weights: [0.32347516 0.31788159 0.35864325], train_wt_loss:  50.3895, val_wt_loss: 43.9404, train_grp_loss: [18.966575   15.01920947 15.59695226], val_grp_loss: [20.59035922  5.63295793 17.90775413], train_hist_grp_loss: [15.25311613 13.5087791  25.5737006 ], cur_train_grp_loss: [0.1505342  0.13408675 0.25158062], max_reward_err:  0.0977, max_reward_err_index: 0, max_kl_dist:  1.6801, max_kl_dist_index: 0, max_train_grp_loss:  18.9666, max_train_grp_loss_index: 0, max_val_grp_loss:  20.5904, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2516, max_cur_train_grp_loss_index: 2, 
2024-09-18 22:53:09,983 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  199, train_loss:  16.8016, val_loss:  14.6127, grad_norm: 0.0130,  live_grad: 0.0000, reward_err: 0.0974, 0.0009, 0.0606, KL_dist: 1.7103, 0.7920, 1.3971, param: [ 8.16141089  4.32562323 12.996181    3.6605463 ], weights: [0.31323729 0.30314378 0.38361893], train_wt_loss:  50.4047, val_wt_loss: 43.8380, train_grp_loss: [18.89268884 15.17422559 15.49159952], val_grp_loss: [20.53585713  5.6560243  17.83555912], train_hist_grp_loss: [30.12684135 26.85145932 50.39570633], cur_train_grp_loss: [0.14994799 0.13546954 0.24988194], max_reward_err:  0.0974, max_reward_err_index: 0, max_kl_dist:  1.7103, max_kl_dist_index: 0, max_train_grp_loss:  18.8927, max_train_grp_loss_index: 0, max_val_grp_loss:  20.5359, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2499, max_cur_train_grp_loss_index: 2, 
2024-09-18 22:53:10,211 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:387] - INFO: Policy parameter learned solely on the preference data rdpo: [ 8.16141089  4.32562323 12.996181    3.6605463 ].
2024-09-18 22:53:10,552 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Uniform reward: 3.7505, 3.7505, 3.1220
2024-09-18 22:53:10,553 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Optimal reward: 3.7911, 3.7911, 3.2656
2024-09-18 22:53:10,553 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Policy reward: 3.4219, 3.7878, 3.0679
2024-09-18 22:53:10,554 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Reward Error: 0.0974, 0.0009, 0.0606
2024-09-18 22:53:11,251 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:416] - INFO: Optimal reward: 3.7911, 3.7911, 3.2656
Known param reward: [[3.7910752296447754, 3.430555582046509, 3.223391532897949], [3.430555582046509, 3.7910752296447754, 3.083258628845215], [3.7511558532714844, 3.553601026535034, 3.2656166553497314]], Known param reward error: [[0.0, 0.09509693840394916, 0.012930214078437238], [0.09509693840394916, 0.0, 0.055841835019360825], [0.010529829653903089, 0.06264032991294467, 0.0]].
