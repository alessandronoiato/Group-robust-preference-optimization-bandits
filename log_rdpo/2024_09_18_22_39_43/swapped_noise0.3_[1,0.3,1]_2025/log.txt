2024-09-18 23:00:22,847 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log_rdpo/2024_09_18_22_39_43/swapped_noise0.3_[1,0.3,1]_2025
2024-09-18 23:00:22,849 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2025
2024-09-18 23:00:22,850 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-09-18 23:00:23,014 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.5798, l2 distance: 6.9075, acc: 0.72.
2024-09-18 23:00:23,014 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-18 23:00:23,015 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [4.52051724 2.23924509 4.09916579 1.35699891]
2024-09-18 23:00:23,227 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.5016, 3.8293, 3.0928
2024-09-18 23:00:23,465 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-18 23:00:24,773 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  20.0454, val_loss:  16.0817, grad_norm: 0.2315, live_grad: 0.0000, reward_err: 0.0934, 0.0013, 0.0540, KL_dist: 1.0084, 0.4737, 0.7831, param: [8.91949931 3.92209266 7.57897724 2.43058137], weights: [0.33300265 0.33301804 0.33397931], train_wt_loss:  60.1363, val_wt_loss: 48.2450, train_grp_loss: [21.11643879 18.50053048 21.45299818], val_grp_loss: [21.26774405  7.78829504 19.16449834], train_hist_grp_loss: [0.18485138 0.18947128 0.47771116], cur_train_grp_loss: [0.18485138 0.18947128 0.47771116], max_reward_err:  0.0934, max_reward_err_index: 0, max_kl_dist:  1.0084, max_kl_dist_index: 0, max_train_grp_loss:  21.4530, max_train_grp_loss_index: 2, max_val_grp_loss:  21.2677, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4777, max_cur_train_grp_loss_index: 2, 
2024-09-18 23:00:29,293 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  100, train_loss:  20.0517, val_loss:  16.0199, grad_norm: 0.0147, live_grad: 0.0000, reward_err: 0.0920, 0.0022, 0.0534, KL_dist: 1.0198, 0.4889, 0.7980, param: [9.22772506 4.11983557 7.32984861 2.61310594], weights: [0.30375524 0.29566149 0.40058327], train_wt_loss:  60.1550, val_wt_loss: 48.0597, train_grp_loss: [20.99483379 18.70394827 21.25686845], val_grp_loss: [21.10212447  7.89124891 19.04232928], train_hist_grp_loss: [17.30537311 14.60466854 44.97531433], cur_train_grp_loss: [0.17070059 0.14497333 0.44289599], max_reward_err:  0.0920, max_reward_err_index: 0, max_kl_dist:  1.0198, max_kl_dist_index: 0, max_train_grp_loss:  21.2569, max_train_grp_loss_index: 2, max_val_grp_loss:  21.1021, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4429, max_cur_train_grp_loss_index: 2, 
2024-09-18 23:00:33,664 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  199, train_loss:  20.0755, val_loss:  15.9553, grad_norm: 0.0384,  live_grad: 0.0000, reward_err: 0.0933, 0.0039, 0.0552, KL_dist: 1.0384, 0.5092, 0.8210, param: [9.57957286 4.36245019 7.0501841  2.83555483], weights: [0.27218315 0.25868213 0.46913472], train_wt_loss:  60.2266, val_wt_loss: 47.8660, train_grp_loss: [20.84818798 18.9850767  21.02617657], val_grp_loss: [20.90503659  8.04100659 18.89666583], train_hist_grp_loss: [34.14716791 29.05965056 88.58864769], cur_train_grp_loss: [0.16951072 0.14714528 0.43809791], max_reward_err:  0.0933, max_reward_err_index: 0, max_kl_dist:  1.0384, max_kl_dist_index: 0, max_train_grp_loss:  21.0262, max_train_grp_loss_index: 2, max_val_grp_loss:  20.9050, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4381, max_cur_train_grp_loss_index: 2, 
2024-09-18 23:00:33,887 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:387] - INFO: Policy parameter learned solely on the preference data rdpo: [9.57957286 4.36245019 7.0501841  2.83555483].
2024-09-18 23:00:34,221 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Uniform reward: 3.8078, 3.8078, 3.1434
2024-09-18 23:00:34,222 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Optimal reward: 3.8386, 3.8386, 3.2517
2024-09-18 23:00:34,222 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Policy reward: 3.4803, 3.8235, 3.0721
2024-09-18 23:00:34,223 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Reward Error: 0.0933, 0.0039, 0.0552
2024-09-18 23:00:34,899 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:416] - INFO: Optimal reward: 3.8386, 3.8386, 3.2517
Known param reward: [[3.8385727405548096, 3.460787534713745, 3.2131664752960205], [3.460787534713745, 3.8385727405548096, 3.0634775161743164], [3.796536684036255, 3.582489252090454, 3.2517144680023193]], Known param reward error: [[0.0, 0.09841814428830158, 0.011854667156547932], [0.09841814428830158, 0.0, 0.057888524247839544], [0.010950959994698183, 0.06671320456137621, 0.0]].
