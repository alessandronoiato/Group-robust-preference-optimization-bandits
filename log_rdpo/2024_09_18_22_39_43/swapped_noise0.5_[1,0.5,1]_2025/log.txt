2024-09-18 22:52:09,885 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log_rdpo/2024_09_18_22_39_43/swapped_noise0.5_[1,0.5,1]_2025
2024-09-18 22:52:09,887 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2025
2024-09-18 22:52:09,888 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-09-18 22:52:10,050 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.4543, l2 distance: 16.6174, acc: 0.81.
2024-09-18 22:52:10,051 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-18 22:52:10,052 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [8.68775344 5.26920364 6.98565022 4.61655316]
2024-09-18 22:52:10,258 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.5914, 3.7958, 3.1513
2024-09-18 22:52:10,509 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-18 22:52:11,822 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  16.1995, val_loss:  14.9576, grad_norm: 0.2510, live_grad: 0.0000, reward_err: 0.0907, 0.0049, 0.0538, KL_dist: 1.4817, 0.8657, 1.2254, param: [12.13306186  5.48596562  8.64464764  4.33324748], weights: [0.33308198 0.33292875 0.33398928], train_wt_loss:  48.5985, val_wt_loss: 44.8727, train_grp_loss: [19.39119611 12.73617226 17.32836851], val_grp_loss: [19.62055278  7.50583318 17.75470251], train_hist_grp_loss: [0.18422462 0.13821097 0.45624995], cur_train_grp_loss: [0.18422462 0.13821097 0.45624995], max_reward_err:  0.0907, max_reward_err_index: 0, max_kl_dist:  1.4817, max_kl_dist_index: 0, max_train_grp_loss:  19.3912, max_train_grp_loss_index: 0, max_val_grp_loss:  19.6206, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4562, max_cur_train_grp_loss_index: 2, 
2024-09-18 22:52:16,304 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  100, train_loss:  16.2062, val_loss:  14.9571, grad_norm: 0.0135, live_grad: 0.0000, reward_err: 0.0893, 0.0056, 0.0526, KL_dist: 1.5038, 0.8983, 1.2501, param: [12.28635913  5.72543725  8.67985555  4.59575474], weights: [0.31532922 0.29763737 0.38703341], train_wt_loss:  48.6185, val_wt_loss: 44.8713, train_grp_loss: [19.21292805 12.99129604 17.14140054], val_grp_loss: [19.44364472  7.8493726  17.58708567], train_hist_grp_loss: [15.87917399 10.10503848 36.36855504], cur_train_grp_loss: [0.15621806 0.10068542 0.35715408], max_reward_err:  0.0893, max_reward_err_index: 0, max_kl_dist:  1.5038, max_kl_dist_index: 0, max_train_grp_loss:  19.2129, max_train_grp_loss_index: 0, max_val_grp_loss:  19.4436, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.3572, max_cur_train_grp_loss_index: 2, 
2024-09-18 22:52:20,707 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  199, train_loss:  16.2297, val_loss:  14.9699, grad_norm: 0.0327,  live_grad: 0.0000, reward_err: 0.0872, 0.0065, 0.0509, KL_dist: 1.5316, 0.9373, 1.2805, param: [12.47131885  5.99595407  8.71808177  4.89271813], weights: [0.29492505 0.26401185 0.44106311], train_wt_loss:  48.6891, val_wt_loss: 44.9098, train_grp_loss: [19.01378413 13.31426898 16.93073841], val_grp_loss: [19.24582963  8.27474256 17.3986251 ], train_hist_grp_loss: [31.26547569 20.19274823 71.51214716], cur_train_grp_loss: [0.15460093 0.10318293 0.3527708 ], max_reward_err:  0.0872, max_reward_err_index: 0, max_kl_dist:  1.5316, max_kl_dist_index: 0, max_train_grp_loss:  19.0138, max_train_grp_loss_index: 0, max_val_grp_loss:  19.2458, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.3528, max_cur_train_grp_loss_index: 2, 
2024-09-18 22:52:20,928 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:387] - INFO: Policy parameter learned solely on the preference data rdpo: [12.47131885  5.99595407  8.71808177  4.89271813].
2024-09-18 22:52:21,261 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Uniform reward: 3.8103, 3.8103, 3.1427
2024-09-18 22:52:21,262 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Optimal reward: 3.8440, 3.8440, 3.2545
2024-09-18 22:52:21,262 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Policy reward: 3.5087, 3.8191, 3.0889
2024-09-18 22:52:21,263 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Reward Error: 0.0872, 0.0065, 0.0509
2024-09-18 22:52:21,943 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:416] - INFO: Optimal reward: 3.8440, 3.8440, 3.2545
Known param reward: [[3.843956232070923, 3.4647014141082764, 3.2180964946746826], [3.4647014141082764, 3.843956232070923, 3.0630156993865967], [3.8041796684265137, 3.590562105178833, 3.254488229751587]], Known param reward error: [[0.0, 0.09866262648841967, 0.011182014654169469], [0.09866262648841967, 0.0, 0.058833376201703216], [0.010347819080910722, 0.06592013841832281, 0.0]].
