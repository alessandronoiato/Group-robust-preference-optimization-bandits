2024-09-18 22:54:13,800 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log_rdpo/2024_09_18_22_39_43/swapped_noise0.5_[1,0.5,1]_2030
2024-09-18 22:54:13,802 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2030
2024-09-18 22:54:13,803 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-09-18 22:54:13,962 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.5211, l2 distance: 8.2067, acc: 0.78.
2024-09-18 22:54:13,962 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-18 22:54:13,963 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [3.37196976 3.35883333 5.6739704  3.17762949]
2024-09-18 22:54:14,172 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.5758, 3.8158, 3.2448
2024-09-18 22:54:14,421 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-18 22:54:15,740 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  18.0522, val_loss:  16.1535, grad_norm: 0.3040, live_grad: 0.0000, reward_err: 0.0863, 0.0125, 0.0484, KL_dist: 0.9628, 0.4976, 0.7585, param: [5.58152718 4.73687634 9.08829576 4.75358236], weights: [0.33311337 0.33290346 0.33398318], train_wt_loss:  54.1567, val_wt_loss: 48.4604, train_grp_loss: [19.51821623 16.57079423 19.20461151], val_grp_loss: [19.78399283 10.0779637  18.29399952], train_hist_grp_loss: [0.21737149 0.15433669 0.47814622], cur_train_grp_loss: [0.21737149 0.15433669 0.47814622], max_reward_err:  0.0863, max_reward_err_index: 0, max_kl_dist:  0.9628, max_kl_dist_index: 0, max_train_grp_loss:  19.5182, max_train_grp_loss_index: 0, max_val_grp_loss:  19.7840, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4781, max_cur_train_grp_loss_index: 2, 
2024-09-18 22:54:20,286 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  100, train_loss:  18.0601, val_loss:  16.1306, grad_norm: 0.0149, live_grad: 0.0000, reward_err: 0.0868, 0.0145, 0.0493, KL_dist: 1.0100, 0.5327, 0.8074, param: [5.2740275  4.93722096 9.53772734 4.98658789], weights: [0.31548035 0.29513862 0.38938104], train_wt_loss:  54.1802, val_wt_loss: 48.3917, train_grp_loss: [19.37385299 16.773944   18.97086118], val_grp_loss: [19.67877939 10.26753569 18.1448078 ], train_hist_grp_loss: [18.39343445 11.72830873 39.43963464], cur_train_grp_loss: [0.18107846 0.11646953 0.38721083], max_reward_err:  0.0868, max_reward_err_index: 0, max_kl_dist:  1.0100, max_kl_dist_index: 0, max_train_grp_loss:  19.3739, max_train_grp_loss_index: 0, max_val_grp_loss:  19.6788, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.3872, max_cur_train_grp_loss_index: 2, 
2024-09-18 22:54:24,709 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  199, train_loss:  18.0878, val_loss:  16.1159, grad_norm: 0.0368,  live_grad: 0.0000, reward_err: 0.0896, 0.0175, 0.0523, KL_dist: 1.0687, 0.5748, 0.8680, param: [ 4.94681068  5.16819516 10.03177917  5.25514222], weights: [0.29499615 0.25929738 0.44570647], train_wt_loss:  54.2633, val_wt_loss: 48.3478, train_grp_loss: [19.21036134 17.04070233 18.7134803 ], val_grp_loss: [19.55994447 10.51330618 17.9790417 ], train_hist_grp_loss: [36.24558288 23.34691365 77.5154118 ], cur_train_grp_loss: [0.17955256 0.11831681 0.38196339], max_reward_err:  0.0896, max_reward_err_index: 0, max_kl_dist:  1.0687, max_kl_dist_index: 0, max_train_grp_loss:  19.2104, max_train_grp_loss_index: 0, max_val_grp_loss:  19.5599, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.3820, max_cur_train_grp_loss_index: 2, 
2024-09-18 22:54:24,931 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:387] - INFO: Policy parameter learned solely on the preference data rdpo: [ 4.94681068  5.16819516 10.03177917  5.25514222].
2024-09-18 22:54:25,263 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Uniform reward: 3.8388, 3.8388, 3.2321
2024-09-18 22:54:25,264 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Optimal reward: 3.8833, 3.8833, 3.3901
2024-09-18 22:54:25,264 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Policy reward: 3.5353, 3.8152, 3.2128
2024-09-18 22:54:25,265 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Reward Error: 0.0896, 0.0175, 0.0523
2024-09-18 22:54:25,957 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:416] - INFO: Optimal reward: 3.8833, 3.8833, 3.3901
Known param reward: [[3.883310317993164, 3.4867608547210693, 3.3494973182678223], [3.4867608547210693, 3.883310317993164, 3.1918535232543945], [3.8442142009735107, 3.598407745361328, 3.390115261077881]], Known param reward error: [[0.0, 0.1021163468277821, 0.011981286676708506], [0.1021163468277821, 0.0, 0.05848230002671041], [0.010067729287176206, 0.07336590416474088, 0.0]].
