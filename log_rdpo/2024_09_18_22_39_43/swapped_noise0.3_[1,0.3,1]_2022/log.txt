2024-09-18 22:59:09,638 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log_rdpo/2024_09_18_22_39_43/swapped_noise0.3_[1,0.3,1]_2022
2024-09-18 22:59:09,639 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2022
2024-09-18 22:59:09,640 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-09-18 22:59:09,804 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.5114, l2 distance: 13.3000, acc: 0.75.
2024-09-18 22:59:09,805 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-18 22:59:09,805 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [2.3431996  2.79147837 9.27451545 2.39716811]
2024-09-18 22:59:10,012 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.4661, 3.8464, 3.0767
2024-09-18 22:59:10,264 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-18 22:59:11,573 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  17.4756, val_loss:  16.1474, grad_norm: 0.2241, live_grad: 0.0000, reward_err: 0.1177, 0.0049, 0.0887, KL_dist: 2.2143, 0.7588, 1.9385, param: [ 3.45561303  3.57138084 16.50360987  3.72711974], weights: [0.33305091 0.33297639 0.33397269], train_wt_loss:  52.4267, val_wt_loss: 48.4422, train_grp_loss: [19.21005018 16.37036547 15.93296211], val_grp_loss: [21.50251881  7.16747212 19.79919354], train_hist_grp_loss: [0.17929471 0.15691683 0.45568014], cur_train_grp_loss: [0.17929471 0.15691683 0.45568014], max_reward_err:  0.1177, max_reward_err_index: 0, max_kl_dist:  2.2143, max_kl_dist_index: 0, max_train_grp_loss:  19.2101, max_train_grp_loss_index: 0, max_val_grp_loss:  21.5025, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4557, max_cur_train_grp_loss_index: 2, 
2024-09-18 22:59:16,080 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  100, train_loss:  17.4785, val_loss:  16.1048, grad_norm: 0.0081, live_grad: 0.0000, reward_err: 0.1169, 0.0049, 0.0882, KL_dist: 2.2651, 0.7865, 1.9872, param: [ 3.47534317  3.68961492 16.77468318  3.85100837], weights: [0.31472934 0.30624643 0.37902423], train_wt_loss:  52.4356, val_wt_loss: 48.3143, train_grp_loss: [19.11420113 16.51638856 15.80398283], val_grp_loss: [21.44693431  7.16960066 19.72456955], train_hist_grp_loss: [15.63361908 12.90132532 34.22233016], cur_train_grp_loss: [0.15415488 0.12802158 0.33628394], max_reward_err:  0.1169, max_reward_err_index: 0, max_kl_dist:  2.2651, max_kl_dist_index: 0, max_train_grp_loss:  19.1142, max_train_grp_loss_index: 0, max_val_grp_loss:  21.4469, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.3363, max_cur_train_grp_loss_index: 2, 
2024-09-18 22:59:20,497 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  199, train_loss:  17.4887, val_loss:  16.0604, grad_norm: 0.0191,  live_grad: 0.0000, reward_err: 0.1157, 0.0049, 0.0869, KL_dist: 2.3213, 0.8181, 2.0408, param: [ 3.50911926  3.81974604 17.07272688  3.98821214], weights: [0.29499402 0.28001149 0.42499449], train_wt_loss:  52.4661, val_wt_loss: 48.1811, train_grp_loss: [19.0101076  16.69192379 15.6615913 ], val_grp_loss: [21.38575891  7.1815129  19.64046021], train_hist_grp_loss: [30.85364071 25.64119486 67.36575204], cur_train_grp_loss: [0.15331618 0.12937965 0.33325755], max_reward_err:  0.1157, max_reward_err_index: 0, max_kl_dist:  2.3213, max_kl_dist_index: 0, max_train_grp_loss:  19.0101, max_train_grp_loss_index: 0, max_val_grp_loss:  21.3858, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.3333, max_cur_train_grp_loss_index: 2, 
2024-09-18 22:59:20,721 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:387] - INFO: Policy parameter learned solely on the preference data rdpo: [ 3.50911926  3.81974604 17.07272688  3.98821214].
2024-09-18 22:59:21,058 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Uniform reward: 3.8377, 3.8377, 3.1941
2024-09-18 22:59:21,059 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Optimal reward: 3.8690, 3.8690, 3.3258
2024-09-18 22:59:21,059 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Policy reward: 3.4214, 3.8501, 3.0367
2024-09-18 22:59:21,060 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Reward Error: 0.1157, 0.0049, 0.0869
2024-09-18 22:59:21,748 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:416] - INFO: Optimal reward: 3.8690, 3.8690, 3.3258
Known param reward: [[3.8689613342285156, 3.540985584259033, 3.2756898403167725], [3.540985584259033, 3.8689613342285156, 3.1665854454040527], [3.825187921524048, 3.636335849761963, 3.3258354663848877]], Known param reward error: [[0.0, 0.08477100741945821, 0.01507760277829452], [0.08477100741945821, 0.0, 0.04788271175481099], [0.011313995908205773, 0.060126081490793466, 0.0]].
