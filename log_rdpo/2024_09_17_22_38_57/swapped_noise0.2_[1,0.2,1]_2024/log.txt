2024-09-17 22:43:10,916 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:198] - INFO: Logging to log_rdpo/2024_09_17_22_38_57/swapped_noise0.2_[1,0.2,1]_2024
2024-09-17 22:43:10,918 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: (IB) Seed: 2024
2024-09-17 22:43:10,919 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Data: 300
2024-09-17 22:43:11,088 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:296] - INFO: MLE reward loss: 0.5015, l2 distance: 15.2278, acc: 0.82.
2024-09-17 22:43:11,089 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-17 22:43:11,090 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: MLE reward parameter: [7.15983146 5.87044235 6.17947344 5.83103905]
2024-09-17 22:43:11,299 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:313] - INFO: Learned oracle reward: 3.7401, 3.8139, 3.3584
2024-09-17 22:43:11,553 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-17 22:43:12,750 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  18.1338, val_loss:  19.3687, grad_norm: 0.2171, live_grad: 0.0000, reward_err: 0.0728, 0.0203, 0.0353, KL_dist: 1.1869, 0.7766, 0.9846, param: [10.22290377  6.52762215  7.58434711  5.73463649], weights: [0.33331832 0.3333633  0.33331838], train_wt_loss:  54.4014, val_wt_loss: 58.1061, train_grp_loss: [18.39515177 20.02287441 16.2532714 ], val_grp_loss: [18.81625438 21.83248276 17.57723123], train_hist_grp_loss: [0.21304334 0.22653634 0.21306264], cur_train_grp_loss: [0.21304334 0.22653634 0.21306264], max_reward_err:  0.0728, max_reward_err_index: 0, max_kl_dist:  1.1869, max_kl_dist_index: 0, max_train_grp_loss:  20.0229, max_train_grp_loss_index: 1, max_val_grp_loss:  21.8325, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2265, max_cur_train_grp_loss_index: 1, 
2024-09-17 22:43:17,169 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  99, train_loss:  18.1360, val_loss:  19.3241, grad_norm: 0.0054,  live_grad: 0.0000, reward_err: 0.0736, 0.0203, 0.0360, KL_dist: 1.1652, 0.7484, 0.9635, param: [10.13906982  6.39179085  7.44039929  5.58316664], weights: [0.33047346 0.34565988 0.32386666], train_wt_loss:  54.4080, val_wt_loss: 57.9724, train_grp_loss: [18.51069424 19.76038113 16.36894544], val_grp_loss: [18.92277538 21.46363002 17.68965218], train_hist_grp_loss: [17.61196646 22.1048619  15.59251994], cur_train_grp_loss: [0.1762818  0.21958696 0.15588416], max_reward_err:  0.0736, max_reward_err_index: 0, max_kl_dist:  1.1652, max_kl_dist_index: 0, max_train_grp_loss:  19.7604, max_train_grp_loss_index: 1, max_val_grp_loss:  21.4636, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2196, max_cur_train_grp_loss_index: 1, 
2024-09-17 22:43:17,395 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:386] - INFO: Policy parameter learned solely on the preference data rdpo: [10.13906982  6.39179085  7.44039929  5.58316664].
2024-09-17 22:43:17,726 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:397] - INFO: Uniform reward: 3.8925, 3.8925, 3.2811
2024-09-17 22:43:17,726 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Optimal reward: 3.9322, 3.9322, 3.4172
2024-09-17 22:43:17,727 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Policy reward: 3.6429, 3.8524, 3.2943
2024-09-17 22:43:17,727 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Reward Error: 0.0736, 0.0203, 0.0360
2024-09-17 22:43:18,413 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:415] - INFO: Optimal reward: 3.9322, 3.9322, 3.4172
Known param reward: [[3.9322431087493896, 3.5081164836883545, 3.382530450820923], [3.5081164836883545, 3.9322431087493896, 3.203848123550415], [3.891317367553711, 3.641733407974243, 3.4171640872955322]], Known param reward error: [[0.0, 0.10785869879645472, 0.010135198541788402], [0.10785869879645472, 0.0, 0.06242485239096118], [0.010407734227982341, 0.07387887593438752, 0.0]].
