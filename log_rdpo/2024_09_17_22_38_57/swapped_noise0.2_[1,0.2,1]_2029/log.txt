2024-09-17 22:44:46,713 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:198] - INFO: Logging to log_rdpo/2024_09_17_22_38_57/swapped_noise0.2_[1,0.2,1]_2029
2024-09-17 22:44:46,715 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: (IB) Seed: 2029
2024-09-17 22:44:46,716 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Data: 300
2024-09-17 22:44:46,883 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:296] - INFO: MLE reward loss: 0.5089, l2 distance: 11.4229, acc: 0.80.
2024-09-17 22:44:46,884 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-17 22:44:46,885 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: MLE reward parameter: [2.85849314 6.00174256 6.47047469 3.99509683]
2024-09-17 22:44:47,093 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:313] - INFO: Learned oracle reward: 3.6523, 3.6714, 3.2651
2024-09-17 22:44:47,344 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-17 22:44:48,782 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  18.0755, val_loss:  19.4049, grad_norm: 0.2673, live_grad: 0.0000, reward_err: 0.0719, 0.0307, 0.0398, KL_dist: 0.9984, 0.6277, 0.8568, param: [ 3.91755393  7.15414783 10.05097872  4.46626914], weights: [0.33343823 0.33317534 0.33338643], train_wt_loss:  54.2264, val_wt_loss: 58.2148, train_grp_loss: [20.16319782 16.35509996 18.00244623], val_grp_loss: [19.16850931 21.24865052 18.10587819], train_hist_grp_loss: [0.25196281 0.17309095 0.23642803], cur_train_grp_loss: [0.25196281 0.17309095 0.23642803], max_reward_err:  0.0719, max_reward_err_index: 0, max_kl_dist:  0.9984, max_kl_dist_index: 0, max_train_grp_loss:  20.1632, max_train_grp_loss_index: 0, max_val_grp_loss:  21.2487, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2520, max_cur_train_grp_loss_index: 0, 
2024-09-17 22:44:53,227 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  99, train_loss:  18.0766, val_loss:  19.4178, grad_norm: 0.0052,  live_grad: 0.0000, reward_err: 0.0706, 0.0311, 0.0389, KL_dist: 1.0020, 0.6440, 0.8623, param: [ 3.93308196  7.25656666 10.0675467   4.57309009], weights: [0.34356944 0.32193801 0.33449254], train_wt_loss:  54.2299, val_wt_loss: 58.2535, train_grp_loss: [20.08780324 16.47484232 17.94275194], val_grp_loss: [19.09519912 21.45780921 18.04077809], train_hist_grp_loss: [21.4484747  14.94545104 18.77100715], cur_train_grp_loss: [0.2137082  0.14975995 0.18690996], max_reward_err:  0.0706, max_reward_err_index: 0, max_kl_dist:  1.0020, max_kl_dist_index: 0, max_train_grp_loss:  20.0878, max_train_grp_loss_index: 0, max_val_grp_loss:  21.4578, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2137, max_cur_train_grp_loss_index: 0, 
2024-09-17 22:44:53,449 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:386] - INFO: Policy parameter learned solely on the preference data rdpo: [ 3.93308196  7.25656666 10.0675467   4.57309009].
2024-09-17 22:44:53,774 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:397] - INFO: Uniform reward: 3.8223, 3.8223, 3.2131
2024-09-17 22:44:53,775 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Optimal reward: 3.8685, 3.8685, 3.3593
2024-09-17 22:44:53,775 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Policy reward: 3.5956, 3.7483, 3.2285
2024-09-17 22:44:53,776 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Reward Error: 0.0706, 0.0311, 0.0389
2024-09-17 22:44:54,463 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:415] - INFO: Optimal reward: 3.8685, 3.8685, 3.3593
Known param reward: [[3.8685142993927, 3.4599270820617676, 3.3229901790618896], [3.4599270820617676, 3.8685142993927, 3.1513752937316895], [3.8328397274017334, 3.5916991233825684, 3.3593173027038574]], Known param reward error: [[0.0, 0.10561863953690821, 0.010813841137521808], [0.10561863953690821, 0.0, 0.06190007975870543], [0.00922177591448148, 0.0715559397191805, 0.0]].
