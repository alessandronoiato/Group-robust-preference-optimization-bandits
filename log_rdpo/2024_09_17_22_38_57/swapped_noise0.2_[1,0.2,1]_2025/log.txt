2024-09-17 22:43:30,033 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:198] - INFO: Logging to log_rdpo/2024_09_17_22_38_57/swapped_noise0.2_[1,0.2,1]_2025
2024-09-17 22:43:30,035 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: (IB) Seed: 2025
2024-09-17 22:43:30,035 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Data: 300
2024-09-17 22:43:30,198 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:296] - INFO: MLE reward loss: 0.5266, l2 distance: 10.2154, acc: 0.77.
2024-09-17 22:43:30,199 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-17 22:43:30,199 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: MLE reward parameter: [6.68024438 2.13602835 4.67140896 2.7561983 ]
2024-09-17 22:43:30,405 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:313] - INFO: Learned oracle reward: 3.4986, 3.8543, 3.0837
2024-09-17 22:43:30,661 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-17 22:43:31,867 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  18.2132, val_loss:  19.0430, grad_norm: 0.2205, live_grad: 0.0000, reward_err: 0.1062, 0.0004, 0.0685, KL_dist: 1.2943, 0.6156, 1.0409, param: [11.26048699  2.95932793  7.37007629  3.64740265], weights: [0.33337748 0.33327951 0.33334301], train_wt_loss:  54.6395, val_wt_loss: 57.1290, train_grp_loss: [19.85333133 16.99078918 18.05631808], val_grp_loss: [20.37563322 18.19287929 18.67886819], train_hist_grp_loss: [0.22967466 0.20028109 0.21933467], cur_train_grp_loss: [0.22967466 0.20028109 0.21933467], max_reward_err:  0.1062, max_reward_err_index: 0, max_kl_dist:  1.2943, max_kl_dist_index: 0, max_train_grp_loss:  19.8533, max_train_grp_loss_index: 0, max_val_grp_loss:  20.3756, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2297, max_cur_train_grp_loss_index: 0, 
2024-09-17 22:43:36,218 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  99, train_loss:  18.2142, val_loss:  19.0229, grad_norm: 0.0044,  live_grad: 0.0000, reward_err: 0.1059, 0.0005, 0.0684, KL_dist: 1.3087, 0.6263, 1.0559, param: [11.39356068  3.05687341  7.32907886  3.73361356], weights: [0.3434656  0.32299669 0.33353771], train_wt_loss:  54.6427, val_wt_loss: 57.0686, train_grp_loss: [19.77400716 17.11084956 17.99751433], val_grp_loss: [20.29963506 18.2626741  18.61578017], train_hist_grp_loss: [21.55131697 15.40683082 18.61821588], cur_train_grp_loss: [0.21494356 0.15414063 0.18554749], max_reward_err:  0.1059, max_reward_err_index: 0, max_kl_dist:  1.3087, max_kl_dist_index: 0, max_train_grp_loss:  19.7740, max_train_grp_loss_index: 0, max_val_grp_loss:  20.2996, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2149, max_cur_train_grp_loss_index: 0, 
2024-09-17 22:43:36,439 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:386] - INFO: Policy parameter learned solely on the preference data rdpo: [11.39356068  3.05687341  7.32907886  3.73361356].
2024-09-17 22:43:36,767 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:397] - INFO: Uniform reward: 3.8278, 3.8278, 3.1587
2024-09-17 22:43:36,768 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Optimal reward: 3.8601, 3.8601, 3.2689
2024-09-17 22:43:36,769 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Policy reward: 3.4513, 3.8583, 3.0454
2024-09-17 22:43:36,769 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Reward Error: 0.1059, 0.0005, 0.0684
2024-09-17 22:43:37,446 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:415] - INFO: Optimal reward: 3.8601, 3.8601, 3.2689
Known param reward: [[3.860135793685913, 3.485208511352539, 3.23291015625], [3.485208511352539, 3.860135793685913, 3.0802385807037354], [3.820385217666626, 3.60957407951355, 3.268871545791626]], Known param reward error: [[0.0, 0.09712800335849549, 0.011001163257064349], [0.09712800335849549, 0.0, 0.05770583592700006], [0.010297714418313411, 0.06491007766675233, 0.0]].
