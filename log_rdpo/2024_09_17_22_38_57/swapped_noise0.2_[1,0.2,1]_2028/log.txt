2024-09-17 22:44:28,047 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:198] - INFO: Logging to log_rdpo/2024_09_17_22_38_57/swapped_noise0.2_[1,0.2,1]_2028
2024-09-17 22:44:28,049 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: (IB) Seed: 2028
2024-09-17 22:44:28,049 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Data: 300
2024-09-17 22:44:28,210 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:296] - INFO: MLE reward loss: 0.5545, l2 distance: 11.3969, acc: 0.77.
2024-09-17 22:44:28,210 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-17 22:44:28,211 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: MLE reward parameter: [7.16676815 4.86261387 3.88616867 2.85919747]
2024-09-17 22:44:28,419 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:313] - INFO: Learned oracle reward: 3.5723, 3.7855, 3.1950
2024-09-17 22:44:28,675 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-17 22:44:29,849 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  19.3641, val_loss:  19.3689, grad_norm: 0.1249, live_grad: 0.0000, reward_err: 0.0959, 0.0262, 0.0631, KL_dist: 1.5105, 0.8436, 1.2946, param: [12.97761094  7.60131708  4.96935259  3.87490851], weights: [0.33321221 0.33342298 0.33336481], train_wt_loss:  58.0924, val_wt_loss: 58.1066, train_grp_loss: [18.74636628 22.83613099 16.73818041], val_grp_loss: [19.14945941 21.44440308 17.52958406], train_hist_grp_loss: [0.17764109 0.24087363 0.22342748], cur_train_grp_loss: [0.17764109 0.24087363 0.22342748], max_reward_err:  0.0959, max_reward_err_index: 0, max_kl_dist:  1.5105, max_kl_dist_index: 0, max_train_grp_loss:  22.8361, max_train_grp_loss_index: 1, max_val_grp_loss:  21.4444, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2409, max_cur_train_grp_loss_index: 1, 
2024-09-17 22:44:34,224 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  99, train_loss:  19.3693, val_loss:  19.3374, grad_norm: 0.0085,  live_grad: 0.0000, reward_err: 0.0986, 0.0261, 0.0656, KL_dist: 1.4856, 0.7981, 1.2690, param: [12.83564364  7.31976801  4.80871238  3.65105915], weights: [0.32005988 0.35115496 0.32878516], train_wt_loss:  58.1079, val_wt_loss: 58.0122, train_grp_loss: [18.92985385 22.41378873 16.93294624], val_grp_loss: [19.33657903 20.95069908 17.724938  ], train_hist_grp_loss: [15.85058888 25.1225384  18.54022961], cur_train_grp_loss: [0.15905981 0.24908479 0.18605604], max_reward_err:  0.0986, max_reward_err_index: 0, max_kl_dist:  1.4856, max_kl_dist_index: 0, max_train_grp_loss:  22.4138, max_train_grp_loss_index: 1, max_val_grp_loss:  20.9507, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2491, max_cur_train_grp_loss_index: 1, 
2024-09-17 22:44:34,445 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:386] - INFO: Policy parameter learned solely on the preference data rdpo: [12.83564364  7.31976801  4.80871238  3.65105915].
2024-09-17 22:44:34,767 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:397] - INFO: Uniform reward: 3.8587, 3.8587, 3.2275
2024-09-17 22:44:34,767 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Optimal reward: 3.8924, 3.8924, 3.3594
2024-09-17 22:44:34,768 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Policy reward: 3.5086, 3.7909, 3.1391
2024-09-17 22:44:34,768 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Reward Error: 0.0986, 0.0261, 0.0656
2024-09-17 22:44:35,426 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:415] - INFO: Optimal reward: 3.8924, 3.8924, 3.3594
Known param reward: [[3.8924267292022705, 3.4758362770080566, 3.323629379272461], [3.4758362770080566, 3.8924267292022705, 3.1391408443450928], [3.8593759536743164, 3.6333539485931396, 3.3593714237213135]], Known param reward error: [[0.0, 0.10702589442951226, 0.01063950362751482], [0.10702589442951226, 0.0, 0.06555707946466434], [0.008491046287396053, 0.0665581650299237, 0.0]].
