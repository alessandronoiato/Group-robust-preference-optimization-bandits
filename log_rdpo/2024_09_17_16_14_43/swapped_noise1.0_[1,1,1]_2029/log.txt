2024-09-17 16:17:24,472 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:198] - INFO: Logging to log_rdpo/2024_09_17_16_14_43/swapped_noise1.0_[1,1,1]_2029
2024-09-17 16:17:24,474 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: (IB) Seed: 2029
2024-09-17 16:17:24,474 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Data: 300
2024-09-17 16:17:24,634 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:296] - INFO: MLE reward loss: 0.3532, l2 distance: 33.1000, acc: 0.81.
2024-09-17 16:17:24,635 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-17 16:17:24,636 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: MLE reward parameter: [15.26318978  5.90939445 13.38318868  8.0442321 ]
2024-09-17 16:17:24,840 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:313] - INFO: Learned oracle reward: 3.5516, 3.8821, 3.2266
2024-09-17 16:17:25,069 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-17 16:17:26,226 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  14.1774, val_loss:  14.9434, grad_norm: 0.3153, live_grad: 0.0000, reward_err: 0.1027, 0.0015, 0.0598, KL_dist: 2.1089, 1.1765, 1.7340, param: [14.36847028  4.12658898 11.03669857  6.18848516], weights: [0.33346601 0.33313699 0.333397  ], train_wt_loss:  42.5323, val_wt_loss: 44.8303, train_grp_loss: [21.20733294  6.89059806 15.64345657], val_grp_loss: [20.57661697  7.10582661 16.66639199], train_hist_grp_loss: [0.25945051 0.1607373  0.2387541 ], cur_train_grp_loss: [0.25945051 0.1607373  0.2387541 ], max_reward_err:  0.1027, max_reward_err_index: 0, max_kl_dist:  2.1089, max_kl_dist_index: 0, max_train_grp_loss:  21.2073, max_train_grp_loss_index: 0, max_val_grp_loss:  20.5766, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2595, max_cur_train_grp_loss_index: 0, 
2024-09-17 16:17:30,527 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  99, train_loss:  14.1857, val_loss:  14.9362, grad_norm: 0.0129,  live_grad: 0.0000, reward_err: 0.0995, 0.0019, 0.0572, KL_dist: 2.1084, 1.1986, 1.7398, param: [14.43895932  4.43125347 11.0229533   6.48072729], weights: [0.3581214  0.30523722 0.33664138], train_wt_loss:  42.5570, val_wt_loss: 44.8085, train_grp_loss: [20.99098841  7.2236422  15.49948723], val_grp_loss: [20.35068474  7.51249088 16.48119224], train_hist_grp_loss: [22.48368902  6.50541018 16.29830593], cur_train_grp_loss: [0.22333261 0.06563566 0.16146857], max_reward_err:  0.0995, max_reward_err_index: 0, max_kl_dist:  2.1084, max_kl_dist_index: 0, max_train_grp_loss:  20.9910, max_train_grp_loss_index: 0, max_val_grp_loss:  20.3507, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2233, max_cur_train_grp_loss_index: 0, 
2024-09-17 16:17:30,743 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:386] - INFO: Policy parameter learned solely on the preference data rdpo: [14.43895932  4.43125347 11.0229533   6.48072729].
2024-09-17 16:17:31,062 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:397] - INFO: Uniform reward: 3.8498, 3.8498, 3.2396
2024-09-17 16:17:31,063 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Optimal reward: 3.8959, 3.8959, 3.3863
2024-09-17 16:17:31,063 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Policy reward: 3.5082, 3.8884, 3.1926
2024-09-17 16:17:31,064 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Reward Error: 0.0995, 0.0019, 0.0572
2024-09-17 16:17:31,720 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:415] - INFO: Optimal reward: 3.8959, 3.8959, 3.3863
Known param reward: [[3.8959105014801025, 3.483445405960083, 3.349421739578247], [3.483445405960083, 3.8959105014801025, 3.177966833114624], [3.861229658126831, 3.6135663986206055, 3.386277914047241]], Known param reward error: [[0.0, 0.10587129641795394, 0.010883978044478947], [0.10587129641795394, 0.0, 0.06151623883807166], [0.008901858330702367, 0.0724719170915839, 0.0]].
