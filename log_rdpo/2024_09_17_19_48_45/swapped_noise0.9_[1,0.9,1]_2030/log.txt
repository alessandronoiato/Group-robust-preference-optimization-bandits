2024-09-17 19:51:48,864 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:198] - INFO: Logging to log_rdpo/2024_09_17_19_48_45/swapped_noise0.9_[1,0.9,1]_2030
2024-09-17 19:51:48,865 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: (IB) Seed: 2030
2024-09-17 19:51:48,866 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Data: 300
2024-09-17 19:51:49,026 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:296] - INFO: MLE reward loss: 0.4341, l2 distance: 23.6252, acc: 0.80.
2024-09-17 19:51:49,027 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-17 19:51:49,028 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: MLE reward parameter: [11.04659098  5.03021714 10.54878401  5.92396953]
2024-09-17 19:51:49,231 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:313] - INFO: Learned oracle reward: 3.5096, 3.7761, 3.1577
2024-09-17 19:51:49,481 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-17 19:51:50,664 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  16.1080, val_loss:  15.3155, grad_norm: 0.2757, live_grad: 0.0000, reward_err: 0.0895, 0.0005, 0.0499, KL_dist: 1.8569, 0.9821, 1.5049, param: [12.56901329  4.56677473 11.08948311  4.46156874], weights: [0.33343739 0.33325968 0.33330293], train_wt_loss:  48.3239, val_wt_loss: 45.9466, train_grp_loss: [21.58970228  9.37304906 18.26061869], val_grp_loss: [19.73478132  7.81631992 17.34430614], train_hist_grp_loss: [0.2568948  0.2035829  0.21655954], cur_train_grp_loss: [0.2568948  0.2035829  0.21655954], max_reward_err:  0.0895, max_reward_err_index: 0, max_kl_dist:  1.8569, max_kl_dist_index: 0, max_train_grp_loss:  21.5897, max_train_grp_loss_index: 0, max_val_grp_loss:  19.7348, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2569, max_cur_train_grp_loss_index: 0, 
2024-09-17 19:51:54,962 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  99, train_loss:  16.1163, val_loss:  15.3088, grad_norm: 0.0121,  live_grad: 0.0000, reward_err: 0.0867, 0.0009, 0.0476, KL_dist: 1.8486, 0.9996, 1.5042, param: [12.61324678  4.87449433 11.0350535   4.78742726], weights: [0.35778737 0.30792406 0.33428857], train_wt_loss:  48.3488, val_wt_loss: 45.9263, train_grp_loss: [21.35516627  9.76989411 18.08247243], val_grp_loss: [19.51922063  8.23446301 17.17718043], train_hist_grp_loss: [24.14453215  9.13596571 17.35110535], cur_train_grp_loss: [0.23997304 0.09212785 0.17223146], max_reward_err:  0.0867, max_reward_err_index: 0, max_kl_dist:  1.8486, max_kl_dist_index: 0, max_train_grp_loss:  21.3552, max_train_grp_loss_index: 0, max_val_grp_loss:  19.5192, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2400, max_cur_train_grp_loss_index: 0, 
2024-09-17 19:51:55,188 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:386] - INFO: Policy parameter learned solely on the preference data rdpo: [12.61324678  4.87449433 11.0350535   4.78742726].
2024-09-17 19:51:55,507 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:397] - INFO: Uniform reward: 3.7539, 3.7539, 3.1386
2024-09-17 19:51:55,507 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Optimal reward: 3.7917, 3.7917, 3.2789
2024-09-17 19:51:55,508 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Policy reward: 3.4628, 3.7882, 3.1227
2024-09-17 19:51:55,508 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Reward Error: 0.0867, 0.0009, 0.0476
2024-09-17 19:51:56,167 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:415] - INFO: Optimal reward: 3.7917, 3.7917, 3.2789
Known param reward: [[3.7916831970214844, 3.4254605770111084, 3.243140459060669], [3.4254605770111084, 3.7916831970214844, 3.0971083641052246], [3.7576465606689453, 3.5452187061309814, 3.2788846492767334]], Known param reward error: [[0.0, 0.0965857644167261, 0.010901325920065232], [0.0965857644167261, 0.0, 0.055438450758432616], [0.00897665616665342, 0.065001340587766, 0.0]].
