2024-09-17 19:50:29,757 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:198] - INFO: Logging to log_rdpo/2024_09_17_19_48_45/swapped_noise0.9_[1,0.9,1]_2026
2024-09-17 19:50:29,759 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: (IB) Seed: 2026
2024-09-17 19:50:29,760 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Data: 300
2024-09-17 19:50:29,920 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:296] - INFO: MLE reward loss: 0.3488, l2 distance: 32.0217, acc: 0.83.
2024-09-17 19:50:29,921 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-17 19:50:29,922 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: MLE reward parameter: [12.90949056  6.74764614 14.72569219  7.55449294]
2024-09-17 19:50:30,122 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:313] - INFO: Learned oracle reward: 3.5580, 3.8415, 3.1779
2024-09-17 19:50:30,373 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-17 19:50:31,562 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  13.9487, val_loss:  15.1035, grad_norm: 0.2754, live_grad: 0.0000, reward_err: 0.0993, 0.0017, 0.0583, KL_dist: 2.0509, 1.1160, 1.7135, param: [ 9.67611515  4.90164117 14.81717532  5.46570274], weights: [0.33335384 0.33320371 0.33344245], train_wt_loss:  41.8462, val_wt_loss: 45.3106, train_grp_loss: [17.70570226  7.98833719 16.15632528], val_grp_loss: [18.56076613  9.07471429 17.2541935 ], train_hist_grp_loss: [0.20535787 0.16031328 0.23193731], cur_train_grp_loss: [0.20535787 0.16031328 0.23193731], max_reward_err:  0.0993, max_reward_err_index: 0, max_kl_dist:  2.0509, max_kl_dist_index: 0, max_train_grp_loss:  17.7057, max_train_grp_loss_index: 0, max_val_grp_loss:  18.5608, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2319, max_cur_train_grp_loss_index: 2, 
2024-09-17 19:50:35,882 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  99, train_loss:  13.9529, val_loss:  15.1143, grad_norm: 0.0089,  live_grad: 0.0000, reward_err: 0.0971, 0.0027, 0.0565, KL_dist: 2.0755, 1.1415, 1.7398, param: [ 9.68042996  5.11357101 14.98540367  5.66145947], weights: [0.34247421 0.31389479 0.34363101], train_wt_loss:  41.8587, val_wt_loss: 45.3428, train_grp_loss: [17.57335729  8.2682215  16.01679119], val_grp_loss: [18.42243318  9.38613282 17.13275822], train_hist_grp_loss: [16.83776885  8.12391913 17.17497597], cur_train_grp_loss: [0.16737816 0.08183418 0.17040642], max_reward_err:  0.0971, max_reward_err_index: 0, max_kl_dist:  2.0755, max_kl_dist_index: 0, max_train_grp_loss:  17.5734, max_train_grp_loss_index: 0, max_val_grp_loss:  18.4224, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.1704, max_cur_train_grp_loss_index: 2, 
2024-09-17 19:50:36,100 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:386] - INFO: Policy parameter learned solely on the preference data rdpo: [ 9.68042996  5.11357101 14.98540367  5.66145947].
2024-09-17 19:50:36,426 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:397] - INFO: Uniform reward: 3.8265, 3.8265, 3.1866
2024-09-17 19:50:36,426 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Optimal reward: 3.8643, 3.8643, 3.3087
2024-09-17 19:50:36,427 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Policy reward: 3.4889, 3.8537, 3.1217
2024-09-17 19:50:36,427 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Reward Error: 0.0971, 0.0027, 0.0565
2024-09-17 19:50:37,086 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:415] - INFO: Optimal reward: 3.8643, 3.8643, 3.3087
Known param reward: [[3.8642568588256836, 3.4780359268188477, 3.275341033935547], [3.4780359268188477, 3.8642568588256836, 3.1216068267822266], [3.821747303009033, 3.596567392349243, 3.308689832687378]], Known param reward error: [[0.0, 0.09994701338880597, 0.010079155326791257], [0.09994701338880597, 0.0, 0.05654292646500478], [0.011000706570413826, 0.06927320730894403, 0.0]].
