2024-09-17 19:51:08,920 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:198] - INFO: Logging to log_rdpo/2024_09_17_19_48_45/swapped_noise0.9_[1,0.9,1]_2028
2024-09-17 19:51:08,922 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: (IB) Seed: 2028
2024-09-17 19:51:08,923 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Data: 300
2024-09-17 19:51:09,084 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:296] - INFO: MLE reward loss: 0.3491, l2 distance: 38.8397, acc: 0.84.
2024-09-17 19:51:09,085 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-17 19:51:09,086 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: MLE reward parameter: [14.06675007 10.59085566 17.19494705  8.75064143]
2024-09-17 19:51:09,286 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:313] - INFO: Learned oracle reward: 3.5930, 3.8290, 3.2226
2024-09-17 19:51:09,549 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-17 19:51:10,752 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  14.8560, val_loss:  15.9490, grad_norm: 0.2466, live_grad: 0.0000, reward_err: 0.0877, 0.0037, 0.0513, KL_dist: 2.0565, 1.1738, 1.7263, param: [ 9.84490086  7.04940341 14.79624397  4.96441027], weights: [0.33326826 0.33327025 0.33346148], train_wt_loss:  44.5679, val_wt_loss: 47.8470, train_grp_loss: [17.98465646  8.63405099 16.9181054 ], val_grp_loss: [19.36030972 11.36601708 16.96153661], train_hist_grp_loss: [0.18440082 0.18499744 0.24236039], cur_train_grp_loss: [0.18440082 0.18499744 0.24236039], max_reward_err:  0.0877, max_reward_err_index: 0, max_kl_dist:  2.0565, max_kl_dist_index: 0, max_train_grp_loss:  17.9847, max_train_grp_loss_index: 0, max_val_grp_loss:  19.3603, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2424, max_cur_train_grp_loss_index: 2, 
2024-09-17 19:51:15,028 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  99, train_loss:  14.8587, val_loss:  15.9925, grad_norm: 0.0070,  live_grad: 0.0000, reward_err: 0.0864, 0.0041, 0.0503, KL_dist: 2.0788, 1.1979, 1.7506, param: [ 9.81278142  7.22202329 14.95270172  5.13554281], weights: [0.33508388 0.31789812 0.347018  ], train_wt_loss:  44.5760, val_wt_loss: 47.9774, train_grp_loss: [17.86026284  8.90715805 16.81956506], val_grp_loss: [19.25247622 11.69878661 16.86712768], train_hist_grp_loss: [15.09500072  9.83000889 18.59457773], cur_train_grp_loss: [0.15009667 0.0989371  0.18484124], max_reward_err:  0.0864, max_reward_err_index: 0, max_kl_dist:  2.0788, max_kl_dist_index: 0, max_train_grp_loss:  17.8603, max_train_grp_loss_index: 0, max_val_grp_loss:  19.2525, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.1848, max_cur_train_grp_loss_index: 2, 
2024-09-17 19:51:15,246 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:386] - INFO: Policy parameter learned solely on the preference data rdpo: [ 9.81278142  7.22202329 14.95270172  5.13554281].
2024-09-17 19:51:15,571 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:397] - INFO: Uniform reward: 3.8293, 3.8293, 3.2043
2024-09-17 19:51:15,572 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Optimal reward: 3.8668, 3.8668, 3.3433
2024-09-17 19:51:15,572 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Policy reward: 3.5329, 3.8508, 3.1751
2024-09-17 19:51:15,573 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Reward Error: 0.0864, 0.0041, 0.0503
2024-09-17 19:51:16,234 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:415] - INFO: Optimal reward: 3.8668, 3.8668, 3.3433
Known param reward: [[3.8668320178985596, 3.456228494644165, 3.3080341815948486], [3.456228494644165, 3.8668320178985596, 3.1274757385253906], [3.834106922149658, 3.6062734127044678, 3.3432865142822266]], Known param reward error: [[0.0, 0.10618602549937976, 0.010544215261474917], [0.10618602549937976, 0.0, 0.06455048792106546], [0.008463024925164944, 0.06738296465634758, 0.0]].
