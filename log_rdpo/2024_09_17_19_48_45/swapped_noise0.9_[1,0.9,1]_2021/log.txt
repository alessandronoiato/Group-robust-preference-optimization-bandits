2024-09-17 19:48:49,203 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:198] - INFO: Logging to log_rdpo/2024_09_17_19_48_45/swapped_noise0.9_[1,0.9,1]_2021
2024-09-17 19:48:49,205 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: (IB) Seed: 2021
2024-09-17 19:48:49,206 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Data: 300
2024-09-17 19:48:49,367 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:296] - INFO: MLE reward loss: 0.4663, l2 distance: 18.0905, acc: 0.74.
2024-09-17 19:48:49,368 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-17 19:48:49,368 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: MLE reward parameter: [7.60830304 2.96644436 9.79918051 5.12566951]
2024-09-17 19:48:49,574 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:313] - INFO: Learned oracle reward: 3.4399, 3.7688, 3.0673
2024-09-17 19:48:49,809 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-17 19:48:50,994 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  16.6493, val_loss:  15.1758, grad_norm: 0.2925, live_grad: 0.0000, reward_err: 0.1093, 0.0060, 0.0717, KL_dist: 1.9738, 0.8951, 1.6493, param: [ 7.29101325  2.80076253 14.5520873   5.25203764], weights: [0.33335952 0.3332593  0.33338117], train_wt_loss:  49.9478, val_wt_loss: 45.5274, train_grp_loss: [23.59043218  7.31956223 19.65453963], val_grp_loss: [20.74171797  7.11263344 18.0420867 ], train_hist_grp_loss: [0.23619295 0.20612441 0.24268627], cur_train_grp_loss: [0.23619295 0.20612441 0.24268627], max_reward_err:  0.1093, max_reward_err_index: 0, max_kl_dist:  1.9738, max_kl_dist_index: 0, max_train_grp_loss:  23.5904, max_train_grp_loss_index: 0, max_val_grp_loss:  20.7417, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2427, max_cur_train_grp_loss_index: 2, 
2024-09-17 19:48:55,305 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  99, train_loss:  16.6642, val_loss:  15.1332, grad_norm: 0.0182,  live_grad: 0.0000, reward_err: 0.1054, 0.0076, 0.0682, KL_dist: 1.9081, 0.8962, 1.5978, param: [ 7.24784896  3.15797554 14.28202555  5.62989546], weights: [0.35415751 0.30159719 0.3442453 ], train_wt_loss:  49.9927, val_wt_loss: 45.3995, train_grp_loss: [23.26761393  7.8994606  19.40073872], val_grp_loss: [20.45197198  7.4562829  17.84166809], train_hist_grp_loss: [23.4338548   7.3689113  20.59512689], cur_train_grp_loss: [0.23270949 0.0751716  0.204246  ], max_reward_err:  0.1054, max_reward_err_index: 0, max_kl_dist:  1.9081, max_kl_dist_index: 0, max_train_grp_loss:  23.2676, max_train_grp_loss_index: 0, max_val_grp_loss:  20.4520, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2327, max_cur_train_grp_loss_index: 0, 
2024-09-17 19:48:55,521 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:386] - INFO: Policy parameter learned solely on the preference data rdpo: [ 7.24784896  3.15797554 14.28202555  5.62989546].
2024-09-17 19:48:55,849 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:397] - INFO: Uniform reward: 3.7630, 3.7630, 3.1214
2024-09-17 19:48:55,850 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Optimal reward: 3.7946, 3.7946, 3.2447
2024-09-17 19:48:55,851 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Policy reward: 3.3947, 3.7659, 3.0234
2024-09-17 19:48:55,851 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Reward Error: 0.1054, 0.0076, 0.0682
2024-09-17 19:48:56,514 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:415] - INFO: Optimal reward: 3.7946, 3.7946, 3.2447
Known param reward: [[3.7945611476898193, 3.4039535522460938, 3.2116000652313232], [3.4039535522460938, 3.7945611476898193, 3.0445375442504883], [3.760617256164551, 3.530181884765625, 3.244687080383301]], Known param reward error: [[0.0, 0.10293880642338121, 0.010197290010495838], [0.10293880642338121, 0.0, 0.061685312381238463], [0.008945406386700095, 0.06967321190360895, 0.0]].
