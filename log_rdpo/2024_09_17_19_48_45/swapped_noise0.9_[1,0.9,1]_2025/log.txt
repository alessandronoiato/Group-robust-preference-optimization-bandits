2024-09-17 19:50:10,003 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:198] - INFO: Logging to log_rdpo/2024_09_17_19_48_45/swapped_noise0.9_[1,0.9,1]_2025
2024-09-17 19:50:10,005 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: (IB) Seed: 2025
2024-09-17 19:50:10,006 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Data: 300
2024-09-17 19:50:10,166 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:296] - INFO: MLE reward loss: 0.3878, l2 distance: 26.1556, acc: 0.81.
2024-09-17 19:50:10,167 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-17 19:50:10,167 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: MLE reward parameter: [11.51788074  5.11842328 12.13433964  6.23296411]
2024-09-17 19:50:10,368 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:313] - INFO: Learned oracle reward: 3.5453, 3.8260, 3.1153
2024-09-17 19:50:10,634 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-17 19:50:11,820 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  14.7486, val_loss:  14.6658, grad_norm: 0.2705, live_grad: 0.0000, reward_err: 0.1025, 0.0001, 0.0633, KL_dist: 1.8662, 1.0707, 1.5329, param: [10.87068301  3.79120103 13.33584661  4.45951046], weights: [0.33346525 0.33312108 0.33341367], train_wt_loss:  44.2457, val_wt_loss: 43.9975, train_grp_loss: [19.32381753  8.24521815 17.85110286], val_grp_loss: [20.36038101  6.03046245 17.42821928], train_hist_grp_loss: [0.24587498 0.14261206 0.23040518], cur_train_grp_loss: [0.24587498 0.14261206 0.23040518], max_reward_err:  0.1025, max_reward_err_index: 0, max_kl_dist:  1.8662, max_kl_dist_index: 0, max_train_grp_loss:  19.3238, max_train_grp_loss_index: 0, max_val_grp_loss:  20.3604, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2459, max_cur_train_grp_loss_index: 0, 
2024-09-17 19:50:16,105 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  99, train_loss:  14.7570, val_loss:  14.6052, grad_norm: 0.0134,  live_grad: 0.0000, reward_err: 0.1001, 0.0002, 0.0612, KL_dist: 1.8751, 1.0908, 1.5466, param: [10.84708737  4.10532848 13.46442348  4.72641388], weights: [0.35081972 0.30724651 0.34193377], train_wt_loss:  44.2709, val_wt_loss: 43.8157, train_grp_loss: [19.0970281   8.62142795 17.66170562], val_grp_loss: [20.14519378  6.25354278 17.24579308], train_hist_grp_loss: [20.92013659  7.6579274  18.35459708], cur_train_grp_loss: [0.20760184 0.07763348 0.18209957], max_reward_err:  0.1001, max_reward_err_index: 0, max_kl_dist:  1.8751, max_kl_dist_index: 0, max_train_grp_loss:  19.0970, max_train_grp_loss_index: 0, max_val_grp_loss:  20.1452, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2076, max_cur_train_grp_loss_index: 0, 
2024-09-17 19:50:16,334 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:386] - INFO: Policy parameter learned solely on the preference data rdpo: [10.84708737  4.10532848 13.46442348  4.72641388].
2024-09-17 19:50:16,653 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:397] - INFO: Uniform reward: 3.8117, 3.8117, 3.1389
2024-09-17 19:50:16,654 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Optimal reward: 3.8428, 3.8428, 3.2468
2024-09-17 19:50:16,655 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Policy reward: 3.4580, 3.8420, 3.0480
2024-09-17 19:50:16,655 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Reward Error: 0.1001, 0.0002, 0.0612
2024-09-17 19:50:17,334 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:415] - INFO: Optimal reward: 3.8428, 3.8428, 3.2468
Known param reward: [[3.8428120613098145, 3.466555118560791, 3.208935022354126], [3.466555118560791, 3.8428120613098145, 3.0578837394714355], [3.8028461933135986, 3.5883326530456543, 3.246764659881592]], Known param reward error: [[0.0, 0.09791187722586076, 0.01165148740064377], [0.09791187722586076, 0.0, 0.05817511898661749], [0.010400162005995563, 0.06622218422449246, 0.0]].
