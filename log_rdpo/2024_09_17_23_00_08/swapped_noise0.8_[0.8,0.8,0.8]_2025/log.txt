2024-09-17 23:04:39,439 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:198] - INFO: Logging to log_rdpo/2024_09_17_23_00_08/swapped_noise0.8_[0.8,0.8,0.8]_2025
2024-09-17 23:04:39,440 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: (IB) Seed: 2025
2024-09-17 23:04:39,441 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Data: 300
2024-09-17 23:04:39,598 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:296] - INFO: MLE reward loss: 0.4236, l2 distance: 24.0392, acc: 0.79.
2024-09-17 23:04:39,599 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-17 23:04:39,600 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: MLE reward parameter: [10.95146557  6.00894238 10.92407557  5.19890253]
2024-09-17 23:04:39,803 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:313] - INFO: Learned oracle reward: 3.5852, 3.8496, 3.1956
2024-09-17 23:04:40,072 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-17 23:04:41,295 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  15.5968, val_loss:  16.5076, grad_norm: 0.2725, live_grad: 0.0000, reward_err: 0.0943, 0.0002, 0.0550, KL_dist: 2.0110, 1.0848, 1.6342, param: [12.88611113  4.81768536 11.54044478  3.5858037 ], weights: [0.33342218 0.33322036 0.33335746], train_wt_loss:  46.7904, val_wt_loss: 49.5229, train_grp_loss: [23.1792764   6.17550159 19.18624701], val_grp_loss: [21.91043682  9.26318542 18.6853579 ], train_hist_grp_loss: [0.24544677 0.18490106 0.22603486], cur_train_grp_loss: [0.24544677 0.18490106 0.22603486], max_reward_err:  0.0943, max_reward_err_index: 0, max_kl_dist:  2.0110, max_kl_dist_index: 0, max_train_grp_loss:  23.1793, max_train_grp_loss_index: 0, max_val_grp_loss:  21.9104, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2454, max_cur_train_grp_loss_index: 0, 
2024-09-17 23:04:45,570 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  99, train_loss:  15.6120, val_loss:  16.4776, grad_norm: 0.0165,  live_grad: 0.0000, reward_err: 0.0899, 0.0007, 0.0512, KL_dist: 1.9822, 1.0959, 1.6182, param: [12.88879238  5.25627183 11.38676542  4.00540722], weights: [0.36052863 0.29774005 0.34173132], train_wt_loss:  46.8359, val_wt_loss: 49.4328, train_grp_loss: [22.89309836  6.67205632 18.93630992], val_grp_loss: [21.63037094  9.641225   18.48103346], train_hist_grp_loss: [25.03798885  5.90292813 19.683332  ], cur_train_grp_loss: [0.24887065 0.06005783 0.19524672], max_reward_err:  0.0899, max_reward_err_index: 0, max_kl_dist:  1.9822, max_kl_dist_index: 0, max_train_grp_loss:  22.8931, max_train_grp_loss_index: 0, max_val_grp_loss:  21.6304, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2489, max_cur_train_grp_loss_index: 0, 
2024-09-17 23:04:45,790 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:386] - INFO: Policy parameter learned solely on the preference data rdpo: [12.88879238  5.25627183 11.38676542  4.00540722].
2024-09-17 23:04:46,111 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:397] - INFO: Uniform reward: 3.8311, 3.8311, 3.1785
2024-09-17 23:04:46,111 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Optimal reward: 3.8728, 3.8728, 3.3212
2024-09-17 23:04:46,112 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Policy reward: 3.5246, 3.8701, 3.1511
2024-09-17 23:04:46,112 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Reward Error: 0.0899, 0.0007, 0.0512
2024-09-17 23:04:46,795 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:415] - INFO: Optimal reward: 3.8728, 3.8728, 3.3212
Known param reward: [[3.872750997543335, 3.4923548698425293, 3.280984401702881], [3.4923548698425293, 3.872750997543335, 3.128255605697632], [3.8364126682281494, 3.625859260559082, 3.321218729019165]], Known param reward error: [[0.0, 0.09822375049212008, 0.012114326275694084], [0.09822375049212008, 0.0, 0.05810009489453885], [0.00938307919570265, 0.06375099693754331, 0.0]].
