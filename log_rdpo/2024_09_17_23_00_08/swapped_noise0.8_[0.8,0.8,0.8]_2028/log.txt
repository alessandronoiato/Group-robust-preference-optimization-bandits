2024-09-17 23:05:35,094 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:198] - INFO: Logging to log_rdpo/2024_09_17_23_00_08/swapped_noise0.8_[0.8,0.8,0.8]_2028
2024-09-17 23:05:35,096 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: (IB) Seed: 2028
2024-09-17 23:05:35,096 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Data: 300
2024-09-17 23:05:35,260 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:296] - INFO: MLE reward loss: 0.4703, l2 distance: 18.6595, acc: 0.79.
2024-09-17 23:05:35,261 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-17 23:05:35,262 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: MLE reward parameter: [9.55159483 5.16480276 8.41496352 3.30300138]
2024-09-17 23:05:35,464 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:313] - INFO: Learned oracle reward: 3.5127, 3.8159, 3.1225
2024-09-17 23:05:35,721 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-17 23:05:36,919 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  16.6535, val_loss:  16.8078, grad_norm: 0.2318, live_grad: 0.0000, reward_err: 0.0974, 0.0006, 0.0582, KL_dist: 1.9722, 1.1023, 1.6177, param: [13.76518816  5.26216357 10.56002626  3.25642039], weights: [0.33326102 0.3332754  0.33346358], train_wt_loss:  49.9605, val_wt_loss: 50.4234, train_grp_loss: [20.25696775  9.16209178 19.35036077], val_grp_loss: [20.50214892 10.20038412 19.39130547], train_hist_grp_loss: [0.19479247 0.19910804 0.25555479], cur_train_grp_loss: [0.19479247 0.19910804 0.25555479], max_reward_err:  0.0974, max_reward_err_index: 0, max_kl_dist:  1.9722, max_kl_dist_index: 0, max_train_grp_loss:  20.2570, max_train_grp_loss_index: 0, max_val_grp_loss:  20.5021, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2556, max_cur_train_grp_loss_index: 2, 
2024-09-17 23:05:41,317 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  99, train_loss:  16.6570, val_loss:  16.7882, grad_norm: 0.0076,  live_grad: 0.0000, reward_err: 0.0956, 0.0007, 0.0566, KL_dist: 1.9760, 1.1218, 1.6246, param: [13.76912861  5.4874152  10.6608275   3.4671649 ], weights: [0.33559099 0.31424836 0.35016066], train_wt_loss:  49.9710, val_wt_loss: 50.3645, train_grp_loss: [20.13801439  9.44184851 19.2407526 ], val_grp_loss: [20.38215806 10.38370593 19.27779471], train_hist_grp_loss: [16.99828892 10.42734003 21.24818444], cur_train_grp_loss: [0.16923713 0.1048766  0.21144909], max_reward_err:  0.0956, max_reward_err_index: 0, max_kl_dist:  1.9760, max_kl_dist_index: 0, max_train_grp_loss:  20.1380, max_train_grp_loss_index: 0, max_val_grp_loss:  20.3822, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2114, max_cur_train_grp_loss_index: 2, 
2024-09-17 23:05:41,536 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:386] - INFO: Policy parameter learned solely on the preference data rdpo: [13.76912861  5.4874152  10.6608275   3.4671649 ].
2024-09-17 23:05:41,860 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:397] - INFO: Uniform reward: 3.7921, 3.7921, 3.1395
2024-09-17 23:05:41,860 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Optimal reward: 3.8328, 3.8328, 3.2723
2024-09-17 23:05:41,861 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Policy reward: 3.4664, 3.8302, 3.0873
2024-09-17 23:05:41,861 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Reward Error: 0.0956, 0.0007, 0.0566
2024-09-17 23:05:42,562 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:415] - INFO: Optimal reward: 3.8328, 3.8328, 3.2723
Known param reward: [[3.8328447341918945, 3.4360735416412354, 3.2429821491241455], [3.4360735416412354, 3.8328447341918945, 3.0682969093322754], [3.796973705291748, 3.567776918411255, 3.272308111190796]], Known param reward error: [[0.0, 0.1035187230547478, 0.008961858440640128], [0.1035187230547478, 0.0, 0.06234474105932544], [0.0093588525984759, 0.06915694064412076, 0.0]].
