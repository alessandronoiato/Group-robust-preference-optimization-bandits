2024-09-17 23:03:40,411 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:198] - INFO: Logging to log_rdpo/2024_09_17_23_00_08/swapped_noise0.8_[0.8,0.8,0.8]_2022
2024-09-17 23:03:40,413 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: (IB) Seed: 2022
2024-09-17 23:03:40,413 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Data: 300
2024-09-17 23:03:40,572 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:296] - INFO: MLE reward loss: 0.4589, l2 distance: 19.0000, acc: 0.79.
2024-09-17 23:03:40,573 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-17 23:03:40,573 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: MLE reward parameter: [9.24563481 4.7262934  8.86667748 4.71278162]
2024-09-17 23:03:40,779 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:313] - INFO: Learned oracle reward: 3.6158, 3.8500, 3.2174
2024-09-17 23:03:41,030 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-17 23:03:42,203 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  16.5907, val_loss:  16.6040, grad_norm: 0.2543, live_grad: 0.0000, reward_err: 0.0730, 0.0023, 0.0381, KL_dist: 1.6557, 0.9611, 1.3573, param: [11.27559224  4.65277931 11.37059483  5.10571288], weights: [0.33338299 0.33326811 0.3333489 ], train_wt_loss:  49.7722, val_wt_loss: 49.8120, train_grp_loss: [20.90166959 10.5560601  18.46660642], val_grp_loss: [19.87072565 12.01674475 17.80663118], train_hist_grp_loss: [0.2351188  0.20065576 0.22489187], cur_train_grp_loss: [0.2351188  0.20065576 0.22489187], max_reward_err:  0.0730, max_reward_err_index: 0, max_kl_dist:  1.6557, max_kl_dist_index: 0, max_train_grp_loss:  20.9017, max_train_grp_loss_index: 0, max_val_grp_loss:  19.8707, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2351, max_cur_train_grp_loss_index: 0, 
2024-09-17 23:03:46,578 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  99, train_loss:  16.5940, val_loss:  16.6220, grad_norm: 0.0086,  live_grad: 0.0000, reward_err: 0.0727, 0.0032, 0.0378, KL_dist: 1.6580, 0.9762, 1.3630, param: [11.34559289  4.83895095 11.33382522  5.27323816], weights: [0.34919373 0.31325321 0.33755306], train_wt_loss:  49.7820, val_wt_loss: 49.8659, train_grp_loss: [20.77621336 10.75799609 18.39554926], val_grp_loss: [19.76537919 12.27239844 17.7185896 ], train_hist_grp_loss: [21.50486502 10.64336336 18.11444929], cur_train_grp_loss: [0.21420112 0.10649322 0.18035569], max_reward_err:  0.0727, max_reward_err_index: 0, max_kl_dist:  1.6580, max_kl_dist_index: 0, max_train_grp_loss:  20.7762, max_train_grp_loss_index: 0, max_val_grp_loss:  19.7654, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2142, max_cur_train_grp_loss_index: 0, 
2024-09-17 23:03:46,802 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:386] - INFO: Policy parameter learned solely on the preference data rdpo: [11.34559289  4.83895095 11.33382522  5.27323816].
2024-09-17 23:03:47,130 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:397] - INFO: Uniform reward: 3.8413, 3.8413, 3.1954
2024-09-17 23:03:47,131 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Optimal reward: 3.8718, 3.8718, 3.3255
2024-09-17 23:03:47,131 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Policy reward: 3.5903, 3.8593, 3.1996
2024-09-17 23:03:47,132 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Reward Error: 0.0727, 0.0032, 0.0378
2024-09-17 23:03:47,813 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:415] - INFO: Optimal reward: 3.8718, 3.8718, 3.3255
Known param reward: [[3.8717610836029053, 3.543931722640991, 3.2762246131896973], [3.543931722640991, 3.8717610836029053, 3.1653871536254883], [3.828972101211548, 3.640883684158325, 3.3254706859588623]], Known param reward error: [[0.0, 0.08467189836436118, 0.014808752630746911], [0.08467189836436118, 0.0, 0.04813860877177323], [0.01105155547241043, 0.05963110699737052, 0.0]].
