2024-09-17 23:04:58,508 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:198] - INFO: Logging to log_rdpo/2024_09_17_23_00_08/swapped_noise0.8_[0.8,0.8,0.8]_2026
2024-09-17 23:04:58,510 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: (IB) Seed: 2026
2024-09-17 23:04:58,511 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Data: 300
2024-09-17 23:04:58,668 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:296] - INFO: MLE reward loss: 0.5020, l2 distance: 14.5300, acc: 0.74.
2024-09-17 23:04:58,669 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-17 23:04:58,670 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: MLE reward parameter: [8.12325045 3.75093326 6.69577588 3.496602  ]
2024-09-17 23:04:58,878 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:313] - INFO: Learned oracle reward: 3.5262, 3.8545, 3.1910
2024-09-17 23:04:59,138 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-17 23:05:00,337 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  17.7159, val_loss:  17.0702, grad_norm: 0.1899, live_grad: 0.0000, reward_err: 0.0967, 0.0022, 0.0591, KL_dist: 1.5660, 0.8065, 1.2664, param: [12.06525332  4.80941849  8.83898107  4.18410437], weights: [0.33338751 0.3332021  0.33341039], train_wt_loss:  53.1478, val_wt_loss: 51.2105, train_grp_loss: [23.55239176 10.71964581 18.71380402], val_grp_loss: [21.00803025 10.36942553 19.35913548], train_hist_grp_loss: [0.22112039 0.16549182 0.22798219], cur_train_grp_loss: [0.22112039 0.16549182 0.22798219], max_reward_err:  0.0967, max_reward_err_index: 0, max_kl_dist:  1.5660, max_kl_dist_index: 0, max_train_grp_loss:  23.5524, max_train_grp_loss_index: 0, max_val_grp_loss:  21.0080, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2280, max_cur_train_grp_loss_index: 2, 
2024-09-17 23:05:04,709 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  99, train_loss:  17.7197, val_loss:  17.0756, grad_norm: 0.0087,  live_grad: 0.0000, reward_err: 0.0961, 0.0027, 0.0586, KL_dist: 1.5495, 0.8168, 1.2557, param: [11.99174506  5.02666714  8.85186741  4.36309572], weights: [0.3489511  0.31070614 0.34034276], train_wt_loss:  53.1590, val_wt_loss: 51.2269, train_grp_loss: [23.45225239 10.93142768 18.6099629 ], val_grp_loss: [20.88729382 10.63029739 19.25189683], train_hist_grp_loss: [22.38135914 10.7729395  19.88350247], cur_train_grp_loss: [0.22336467 0.10820914 0.19798974], max_reward_err:  0.0961, max_reward_err_index: 0, max_kl_dist:  1.5495, max_kl_dist_index: 0, max_train_grp_loss:  23.4523, max_train_grp_loss_index: 0, max_val_grp_loss:  20.8873, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2234, max_cur_train_grp_loss_index: 0, 
2024-09-17 23:05:04,929 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:386] - INFO: Policy parameter learned solely on the preference data rdpo: [11.99174506  5.02666714  8.85186741  4.36309572].
2024-09-17 23:05:05,252 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:397] - INFO: Uniform reward: 3.8279, 3.8279, 3.2154
2024-09-17 23:05:05,252 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Optimal reward: 3.8695, 3.8695, 3.3645
2024-09-17 23:05:05,253 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Policy reward: 3.4977, 3.8591, 3.1675
2024-09-17 23:05:05,253 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Reward Error: 0.0961, 0.0027, 0.0586
2024-09-17 23:05:05,932 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:415] - INFO: Optimal reward: 3.8695, 3.8695, 3.3645
Known param reward: [[3.8695008754730225, 3.466553211212158, 3.324392795562744], [3.466553211212158, 3.8695008754730225, 3.1501362323760986], [3.8326010704040527, 3.604762315750122, 3.364454984664917]], Known param reward error: [[0.0, 0.10413427396152389, 0.011907482574376856], [0.10413427396152389, 0.0, 0.063700882688482], [0.009536063243417396, 0.0684167204615344, 0.0]].
