2024-09-17 23:04:19,410 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:198] - INFO: Logging to log_rdpo/2024_09_17_23_00_08/swapped_noise0.8_[0.8,0.8,0.8]_2024
2024-09-17 23:04:19,412 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: (IB) Seed: 2024
2024-09-17 23:04:19,412 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Data: 300
2024-09-17 23:04:19,574 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:296] - INFO: MLE reward loss: 0.4566, l2 distance: 20.3015, acc: 0.77.
2024-09-17 23:04:19,575 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-17 23:04:19,575 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: MLE reward parameter: [10.5690194   4.65715223  8.57528304  4.72120913]
2024-09-17 23:04:19,781 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:313] - INFO: Learned oracle reward: 3.5722, 3.9111, 3.2469
2024-09-17 23:04:20,040 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-17 23:04:21,287 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  16.5663, val_loss:  17.9495, grad_norm: 0.2549, live_grad: 0.0000, reward_err: 0.1053, 0.0003, 0.0617, KL_dist: 1.9557, 1.0047, 1.5977, param: [13.6426031   4.45527625 10.31012576  4.4795905 ], weights: [0.33334423 0.33331022 0.33334555], train_wt_loss:  49.6989, val_wt_loss: 53.8485, train_grp_loss: [20.50206563 10.04778774 18.21784723], val_grp_loss: [21.32428863 12.61613797 19.63562252], train_hist_grp_loss: [0.22370296 0.21350122 0.22409927], cur_train_grp_loss: [0.22370296 0.21350122 0.22409927], max_reward_err:  0.1053, max_reward_err_index: 0, max_kl_dist:  1.9557, max_kl_dist_index: 0, max_train_grp_loss:  20.5021, max_train_grp_loss_index: 0, max_val_grp_loss:  21.3243, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2241, max_cur_train_grp_loss_index: 2, 
2024-09-17 23:04:25,705 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  99, train_loss:  16.5682, val_loss:  17.9613, grad_norm: 0.0063,  live_grad: 0.0000, reward_err: 0.1053, 0.0004, 0.0617, KL_dist: 1.9604, 1.0152, 1.6047, param: [13.7109188   4.60226007 10.30442729  4.61516977], weights: [0.34477817 0.31777657 0.33744526], train_wt_loss:  49.7047, val_wt_loss: 53.8839, train_grp_loss: [20.42378317 10.22774482 18.14737979], val_grp_loss: [21.24659204 12.81402718 19.5601466 ], train_hist_grp_loss: [19.51785941 11.36258998 17.36806921], cur_train_grp_loss: [0.19451985 0.11362053 0.17283898], max_reward_err:  0.1053, max_reward_err_index: 0, max_kl_dist:  1.9604, max_kl_dist_index: 0, max_train_grp_loss:  20.4238, max_train_grp_loss_index: 0, max_val_grp_loss:  21.2466, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.1945, max_cur_train_grp_loss_index: 0, 
2024-09-17 23:04:25,930 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:386] - INFO: Policy parameter learned solely on the preference data rdpo: [13.7109188   4.60226007 10.30442729  4.61516977].
2024-09-17 23:04:26,260 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:397] - INFO: Uniform reward: 3.8875, 3.8875, 3.2769
2024-09-17 23:04:26,261 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Optimal reward: 3.9272, 3.9272, 3.4129
2024-09-17 23:04:26,261 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Policy reward: 3.5137, 3.9258, 3.2022
2024-09-17 23:04:26,262 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Reward Error: 0.1053, 0.0004, 0.0617
2024-09-17 23:04:26,946 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:415] - INFO: Optimal reward: 3.9272, 3.9272, 3.4129
Known param reward: [[3.9271814823150635, 3.503054618835449, 3.378288984298706], [3.503054618835449, 3.9271814823150635, 3.1996068954467773], [3.8862557411193848, 3.636671543121338, 3.4129228591918945]], Known param reward error: [[0.0, 0.1079977753484396, 0.0101478633775476], [0.1079977753484396, 0.0, 0.06250242755138795], [0.010421148444495387, 0.07397415691175818, 0.0]].
