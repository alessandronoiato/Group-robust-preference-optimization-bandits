2024-09-17 23:05:54,153 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:198] - INFO: Logging to log_rdpo/2024_09_17_23_00_08/swapped_noise0.8_[0.8,0.8,0.8]_2029
2024-09-17 23:05:54,155 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: (IB) Seed: 2029
2024-09-17 23:05:54,155 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Data: 300
2024-09-17 23:05:54,318 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:296] - INFO: MLE reward loss: 0.4010, l2 distance: 24.6728, acc: 0.78.
2024-09-17 23:05:54,318 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-17 23:05:54,319 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: MLE reward parameter: [ 9.80241249  5.29789874 12.37468391  6.11589019]
2024-09-17 23:05:54,527 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:313] - INFO: Learned oracle reward: 3.5074, 3.8274, 3.1464
2024-09-17 23:05:54,782 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-17 23:05:55,996 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  15.0842, val_loss:  17.3356, grad_norm: 0.2292, live_grad: 0.0000, reward_err: 0.0951, 0.0014, 0.0541, KL_dist: 1.8972, 1.0079, 1.5570, param: [10.0018453   4.36441282 13.32001328  5.18068288], weights: [0.33347011 0.33308661 0.33344328], train_wt_loss:  45.2526, val_wt_loss: 52.0068, train_grp_loss: [20.70101773  7.12844262 18.70039519], val_grp_loss: [20.45765462 11.16232719 19.69084444], train_hist_grp_loss: [0.23540291 0.12033388 0.22735902], cur_train_grp_loss: [0.23540291 0.12033388 0.22735902], max_reward_err:  0.0951, max_reward_err_index: 0, max_kl_dist:  1.8972, max_kl_dist_index: 0, max_train_grp_loss:  20.7010, max_train_grp_loss_index: 0, max_val_grp_loss:  20.4577, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2354, max_cur_train_grp_loss_index: 0, 
2024-09-17 23:06:00,311 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  99, train_loss:  15.0909, val_loss:  17.3698, grad_norm: 0.0123,  live_grad: 0.0000, reward_err: 0.0951, 0.0021, 0.0543, KL_dist: 1.9081, 1.0301, 1.5725, param: [ 9.90817895  4.57386223 13.47416335  5.46655975], weights: [0.35294447 0.3028414  0.34421413], train_wt_loss:  45.2728, val_wt_loss: 52.1095, train_grp_loss: [20.54317945  7.38596887 18.58085098], val_grp_loss: [20.33681463 11.56970979 19.54974157], train_hist_grp_loss: [21.95651228  6.64636076 19.45183355], cur_train_grp_loss: [0.21856218 0.06711886 0.19356354], max_reward_err:  0.0951, max_reward_err_index: 0, max_kl_dist:  1.9081, max_kl_dist_index: 0, max_train_grp_loss:  20.5432, max_train_grp_loss_index: 0, max_val_grp_loss:  20.3368, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2186, max_cur_train_grp_loss_index: 0, 
2024-09-17 23:06:00,529 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:386] - INFO: Policy parameter learned solely on the preference data rdpo: [ 9.90817895  4.57386223 13.47416335  5.46655975].
2024-09-17 23:06:00,849 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:397] - INFO: Uniform reward: 3.8079, 3.8079, 3.1721
2024-09-17 23:06:00,850 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Optimal reward: 3.8486, 3.8486, 3.3067
2024-09-17 23:06:00,850 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Policy reward: 3.4826, 3.8405, 3.1271
2024-09-17 23:06:00,850 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Reward Error: 0.0951, 0.0021, 0.0543
2024-09-17 23:06:01,528 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:415] - INFO: Optimal reward: 3.8486, 3.8486, 3.3067
Known param reward: [[3.848555564880371, 3.458169937133789, 3.2784266471862793], [3.458169937133789, 3.848555564880371, 3.1137285232543945], [3.812652349472046, 3.571387767791748, 3.3066821098327637]], Known param reward error: [[0.0, 0.1014369212462486, 0.008544958876592283], [0.1014369212462486, 0.0, 0.05835262664185394], [0.009329010534746227, 0.07201865541916336, 0.0]].
