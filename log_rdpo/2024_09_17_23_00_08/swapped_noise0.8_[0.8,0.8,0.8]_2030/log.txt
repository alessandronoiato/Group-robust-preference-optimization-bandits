2024-09-17 23:06:14,879 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:198] - INFO: Logging to log_rdpo/2024_09_17_23_00_08/swapped_noise0.8_[0.8,0.8,0.8]_2030
2024-09-17 23:06:14,881 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: (IB) Seed: 2030
2024-09-17 23:06:14,882 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Data: 300
2024-09-17 23:06:15,042 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:296] - INFO: MLE reward loss: 0.4085, l2 distance: 24.8006, acc: 0.82.
2024-09-17 23:06:15,043 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-17 23:06:15,044 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: MLE reward parameter: [10.58796089  5.22407085 12.2021509   5.10448009]
2024-09-17 23:06:15,245 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:313] - INFO: Learned oracle reward: 3.4633, 3.7848, 3.1291
2024-09-17 23:06:15,488 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-17 23:06:16,665 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  15.2516, val_loss:  17.4264, grad_norm: 0.2477, live_grad: 0.0000, reward_err: 0.1143, 0.0003, 0.0721, KL_dist: 2.1182, 1.0808, 1.7197, param: [11.3593948   4.17280385 13.97971418  3.81399706], weights: [0.333451   0.33324641 0.33330259], train_wt_loss:  45.7548, val_wt_loss: 52.2791, train_grp_loss: [21.18805498  7.25320362 18.2943658 ], val_grp_loss: [22.10729086 10.08465139 19.28954442], train_hist_grp_loss: [0.24603236 0.18465809 0.20151444], cur_train_grp_loss: [0.24603236 0.18465809 0.20151444], max_reward_err:  0.1143, max_reward_err_index: 0, max_kl_dist:  2.1182, max_kl_dist_index: 0, max_train_grp_loss:  21.1881, max_train_grp_loss_index: 0, max_val_grp_loss:  22.1073, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2460, max_cur_train_grp_loss_index: 0, 
2024-09-17 23:06:20,980 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  99, train_loss:  15.2583, val_loss:  17.4071, grad_norm: 0.0119,  live_grad: 0.0000, reward_err: 0.1119, 0.0001, 0.0700, KL_dist: 2.1106, 1.0875, 1.7182, param: [11.28396151  4.41989118 14.04385458  4.09003434], weights: [0.35903613 0.30398055 0.33698332], train_wt_loss:  45.7749, val_wt_loss: 52.2214, train_grp_loss: [21.03093785  7.53298792 18.16417064], val_grp_loss: [21.95548993 10.34144276 19.1531173 ], train_hist_grp_loss: [23.72946964  7.083538   17.39051063], cur_train_grp_loss: [0.23632123 0.07103636 0.17300509], max_reward_err:  0.1119, max_reward_err_index: 0, max_kl_dist:  2.1106, max_kl_dist_index: 0, max_train_grp_loss:  21.0309, max_train_grp_loss_index: 0, max_val_grp_loss:  21.9555, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2363, max_cur_train_grp_loss_index: 0, 
2024-09-17 23:06:21,212 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:386] - INFO: Policy parameter learned solely on the preference data rdpo: [11.28396151  4.41989118 14.04385458  4.09003434].
2024-09-17 23:06:21,530 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:397] - INFO: Uniform reward: 3.7556, 3.7556, 3.1458
2024-09-17 23:06:21,531 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Optimal reward: 3.7933, 3.7933, 3.2870
2024-09-17 23:06:21,531 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Policy reward: 3.3687, 3.7928, 3.0568
2024-09-17 23:06:21,532 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Reward Error: 0.1119, 0.0001, 0.0700
2024-09-17 23:06:22,212 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:415] - INFO: Optimal reward: 3.7933, 3.7933, 3.2870
Known param reward: [[3.793292999267578, 3.4222915172576904, 3.2522172927856445], [3.4222915172576904, 3.793292999267578, 3.1010961532592773], [3.759493589401245, 3.5484824180603027, 3.287027359008789]], Known param reward error: [[0.0, 0.0978045940773681, 0.010590135834355084], [0.0978045940773681, 0.0, 0.0565651530827476], [0.008910308239532014, 0.0645377462944582, 0.0]].
