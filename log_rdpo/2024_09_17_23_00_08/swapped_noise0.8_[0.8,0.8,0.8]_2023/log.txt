2024-09-17 23:04:00,117 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:198] - INFO: Logging to log_rdpo/2024_09_17_23_00_08/swapped_noise0.8_[0.8,0.8,0.8]_2023
2024-09-17 23:04:00,119 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: (IB) Seed: 2023
2024-09-17 23:04:00,120 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Data: 300
2024-09-17 23:04:00,279 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:296] - INFO: MLE reward loss: 0.5051, l2 distance: 13.0237, acc: 0.73.
2024-09-17 23:04:00,279 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-17 23:04:00,280 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: MLE reward parameter: [5.76166032 4.28477317 7.63729755 1.95215171]
2024-09-17 23:04:00,482 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:313] - INFO: Learned oracle reward: 3.5214, 3.8432, 3.1369
2024-09-17 23:04:00,745 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-17 23:04:01,947 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  17.6423, val_loss:  16.6251, grad_norm: 0.1979, live_grad: 0.0000, reward_err: 0.1006, 0.0020, 0.0612, KL_dist: 1.4545, 0.7727, 1.1703, param: [ 8.91056068  5.22799677 11.401725    2.39986566], weights: [0.33339758 0.33319296 0.33340946], train_wt_loss:  52.9270, val_wt_loss: 49.8752, train_grp_loss: [23.31458502 10.7318403  19.40074863], val_grp_loss: [21.3651295   9.13590381 19.43531597], train_hist_grp_loss: [0.22781476 0.16642223 0.2313768 ], cur_train_grp_loss: [0.22781476 0.16642223 0.2313768 ], max_reward_err:  0.1006, max_reward_err_index: 0, max_kl_dist:  1.4545, max_kl_dist_index: 0, max_train_grp_loss:  23.3146, max_train_grp_loss_index: 0, max_val_grp_loss:  21.3651, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2314, max_cur_train_grp_loss_index: 2, 
2024-09-17 23:04:06,253 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  99, train_loss:  17.6469, val_loss:  16.5940, grad_norm: 0.0108,  live_grad: 0.0000, reward_err: 0.0983, 0.0021, 0.0592, KL_dist: 1.4462, 0.7775, 1.1675, param: [ 8.78244328  5.40118034 11.4596589   2.59963934], weights: [0.35054519 0.30794798 0.34150683], train_wt_loss:  52.9406, val_wt_loss: 49.7820, train_grp_loss: [23.17112563 10.94267596 19.3300281 ], val_grp_loss: [21.25204482  9.22242045 19.36717932], train_hist_grp_loss: [23.23979618 10.28392069 20.6276033 ], cur_train_grp_loss: [0.23172625 0.10321078 0.20564643], max_reward_err:  0.0983, max_reward_err_index: 0, max_kl_dist:  1.4462, max_kl_dist_index: 0, max_train_grp_loss:  23.1711, max_train_grp_loss_index: 0, max_val_grp_loss:  21.2520, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2317, max_cur_train_grp_loss_index: 0, 
2024-09-17 23:04:06,469 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:386] - INFO: Policy parameter learned solely on the preference data rdpo: [ 8.78244328  5.40118034 11.4596589   2.59963934].
2024-09-17 23:04:06,792 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:397] - INFO: Uniform reward: 3.8265, 3.8265, 3.1778
2024-09-17 23:04:06,792 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Optimal reward: 3.8671, 3.8671, 3.3081
2024-09-17 23:04:06,793 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Policy reward: 3.4871, 3.8590, 3.1123
2024-09-17 23:04:06,793 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Reward Error: 0.0983, 0.0021, 0.0592
2024-09-17 23:04:07,457 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:415] - INFO: Optimal reward: 3.8671, 3.8671, 3.3081
Known param reward: [[3.867140769958496, 3.49029541015625, 3.2803642749786377], [3.49029541015625, 3.867140769958496, 3.118959903717041], [3.833752155303955, 3.6075756549835205, 3.3081343173980713]], Known param reward error: [[0.0, 0.09744805845438374, 0.00839447245941193], [0.09744805845438374, 0.0, 0.05718462297196584], [0.008633927917472566, 0.06712067918276514, 0.0]].
