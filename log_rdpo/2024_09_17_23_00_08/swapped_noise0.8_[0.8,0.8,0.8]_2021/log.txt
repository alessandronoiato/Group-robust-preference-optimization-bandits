2024-09-17 23:03:21,839 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:198] - INFO: Logging to log_rdpo/2024_09_17_23_00_08/swapped_noise0.8_[0.8,0.8,0.8]_2021
2024-09-17 23:03:21,841 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: (IB) Seed: 2021
2024-09-17 23:03:21,841 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Data: 300
2024-09-17 23:03:22,003 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:296] - INFO: MLE reward loss: 0.4786, l2 distance: 16.2585, acc: 0.78.
2024-09-17 23:03:22,004 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-17 23:03:22,005 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: MLE reward parameter: [8.85125512 3.67477553 7.24668871 4.26292019]
2024-09-17 23:03:22,208 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:313] - INFO: Learned oracle reward: 3.5287, 3.8752, 3.1509
2024-09-17 23:03:22,455 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-17 23:03:23,617 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  16.9138, val_loss:  16.9234, grad_norm: 0.2779, live_grad: 0.0000, reward_err: 0.1049, 0.0005, 0.0625, KL_dist: 1.7099, 0.9342, 1.4054, param: [13.00667366  3.94118605  9.58774181  4.95367905], weights: [0.33334207 0.33326764 0.33339029], train_wt_loss:  50.7414, val_wt_loss: 50.7702, train_grp_loss: [20.56257422 11.36086837 19.21048661], val_grp_loss: [21.018018   10.69496885 19.43129593], train_hist_grp_loss: [0.23889649 0.21656322 0.25336058], cur_train_grp_loss: [0.23889649 0.21656322 0.25336058], max_reward_err:  0.1049, max_reward_err_index: 0, max_kl_dist:  1.7099, max_kl_dist_index: 0, max_train_grp_loss:  20.5626, max_train_grp_loss_index: 0, max_val_grp_loss:  21.0180, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2534, max_cur_train_grp_loss_index: 2, 
2024-09-17 23:03:27,996 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  99, train_loss:  16.9167, val_loss:  16.9281, grad_norm: 0.0073,  live_grad: 0.0000, reward_err: 0.1020, 0.0007, 0.0600, KL_dist: 1.7171, 0.9488, 1.4158, param: [13.10571887  4.10838332  9.56211376  5.15463242], weights: [0.34412738 0.31282066 0.34305196], train_wt_loss:  50.7501, val_wt_loss: 50.7842, train_grp_loss: [20.46066272 11.53586387 19.13342454], val_grp_loss: [20.91658894 10.89055305 19.33925673], train_hist_grp_loss: [20.54623963 11.00805775 20.23324385], cur_train_grp_loss: [0.20461712 0.1098474  0.20141283], max_reward_err:  0.1020, max_reward_err_index: 0, max_kl_dist:  1.7171, max_kl_dist_index: 0, max_train_grp_loss:  20.4607, max_train_grp_loss_index: 0, max_val_grp_loss:  20.9166, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2046, max_cur_train_grp_loss_index: 0, 
2024-09-17 23:03:28,211 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:386] - INFO: Policy parameter learned solely on the preference data rdpo: [13.10571887  4.10838332  9.56211376  5.15463242].
2024-09-17 23:03:28,530 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:397] - INFO: Uniform reward: 3.8503, 3.8503, 3.2061
2024-09-17 23:03:28,530 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Optimal reward: 3.8851, 3.8851, 3.3189
2024-09-17 23:03:28,531 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Policy reward: 3.4889, 3.8823, 3.1197
2024-09-17 23:03:28,531 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Reward Error: 0.1020, 0.0007, 0.0600
2024-09-17 23:03:29,193 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:415] - INFO: Optimal reward: 3.8851, 3.8851, 3.3189
Known param reward: [[3.88508939743042, 3.4581034183502197, 3.2941160202026367], [3.4581034183502197, 3.88508939743042, 3.1016483306884766], [3.85002064704895, 3.5887107849121094, 3.318911552429199]], Known param reward error: [[0.0, 0.10990377193446481, 0.007470983132531505], [0.10990377193446481, 0.0, 0.06546219093476653], [0.009026497666865538, 0.07628617573493521, 0.0]].
