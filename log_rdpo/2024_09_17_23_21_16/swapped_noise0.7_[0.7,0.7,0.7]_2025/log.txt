2024-09-17 23:25:45,297 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:198] - INFO: Logging to log_rdpo/2024_09_17_23_21_16/swapped_noise0.7_[0.7,0.7,0.7]_2025
2024-09-17 23:25:45,299 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: (IB) Seed: 2025
2024-09-17 23:25:45,300 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Data: 300
2024-09-17 23:25:45,456 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:296] - INFO: MLE reward loss: 0.4874, l2 distance: 14.5203, acc: 0.75.
2024-09-17 23:25:45,456 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-17 23:25:45,457 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: MLE reward parameter: [5.86893008 3.81025835 8.78907709 2.02187181]
2024-09-17 23:25:45,656 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:313] - INFO: Learned oracle reward: 3.4656, 3.8462, 3.0516
2024-09-17 23:25:45,919 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-17 23:25:47,113 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  16.9996, val_loss:  17.9676, grad_norm: 0.2265, live_grad: 0.0000, reward_err: 0.1193, 0.0004, 0.0811, KL_dist: 1.6944, 0.8390, 1.3848, param: [ 8.44892396  4.10097239 13.14635336  2.2911808 ], weights: [0.33343647 0.33316321 0.33340032], train_wt_loss:  50.9987, val_wt_loss: 53.9027, train_grp_loss: [22.40505825  9.1054357  20.90618512], val_grp_loss: [22.67949104 10.56165864 20.86742746], train_hist_grp_loss: [0.24360728 0.16161937 0.23276232], cur_train_grp_loss: [0.24360728 0.16161937 0.23276232], max_reward_err:  0.1193, max_reward_err_index: 0, max_kl_dist:  1.6944, max_kl_dist_index: 0, max_train_grp_loss:  22.4051, max_train_grp_loss_index: 0, max_val_grp_loss:  22.6795, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2436, max_cur_train_grp_loss_index: 0, 
2024-09-17 23:25:51,416 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  99, train_loss:  17.0073, val_loss:  17.9309, grad_norm: 0.0122,  live_grad: 0.0000, reward_err: 0.1128, 0.0003, 0.0749, KL_dist: 1.6701, 0.8407, 1.3688, param: [ 8.42125226  4.40523617 13.0881047   2.59320657], weights: [0.35380976 0.30195292 0.34423732], train_wt_loss:  51.0220, val_wt_loss: 53.7927, train_grp_loss: [22.21327334  9.39077832 20.78558473], val_grp_loss: [22.52013226 10.7266581  20.7464885 ], train_hist_grp_loss: [24.25266819  8.4038424  21.50986223], cur_train_grp_loss: [0.24147053 0.08457266 0.2142974 ], max_reward_err:  0.1128, max_reward_err_index: 0, max_kl_dist:  1.6701, max_kl_dist_index: 0, max_train_grp_loss:  22.2133, max_train_grp_loss_index: 0, max_val_grp_loss:  22.5201, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2415, max_cur_train_grp_loss_index: 0, 
2024-09-17 23:25:51,633 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:386] - INFO: Policy parameter learned solely on the preference data rdpo: [ 8.42125226  4.40523617 13.0881047   2.59320657].
2024-09-17 23:25:51,959 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:397] - INFO: Uniform reward: 3.8189, 3.8189, 3.1471
2024-09-17 23:25:51,960 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Optimal reward: 3.8509, 3.8509, 3.2572
2024-09-17 23:25:51,960 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Policy reward: 3.4165, 3.8496, 3.0131
2024-09-17 23:25:51,961 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Reward Error: 0.1128, 0.0003, 0.0749
2024-09-17 23:25:52,623 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:415] - INFO: Optimal reward: 3.8509, 3.8509, 3.2572
Known param reward: [[3.850886821746826, 3.4759232997894287, 3.2200934886932373], [3.4759232997894287, 3.850886821746826, 3.068084716796875], [3.8119678497314453, 3.597700595855713, 3.257154703140259]], Known param reward error: [[0.0, 0.09737069389832334, 0.011378401649541042], [0.09737069389832334, 0.0, 0.058047591709751864], [0.010106495936363709, 0.06574751157611633, 0.0]].
