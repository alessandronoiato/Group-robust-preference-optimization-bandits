2024-09-17 23:26:22,093 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:198] - INFO: Logging to log_rdpo/2024_09_17_23_21_16/swapped_noise0.7_[0.7,0.7,0.7]_2027
2024-09-17 23:26:22,094 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: (IB) Seed: 2027
2024-09-17 23:26:22,095 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Data: 300
2024-09-17 23:26:22,251 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:296] - INFO: MLE reward loss: 0.4784, l2 distance: 16.4441, acc: 0.78.
2024-09-17 23:26:22,251 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-17 23:26:22,252 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: MLE reward parameter: [9.38436691 4.90218903 6.44837083 3.36986384]
2024-09-17 23:26:22,456 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:313] - INFO: Learned oracle reward: 3.5260, 3.8224, 3.1967
2024-09-17 23:26:22,703 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-17 23:26:23,894 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  16.8378, val_loss:  18.1760, grad_norm: 0.2643, live_grad: 0.0000, reward_err: 0.1108, 0.0032, 0.0704, KL_dist: 1.9495, 0.9252, 1.5994, param: [14.2692636   5.25516813  8.38122722  2.78600657], weights: [0.33334988 0.33331495 0.33333517], train_wt_loss:  50.5134, val_wt_loss: 54.5279, train_grp_loss: [21.30715447  9.44119313 18.82142161], val_grp_loss: [23.2905025  11.30670098 19.90438382], train_hist_grp_loss: [0.22893423 0.21845469 0.22452204], cur_train_grp_loss: [0.22893423 0.21845469 0.22452204], max_reward_err:  0.1108, max_reward_err_index: 0, max_kl_dist:  1.9495, max_kl_dist_index: 0, max_train_grp_loss:  21.3072, max_train_grp_loss_index: 0, max_val_grp_loss:  23.2905, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2289, max_cur_train_grp_loss_index: 0, 
2024-09-17 23:26:28,187 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  99, train_loss:  16.8405, val_loss:  18.1899, grad_norm: 0.0067,  live_grad: 0.0000, reward_err: 0.1086, 0.0038, 0.0686, KL_dist: 1.9559, 0.9356, 1.6097, param: [14.36760264  5.43096447  8.3094591   2.9724905 ], weights: [0.34707222 0.31446164 0.33846614], train_wt_loss:  50.5214, val_wt_loss: 54.5696, train_grp_loss: [21.1943123   9.63481028 18.77300257], val_grp_loss: [23.22051705 11.48312866 19.84127589], train_hist_grp_loss: [20.45883019 10.59175017 17.94794876], cur_train_grp_loss: [0.20380259 0.10585424 0.17879522], max_reward_err:  0.1086, max_reward_err_index: 0, max_kl_dist:  1.9559, max_kl_dist_index: 0, max_train_grp_loss:  21.1943, max_train_grp_loss_index: 0, max_val_grp_loss:  23.2205, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2038, max_cur_train_grp_loss_index: 0, 
2024-09-17 23:26:28,418 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:386] - INFO: Policy parameter learned solely on the preference data rdpo: [14.36760264  5.43096447  8.3094591   2.9724905 ].
2024-09-17 23:26:28,743 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:397] - INFO: Uniform reward: 3.8110, 3.8110, 3.2056
2024-09-17 23:26:28,744 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Optimal reward: 3.8554, 3.8554, 3.3544
2024-09-17 23:26:28,745 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Policy reward: 3.4367, 3.8408, 3.1244
2024-09-17 23:26:28,745 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Reward Error: 0.1086, 0.0038, 0.0686
2024-09-17 23:26:29,403 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:415] - INFO: Optimal reward: 3.8554, 3.8554, 3.3544
Known param reward: [[3.8553552627563477, 3.4600868225097656, 3.3136484622955322], [3.4600868225097656, 3.8553552627563477, 3.155968189239502], [3.8124771118164062, 3.5852954387664795, 3.354396104812622]], Known param reward error: [[0.0, 0.10252451805543565, 0.012147534531961908], [0.10252451805543565, 0.0, 0.059154586808764606], [0.011121712012938103, 0.07004797368447742, 0.0]].
