2024-09-17 23:25:07,158 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:198] - INFO: Logging to log_rdpo/2024_09_17_23_21_16/swapped_noise0.7_[0.7,0.7,0.7]_2023
2024-09-17 23:25:07,160 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: (IB) Seed: 2023
2024-09-17 23:25:07,160 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Data: 300
2024-09-17 23:25:07,346 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:296] - INFO: MLE reward loss: 0.4946, l2 distance: 13.2114, acc: 0.75.
2024-09-17 23:25:07,347 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-17 23:25:07,348 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: MLE reward parameter: [5.84205766 5.03735432 6.87980734 4.5148032 ]
2024-09-17 23:25:07,548 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:313] - INFO: Learned oracle reward: 3.5857, 3.7393, 3.1731
2024-09-17 23:25:07,799 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-17 23:25:08,968 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  17.6133, val_loss:  18.0730, grad_norm: 0.2650, live_grad: 0.0000, reward_err: 0.0704, 0.0118, 0.0333, KL_dist: 1.1249, 0.7157, 0.9201, param: [8.147098   5.73349786 9.3243024  5.39985533], weights: [0.33342544 0.3331417  0.33343286], train_wt_loss:  52.8398, val_wt_loss: 54.2189, train_grp_loss: [22.98809266 10.96830975 19.38864865], val_grp_loss: [21.17403428 13.45868586 19.36791276], train_hist_grp_loss: [0.24676525 0.16162918 0.24898927], cur_train_grp_loss: [0.24676525 0.16162918 0.24898927], max_reward_err:  0.0704, max_reward_err_index: 0, max_kl_dist:  1.1249, max_kl_dist_index: 0, max_train_grp_loss:  22.9881, max_train_grp_loss_index: 0, max_val_grp_loss:  21.1740, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2490, max_cur_train_grp_loss_index: 2, 
2024-09-17 23:25:13,272 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  99, train_loss:  17.6178, val_loss:  18.1458, grad_norm: 0.0098,  live_grad: 0.0000, reward_err: 0.0669, 0.0149, 0.0306, KL_dist: 1.1106, 0.7356, 0.9129, param: [8.15879926 5.93592079 9.18488404 5.61407089], weights: [0.34962065 0.3087491  0.34163024], train_wt_loss:  52.8534, val_wt_loss: 54.4375, train_grp_loss: [22.84772533 11.18938566 19.30314138], val_grp_loss: [21.07100976 13.89726859 19.27216765], train_hist_grp_loss: [22.93682181 10.50484888 20.6248494 ], cur_train_grp_loss: [0.2284918  0.10553735 0.20536204], max_reward_err:  0.0669, max_reward_err_index: 0, max_kl_dist:  1.1106, max_kl_dist_index: 0, max_train_grp_loss:  22.8477, max_train_grp_loss_index: 0, max_val_grp_loss:  21.0710, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2285, max_cur_train_grp_loss_index: 0, 
2024-09-17 23:25:13,489 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:386] - INFO: Policy parameter learned solely on the preference data rdpo: [8.15879926 5.93592079 9.18488404 5.61407089].
2024-09-17 23:25:13,808 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:397] - INFO: Uniform reward: 3.7839, 3.7839, 3.1364
2024-09-17 23:25:13,808 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Optimal reward: 3.8185, 3.8185, 3.2590
2024-09-17 23:25:13,809 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Policy reward: 3.5632, 3.7616, 3.1594
2024-09-17 23:25:13,809 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Reward Error: 0.0669, 0.0149, 0.0306
2024-09-17 23:25:14,475 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:415] - INFO: Optimal reward: 3.8185, 3.8185, 3.2590
Known param reward: [[3.8185489177703857, 3.427854061126709, 3.2254443168640137], [3.427854061126709, 3.8185489177703857, 3.064500570297241], [3.7794888019561768, 3.5508782863616943, 3.258955478668213]], Known param reward error: [[0.0, 0.10231500631705924, 0.010282792147223106], [0.10231500631705924, 0.0, 0.059667862799536175], [0.010229046859249302, 0.07009747345726862, 0.0]].
