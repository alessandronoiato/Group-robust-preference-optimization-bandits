2024-09-17 23:24:29,168 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:198] - INFO: Logging to log_rdpo/2024_09_17_23_21_16/swapped_noise0.7_[0.7,0.7,0.7]_2021
2024-09-17 23:24:29,169 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: (IB) Seed: 2021
2024-09-17 23:24:29,170 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Data: 300
2024-09-17 23:24:29,327 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:296] - INFO: MLE reward loss: 0.5223, l2 distance: 11.7253, acc: 0.75.
2024-09-17 23:24:29,327 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-17 23:24:29,328 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: MLE reward parameter: [5.4903206  2.66270796 6.9133025  4.04088463]
2024-09-17 23:24:29,530 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:313] - INFO: Learned oracle reward: 3.5535, 3.8556, 3.1690
2024-09-17 23:24:29,762 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-17 23:24:30,933 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  18.2281, val_loss:  18.2262, grad_norm: 0.2269, live_grad: 0.0000, reward_err: 0.1017, 0.0090, 0.0612, KL_dist: 1.3332, 0.7115, 1.0906, param: [ 7.45144099  3.23745502 11.4247922   5.69717652], weights: [0.33336332 0.33323721 0.33339948], train_wt_loss:  54.6842, val_wt_loss: 54.6787, train_grp_loss: [21.77774796 11.12660024 22.34054886], val_grp_loss: [21.28697502 13.57556593 20.03480452], train_hist_grp_loss: [0.22966045 0.19182236 0.24050566], cur_train_grp_loss: [0.22966045 0.19182236 0.24050566], max_reward_err:  0.1017, max_reward_err_index: 0, max_kl_dist:  1.3332, max_kl_dist_index: 0, max_train_grp_loss:  22.3405, max_train_grp_loss_index: 2, max_val_grp_loss:  21.2870, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2405, max_cur_train_grp_loss_index: 2, 
2024-09-17 23:24:35,258 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  99, train_loss:  18.2343, val_loss:  18.2724, grad_norm: 0.0100,  live_grad: 0.0000, reward_err: 0.0962, 0.0111, 0.0565, KL_dist: 1.2972, 0.7229, 1.0642, param: [ 7.4899167   3.52168672 11.2271191   5.98599991], weights: [0.34321213 0.30772104 0.34906683], train_wt_loss:  54.7028, val_wt_loss: 54.8171, train_grp_loss: [21.66247106 11.4248265  22.15187947], val_grp_loss: [21.14749478 13.946956   19.92661218], train_hist_grp_loss: [21.73356033 10.81805248 23.42502796], cur_train_grp_loss: [0.2166366  0.10877689 0.23319811], max_reward_err:  0.0962, max_reward_err_index: 0, max_kl_dist:  1.2972, max_kl_dist_index: 0, max_train_grp_loss:  22.1519, max_train_grp_loss_index: 2, max_val_grp_loss:  21.1475, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2332, max_cur_train_grp_loss_index: 2, 
2024-09-17 23:24:35,476 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:386] - INFO: Policy parameter learned solely on the preference data rdpo: [ 7.4899167   3.52168672 11.2271191   5.98599991].
2024-09-17 23:24:35,797 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:397] - INFO: Uniform reward: 3.8605, 3.8605, 3.2147
2024-09-17 23:24:35,797 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Optimal reward: 3.8953, 3.8953, 3.3285
2024-09-17 23:24:35,798 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Policy reward: 3.5206, 3.8523, 3.1403
2024-09-17 23:24:35,798 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Reward Error: 0.0962, 0.0111, 0.0565
2024-09-17 23:24:36,468 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:415] - INFO: Optimal reward: 3.8953, 3.8953, 3.3285
Known param reward: [[3.8953495025634766, 3.470022678375244, 3.3036766052246094], [3.470022678375244, 3.8953495025634766, 3.1119751930236816], [3.860280990600586, 3.6015567779541016, 3.328472137451172]], Known param reward error: [[0.0, 0.10918836009665644, 0.007449523746216501], [0.10918836009665644, 0.0, 0.06504394072929691], [0.009002661234842346, 0.07542140298734017, 0.0]].
