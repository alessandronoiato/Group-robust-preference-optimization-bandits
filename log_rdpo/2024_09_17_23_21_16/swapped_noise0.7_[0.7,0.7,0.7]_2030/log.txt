2024-09-17 23:27:18,381 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:198] - INFO: Logging to log_rdpo/2024_09_17_23_21_16/swapped_noise0.7_[0.7,0.7,0.7]_2030
2024-09-17 23:27:18,383 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: (IB) Seed: 2030
2024-09-17 23:27:18,383 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Data: 300
2024-09-17 23:27:18,540 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:296] - INFO: MLE reward loss: 0.4482, l2 distance: 19.4925, acc: 0.79.
2024-09-17 23:27:18,540 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-17 23:27:18,541 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: MLE reward parameter: [ 5.97129893  4.34120631 11.87224408  3.23095933]
2024-09-17 23:27:18,745 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:313] - INFO: Learned oracle reward: 3.3778, 3.7898, 3.0477
2024-09-17 23:27:18,989 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-17 23:27:20,177 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  15.9043, val_loss:  18.2392, grad_norm: 0.2076, live_grad: 0.0000, reward_err: 0.1350, 0.0010, 0.0961, KL_dist: 2.5321, 0.9546, 2.1401, param: [ 6.6800898   3.8873437  16.97209329  2.53547282], weights: [0.33350908 0.3331557  0.33333522], train_wt_loss:  47.7130, val_wt_loss: 54.7176, train_grp_loss: [23.39331368  8.14942776 17.38528837], val_grp_loss: [22.98278008 10.61544428 20.71254532], train_hist_grp_loss: [0.25587917 0.14986345 0.20373454], cur_train_grp_loss: [0.25587917 0.14986345 0.20373454], max_reward_err:  0.1350, max_reward_err_index: 0, max_kl_dist:  2.5321, max_kl_dist_index: 0, max_train_grp_loss:  23.3933, max_train_grp_loss_index: 0, max_val_grp_loss:  22.9828, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2559, max_cur_train_grp_loss_index: 0, 
2024-09-17 23:27:24,521 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  99, train_loss:  15.9104, val_loss:  18.1897, grad_norm: 0.0102,  live_grad: 0.0000, reward_err: 0.1321, 0.0009, 0.0936, KL_dist: 2.5113, 0.9475, 2.1279, param: [ 6.5548188   4.11570251 16.95833418  2.8327181 ], weights: [0.36485458 0.30375872 0.3313867 ], train_wt_loss:  47.7312, val_wt_loss: 54.5690, train_grp_loss: [23.22455067  8.37321254 17.31978631], val_grp_loss: [22.84772036 10.70099501 20.62091238], train_hist_grp_loss: [26.18662679  7.86010883 16.56533763], cur_train_grp_loss: [0.26097031 0.07896844 0.16495684], max_reward_err:  0.1321, max_reward_err_index: 0, max_kl_dist:  2.5113, max_kl_dist_index: 0, max_train_grp_loss:  23.2246, max_train_grp_loss_index: 0, max_val_grp_loss:  22.8477, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2610, max_cur_train_grp_loss_index: 0, 
2024-09-17 23:27:24,738 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:386] - INFO: Policy parameter learned solely on the preference data rdpo: [ 6.5548188   4.11570251 16.95833418  2.8327181 ].
2024-09-17 23:27:25,057 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:397] - INFO: Uniform reward: 3.7589, 3.7589, 3.1455
2024-09-17 23:27:25,058 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Optimal reward: 3.7968, 3.7968, 3.2861
2024-09-17 23:27:25,058 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Policy reward: 3.2953, 3.7934, 2.9785
2024-09-17 23:27:25,059 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Reward Error: 0.1321, 0.0009, 0.0936
2024-09-17 23:27:25,727 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:415] - INFO: Optimal reward: 3.7968, 3.7968, 3.2861
Known param reward: [[3.7967944145202637, 3.4310121536254883, 3.2510554790496826], [3.4310121536254883, 3.7967944145202637, 3.104628562927246], [3.762887954711914, 3.552025556564331, 3.2860965728759766]], Known param reward error: [[0.0, 0.09633975953396283, 0.010663440056974997], [0.09633975953396283, 0.0, 0.05522296923547518], [0.008930285948240838, 0.06446724031721372, 0.0]].
