2024-09-17 23:25:25,994 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:198] - INFO: Logging to log_rdpo/2024_09_17_23_21_16/swapped_noise0.7_[0.7,0.7,0.7]_2024
2024-09-17 23:25:25,996 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: (IB) Seed: 2024
2024-09-17 23:25:25,997 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Data: 300
2024-09-17 23:25:26,153 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:296] - INFO: MLE reward loss: 0.5476, l2 distance: 11.1533, acc: 0.75.
2024-09-17 23:25:26,154 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-17 23:25:26,154 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: MLE reward parameter: [5.90113754 4.18203339 5.68128049 3.94458909]
2024-09-17 23:25:26,355 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:313] - INFO: Learned oracle reward: 3.6835, 3.8594, 3.3262
2024-09-17 23:25:26,611 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-17 23:25:27,775 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  19.2621, val_loss:  17.9137, grad_norm: 0.1893, live_grad: 0.0000, reward_err: 0.0713, 0.0116, 0.0327, KL_dist: 1.1729, 0.7144, 0.9512, param: [9.2699213  5.87768841 8.8665907  5.17758047], weights: [0.33330046 0.3333892  0.33331034], train_wt_loss:  57.7863, val_wt_loss: 53.7410, train_grp_loss: [22.01172294 14.76726101 20.36516017], val_grp_loss: [21.51643958 12.610663   19.34151663], train_hist_grp_loss: [0.21479501 0.24141446 0.21775885], cur_train_grp_loss: [0.21479501 0.24141446 0.21775885], max_reward_err:  0.0713, max_reward_err_index: 0, max_kl_dist:  1.1729, max_kl_dist_index: 0, max_train_grp_loss:  22.0117, max_train_grp_loss_index: 0, max_val_grp_loss:  21.5164, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2414, max_cur_train_grp_loss_index: 1, 
2024-09-17 23:25:32,110 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  99, train_loss:  19.2625, val_loss:  17.9269, grad_norm: 0.0026,  live_grad: 0.0000, reward_err: 0.0703, 0.0124, 0.0319, KL_dist: 1.1737, 0.7242, 0.9538, param: [9.26874024 5.95853034 8.88290736 5.25731409], weights: [0.33997233 0.32526587 0.3347618 ], train_wt_loss:  57.7876, val_wt_loss: 53.7806, train_grp_loss: [21.97288457 14.84681622 20.33708569], val_grp_loss: [21.47510223 12.73970766 19.29924463], train_hist_grp_loss: [20.95058224 16.52845077 19.40608312], cur_train_grp_loss: [0.2092693  0.16495554 0.19368922], max_reward_err:  0.0703, max_reward_err_index: 0, max_kl_dist:  1.1737, max_kl_dist_index: 0, max_train_grp_loss:  21.9729, max_train_grp_loss_index: 0, max_val_grp_loss:  21.4751, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2093, max_cur_train_grp_loss_index: 0, 
2024-09-17 23:25:32,327 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:386] - INFO: Policy parameter learned solely on the preference data rdpo: [9.26874024 5.95853034 8.88290736 5.25731409].
2024-09-17 23:25:32,646 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:397] - INFO: Uniform reward: 3.8925, 3.8925, 3.2811
2024-09-17 23:25:32,647 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Optimal reward: 3.9322, 3.9322, 3.4172
2024-09-17 23:25:32,647 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Policy reward: 3.6557, 3.8834, 3.3080
2024-09-17 23:25:32,648 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Reward Error: 0.0703, 0.0124, 0.0319
2024-09-17 23:25:33,309 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:415] - INFO: Optimal reward: 3.9322, 3.9322, 3.4172
Known param reward: [[3.9322431087493896, 3.5081164836883545, 3.382530450820923], [3.5081164836883545, 3.9322431087493896, 3.203848123550415], [3.891317367553711, 3.641733407974243, 3.4171640872955322]], Known param reward error: [[0.0, 0.10785869879645472, 0.010135198541788402], [0.10785869879645472, 0.0, 0.06242485239096118], [0.010407734227982341, 0.07387887593438752, 0.0]].
