2024-09-17 23:27:00,518 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:198] - INFO: Logging to log_rdpo/2024_09_17_23_21_16/swapped_noise0.7_[0.7,0.7,0.7]_2029
2024-09-17 23:27:00,520 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: (IB) Seed: 2029
2024-09-17 23:27:00,520 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Data: 300
2024-09-17 23:27:00,678 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:296] - INFO: MLE reward loss: 0.5036, l2 distance: 12.2568, acc: 0.76.
2024-09-17 23:27:00,678 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-17 23:27:00,679 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: MLE reward parameter: [4.87068676 3.15664954 7.32045632 4.78837788]
2024-09-17 23:27:00,881 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:313] - INFO: Learned oracle reward: 3.5801, 3.7810, 3.2295
2024-09-17 23:27:01,128 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-17 23:27:02,318 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  17.6956, val_loss:  18.6381, grad_norm: 0.1478, live_grad: 0.0000, reward_err: 0.0843, 0.0181, 0.0479, KL_dist: 1.3247, 0.7016, 1.0977, param: [ 6.21097247  3.89134263 11.41483987  6.26292294], weights: [0.33348518 0.33310857 0.33340625], train_wt_loss:  53.0869, val_wt_loss: 55.9144, train_grp_loss: [22.39415037 12.55986898 18.97978165], val_grp_loss: [20.3146661  14.16401826 20.70312376], train_hist_grp_loss: [0.24385859 0.13086289 0.2201858 ], cur_train_grp_loss: [0.24385859 0.13086289 0.2201858 ], max_reward_err:  0.0843, max_reward_err_index: 0, max_kl_dist:  1.3247, max_kl_dist_index: 0, max_train_grp_loss:  22.3942, max_train_grp_loss_index: 0, max_val_grp_loss:  20.7031, max_val_grp_loss_index: 2, max_cur_train_grp_loss:  0.2439, max_cur_train_grp_loss_index: 0, 
2024-09-17 23:27:06,618 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  99, train_loss:  17.6989, val_loss:  18.6767, grad_norm: 0.0084,  live_grad: 0.0000, reward_err: 0.0818, 0.0191, 0.0457, KL_dist: 1.3192, 0.7201, 1.0971, param: [ 6.18302214  4.05772293 11.40299318  6.45160779], weights: [0.35147377 0.31089373 0.3376325 ], train_wt_loss:  53.0966, val_wt_loss: 56.0302, train_grp_loss: [22.28696682 12.72364501 18.90710665], val_grp_loss: [20.22494503 14.48201088 20.63604791], train_hist_grp_loss: [23.77400884 11.50561779 19.7563041 ], cur_train_grp_loss: [0.23710733 0.11565317 0.19695686], max_reward_err:  0.0818, max_reward_err_index: 0, max_kl_dist:  1.3192, max_kl_dist_index: 0, max_train_grp_loss:  22.2870, max_train_grp_loss_index: 0, max_val_grp_loss:  20.6360, max_val_grp_loss_index: 2, max_cur_train_grp_loss:  0.2371, max_cur_train_grp_loss_index: 0, 
2024-09-17 23:27:06,837 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:386] - INFO: Policy parameter learned solely on the preference data rdpo: [ 6.18302214  4.05772293 11.40299318  6.45160779].
2024-09-17 23:27:07,157 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:397] - INFO: Uniform reward: 3.8223, 3.8223, 3.2131
2024-09-17 23:27:07,157 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Optimal reward: 3.8685, 3.8685, 3.3593
2024-09-17 23:27:07,158 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Policy reward: 3.5522, 3.7948, 3.2056
2024-09-17 23:27:07,158 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Reward Error: 0.0818, 0.0191, 0.0457
2024-09-17 23:27:07,821 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:415] - INFO: Optimal reward: 3.8685, 3.8685, 3.3593
Known param reward: [[3.8685142993927, 3.4599270820617676, 3.3229901790618896], [3.4599270820617676, 3.8685142993927, 3.1513752937316895], [3.8328397274017334, 3.5916991233825684, 3.3593173027038574]], Known param reward error: [[0.0, 0.10561863953690821, 0.010813841137521808], [0.10561863953690821, 0.0, 0.06190007975870543], [0.00922177591448148, 0.0715559397191805, 0.0]].
