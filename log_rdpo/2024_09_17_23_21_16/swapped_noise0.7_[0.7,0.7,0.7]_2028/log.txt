2024-09-17 23:26:40,917 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:198] - INFO: Logging to log_rdpo/2024_09_17_23_21_16/swapped_noise0.7_[0.7,0.7,0.7]_2028
2024-09-17 23:26:40,919 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: (IB) Seed: 2028
2024-09-17 23:26:40,919 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Data: 300
2024-09-17 23:26:41,075 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:296] - INFO: MLE reward loss: 0.4966, l2 distance: 15.2791, acc: 0.78.
2024-09-17 23:26:41,076 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-17 23:26:41,077 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: MLE reward parameter: [6.8041789  4.08605626 8.32789205 4.25371169]
2024-09-17 23:26:41,275 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:313] - INFO: Learned oracle reward: 3.5940, 3.8655, 3.2275
2024-09-17 23:26:41,523 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-17 23:26:42,695 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  17.5589, val_loss:  17.3852, grad_norm: 0.1946, live_grad: 0.0000, reward_err: 0.0903, 0.0019, 0.0523, KL_dist: 1.6192, 0.8767, 1.3178, param: [ 9.44430256  4.70043852 12.17939155  4.83790619], weights: [0.33323421 0.33333199 0.3334338 ], train_wt_loss:  52.6767, val_wt_loss: 52.1555, train_grp_loss: [19.87856128 12.15768398 19.86741015], val_grp_loss: [20.68737152 11.98324999 19.28969001], train_hist_grp_loss: [0.18134705 0.21068677 0.24122552], cur_train_grp_loss: [0.18134705 0.21068677 0.24122552], max_reward_err:  0.0903, max_reward_err_index: 0, max_kl_dist:  1.6192, max_kl_dist_index: 0, max_train_grp_loss:  19.8786, max_train_grp_loss_index: 0, max_val_grp_loss:  20.6874, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2412, max_cur_train_grp_loss_index: 2, 
2024-09-17 23:26:47,023 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  99, train_loss:  17.5599, val_loss:  17.3945, grad_norm: 0.0044,  live_grad: 0.0000, reward_err: 0.0881, 0.0021, 0.0505, KL_dist: 1.6249, 0.8896, 1.3247, param: [ 9.48836295  4.79155121 12.21081645  4.9579996 ], weights: [0.33082726 0.32091848 0.34825426], train_wt_loss:  52.6797, val_wt_loss: 52.1836, train_grp_loss: [19.82046251 12.28760335 19.81815195], val_grp_loss: [20.63339853 12.12068015 19.23743516], train_hist_grp_loss: [16.69508578 13.65416312 21.82873567], cur_train_grp_loss: [0.16656346 0.13651392 0.21778738], max_reward_err:  0.0881, max_reward_err_index: 0, max_kl_dist:  1.6249, max_kl_dist_index: 0, max_train_grp_loss:  19.8205, max_train_grp_loss_index: 0, max_val_grp_loss:  20.6334, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2178, max_cur_train_grp_loss_index: 2, 
2024-09-17 23:26:47,240 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:386] - INFO: Policy parameter learned solely on the preference data rdpo: [ 9.48836295  4.79155121 12.21081645  4.9579996 ].
2024-09-17 23:26:47,560 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:397] - INFO: Uniform reward: 3.8595, 3.8595, 3.2317
2024-09-17 23:26:47,560 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Optimal reward: 3.8937, 3.8937, 3.3654
2024-09-17 23:26:47,561 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Policy reward: 3.5508, 3.8857, 3.1954
2024-09-17 23:26:47,561 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Reward Error: 0.0881, 0.0021, 0.0505
2024-09-17 23:26:48,233 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:415] - INFO: Optimal reward: 3.8937, 3.8937, 3.3654
Known param reward: [[3.8937318325042725, 3.480532169342041, 3.329375982284546], [3.480532169342041, 3.8937318325042725, 3.148448944091797], [3.859982490539551, 3.6322221755981445, 3.3654303550720215]], Known param reward error: [[0.0, 0.1061191887209346, 0.010713153737719826], [0.1061191887209346, 0.0, 0.06447360013057858], [0.008667608201208769, 0.06716170197523252, 0.0]].
