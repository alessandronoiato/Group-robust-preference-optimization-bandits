2024-09-17 23:24:48,174 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:198] - INFO: Logging to log_rdpo/2024_09_17_23_21_16/swapped_noise0.7_[0.7,0.7,0.7]_2022
2024-09-17 23:24:48,176 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: (IB) Seed: 2022
2024-09-17 23:24:48,177 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Data: 300
2024-09-17 23:24:48,332 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:296] - INFO: MLE reward loss: 0.4993, l2 distance: 13.7379, acc: 0.76.
2024-09-17 23:24:48,333 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-17 23:24:48,334 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: MLE reward parameter: [6.5702886  3.90633307 7.4250801  3.98010948]
2024-09-17 23:24:48,536 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:313] - INFO: Learned oracle reward: 3.6248, 3.8416, 3.2262
2024-09-17 23:24:48,786 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-17 23:24:49,948 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  17.6353, val_loss:  18.0173, grad_norm: 0.2127, live_grad: 0.0000, reward_err: 0.0785, 0.0028, 0.0435, KL_dist: 1.4022, 0.7575, 1.1360, param: [ 9.10427291  4.13224451 11.04094851  4.58551683], weights: [0.3334353  0.33318411 0.3333806 ], train_wt_loss:  52.9058, val_wt_loss: 54.0519, train_grp_loss: [21.32493553 11.78972429 19.91469409], val_grp_loss: [21.80964029 11.49217642 20.64620631], train_hist_grp_loss: [0.23859351 0.16323074 0.22218703], cur_train_grp_loss: [0.23859351 0.16323074 0.22218703], max_reward_err:  0.0785, max_reward_err_index: 0, max_kl_dist:  1.4022, max_kl_dist_index: 0, max_train_grp_loss:  21.3249, max_train_grp_loss_index: 0, max_val_grp_loss:  21.8096, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2386, max_cur_train_grp_loss_index: 0, 
2024-09-17 23:24:54,276 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  99, train_loss:  17.6386, val_loss:  17.9921, grad_norm: 0.0081,  live_grad: 0.0000, reward_err: 0.0759, 0.0035, 0.0411, KL_dist: 1.3919, 0.7687, 1.1306, param: [ 9.16918165  4.33109899 10.93797104  4.76921838], weights: [0.34724471 0.31383721 0.33891808], train_wt_loss:  52.9159, val_wt_loss: 53.9762, train_grp_loss: [21.19613579 12.00742142 19.83148904], val_grp_loss: [21.70866853 11.61944999 20.54714691], train_hist_grp_loss: [21.93850122 11.82296762 19.51136689], cur_train_grp_loss: [0.21853048 0.11886228 0.19443471], max_reward_err:  0.0759, max_reward_err_index: 0, max_kl_dist:  1.3919, max_kl_dist_index: 0, max_train_grp_loss:  21.1961, max_train_grp_loss_index: 0, max_val_grp_loss:  21.7087, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2185, max_cur_train_grp_loss_index: 0, 
2024-09-17 23:24:54,492 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:386] - INFO: Policy parameter learned solely on the preference data rdpo: [ 9.16918165  4.33109899 10.93797104  4.76921838].
2024-09-17 23:24:54,810 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:397] - INFO: Uniform reward: 3.8444, 3.8444, 3.1998
2024-09-17 23:24:54,810 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Optimal reward: 3.8757, 3.8757, 3.3316
2024-09-17 23:24:54,811 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Policy reward: 3.5816, 3.8622, 3.1947
2024-09-17 23:24:54,811 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Reward Error: 0.0759, 0.0035, 0.0411
2024-09-17 23:24:55,476 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:415] - INFO: Optimal reward: 3.8757, 3.8757, 3.3316
Known param reward: [[3.8757123947143555, 3.5474281311035156, 3.28242826461792], [3.5474281311035156, 3.8757123947143555, 3.1710550785064697], [3.833740711212158, 3.6443803310394287, 3.3315517902374268]], Known param reward error: [[0.0, 0.08470294752999462, 0.014744938308765115], [0.08470294752999462, 0.0, 0.048174761143220605], [0.010829411274024791, 0.059687623877977714, 0.0]].
