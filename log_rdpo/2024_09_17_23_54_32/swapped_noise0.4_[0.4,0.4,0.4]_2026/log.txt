2024-09-17 23:59:16,318 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:198] - INFO: Logging to log_rdpo/2024_09_17_23_54_32/swapped_noise0.4_[0.4,0.4,0.4]_2026
2024-09-17 23:59:16,320 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: (IB) Seed: 2026
2024-09-17 23:59:16,321 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Data: 300
2024-09-17 23:59:16,486 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:296] - INFO: MLE reward loss: 0.6199, l2 distance: 4.9196, acc: 0.62.
2024-09-17 23:59:16,487 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-17 23:59:16,488 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: MLE reward parameter: [3.69886944 1.37782594 2.86087464 2.30933931]
2024-09-17 23:59:16,695 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:313] - INFO: Learned oracle reward: 3.5716, 3.8418, 3.1854
2024-09-17 23:59:16,954 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-17 23:59:18,164 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  21.7105, val_loss:  20.0398, grad_norm: 0.1018, live_grad: 0.0000, reward_err: 0.0805, 0.0069, 0.0410, KL_dist: 0.7354, 0.3322, 0.5540, param: [7.54118544 2.59667052 5.93525918 4.39118381], weights: [0.33333283 0.33323427 0.3334329 ], train_wt_loss:  65.1315, val_wt_loss: 60.1195, train_grp_loss: [23.25507301 18.50939577 23.42470193], val_grp_loss: [22.92869667 14.34473274 22.73254818], train_hist_grp_loss: [0.22608826 0.19651594 0.2561043 ], cur_train_grp_loss: [0.22608826 0.19651594 0.2561043 ], max_reward_err:  0.0805, max_reward_err_index: 0, max_kl_dist:  0.7354, max_kl_dist_index: 0, max_train_grp_loss:  23.4247, max_train_grp_loss_index: 2, max_val_grp_loss:  22.9287, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2561, max_cur_train_grp_loss_index: 2, 
2024-09-17 23:59:22,509 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  99, train_loss:  21.7108, val_loss:  20.0418, grad_norm: 0.0026,  live_grad: 0.0000, reward_err: 0.0816, 0.0069, 0.0421, KL_dist: 0.7328, 0.3359, 0.5531, param: [7.56424056 2.64262788 5.8870027  4.45309506], weights: [0.33434241 0.32191497 0.34374261], train_wt_loss:  65.1325, val_wt_loss: 60.1255, train_grp_loss: [23.23807391 18.54531837 23.40609577], val_grp_loss: [22.91209722 14.37553484 22.72503289], train_hist_grp_loss: [22.14440226 18.35658192 24.91715314], cur_train_grp_loss: [0.22131665 0.18361328 0.24900305], max_reward_err:  0.0816, max_reward_err_index: 0, max_kl_dist:  0.7328, max_kl_dist_index: 0, max_train_grp_loss:  23.4061, max_train_grp_loss_index: 2, max_val_grp_loss:  22.9121, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2490, max_cur_train_grp_loss_index: 2, 
2024-09-17 23:59:22,730 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:386] - INFO: Policy parameter learned solely on the preference data rdpo: [7.56424056 2.64262788 5.8870027  4.45309506].
2024-09-17 23:59:23,056 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:397] - INFO: Uniform reward: 3.8381, 3.8381, 3.1940
2024-09-17 23:59:23,057 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Optimal reward: 3.8761, 3.8761, 3.3159
2024-09-17 23:59:23,057 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Policy reward: 3.5597, 3.8492, 3.1764
2024-09-17 23:59:23,058 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Reward Error: 0.0816, 0.0069, 0.0421
2024-09-17 23:59:23,733 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:415] - INFO: Optimal reward: 3.8761, 3.8761, 3.3159
Known param reward: [[3.8760921955108643, 3.486328125, 3.2829432487487793], [3.486328125, 3.8760921955108643, 3.1273369789123535], [3.833125114440918, 3.6059510707855225, 3.3158624172210693]], Known param reward error: [[0.0, 0.10055593387646287, 0.009927784790262397], [0.10055593387646287, 0.0, 0.05685562746198428], [0.011085154558425894, 0.06969419484866962, 0.0]].
