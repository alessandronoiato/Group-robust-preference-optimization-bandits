2024-09-17 23:58:39,552 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:198] - INFO: Logging to log_rdpo/2024_09_17_23_54_32/swapped_noise0.4_[0.4,0.4,0.4]_2024
2024-09-17 23:58:39,554 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: (IB) Seed: 2024
2024-09-17 23:58:39,554 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Data: 300
2024-09-17 23:58:39,719 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:296] - INFO: MLE reward loss: 0.6096, l2 distance: 4.5804, acc: 0.66.
2024-09-17 23:58:39,719 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-17 23:58:39,720 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: MLE reward parameter: [3.43667079 3.05372886 2.69231502 2.26156934]
2024-09-17 23:58:39,924 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:313] - INFO: Learned oracle reward: 3.7110, 3.7675, 3.3133
2024-09-17 23:58:40,176 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-17 23:58:41,349 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  21.3842, val_loss:  20.1694, grad_norm: 0.1727, live_grad: 0.0000, reward_err: 0.0589, 0.0338, 0.0267, KL_dist: 0.5695, 0.4061, 0.4477, param: [6.87015323 5.54991019 4.82571954 3.8668092 ], weights: [0.33333034 0.3333355  0.33333416], train_wt_loss:  64.1525, val_wt_loss: 60.5083, train_grp_loss: [22.71987945 17.51346296 23.36617819], val_grp_loss: [22.40071788 15.64756589 22.39252603], train_hist_grp_loss: [0.23100456 0.2325537  0.23215197], cur_train_grp_loss: [0.23100456 0.2325537  0.23215197], max_reward_err:  0.0589, max_reward_err_index: 0, max_kl_dist:  0.5695, max_kl_dist_index: 0, max_train_grp_loss:  23.3662, max_train_grp_loss_index: 2, max_val_grp_loss:  22.4007, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2326, max_cur_train_grp_loss_index: 1, 
2024-09-17 23:58:45,695 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  99, train_loss:  21.3843, val_loss:  20.1790, grad_norm: 0.0014,  live_grad: 0.0000, reward_err: 0.0578, 0.0344, 0.0259, KL_dist: 0.5671, 0.4101, 0.4466, param: [6.85530308 5.58533589 4.81316441 3.89510806], weights: [0.3350084  0.32793183 0.33705977], train_wt_loss:  64.1528, val_wt_loss: 60.5371, train_grp_loss: [22.70832369 17.54088182 23.35451859], val_grp_loss: [22.39342662 15.69074446 22.38591376], train_hist_grp_loss: [21.64721341 19.51222659 22.2576801 ], cur_train_grp_loss: [0.21627086 0.19489557 0.22242511], max_reward_err:  0.0578, max_reward_err_index: 0, max_kl_dist:  0.5671, max_kl_dist_index: 0, max_train_grp_loss:  23.3545, max_train_grp_loss_index: 2, max_val_grp_loss:  22.3934, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2224, max_cur_train_grp_loss_index: 2, 
2024-09-17 23:58:45,923 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:386] - INFO: Policy parameter learned solely on the preference data rdpo: [6.85530308 5.58533589 4.81316441 3.89510806].
2024-09-17 23:58:46,251 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:397] - INFO: Uniform reward: 3.8650, 3.8650, 3.2436
2024-09-17 23:58:46,252 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Optimal reward: 3.9035, 3.9035, 3.3772
2024-09-17 23:58:46,253 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Policy reward: 3.6778, 3.7693, 3.2896
2024-09-17 23:58:46,253 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Reward Error: 0.0578, 0.0344, 0.0259
2024-09-17 23:58:46,925 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:415] - INFO: Optimal reward: 3.9035, 3.9035, 3.3772
Known param reward: [[3.903468370437622, 3.4978456497192383, 3.3427646160125732], [3.4978456497192383, 3.903468370437622, 3.172839879989624], [3.863295316696167, 3.63002347946167, 3.377150297164917]], Known param reward error: [[0.0, 0.10391341295098261, 0.010181862850821349], [0.10391341295098261, 0.0, 0.06049787518986332], [0.010291630398673176, 0.07005177576097432, 0.0]].
