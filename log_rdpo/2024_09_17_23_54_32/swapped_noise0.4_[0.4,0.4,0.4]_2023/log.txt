2024-09-17 23:58:20,647 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:198] - INFO: Logging to log_rdpo/2024_09_17_23_54_32/swapped_noise0.4_[0.4,0.4,0.4]_2023
2024-09-17 23:58:20,649 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: (IB) Seed: 2023
2024-09-17 23:58:20,649 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Data: 300
2024-09-17 23:58:20,815 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:296] - INFO: MLE reward loss: 0.5711, l2 distance: 7.7876, acc: 0.70.
2024-09-17 23:58:20,815 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-17 23:58:20,816 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: MLE reward parameter: [5.07003306 2.25187984 4.44801246 2.24744995]
2024-09-17 23:58:21,024 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:313] - INFO: Learned oracle reward: 3.5487, 3.8631, 3.1669
2024-09-17 23:58:21,273 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-17 23:58:22,460 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  19.7231, val_loss:  19.8413, grad_norm: 0.1848, live_grad: 0.0000, reward_err: 0.0911, 0.0005, 0.0523, KL_dist: 1.1836, 0.5711, 0.9350, param: [9.87035666 3.6323156  8.02146502 3.71149107], weights: [0.33337113 0.33322381 0.33340506], train_wt_loss:  59.1694, val_wt_loss: 59.5240, train_grp_loss: [24.4610665  12.04788585 23.33779788], val_grp_loss: [23.79400949 13.95588548 21.53757744], train_hist_grp_loss: [0.23915959 0.19495845 0.24933707], cur_train_grp_loss: [0.23915959 0.19495845 0.24933707], max_reward_err:  0.0911, max_reward_err_index: 0, max_kl_dist:  1.1836, max_kl_dist_index: 0, max_train_grp_loss:  24.4611, max_train_grp_loss_index: 0, max_val_grp_loss:  23.7940, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2493, max_cur_train_grp_loss_index: 2, 
2024-09-17 23:58:26,778 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  99, train_loss:  19.7289, val_loss:  19.8733, grad_norm: 0.0100,  live_grad: 0.0000, reward_err: 0.0897, 0.0014, 0.0513, KL_dist: 1.1468, 0.5652, 0.9090, param: [9.80466481 3.85468455 7.75954408 3.93297768], weights: [0.34681518 0.30506177 0.34812305], train_wt_loss:  59.1868, val_wt_loss: 59.6200, train_grp_loss: [24.32391484 12.30211882 23.21554058], val_grp_loss: [23.66555043 14.23999603 21.48741627], train_hist_grp_loss: [24.38895914 11.56118316 24.76535783], cur_train_grp_loss: [0.24325333 0.1160313  0.24698732], max_reward_err:  0.0897, max_reward_err_index: 0, max_kl_dist:  1.1468, max_kl_dist_index: 0, max_train_grp_loss:  24.3239, max_train_grp_loss_index: 0, max_val_grp_loss:  23.6656, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2470, max_cur_train_grp_loss_index: 2, 
2024-09-17 23:58:26,999 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:386] - INFO: Policy parameter learned solely on the preference data rdpo: [9.80466481 3.85468455 7.75954408 3.93297768].
2024-09-17 23:58:27,325 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:397] - INFO: Uniform reward: 3.8311, 3.8311, 3.1864
2024-09-17 23:58:27,326 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Optimal reward: 3.8736, 3.8736, 3.3192
2024-09-17 23:58:27,326 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Policy reward: 3.5260, 3.8683, 3.1489
2024-09-17 23:58:27,327 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Reward Error: 0.0897, 0.0014, 0.0513
2024-09-17 23:58:27,998 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:415] - INFO: Optimal reward: 3.8736, 3.8736, 3.3192
Known param reward: [[3.873610019683838, 3.490786552429199, 3.2907512187957764], [3.490786552429199, 3.873610019683838, 3.1261727809906006], [3.838348150253296, 3.61712908744812, 3.319157123565674]], Known param reward error: [[0.0, 0.09882860311423, 0.00855816814703301], [0.09882860311423, 0.0, 0.058142575175156454], [0.009103102597153042, 0.06621237835827666, 0.0]].
