2024-09-17 23:58:57,278 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:198] - INFO: Logging to log_rdpo/2024_09_17_23_54_32/swapped_noise0.4_[0.4,0.4,0.4]_2025
2024-09-17 23:58:57,280 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: (IB) Seed: 2025
2024-09-17 23:58:57,281 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Data: 300
2024-09-17 23:58:57,444 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:296] - INFO: MLE reward loss: 0.5644, l2 distance: 7.1605, acc: 0.70.
2024-09-17 23:58:57,445 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-17 23:58:57,446 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: MLE reward parameter: [4.16061983 3.00918294 4.66723627 1.95463813]
2024-09-17 23:58:57,656 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:313] - INFO: Learned oracle reward: 3.6139, 3.8500, 3.2304
2024-09-17 23:58:57,907 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-17 23:58:59,065 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  19.6110, val_loss:  20.1013, grad_norm: 0.1422, live_grad: 0.0000, reward_err: 0.0781, 0.0054, 0.0407, KL_dist: 0.9753, 0.4622, 0.7517, param: [7.84408352 4.49371325 7.75603616 3.13147012], weights: [0.33344544 0.33315805 0.33339652], train_wt_loss:  58.8330, val_wt_loss: 60.3040, train_grp_loss: [23.1933588  15.01097576 21.47725592], val_grp_loss: [23.86167358 14.1631149  22.4963734 ], train_hist_grp_loss: [0.24898917 0.16276308 0.23431659], cur_train_grp_loss: [0.24898917 0.16276308 0.23431659], max_reward_err:  0.0781, max_reward_err_index: 0, max_kl_dist:  0.9753, max_kl_dist_index: 0, max_train_grp_loss:  23.1934, max_train_grp_loss_index: 0, max_val_grp_loss:  23.8617, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2490, max_cur_train_grp_loss_index: 0, 
2024-09-17 23:59:03,400 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  99, train_loss:  19.6143, val_loss:  20.0980, grad_norm: 0.0073,  live_grad: 0.0000, reward_err: 0.0763, 0.0069, 0.0394, KL_dist: 0.9668, 0.4744, 0.7482, param: [8.05740074 4.65551316 7.48299942 3.28587698], weights: [0.34943799 0.31145238 0.33910963], train_wt_loss:  58.8430, val_wt_loss: 60.2941, train_grp_loss: [23.05082332 15.17852101 21.43097628], val_grp_loss: [23.78167671 14.26708539 22.45808149], train_hist_grp_loss: [25.13134298 13.62337699 22.13107745], cur_train_grp_loss: [0.25056819 0.13672725 0.22094275], max_reward_err:  0.0763, max_reward_err_index: 0, max_kl_dist:  0.9668, max_kl_dist_index: 0, max_train_grp_loss:  23.0508, max_train_grp_loss_index: 0, max_val_grp_loss:  23.7817, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2506, max_cur_train_grp_loss_index: 0, 
2024-09-17 23:59:03,636 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:386] - INFO: Policy parameter learned solely on the preference data rdpo: [8.05740074 4.65551316 7.48299942 3.28587698].
2024-09-17 23:59:03,960 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:397] - INFO: Uniform reward: 3.8477, 3.8477, 3.2022
2024-09-17 23:59:03,961 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Optimal reward: 3.8884, 3.8884, 3.3468
2024-09-17 23:59:03,961 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Policy reward: 3.5917, 3.8616, 3.2149
2024-09-17 23:59:03,962 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Reward Error: 0.0763, 0.0069, 0.0394
2024-09-17 23:59:04,635 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:415] - INFO: Optimal reward: 3.8884, 3.8884, 3.3468
Known param reward: [[3.8883774280548096, 3.499903678894043, 3.3037302494049072], [3.499903678894043, 3.8883774280548096, 3.1488685607910156], [3.8492772579193115, 3.6396799087524414, 3.346843719482422]], Known param reward error: [[0.0, 0.09990638932268042, 0.012881829476095764], [0.09990638932268042, 0.0, 0.05915279447885975], [0.010055651967679024, 0.06395920249613757, 0.0]].
