2024-09-18 00:00:35,233 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:198] - INFO: Logging to log_rdpo/2024_09_17_23_54_32/swapped_noise0.4_[0.4,0.4,0.4]_2030
2024-09-18 00:00:35,235 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: (IB) Seed: 2030
2024-09-18 00:00:35,236 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Data: 300
2024-09-18 00:00:35,404 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:296] - INFO: MLE reward loss: 0.5934, l2 distance: 5.7688, acc: 0.65.
2024-09-18 00:00:35,405 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-18 00:00:35,406 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: MLE reward parameter: [2.97650869 1.42376823 4.29160856 1.61683097]
2024-09-18 00:00:35,613 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:313] - INFO: Learned oracle reward: 3.4812, 3.8882, 3.1736
2024-09-18 00:00:35,866 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-18 00:00:37,052 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  20.5484, val_loss:  20.3255, grad_norm: 0.1297, live_grad: 0.0000, reward_err: 0.1097, 0.0009, 0.0678, KL_dist: 1.0252, 0.3182, 0.7744, param: [5.77154958 2.39119691 8.89688235 2.94190787], weights: [0.3334722  0.33319437 0.33333343], train_wt_loss:  61.6451, val_wt_loss: 60.9765, train_grp_loss: [24.44996616 14.52106146 23.32597691], val_grp_loss: [24.09838679 13.839044   22.72149085], train_hist_grp_loss: [0.26336319 0.18001204 0.22174062], cur_train_grp_loss: [0.26336319 0.18001204 0.22174062], max_reward_err:  0.1097, max_reward_err_index: 0, max_kl_dist:  1.0252, max_kl_dist_index: 0, max_train_grp_loss:  24.4500, max_train_grp_loss_index: 0, max_val_grp_loss:  24.0984, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2634, max_cur_train_grp_loss_index: 0, 
2024-09-18 00:00:41,398 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  99, train_loss:  20.5508, val_loss:  20.3343, grad_norm: 0.0065,  live_grad: 0.0000, reward_err: 0.1078, 0.0019, 0.0662, KL_dist: 0.9890, 0.3132, 0.7465, param: [5.66644691 2.51466648 8.76897232 3.11285467], weights: [0.35438454 0.30926199 0.33635347], train_wt_loss:  61.6525, val_wt_loss: 61.0030, train_grp_loss: [24.36784062 14.64206735 23.28048931], val_grp_loss: [24.04155786 13.96263238 22.68676524], train_hist_grp_loss: [27.41578563 13.79640614 22.19378787], cur_train_grp_loss: [0.27380557 0.13812015 0.22172345], max_reward_err:  0.1078, max_reward_err_index: 0, max_kl_dist:  0.9890, max_kl_dist_index: 0, max_train_grp_loss:  24.3678, max_train_grp_loss_index: 0, max_val_grp_loss:  24.0416, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2738, max_cur_train_grp_loss_index: 0, 
2024-09-18 00:00:41,622 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:386] - INFO: Policy parameter learned solely on the preference data rdpo: [5.66644691 2.51466648 8.76897232 3.11285467].
2024-09-18 00:00:41,950 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:397] - INFO: Uniform reward: 3.8534, 3.8534, 3.2384
2024-09-18 00:00:41,951 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Optimal reward: 3.8968, 3.8968, 3.3939
2024-09-18 00:00:41,951 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Policy reward: 3.4767, 3.8896, 3.1693
2024-09-18 00:00:41,952 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Reward Error: 0.1078, 0.0019, 0.0662
2024-09-18 00:00:42,631 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:415] - INFO: Optimal reward: 3.8968, 3.8968, 3.3939
Known param reward: [[3.89680814743042, 3.508673906326294, 3.352841377258301], [3.508673906326294, 3.89680814743042, 3.2001588344573975], [3.8573405742645264, 3.620272397994995, 3.3939409255981445]], Known param reward error: [[0.0, 0.09960311783890725, 0.012109682885125766], [0.09960311783890725, 0.0, 0.05709648322962343], [0.010128179698022528, 0.0709646815991632, 0.0]].
