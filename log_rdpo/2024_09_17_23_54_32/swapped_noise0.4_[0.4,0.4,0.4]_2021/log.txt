2024-09-17 23:57:42,824 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:198] - INFO: Logging to log_rdpo/2024_09_17_23_54_32/swapped_noise0.4_[0.4,0.4,0.4]_2021
2024-09-17 23:57:42,826 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: (IB) Seed: 2021
2024-09-17 23:57:42,827 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Data: 300
2024-09-17 23:57:42,991 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:296] - INFO: MLE reward loss: 0.5896, l2 distance: 7.2846, acc: 0.70.
2024-09-17 23:57:42,992 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-17 23:57:42,993 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: MLE reward parameter: [4.36544362 1.37954621 4.59478501 2.54472126]
2024-09-17 23:57:43,203 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:313] - INFO: Learned oracle reward: 3.4589, 3.7861, 3.0943
2024-09-17 23:57:43,454 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-17 23:57:44,619 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  20.4558, val_loss:  20.5173, grad_norm: 0.1932, live_grad: 0.0000, reward_err: 0.0980, 0.0031, 0.0578, KL_dist: 1.1451, 0.5357, 0.8909, param: [8.09341899 2.32331101 9.26229492 4.50870097], weights: [0.33335753 0.33324201 0.33340046], train_wt_loss:  61.3675, val_wt_loss: 61.5519, train_grp_loss: [22.79711375 16.49232189 22.3720706 ], val_grp_loss: [22.06166765 17.17618967 22.57038667], train_hist_grp_loss: [0.24272526 0.20806493 0.25559985], cur_train_grp_loss: [0.24272526 0.20806493 0.25559985], max_reward_err:  0.0980, max_reward_err_index: 0, max_kl_dist:  1.1451, max_kl_dist_index: 0, max_train_grp_loss:  22.7971, max_train_grp_loss_index: 0, max_val_grp_loss:  22.5704, max_val_grp_loss_index: 2, max_cur_train_grp_loss:  0.2556, max_cur_train_grp_loss_index: 2, 
2024-09-17 23:57:48,964 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  99, train_loss:  20.4566, val_loss:  20.5247, grad_norm: 0.0040,  live_grad: 0.0000, reward_err: 0.0971, 0.0035, 0.0571, KL_dist: 1.1430, 0.5423, 0.8906, param: [8.11266872 2.4091849  9.26055715 4.60566275], weights: [0.34013144 0.31711715 0.34275141], train_wt_loss:  61.3698, val_wt_loss: 61.5742, train_grp_loss: [22.75564302 16.55276444 22.35134717], val_grp_loss: [22.03555426 17.24940039 22.54037265], train_hist_grp_loss: [22.79170753 15.78562005 23.55903595], cur_train_grp_loss: [0.22756072 0.15763922 0.23527959], max_reward_err:  0.0971, max_reward_err_index: 0, max_kl_dist:  1.1430, max_kl_dist_index: 0, max_train_grp_loss:  22.7556, max_train_grp_loss_index: 0, max_val_grp_loss:  22.5404, max_val_grp_loss_index: 2, max_cur_train_grp_loss:  0.2353, max_cur_train_grp_loss_index: 2, 
2024-09-17 23:57:49,188 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:386] - INFO: Policy parameter learned solely on the preference data rdpo: [8.11266872 2.4091849  9.26055715 4.60566275].
2024-09-17 23:57:49,518 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:397] - INFO: Uniform reward: 3.7701, 3.7701, 3.1348
2024-09-17 23:57:49,519 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Optimal reward: 3.8031, 3.8031, 3.2612
2024-09-17 23:57:49,520 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Policy reward: 3.4338, 3.7896, 3.0750
2024-09-17 23:57:49,520 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Reward Error: 0.0971, 0.0035, 0.0571
2024-09-17 23:57:50,203 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:415] - INFO: Optimal reward: 3.8031, 3.8031, 3.2612
Known param reward: [[3.8031005859375, 3.407827615737915, 3.227226972579956], [3.407827615737915, 3.8031005859375, 3.0572001934051514], [3.767336845397949, 3.540113687515259, 3.2611656188964844]], Known param reward error: [[0.0, 0.1039343980701332, 0.010406906696143971], [0.1039343980701332, 0.0, 0.0625437188192702], [0.009403837666506178, 0.0691506554926978, 0.0]].
