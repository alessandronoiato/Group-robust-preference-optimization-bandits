2024-09-17 23:59:55,237 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:198] - INFO: Logging to log_rdpo/2024_09_17_23_54_32/swapped_noise0.4_[0.4,0.4,0.4]_2028
2024-09-17 23:59:55,239 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: (IB) Seed: 2028
2024-09-17 23:59:55,239 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Data: 300
2024-09-17 23:59:55,406 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:296] - INFO: MLE reward loss: 0.6090, l2 distance: 6.8385, acc: 0.69.
2024-09-17 23:59:55,407 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-17 23:59:55,408 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: MLE reward parameter: [5.18949372 1.72963998 2.8716218  1.75848308]
2024-09-17 23:59:55,621 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:313] - INFO: Learned oracle reward: 3.4853, 3.8323, 3.0983
2024-09-17 23:59:55,868 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-17 23:59:57,057 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  21.2274, val_loss:  19.9713, grad_norm: 0.1409, live_grad: 0.0000, reward_err: 0.0956, 0.0014, 0.0589, KL_dist: 1.1845, 0.4624, 0.9519, param: [10.71402977  3.26990396  5.59039416  3.28945503], weights: [0.33322494 0.33338886 0.33338619], train_wt_loss:  63.6821, val_wt_loss: 59.9138, train_grp_loss: [24.02663112 16.96207167 21.78519644], val_grp_loss: [23.73462972 14.08047572 22.06520827], train_hist_grp_loss: [0.19919667 0.24837722 0.24757623], cur_train_grp_loss: [0.19919667 0.24837722 0.24757623], max_reward_err:  0.0956, max_reward_err_index: 0, max_kl_dist:  1.1845, max_kl_dist_index: 0, max_train_grp_loss:  24.0266, max_train_grp_loss_index: 0, max_val_grp_loss:  23.7346, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2484, max_cur_train_grp_loss_index: 1, 
2024-09-18 00:00:01,363 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  99, train_loss:  21.2276, val_loss:  19.9624, grad_norm: 0.0018,  live_grad: 0.0000, reward_err: 0.0947, 0.0017, 0.0580, KL_dist: 1.1809, 0.4665, 0.9487, param: [10.68141499  3.30930033  5.65553908  3.33654537], weights: [0.33052416 0.32634576 0.34313008], train_wt_loss:  63.6827, val_wt_loss: 59.8872, train_grp_loss: [24.03247856 16.98300281 21.75751138], val_grp_loss: [23.71603856 14.08920017 22.04840825], train_hist_grp_loss: [20.19012746 18.91789461 23.93311218], cur_train_grp_loss: [0.20195309 0.18869759 0.23909664], max_reward_err:  0.0947, max_reward_err_index: 0, max_kl_dist:  1.1809, max_kl_dist_index: 0, max_train_grp_loss:  24.0325, max_train_grp_loss_index: 0, max_val_grp_loss:  23.7160, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2391, max_cur_train_grp_loss_index: 2, 
2024-09-18 00:00:01,584 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:386] - INFO: Policy parameter learned solely on the preference data rdpo: [10.68141499  3.30930033  5.65553908  3.33654537].
2024-09-18 00:00:01,912 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:397] - INFO: Uniform reward: 3.8016, 3.8016, 3.1504
2024-09-18 00:00:01,913 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Optimal reward: 3.8416, 3.8416, 3.2815
2024-09-18 00:00:01,913 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Policy reward: 3.4777, 3.8352, 3.0912
2024-09-18 00:00:01,914 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Reward Error: 0.0947, 0.0017, 0.0580
2024-09-18 00:00:02,600 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:415] - INFO: Optimal reward: 3.8416, 3.8416, 3.2815
Known param reward: [[3.841636896133423, 3.4451205730438232, 3.251262903213501], [3.4451205730438232, 3.841636896133423, 3.080437421798706], [3.805366277694702, 3.5709657669067383, 3.281508684158325]], Known param reward error: [[0.0, 0.10321546096370798, 0.00921703516764636], [0.10321546096370798, 0.0, 0.0612740302441686], [0.009441448897793229, 0.0704572390740814, 0.0]].
