2024-09-18 00:00:14,383 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:198] - INFO: Logging to log_rdpo/2024_09_17_23_54_32/swapped_noise0.4_[0.4,0.4,0.4]_2029
2024-09-18 00:00:14,385 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: (IB) Seed: 2029
2024-09-18 00:00:14,385 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Data: 300
2024-09-18 00:00:14,552 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:296] - INFO: MLE reward loss: 0.5210, l2 distance: 10.4945, acc: 0.73.
2024-09-18 00:00:14,552 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-18 00:00:14,553 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: MLE reward parameter: [2.93068584 2.27402775 6.80133542 4.9818987 ]
2024-09-18 00:00:14,763 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:313] - INFO: Learned oracle reward: 3.5978, 3.7356, 3.2418
2024-09-18 00:00:15,012 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-18 00:00:16,199 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  18.1087, val_loss:  21.2925, grad_norm: 0.1712, live_grad: 0.0000, reward_err: 0.0915, 0.0366, 0.0584, KL_dist: 1.3560, 0.7094, 1.1669, param: [ 3.48374545  2.86769117 11.94611039  7.19134575], weights: [0.3334556  0.33309858 0.33344582], train_wt_loss:  54.3261, val_wt_loss: 63.8774, train_grp_loss: [21.53215553 11.75599183 22.035759  ], val_grp_loss: [22.15646832 18.38462842 23.02449384], train_hist_grp_loss: [0.24372667 0.13660252 0.24079165], cur_train_grp_loss: [0.24372667 0.13660252 0.24079165], max_reward_err:  0.0915, max_reward_err_index: 0, max_kl_dist:  1.3560, max_kl_dist_index: 0, max_train_grp_loss:  22.0358, max_train_grp_loss_index: 2, max_val_grp_loss:  23.0245, max_val_grp_loss_index: 2, max_cur_train_grp_loss:  0.2437, max_cur_train_grp_loss_index: 0, 
2024-09-18 00:00:20,510 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  99, train_loss:  18.1099, val_loss:  21.3141, grad_norm: 0.0052,  live_grad: 0.0000, reward_err: 0.0908, 0.0366, 0.0573, KL_dist: 1.3547, 0.7244, 1.1660, param: [ 3.58759895  2.95202073 11.9422822   7.29377587], weights: [0.3465182  0.30681848 0.34666331], train_wt_loss:  54.3297, val_wt_loss: 63.9424, train_grp_loss: [21.50564844 11.80885169 22.00484044], val_grp_loss: [22.12076874 18.5233749  22.99933353], train_hist_grp_loss: [22.9076534  10.73975032 22.94952212], cur_train_grp_loss: [0.2287865  0.10734785 0.22922042], max_reward_err:  0.0908, max_reward_err_index: 0, max_kl_dist:  1.3547, max_kl_dist_index: 0, max_train_grp_loss:  22.0048, max_train_grp_loss_index: 2, max_val_grp_loss:  22.9993, max_val_grp_loss_index: 2, max_cur_train_grp_loss:  0.2292, max_cur_train_grp_loss_index: 2, 
2024-09-18 00:00:20,732 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:386] - INFO: Policy parameter learned solely on the preference data rdpo: [ 3.58759895  2.95202073 11.9422822   7.29377587].
2024-09-18 00:00:21,058 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:397] - INFO: Uniform reward: 3.8505, 3.8505, 3.2427
2024-09-18 00:00:21,059 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Optimal reward: 3.8970, 3.8970, 3.3894
2024-09-18 00:00:21,059 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Policy reward: 3.5433, 3.7544, 3.1950
2024-09-18 00:00:21,060 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Reward Error: 0.0908, 0.0366, 0.0573
2024-09-18 00:00:21,737 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:415] - INFO: Optimal reward: 3.8970, 3.8970, 3.3894
Known param reward: [[3.8969926834106445, 3.485361099243164, 3.352837324142456], [3.485361099243164, 3.8969926834106445, 3.181079149246216], [3.8613202571868896, 3.6162831783294678, 3.3893625736236572]], Known param reward error: [[0.0, 0.10562801052200613, 0.010776436184621895], [0.10562801052200613, 0.0, 0.061452093086270226], [0.009153834539030853, 0.07203234080375538, 0.0]].
