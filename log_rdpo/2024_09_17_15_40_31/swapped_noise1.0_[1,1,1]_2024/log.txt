2024-09-17 15:45:49,393 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:198] - INFO: Logging to log_rdpo/2024_09_17_15_40_31/swapped_noise1.0_[1,1,1]_2024
2024-09-17 15:45:49,395 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: (IB) Seed: 2024
2024-09-17 15:45:49,395 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Data: 300
2024-09-17 15:45:49,557 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:296] - INFO: MLE reward loss: 0.3356, l2 distance: 38.9673, acc: 0.85.
2024-09-17 15:45:49,557 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-17 15:45:49,558 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: MLE reward parameter: [17.27970071  8.4454928  15.8117603   7.63032288]
2024-09-17 15:45:49,759 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:313] - INFO: Learned oracle reward: 3.4756, 3.7525, 3.0863
2024-09-17 15:45:49,988 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-17 15:45:51,154 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  14.2034, val_loss:  15.3329, grad_norm: 0.2917, live_grad: 0.0000, reward_err: 0.0910, 0.0004, 0.0539, KL_dist: 2.2845, 1.3386, 1.8775, param: [14.47097672  5.55876432 12.79854097  4.73007604], weights: [0.33330241 0.33339233 0.33330525], train_wt_loss:  42.6101, val_wt_loss: 45.9987, train_grp_loss: [18.3898056   8.01621739 15.3202444 ], val_grp_loss: [19.86814884  8.34887898 17.31047267], train_hist_grp_loss: [0.21290285 0.23987755 0.21375545], cur_train_grp_loss: [0.21290285 0.23987755 0.21375545], max_reward_err:  0.0910, max_reward_err_index: 0, max_kl_dist:  2.2845, max_kl_dist_index: 0, max_train_grp_loss:  18.3898, max_train_grp_loss_index: 0, max_val_grp_loss:  19.8681, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2399, max_cur_train_grp_loss_index: 1, 
2024-09-17 15:45:55,547 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  100, train_loss:  14.2064, val_loss:  15.3513, grad_norm: 0.0070, live_grad: 0.0000, reward_err: 0.0904, 0.0006, 0.0533, KL_dist: 2.2970, 1.3616, 1.8919, param: [14.53741523  5.75017535 12.86622969  4.93037364], weights: [0.34590245 0.31815078 0.33594676], train_wt_loss:  42.6192, val_wt_loss: 46.0539, train_grp_loss: [18.26667731  8.30807157 15.20183169], val_grp_loss: [19.73582722  8.68726433 17.18632326], train_hist_grp_loss: [17.66888814  9.30575051 14.7484776 ], cur_train_grp_loss: [0.17398003 0.09227858 0.14479052], max_reward_err:  0.0904, max_reward_err_index: 0, max_kl_dist:  2.2970, max_kl_dist_index: 0, max_train_grp_loss:  18.2667, max_train_grp_loss_index: 0, max_val_grp_loss:  19.7358, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.1740, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:45:59,997 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  200, train_loss:  14.2154, val_loss:  15.3766, grad_norm: 0.0140, live_grad: 0.0000, reward_err: 0.0893, 0.0011, 0.0523, KL_dist: 2.3090, 1.3846, 1.9058, param: [14.5979572   5.94110753 12.93160402  5.12900513], weights: [0.35805535 0.30418948 0.33775516], train_wt_loss:  42.6462, val_wt_loss: 46.1297, train_grp_loss: [18.14502946  8.61502075 15.08605312], val_grp_loss: [19.6043468   9.04441554 17.06402167], train_hist_grp_loss: [35.00820984 18.70453167 29.17157746], cur_train_grp_loss: [0.17282128 0.09568765 0.14368756], max_reward_err:  0.0893, max_reward_err_index: 0, max_kl_dist:  2.3090, max_kl_dist_index: 0, max_train_grp_loss:  18.1450, max_train_grp_loss_index: 0, max_val_grp_loss:  19.6043, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.1728, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:46:04,312 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  300, train_loss:  14.2300, val_loss:  15.4081, grad_norm: 0.0210, live_grad: 0.0000, reward_err: 0.0877, 0.0012, 0.0510, KL_dist: 2.3203, 1.4075, 1.9192, param: [14.65217493  6.12960214 12.99395501  5.32396732], weights: [0.36974126 0.29148384 0.3387749 ], train_wt_loss:  42.6900, val_wt_loss: 46.2242, train_grp_loss: [18.02605317  8.93325706 14.97400484], val_grp_loss: [19.47502831  9.41585287 16.94476415], train_hist_grp_loss: [52.23284386 28.45095468 43.48608717], cur_train_grp_loss: [0.17168787 0.09922259 0.14262003], max_reward_err:  0.0877, max_reward_err_index: 0, max_kl_dist:  2.3203, max_kl_dist_index: 0, max_train_grp_loss:  18.0261, max_train_grp_loss_index: 0, max_val_grp_loss:  19.4750, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.1717, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:46:08,658 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  400, train_loss:  14.2497, val_loss:  15.4451, grad_norm: 0.0278, live_grad: 0.0000, reward_err: 0.0860, 0.0014, 0.0495, KL_dist: 2.3308, 1.4299, 1.9319, param: [14.69977113  6.31376676 13.05270266  5.51336026], weights: [0.3809501  0.27999227 0.33905763], train_wt_loss:  42.7490, val_wt_loss: 46.3353, train_grp_loss: [17.91085847  9.25847281 14.86667694], val_grp_loss: [19.34911686  9.79646904 16.82965279], train_hist_grp_loss: [69.34586622 38.55522775 57.69603623], cur_train_grp_loss: [0.17059037 0.10283557 0.14159737], max_reward_err:  0.0860, max_reward_err_index: 0, max_kl_dist:  2.3308, max_kl_dist_index: 0, max_train_grp_loss:  17.9109, max_train_grp_loss_index: 0, max_val_grp_loss:  19.3491, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.1706, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:46:12,991 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  500, train_loss:  14.2737, val_loss:  15.4866, grad_norm: 0.0342, live_grad: 0.0000, reward_err: 0.0843, 0.0016, 0.0480, KL_dist: 2.3405, 1.4516, 1.9437, param: [14.74058761  6.49185866 13.10740882  5.6954681 ], weights: [0.39168067 0.26965932 0.33866001], train_wt_loss:  42.8211, val_wt_loss: 46.4598, train_grp_loss: [17.80042883  9.58609161 14.76491494], val_grp_loss: [19.22773043 10.18080644 16.7196515 ], train_hist_grp_loss: [86.35135369 49.02260207 71.8063316 ], cur_train_grp_loss: [0.16953816 0.10647576 0.14062764], max_reward_err:  0.0843, max_reward_err_index: 0, max_kl_dist:  2.3405, max_kl_dist_index: 0, max_train_grp_loss:  17.8004, max_train_grp_loss_index: 0, max_val_grp_loss:  19.2277, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.1695, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:46:17,359 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  600, train_loss:  14.3012, val_loss:  15.5314, grad_norm: 0.0403, live_grad: 0.0000, reward_err: 0.0823, 0.0018, 0.0463, KL_dist: 2.3492, 1.4725, 1.9547, param: [14.77460505  6.66235667 13.1577806   5.86882613], weights: [0.4019395  0.26041884 0.33764167], train_wt_loss:  42.9036, val_wt_loss: 46.5943, train_grp_loss: [17.69558514  9.91152225 14.66939184], val_grp_loss: [19.11181812 10.56336356 16.6155522 ], train_hist_grp_loss: [103.25424545  59.85321209  85.8226059 ], cur_train_grp_loss: [0.16853908 0.11009215 0.13971728], max_reward_err:  0.0823, max_reward_err_index: 0, max_kl_dist:  2.3492, max_kl_dist_index: 0, max_train_grp_loss:  17.6956, max_train_grp_loss_index: 0, max_val_grp_loss:  19.1118, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.1685, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:46:21,705 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  700, train_loss:  14.3313, val_loss:  15.5785, grad_norm: 0.0459, live_grad: 0.0000, reward_err: 0.0808, 0.0021, 0.0449, KL_dist: 2.3569, 1.4922, 1.9646, param: [14.80193453  6.82401493 13.20366471  6.03226824], weights: [0.41173952 0.25219715 0.33606332], train_wt_loss:  42.9938, val_wt_loss: 46.7354, train_grp_loss: [17.59696213 10.23040658 14.58059258], val_grp_loss: [19.00213162 10.93889573 16.51795396], train_hist_grp_loss: [120.06017604  71.04219725  99.75104476], cur_train_grp_loss: [0.1675992  0.11363626 0.13887092], max_reward_err:  0.0808, max_reward_err_index: 0, max_kl_dist:  2.3569, max_kl_dist_index: 0, max_train_grp_loss:  17.5970, max_train_grp_loss_index: 0, max_val_grp_loss:  19.0021, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.1676, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:46:26,064 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  800, train_loss:  14.3630, val_loss:  15.6265, grad_norm: 0.0510, live_grad: 0.0000, reward_err: 0.0799, 0.0023, 0.0442, KL_dist: 2.3636, 1.5107, 1.9736, param: [14.82280232  6.97589481 13.24503459  6.18495185], weights: [0.4210988  0.24491602 0.33398518], train_wt_loss:  43.0890, val_wt_loss: 46.8794, train_grp_loss: [17.50499837 10.53883436 14.49881132], val_grp_loss: [18.8992116  11.30267728 16.42725582], train_hist_grp_loss: [136.77529232  82.58008325 113.59820547], cur_train_grp_loss: [0.16672271 0.11706459 0.13809137], max_reward_err:  0.0799, max_reward_err_index: 0, max_kl_dist:  2.3636, max_kl_dist_index: 0, max_train_grp_loss:  17.5050, max_train_grp_loss_index: 0, max_val_grp_loss:  18.8992, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.1667, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:46:30,464 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  900, train_loss:  14.3955, val_loss:  15.6744, grad_norm: 0.0555, live_grad: 0.0000, reward_err: 0.0788, 0.0026, 0.0432, KL_dist: 2.3693, 1.5278, 1.9815, param: [14.83753003  7.11737419 13.28197232  6.32636018], weights: [0.43003917 0.23849524 0.33146559], train_wt_loss:  43.1865, val_wt_loss: 47.0232, train_grp_loss: [17.41993929 10.83350544 14.42416032], val_grp_loss: [18.80338834 11.65070065 16.34366238], train_hist_grp_loss: [153.40606703  94.45337444 127.37083857], cur_train_grp_loss: [0.16591196 0.1203404  0.13737973], max_reward_err:  0.0788, max_reward_err_index: 0, max_kl_dist:  2.3693, max_kl_dist_index: 0, max_train_grp_loss:  17.4199, max_train_grp_loss_index: 0, max_val_grp_loss:  18.8034, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.1659, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:46:34,884 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  1000, train_loss:  14.4280, val_loss:  15.7213, grad_norm: 0.0596, live_grad: 0.0000, reward_err: 0.0767, 0.0029, 0.0414, KL_dist: 2.3741, 1.5434, 1.9883, param: [14.84651238  7.24813606 13.31464767  6.45628468], weights: [0.43858503 0.23285488 0.32856009], train_wt_loss:  43.2840, val_wt_loss: 47.1640, train_grp_loss: [17.34185122 11.11182836 14.35658821], val_grp_loss: [18.71479504 11.97979945 16.2672002 ], train_hist_grp_loss: [169.95912075 106.64529204 141.07572266], cur_train_grp_loss: [0.1651676  0.12343481 0.13673552], max_reward_err:  0.0767, max_reward_err_index: 0, max_kl_dist:  2.3741, max_kl_dist_index: 0, max_train_grp_loss:  17.3419, max_train_grp_loss_index: 0, max_val_grp_loss:  18.7148, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.1652, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:46:39,182 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  1100, train_loss:  14.4599, val_loss:  15.7664, grad_norm: 0.0631, live_grad: 0.0000, reward_err: 0.0767, 0.0032, 0.0414, KL_dist: 2.3778, 1.5576, 1.9941, param: [14.85019455  7.36814045 13.34329644  6.57479191], weights: [0.44676229 0.22791709 0.32532063], train_wt_loss:  43.3796, val_wt_loss: 47.2993, train_grp_loss: [17.27064364 11.37195522 14.29590456], val_grp_loss: [18.63339039 12.28769423 16.19774167], train_hist_grp_loss: [186.44106128 119.13658637 154.71951971], cur_train_grp_loss: [0.16448878 0.1263272  0.13615694], max_reward_err:  0.0767, max_reward_err_index: 0, max_kl_dist:  2.3778, max_kl_dist_index: 0, max_train_grp_loss:  17.2706, max_train_grp_loss_index: 0, max_val_grp_loss:  18.6334, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.1645, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:46:43,494 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  1200, train_loss:  14.4906, val_loss:  15.8092, grad_norm: 0.0660, live_grad: 0.0000, reward_err: 0.0761, 0.0033, 0.0410, KL_dist: 2.3807, 1.5704, 1.9990, param: [14.84905109  7.47758499 13.36819985  6.68218019], weights: [0.45459736 0.22360748 0.32179516], train_wt_loss:  43.4718, val_wt_loss: 47.4275, train_grp_loss: [17.20609645 11.61275994 14.24180787], val_grp_loss: [18.5589872  12.57296998 16.13503339], train_hist_grp_loss: [202.85834686 131.90635583 168.3086557 ], cur_train_grp_loss: [0.16387343 0.129005   0.13564112], max_reward_err:  0.0761, max_reward_err_index: 0, max_kl_dist:  2.3807, max_kl_dist_index: 0, max_train_grp_loss:  17.2061, max_train_grp_loss_index: 0, max_val_grp_loss:  18.5590, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.1639, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:46:47,773 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  1300, train_loss:  14.5198, val_loss:  15.8491, grad_norm: 0.0685, live_grad: 0.0000, reward_err: 0.0753, 0.0035, 0.0403, KL_dist: 2.3828, 1.5817, 2.0029, param: [14.8435672   7.57685923 13.38966602  6.77893154], weights: [0.46211648 0.21985613 0.31802739], train_wt_loss:  43.5593, val_wt_loss: 47.5473, train_grp_loss: [17.14788906 11.83377317 14.19391415], val_grp_loss: [18.49128352 12.83500057 16.07872598], train_hist_grp_loss: [219.21717637 144.93281639 181.84922834], cur_train_grp_loss: [0.16331849 0.1314629  0.13518442], max_reward_err:  0.0753, max_reward_err_index: 0, max_kl_dist:  2.3828, max_kl_dist_index: 0, max_train_grp_loss:  17.1479, max_train_grp_loss_index: 0, max_val_grp_loss:  18.4913, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.1633, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:46:52,088 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  1400, train_loss:  14.5471, val_loss:  15.8860, grad_norm: 0.0706, live_grad: 0.0000, reward_err: 0.0753, 0.0036, 0.0403, KL_dist: 2.3840, 1.5917, 2.0059, param: [14.83422338  7.66649762 13.40801444  6.86566318], weights: [0.46934508 0.2165982  0.31405672], train_wt_loss:  43.6414, val_wt_loss: 47.6579, train_grp_loss: [17.09562898 12.03508847 14.15178393], val_grp_loss: [18.4298936  13.07383812 16.02840275], train_hist_grp_loss: [235.52340733 158.19398175 195.34694144], cur_train_grp_loss: [0.16282022 0.1337019  0.13478265], max_reward_err:  0.0753, max_reward_err_index: 0, max_kl_dist:  2.3840, max_kl_dist_index: 0, max_train_grp_loss:  17.0956, max_train_grp_loss_index: 0, max_val_grp_loss:  18.4299, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.1628, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:46:56,429 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  1500, train_loss:  14.5725, val_loss:  15.9196, grad_norm: 0.0722, live_grad: 0.0000, reward_err: 0.0738, 0.0040, 0.0390, KL_dist: 2.3846, 1.6004, 2.0082, param: [14.82148345  7.74713478 13.42356361  6.9430824 ], weights: [0.47630735 0.21377427 0.30991838], train_wt_loss:  43.7175, val_wt_loss: 47.7589, train_grp_loss: [17.0488779  12.21725436 14.11494632], val_grp_loss: [18.37437635 13.29008475 15.98360564], train_hist_grp_loss: [251.78249989 171.66823    208.80706369], cur_train_grp_loss: [0.16237447 0.13572805 0.13443133], max_reward_err:  0.0738, max_reward_err_index: 0, max_kl_dist:  2.3846, max_kl_dist_index: 0, max_train_grp_loss:  17.0489, max_train_grp_loss_index: 0, max_val_grp_loss:  18.3744, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.1624, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:47:00,831 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  1600, train_loss:  14.5959, val_loss:  15.9501, grad_norm: 0.0735, live_grad: 0.0000, reward_err: 0.0727, 0.0044, 0.0381, KL_dist: 2.3845, 1.6079, 2.0097, param: [14.80578584  7.81946562 13.4366217   7.01194679], weights: [0.48302596 0.21133046 0.30564358], train_wt_loss:  43.7876, val_wt_loss: 47.8503, train_grp_loss: [17.00717421 12.38116421 14.08291911], val_grp_loss: [18.32426025 13.48476115 15.94385741], train_hist_grp_loss: [267.99948416 185.33474843 222.23440854], cur_train_grp_loss: [0.16197684 0.13755124 0.13412588], max_reward_err:  0.0727, max_reward_err_index: 0, max_kl_dist:  2.3845, max_kl_dist_index: 0, max_train_grp_loss:  17.0072, max_train_grp_loss_index: 0, max_val_grp_loss:  18.3243, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.1620, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:47:05,234 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  1700, train_loss:  14.6172, val_loss:  15.9775, grad_norm: 0.0744, live_grad: 0.0000, reward_err: 0.0717, 0.0046, 0.0373, KL_dist: 2.3838, 1.6144, 2.0106, param: [14.78753793  7.88421169 13.44747999  7.07303131], weights: [0.48952188 0.20921832 0.3012598 ], train_wt_loss:  43.8517, val_wt_loss: 47.9324, train_grp_loss: [16.97005137 12.52795293 14.05522492], val_grp_loss: [18.27906377 13.65918288 15.90867951], train_hist_grp_loss: [284.178947   199.17385883 235.63333135], cur_train_grp_loss: [0.16162287 0.13918406 0.13386173], max_reward_err:  0.0717, max_reward_err_index: 0, max_kl_dist:  2.3838, max_kl_dist_index: 0, max_train_grp_loss:  16.9701, max_train_grp_loss_index: 0, max_val_grp_loss:  18.2791, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.1616, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:47:09,571 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  1800, train_loss:  14.6366, val_loss:  16.0019, grad_norm: 0.0750, live_grad: 0.0000, reward_err: 0.0702, 0.0046, 0.0361, KL_dist: 2.3827, 1.6198, 2.0109, param: [14.76711279  7.94209433 13.45640872  7.12710223], weights: [0.49581428 0.20739463 0.29679109], train_wt_loss:  43.9099, val_wt_loss: 48.0056, train_grp_loss: [16.93705223 12.65890595 14.03140321], val_grp_loss: [18.23831146 13.81485125 15.87760579], train_hist_grp_loss: [300.3250344  213.16723455 249.00773999], cur_train_grp_loss: [0.16130822 0.14064078 0.13363451], max_reward_err:  0.0702, max_reward_err_index: 0, max_kl_dist:  2.3827, max_kl_dist_index: 0, max_train_grp_loss:  16.9371, max_train_grp_loss_index: 0, max_val_grp_loss:  18.2383, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.1613, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:47:13,958 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  1900, train_loss:  14.6542, val_loss:  16.0235, grad_norm: 0.0754, live_grad: 0.0000, reward_err: 0.0702, 0.0048, 0.0361, KL_dist: 2.3811, 1.6244, 2.0107, param: [14.74484794  7.99381423 13.46365481  7.17489776], weights: [0.50192052 0.2058211  0.29225838], train_wt_loss:  43.9625, val_wt_loss: 48.0704, train_grp_loss: [16.90773939 12.7753835  14.0110188 ], val_grp_loss: [18.20154578 13.95336216 15.85019242], train_hist_grp_loss: [316.4414656  227.29802461 262.3611151 ], cur_train_grp_loss: [0.16102872 0.14193651 0.13344007], max_reward_err:  0.0702, max_reward_err_index: 0, max_kl_dist:  2.3811, max_kl_dist_index: 0, max_train_grp_loss:  16.9077, max_train_grp_loss_index: 0, max_val_grp_loss:  18.2015, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.1610, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:47:18,238 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  1999, train_loss:  14.6699, val_loss:  16.0424, grad_norm: 0.0755,  live_grad: 0.0000, reward_err: 0.0699, 0.0050, 0.0358, KL_dist: 2.3792, 1.6282, 2.0100, param: [14.72129035  8.03959988 13.46938976  7.21671786], weights: [0.50779764 0.20447658 0.28772579], train_wt_loss:  44.0096, val_wt_loss: 48.1271, train_grp_loss: [16.88194774 12.87778719 13.99382706], val_grp_loss: [18.16865117 14.07517574 15.82625135], train_hist_grp_loss: [332.37077504 241.40781584 275.56326253], cur_train_grp_loss: [0.16078279 0.1430757  0.13327607], max_reward_err:  0.0699, max_reward_err_index: 0, max_kl_dist:  2.3792, max_kl_dist_index: 0, max_train_grp_loss:  16.8819, max_train_grp_loss_index: 0, max_val_grp_loss:  18.1687, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.1608, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:47:18,457 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:386] - INFO: Policy parameter learned solely on the preference data rdpo: [14.72129035  8.03959988 13.46938976  7.21671786].
2024-09-17 15:47:18,781 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:397] - INFO: Uniform reward: 3.7209, 3.7209, 3.0767
2024-09-17 15:47:18,782 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Optimal reward: 3.7640, 3.7640, 3.2194
2024-09-17 15:47:18,782 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Policy reward: 3.5008, 3.7452, 3.1041
2024-09-17 15:47:18,782 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Reward Error: 0.0699, 0.0050, 0.0358
2024-09-17 15:47:19,481 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:415] - INFO: Optimal reward: 3.7640, 3.7640, 3.2194
Known param reward: [[3.763953685760498, 3.410576581954956, 3.186079502105713], [3.410576581954956, 3.763953685760498, 3.0397133827209473], [3.730111837387085, 3.5351030826568604, 3.21937894821167]], Known param reward error: [[0.0, 0.0938845515401561, 0.010343437862279155], [0.0938845515401561, 0.0, 0.05580752324622267], [0.008991037403419968, 0.06080058954216355, 0.0]].
