2024-09-17 15:49:17,952 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:198] - INFO: Logging to log_rdpo/2024_09_17_15_40_31/swapped_noise1.0_[1,1,1]_2026
2024-09-17 15:49:17,953 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: (IB) Seed: 2026
2024-09-17 15:49:17,954 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Data: 300
2024-09-17 15:49:18,116 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:296] - INFO: MLE reward loss: 0.3087, l2 distance: 38.9242, acc: 0.85.
2024-09-17 15:49:18,116 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-17 15:49:18,117 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: MLE reward parameter: [15.88878879  8.80170801 16.01295451  9.88039608]
2024-09-17 15:49:18,324 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:313] - INFO: Learned oracle reward: 3.5908, 3.8271, 3.2006
2024-09-17 15:49:18,556 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-17 15:49:19,741 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  13.4192, val_loss:  14.0323, grad_norm: 0.2676, live_grad: 0.0000, reward_err: 0.0870, 0.0022, 0.0464, KL_dist: 2.0305, 1.2295, 1.6846, param: [12.10218496  6.2922392  13.44193991  5.18633949], weights: [0.33338144 0.33319094 0.33342763], train_wt_loss:  40.2575, val_wt_loss: 42.0968, train_grp_loss: [19.04301373  6.37026789 14.71101654], val_grp_loss: [18.28658065  7.93671035 15.28820238], train_hist_grp_loss: [0.20616348 0.14900545 0.22001781], cur_train_grp_loss: [0.20616348 0.14900545 0.22001781], max_reward_err:  0.0870, max_reward_err_index: 0, max_kl_dist:  2.0305, max_kl_dist_index: 0, max_train_grp_loss:  19.0430, max_train_grp_loss_index: 0, max_val_grp_loss:  18.2866, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2200, max_cur_train_grp_loss_index: 2, 
2024-09-17 15:49:24,084 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  100, train_loss:  13.4247, val_loss:  14.0553, grad_norm: 0.0107, live_grad: 0.0000, reward_err: 0.0853, 0.0028, 0.0450, KL_dist: 2.0494, 1.2606, 1.7055, param: [12.2296861   6.54133161 13.50621178  5.39865849], weights: [0.34899603 0.31056594 0.34043803], train_wt_loss:  40.2741, val_wt_loss: 42.1660, train_grp_loss: [18.89417328  6.68367209 14.55819097], val_grp_loss: [18.12939522  8.34281444 15.1411237 ], train_hist_grp_loss: [18.27266679  6.6062391  15.78992486], cur_train_grp_loss: [0.17995895 0.06614182 0.15489083], max_reward_err:  0.0853, max_reward_err_index: 0, max_kl_dist:  2.0494, max_kl_dist_index: 0, max_train_grp_loss:  18.8942, max_train_grp_loss_index: 0, max_val_grp_loss:  18.1294, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.1800, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:49:28,493 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  200, train_loss:  13.4420, val_loss:  14.0900, grad_norm: 0.0222, live_grad: 0.0000, reward_err: 0.0841, 0.0033, 0.0439, KL_dist: 2.0686, 1.2933, 1.7269, param: [12.35621084  6.80060679 13.56847325  5.62039808], weights: [0.36398588 0.2897783  0.34623582], train_wt_loss:  40.3260, val_wt_loss: 42.2699, train_grp_loss: [18.74023801  7.04037475 14.40214717], val_grp_loss: [17.96691871  8.79503254 14.99084718], train_hist_grp_loss: [36.19488606 13.39499358 31.19539093], cur_train_grp_loss: [0.1784933  0.06966926 0.15323103], max_reward_err:  0.0841, max_reward_err_index: 0, max_kl_dist:  2.0686, max_kl_dist_index: 0, max_train_grp_loss:  18.7402, max_train_grp_loss_index: 0, max_val_grp_loss:  17.9669, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.1785, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:49:32,892 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  300, train_loss:  13.4720, val_loss:  14.1367, grad_norm: 0.0343, live_grad: 0.0000, reward_err: 0.0819, 0.0043, 0.0421, KL_dist: 2.0877, 1.3273, 1.7485, param: [12.47996613  7.06715852 13.62748834  5.84914527], weights: [0.3783012  0.27085432 0.35084448], train_wt_loss:  40.4161, val_wt_loss: 42.4101, train_grp_loss: [18.58297872  7.43939062 14.24486508], val_grp_loss: [17.80104534  9.29107275 14.8392554 ], train_hist_grp_loss: [53.9687823  20.55782339 46.43401678], cur_train_grp_loss: [0.17699582 0.07361584 0.15155784], max_reward_err:  0.0819, max_reward_err_index: 0, max_kl_dist:  2.0877, max_kl_dist_index: 0, max_train_grp_loss:  18.5830, max_train_grp_loss_index: 0, max_val_grp_loss:  17.8010, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.1770, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:49:37,320 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  400, train_loss:  13.5151, val_loss:  14.1956, grad_norm: 0.0468, live_grad: 0.0000, reward_err: 0.0794, 0.0047, 0.0400, KL_dist: 2.1065, 1.3621, 1.7701, param: [12.59923603  7.33759069 13.68204208  6.08204175], weights: [0.39191112 0.25377971 0.35430917], train_wt_loss:  40.5452, val_wt_loss: 42.5868, train_grp_loss: [18.42439974  7.87758796 14.08848167], val_grp_loss: [17.63391646  9.82635652 14.68838164], train_hist_grp_loss: [71.59211954 28.1352723  61.50560107], cur_train_grp_loss: [0.17548557 0.07795077 0.14989398], max_reward_err:  0.0794, max_reward_err_index: 0, max_kl_dist:  2.1065, max_kl_dist_index: 0, max_train_grp_loss:  18.4244, max_train_grp_loss_index: 0, max_val_grp_loss:  17.6339, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.1755, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:49:41,653 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  500, train_loss:  13.5707, val_loss:  14.2659, grad_norm: 0.0593, live_grad: 0.0000, reward_err: 0.0770, 0.0060, 0.0380, KL_dist: 2.1248, 1.3972, 1.7914, param: [12.71247963  7.60817121 13.73101989  6.31591063], weights: [0.40480237 0.23850478 0.35669285], train_wt_loss:  40.7121, val_wt_loss: 42.7978, train_grp_loss: [18.26664334  8.34959738 13.93518004], val_grp_loss: [17.46781685 10.39401338 14.5403056 ], train_hist_grp_loss: [89.06464433 36.16368436 76.41225075], cur_train_grp_loss: [0.17398295 0.08262112 0.14826267], max_reward_err:  0.0770, max_reward_err_index: 0, max_kl_dist:  2.1248, max_kl_dist_index: 0, max_train_grp_loss:  18.2666, max_train_grp_loss_index: 0, max_val_grp_loss:  17.4678, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.1740, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:49:46,037 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  600, train_loss:  13.6379, val_loss:  14.3464, grad_norm: 0.0717, live_grad: 0.0000, reward_err: 0.0758, 0.0063, 0.0370, KL_dist: 2.1421, 1.4322, 1.8119, param: [12.81841585  7.87503438 13.773481    6.5474279 ], weights: [0.4169774  0.22495061 0.35807199], train_wt_loss:  40.9138, val_wt_loss: 43.0392, train_grp_loss: [18.1118722   8.84797219 13.78706611], val_grp_loss: [17.30504809 10.9851396  14.39703676], train_hist_grp_loss: [106.38816301  44.67304498  91.15836565], cur_train_grp_loss: [0.17250855 0.08755333 0.14668633], max_reward_err:  0.0758, max_reward_err_index: 0, max_kl_dist:  2.1421, max_kl_dist_index: 0, max_train_grp_loss:  18.1119, max_train_grp_loss_index: 0, max_val_grp_loss:  17.3050, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.1725, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:49:50,419 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  700, train_loss:  13.7149, val_loss:  14.4352, grad_norm: 0.0836, live_grad: 0.0000, reward_err: 0.0738, 0.0083, 0.0353, KL_dist: 2.1583, 1.4666, 1.8314, param: [12.91608432  8.13441028 13.80871566  6.7733204 ], weights: [0.42845212 0.21301553 0.35853235], train_wt_loss:  41.1448, val_wt_loss: 43.3055, train_grp_loss: [17.96214292  9.3636124  13.64604747], val_grp_loss: [17.14779298 11.5893194  14.26039931], train_hist_grp_loss: [123.56650161  53.6851112  105.75049171], cur_train_grp_loss: [0.17108199 0.09265746 0.14518529], max_reward_err:  0.0738, max_reward_err_index: 0, max_kl_dist:  2.1583, max_kl_dist_index: 0, max_train_grp_loss:  17.9621, max_train_grp_loss_index: 0, max_val_grp_loss:  17.1478, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.1711, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:49:54,754 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  800, train_loss:  13.7995, val_loss:  14.5298, grad_norm: 0.0948, live_grad: 0.0000, reward_err: 0.0720, 0.0091, 0.0339, KL_dist: 2.1732, 1.4997, 1.8497, param: [13.00487541  8.38285207 13.83627905  6.99056543], weights: [0.43925335 0.20258178 0.35816487], train_wt_loss:  41.3984, val_wt_loss: 43.5895, train_grp_loss: [17.81928668  9.88640921 13.51372958], val_grp_loss: [16.99798853 12.19535121 14.13193296], train_hist_grp_loss: [140.60534733  63.21207558 120.19705315], cur_train_grp_loss: [0.16972072 0.09783347 0.14377665], max_reward_err:  0.0720, max_reward_err_index: 0, max_kl_dist:  2.1732, max_kl_dist_index: 0, max_train_grp_loss:  17.8193, max_train_grp_loss_index: 0, max_val_grp_loss:  16.9980, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.1697, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:49:59,097 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  900, train_loss:  13.8890, val_loss:  14.6279, grad_norm: 0.1052, live_grad: 0.0000, reward_err: 0.0705, 0.0101, 0.0328, KL_dist: 2.1867, 1.5313, 1.8664, param: [13.08452771  8.6174316  13.85599871  7.19656543], weights: [0.44941631 0.19352161 0.35706208], train_wt_loss:  41.6670, val_wt_loss: 43.8837, train_grp_loss: [17.68481231 10.40601731 13.3913419 ], val_grp_loss: [16.85722367 12.79207517 14.0128218 ], train_hist_grp_loss: [157.51198584  73.25594016 134.50798911], cur_train_grp_loss: [0.16843916 0.10297891 0.14247355], max_reward_err:  0.0705, max_reward_err_index: 0, max_kl_dist:  2.1867, max_kl_dist_index: 0, max_train_grp_loss:  17.6848, max_train_grp_loss_index: 0, max_val_grp_loss:  16.8572, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.1684, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:50:03,438 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  1000, train_loss:  13.9808, val_loss:  14.7268, grad_norm: 0.1146, live_grad: 0.0000, reward_err: 0.0685, 0.0110, 0.0312, KL_dist: 2.1985, 1.5609, 1.8816, param: [13.15509688  8.83587895 13.8679574   7.38927581], weights: [0.45898205 0.18570292 0.35531503], train_wt_loss:  41.9425, val_wt_loss: 44.1803, train_grp_loss: [17.55984323 10.91263462 13.2797011 ], val_grp_loss: [16.7266736  13.36917575 13.90385823], train_hist_grp_loss: [174.29496163  83.80866892 148.69433085], cur_train_grp_loss: [0.16724803 0.10799666 0.14128471], max_reward_err:  0.0685, max_reward_err_index: 0, max_kl_dist:  2.1985, max_kl_dist_index: 0, max_train_grp_loss:  17.5598, max_train_grp_loss_index: 0, max_val_grp_loss:  16.7267, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.1672, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:50:07,763 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  1100, train_loss:  14.0725, val_loss:  14.8241, grad_norm: 0.1230, live_grad: 0.0000, reward_err: 0.0656, 0.0119, 0.0289, KL_dist: 2.2086, 1.5882, 1.8950, param: [13.21690374  9.0366525  13.87245675  7.56727298], weights: [0.46799524 0.17899392 0.35301084], train_wt_loss:  42.2175, val_wt_loss: 44.4723, train_grp_loss: [17.44509313 11.39767204 13.17921205], val_grp_loss: [16.60707571 13.91784294 13.80544289], train_hist_grp_loss: [190.96369632  94.85306714 162.76775988], cur_train_grp_loss: [0.16615418 0.11280151 0.14021448], max_reward_err:  0.0656, max_reward_err_index: 0, max_kl_dist:  2.2086, max_kl_dist_index: 0, max_train_grp_loss:  17.4451, max_train_grp_loss_index: 0, max_val_grp_loss:  16.6071, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.1662, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:50:12,073 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  1200, train_loss:  14.1617, val_loss:  14.9179, grad_norm: 0.1302, live_grad: 0.0000, reward_err: 0.0641, 0.0128, 0.0277, KL_dist: 2.2172, 1.6130, 1.9066, param: [13.27047119  9.218939   13.86996938  7.72976112], weights: [0.47650207 0.17326694 0.35023099], train_wt_loss:  42.4852, val_wt_loss: 44.7536, train_grp_loss: [17.34087867 11.8542273  13.08990155], val_grp_loss: [16.4987449  14.43121255 13.71761582], train_hist_grp_loss: [207.52810174 106.36423315 176.74018516], cur_train_grp_loss: [0.16516065 0.11732496 0.13926319], max_reward_err:  0.0641, max_reward_err_index: 0, max_kl_dist:  2.2172, max_kl_dist_index: 0, max_train_grp_loss:  17.3409, max_train_grp_loss_index: 0, max_val_grp_loss:  16.4987, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.1652, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:50:16,410 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  1300, train_loss:  14.2468, val_loss:  15.0064, grad_norm: 0.1363, live_grad: 0.0000, reward_err: 0.0636, 0.0138, 0.0273, KL_dist: 2.2241, 1.6352, 1.9166, param: [13.31645911  9.38259386 13.861087    7.87652608], weights: [0.48454864 0.16840121 0.34705016], train_wt_loss:  42.7404, val_wt_loss: 45.0193, train_grp_loss: [17.2471618  12.27732521 13.01147537], val_grp_loss: [16.40162008 14.90455685 13.64011031], train_hist_grp_loss: [223.99821978 118.31136565 190.6233693 ], cur_train_grp_loss: [0.16426712 0.12151754 0.13842774], max_reward_err:  0.0636, max_reward_err_index: 0, max_kl_dist:  2.2241, max_kl_dist_index: 0, max_train_grp_loss:  17.2472, max_train_grp_loss_index: 0, max_val_grp_loss:  16.4016, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.1643, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:50:20,772 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  1400, train_loss:  14.3264, val_loss:  15.0887, grad_norm: 0.1414, live_grad: 0.0000, reward_err: 0.0631, 0.0145, 0.0270, KL_dist: 2.2295, 1.6549, 1.9248, param: [13.35560449  9.52803951 13.84647099  8.00785116], weights: [0.49217959 0.1642848  0.34353561], train_wt_loss:  42.9792, val_wt_loss: 45.2661, train_grp_loss: [17.1636117  12.66393375 12.9433883 ], val_grp_loss: [16.31533108 15.33524492 13.57241913], train_hist_grp_loss: [240.38391268 130.65969673 204.42862327], cur_train_grp_loss: [0.16347046 0.12534905 0.13770234], max_reward_err:  0.0631, max_reward_err_index: 0, max_kl_dist:  2.2295, max_kl_dist_index: 0, max_train_grp_loss:  17.1636, max_train_grp_loss_index: 0, max_val_grp_loss:  16.3153, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.1635, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:50:25,100 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  1500, train_loss:  14.3996, val_loss:  15.1640, grad_norm: 0.1455, live_grad: 0.0000, reward_err: 0.0631, 0.0152, 0.0270, KL_dist: 2.2336, 1.6721, 1.9315, param: [13.38867117  9.65614127 13.82680961  8.12441201], weights: [0.49943719 0.16081573 0.33974708], train_wt_loss:  43.1989, val_wt_loss: 45.4920, train_grp_loss: [17.08967543 13.01280121 12.88491701], val_grp_loss: [16.23927438 15.72252547 13.51386396], train_hist_grp_loss: [256.69461718 143.37234822 218.16657784], cur_train_grp_loss: [0.16276542 0.12880693 0.13707933], max_reward_err:  0.0631, max_reward_err_index: 0, max_kl_dist:  2.2336, max_kl_dist_index: 0, max_train_grp_loss:  17.0897, max_train_grp_loss_index: 0, max_val_grp_loss:  16.2393, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.1628, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:50:29,454 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  1600, train_loss:  14.4661, val_loss:  15.2320, grad_norm: 0.1487, live_grad: 0.0000, reward_err: 0.0627, 0.0152, 0.0266, KL_dist: 2.2363, 1.6870, 1.9367, param: [13.41641105  9.76807876 13.80278402  8.22716637], weights: [0.50636068 0.15790241 0.33573691], train_wt_loss:  43.3984, val_wt_loss: 45.6961, train_grp_loss: [17.0246483  13.32417623 12.8352283 ], val_grp_loss: [16.17268809 16.06719956 13.46366033], train_hist_grp_loss: [272.93916649 156.4119642  231.84703076], cur_train_grp_loss: [0.16214531 0.13189351 0.13654984], max_reward_err:  0.0627, max_reward_err_index: 0, max_kl_dist:  2.2363, max_kl_dist_index: 0, max_train_grp_loss:  17.0246, max_train_grp_loss_index: 0, max_val_grp_loss:  16.1727, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.1621, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:50:33,827 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  1700, train_loss:  14.5258, val_loss:  15.2929, grad_norm: 0.1511, live_grad: 0.0000, reward_err: 0.0621, 0.0155, 0.0262, KL_dist: 2.2380, 1.6997, 1.9406, param: [13.43953689  9.86522642 13.77504368  8.3172506 ], weights: [0.51298586 0.15546364 0.3315505 ], train_wt_loss:  43.5774, val_wt_loss: 45.8786, train_grp_loss: [16.96773736 13.59947307 12.7934377 ], val_grp_loss: [16.1147193  16.37124805 13.42097365], train_hist_grp_loss: [289.12567642 169.74203464 245.47886173], cur_train_grp_loss: [0.16160256 0.13462269 0.13610446], max_reward_err:  0.0621, max_reward_err_index: 0, max_kl_dist:  2.2380, max_kl_dist_index: 0, max_train_grp_loss:  16.9677, max_train_grp_loss_index: 0, max_val_grp_loss:  16.3712, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.1616, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:50:38,153 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  1800, train_loss:  14.5788, val_loss:  15.3468, grad_norm: 0.1528, live_grad: 0.0000, reward_err: 0.0621, 0.0163, 0.0262, KL_dist: 2.2386, 1.7104, 1.9433, param: [13.45870502  9.94905141 13.74419012  8.39589073], weights: [0.51934502 0.15342815 0.32722683], train_wt_loss:  43.7365, val_wt_loss: 46.0403, train_grp_loss: [16.91811426 13.84093311 12.75865616], val_grp_loss: [16.06448    16.63746523 13.38496379], train_hist_grp_loss: [305.26148717 183.32788216 259.07000351], cur_train_grp_loss: [0.16112931 0.13701661 0.13573375], max_reward_err:  0.0621, max_reward_err_index: 0, max_kl_dist:  2.2386, max_kl_dist_index: 0, max_train_grp_loss:  16.9181, max_train_grp_loss_index: 0, max_val_grp_loss:  16.6375, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.1611, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:50:42,454 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  1900, train_loss:  14.6256, val_loss:  15.3942, grad_norm: 0.1538, live_grad: 0.0000, reward_err: 0.0615, 0.0163, 0.0258, KL_dist: 2.2384, 1.7193, 1.9451, param: [13.47450634 10.02103283 13.71076791  8.46433145], weights: [0.52546688 0.15173399 0.32279913], train_wt_loss:  43.8768, val_wt_loss: 46.1825, train_grp_loss: [16.87495625 14.05131785 12.7300245 ], val_grp_loss: [16.02109016 16.86913316 13.35481809], train_hist_grp_loss: [321.35314991 197.1373269  272.62745625], cur_train_grp_loss: [0.1607177  0.13910255 0.13542854], max_reward_err:  0.0615, max_reward_err_index: 0, max_kl_dist:  2.2384, max_kl_dist_index: 0, max_train_grp_loss:  16.8750, max_train_grp_loss_index: 0, max_val_grp_loss:  16.8691, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.1607, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:50:46,734 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  1999, train_loss:  14.6662, val_loss:  15.4353, grad_norm: 0.1543,  live_grad: 0.0000, reward_err: 0.0615, 0.0169, 0.0258, KL_dist: 2.2374, 1.7267, 1.9459, param: [13.4873463  10.08203356 13.67562498  8.52322967], weights: [0.53131867 0.1503405  0.31834084], train_wt_loss:  43.9985, val_wt_loss: 46.3058, train_grp_loss: [16.83782463 14.23195795 12.70694573], val_grp_loss: [15.98405527 17.06789011 13.33000134], train_hist_grp_loss: [337.24608654 211.00016079 286.02215223], cur_train_grp_loss: [0.16036356 0.14089367 0.1351825 ], max_reward_err:  0.0615, max_reward_err_index: 0, max_kl_dist:  2.2374, max_kl_dist_index: 0, max_train_grp_loss:  16.8378, max_train_grp_loss_index: 0, max_val_grp_loss:  17.0679, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.1604, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:50:46,952 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:386] - INFO: Policy parameter learned solely on the preference data rdpo: [13.4873463  10.08203356 13.67562498  8.52322967].
2024-09-17 15:50:47,272 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:397] - INFO: Uniform reward: 3.8214, 3.8214, 3.1807
2024-09-17 15:50:47,273 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Optimal reward: 3.8609, 3.8609, 3.3073
2024-09-17 15:50:47,273 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Policy reward: 3.6233, 3.7958, 3.2221
2024-09-17 15:50:47,274 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Reward Error: 0.0615, 0.0169, 0.0258
2024-09-17 15:50:47,977 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:415] - INFO: Optimal reward: 3.8609, 3.8609, 3.3073
Known param reward: [[3.8608756065368652, 3.4840316772460938, 3.274003028869629], [3.4840316772460938, 3.8608756065368652, 3.124580144882202], [3.820035219192505, 3.599329948425293, 3.307262659072876]], Known param reward error: [[0.0, 0.09760581994735479, 0.010056543320502622], [0.09760581994735479, 0.0, 0.055236772225972876], [0.010578011701597771, 0.06774257571747408, 0.0]].
