2024-09-17 15:44:05,441 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:198] - INFO: Logging to log_rdpo/2024_09_17_15_40_31/swapped_noise1.0_[1,1,1]_2023
2024-09-17 15:44:05,443 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: (IB) Seed: 2023
2024-09-17 15:44:05,443 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Data: 300
2024-09-17 15:44:05,609 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:296] - INFO: MLE reward loss: 0.3640, l2 distance: 33.1940, acc: 0.79.
2024-09-17 15:44:05,610 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-17 15:44:05,610 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: MLE reward parameter: [12.21044287  7.99401411 15.4309833   8.31914459]
2024-09-17 15:44:05,816 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:313] - INFO: Learned oracle reward: 3.5753, 3.8283, 3.1796
2024-09-17 15:44:06,159 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-17 15:44:07,316 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  14.6066, val_loss:  14.7000, grad_norm: 0.2988, live_grad: 0.0000, reward_err: 0.1018, 0.0007, 0.0637, KL_dist: 2.1608, 1.1763, 1.8143, param: [ 9.49712273  4.42807493 15.76875098  5.04876892], weights: [0.33333577 0.33327412 0.33339012], train_wt_loss:  43.8197, val_wt_loss: 44.0999, train_grp_loss: [21.26770405  6.5710972  16.58155136], val_grp_loss: [19.2266999   6.82553381 17.84002684], train_hist_grp_loss: [0.22367458 0.20517723 0.2399775 ], cur_train_grp_loss: [0.22367458 0.20517723 0.2399775 ], max_reward_err:  0.1018, max_reward_err_index: 0, max_kl_dist:  2.1608, max_kl_dist_index: 0, max_train_grp_loss:  21.2677, max_train_grp_loss_index: 0, max_val_grp_loss:  19.2267, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2400, max_cur_train_grp_loss_index: 2, 
2024-09-17 15:44:11,687 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  100, train_loss:  14.6169, val_loss:  14.7008, grad_norm: 0.0145, live_grad: 0.0000, reward_err: 0.1001, 0.0014, 0.0624, KL_dist: 2.1644, 1.1927, 1.8262, param: [ 9.35364866  4.74706157 15.8829137   5.39448743], weights: [0.35364753 0.30512549 0.34122698], train_wt_loss:  43.8507, val_wt_loss: 44.1023, train_grp_loss: [21.00205118  7.01078533 16.40133307], val_grp_loss: [19.01435132  7.23888696 17.65395325], train_hist_grp_loss: [21.3610531   6.60329501 17.78576903], cur_train_grp_loss: [0.21004775 0.06609419 0.17450186], max_reward_err:  0.1001, max_reward_err_index: 0, max_kl_dist:  2.1644, max_kl_dist_index: 0, max_train_grp_loss:  21.0021, max_train_grp_loss_index: 0, max_val_grp_loss:  19.0144, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2100, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:44:16,121 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  200, train_loss:  14.6502, val_loss:  14.7216, grad_norm: 0.0305, live_grad: 0.0000, reward_err: 0.0978, 0.0018, 0.0606, KL_dist: 2.1666, 1.2126, 1.8372, param: [ 9.2229199   5.08507722 15.97651915  5.76137457], weights: [0.37292236 0.2796818  0.34739584], train_wt_loss:  43.9507, val_wt_loss: 44.1647, train_grp_loss: [20.72416974  7.53329875 16.21404354], val_grp_loss: [18.78870762  7.73865233 17.45685179], train_hist_grp_loss: [42.22640519 13.45463208 35.13586885], cur_train_grp_loss: [0.20726996 0.07101563 0.17251002], max_reward_err:  0.0978, max_reward_err_index: 0, max_kl_dist:  2.1666, max_kl_dist_index: 0, max_train_grp_loss:  20.7242, max_train_grp_loss_index: 0, max_val_grp_loss:  18.7887, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2073, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:44:20,491 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  300, train_loss:  14.7092, val_loss:  14.7656, grad_norm: 0.0475, live_grad: 0.0000, reward_err: 0.0937, 0.0027, 0.0573, KL_dist: 2.1676, 1.2360, 1.8475, param: [ 9.10485883  5.43675894 16.04983555  6.14363764], weights: [0.39103266 0.2569999  0.35196743], train_wt_loss:  44.1275, val_wt_loss: 44.2967, train_grp_loss: [20.43846024  8.13926287 16.02282464], val_grp_loss: [18.55381007  8.32669116 17.25236246], train_hist_grp_loss: [62.80959029 20.83805247 52.28434667], cur_train_grp_loss: [0.20441339 0.07672455 0.170476  ], max_reward_err:  0.0937, max_reward_err_index: 0, max_kl_dist:  2.1676, max_kl_dist_index: 0, max_train_grp_loss:  20.4385, max_train_grp_loss_index: 0, max_val_grp_loss:  18.5538, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2044, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:44:24,867 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  400, train_loss:  14.7948, val_loss:  14.8344, grad_norm: 0.0650, live_grad: 0.0000, reward_err: 0.0900, 0.0040, 0.0543, KL_dist: 2.1676, 1.2628, 1.8572, param: [ 8.99894238  5.79538151 16.10389659  6.53397173], weights: [0.40790014 0.23704998 0.35504987], train_wt_loss:  44.3843, val_wt_loss: 44.5032, train_grp_loss: [20.15026814  8.82313925 15.83141384], val_grp_loss: [18.31462417  8.99841563 17.04490649], train_hist_grp_loss: [83.10536123 28.83022291 69.22894852], cur_train_grp_loss: [0.20153143 0.08316934 0.16843953], max_reward_err:  0.0900, max_reward_err_index: 0, max_kl_dist:  2.1676, max_kl_dist_index: 0, max_train_grp_loss:  20.1503, max_train_grp_loss_index: 0, max_val_grp_loss:  18.3146, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2015, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:44:29,202 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  500, train_loss:  14.9059, val_loss:  14.9277, grad_norm: 0.0825, live_grad: 0.0000, reward_err: 0.0897, 0.0048, 0.0540, KL_dist: 2.1671, 1.2925, 1.8664, param: [ 8.90429061  6.15329816 16.14037477  6.92403239], weights: [0.42349382 0.21972826 0.35677792], train_wt_loss:  44.7176, val_wt_loss: 44.7832, train_grp_loss: [19.86549485  9.57254032 15.64385887], val_grp_loss: [18.07666048  9.74194062 16.83934101], train_hist_grp_loss: [103.11413064  37.49939895  85.97158972], cur_train_grp_loss: [0.19868306 0.09023376 0.16644364], max_reward_err:  0.0897, max_reward_err_index: 0, max_kl_dist:  2.1671, max_kl_dist_index: 0, max_train_grp_loss:  19.8655, max_train_grp_loss_index: 0, max_val_grp_loss:  18.0767, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.1987, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:44:33,529 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  600, train_loss:  15.0391, val_loss:  15.0429, grad_norm: 0.0995, live_grad: 0.0000, reward_err: 0.0877, 0.0061, 0.0522, KL_dist: 2.1663, 1.3242, 1.8751, param: [ 8.81977327  6.50258336 16.16140293  7.3051335 ], weights: [0.43782524 0.20487252 0.35730224], train_wt_loss:  45.1172, val_wt_loss: 45.1286, train_grp_loss: [19.59007451 10.36871106 15.46414981], val_grp_loss: [17.84547533 10.53846922 16.64051403], train_hist_grp_loss: [122.84227569  46.89908716 102.51849582], cur_train_grp_loss: [0.19592764 0.09774143 0.16453081], max_reward_err:  0.0877, max_reward_err_index: 0, max_kl_dist:  2.1663, max_kl_dist_index: 0, max_train_grp_loss:  19.5901, max_train_grp_loss_index: 0, max_val_grp_loss:  17.8455, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.1959, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:44:37,860 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  700, train_loss:  15.1890, val_loss:  15.1752, grad_norm: 0.1154, live_grad: 0.0000, reward_err: 0.0822, 0.0083, 0.0477, KL_dist: 2.1653, 1.3570, 1.8833, param: [ 8.74412345  6.8357706  16.16936753  7.66905541], weights: [0.45094157 0.19227882 0.35677961], train_wt_loss:  45.5671, val_wt_loss: 45.5256, train_grp_loss: [19.32941204 11.18827759 15.29583777], val_grp_loss: [17.62614206 11.36404512 16.45280178], train_hist_grp_loss: [142.30189113  57.06276134 118.87993812], cur_train_grp_loss: [0.1933193  0.10547216 0.16273888], max_reward_err:  0.0822, max_reward_err_index: 0, max_kl_dist:  2.1653, max_kl_dist_index: 0, max_train_grp_loss:  19.3294, max_train_grp_loss_index: 0, max_val_grp_loss:  17.6261, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.1933, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:44:42,215 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  800, train_loss:  15.3491, val_loss:  15.3187, grad_norm: 0.1298, live_grad: 0.0000, reward_err: 0.0789, 0.0114, 0.0452, KL_dist: 2.1641, 1.3896, 1.8910, param: [ 8.67604548  7.14653823 16.16670379  8.00880297], weights: [0.4629174  0.18171794 0.35536466], train_wt_loss:  46.0474, val_wt_loss: 45.9562, train_grp_loss: [19.08789689 12.00595143 15.14171843], val_grp_loss: [17.42279854 12.19236341 16.27972122], train_hist_grp_loss: [161.51000851  68.00071471 135.0695911 ], cur_train_grp_loss: [0.19090206 0.11318741 0.16109769], max_reward_err:  0.0789, max_reward_err_index: 0, max_kl_dist:  2.1641, max_kl_dist_index: 0, max_train_grp_loss:  19.0879, max_train_grp_loss_index: 0, max_val_grp_loss:  17.4228, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.1909, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:44:46,593 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  900, train_loss:  15.5125, val_loss:  15.4670, grad_norm: 0.1426, live_grad: 0.0000, reward_err: 0.0785, 0.0134, 0.0449, KL_dist: 2.1629, 1.4210, 1.8979, param: [ 8.61430477  7.43020632 16.1557213   8.31916136], weights: [0.47384602 0.17295043 0.35320354], train_wt_loss:  46.5374, val_wt_loss: 46.4009, train_grp_loss: [18.86858671 12.79754859 15.00364088], val_grp_loss: [17.23835666 12.99796779 16.12369049], train_hist_grp_loss: [180.48740727  79.69966818 151.1036153 ], cur_train_grp_loss: [0.18870663 0.1206588  0.15962701], max_reward_err:  0.0785, max_reward_err_index: 0, max_kl_dist:  2.1629, max_kl_dist_index: 0, max_train_grp_loss:  18.8686, max_train_grp_loss_index: 0, max_val_grp_loss:  17.2384, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.1887, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:44:50,969 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  1000, train_loss:  15.6726, val_loss:  15.6137, grad_norm: 0.1536, live_grad: 0.0000, reward_err: 0.0776, 0.0147, 0.0441, KL_dist: 2.1615, 1.4503, 1.9039, param: [ 8.55779104  7.68396322 16.13847954  8.59695768], weights: [0.48383121 0.1657391  0.3504297 ], train_wt_loss:  47.0178, val_wt_loss: 46.8412, train_grp_loss: [18.67310489 13.54260097 14.88246527], val_grp_loss: [17.07441075 13.75906093 15.98596566], train_hist_grp_loss: [199.25721414  92.12508903 166.99961492], cur_train_grp_loss: [0.1867494  0.12769279 0.15833609], max_reward_err:  0.0776, max_reward_err_index: 0, max_kl_dist:  2.1615, max_kl_dist_index: 0, max_train_grp_loss:  18.6731, max_train_grp_loss_index: 0, max_val_grp_loss:  17.0744, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.1867, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:44:55,317 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  1100, train_loss:  15.8243, val_loss:  15.7539, grad_norm: 0.1626, live_grad: 0.0000, reward_err: 0.0760, 0.0159, 0.0431, KL_dist: 2.1598, 1.4768, 1.9088, param: [ 8.50555239  7.90681811 16.1167196   8.84102072], weights: [0.49298003 0.15985854 0.34716143], train_wt_loss:  47.4728, val_wt_loss: 47.2618, train_grp_loss: [18.50173665 14.22603334 14.77815278], val_grp_loss: [16.93132882 14.45935176 15.86673571], train_hist_grp_loss: [217.84350188 105.22556533 182.77562311], cur_train_grp_loss: [0.18503333 0.13414659 0.15722462], max_reward_err:  0.0760, max_reward_err_index: 0, max_kl_dist:  2.1598, max_kl_dist_index: 0, max_train_grp_loss:  18.5017, max_train_grp_loss_index: 0, max_val_grp_loss:  16.9313, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.1850, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:44:59,677 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  1200, train_loss:  15.9638, val_loss:  15.8838, grad_norm: 0.1699, live_grad: 0.0000, reward_err: 0.0750, 0.0170, 0.0424, KL_dist: 2.1577, 1.5001, 1.9127, param: [ 8.45680375  8.09934093 16.09184617  9.05190386], weights: [0.50139724 0.15510162 0.34350114], train_wt_loss:  47.8913, val_wt_loss: 47.6513, train_grp_loss: [18.35366602 14.83872921 14.68994429], val_grp_loss: [16.80847126 15.0887327  15.76532475], train_hist_grp_loss: [236.27005974 118.93824316 198.4492341 ], cur_train_grp_loss: [0.18355036 0.13993366 0.15628458], max_reward_err:  0.0750, max_reward_err_index: 0, max_kl_dist:  2.1577, max_kl_dist_index: 0, max_train_grp_loss:  18.3537, max_train_grp_loss_index: 0, max_val_grp_loss:  16.8085, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.1836, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:45:04,035 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  1300, train_loss:  16.0889, val_loss:  16.0010, grad_norm: 0.1756, live_grad: 0.0000, reward_err: 0.0735, 0.0181, 0.0412, KL_dist: 2.1553, 1.5201, 1.9155, param: [ 8.41091651  8.26328313 16.06494674  9.23147303], weights: [0.50918122 0.15128309 0.33953569], train_wt_loss:  48.2666, val_wt_loss: 48.0031, train_grp_loss: [18.22727996 15.37713708 14.6165763 ], val_grp_loss: [16.70446923 15.64293202 15.68044127], train_hist_grp_loss: [254.55944015 133.19432772 214.03694946], cur_train_grp_loss: [0.18228443 0.14502001 0.15550257], max_reward_err:  0.0735, max_reward_err_index: 0, max_kl_dist:  2.1553, max_kl_dist_index: 0, max_train_grp_loss:  18.2273, max_train_grp_loss_index: 0, max_val_grp_loss:  16.7045, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.1823, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:45:08,418 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  1400, train_loss:  16.1988, val_loss:  16.1047, grad_norm: 0.1798, live_grad: 0.0000, reward_err: 0.0730, 0.0196, 0.0409, KL_dist: 2.1525, 1.5369, 1.9173, param: [ 8.36739759  8.40117066 16.03683268  9.38246053], weights: [0.51642149 0.14824096 0.33533756], train_wt_loss:  48.5964, val_wt_loss: 48.3140, train_grp_loss: [18.12047446 15.84225535 14.55649109], val_grp_loss: [16.61750335 16.12249175 15.61042312], train_hist_grp_loss: [272.73231522 147.92389323 229.55375424], cur_train_grp_loss: [0.18121453 0.14941467 0.15486204], max_reward_err:  0.0730, max_reward_err_index: 0, max_kl_dist:  2.1525, max_kl_dist_index: 0, max_train_grp_loss:  18.1205, max_train_grp_loss_index: 0, max_val_grp_loss:  16.6175, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.1812, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:45:12,892 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  1500, train_loss:  16.2937, val_loss:  16.1947, grad_norm: 0.1827, live_grad: 0.0000, reward_err: 0.0726, 0.0196, 0.0407, KL_dist: 2.1492, 1.5507, 1.9180, param: [ 8.32586471  8.51593596 16.00808928  9.50805922], weights: [0.52319748 0.14583614 0.33096637], train_wt_loss:  48.8811, val_wt_loss: 48.5841, train_grp_loss: [18.03091935 16.23836138 14.50801346], val_grp_loss: [16.54554359 16.53145663 15.55344542], train_hist_grp_loss: [290.80712147 163.05958904 245.01290069], cur_train_grp_loss: [0.18031737 0.15315776 0.15434517], max_reward_err:  0.0726, max_reward_err_index: 0, max_kl_dist:  2.1492, max_kl_dist_index: 0, max_train_grp_loss:  18.0309, max_train_grp_loss_index: 0, max_val_grp_loss:  16.5455, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.1803, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:45:17,284 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  1600, train_loss:  16.3746, val_loss:  16.2719, grad_norm: 0.1845, live_grad: 0.0000, reward_err: 0.0724, 0.0207, 0.0407, KL_dist: 2.1456, 1.5617, 1.9179, param: [ 8.28602241  8.61062486 15.97912539  9.61159783], weights: [0.52957829 0.14395101 0.3264707 ], train_wt_loss:  49.1237, val_wt_loss: 48.8157, train_grp_loss: [17.9562611  16.57177052 14.46948288], val_grp_loss: [16.48653257 16.87607937 15.5076773 ], train_hist_grp_loss: [308.7999395  178.53914274 260.42585703], cur_train_grp_loss: [0.17956941 0.15630871 0.1539343 ], max_reward_err:  0.0724, max_reward_err_index: 0, max_kl_dist:  2.1456, max_kl_dist_index: 0, max_train_grp_loss:  17.9563, max_train_grp_loss_index: 0, max_val_grp_loss:  16.8761, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.1796, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:45:21,652 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  1700, train_loss:  16.4427, val_loss:  16.3374, grad_norm: 0.1853, live_grad: 0.0000, reward_err: 0.0724, 0.0211, 0.0407, KL_dist: 2.1417, 1.5704, 1.9170, param: [ 8.24764152  8.68818827 15.95021749  9.69630905], weights: [0.53562302 0.14248731 0.32188968], train_wt_loss:  49.3280, val_wt_loss: 49.0122, train_grp_loss: [17.89426159 16.84979384 14.43934103], val_grp_loss: [16.43851064 17.16372468 15.47138722], train_hist_grp_loss: [326.72454448 194.30677673 275.8023728 ], cur_train_grp_loss: [0.17894826 0.15893644 0.15361283], max_reward_err:  0.0724, max_reward_err_index: 0, max_kl_dist:  2.1417, max_kl_dist_index: 0, max_train_grp_loss:  17.8943, max_train_grp_loss_index: 0, max_val_grp_loss:  17.1637, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.1789, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:45:26,061 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  1800, train_loss:  16.4996, val_loss:  16.3926, grad_norm: 0.1855, live_grad: 0.0000, reward_err: 0.0710, 0.0211, 0.0396, KL_dist: 2.1375, 1.5770, 1.9155, param: [ 8.2105426   8.75135131 15.92154595  9.7651831 ], weights: [0.54138158 0.14136374 0.31725468], train_wt_loss:  49.4988, val_wt_loss: 49.1777, train_grp_loss: [17.8428809  17.07995875 14.41618186], val_grp_loss: [16.39969049 17.40204422 15.44300435], train_hist_grp_loss: [344.59256668 210.31376239 291.15061691], cur_train_grp_loss: [0.17843348 0.16111198 0.15336578], max_reward_err:  0.0710, max_reward_err_index: 0, max_kl_dist:  2.1375, max_kl_dist_index: 0, max_train_grp_loss:  17.8429, max_train_grp_loss_index: 0, max_val_grp_loss:  17.4020, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.1784, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:45:30,463 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  1900, train_loss:  16.5469, val_loss:  16.4388, grad_norm: 0.1850, live_grad: 0.0000, reward_err: 0.0710, 0.0216, 0.0396, KL_dist: 2.1331, 1.5820, 1.9135, param: [ 8.17458337  8.80254439 15.89322334  9.82088995], weights: [0.5468957  0.14051364 0.31259065], train_wt_loss:  49.6408, val_wt_loss: 49.3165, train_grp_loss: [17.80031696 17.26948638 14.39877315], val_grp_loss: [16.36849297 17.59841912 15.42114675], train_hist_grp_loss: [362.4137123  226.5183613  306.47735312], cur_train_grp_loss: [0.17800704 0.16290349 0.15318003], max_reward_err:  0.0710, max_reward_err_index: 0, max_kl_dist:  2.1331, max_kl_dist_index: 0, max_train_grp_loss:  17.8003, max_train_grp_loss_index: 0, max_val_grp_loss:  17.5984, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.1780, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:45:34,801 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  1999, train_loss:  16.5858, val_loss:  16.4772, grad_norm: 0.1841,  live_grad: 0.0000, reward_err: 0.0705, 0.0216, 0.0392, KL_dist: 2.1286, 1.5854, 1.9110, param: [ 8.13999401  8.84350867 15.86559256  9.86534977], weights: [0.55214787 0.13988804 0.30796409], train_wt_loss:  49.7573, val_wt_loss: 49.4315, train_grp_loss: [17.7653365 17.4235766 14.3861657], val_grp_loss: [16.34377814 17.75816859 15.40476863], train_hist_grp_loss: [380.01835466 242.72100413 321.63508313], cur_train_grp_loss: [0.17765659 0.16436007 0.15304546], max_reward_err:  0.0705, max_reward_err_index: 0, max_kl_dist:  2.1286, max_kl_dist_index: 0, max_train_grp_loss:  17.7653, max_train_grp_loss_index: 0, max_val_grp_loss:  17.7582, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.1777, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:45:35,038 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:386] - INFO: Policy parameter learned solely on the preference data rdpo: [ 8.13999401  8.84350867 15.86559256  9.86534977].
2024-09-17 15:45:35,359 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:397] - INFO: Uniform reward: 3.8165, 3.8165, 3.1738
2024-09-17 15:45:35,360 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Optimal reward: 3.8573, 3.8573, 3.3040
2024-09-17 15:45:35,360 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Policy reward: 3.5852, 3.7742, 3.1745
2024-09-17 15:45:35,361 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Reward Error: 0.0705, 0.0216, 0.0392
2024-09-17 15:45:36,092 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:415] - INFO: Optimal reward: 3.8573, 3.8573, 3.3040
Known param reward: [[3.8573076725006104, 3.4820022583007812, 3.2755494117736816], [3.4820022583007812, 3.8573076725006104, 3.1173529624938965], [3.8217499256134033, 3.595449686050415, 3.3040339946746826]], Known param reward error: [[0.0, 0.09729724617910154, 0.008621153095552695], [0.09729724617910154, 0.0, 0.05650094172204995], [0.00921828122260097, 0.06788620682685609, 0.0]].
