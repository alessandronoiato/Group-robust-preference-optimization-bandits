2024-09-17 15:40:35,934 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:198] - INFO: Logging to log_rdpo/2024_09_17_15_40_31/swapped_noise1.0_[1,1,1]_2021
2024-09-17 15:40:35,936 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: (IB) Seed: 2021
2024-09-17 15:40:35,937 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Data: 300
2024-09-17 15:40:36,108 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:296] - INFO: MLE reward loss: 0.3558, l2 distance: 33.1024, acc: 0.82.
2024-09-17 15:40:36,109 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-17 15:40:36,110 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: MLE reward parameter: [13.32826759  7.48737825 15.0322688   7.4309059 ]
2024-09-17 15:40:36,317 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:313] - INFO: Learned oracle reward: 3.5551, 3.8681, 3.1638
2024-09-17 15:40:36,714 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-17 15:40:37,894 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  14.3009, val_loss:  14.4608, grad_norm: 0.2866, live_grad: 0.0000, reward_err: 0.1118, 0.0000, 0.0691, KL_dist: 2.0333, 1.1488, 1.6849, param: [10.69321849  4.39232939 14.49580063  4.53334665], weights: [0.33340829 0.33316708 0.33342462], train_wt_loss:  42.9028, val_wt_loss: 43.3824, train_grp_loss: [21.04235733  5.76136524 16.64313617], val_grp_loss: [20.0543748   5.60316741 17.86590837], train_hist_grp_loss: [0.22994676 0.15757396 0.23484498], cur_train_grp_loss: [0.22994676 0.15757396 0.23484498], max_reward_err:  0.1118, max_reward_err_index: 0, max_kl_dist:  2.0333, max_kl_dist_index: 0, max_train_grp_loss:  21.0424, max_train_grp_loss_index: 0, max_val_grp_loss:  20.0544, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2348, max_cur_train_grp_loss_index: 2, 
2024-09-17 15:40:42,356 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  100, train_loss:  14.3101, val_loss:  14.4340, grad_norm: 0.0141, live_grad: 0.0000, reward_err: 0.1105, 0.0003, 0.0680, KL_dist: 2.0274, 1.1636, 1.6857, param: [10.69217236  4.70457978 14.53272557  4.83886277], weights: [0.35421477 0.30379205 0.34199317], train_wt_loss:  42.9302, val_wt_loss: 43.3019, train_grp_loss: [20.83978929  6.14133523 16.46530034], val_grp_loss: [19.83994853  5.92087586 17.67531952], train_hist_grp_loss: [21.17343587  5.81743524 17.66217032], cur_train_grp_loss: [0.20841897 0.05844892 0.17333819], max_reward_err:  0.1105, max_reward_err_index: 0, max_kl_dist:  2.0274, max_kl_dist_index: 0, max_train_grp_loss:  20.8398, max_train_grp_loss_index: 0, max_val_grp_loss:  19.8399, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2084, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:40:46,814 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  200, train_loss:  14.3402, val_loss:  14.4226, grad_norm: 0.0299, live_grad: 0.0000, reward_err: 0.1060, 0.0006, 0.0641, KL_dist: 2.0208, 1.1814, 1.6863, param: [10.70154876  5.04116794 14.5563767   5.16788255], weights: [0.37412336 0.27707803 0.34879861], train_wt_loss:  43.0206, val_wt_loss: 43.2677, train_grp_loss: [20.62158809  6.60441515 16.27826028], val_grp_loss: [19.61047327  6.31275773 17.4706958 ], train_hist_grp_loss: [41.9064052  11.87776299 34.89731578], cur_train_grp_loss: [0.20623838 0.06285097 0.17137019], max_reward_err:  0.1060, max_reward_err_index: 0, max_kl_dist:  2.0208, max_kl_dist_index: 0, max_train_grp_loss:  20.6216, max_train_grp_loss_index: 0, max_val_grp_loss:  19.6105, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2062, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:40:51,242 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  300, train_loss:  14.3950, val_loss:  14.4305, grad_norm: 0.0470, live_grad: 0.0000, reward_err: 0.1049, 0.0012, 0.0631, KL_dist: 2.0139, 1.2026, 1.6872, param: [10.71980421  5.39804771 14.56722117  5.51620095], weights: [0.39299623 0.25311883 0.35388495], train_wt_loss:  43.1850, val_wt_loss: 43.2916, train_grp_loss: [20.39088012  7.15594332 16.08458969], val_grp_loss: [19.36917208  6.78424862 17.25517712], train_hist_grp_loss: [62.41467536 18.42057983 51.93185957], cur_train_grp_loss: [0.20393236 0.0680951  0.16933209], max_reward_err:  0.1049, max_reward_err_index: 0, max_kl_dist:  2.0139, max_kl_dist_index: 0, max_train_grp_loss:  20.3909, max_train_grp_loss_index: 0, max_val_grp_loss:  19.3692, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2039, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:40:55,676 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  400, train_loss:  14.4769, val_loss:  14.4609, grad_norm: 0.0650, live_grad: 0.0000, reward_err: 0.1002, 0.0021, 0.0589, KL_dist: 2.0070, 1.2270, 1.6886, param: [10.74515883  5.76945087 14.56597566  5.87794298], weights: [0.41074025 0.23191934 0.3573404 ], train_wt_loss:  43.4308, val_wt_loss: 43.3827, train_grp_loss: [20.15186046  7.79586958 15.88765887], val_grp_loss: [19.1203489   7.33597411 17.03286763], train_hist_grp_loss: [82.68773376 25.53059628 68.76051434], cur_train_grp_loss: [0.20154276 0.07418142 0.16725928], max_reward_err:  0.1002, max_reward_err_index: 0, max_kl_dist:  2.0070, max_kl_dist_index: 0, max_train_grp_loss:  20.1519, max_train_grp_loss_index: 0, max_val_grp_loss:  19.1203, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2015, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:41:00,107 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  500, train_loss:  14.5865, val_loss:  14.5150, grad_norm: 0.0833, live_grad: 0.0000, reward_err: 0.0958, 0.0026, 0.0552, KL_dist: 2.0006, 1.2545, 1.6907, param: [10.77571796  6.14811131 14.55355098  6.24580803], weights: [0.42730634 0.21340616 0.3592875 ], train_wt_loss:  43.7595, val_wt_loss: 43.5451, train_grp_loss: [19.90956917  8.51722842 15.69144746], val_grp_loss: [18.8691568   7.96229898 16.80860334], train_hist_grp_loss: [102.719707    33.28930707  85.38188053], cur_train_grp_loss: [0.1991199  0.08104432 0.1651936 ], max_reward_err:  0.0958, max_reward_err_index: 0, max_kl_dist:  2.0006, max_kl_dist_index: 0, max_train_grp_loss:  19.9096, max_train_grp_loss_index: 0, max_val_grp_loss:  18.8692, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.1991, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:41:04,547 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  600, train_loss:  14.7218, val_loss:  14.5923, grad_norm: 0.1014, live_grad: 0.0000, reward_err: 0.0924, 0.0035, 0.0523, KL_dist: 1.9950, 1.2845, 1.6937, param: [10.80960078  6.52576667 14.53099562  6.61158287], weights: [0.44268614 0.19744125 0.35987261], train_wt_loss:  44.1655, val_wt_loss: 43.7768, train_grp_loss: [19.66950337  9.30554342 15.5002262 ], val_grp_loss: [18.62119686  8.65071164 16.5875724 ], train_hist_grp_loss: [122.51002621  41.76802989 101.79893201], cur_train_grp_loss: [0.19671875 0.08854661 0.16318   ], max_reward_err:  0.0924, max_reward_err_index: 0, max_kl_dist:  1.9950, max_kl_dist_index: 0, max_train_grp_loss:  19.6695, max_train_grp_loss_index: 0, max_val_grp_loss:  18.6212, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.1967, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:41:09,005 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  700, train_loss:  14.8786, val_loss:  14.6898, grad_norm: 0.1186, live_grad: 0.0000, reward_err: 0.0876, 0.0055, 0.0484, KL_dist: 1.9902, 1.3161, 1.6973, param: [10.84506408  6.89388723 14.49944121  6.96686932], weights: [0.45690677 0.18383762 0.3592556 ], train_wt_loss:  44.6359, val_wt_loss: 44.0695, train_grp_loss: [19.43711629 10.13958504 15.31815365], val_grp_loss: [18.38200235  9.38244367 16.37484059], train_hist_grp_loss: [142.0636421   51.02099319 118.01911685], cur_train_grp_loss: [0.19439385 0.09648667 0.16126228], max_reward_err:  0.0876, max_reward_err_index: 0, max_kl_dist:  1.9902, max_kl_dist_index: 0, max_train_grp_loss:  19.4371, max_train_grp_loss_index: 0, max_val_grp_loss:  18.3820, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.1944, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:41:13,437 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  800, train_loss:  15.0506, val_loss:  14.8030, grad_norm: 0.1345, live_grad: 0.0000, reward_err: 0.0838, 0.0070, 0.0452, KL_dist: 1.9862, 1.3482, 1.7015, param: [10.88060643  7.24450349 14.4600527   7.30389711], weights: [0.47002398 0.17237541 0.35760061], train_wt_loss:  45.1519, val_wt_loss: 44.4089, train_grp_loss: [19.21729695 10.99353053 15.14886626], val_grp_loss: [18.15650601 10.13438538 16.17487172], train_hist_grp_loss: [161.39072059  61.07982187 134.05402222], cur_train_grp_loss: [0.19219419 0.10461888 0.1594788 ], max_reward_err:  0.0838, max_reward_err_index: 0, max_kl_dist:  1.9862, max_kl_dist_index: 0, max_train_grp_loss:  19.2173, max_train_grp_loss_index: 0, max_val_grp_loss:  18.1565, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.1922, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:41:17,942 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  900, train_loss:  15.2305, val_loss:  14.9258, grad_norm: 0.1488, live_grad: 0.0000, reward_err: 0.0812, 0.0097, 0.0430, KL_dist: 1.9828, 1.3798, 1.7058, param: [10.91503914  7.57096085 14.4139853   7.61625353], weights: [0.48211454 0.16281736 0.3550681 ], train_wt_loss:  45.6914, val_wt_loss: 44.7775, train_grp_loss: [19.01393752 11.84009815 14.99514856], val_grp_loss: [17.94860102 10.88191857 15.99114173], train_hist_grp_loss: [180.50585306  71.9505907  149.91864259], cur_train_grp_loss: [0.1901588  0.11268339 0.15785897], max_reward_err:  0.0812, max_reward_err_index: 0, max_kl_dist:  1.9828, max_kl_dist_index: 0, max_train_grp_loss:  19.0139, max_train_grp_loss_index: 0, max_val_grp_loss:  17.9486, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.1902, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:41:22,469 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  1000, train_loss:  15.4107, val_loss:  15.0522, grad_norm: 0.1611, live_grad: 0.0000, reward_err: 0.0789, 0.0109, 0.0413, KL_dist: 1.9797, 1.4099, 1.7100, param: [10.94751563  7.86844636 14.36234935  7.89938043], weights: [0.49326855 0.15492248 0.35180897], train_wt_loss:  46.2321, val_wt_loss: 45.1567, train_grp_loss: [18.829672   12.65388094 14.85874748], val_grp_loss: [17.76088047 11.60196216 15.82591947], train_hist_grp_loss: [199.42691358  83.61402475 165.63037186], cur_train_grp_loss: [0.18831415 0.12043789 0.15642129], max_reward_err:  0.0789, max_reward_err_index: 0, max_kl_dist:  1.9797, max_kl_dist_index: 0, max_train_grp_loss:  18.8297, max_train_grp_loss_index: 0, max_val_grp_loss:  17.7609, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.1883, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:41:27,030 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  1100, train_loss:  15.5846, val_loss:  15.1765, grad_norm: 0.1714, live_grad: 0.0000, reward_err: 0.0763, 0.0120, 0.0390, KL_dist: 1.9768, 1.4377, 1.7136, param: [10.97751944  8.13420275 14.30618325  8.15076058], weights: [0.50358244 0.14845714 0.34796042], train_wt_loss:  46.7539, val_wt_loss: 45.5294, train_grp_loss: [18.66581793 13.41407147 14.74035121], val_grp_loss: [17.59458614 12.27548619 15.68023794], train_hist_grp_loss: [218.17375525  96.02864461 181.20788616], cur_train_grp_loss: [0.18667354 0.1276837  0.15517312], max_reward_err:  0.0763, max_reward_err_index: 0, max_kl_dist:  1.9768, max_kl_dist_index: 0, max_train_grp_loss:  18.6658, max_train_grp_loss_index: 0, max_val_grp_loss:  17.5946, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.1867, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:41:31,450 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  1200, train_loss:  15.7472, val_loss:  15.2940, grad_norm: 0.1796, live_grad: 0.0000, reward_err: 0.0756, 0.0144, 0.0384, KL_dist: 1.9737, 1.4626, 1.7164, param: [11.00481982  8.36743649 14.24643429  8.36980522], weights: [0.51315304 0.14320321 0.34364375], train_wt_loss:  47.2416, val_wt_loss: 45.8820, train_grp_loss: [18.52249757 14.10604674 14.63970891], val_grp_loss: [17.44974027 12.88899858 15.5540283 ], train_hist_grp_loss: [236.7669409  109.135995   196.67008139], cur_train_grp_loss: [0.18523831 0.13428092 0.1541119 ], max_reward_err:  0.0756, max_reward_err_index: 0, max_kl_dist:  1.9737, max_kl_dist_index: 0, max_train_grp_loss:  18.5225, max_train_grp_loss_index: 0, max_val_grp_loss:  17.4497, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.1852, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:41:35,865 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  1300, train_loss:  15.8949, val_loss:  15.4016, grad_norm: 0.1860, live_grad: 0.0000, reward_err: 0.0736, 0.0150, 0.0367, KL_dist: 1.9703, 1.4842, 1.7182, param: [11.02940835  8.56899895 14.18394686  8.557524  ], weights: [0.52207314 0.13896317 0.33896369], train_wt_loss:  47.6847, val_wt_loss: 46.2048, train_grp_loss: [18.39887795 14.72170339 14.55583906], val_grp_loss: [17.32539697 13.43489287 15.44635746], train_hist_grp_loss: [255.22665973 122.86678627 212.03518816], cur_train_grp_loss: [0.18400021 0.14015177 0.15322736], max_reward_err:  0.0736, max_reward_err_index: 0, max_kl_dist:  1.9703, max_kl_dist_index: 0, max_train_grp_loss:  18.3989, max_train_grp_loss_index: 0, max_val_grp_loss:  17.3254, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.1840, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:41:40,277 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  1400, train_loss:  16.0260, val_loss:  15.4975, grad_norm: 0.1907, live_grad: 0.0000, reward_err: 0.0713, 0.0160, 0.0350, KL_dist: 1.9665, 1.5027, 1.7190, param: [11.05143087  8.74095094 14.11945741  8.71608731], weights: [0.53042849 0.13556274 0.33400878], train_wt_loss:  48.0781, val_wt_loss: 46.4924, train_grp_loss: [18.29345922 15.25878773 14.48726918], val_grp_loss: [17.21994046 13.91087255 15.35570301], train_hist_grp_loss: [273.57191352 137.14685194 227.32012713], cur_train_grp_loss: [0.18294429 0.1452743  0.15250405], max_reward_err:  0.0713, max_reward_err_index: 0, max_kl_dist:  1.9665, max_kl_dist_index: 0, max_train_grp_loss:  18.2935, max_train_grp_loss_index: 0, max_val_grp_loss:  17.2199, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.1829, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:41:44,650 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  1500, train_loss:  16.1402, val_loss:  15.5810, grad_norm: 0.1938, live_grad: 0.0000, reward_err: 0.0698, 0.0167, 0.0337, KL_dist: 1.9622, 1.5180, 1.7188, param: [11.07112556  8.88611274 14.05359516  8.84838043], weights: [0.53829604 0.13285128 0.32885268], train_wt_loss:  48.4206, val_wt_loss: 46.7429, train_grp_loss: [18.20435292 15.71963669 14.43226098], val_grp_loss: [17.13137081 14.31882823 15.28021271], train_hist_grp_loss: [291.8199902  151.90215572 242.54011225], cur_train_grp_loss: [0.1820517  0.14967038 0.15192368], max_reward_err:  0.0698, max_reward_err_index: 0, max_kl_dist:  1.9622, max_kl_dist_index: 0, max_train_grp_loss:  18.2044, max_train_grp_loss_index: 0, max_val_grp_loss:  17.1314, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.1821, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:41:49,066 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  1600, train_loss:  16.2381, val_loss:  15.6523, grad_norm: 0.1957, live_grad: 0.0000, reward_err: 0.0684, 0.0178, 0.0327, KL_dist: 1.9574, 1.5305, 1.7176, param: [11.08877318  9.00766967 13.98688757  8.95761709], weights: [0.54574331 0.13070092 0.32355577], train_wt_loss:  48.7143, val_wt_loss: 46.9570, train_grp_loss: [18.12951404 16.10973605 14.38899385], val_grp_loss: [17.05754061 14.66353843 15.21791702], train_hist_grp_loss: [309.98619488 167.06248475 257.70847092], cur_train_grp_loss: [0.18130199 0.15339202 0.1514671 ], max_reward_err:  0.0684, max_reward_err_index: 0, max_kl_dist:  1.9574, max_kl_dist_index: 0, max_train_grp_loss:  18.1295, max_train_grp_loss_index: 0, max_val_grp_loss:  17.0575, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.1813, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:41:53,487 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  1700, train_loss:  16.3210, val_loss:  15.7124, grad_norm: 0.1965, live_grad: 0.0000, reward_err: 0.0675, 0.0188, 0.0320, KL_dist: 1.9522, 1.5405, 1.7156, param: [11.10466134  9.10886769 13.91976901  9.04704414], weights: [0.55282846 0.12900459 0.31816695], train_wt_loss:  48.9630, val_wt_loss: 47.1373, train_grp_loss: [18.06691249 16.4363882  14.35569734], val_grp_loss: [16.99632899 14.95146266 15.16688351], train_hist_grp_loss: [328.08378331 182.56380366 272.83663087], cur_train_grp_loss: [0.18067484 0.15650866 0.15111565], max_reward_err:  0.0675, max_reward_err_index: 0, max_kl_dist:  1.9522, max_kl_dist_index: 0, max_train_grp_loss:  18.0669, max_train_grp_loss_index: 0, max_val_grp_loss:  16.9963, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.1807, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:41:57,976 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  1800, train_loss:  16.3906, val_loss:  15.7624, grad_norm: 0.1964, live_grad: 0.0000, reward_err: 0.0661, 0.0191, 0.0308, KL_dist: 1.9467, 1.5482, 1.7128, param: [11.11906178  9.19280459 13.85259141  9.1197414 ], weights: [0.55960085 0.12767372 0.31272543], train_wt_loss:  49.1719, val_wt_loss: 47.2872, train_grp_loss: [18.01464546 16.70764318 14.33073509], val_grp_loss: [16.94575467 15.18976924 15.12531589], train_hist_grp_loss: [346.12403704 198.34945691 287.93422058], cur_train_grp_loss: [0.18015123 0.15909693 0.15085209], max_reward_err:  0.0661, max_reward_err_index: 0, max_kl_dist:  1.9467, max_kl_dist_index: 0, max_train_grp_loss:  18.0146, max_train_grp_loss_index: 0, max_val_grp_loss:  16.9458, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.1802, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:42:02,491 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  1900, train_loss:  16.4487, val_loss:  15.8036, grad_norm: 0.1956, live_grad: 0.0000, reward_err: 0.0658, 0.0194, 0.0305, KL_dist: 1.9408, 1.5541, 1.7094, param: [11.1322178   9.26230502 13.78563558  9.17850388], weights: [0.56610186 0.12663573 0.30726241], train_wt_loss:  49.3461, val_wt_loss: 47.4108, train_grp_loss: [17.97100042 16.93153493 14.31264941], val_grp_loss: [16.90403866 15.38563826 15.09160761], train_hist_grp_loss: [364.11642548 214.37049695 303.0092367 ], cur_train_grp_loss: [0.17971399 0.16123338 0.15066106], max_reward_err:  0.0658, max_reward_err_index: 0, max_kl_dist:  1.9408, max_kl_dist_index: 0, max_train_grp_loss:  17.9710, max_train_grp_loss_index: 0, max_val_grp_loss:  16.9040, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.1797, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:42:06,998 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  1999, train_loss:  16.4966, val_loss:  15.8370, grad_norm: 0.1942,  live_grad: 0.0000, reward_err: 0.0652, 0.0203, 0.0300, KL_dist: 1.9348, 1.5585, 1.7055, param: [11.14422253  9.31933666 13.71978481  9.22536417], weights: [0.57230434 0.12583866 0.301857  ], train_wt_loss:  49.4897, val_wt_loss: 47.5109, train_grp_loss: [17.93481577 17.11392963 14.30027757], val_grp_loss: [16.86994209 15.54437108 15.06460687], train_hist_grp_loss: [381.88946358 230.42243021 317.91771307], cur_train_grp_loss: [0.17935151 0.1629739  0.1505303 ], max_reward_err:  0.0652, max_reward_err_index: 0, max_kl_dist:  1.9348, max_kl_dist_index: 0, max_train_grp_loss:  17.9348, max_train_grp_loss_index: 0, max_val_grp_loss:  16.8699, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.1794, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:42:07,230 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:386] - INFO: Policy parameter learned solely on the preference data rdpo: [11.14422253  9.31933666 13.71978481  9.22536417].
2024-09-17 15:42:07,572 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:397] - INFO: Uniform reward: 3.8482, 3.8482, 3.1986
2024-09-17 15:42:07,573 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Optimal reward: 3.8836, 3.8836, 3.3119
2024-09-17 15:42:07,574 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Policy reward: 3.6303, 3.8046, 3.2124
2024-09-17 15:42:07,574 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Reward Error: 0.0652, 0.0203, 0.0300
2024-09-17 15:42:08,316 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:415] - INFO: Optimal reward: 3.8836, 3.8836, 3.3119
Known param reward: [[3.8835737705230713, 3.457217216491699, 3.288090705871582], [3.457217216491699, 3.8835737705230713, 3.0940170288085938], [3.8489270210266113, 3.5929198265075684, 3.3118627071380615]], Known param reward error: [[0.0, 0.10978458997418425, 0.007177834158174392], [0.10978458997418425, 0.0, 0.06577738801187161], [0.00892135737434272, 0.07484187534214273, 0.0]].
