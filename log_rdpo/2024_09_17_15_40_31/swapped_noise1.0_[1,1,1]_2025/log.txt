2024-09-17 15:47:33,862 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:198] - INFO: Logging to log_rdpo/2024_09_17_15_40_31/swapped_noise1.0_[1,1,1]_2025
2024-09-17 15:47:33,863 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: (IB) Seed: 2025
2024-09-17 15:47:33,864 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Data: 300
2024-09-17 15:47:34,026 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:296] - INFO: MLE reward loss: 0.3597, l2 distance: 31.6072, acc: 0.81.
2024-09-17 15:47:34,026 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-17 15:47:34,027 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: MLE reward parameter: [13.00274755  7.23429623 14.54687762  6.41459427]
2024-09-17 15:47:34,235 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:313] - INFO: Learned oracle reward: 3.5469, 3.8252, 3.1158
2024-09-17 15:47:34,483 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-17 15:47:35,664 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  14.4628, val_loss:  14.9123, grad_norm: 0.2942, live_grad: 0.0000, reward_err: 0.0920, 0.0002, 0.0530, KL_dist: 1.7846, 1.0584, 1.4618, param: [11.92582843  4.42489427 12.0261898   4.33152308], weights: [0.33346494 0.33311791 0.33341715], train_wt_loss:  43.3883, val_wt_loss: 44.7369, train_grp_loss: [19.64836894  6.04611199 19.17586793], val_grp_loss: [20.74167535  5.98271522 17.82542621], train_hist_grp_loss: [0.24945791 0.14533452 0.23512367], cur_train_grp_loss: [0.24945791 0.14533452 0.23512367], max_reward_err:  0.0920, max_reward_err_index: 0, max_kl_dist:  1.7846, max_kl_dist_index: 0, max_train_grp_loss:  19.6484, max_train_grp_loss_index: 0, max_val_grp_loss:  20.7417, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2495, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:47:40,100 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  100, train_loss:  14.4771, val_loss:  14.8753, grad_norm: 0.0181, live_grad: 0.0000, reward_err: 0.0863, 0.0007, 0.0480, KL_dist: 1.7750, 1.0748, 1.4611, param: [11.80498449  4.81013449 12.12360113  4.69740011], weights: [0.35220906 0.30120298 0.34658796], train_wt_loss:  43.4312, val_wt_loss: 44.6259, train_grp_loss: [19.37755346  6.57011453 18.87732144], val_grp_loss: [20.45955525  6.39198957 17.59859975], train_hist_grp_loss: [21.46202168  5.81796634 19.85319361], cur_train_grp_loss: [0.21065578 0.05913822 0.19464318], max_reward_err:  0.0863, max_reward_err_index: 0, max_kl_dist:  1.7750, max_kl_dist_index: 0, max_train_grp_loss:  19.3776, max_train_grp_loss_index: 0, max_val_grp_loss:  20.4596, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2107, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:47:44,465 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  200, train_loss:  14.5231, val_loss:  14.8630, grad_norm: 0.0386, live_grad: 0.0000, reward_err: 0.0831, 0.0015, 0.0453, KL_dist: 1.7675, 1.0964, 1.4631, param: [11.6927236   5.22007393 12.21041286  5.08585437], weights: [0.36948394 0.27273087 0.35778519], train_wt_loss:  43.5693, val_wt_loss: 44.5889, train_grp_loss: [19.09432103  7.20281366 18.56437442], val_grp_loss: [20.16333315  6.90109973 17.36213463], train_hist_grp_loss: [42.3730693  12.01088894 39.15562085], cur_train_grp_loss: [0.20757822 0.06482832 0.19141809], max_reward_err:  0.0831, max_reward_err_index: 0, max_kl_dist:  1.7675, max_kl_dist_index: 0, max_train_grp_loss:  19.0943, max_train_grp_loss_index: 0, max_val_grp_loss:  20.1633, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2076, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:47:48,776 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  300, train_loss:  14.6046, val_loss:  14.8794, grad_norm: 0.0609, live_grad: 0.0000, reward_err: 0.0793, 0.0033, 0.0421, KL_dist: 1.7626, 1.1234, 1.4680, param: [11.58972454  5.64658317 12.28640468  5.48930415], weights: [0.38523581 0.24773443 0.36702976], train_wt_loss:  43.8137, val_wt_loss: 44.6382, train_grp_loss: [18.80449979  7.94333245 18.24372679], val_grp_loss: [19.85922548  7.51110158 17.12092083], train_hist_grp_loss: [62.97213034 18.82230185 58.13086123], cur_train_grp_loss: [0.20442836 0.07149027 0.18811285], max_reward_err:  0.0793, max_reward_err_index: 0, max_kl_dist:  1.7626, max_kl_dist_index: 0, max_train_grp_loss:  18.8045, max_train_grp_loss_index: 0, max_val_grp_loss:  19.8592, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2044, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:47:53,074 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  400, train_loss:  14.7221, val_loss:  14.9264, grad_norm: 0.0841, live_grad: 0.0000, reward_err: 0.0761, 0.0047, 0.0394, KL_dist: 1.7603, 1.1555, 1.4757, param: [11.49630418  6.07963922 12.35182489  5.89843003], weights: [0.3994757  0.22611658 0.37440772], train_wt_loss:  44.1662, val_wt_loss: 44.7791, train_grp_loss: [18.51487731  8.78113102 17.923146  ], val_grp_loss: [19.55450784  8.21413461 16.88060118], train_hist_grp_loss: [83.25563372 26.34540845 76.77487674], cur_train_grp_loss: [0.20127988 0.07903001 0.18480747], max_reward_err:  0.0761, max_reward_err_index: 0, max_kl_dist:  1.7603, max_kl_dist_index: 0, max_train_grp_loss:  18.5149, max_train_grp_loss_index: 0, max_val_grp_loss:  19.5545, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2013, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:47:57,392 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  500, train_loss:  14.8728, val_loss:  15.0027, grad_norm: 0.1075, live_grad: 0.0000, reward_err: 0.0718, 0.0070, 0.0359, KL_dist: 1.7607, 1.1917, 1.4860, param: [11.41245754  6.50818857 12.40730075  6.30297452], weights: [0.41226738 0.20767815 0.38005447], train_wt_loss:  44.6184, val_wt_loss: 45.0082, train_grp_loss: [18.23256699  9.6955709  17.61072515], val_grp_loss: [19.25683227  8.99280822 16.64703938], train_hist_grp_loss: [103.2276266   34.6593699   95.09187478], cur_train_grp_loss: [0.19821012 0.0872625  0.18158539], max_reward_err:  0.0718, max_reward_err_index: 0, max_kl_dist:  1.7607, max_kl_dist_index: 0, max_train_grp_loss:  18.2326, max_train_grp_loss_index: 0, max_val_grp_loss:  19.2568, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.1982, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:48:01,711 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  600, train_loss:  15.0505, val_loss:  15.1043, grad_norm: 0.1302, live_grad: 0.0000, reward_err: 0.0704, 0.0087, 0.0349, KL_dist: 1.7635, 1.2306, 1.4983, param: [11.33790562  6.92128162 12.45373063  6.69279259], weights: [0.42371346 0.19214841 0.38413813], train_wt_loss:  45.1516, val_wt_loss: 45.3130, train_grp_loss: [17.96425978 10.65758985 17.31402481], val_grp_loss: [18.97342061  9.82156233 16.42570116], train_hist_grp_loss: [122.89972906  43.82079127 113.09420795], cur_train_grp_loss: [0.19529189 0.09592652 0.17852466], max_reward_err:  0.0704, max_reward_err_index: 0, max_kl_dist:  1.7635, max_kl_dist_index: 0, max_train_grp_loss:  17.9643, max_train_grp_loss_index: 0, max_val_grp_loss:  18.9734, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.1953, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:48:06,091 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  700, train_loss:  15.2465, val_loss:  15.2248, grad_norm: 0.1515, live_grad: 0.0000, reward_err: 0.0671, 0.0110, 0.0323, KL_dist: 1.7682, 1.2705, 1.5120, param: [11.27214773  7.30923671 12.49217298  7.0589284 ], weights: [0.43394162 0.17921449 0.38684389], train_wt_loss:  45.7394, val_wt_loss: 45.6744, train_grp_loss: [17.71552991 11.63330946 17.0392922 ], val_grp_loss: [18.7103146  10.66988578 16.22108904], train_hist_grp_loss: [142.29028861  53.85762202 130.80141155], cur_train_grp_loss: [0.19258593 0.1047171  0.17568984], max_reward_err:  0.0671, max_reward_err_index: 0, max_kl_dist:  1.7682, max_kl_dist_index: 0, max_train_grp_loss:  17.7155, max_train_grp_loss_index: 0, max_val_grp_loss:  18.7103, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.1926, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:48:10,443 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  800, train_loss:  15.4506, val_loss:  15.3564, grad_norm: 0.1708, live_grad: 0.0000, reward_err: 0.0643, 0.0125, 0.0301, KL_dist: 1.7741, 1.3097, 1.5262, param: [11.21451667  7.66456781 12.52374525  7.39447169], weights: [0.44309202 0.16854742 0.38836056], train_wt_loss:  46.3517, val_wt_loss: 46.0692, train_grp_loss: [17.49035122 12.58866109 16.79093231], val_grp_loss: [18.47185123 11.50657105 16.03635855], train_hist_grp_loss: [161.42288168  64.76685034 148.2385525 ], cur_train_grp_loss: [0.19013563 0.11332713 0.17312656], max_reward_err:  0.0643, max_reward_err_index: 0, max_kl_dist:  1.7741, max_kl_dist_index: 0, max_train_grp_loss:  17.4904, max_train_grp_loss_index: 0, max_val_grp_loss:  18.4719, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.1901, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:48:14,839 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  900, train_loss:  15.6533, val_loss:  15.4914, grad_norm: 0.1878, live_grad: 0.0000, reward_err: 0.0619, 0.0141, 0.0282, KL_dist: 1.7808, 1.3469, 1.5403, param: [11.16423503  7.98248845 12.54954225  7.69502064], weights: [0.45130695 0.15982296 0.38887008], train_wt_loss:  46.9599, val_wt_loss: 46.4742, train_grp_loss: [17.29090974 13.49375735 16.57132002], val_grp_loss: [18.26045541 12.30382024 15.8731818 ], train_hist_grp_loss: [180.32444522  76.51634678 165.43420418], cur_train_grp_loss: [0.18796493 0.12148681 0.17085949], max_reward_err:  0.0619, max_reward_err_index: 0, max_kl_dist:  1.7808, max_kl_dist_index: 0, max_train_grp_loss:  17.2909, max_train_grp_loss_index: 0, max_val_grp_loss:  18.2605, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.1880, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:48:19,178 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  1000, train_loss:  15.8465, val_loss:  15.6231, grad_norm: 0.2024, live_grad: 0.0000, reward_err: 0.0604, 0.0153, 0.0271, KL_dist: 1.7876, 1.3809, 1.5536, param: [11.12046919  8.26094593 12.57057834  7.95870948], weights: [0.4587231  0.15273651 0.38854038], train_wt_loss:  47.5396, val_wt_loss: 46.8694, train_grp_loss: [17.11770323 14.32594156 16.38093455], val_grp_loss: [18.07674117 13.04018302 15.73184623], train_hist_grp_loss: [199.0233639   89.05011746 182.41839784], cur_train_grp_loss: [0.18607943 0.1289913  0.16889377], max_reward_err:  0.0604, max_reward_err_index: 0, max_kl_dist:  1.7876, max_kl_dist_index: 0, max_train_grp_loss:  17.1177, max_train_grp_loss_index: 0, max_val_grp_loss:  18.0767, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.1861, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:48:23,550 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  1100, train_loss:  16.0244, val_loss:  15.7465, grad_norm: 0.2145, live_grad: 0.0000, reward_err: 0.0588, 0.0165, 0.0260, KL_dist: 1.7942, 1.4113, 1.5658, param: [11.08237742  8.50027303 12.58775337  8.18588239], weights: [0.4654664  0.14701244 0.38752116], train_wt_loss:  48.0733, val_wt_loss: 47.2395, train_grp_loss: [16.96984586 15.07104649 16.21871818], val_grp_loss: [17.91983401 13.70185407 15.61151731], train_hist_grp_loss: [217.54778525 102.29551537 199.22083743], cur_train_grp_loss: [0.18446961 0.13571218 0.16721863], max_reward_err:  0.0588, max_reward_err_index: 0, max_kl_dist:  1.7942, max_kl_dist_index: 0, max_train_grp_loss:  16.9698, max_train_grp_loss_index: 0, max_val_grp_loss:  17.9198, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.1845, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:48:27,938 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  1200, train_loss:  16.1835, val_loss:  15.8582, grad_norm: 0.2242, live_grad: 0.0000, reward_err: 0.0573, 0.0172, 0.0249, KL_dist: 1.8002, 1.4378, 1.5766, param: [11.04914868  8.70261731 12.60183856  8.37856255], weights: [0.47164918 0.14240861 0.38594221], train_wt_loss:  48.5504, val_wt_loss: 47.5746, train_grp_loss: [16.84546844 15.72302562 16.08253366], val_grp_loss: [17.78779727 14.28245066 15.5105739 ], train_hist_grp_loss: [235.9243273  116.1708286  215.86954524], cur_train_grp_loss: [0.18311526 0.14159432 0.16581212], max_reward_err:  0.0573, max_reward_err_index: 0, max_kl_dist:  1.8002, max_kl_dist_index: 0, max_train_grp_loss:  16.8455, max_train_grp_loss_index: 0, max_val_grp_loss:  17.7878, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.1831, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:48:32,379 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  1300, train_loss:  16.3223, val_loss:  15.9566, grad_norm: 0.2319, live_grad: 0.0000, reward_err: 0.0560, 0.0180, 0.0239, KL_dist: 1.8055, 1.4603, 1.5860, param: [11.02003053  8.87131073 12.6134771   8.53986713], weights: [0.47736912 0.13871727 0.38391361], train_wt_loss:  48.9669, val_wt_loss: 47.8698, train_grp_loss: [16.74211807 16.28250674 15.9696136 ], val_grp_loss: [17.67805934 14.7817634  15.42693797], train_hist_grp_loss: [254.17722818 130.59200795 232.38998252], cur_train_grp_loss: [0.18198974 0.14664284 0.16464575], max_reward_err:  0.0560, max_reward_err_index: 0, max_kl_dist:  1.8055, max_kl_dist_index: 0, max_train_grp_loss:  16.7421, max_train_grp_loss_index: 0, max_val_grp_loss:  17.6781, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.1820, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:48:36,758 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  1400, train_loss:  16.4410, val_loss:  16.0414, grad_norm: 0.2377, live_grad: 0.0000, reward_err: 0.0552, 0.0187, 0.0232, KL_dist: 1.8100, 1.4792, 1.5939, param: [10.99434622  9.01029911 12.62319408  8.67347841], weights: [0.48270942 0.13576349 0.38152709], train_wt_loss:  49.3231, val_wt_loss: 48.1241, train_grp_loss: [16.65709586 16.75489356 15.87693559], val_grp_loss: [17.58777567 15.20405634 15.35834991], train_hist_grp_loss: [272.3279007  145.47784602 248.80459939], cur_train_grp_loss: [0.18106374 0.15090608 0.16368837], max_reward_err:  0.0552, max_reward_err_index: 0, max_kl_dist:  1.8100, max_kl_dist_index: 0, max_train_grp_loss:  16.7549, max_train_grp_loss_index: 1, max_val_grp_loss:  17.5878, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.1811, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:48:41,155 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  1500, train_loss:  16.5410, val_loss:  16.1132, grad_norm: 0.2420, live_grad: 0.0000, reward_err: 0.0544, 0.0202, 0.0227, KL_dist: 1.8138, 1.4949, 1.6004, param: [10.97150232  9.12369393 12.63141106  8.78322872], weights: [0.48773987 0.13340218 0.37885795], train_wt_loss:  49.6230, val_wt_loss: 48.3395, train_grp_loss: [16.58770712 17.14850449 15.80149693], val_grp_loss: [17.51409753 15.55637427 15.30257014], train_hist_grp_loss: [290.39480779 160.75343365 265.13272088], cur_train_grp_loss: [0.18030796 0.1544588  0.16290902], max_reward_err:  0.0544, max_reward_err_index: 0, max_kl_dist:  1.8138, max_kl_dist_index: 0, max_train_grp_loss:  17.1485, max_train_grp_loss_index: 1, max_val_grp_loss:  17.5141, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.1803, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:48:45,579 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  1600, train_loss:  16.6241, val_loss:  16.1731, grad_norm: 0.2449, live_grad: 0.0000, reward_err: 0.0544, 0.0205, 0.0227, KL_dist: 1.8169, 1.5077, 1.6058, param: [10.95098921  9.21546122 12.6384622   8.87281267], weights: [0.49251819 0.13151441 0.3759674 ], train_wt_loss:  49.8722, val_wt_loss: 48.5192, train_grp_loss: [16.53142447 17.47302909 15.74049168], val_grp_loss: [17.45434796 15.84712449 15.25750884], train_hist_grp_loss: [308.39356219 176.35206782 281.3906655 ], cur_train_grp_loss: [0.17969489 0.15738823 0.16227875], max_reward_err:  0.0544, max_reward_err_index: 0, max_kl_dist:  1.8169, max_kl_dist_index: 0, max_train_grp_loss:  17.4730, max_train_grp_loss_index: 1, max_val_grp_loss:  17.4543, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.1797, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:48:49,977 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  1700, train_loss:  16.6925, val_loss:  16.2225, grad_norm: 0.2467, live_grad: 0.0000, reward_err: 0.0544, 0.0208, 0.0227, KL_dist: 1.8194, 1.5180, 1.6102, param: [10.93237664  9.28923341 12.64460983  8.94561321], weights: [0.49709168 0.13000363 0.37290469], train_wt_loss:  50.0774, val_wt_loss: 48.6676, train_grp_loss: [16.48597848 17.73840037 15.69140729], val_grp_loss: [17.40612004 16.0850314  15.22129655], train_hist_grp_loss: [326.33716285 192.21595238 297.59200326], cur_train_grp_loss: [0.17919985 0.15978385 0.16177161], max_reward_err:  0.0544, max_reward_err_index: 0, max_kl_dist:  1.8194, max_kl_dist_index: 0, max_train_grp_loss:  17.7384, max_train_grp_loss_index: 1, max_val_grp_loss:  17.4061, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.1792, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:48:54,336 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  1800, train_loss:  16.7483, val_loss:  16.2631, grad_norm: 0.2477, live_grad: 0.0000, reward_err: 0.0536, 0.0208, 0.0221, KL_dist: 1.8213, 1.5263, 1.6136, param: [10.91530635  9.34821662 12.65005839  9.00461603], weights: [0.50149874 0.128792   0.36970926], train_wt_loss:  50.2450, val_wt_loss: 48.7892, train_grp_loss: [16.4493948  17.95406338 15.65206266], val_grp_loss: [17.36731781 16.27845129 15.19231158], train_hist_grp_loss: [344.23629918 208.29606387 313.74788175], cur_train_grp_loss: [0.17880133 0.16173085 0.1613651 ], max_reward_err:  0.0536, max_reward_err_index: 0, max_kl_dist:  1.8213, max_kl_dist_index: 0, max_train_grp_loss:  17.9541, max_train_grp_loss_index: 1, max_val_grp_loss:  17.3673, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.1788, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:48:58,665 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  1900, train_loss:  16.7937, val_loss:  16.2960, grad_norm: 0.2479, live_grad: 0.0000, reward_err: 0.0536, 0.0211, 0.0221, KL_dist: 1.8228, 1.5330, 1.6164, param: [10.89948335  9.39516457 12.65496636  9.05238572], weights: [0.50577035 0.12781719 0.36641247], train_wt_loss:  50.3811, val_wt_loss: 48.8881, train_grp_loss: [16.4199959  18.12856427 15.62060781], val_grp_loss: [17.33615917 16.43498116 15.16917919], train_hist_grp_loss: [362.0996753  224.55150799 329.8673702 ], cur_train_grp_loss: [0.17848108 0.16330628 0.16104009], max_reward_err:  0.0536, max_reward_err_index: 0, max_kl_dist:  1.8228, max_kl_dist_index: 0, max_train_grp_loss:  18.1286, max_train_grp_loss_index: 1, max_val_grp_loss:  17.3362, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.1785, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:49:02,943 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  1999, train_loss:  16.8301, val_loss:  16.3225, grad_norm: 0.2475,  live_grad: 0.0000, reward_err: 0.0536, 0.0215, 0.0221, KL_dist: 1.8239, 1.5382, 1.6185, param: [10.88481085  9.43206356 12.65941294  9.09073242], weights: [0.50989022 0.12703655 0.36307323], train_wt_loss:  50.4903, val_wt_loss: 48.9676, train_grp_loss: [16.39659321 18.26810791 15.59572485], val_grp_loss: [17.31137976 16.56014849 15.15091833], train_hist_grp_loss: [379.75609974 240.78403807 345.79700978], cur_train_grp_loss: [0.17822614 0.16456615 0.16078298], max_reward_err:  0.0536, max_reward_err_index: 0, max_kl_dist:  1.8239, max_kl_dist_index: 0, max_train_grp_loss:  18.2681, max_train_grp_loss_index: 1, max_val_grp_loss:  17.3114, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.1782, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:49:03,169 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:386] - INFO: Policy parameter learned solely on the preference data rdpo: [10.88481085  9.43206356 12.65941294  9.09073242].
2024-09-17 15:49:03,493 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:397] - INFO: Uniform reward: 3.8117, 3.8117, 3.1389
2024-09-17 15:49:03,494 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Optimal reward: 3.8428, 3.8428, 3.2468
2024-09-17 15:49:03,494 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Policy reward: 3.6370, 3.7602, 3.1751
2024-09-17 15:49:03,495 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Reward Error: 0.0536, 0.0215, 0.0221
2024-09-17 15:49:04,208 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:415] - INFO: Optimal reward: 3.8428, 3.8428, 3.2468
Known param reward: [[3.8428120613098145, 3.466555118560791, 3.208935022354126], [3.466555118560791, 3.8428120613098145, 3.0578837394714355], [3.8028461933135986, 3.5883326530456543, 3.246764659881592]], Known param reward error: [[0.0, 0.09791187722586076, 0.01165148740064377], [0.09791187722586076, 0.0, 0.05817511898661749], [0.010400162005995563, 0.06622218422449246, 0.0]].
