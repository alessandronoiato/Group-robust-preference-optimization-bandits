2024-09-17 15:51:00,061 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:198] - INFO: Logging to log_rdpo/2024_09_17_15_40_31/swapped_noise1.0_[1,1,1]_2027
2024-09-17 15:51:00,063 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: (IB) Seed: 2027
2024-09-17 15:51:00,063 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Data: 300
2024-09-17 15:51:00,225 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:296] - INFO: MLE reward loss: 0.3228, l2 distance: 41.2733, acc: 0.83.
2024-09-17 15:51:00,225 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-17 15:51:00,226 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: MLE reward parameter: [19.657317    8.84358436 14.57070386  8.52464726]
2024-09-17 15:51:00,429 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:313] - INFO: Learned oracle reward: 3.5307, 3.8480, 3.2060
2024-09-17 15:51:00,685 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-17 15:51:01,838 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  14.0236, val_loss:  14.6933, grad_norm: 0.2772, live_grad: 0.0000, reward_err: 0.1105, 0.0010, 0.0697, KL_dist: 2.4178, 1.2417, 2.0089, param: [16.55418053  5.15597897 10.16373288  4.16420373], weights: [0.33333767 0.33331845 0.33334388], train_wt_loss:  42.0709, val_wt_loss: 44.0799, train_grp_loss: [16.09423418  7.35261906 17.75428336], val_grp_loss: [19.69651251  6.82803794 17.69750352], train_hist_grp_loss: [0.20335577 0.19758917 0.20521869], cur_train_grp_loss: [0.20335577 0.19758917 0.20521869], max_reward_err:  0.1105, max_reward_err_index: 0, max_kl_dist:  2.4178, max_kl_dist_index: 0, max_train_grp_loss:  17.7543, max_train_grp_loss_index: 2, max_val_grp_loss:  19.6965, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2052, max_cur_train_grp_loss_index: 2, 
2024-09-17 15:51:06,199 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  100, train_loss:  14.0283, val_loss:  14.6963, grad_norm: 0.0091, live_grad: 0.0000, reward_err: 0.1068, 0.0010, 0.0663, KL_dist: 2.4332, 1.2630, 2.0273, param: [16.68545454  5.42193545 10.17920909  4.36872941], weights: [0.33946095 0.31617113 0.34436792], train_wt_loss:  42.0850, val_wt_loss: 44.0888, train_grp_loss: [15.92886518  7.75074592 17.58649991], val_grp_loss: [19.54621542  7.12886626 17.54967019], train_hist_grp_loss: [15.59951117  8.49198035 17.03468088], cur_train_grp_loss: [0.15317784 0.08512817 0.16750627], max_reward_err:  0.1068, max_reward_err_index: 0, max_kl_dist:  2.4332, max_kl_dist_index: 0, max_train_grp_loss:  17.5865, max_train_grp_loss_index: 2, max_val_grp_loss:  19.5462, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.1675, max_cur_train_grp_loss_index: 2, 
2024-09-17 15:51:10,621 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  200, train_loss:  14.0421, val_loss:  14.7087, grad_norm: 0.0187, live_grad: 0.0000, reward_err: 0.1060, 0.0015, 0.0656, KL_dist: 2.4477, 1.2847, 2.0446, param: [16.80468713  5.68279894 10.20043458  4.56980943], weights: [0.34460316 0.30077004 0.3546268 ], train_wt_loss:  42.1262, val_wt_loss: 44.1260, train_grp_loss: [15.76898034  8.16696512 17.4233389 ], val_grp_loss: [19.39870783  7.45159116 17.40510066], train_hist_grp_loss: [30.83911234 17.23436252 33.70635899], cur_train_grp_loss: [0.15163986 0.08970041 0.16595182], max_reward_err:  0.1060, max_reward_err_index: 0, max_kl_dist:  2.4477, max_kl_dist_index: 0, max_train_grp_loss:  17.4233, max_train_grp_loss_index: 2, max_val_grp_loss:  19.3987, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.1660, max_cur_train_grp_loss_index: 2, 
2024-09-17 15:51:14,984 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  300, train_loss:  14.0638, val_loss:  14.7296, grad_norm: 0.0284, live_grad: 0.0000, reward_err: 0.1038, 0.0020, 0.0638, KL_dist: 2.4610, 1.3067, 2.0609, param: [16.91179416  5.93506677 10.22589106  4.76472225], weights: [0.34881546 0.28705267 0.36413187], train_wt_loss:  42.1915, val_wt_loss: 44.1889, train_grp_loss: [15.61641246  8.5937365  17.26682937], val_grp_loss: [19.25604395  7.78978647 17.26574799], train_hist_grp_loss: [45.92832389 26.440595   50.22563002], cur_train_grp_loss: [0.15017208 0.09438948 0.16446053], max_reward_err:  0.1038, max_reward_err_index: 0, max_kl_dist:  2.4610, max_kl_dist_index: 0, max_train_grp_loss:  17.2668, max_train_grp_loss_index: 2, max_val_grp_loss:  19.2560, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.1645, max_cur_train_grp_loss_index: 2, 
2024-09-17 15:51:19,294 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  400, train_loss:  14.0924, val_loss:  14.7578, grad_norm: 0.0381, live_grad: 0.0000, reward_err: 0.1024, 0.0021, 0.0625, KL_dist: 2.4732, 1.3284, 2.0760, param: [17.00695027  6.17561568 10.25415017  4.95101926], weights: [0.35216069 0.27493013 0.37290918], train_wt_loss:  42.2772, val_wt_loss: 44.2735, train_grp_loss: [15.47271084  9.02294525 17.11871909], val_grp_loss: [19.12003545  8.13621871 17.13331313], train_hist_grp_loss: [60.87494487 36.11788476 66.59967885], cur_train_grp_loss: [0.14878942 0.09910624 0.16304908], max_reward_err:  0.1024, max_reward_err_index: 0, max_kl_dist:  2.4732, max_kl_dist_index: 0, max_train_grp_loss:  17.1187, max_train_grp_loss_index: 2, max_val_grp_loss:  19.1200, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.1630, max_cur_train_grp_loss_index: 2, 
2024-09-17 15:51:23,672 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  500, train_loss:  14.1261, val_loss:  14.7918, grad_norm: 0.0476, live_grad: 0.0000, reward_err: 0.1015, 0.0022, 0.0615, KL_dist: 2.4843, 1.3495, 2.0898, param: [17.09055982  6.40186452 10.28394039  5.12665546], weights: [0.35470944 0.26429418 0.38099638], train_wt_loss:  42.3784, val_wt_loss: 44.3753, train_grp_loss: [15.33906893  9.4465061  16.98038953], val_grp_loss: [18.99215967  8.48342208 17.00916141], train_hist_grp_loss: [75.6880991  46.26448184 82.83718757], cur_train_grp_loss: [0.14750339 0.1037618  0.16173068], max_reward_err:  0.1015, max_reward_err_index: 0, max_kl_dist:  2.4843, max_kl_dist_index: 0, max_train_grp_loss:  16.9804, max_train_grp_loss_index: 2, max_val_grp_loss:  18.9922, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.1617, max_cur_train_grp_loss_index: 2, 
2024-09-17 15:51:28,040 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  600, train_loss:  14.1634, val_loss:  14.8297, grad_norm: 0.0567, live_grad: 0.0000, reward_err: 0.0989, 0.0027, 0.0595, KL_dist: 2.4942, 1.3697, 2.1023, param: [17.16321673  6.6118803  10.31419012  5.2900772 ], weights: [0.35653644 0.2550241  0.38843946], train_wt_loss:  42.4902, val_wt_loss: 44.4890, train_grp_loss: [15.21628692  9.85694127 16.85280846], val_grp_loss: [18.87350409  8.82427205 16.89427469], train_hist_grp_loss: [90.37787232 56.87003266 98.9479611 ], cur_train_grp_loss: [0.14632172 0.10827389 0.16051456], max_reward_err:  0.0989, max_reward_err_index: 0, max_kl_dist:  2.4942, max_kl_dist_index: 0, max_train_grp_loss:  16.8528, max_train_grp_loss_index: 2, max_val_grp_loss:  18.8735, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.1605, max_cur_train_grp_loss_index: 2, 
2024-09-17 15:51:32,425 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  700, train_loss:  14.2026, val_loss:  14.8698, grad_norm: 0.0653, live_grad: 0.0000, reward_err: 0.0984, 0.0030, 0.0590, KL_dist: 2.5031, 1.3887, 2.1135, param: [17.22565793  6.80441954 10.34404663  5.44026015], weights: [0.35771739 0.24699278 0.39528982], train_wt_loss:  42.6079, val_wt_loss: 44.6094, train_grp_loss: [15.10477033 10.24785015 16.73652186], val_grp_loss: [18.76474968  9.1524729  16.78924099], train_hist_grp_loss: [104.95493058  67.91651602 114.94252633], cur_train_grp_loss: [0.14524836 0.11257204 0.15940598], max_reward_err:  0.0984, max_reward_err_index: 0, max_kl_dist:  2.5031, max_kl_dist_index: 0, max_train_grp_loss:  16.7365, max_train_grp_loss_index: 2, max_val_grp_loss:  18.7647, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.1594, max_cur_train_grp_loss_index: 2, 
2024-09-17 15:51:36,799 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  800, train_loss:  14.2423, val_loss:  14.9107, grad_norm: 0.0734, live_grad: 0.0000, reward_err: 0.0975, 0.0037, 0.0582, KL_dist: 2.5108, 1.4064, 2.1234, param: [17.27871537  6.97890855 10.37287396  5.576699  ], weights: [0.35832645 0.24007204 0.40160151], train_wt_loss:  42.7269, val_wt_loss: 44.7320, train_grp_loss: [15.00455988 10.61421803 16.6316807 ], val_grp_loss: [18.66618964  9.46290054 16.69427731], train_hist_grp_loss: [119.43015278  79.3796108  130.83174065], cur_train_grp_loss: [0.14428372 0.11660097 0.15840641], max_reward_err:  0.0975, max_reward_err_index: 0, max_kl_dist:  2.5108, max_kl_dist_index: 0, max_train_grp_loss:  16.6317, max_train_grp_loss_index: 2, max_val_grp_loss:  18.6662, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.1584, max_cur_train_grp_loss_index: 2, 
2024-09-17 15:51:41,267 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  900, train_loss:  14.2813, val_loss:  14.9509, grad_norm: 0.0809, live_grad: 0.0000, reward_err: 0.0960, 0.0039, 0.0571, KL_dist: 2.5174, 1.4225, 2.1321, param: [17.32327082  7.13537434 10.4002351   5.69935795], weights: [0.35843427 0.23413674 0.40742899], train_wt_loss:  42.8438, val_wt_loss: 44.8527, train_grp_loss: [14.91538411 10.95254724 16.53809367], val_grp_loss: [18.57777524  9.75177715 16.60927728], train_hist_grp_loss: [133.8143035   91.23030634 146.62643887], cur_train_grp_loss: [0.14342522 0.12032209 0.15751405], max_reward_err:  0.0960, max_reward_err_index: 0, max_kl_dist:  2.5174, max_kl_dist_index: 0, max_train_grp_loss:  16.5381, max_train_grp_loss_index: 2, max_val_grp_loss:  18.5778, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.1575, max_cur_train_grp_loss_index: 2, 
2024-09-17 15:51:45,685 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  1000, train_loss:  14.3185, val_loss:  14.9894, grad_norm: 0.0877, live_grad: 0.0000, reward_err: 0.0951, 0.0040, 0.0564, KL_dist: 2.5232, 1.4371, 2.1396, param: [17.36021682  7.27434305 10.42586405  5.80859449], weights: [0.35810666 0.229068   0.41282535], train_wt_loss:  42.9556, val_wt_loss: 44.9683, train_grp_loss: [14.83672485 11.26082745 16.45529511], val_grp_loss: [18.49917838 10.01668775 16.53387354], train_hist_grp_loss: [148.1177634  103.43656649 162.33713859], cur_train_grp_loss: [0.1426679  0.12371315 0.15672449], max_reward_err:  0.0951, max_reward_err_index: 0, max_kl_dist:  2.5232, max_kl_dist_index: 0, max_train_grp_loss:  16.4553, max_train_grp_loss_index: 2, max_val_grp_loss:  18.4992, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.1567, max_cur_train_grp_loss_index: 2, 
2024-09-17 15:51:49,990 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  1100, train_loss:  14.3534, val_loss:  15.0256, grad_norm: 0.0939, live_grad: 0.0000, reward_err: 0.0951, 0.0046, 0.0564, KL_dist: 2.5280, 1.4502, 2.1461, param: [17.39042519  7.39672328 10.44963352  5.90507034], weights: [0.35740377 0.2247552  0.41784103], train_wt_loss:  43.0603, val_wt_loss: 45.0767, train_grp_loss: [14.76788616 11.53838329 16.38261802], val_grp_loss: [18.42986076 10.25647182 16.46750519], train_hist_grp_loss: [162.35032478 115.96489031 177.9738132 ], cur_train_grp_loss: [0.14200508 0.12676658 0.1560314 ], max_reward_err:  0.0951, max_reward_err_index: 0, max_kl_dist:  2.5280, max_kl_dist_index: 0, max_train_grp_loss:  16.3826, max_train_grp_loss_index: 2, max_val_grp_loss:  18.4299, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.1560, max_cur_train_grp_loss_index: 2, 
2024-09-17 15:51:54,285 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  1200, train_loss:  14.3855, val_loss:  15.0588, grad_norm: 0.0995, live_grad: 0.0000, reward_err: 0.0929, 0.0049, 0.0546, KL_dist: 2.5320, 1.4617, 2.1515, param: [17.41472396  7.50368924 10.47152234  5.9896611 ], weights: [0.35637976 0.22109732 0.42252292], train_wt_loss:  43.1565, val_wt_loss: 45.1763, train_grp_loss: [14.70805946 11.78564662 16.31926379], val_grp_loss: [18.36914139 10.47103373 16.4094827 ], train_hist_grp_loss: [176.52105225 128.78165996 193.54573358], cur_train_grp_loss: [0.141429   0.12948704 0.15542718], max_reward_err:  0.0929, max_reward_err_index: 0, max_kl_dist:  2.5320, max_kl_dist_index: 0, max_train_grp_loss:  16.3193, max_train_grp_loss_index: 2, max_val_grp_loss:  18.3691, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.1554, max_cur_train_grp_loss_index: 2, 
2024-09-17 15:51:58,597 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  1300, train_loss:  14.4146, val_loss:  15.0888, grad_norm: 0.1046, live_grad: 0.0000, reward_err: 0.0916, 0.0051, 0.0534, KL_dist: 2.5352, 1.4718, 2.1560, param: [17.43388177  7.59657446 10.49158567  6.06337343], weights: [0.35508267 0.21800343 0.4269139 ], train_wt_loss:  43.2438, val_wt_loss: 45.2664, train_grp_loss: [14.65638009 12.00389779 16.26436352], val_grp_loss: [18.31625673 10.66111485 16.35904501], train_hist_grp_loss: [190.63820215 141.85421768 209.06137243], cur_train_grp_loss: [0.14093134 0.1318885  0.15490356], max_reward_err:  0.0916, max_reward_err_index: 0, max_kl_dist:  2.5352, max_kl_dist_index: 0, max_train_grp_loss:  16.2644, max_train_grp_loss_index: 2, max_val_grp_loss:  18.3163, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.1549, max_cur_train_grp_loss_index: 2, 
2024-09-17 15:52:02,905 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  1400, train_loss:  14.4406, val_loss:  15.1156, grad_norm: 0.1091, live_grad: 0.0000, reward_err: 0.0916, 0.0054, 0.0534, KL_dist: 2.5378, 1.4805, 2.1597, param: [17.44859906  7.67678246 10.5099296   6.12727492], weights: [0.35355473 0.21539272 0.43105255], train_wt_loss:  43.3218, val_wt_loss: 45.3468, train_grp_loss: [14.61197288 12.1950111  16.21702778], val_grp_loss: [18.27041038 10.82806215 16.31540624], train_hist_grp_loss: [204.70919121 155.15165812 224.52836181], cur_train_grp_loss: [0.14050369 0.13399151 0.15445206], max_reward_err:  0.0916, max_reward_err_index: 0, max_kl_dist:  2.5378, max_kl_dist_index: 0, max_train_grp_loss:  16.2170, max_train_grp_loss_index: 2, max_val_grp_loss:  18.2704, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.1545, max_cur_train_grp_loss_index: 2, 
2024-09-17 15:52:07,209 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  1500, train_loss:  14.4636, val_loss:  15.1392, grad_norm: 0.1131, live_grad: 0.0000, reward_err: 0.0916, 0.0058, 0.0534, KL_dist: 2.5398, 1.4881, 2.1627, param: [17.45950438  7.7457167  10.5266907   6.18243873], weights: [0.35183264 0.21319412 0.43497324], train_wt_loss:  43.3909, val_wt_loss: 45.4177, train_grp_loss: [14.57398641 12.36122759 16.17638453], val_grp_loss: [18.23081136 10.97361694 16.27779129], train_hist_grp_loss: [218.74060364 168.64535423 239.95349234], cur_train_grp_loss: [0.14013786 0.13582067 0.15406439], max_reward_err:  0.0916, max_reward_err_index: 0, max_kl_dist:  2.5398, max_kl_dist_index: 0, max_train_grp_loss:  16.1764, max_train_grp_loss_index: 2, max_val_grp_loss:  18.2308, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.1541, max_cur_train_grp_loss_index: 2, 
2024-09-17 15:52:11,552 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  1600, train_loss:  14.4838, val_loss:  15.1599, grad_norm: 0.1167, live_grad: 0.0000, reward_err: 0.0910, 0.0060, 0.0530, KL_dist: 2.5413, 1.4946, 2.1651, param: [17.46715476  7.80472962 10.54202042  6.22990298], weights: [0.34994809 0.21134568 0.43870623], train_wt_loss:  43.4515, val_wt_loss: 45.4796, train_grp_loss: [14.54161667 12.50496721 16.14160562], val_grp_loss: [18.19670153 11.09973724 16.24546109], train_hist_grp_loss: [232.73822605 182.30925417 255.34274311], cur_train_grp_loss: [0.13982611 0.13740256 0.15373264], max_reward_err:  0.0910, max_reward_err_index: 0, max_kl_dist:  2.5413, max_kl_dist_index: 0, max_train_grp_loss:  16.1416, max_train_grp_loss_index: 2, max_val_grp_loss:  18.1967, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.1537, max_cur_train_grp_loss_index: 2, 
2024-09-17 15:52:15,947 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  1700, train_loss:  14.5014, val_loss:  15.1777, grad_norm: 0.1199, live_grad: 0.0000, reward_err: 0.0910, 0.0063, 0.0530, KL_dist: 2.5424, 1.5001, 2.1669, param: [17.47203863  7.85508841 10.55607381  6.27064321], weights: [0.34792823 0.20979381 0.44227796], train_wt_loss:  43.5043, val_wt_loss: 45.5332, train_grp_loss: [14.51412193 12.62868396 16.11192376], val_grp_loss: [18.1673736  11.20845811 16.21772878], train_hist_grp_loss: [246.70710072 196.11999526 270.70133221], cur_train_grp_loss: [0.1395613  0.13876415 0.1534495 ], max_reward_err:  0.0910, max_reward_err_index: 0, max_kl_dist:  2.5424, max_kl_dist_index: 0, max_train_grp_loss:  16.1119, max_train_grp_loss_index: 2, max_val_grp_loss:  18.1674, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.1534, max_cur_train_grp_loss_index: 2, 
2024-09-17 15:52:20,324 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  1800, train_loss:  14.5167, val_loss:  15.1931, grad_norm: 0.1227, live_grad: 0.0000, reward_err: 0.0910, 0.0063, 0.0530, KL_dist: 2.5431, 1.5048, 2.1683, param: [17.47458067  7.89795473 10.56900182  6.3055558 ], weights: [0.34579623 0.2084924  0.44571137], train_wt_loss:  43.5501, val_wt_loss: 45.5792, train_grp_loss: [14.49083035 12.73476139 16.08664171], val_grp_loss: [18.14218144 11.30178902 16.19396883], train_hist_grp_loss: [260.65158962 210.05688107 286.03377949], cur_train_grp_loss: [0.13933697 0.13993165 0.15320833], max_reward_err:  0.0910, max_reward_err_index: 0, max_kl_dist:  2.5431, max_kl_dist_index: 0, max_train_grp_loss:  16.0866, max_train_grp_loss_index: 2, max_val_grp_loss:  18.1422, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.1532, max_cur_train_grp_loss_index: 2, 
2024-09-17 15:52:24,712 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  1900, train_loss:  14.5298, val_loss:  15.2062, grad_norm: 0.1253, live_grad: 0.0000, reward_err: 0.0910, 0.0063, 0.0530, KL_dist: 2.5435, 1.5088, 2.1692, param: [17.4751474   7.9343752  10.58094636  6.33544987], weights: [0.34357174 0.20740204 0.44902621], train_wt_loss:  43.5895, val_wt_loss: 45.6185, train_grp_loss: [14.47114238 12.82544306 16.0651357 ], val_grp_loss: [18.12054461 11.38164357 16.17362063], train_hist_grp_loss: [274.57544309 224.10176324 301.34397534], cur_train_grp_loss: [0.13914734 0.14092973 0.15300318], max_reward_err:  0.0910, max_reward_err_index: 0, max_kl_dist:  2.5435, max_kl_dist_index: 0, max_train_grp_loss:  16.0651, max_train_grp_loss_index: 2, max_val_grp_loss:  18.1205, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.1530, max_cur_train_grp_loss_index: 2, 
2024-09-17 15:52:29,090 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  1999, train_loss:  14.5410, val_loss:  15.2172, grad_norm: 0.1276,  live_grad: 0.0000, reward_err: 0.0905, 0.0063, 0.0526, KL_dist: 2.5436, 1.5121, 2.1698, param: [17.47407155  7.96499517 10.59193047  6.36080854], weights: [0.34129471 0.20649751 0.45220778], train_wt_loss:  43.6231, val_wt_loss: 45.6515, train_grp_loss: [14.45468188 12.90207726 16.04702313], val_grp_loss: [18.10212108 11.44916671 16.15634961], train_hist_grp_loss: [288.34288168 238.09708179 316.48242175], cur_train_grp_loss: [0.13898879 0.14177321 0.1528304 ], max_reward_err:  0.0905, max_reward_err_index: 0, max_kl_dist:  2.5436, max_kl_dist_index: 0, max_train_grp_loss:  16.0470, max_train_grp_loss_index: 2, max_val_grp_loss:  18.1021, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.1528, max_cur_train_grp_loss_index: 2, 
2024-09-17 15:52:29,313 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:386] - INFO: Policy parameter learned solely on the preference data rdpo: [17.47407155  7.96499517 10.59193047  6.36080854].
2024-09-17 15:52:29,648 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:397] - INFO: Uniform reward: 3.8228, 3.8228, 3.2184
2024-09-17 15:52:29,649 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Optimal reward: 3.8669, 3.8669, 3.3658
2024-09-17 15:52:29,650 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Policy reward: 3.5168, 3.8424, 3.1888
2024-09-17 15:52:29,650 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Reward Error: 0.0905, 0.0063, 0.0526
2024-09-17 15:52:30,369 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:415] - INFO: Optimal reward: 3.8669, 3.8669, 3.3658
Known param reward: [[3.8669028282165527, 3.4664041996002197, 3.3253726959228516], [3.4664041996002197, 3.8669028282165527, 3.1640493869781494], [3.8246397972106934, 3.594559669494629, 3.3657867908477783]], Known param reward error: [[0.0, 0.10357090581483432, 0.012007324716711247], [0.10357090581483432, 0.0, 0.05993766581358977], [0.01092942669711497, 0.07042927397467878, 0.0]].
