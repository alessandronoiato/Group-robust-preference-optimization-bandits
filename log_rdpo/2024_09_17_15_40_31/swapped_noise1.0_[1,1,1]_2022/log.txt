2024-09-17 15:42:21,523 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:198] - INFO: Logging to log_rdpo/2024_09_17_15_40_31/swapped_noise1.0_[1,1,1]_2022
2024-09-17 15:42:21,525 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: (IB) Seed: 2022
2024-09-17 15:42:21,526 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Data: 300
2024-09-17 15:42:21,690 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:296] - INFO: MLE reward loss: 0.3316, l2 distance: 39.4446, acc: 0.83.
2024-09-17 15:42:21,691 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-17 15:42:21,692 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: MLE reward parameter: [16.35863729  9.16281242 16.84987109  7.67203992]
2024-09-17 15:42:21,900 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:313] - INFO: Learned oracle reward: 3.6080, 3.8501, 3.2158
2024-09-17 15:42:22,140 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-17 15:42:23,372 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  14.1493, val_loss:  14.3858, grad_norm: 0.2573, live_grad: 0.0000, reward_err: 0.0801, 0.0005, 0.0440, KL_dist: 2.1107, 1.2508, 1.7483, param: [12.59928615  4.88174311 13.85531942  5.15044657], weights: [0.33346304 0.33315452 0.33338244], train_wt_loss:  42.4480, val_wt_loss: 43.1575, train_grp_loss: [19.60859429  7.17620229 15.86246629], val_grp_loss: [20.47688718  7.06393916 15.98688058], train_hist_grp_loss: [0.2357484  0.14318371 0.21157298], cur_train_grp_loss: [0.2357484  0.14318371 0.21157298], max_reward_err:  0.0801, max_reward_err_index: 0, max_kl_dist:  2.1107, max_kl_dist_index: 0, max_train_grp_loss:  19.6086, max_train_grp_loss_index: 0, max_val_grp_loss:  20.4769, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2357, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:42:27,820 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  100, train_loss:  14.1561, val_loss:  14.4047, grad_norm: 0.0111, live_grad: 0.0000, reward_err: 0.0802, 0.0008, 0.0442, KL_dist: 2.1260, 1.2750, 1.7676, param: [12.50591217  5.15886456 14.07131496  5.39632553], weights: [0.35294909 0.31016736 0.33688355], train_wt_loss:  42.4684, val_wt_loss: 43.2142, train_grp_loss: [19.40510439  7.54720754 15.70859941], val_grp_loss: [20.2933222   7.43452326 15.83358454], train_hist_grp_loss: [20.34732331  7.42614071 15.68867124], cur_train_grp_loss: [0.2000738  0.0746857  0.15402114], max_reward_err:  0.0802, max_reward_err_index: 0, max_kl_dist:  2.1260, max_kl_dist_index: 0, max_train_grp_loss:  19.4051, max_train_grp_loss_index: 0, max_val_grp_loss:  20.2933, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2001, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:42:32,335 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  200, train_loss:  14.1772, val_loss:  14.4387, grad_norm: 0.0229, live_grad: 0.0000, reward_err: 0.0783, 0.0018, 0.0427, KL_dist: 2.1419, 1.3011, 1.7879, param: [12.41941193  5.44723547 14.2742223   5.65188844], weights: [0.37182299 0.28915061 0.3390264 ], train_wt_loss:  42.5315, val_wt_loss: 43.3162, train_grp_loss: [19.19837229  7.9666382  15.55169688], val_grp_loss: [20.10408914  7.85662983 15.67741628], train_hist_grp_loss: [40.24726913 15.10024628 31.01327613], cur_train_grp_loss: [0.19794276 0.07883376 0.15248308], max_reward_err:  0.0783, max_reward_err_index: 0, max_kl_dist:  2.1419, max_kl_dist_index: 0, max_train_grp_loss:  19.1984, max_train_grp_loss_index: 0, max_val_grp_loss:  20.1041, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.1979, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:42:36,823 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  300, train_loss:  14.2131, val_loss:  14.4885, grad_norm: 0.0349, live_grad: 0.0000, reward_err: 0.0766, 0.0029, 0.0412, KL_dist: 2.1581, 1.3290, 1.8087, param: [12.33881565  5.74310698 14.46287369  5.91361635], weights: [0.38998526 0.27012907 0.33988567], train_wt_loss:  42.6394, val_wt_loss: 43.4654, train_grp_loss: [18.99078418  8.43217453 15.3939819 ], val_grp_loss: [19.91161255  8.32778538 15.52052754], train_hist_grp_loss: [59.93343472 23.21252868 46.18346909], cur_train_grp_loss: [0.19580264 0.08343867 0.15093682], max_reward_err:  0.0766, max_reward_err_index: 0, max_kl_dist:  2.1581, max_kl_dist_index: 0, max_train_grp_loss:  18.9908, max_train_grp_loss_index: 0, max_val_grp_loss:  19.9116, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.1958, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:42:41,248 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  400, train_loss:  14.2641, val_loss:  14.5537, grad_norm: 0.0468, live_grad: 0.0000, reward_err: 0.0757, 0.0037, 0.0405, KL_dist: 2.1742, 1.3583, 1.8297, param: [12.26298075  6.04216344 14.63646545  6.17749942], weights: [0.40736348 0.25308035 0.33955617], train_wt_loss:  42.7922, val_wt_loss: 43.6612, train_grp_loss: [18.78496875  8.93874823 15.23787274], val_grp_loss: [19.71863047  8.8425749  15.36525906], train_hist_grp_loss: [79.40626427 31.80638389 61.19961702], cur_train_grp_loss: [0.19368051 0.08845052 0.14940606], max_reward_err:  0.0757, max_reward_err_index: 0, max_kl_dist:  2.1742, max_kl_dist_index: 0, max_train_grp_loss:  18.7850, max_train_grp_loss_index: 0, max_val_grp_loss:  19.7186, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.1937, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:42:45,581 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  500, train_loss:  14.3290, val_loss:  14.6334, grad_norm: 0.0585, live_grad: 0.0000, reward_err: 0.0740, 0.0040, 0.0392, KL_dist: 2.1900, 1.3884, 1.8504, param: [12.19069395  6.33976285 14.79457871  6.43926561], weights: [0.42391176 0.2379413  0.33814694], train_wt_loss:  42.9870, val_wt_loss: 43.9001, train_grp_loss: [18.5836432   9.47857581 15.0858318 ], val_grp_loss: [19.52803046  9.39268506 15.21399586], train_hist_grp_loss: [98.66897174 40.91884136 76.06449236], cur_train_grp_loss: [0.19160439 0.09379252 0.14791494], max_reward_err:  0.0740, max_reward_err_index: 0, max_kl_dist:  2.1900, max_kl_dist_index: 0, max_train_grp_loss:  18.5836, max_train_grp_loss_index: 0, max_val_grp_loss:  19.5280, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.1916, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:42:49,930 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  600, train_loss:  14.4062, val_loss:  14.7253, grad_norm: 0.0696, live_grad: 0.0000, reward_err: 0.0735, 0.0054, 0.0389, KL_dist: 2.2050, 1.4189, 1.8705, param: [12.12077048  6.6312338  14.9371796   6.69465677], weights: [0.43960896 0.22461562 0.33577542], train_wt_loss:  43.2187, val_wt_loss: 44.1759, train_grp_loss: [18.38943483 10.04156024 14.94019946], val_grp_loss: [19.34265694  9.96734067 15.06900752], train_hist_grp_loss: [117.7275422   50.57804196  90.78323605], cur_train_grp_loss: [0.18960138 0.09936488 0.14648644], max_reward_err:  0.0735, max_reward_err_index: 0, max_kl_dist:  2.2050, max_kl_dist_index: 0, max_train_grp_loss:  18.3894, max_train_grp_loss_index: 0, max_val_grp_loss:  19.3427, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.1896, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:42:54,366 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  700, train_loss:  14.4933, val_loss:  14.8267, grad_norm: 0.0799, live_grad: 0.0000, reward_err: 0.0726, 0.0064, 0.0382, KL_dist: 2.2190, 1.4491, 1.8896, param: [12.05213914  6.91218919 15.06459626  6.93971501], weights: [0.45445578 0.21298208 0.33256214], train_wt_loss:  43.4799, val_wt_loss: 44.4800, train_grp_loss: [18.20470367 10.61603396 14.80303667], val_grp_loss: [19.16511703 10.55410437 14.93229594], train_hist_grp_loss: [136.59054729  60.80128676 105.3631598 ], cur_train_grp_loss: [0.18769585 0.1050522  0.14514079], max_reward_err:  0.0726, max_reward_err_index: 0, max_kl_dist:  2.2190, max_kl_dist_index: 0, max_train_grp_loss:  18.2047, max_train_grp_loss_index: 0, max_val_grp_loss:  19.1651, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.1877, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:42:58,793 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  800, train_loss:  14.5872, val_loss:  14.9342, grad_norm: 0.0892, live_grad: 0.0000, reward_err: 0.0707, 0.0074, 0.0369, KL_dist: 2.2319, 1.4783, 1.9075, param: [11.98390433  7.17881107 15.17747414  7.17103776], weights: [0.46847121 0.20290263 0.32862616], train_wt_loss:  43.7616, val_wt_loss: 44.8027, train_grp_loss: [18.0313932 11.1897322 14.6759991], val_grp_loss: [18.99761361 11.13991961 14.80547307], train_hist_grp_loss: [155.2687901   71.59394644 119.81340765], cur_train_grp_loss: [0.18590788 0.11073306 0.14389427], max_reward_err:  0.0707, max_reward_err_index: 0, max_kl_dist:  2.2319, max_kl_dist_index: 0, max_train_grp_loss:  18.0314, max_train_grp_loss_index: 0, max_val_grp_loss:  18.9976, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.1859, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:43:03,219 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  900, train_loss:  14.6849, val_loss:  15.0445, grad_norm: 0.0974, live_grad: 0.0000, reward_err: 0.0697, 0.0079, 0.0361, KL_dist: 2.2435, 1.5061, 1.9239, param: [11.91538096  7.42806634 15.27671407  7.38596576], weights: [0.48168854 0.19423006 0.32408139], train_wt_loss:  44.0546, val_wt_loss: 45.1335, train_grp_loss: [17.87092985 11.75082845 14.56025913], val_grp_loss: [18.84182853 11.71221659 14.68968441], train_hist_grp_loss: [173.77481959  82.94937994 134.1445165 ], cur_train_grp_loss: [0.18425224 0.11629025 0.14275841], max_reward_err:  0.0697, max_reward_err_index: 0, max_kl_dist:  2.2435, max_kl_dist_index: 0, max_train_grp_loss:  17.8709, max_train_grp_loss_index: 0, max_val_grp_loss:  18.8418, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.1843, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:43:07,739 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  1000, train_loss:  14.7833, val_loss:  15.1542, grad_norm: 0.1044, live_grad: 0.0000, reward_err: 0.0683, 0.0089, 0.0350, KL_dist: 2.2536, 1.5319, 1.9387, param: [11.84610252  7.6578277  15.36340059  7.58268253], weights: [0.49415144 0.1868146  0.31903397], train_wt_loss:  44.3498, val_wt_loss: 45.4626, train_grp_loss: [17.72418169 12.28885466 14.4564822 ], val_grp_loss: [18.69886793 12.25989196 14.58558477], train_hist_grp_loss: [192.12237133  94.84983549 148.36792639], cur_train_grp_loss: [0.18273794 0.12161998 0.1417398 ], max_reward_err:  0.0683, max_reward_err_index: 0, max_kl_dist:  2.2536, max_kl_dist_index: 0, max_train_grp_loss:  17.7242, max_train_grp_loss_index: 0, max_val_grp_loss:  18.6989, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.1827, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:43:12,213 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  1100, train_loss:  14.8797, val_loss:  15.2605, grad_norm: 0.1102, live_grad: 0.0000, reward_err: 0.0666, 0.0093, 0.0337, KL_dist: 2.2623, 1.5554, 1.9518, param: [11.77580702  7.86689459 15.43872879  7.76022232], weights: [0.50591016 0.18050936 0.31358049], train_wt_loss:  44.6392, val_wt_loss: 45.7814, train_grp_loss: [17.59147438 12.795369   14.36485306], val_grp_loss: [18.56926889 12.77401651 14.49336251], train_hist_grp_loss: [210.32579542 107.26814759 162.49549253], cur_train_grp_loss: [0.18136837 0.12663843 0.14084029], max_reward_err:  0.0666, max_reward_err_index: 0, max_kl_dist:  2.2623, max_kl_dist_index: 0, max_train_grp_loss:  17.5915, max_train_grp_loss_index: 0, max_val_grp_loss:  18.5693, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.1814, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:43:16,649 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  1200, train_loss:  14.9721, val_loss:  15.3610, grad_norm: 0.1149, live_grad: 0.0000, reward_err: 0.0655, 0.0097, 0.0329, KL_dist: 2.2696, 1.5765, 1.9631, param: [11.70440744  8.0549267  15.50393677  7.91839992], weights: [0.51701834 0.17517448 0.30780717], train_wt_loss:  44.9163, val_wt_loss: 46.0830, train_grp_loss: [17.47265306 13.26430489 14.28514016], val_grp_loss: [18.45305623 13.24820143 14.41280091], train_hist_grp_loss: [228.3995256  120.16994126 176.53904283], cur_train_grp_loss: [0.180142   0.1312853  0.14005765], max_reward_err:  0.0655, max_reward_err_index: 0, max_kl_dist:  2.2696, max_kl_dist_index: 0, max_train_grp_loss:  17.4727, max_train_grp_loss_index: 0, max_val_grp_loss:  18.4531, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.1801, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:43:21,069 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  1300, train_loss:  15.0587, val_loss:  15.4542, grad_norm: 0.1185, live_grad: 0.0000, reward_err: 0.0653, 0.0108, 0.0328, KL_dist: 2.2755, 1.5950, 1.9729, param: [11.63195424  8.22231529 15.56024893  8.05768591], weights: [0.52753036 0.17067999 0.30178965], train_wt_loss:  45.1762, val_wt_loss: 46.3626, train_grp_loss: [17.36717341 13.69200923 14.21678255], val_grp_loss: [18.34983218 13.67863272 14.34336171], train_hist_grp_loss: [246.35762866 133.51602615 190.51001073], cur_train_grp_loss: [0.17905324 0.13552419 0.1393864 ], max_reward_err:  0.0653, max_reward_err_index: 0, max_kl_dist:  2.2755, max_kl_dist_index: 0, max_train_grp_loss:  17.3672, max_train_grp_loss_index: 0, max_val_grp_loss:  18.3498, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.1791, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:43:25,497 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  1400, train_loss:  15.1386, val_loss:  15.5391, grad_norm: 0.1211, live_grad: 0.0000, reward_err: 0.0634, 0.0114, 0.0313, KL_dist: 2.2801, 1.6111, 1.9810, param: [11.55859636  8.37002095 15.60883261  8.17905432], weights: [0.53749924 0.16690751 0.29559326], train_wt_loss:  45.4159, val_wt_loss: 46.6172, train_grp_loss: [17.27420475 14.0770329  14.15898393], val_grp_loss: [18.25888102 14.06384219 14.2842761 ], train_hist_grp_loss: [264.21345513 147.2647004  204.41915785], cur_train_grp_loss: [0.17809356 0.13934053 0.13881875], max_reward_err:  0.0634, max_reward_err_index: 0, max_kl_dist:  2.2801, max_kl_dist_index: 0, max_train_grp_loss:  17.2742, max_train_grp_loss_index: 0, max_val_grp_loss:  18.2589, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.1781, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:43:29,952 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  1500, train_loss:  15.2113, val_loss:  15.6151, grad_norm: 0.1229, live_grad: 0.0000, reward_err: 0.0630, 0.0121, 0.0312, KL_dist: 2.2836, 1.6247, 1.9878, param: [11.48454524  8.49940446 15.65076851  8.2838264 ], weights: [0.54697523 0.16375103 0.28927374], train_wt_loss:  45.6339, val_wt_loss: 46.8454, train_grp_loss: [17.19273078 14.41976296 14.11080215], val_grp_loss: [18.17927326 14.4043111  14.23463143], train_hist_grp_loss: [281.9793962  161.37376172 218.27638748], cur_train_grp_loss: [0.1772525  0.14273802 0.13834549], max_reward_err:  0.0630, max_reward_err_index: 0, max_kl_dist:  2.2836, max_kl_dist_index: 0, max_train_grp_loss:  17.1927, max_train_grp_loss_index: 0, max_val_grp_loss:  18.1793, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.1773, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:43:34,384 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  1600, train_loss:  15.2766, val_loss:  15.6825, grad_norm: 0.1238, live_grad: 0.0000, reward_err: 0.0629, 0.0126, 0.0312, KL_dist: 2.2860, 1.6361, 1.9932, param: [11.41004486  8.61207029 15.68703327  8.37352802], weights: [0.55600489 0.161117   0.28287811], train_wt_loss:  45.8298, val_wt_loss: 47.0474, train_grp_loss: [17.12163838 14.72198538 14.07122605], val_grp_loss: [18.10995872 14.70200129 14.19344604], train_hist_grp_loss: [299.66673899 175.80211357 232.09064007], cur_train_grp_loss: [0.17651857 0.14573421 0.13795669], max_reward_err:  0.0629, max_reward_err_index: 0, max_kl_dist:  2.2860, max_kl_dist_index: 0, max_train_grp_loss:  17.1216, max_train_grp_loss_index: 0, max_val_grp_loss:  18.1100, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.1765, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:43:38,807 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  1700, train_loss:  15.3348, val_loss:  15.7414, grad_norm: 0.1241, live_grad: 0.0000, reward_err: 0.0627, 0.0133, 0.0312, KL_dist: 2.2875, 1.6455, 1.9975, param: [11.33534853  8.70973458 15.71849232  8.44977072], weights: [0.56463056 0.15892381 0.27644563], train_wt_loss:  46.0043, val_wt_loss: 47.2241, train_grp_loss: [17.05978925 14.98644958 14.03923624], val_grp_loss: [18.04984279 14.95988977 14.15972865], train_hist_grp_loss: [317.28560483 190.51093432 245.8698565 ], cur_train_grp_loss: [0.17588006 0.14835625 0.13764237], max_reward_err:  0.0627, max_reward_err_index: 0, max_kl_dist:  2.2875, max_kl_dist_index: 0, max_train_grp_loss:  17.0598, max_train_grp_loss_index: 0, max_val_grp_loss:  18.0498, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.1759, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:43:43,211 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  1800, train_loss:  15.3862, val_loss:  15.7925, grad_norm: 0.1238, live_grad: 0.0000, reward_err: 0.0614, 0.0138, 0.0302, KL_dist: 2.2882, 1.6531, 2.0008, param: [11.26070247  8.79412247 15.74590017  8.5141603 ], weights: [0.57289021 0.157101   0.27000879], train_wt_loss:  46.1587, val_wt_loss: 47.3774, train_grp_loss: [17.00607336 15.21648131 14.0138494 ], val_grp_loss: [17.99784411 15.18155613 14.13252165], train_hist_grp_loss: [334.84495219 205.46443616 259.62099275], cur_train_grp_loss: [0.1753255  0.15063703 0.13739288], max_reward_err:  0.0614, max_reward_err_index: 0, max_kl_dist:  2.2882, max_kl_dist_index: 0, max_train_grp_loss:  17.0061, max_train_grp_loss_index: 0, max_val_grp_loss:  17.9978, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.1753, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:43:47,676 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  1900, train_loss:  15.4315, val_loss:  15.8365, grad_norm: 0.1231, live_grad: 0.0000, reward_err: 0.0608, 0.0138, 0.0298, KL_dist: 2.2883, 1.6591, 2.0032, param: [11.18633514  8.8668944  15.7699059   8.56823205], weights: [0.58081749 0.15558825 0.26359426], train_wt_loss:  46.2945, val_wt_loss: 47.5094, train_grp_loss: [16.95944525 15.41566767 13.99414748], val_grp_loss: [17.95293466 15.37084763 14.11092995], train_hist_grp_loss: [352.35262563 220.63027497 273.35007061], cur_train_grp_loss: [0.17484412 0.15261205 0.13719921], max_reward_err:  0.0608, max_reward_err_index: 0, max_kl_dist:  2.2883, max_kl_dist_index: 0, max_train_grp_loss:  16.9594, max_train_grp_loss_index: 0, max_val_grp_loss:  17.9529, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.1748, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:43:52,107 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  1999, train_loss:  15.4709, val_loss:  15.8737, grad_norm: 0.1220,  live_grad: 0.0000, reward_err: 0.0608, 0.0138, 0.0298, KL_dist: 2.2879, 1.6637, 2.0050, param: [11.11318709  8.92901607 15.79086277  8.61299732], weights: [0.58836712 0.15434567 0.25728721], train_wt_loss:  46.4126, val_wt_loss: 47.6212, train_grp_loss: [16.91932366 15.58602356 13.97942171], val_grp_loss: [17.91452516 15.53014876 14.09428436], train_hist_grp_loss: [369.64100878 235.82536937 286.92519761], cur_train_grp_loss: [0.17442991 0.15430124 0.1370544 ], max_reward_err:  0.0608, max_reward_err_index: 0, max_kl_dist:  2.2879, max_kl_dist_index: 0, max_train_grp_loss:  16.9193, max_train_grp_loss_index: 0, max_val_grp_loss:  17.9145, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.1744, max_cur_train_grp_loss_index: 0, 
2024-09-17 15:43:52,343 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:386] - INFO: Policy parameter learned solely on the preference data rdpo: [11.11318709  8.92901607 15.79086277  8.61299732].
2024-09-17 15:43:52,669 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:397] - INFO: Uniform reward: 3.8395, 3.8395, 3.1958
2024-09-17 15:43:52,670 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Optimal reward: 3.8707, 3.8707, 3.3276
2024-09-17 15:43:52,670 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Policy reward: 3.6354, 3.8173, 3.2284
2024-09-17 15:43:52,671 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Reward Error: 0.0608, 0.0138, 0.0298
2024-09-17 15:43:53,378 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:415] - INFO: Optimal reward: 3.8707, 3.8707, 3.3276
Known param reward: [[3.870737075805664, 3.5440561771392822, 3.277423858642578], [3.5440561771392822, 3.870737075805664, 3.1691665649414062], [3.8269641399383545, 3.639406681060791, 3.327569007873535]], Known param reward error: [[0.0, 0.08439759463599984, 0.015069604600928176], [0.08439759463599984, 0.0, 0.04760305272627693], [0.011308682302633167, 0.059763913232655674, 0.0]].
