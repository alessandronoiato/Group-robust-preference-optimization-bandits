2024-09-18 00:20:43,368 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:198] - INFO: Logging to log_rdpo/2024_09_18_00_15_00/swapped_noise0.3_[0.3,0.3,1]_2029
2024-09-18 00:20:43,370 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: (IB) Seed: 2029
2024-09-18 00:20:43,370 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Data: 300
2024-09-18 00:20:43,536 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:296] - INFO: MLE reward loss: 0.6009, l2 distance: 5.9842, acc: 0.70.
2024-09-18 00:20:43,537 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-18 00:20:43,538 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: MLE reward parameter: [3.17823797 1.67370896 4.32981238 1.29270305]
2024-09-18 00:20:43,746 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:313] - INFO: Learned oracle reward: 3.4971, 3.8739, 3.1784
2024-09-18 00:20:43,996 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-18 00:20:45,163 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  20.8635, val_loss:  19.7557, grad_norm: 0.1364, live_grad: 0.0000, reward_err: 0.1039, 0.0004, 0.0617, KL_dist: 0.9798, 0.3465, 0.7441, param: [6.44777437 3.06552003 8.76158185 2.43031557], weights: [0.33344766 0.33321119 0.33334115], train_wt_loss:  62.5905, val_wt_loss: 59.2672, train_grp_loss: [24.59417224 19.53210731 18.73610091], val_grp_loss: [24.70120087 14.82117426 19.35791498], train_hist_grp_loss: [0.25939051 0.18844647 0.22744219], cur_train_grp_loss: [0.25939051 0.18844647 0.22744219], max_reward_err:  0.1039, max_reward_err_index: 0, max_kl_dist:  0.9798, max_kl_dist_index: 0, max_train_grp_loss:  24.5942, max_train_grp_loss_index: 0, max_val_grp_loss:  24.7012, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2594, max_cur_train_grp_loss_index: 0, 
2024-09-18 00:20:49,484 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  99, train_loss:  20.8636, val_loss:  19.7442, grad_norm: 0.0014,  live_grad: 0.0000, reward_err: 0.1023, 0.0004, 0.0602, KL_dist: 0.9719, 0.3465, 0.7373, param: [6.49712    3.09574271 8.69220189 2.45793167], weights: [0.35019574 0.32204373 0.32776053], train_wt_loss:  62.5909, val_wt_loss: 59.2326, train_grp_loss: [24.58828096 19.55650456 18.71436267], val_grp_loss: [24.68193039 14.82315603 19.34140795], train_hist_grp_loss: [26.15872042 17.77823112 19.5378219 ], cur_train_grp_loss: [0.26157811 0.17778418 0.19494349], max_reward_err:  0.1023, max_reward_err_index: 0, max_kl_dist:  0.9719, max_kl_dist_index: 0, max_train_grp_loss:  24.5883, max_train_grp_loss_index: 0, max_val_grp_loss:  24.6819, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2616, max_cur_train_grp_loss_index: 0, 
2024-09-18 00:20:49,707 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:386] - INFO: Policy parameter learned solely on the preference data rdpo: [6.49712    3.09574271 8.69220189 2.45793167].
2024-09-18 00:20:50,034 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:397] - INFO: Uniform reward: 3.8327, 3.8327, 3.2256
2024-09-18 00:20:50,035 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Optimal reward: 3.8777, 3.8777, 3.3695
2024-09-18 00:20:50,035 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Policy reward: 3.4809, 3.8761, 3.1667
2024-09-18 00:20:50,036 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Reward Error: 0.1023, 0.0004, 0.0602
2024-09-18 00:20:50,711 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:415] - INFO: Optimal reward: 3.8777, 3.8777, 3.3695
Known param reward: [[3.877681255340576, 3.4682672023773193, 3.333303689956665], [3.4682672023773193, 3.877681255340576, 3.161881923675537], [3.841872215270996, 3.599954605102539, 3.3694965839385986]], Known param reward error: [[0.0, 0.10558218326980516, 0.010741335710044788], [0.10558218326980516, 0.0, 0.06161592840090703], [0.009234652801919114, 0.071621835821481, 0.0]].
