2024-09-18 00:21:03,545 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:198] - INFO: Logging to log_rdpo/2024_09_18_00_15_00/swapped_noise0.3_[0.3,0.3,1]_2030
2024-09-18 00:21:03,547 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: (IB) Seed: 2030
2024-09-18 00:21:03,548 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Data: 300
2024-09-18 00:21:03,711 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:296] - INFO: MLE reward loss: 0.5370, l2 distance: 9.6501, acc: 0.76.
2024-09-18 00:21:03,712 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-18 00:21:03,713 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: MLE reward parameter: [5.67778576 2.25753769 5.48532197 2.33243305]
2024-09-18 00:21:03,917 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:313] - INFO: Learned oracle reward: 3.5670, 3.8970, 3.2444
2024-09-18 00:21:04,172 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-18 00:21:05,329 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  18.5766, val_loss:  18.9738, grad_norm: 0.1917, live_grad: 0.0000, reward_err: 0.1011, 0.0000, 0.0584, KL_dist: 1.4192, 0.5873, 1.0974, param: [9.59993526 2.88033837 9.25981983 3.16841928], weights: [0.33351113 0.33317934 0.33330953], train_wt_loss:  55.7299, val_wt_loss: 56.9214, train_grp_loss: [24.0308491  14.76773686 17.79874423], val_grp_loss: [23.64992863 14.41426508 18.46912165], train_hist_grp_loss: [0.27107042 0.17153705 0.21060284], cur_train_grp_loss: [0.27107042 0.17153705 0.21060284], max_reward_err:  0.1011, max_reward_err_index: 0, max_kl_dist:  1.4192, max_kl_dist_index: 0, max_train_grp_loss:  24.0308, max_train_grp_loss_index: 0, max_val_grp_loss:  23.6499, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2711, max_cur_train_grp_loss_index: 0, 
2024-09-18 00:21:09,681 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  99, train_loss:  18.5774, val_loss:  18.9569, grad_norm: 0.0035,  live_grad: 0.0000, reward_err: 0.0989, 0.0000, 0.0565, KL_dist: 1.4091, 0.5875, 1.0904, param: [9.55234394 2.97581964 9.26708037 3.2637796 ], weights: [0.35934013 0.31554136 0.3251185 ], train_wt_loss:  55.7322, val_wt_loss: 56.8706, train_grp_loss: [24.00256236 14.82228673 17.7697664 ], val_grp_loss: [23.62955406 14.43277633 18.42053768], train_hist_grp_loss: [26.98670839 13.98874825 16.97874425], cur_train_grp_loss: [0.26969509 0.13982737 0.16923865], max_reward_err:  0.0989, max_reward_err_index: 0, max_kl_dist:  1.4091, max_kl_dist_index: 0, max_train_grp_loss:  24.0026, max_train_grp_loss_index: 0, max_val_grp_loss:  23.6296, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2697, max_cur_train_grp_loss_index: 0, 
2024-09-18 00:21:09,910 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:386] - INFO: Policy parameter learned solely on the preference data rdpo: [9.55234394 2.97581964 9.26708037 3.2637796 ].
2024-09-18 00:21:10,234 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:397] - INFO: Uniform reward: 3.8586, 3.8586, 3.2436
2024-09-18 00:21:10,235 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Optimal reward: 3.9020, 3.9020, 3.3991
2024-09-18 00:21:10,235 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Policy reward: 3.5162, 3.9020, 3.2069
2024-09-18 00:21:10,236 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Reward Error: 0.0989, 0.0000, 0.0565
2024-09-18 00:21:10,914 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:415] - INFO: Optimal reward: 3.9020, 3.9020, 3.3991
Known param reward: [[3.902012586593628, 3.5148375034332275, 3.3579766750335693], [3.5148375034332275, 3.902012586593628, 3.205984354019165], [3.8625452518463135, 3.624565362930298, 3.399076461791992]], Known param reward error: [[0.0, 0.09922445778125893, 0.012091456964976615], [0.09922445778125893, 0.0, 0.05680722688745549], [0.010114609799802972, 0.07110362088953062, 0.0]].
