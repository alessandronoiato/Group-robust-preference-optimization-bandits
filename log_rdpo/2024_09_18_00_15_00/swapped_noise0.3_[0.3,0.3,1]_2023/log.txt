2024-09-18 00:18:47,655 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:198] - INFO: Logging to log_rdpo/2024_09_18_00_15_00/swapped_noise0.3_[0.3,0.3,1]_2023
2024-09-18 00:18:47,657 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: (IB) Seed: 2023
2024-09-18 00:18:47,658 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Data: 300
2024-09-18 00:18:47,820 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:296] - INFO: MLE reward loss: 0.5558, l2 distance: 9.0221, acc: 0.72.
2024-09-18 00:18:47,820 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-18 00:18:47,821 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: MLE reward parameter: [6.19584802 2.72908814 3.85848297 3.05831559]
2024-09-18 00:18:48,031 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:313] - INFO: Learned oracle reward: 3.4972, 3.7813, 3.1032
2024-09-18 00:18:48,283 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-18 00:18:49,475 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  19.4009, val_loss:  19.7777, grad_norm: 0.2165, live_grad: 0.0000, reward_err: 0.0970, 0.0047, 0.0590, KL_dist: 1.2112, 0.5165, 0.9840, param: [10.78005581  3.95301906  5.89077048  3.99076647], weights: [0.33338454 0.33321077 0.33340469], train_wt_loss:  58.2027, val_wt_loss: 59.3331, train_grp_loss: [23.54079279 14.32667162 20.71877263], val_grp_loss: [22.93973494 16.8506913  19.26006627], train_hist_grp_loss: [0.24432243 0.19218556 0.25036422], cur_train_grp_loss: [0.24432243 0.19218556 0.25036422], max_reward_err:  0.0970, max_reward_err_index: 0, max_kl_dist:  1.2112, max_kl_dist_index: 0, max_train_grp_loss:  23.5408, max_train_grp_loss_index: 0, max_val_grp_loss:  22.9397, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2504, max_cur_train_grp_loss_index: 2, 
2024-09-18 00:18:53,792 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  99, train_loss:  19.4033, val_loss:  19.7683, grad_norm: 0.0069,  live_grad: 0.0000, reward_err: 0.0950, 0.0049, 0.0573, KL_dist: 1.2046, 0.5271, 0.9819, param: [10.77719682  4.10641165  5.84927649  4.15949687], weights: [0.34589925 0.31335651 0.34074424], train_wt_loss:  58.2099, val_wt_loss: 59.3048, train_grp_loss: [23.48227413 14.47685904 20.61926588], val_grp_loss: [22.88560232 16.98263814 19.16912699], train_hist_grp_loss: [23.52124139 13.64064105 22.01970211], cur_train_grp_loss: [0.23482878 0.13655889 0.21936481], max_reward_err:  0.0950, max_reward_err_index: 0, max_kl_dist:  1.2046, max_kl_dist_index: 0, max_train_grp_loss:  23.4823, max_train_grp_loss_index: 0, max_val_grp_loss:  22.8856, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2348, max_cur_train_grp_loss_index: 0, 
2024-09-18 00:18:54,020 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:386] - INFO: Policy parameter learned solely on the preference data rdpo: [10.77719682  4.10641165  5.84927649  4.15949687].
2024-09-18 00:18:54,349 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:397] - INFO: Uniform reward: 3.7823, 3.7823, 3.1340
2024-09-18 00:18:54,350 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Optimal reward: 3.8164, 3.8164, 3.2560
2024-09-18 00:18:54,350 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Policy reward: 3.4540, 3.7976, 3.0693
2024-09-18 00:18:54,351 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Reward Error: 0.0950, 0.0049, 0.0573
2024-09-18 00:18:55,032 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:415] - INFO: Optimal reward: 3.8164, 3.8164, 3.2560
Known param reward: [[3.816397190093994, 3.425919532775879, 3.2214560508728027], [3.425919532775879, 3.816397190093994, 3.061397075653076], [3.77667236328125, 3.5491819381713867, 3.2560200691223145]], Known param reward error: [[0.0, 0.10231578053030119, 0.010615419289730827], [0.10231578053030119, 0.0, 0.05977327821621825], [0.01040898649539299, 0.07001767337430258, 0.0]].
