2024-09-18 00:19:05,415 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:198] - INFO: Logging to log_rdpo/2024_09_18_00_15_00/swapped_noise0.3_[0.3,0.3,1]_2024
2024-09-18 00:19:05,417 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: (IB) Seed: 2024
2024-09-18 00:19:05,418 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Data: 300
2024-09-18 00:19:05,581 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:296] - INFO: MLE reward loss: 0.5484, l2 distance: 11.7613, acc: 0.72.
2024-09-18 00:19:05,582 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-18 00:19:05,583 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: MLE reward parameter: [8.04989099 2.27718778 3.76647858 1.25812534]
2024-09-18 00:19:05,786 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:313] - INFO: Learned oracle reward: 3.4363, 3.9127, 3.1172
2024-09-18 00:19:06,033 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-18 00:19:07,196 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  18.8856, val_loss:  20.1237, grad_norm: 0.1646, live_grad: 0.0000, reward_err: 0.1309, 0.0037, 0.0902, KL_dist: 2.0991, 0.7832, 1.7408, param: [14.87037253  3.40044628  6.17242012  1.2894958 ], weights: [0.33336612 0.33332968 0.33330419], train_wt_loss:  56.6567, val_wt_loss: 60.3711, train_grp_loss: [23.59345251 14.51961503 17.91991771], val_grp_loss: [24.50857599 15.64627274 19.96622251], train_hist_grp_loss: [0.22751529 0.21658358 0.20893528], cur_train_grp_loss: [0.22751529 0.21658358 0.20893528], max_reward_err:  0.1309, max_reward_err_index: 0, max_kl_dist:  2.0991, max_kl_dist_index: 0, max_train_grp_loss:  23.5935, max_train_grp_loss_index: 0, max_val_grp_loss:  24.5086, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2275, max_cur_train_grp_loss_index: 0, 
2024-09-18 00:19:11,581 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  99, train_loss:  18.8858, val_loss:  20.1063, grad_norm: 0.0019,  live_grad: 0.0000, reward_err: 0.1303, 0.0038, 0.0895, KL_dist: 2.0894, 0.7794, 1.7332, param: [14.84290938  3.45085234  6.15341435  1.3401927 ], weights: [0.34636773 0.32537125 0.32826102], train_wt_loss:  56.6574, val_wt_loss: 60.3190, train_grp_loss: [23.57656451 14.56283112 17.90039395], val_grp_loss: [24.49570488 15.63719578 19.93661544], train_hist_grp_loss: [22.46492937 16.21151247 17.09573585], cur_train_grp_loss: [0.22454036 0.16180428 0.17048181], max_reward_err:  0.1303, max_reward_err_index: 0, max_kl_dist:  2.0894, max_kl_dist_index: 0, max_train_grp_loss:  23.5766, max_train_grp_loss_index: 0, max_val_grp_loss:  24.4957, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2245, max_cur_train_grp_loss_index: 0, 
2024-09-18 00:19:11,798 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:386] - INFO: Policy parameter learned solely on the preference data rdpo: [14.84290938  3.45085234  6.15341435  1.3401927 ].
2024-09-18 00:19:12,117 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:397] - INFO: Uniform reward: 3.8827, 3.8827, 3.2643
2024-09-18 00:19:12,118 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Optimal reward: 3.9217, 3.9217, 3.3993
2024-09-18 00:19:12,118 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Policy reward: 3.4109, 3.9066, 3.0950
2024-09-18 00:19:12,119 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Reward Error: 0.1303, 0.0038, 0.0895
2024-09-18 00:19:12,788 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:415] - INFO: Optimal reward: 3.9217, 3.9217, 3.3993
Known param reward: [[3.9217183589935303, 3.5069820880889893, 3.3640332221984863], [3.5069820880889893, 3.9217183589935303, 3.1911284923553467], [3.880511999130249, 3.6409873962402344, 3.399339199066162]], Known param reward error: [[0.0, 0.10575371124074777, 0.010386129421087117], [0.10575371124074777, 0.0, 0.06125034735221873], [0.01050722058323853, 0.07158366232738414, 0.0]].
