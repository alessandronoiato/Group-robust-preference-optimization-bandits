2024-09-18 00:19:24,367 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:198] - INFO: Logging to log_rdpo/2024_09_18_00_15_00/swapped_noise0.3_[0.3,0.3,1]_2025
2024-09-18 00:19:24,369 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: (IB) Seed: 2025
2024-09-18 00:19:24,370 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Data: 300
2024-09-18 00:19:24,540 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:296] - INFO: MLE reward loss: 0.5538, l2 distance: 8.9714, acc: 0.73.
2024-09-18 00:19:24,541 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-18 00:19:24,542 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: MLE reward parameter: [5.6201857  2.02979985 4.80944882 3.0171891 ]
2024-09-18 00:19:24,757 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:313] - INFO: Learned oracle reward: 3.5606, 3.8633, 3.1831
2024-09-18 00:19:25,016 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-18 00:19:26,221 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  19.2349, val_loss:  19.5069, grad_norm: 0.2054, live_grad: 0.0000, reward_err: 0.0885, 0.0014, 0.0498, KL_dist: 1.2188, 0.5803, 0.9546, param: [9.33280122 2.893675   8.38609341 4.57877665], weights: [0.33346112 0.33316192 0.33337696], train_wt_loss:  57.7047, val_wt_loss: 58.5207, train_grp_loss: [23.30704048 15.53230512 19.60960805], val_grp_loss: [23.66777871 16.7809564  18.43828925], train_hist_grp_loss: [0.2641278  0.17436394 0.23888667], cur_train_grp_loss: [0.2641278  0.17436394 0.23888667], max_reward_err:  0.0885, max_reward_err_index: 0, max_kl_dist:  1.2188, max_kl_dist_index: 0, max_train_grp_loss:  23.3070, max_train_grp_loss_index: 0, max_val_grp_loss:  23.6678, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2641, max_cur_train_grp_loss_index: 0, 
2024-09-18 00:19:30,481 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  99, train_loss:  19.2373, val_loss:  19.5002, grad_norm: 0.0056,  live_grad: 0.0000, reward_err: 0.0874, 0.0022, 0.0490, KL_dist: 1.2253, 0.5924, 0.9635, param: [9.57992076 3.04296119 8.1836444  4.703929  ], weights: [0.35156254 0.31429234 0.33414512], train_wt_loss:  57.7118, val_wt_loss: 58.5007, train_grp_loss: [23.21780298 15.67719176 19.53577098], val_grp_loss: [23.63536209 16.91540894 18.31180761], train_hist_grp_loss: [25.29688531 14.09048166 20.21566478], cur_train_grp_loss: [0.25237715 0.14122218 0.20140748], max_reward_err:  0.0874, max_reward_err_index: 0, max_kl_dist:  1.2253, max_kl_dist_index: 0, max_train_grp_loss:  23.2178, max_train_grp_loss_index: 0, max_val_grp_loss:  23.6354, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2524, max_cur_train_grp_loss_index: 0, 
2024-09-18 00:19:30,699 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:386] - INFO: Policy parameter learned solely on the preference data rdpo: [9.57992076 3.04296119 8.1836444  4.703929  ].
2024-09-18 00:19:31,018 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:397] - INFO: Uniform reward: 3.8385, 3.8385, 3.1882
2024-09-18 00:19:31,018 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Optimal reward: 3.8795, 3.8795, 3.3318
2024-09-18 00:19:31,019 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Policy reward: 3.5406, 3.8709, 3.1687
2024-09-18 00:19:31,019 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Reward Error: 0.0874, 0.0022, 0.0490
2024-09-18 00:19:31,689 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:415] - INFO: Optimal reward: 3.8795, 3.8795, 3.3318
Known param reward: [[3.87953782081604, 3.4939897060394287, 3.290055751800537], [3.4939897060394287, 3.87953782081604, 3.1354916095733643], [3.8410425186157227, 3.6315650939941406, 3.3318350315093994]], Known param reward error: [[0.0, 0.09937990878911275, 0.01253942026353427], [0.09937990878911275, 0.0, 0.058929514840681346], [0.009922651609108454, 0.06391811042319977, 0.0]].
