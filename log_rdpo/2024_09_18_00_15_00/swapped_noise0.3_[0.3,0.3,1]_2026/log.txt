2024-09-18 00:19:42,209 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:198] - INFO: Logging to log_rdpo/2024_09_18_00_15_00/swapped_noise0.3_[0.3,0.3,1]_2026
2024-09-18 00:19:42,211 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: (IB) Seed: 2026
2024-09-18 00:19:42,211 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Data: 300
2024-09-18 00:19:42,376 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:296] - INFO: MLE reward loss: 0.5758, l2 distance: 8.1084, acc: 0.74.
2024-09-18 00:19:42,377 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-18 00:19:42,378 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: MLE reward parameter: [3.90195514 2.43903435 5.63229133 2.65737389]
2024-09-18 00:19:42,583 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:313] - INFO: Learned oracle reward: 3.5354, 3.8444, 3.1588
2024-09-18 00:19:42,836 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-18 00:19:43,972 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  20.0512, val_loss:  20.1795, grad_norm: 0.1480, live_grad: 0.0000, reward_err: 0.0940, 0.0047, 0.0534, KL_dist: 1.1775, 0.5423, 0.9440, param: [ 6.66489748  3.7075297  10.37893983  4.40965744], weights: [0.33333699 0.33331264 0.33335037], train_wt_loss:  60.1536, val_wt_loss: 60.5384, train_grp_loss: [22.03190437 19.80707019 18.10103851], val_grp_loss: [24.35572543 17.35544383 18.69896542], train_hist_grp_loss: [0.2214597  0.21415516 0.2254739 ], cur_train_grp_loss: [0.2214597  0.21415516 0.2254739 ], max_reward_err:  0.0940, max_reward_err_index: 0, max_kl_dist:  1.1775, max_kl_dist_index: 0, max_train_grp_loss:  22.0319, max_train_grp_loss_index: 0, max_val_grp_loss:  24.3557, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2255, max_cur_train_grp_loss_index: 2, 
2024-09-18 00:19:48,303 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  99, train_loss:  20.0512, val_loss:  20.1805, grad_norm: 0.0002,  live_grad: 0.0000, reward_err: 0.0940, 0.0047, 0.0534, KL_dist: 1.1782, 0.5425, 0.9449, param: [ 6.64964011  3.71167874 10.38997996  4.41390146], weights: [0.33675049 0.3321897  0.33105981], train_wt_loss:  60.1536, val_wt_loss: 60.5416, train_grp_loss: [22.03014039 19.80906921 18.10087435], val_grp_loss: [24.35594178 17.35947566 18.69777907], train_hist_grp_loss: [20.99357629 19.62996804 19.28925314], cur_train_grp_loss: [0.20981103 0.19612919 0.19256251], max_reward_err:  0.0940, max_reward_err_index: 0, max_kl_dist:  1.1782, max_kl_dist_index: 0, max_train_grp_loss:  22.0301, max_train_grp_loss_index: 0, max_val_grp_loss:  24.3559, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2098, max_cur_train_grp_loss_index: 0, 
2024-09-18 00:19:48,526 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:386] - INFO: Policy parameter learned solely on the preference data rdpo: [ 6.64964011  3.71167874 10.38997996  4.41390146].
2024-09-18 00:19:48,856 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:397] - INFO: Uniform reward: 3.8317, 3.8317, 3.1908
2024-09-18 00:19:48,856 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Optimal reward: 3.8697, 3.8697, 3.3127
2024-09-18 00:19:48,857 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Policy reward: 3.5062, 3.8515, 3.1357
2024-09-18 00:19:48,857 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Reward Error: 0.0940, 0.0047, 0.0534
2024-09-18 00:19:49,535 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:415] - INFO: Optimal reward: 3.8697, 3.8697, 3.3127
Known param reward: [[3.8697431087493896, 3.4774062633514404, 3.2797791957855225], [3.4774062633514404, 3.8697431087493896, 3.122826337814331], [3.8267757892608643, 3.597029209136963, 3.3126978874206543]], Known param reward error: [[0.0, 0.10138575982237315, 0.009937124589638663], [0.10138575982237315, 0.0, 0.05731628903659602], [0.01110340358029901, 0.07047338594539458, 0.0]].
