2024-09-18 00:18:28,724 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:198] - INFO: Logging to log_rdpo/2024_09_18_00_15_00/swapped_noise0.3_[0.3,0.3,1]_2022
2024-09-18 00:18:28,726 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: (IB) Seed: 2022
2024-09-18 00:18:28,727 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Data: 300
2024-09-18 00:18:28,889 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:296] - INFO: MLE reward loss: 0.5715, l2 distance: 8.0527, acc: 0.72.
2024-09-18 00:18:28,890 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-18 00:18:28,891 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: MLE reward parameter: [4.81498563 2.05087294 4.78941324 3.20789022]
2024-09-18 00:18:29,101 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:313] - INFO: Learned oracle reward: 3.5711, 3.8350, 3.2052
2024-09-18 00:18:29,354 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-18 00:18:30,551 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  19.8992, val_loss:  19.9600, grad_norm: 0.1722, live_grad: 0.0000, reward_err: 0.0820, 0.0061, 0.0426, KL_dist: 1.0854, 0.5570, 0.8494, param: [8.57744832 2.96599629 8.37138392 5.32962028], weights: [0.3334163  0.33327444 0.33330926], train_wt_loss:  59.6976, val_wt_loss: 59.8799, train_grp_loss: [24.63259972 16.63972937 18.6253765 ], val_grp_loss: [24.12601327 16.63244985 19.16015029], train_hist_grp_loss: [0.2496904  0.20713322 0.21758038], cur_train_grp_loss: [0.2496904  0.20713322 0.21758038], max_reward_err:  0.0820, max_reward_err_index: 0, max_kl_dist:  1.0854, max_kl_dist_index: 0, max_train_grp_loss:  24.6326, max_train_grp_loss_index: 0, max_val_grp_loss:  24.1260, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2497, max_cur_train_grp_loss_index: 0, 
2024-09-18 00:18:34,864 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  99, train_loss:  19.8996, val_loss:  19.9556, grad_norm: 0.0028,  live_grad: 0.0000, reward_err: 0.0820, 0.0066, 0.0426, KL_dist: 1.0750, 0.5568, 0.8419, param: [8.57356618 3.02044198 8.29150527 5.38223126], weights: [0.35125658 0.32154352 0.3271999 ], train_wt_loss:  59.6989, val_wt_loss: 59.8668, train_grp_loss: [24.6091803  16.6870952  18.60198342], val_grp_loss: [24.10911194 16.66120248 19.136466  ], train_hist_grp_loss: [25.37845882 16.54005346 18.2838941 ], cur_train_grp_loss: [0.2537054  0.16521385 0.18237469], max_reward_err:  0.0820, max_reward_err_index: 0, max_kl_dist:  1.0750, max_kl_dist_index: 0, max_train_grp_loss:  24.6092, max_train_grp_loss_index: 0, max_val_grp_loss:  24.1091, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2537, max_cur_train_grp_loss_index: 0, 
2024-09-18 00:18:35,086 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:386] - INFO: Policy parameter learned solely on the preference data rdpo: [8.57356618 3.02044198 8.29150527 5.38223126].
2024-09-18 00:18:35,414 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:397] - INFO: Uniform reward: 3.8313, 3.8313, 3.1994
2024-09-18 00:18:35,415 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Optimal reward: 3.8668, 3.8668, 3.3324
2024-09-18 00:18:35,415 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Policy reward: 3.5497, 3.8413, 3.1904
2024-09-18 00:18:35,416 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Reward Error: 0.0820, 0.0066, 0.0426
2024-09-18 00:18:36,094 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:415] - INFO: Optimal reward: 3.8668, 3.8668, 3.3324
Known param reward: [[3.8668389320373535, 3.4814906120300293, 3.3017218112945557], [3.4814906120300293, 3.8668389320373535, 3.141117572784424], [3.833250045776367, 3.5895702838897705, 3.332355499267578]], Known param reward error: [[0.0, 0.09965460852652908, 0.009192803102716824], [0.09965460852652908, 0.0, 0.05738821278977788], [0.008686393938650316, 0.07170421448133506, 0.0]].
