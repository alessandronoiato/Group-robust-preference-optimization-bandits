2024-09-18 00:20:22,008 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:198] - INFO: Logging to log_rdpo/2024_09_18_00_15_00/swapped_noise0.3_[0.3,0.3,1]_2028
2024-09-18 00:20:22,010 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: (IB) Seed: 2028
2024-09-18 00:20:22,011 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Data: 300
2024-09-18 00:20:22,174 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:296] - INFO: MLE reward loss: 0.6022, l2 distance: 6.5058, acc: 0.70.
2024-09-18 00:20:22,175 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-18 00:20:22,176 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: MLE reward parameter: [4.32841582 2.65008307 3.99886397 2.4333316 ]
2024-09-18 00:20:22,380 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:313] - INFO: Learned oracle reward: 3.6247, 3.8508, 3.2489
2024-09-18 00:20:22,628 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-18 00:20:23,783 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  21.0299, val_loss:  21.1829, grad_norm: 0.1416, live_grad: 0.0000, reward_err: 0.0797, 0.0072, 0.0432, KL_dist: 0.9721, 0.5164, 0.7627, param: [8.70224736 4.71279404 7.37952533 4.19893744], weights: [0.33324645 0.33339903 0.33335453], train_wt_loss:  63.0898, val_wt_loss: 63.5486, train_grp_loss: [24.64256799 19.9289752  17.39455325], val_grp_loss: [24.02030298 20.89547226 18.364227  ], train_hist_grp_loss: [0.20243007 0.24820602 0.23485712], cur_train_grp_loss: [0.20243007 0.24820602 0.23485712], max_reward_err:  0.0797, max_reward_err_index: 0, max_kl_dist:  0.9721, max_kl_dist_index: 0, max_train_grp_loss:  24.6426, max_train_grp_loss_index: 0, max_val_grp_loss:  24.0203, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2482, max_cur_train_grp_loss_index: 1, 
2024-09-18 00:20:28,154 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  99, train_loss:  21.0301, val_loss:  21.1704, grad_norm: 0.0016,  live_grad: 0.0000, reward_err: 0.0802, 0.0070, 0.0436, KL_dist: 0.9650, 0.5080, 0.7558, param: [8.65717907 4.66638437 7.34984491 4.14731118], weights: [0.3334065  0.33822821 0.32836529], train_wt_loss:  63.0904, val_wt_loss: 63.5111, train_grp_loss: [24.64859297 19.87760008 17.43818313], val_grp_loss: [24.0249474  20.81114135 18.40609088], train_hist_grp_loss: [20.70589031 22.14172758 19.18231236], cur_train_grp_loss: [0.20713053 0.22086776 0.19162367], max_reward_err:  0.0802, max_reward_err_index: 0, max_kl_dist:  0.9650, max_kl_dist_index: 0, max_train_grp_loss:  24.6486, max_train_grp_loss_index: 0, max_val_grp_loss:  24.0249, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2209, max_cur_train_grp_loss_index: 1, 
2024-09-18 00:20:28,374 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:386] - INFO: Policy parameter learned solely on the preference data rdpo: [8.65717907 4.66638437 7.34984491 4.14731118].
2024-09-18 00:20:28,703 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:397] - INFO: Uniform reward: 3.8548, 3.8548, 3.2274
2024-09-18 00:20:28,703 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Optimal reward: 3.8897, 3.8897, 3.3617
2024-09-18 00:20:28,704 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Policy reward: 3.5776, 3.8623, 3.2151
2024-09-18 00:20:28,704 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Reward Error: 0.0802, 0.0070, 0.0436
2024-09-18 00:20:29,373 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:415] - INFO: Optimal reward: 3.8897, 3.8897, 3.3617
Known param reward: [[3.8896820545196533, 3.4789624214172363, 3.324706554412842], [3.4789624214172363, 3.8896820545196533, 3.1460585594177246], [3.855863332748413, 3.632194757461548, 3.3616816997528076]], Known param reward error: [[0.0, 0.10559208370904696, 0.010999002476256063], [0.10559208370904696, 0.0, 0.06414145049810584], [0.00869446944434552, 0.06619751780455053, 0.0]].
