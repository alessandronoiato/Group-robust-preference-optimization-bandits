2024-09-18 00:18:09,626 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:198] - INFO: Logging to log_rdpo/2024_09_18_00_15_00/swapped_noise0.3_[0.3,0.3,1]_2021
2024-09-18 00:18:09,628 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: (IB) Seed: 2021
2024-09-18 00:18:09,628 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Data: 300
2024-09-18 00:18:09,791 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:296] - INFO: MLE reward loss: 0.5559, l2 distance: 8.3136, acc: 0.74.
2024-09-18 00:18:09,792 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-18 00:18:09,793 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: MLE reward parameter: [5.10539332 2.88196166 4.8068994  2.46605186]
2024-09-18 00:18:09,995 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:313] - INFO: Learned oracle reward: 3.5067, 3.7788, 3.1290
2024-09-18 00:18:10,248 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-18 00:18:11,426 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  19.3518, val_loss:  19.0342, grad_norm: 0.1653, live_grad: 0.0000, reward_err: 0.0877, 0.0023, 0.0495, KL_dist: 1.0916, 0.5200, 0.8535, param: [9.40349723 4.13633024 7.62429721 3.55999358], weights: [0.3334157  0.33319912 0.33338519], train_wt_loss:  58.0555, val_wt_loss: 57.1025, train_grp_loss: [24.37546259 15.22330566 18.6269274 ], val_grp_loss: [23.77924351 15.21556798 18.30633724], train_hist_grp_loss: [0.24135546 0.17637583 0.23220454], cur_train_grp_loss: [0.24135546 0.17637583 0.23220454], max_reward_err:  0.0877, max_reward_err_index: 0, max_kl_dist:  1.0916, max_kl_dist_index: 0, max_train_grp_loss:  24.3755, max_train_grp_loss_index: 0, max_val_grp_loss:  23.7792, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2414, max_cur_train_grp_loss_index: 0, 
2024-09-18 00:18:15,734 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  99, train_loss:  19.3527, val_loss:  19.0361, grad_norm: 0.0041,  live_grad: 0.0000, reward_err: 0.0867, 0.0025, 0.0488, KL_dist: 1.0878, 0.5252, 0.8524, param: [9.43950906 4.22140146 7.56001605 3.65612259], weights: [0.3496039  0.31697182 0.33342428], train_wt_loss:  58.0580, val_wt_loss: 57.1084, train_grp_loss: [24.3478758  15.29111202 18.58365138], val_grp_loss: [23.75806479 15.29364765 18.25353005], train_hist_grp_loss: [24.35966864 14.56087765 19.62117076], cur_train_grp_loss: [0.24348162 0.14562278 0.19562202], max_reward_err:  0.0867, max_reward_err_index: 0, max_kl_dist:  1.0878, max_kl_dist_index: 0, max_train_grp_loss:  24.3479, max_train_grp_loss_index: 0, max_val_grp_loss:  23.7581, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2435, max_cur_train_grp_loss_index: 0, 
2024-09-18 00:18:15,954 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:386] - INFO: Policy parameter learned solely on the preference data rdpo: [9.43950906 4.22140146 7.56001605 3.65612259].
2024-09-18 00:18:16,276 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:397] - INFO: Uniform reward: 3.7677, 3.7677, 3.1326
2024-09-18 00:18:16,277 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Optimal reward: 3.8011, 3.8011, 3.2596
2024-09-18 00:18:16,278 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Policy reward: 3.4715, 3.7917, 3.1006
2024-09-18 00:18:16,278 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Reward Error: 0.0867, 0.0025, 0.0488
2024-09-18 00:18:16,961 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:415] - INFO: Optimal reward: 3.8011, 3.8011, 3.2596
Known param reward: [[3.801053285598755, 3.4089272022247314, 3.2255265712738037], [3.4089272022247314, 3.801053285598755, 3.0588371753692627], [3.766353130340576, 3.5368399620056152, 3.259605646133423]], Known param reward error: [[0.0, 0.10316247995251517, 0.010454968655501037], [0.10316247995251517, 0.0, 0.06159287121198656], [0.009129089399943158, 0.0695105550333057, 0.0]].
