2024-09-18 20:41:10,244 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log_rdpo/2024_09_18_20_28_18/swapped_noise0.5_[1,0.5,1]_2029
2024-09-18 20:41:10,246 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2029
2024-09-18 20:41:10,247 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-09-18 20:41:10,416 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.4622, l2 distance: 15.7048, acc: 0.76.
2024-09-18 20:41:10,417 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-18 20:41:10,417 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [8.03172364 3.1446329  7.65537172 4.62681821]
2024-09-18 20:41:10,629 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.5601, 3.8681, 3.2290
2024-09-18 20:41:10,884 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-18 20:41:12,245 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  16.4040, val_loss:  17.5210, grad_norm: 0.3206, live_grad: 0.0000, reward_err: 0.0962, 0.0016, 0.0532, KL_dist: 1.5419, 0.7815, 1.2293, param: [10.12436873  3.42862438 10.69670686  4.87627053], weights: [0.33292097 0.3328229  0.33425613], train_wt_loss:  49.2120, val_wt_loss: 52.5630, train_grp_loss: [21.5789782  10.58351061 18.57692245], val_grp_loss: [19.84969821 14.27319565 17.99737206], train_hist_grp_loss: [0.18855987 0.15909634 0.58880221], cur_train_grp_loss: [0.18855987 0.15909634 0.58880221], max_reward_err:  0.0962, max_reward_err_index: 0, max_kl_dist:  1.5419, max_kl_dist_index: 0, max_train_grp_loss:  21.5790, max_train_grp_loss_index: 0, max_val_grp_loss:  19.8497, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.5888, max_cur_train_grp_loss_index: 2, 
2024-09-18 20:41:16,801 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  99, train_loss:  16.4141, val_loss:  17.4787, grad_norm: 0.0194,  live_grad: 0.0000, reward_err: 0.0922, 0.0020, 0.0500, KL_dist: 1.5490, 0.8068, 1.2411, param: [10.02249721  3.68626602 10.91177602  5.18433871], weights: [0.30771925 0.28303017 0.40925058], train_wt_loss:  49.2424, val_wt_loss: 52.4361, train_grp_loss: [21.39277699 10.86047015 18.35890339], val_grp_loss: [19.66211693 14.56765693 17.80895632], train_hist_grp_loss: [16.68046771  8.31703356 45.19444667], cur_train_grp_loss: [0.16585133 0.08351654 0.44783791], max_reward_err:  0.0922, max_reward_err_index: 0, max_kl_dist:  1.5490, max_kl_dist_index: 0, max_train_grp_loss:  21.3928, max_train_grp_loss_index: 0, max_val_grp_loss:  19.6621, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4478, max_cur_train_grp_loss_index: 2, 
2024-09-18 20:41:17,030 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:387] - INFO: Policy parameter learned solely on the preference data rdpo: [10.02249721  3.68626602 10.91177602  5.18433871].
2024-09-18 20:41:17,368 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Uniform reward: 3.8386, 3.8386, 3.2274
2024-09-18 20:41:17,369 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Optimal reward: 3.8850, 3.8850, 3.3731
2024-09-18 20:41:17,370 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Policy reward: 3.5269, 3.8772, 3.2046
2024-09-18 20:41:17,370 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Reward Error: 0.0922, 0.0020, 0.0500
2024-09-18 20:41:18,064 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:416] - INFO: Optimal reward: 3.8850, 3.8850, 3.3731
Known param reward: [[3.8849852085113525, 3.4774763584136963, 3.335669994354248], [3.4774763584136963, 3.8849852085113525, 3.1690282821655273], [3.8491885662078857, 3.6059226989746094, 3.3731210231781006]], Known param reward error: [[0.0, 0.10489328227167315, 0.011102782428057319], [0.10489328227167315, 0.0, 0.06050560878491111], [0.009214100024124247, 0.07183103527018941, 0.0]].
