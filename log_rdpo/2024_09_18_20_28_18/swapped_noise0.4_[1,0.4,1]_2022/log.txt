2024-09-18 20:42:12,740 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log_rdpo/2024_09_18_20_28_18/swapped_noise0.4_[1,0.4,1]_2022
2024-09-18 20:42:12,742 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2022
2024-09-18 20:42:12,742 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-09-18 20:42:12,907 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.4879, l2 distance: 12.6795, acc: 0.82.
2024-09-18 20:42:12,908 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-18 20:42:12,909 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [6.75502214 3.97653476 5.79379738 4.90833845]
2024-09-18 20:42:13,124 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.6743, 3.8038, 3.2594
2024-09-18 20:42:13,380 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-18 20:42:14,701 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  17.1514, val_loss:  17.7455, grad_norm: 0.2542, live_grad: 0.0000, reward_err: 0.0636, 0.0097, 0.0306, KL_dist: 1.2285, 0.7577, 1.0091, param: [9.99149194 4.76684771 8.56675988 6.00516223], weights: [0.33301681 0.33298503 0.33399815], train_wt_loss:  51.4541, val_wt_loss: 53.2364, train_grp_loss: [17.67154529 17.33300434 15.28044946], val_grp_loss: [19.60319601 16.1986018  17.48029634], train_hist_grp_loss: [0.17688021 0.16733739 0.47112971], cur_train_grp_loss: [0.17688021 0.16733739 0.47112971], max_reward_err:  0.0636, max_reward_err_index: 0, max_kl_dist:  1.2285, max_kl_dist_index: 0, max_train_grp_loss:  17.6715, max_train_grp_loss_index: 0, max_val_grp_loss:  19.6032, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4711, max_cur_train_grp_loss_index: 2, 
2024-09-18 20:42:19,211 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  99, train_loss:  17.1537, val_loss:  17.7407, grad_norm: 0.0067,  live_grad: 0.0000, reward_err: 0.0639, 0.0097, 0.0309, KL_dist: 1.2659, 0.7848, 1.0431, param: [10.23411945  4.83401334  8.63914563  6.1161601 ], weights: [0.31316889 0.31088495 0.37594616], train_wt_loss:  51.4611, val_wt_loss: 53.2221, train_grp_loss: [17.58463402 17.47016623 15.14810492], val_grp_loss: [19.53741288 16.34606762 17.37714966], train_hist_grp_loss: [14.25187314 13.51989966 32.52220423], cur_train_grp_loss: [0.14181901 0.1354159  0.32233012], max_reward_err:  0.0639, max_reward_err_index: 0, max_kl_dist:  1.2659, max_kl_dist_index: 0, max_train_grp_loss:  17.5846, max_train_grp_loss_index: 0, max_val_grp_loss:  19.5374, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.3223, max_cur_train_grp_loss_index: 2, 
2024-09-18 20:42:19,437 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:387] - INFO: Policy parameter learned solely on the preference data rdpo: [10.23411945  4.83401334  8.63914563  6.1161601 ].
2024-09-18 20:42:19,771 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Uniform reward: 3.8352, 3.8352, 3.1931
2024-09-18 20:42:19,772 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Optimal reward: 3.8672, 3.8672, 3.3262
2024-09-18 20:42:19,772 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Policy reward: 3.6202, 3.8299, 3.2232
2024-09-18 20:42:19,773 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Reward Error: 0.0639, 0.0097, 0.0309
2024-09-18 20:42:20,464 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:416] - INFO: Optimal reward: 3.8672, 3.8672, 3.3262
Known param reward: [[3.867177724838257, 3.538572311401367, 3.2763869762420654], [3.538572311401367, 3.867177724838257, 3.1662933826446533], [3.823817253112793, 3.633922815322876, 3.3261606693267822]], Known param reward error: [[0.0, 0.08497292775718847, 0.01496430811166769], [0.08497292775718847, 0.0, 0.04806360924064627], [0.011212433151692661, 0.060316573509725795, 0.0]].
