2024-09-18 20:40:10,824 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log_rdpo/2024_09_18_20_28_18/swapped_noise0.5_[1,0.5,1]_2026
2024-09-18 20:40:10,826 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2026
2024-09-18 20:40:10,826 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-09-18 20:40:10,991 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.5028, l2 distance: 11.6904, acc: 0.77.
2024-09-18 20:40:10,992 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-18 20:40:10,993 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [6.16271418 4.47849874 6.01550773 3.20945473]
2024-09-18 20:40:11,198 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.6186, 3.8173, 3.2213
2024-09-18 20:40:11,456 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-18 20:40:12,803 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  17.6861, val_loss:  17.8656, grad_norm: 0.2223, live_grad: 0.0000, reward_err: 0.0762, 0.0107, 0.0374, KL_dist: 1.1136, 0.6401, 0.8977, param: [9.65656759 5.69993365 7.75644869 4.07831669], weights: [0.33299854 0.33296988 0.33403158], train_wt_loss:  53.0582, val_wt_loss: 53.5969, train_grp_loss: [19.8299216  14.60559803 18.92874388], val_grp_loss: [19.72685755 16.00852711 17.6163457 ], train_hist_grp_loss: [0.1635404  0.15493322 0.47328458], cur_train_grp_loss: [0.1635404  0.15493322 0.47328458], max_reward_err:  0.0762, max_reward_err_index: 0, max_kl_dist:  1.1136, max_kl_dist_index: 0, max_train_grp_loss:  19.8299, max_train_grp_loss_index: 0, max_val_grp_loss:  19.7269, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4733, max_cur_train_grp_loss_index: 2, 
2024-09-18 20:40:17,297 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  99, train_loss:  17.6894, val_loss:  17.8690, grad_norm: 0.0097,  live_grad: 0.0000, reward_err: 0.0780, 0.0116, 0.0393, KL_dist: 1.1430, 0.6652, 0.9270, param: [9.94784678 5.85209668 7.64878082 4.20064196], weights: [0.30489888 0.3001961  0.39490503], train_wt_loss:  53.0683, val_wt_loss: 53.6071, train_grp_loss: [19.73072578 14.78290976 18.80757255], val_grp_loss: [19.63285917 16.23594539 17.51852309], train_hist_grp_loss: [14.35510242 12.8006768  40.22161547], cur_train_grp_loss: [0.14298414 0.12852935 0.40018931], max_reward_err:  0.0780, max_reward_err_index: 0, max_kl_dist:  1.1430, max_kl_dist_index: 0, max_train_grp_loss:  19.7307, max_train_grp_loss_index: 0, max_val_grp_loss:  19.6329, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4002, max_cur_train_grp_loss_index: 2, 
2024-09-18 20:40:17,521 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:387] - INFO: Policy parameter learned solely on the preference data rdpo: [9.94784678 5.85209668 7.64878082 4.20064196].
2024-09-18 20:40:17,856 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Uniform reward: 3.8450, 3.8450, 3.2027
2024-09-18 20:40:17,857 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Optimal reward: 3.8809, 3.8809, 3.3197
2024-09-18 20:40:17,858 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Policy reward: 3.5783, 3.8360, 3.1891
2024-09-18 20:40:17,858 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Reward Error: 0.0780, 0.0116, 0.0393
2024-09-18 20:40:18,551 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:416] - INFO: Optimal reward: 3.8809, 3.8809, 3.3197
Known param reward: [[3.880918025970459, 3.483751058578491, 3.287625551223755], [3.483751058578491, 3.880918025970459, 3.126237392425537], [3.8381175994873047, 3.608170986175537, 3.319674015045166]], Known param reward error: [[0.0, 0.10233840672083058, 0.009654099672486998], [0.10233840672083058, 0.0, 0.05826976436329309], [0.011028428376157638, 0.07027900047611002, 0.0]].
