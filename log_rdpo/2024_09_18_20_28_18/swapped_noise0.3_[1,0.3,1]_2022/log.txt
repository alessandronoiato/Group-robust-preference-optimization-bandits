2024-09-18 20:45:48,571 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log_rdpo/2024_09_18_20_28_18/swapped_noise0.3_[1,0.3,1]_2022
2024-09-18 20:45:48,572 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2022
2024-09-18 20:45:48,573 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-09-18 20:45:48,739 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.5114, l2 distance: 13.3000, acc: 0.75.
2024-09-18 20:45:48,739 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-18 20:45:48,740 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [2.3431996  2.79147837 9.27451545 2.39716811]
2024-09-18 20:45:48,953 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.4661, 3.8464, 3.0767
2024-09-18 20:45:49,193 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-18 20:45:50,527 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  17.4756, val_loss:  18.4026, grad_norm: 0.2638, live_grad: 0.0000, reward_err: 0.1177, 0.0049, 0.0887, KL_dist: 2.2143, 0.7588, 1.9385, param: [ 3.45565867  3.57122712 16.50368624  3.72699273], weights: [0.33299736 0.33297368 0.33402896], train_wt_loss:  52.4267, val_wt_loss: 55.2077, train_grp_loss: [19.21014254 16.37026226 15.93300156], val_grp_loss: [21.59703169 15.26514037 18.3549797 ], train_hist_grp_loss: [0.18662452 0.17951476 0.49594058], cur_train_grp_loss: [0.18662452 0.17951476 0.49594058], max_reward_err:  0.1177, max_reward_err_index: 0, max_kl_dist:  2.2143, max_kl_dist_index: 0, max_train_grp_loss:  19.2101, max_train_grp_loss_index: 0, max_val_grp_loss:  21.5970, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4959, max_cur_train_grp_loss_index: 2, 
2024-09-18 20:45:55,057 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  99, train_loss:  17.4785, val_loss:  18.3910, grad_norm: 0.0080,  live_grad: 0.0000, reward_err: 0.1169, 0.0049, 0.0882, KL_dist: 2.2646, 0.7862, 1.9867, param: [ 3.47512527  3.68822707 16.77195005  3.84958567], weights: [0.31486748 0.30650727 0.37862525], train_wt_loss:  52.4354, val_wt_loss: 55.1729, train_grp_loss: [19.11528645 16.51469339 15.80536628], val_grp_loss: [21.53814183 15.38068697 18.26308552], train_hist_grp_loss: [15.48686351 12.79582717 33.92637104], cur_train_grp_loss: [0.15416363 0.12800846 0.33631335], max_reward_err:  0.1169, max_reward_err_index: 0, max_kl_dist:  2.2646, max_kl_dist_index: 0, max_train_grp_loss:  19.1153, max_train_grp_loss_index: 0, max_val_grp_loss:  21.5381, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.3363, max_cur_train_grp_loss_index: 2, 
2024-09-18 20:45:55,292 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:387] - INFO: Policy parameter learned solely on the preference data rdpo: [ 3.47512527  3.68822707 16.77195005  3.84958567].
2024-09-18 20:45:55,631 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Uniform reward: 3.8377, 3.8377, 3.1941
2024-09-18 20:45:55,632 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Optimal reward: 3.8690, 3.8690, 3.3258
2024-09-18 20:45:55,632 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Policy reward: 3.4165, 3.8501, 3.0325
2024-09-18 20:45:55,633 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Reward Error: 0.1169, 0.0049, 0.0882
2024-09-18 20:45:56,336 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:416] - INFO: Optimal reward: 3.8690, 3.8690, 3.3258
Known param reward: [[3.8689613342285156, 3.540985584259033, 3.2756898403167725], [3.540985584259033, 3.8689613342285156, 3.1665854454040527], [3.825187921524048, 3.636335849761963, 3.3258354663848877]], Known param reward error: [[0.0, 0.08477100741945821, 0.01507760277829452], [0.08477100741945821, 0.0, 0.04788271175481099], [0.011313995908205773, 0.060126081490793466, 0.0]].
