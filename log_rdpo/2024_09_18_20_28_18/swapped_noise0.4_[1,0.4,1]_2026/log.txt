2024-09-18 20:43:42,245 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log_rdpo/2024_09_18_20_28_18/swapped_noise0.4_[1,0.4,1]_2026
2024-09-18 20:43:42,247 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2026
2024-09-18 20:43:42,247 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-09-18 20:43:42,411 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.5431, l2 distance: 9.5009, acc: 0.73.
2024-09-18 20:43:42,412 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-18 20:43:42,412 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [4.34794473 3.37466145 6.23728494 2.01628827]
2024-09-18 20:43:42,620 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.5407, 3.8522, 3.1577
2024-09-18 20:43:42,880 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-18 20:43:44,292 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  18.8425, val_loss:  17.5731, grad_norm: 0.2047, live_grad: 0.0000, reward_err: 0.0886, 0.0037, 0.0478, KL_dist: 1.1731, 0.5920, 0.9352, param: [ 7.63982476  5.13463384 10.09126223  3.13031451], weights: [0.33295338 0.33300216 0.33404445], train_wt_loss:  56.5275, val_wt_loss: 52.7193, train_grp_loss: [19.17036459 17.73126625 20.5988375 ], val_grp_loss: [19.1543295  14.11857534 18.94817122], train_hist_grp_loss: [0.16375706 0.17840737 0.49091667], cur_train_grp_loss: [0.16375706 0.17840737 0.49091667], max_reward_err:  0.0886, max_reward_err_index: 0, max_kl_dist:  1.1731, max_kl_dist_index: 0, max_train_grp_loss:  20.5988, max_train_grp_loss_index: 2, max_val_grp_loss:  19.1543, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4909, max_cur_train_grp_loss_index: 2, 
2024-09-18 20:43:48,853 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  99, train_loss:  18.8494, val_loss:  17.5124, grad_norm: 0.0097,  live_grad: 0.0000, reward_err: 0.0863, 0.0044, 0.0452, KL_dist: 1.1502, 0.6074, 0.9134, param: [8.26905153 5.27114526 9.5404997  3.23888454], weights: [0.29734319 0.30244696 0.40020985], train_wt_loss:  56.5483, val_wt_loss: 52.5371, train_grp_loss: [19.02845713 18.04112532 20.30152746], val_grp_loss: [19.08643173 14.21657695 18.75567874], train_hist_grp_loss: [13.86718058 15.56907492 43.57738368], cur_train_grp_loss: [0.13789845 0.1568486  0.43201568], max_reward_err:  0.0863, max_reward_err_index: 0, max_kl_dist:  1.1502, max_kl_dist_index: 0, max_train_grp_loss:  20.3015, max_train_grp_loss_index: 2, max_val_grp_loss:  19.0864, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4320, max_cur_train_grp_loss_index: 2, 
2024-09-18 20:43:49,076 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:387] - INFO: Policy parameter learned solely on the preference data rdpo: [8.26905153 5.27114526 9.5404997  3.23888454].
2024-09-18 20:43:49,409 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Uniform reward: 3.8382, 3.8382, 3.1948
2024-09-18 20:43:49,409 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Optimal reward: 3.8741, 3.8741, 3.3119
2024-09-18 20:43:49,410 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Policy reward: 3.5398, 3.8569, 3.1623
2024-09-18 20:43:49,411 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Reward Error: 0.0863, 0.0044, 0.0452
2024-09-18 20:43:50,090 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:416] - INFO: Optimal reward: 3.8741, 3.8741, 3.3119
Known param reward: [[3.8741025924682617, 3.481130361557007, 3.279806137084961], [3.481130361557007, 3.8741025924682617, 3.1205224990844727], [3.8313021659851074, 3.6054656505584717, 3.3118550777435303]], Known param reward error: [[0.0, 0.10143568001406103, 0.009677035953036107], [0.10143568001406103, 0.0, 0.057772026301772375], [0.011047829906818591, 0.06934172121101123, 0.0]].
