2024-09-18 20:44:03,479 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log_rdpo/2024_09_18_20_28_18/swapped_noise0.4_[1,0.4,1]_2027
2024-09-18 20:44:03,481 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2027
2024-09-18 20:44:03,482 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-09-18 20:44:03,643 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.5246, l2 distance: 10.8519, acc: 0.78.
2024-09-18 20:44:03,643 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-18 20:44:03,644 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [5.8799585  2.6215873  6.27181202 2.45592119]
2024-09-18 20:44:03,846 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.4476, 3.7545, 3.0705
2024-09-18 20:44:04,100 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-18 20:44:05,439 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  18.1707, val_loss:  18.5697, grad_norm: 0.2713, live_grad: 0.0000, reward_err: 0.0902, 0.0004, 0.0533, KL_dist: 1.3892, 0.6756, 1.1033, param: [ 9.20119788  3.82920584 10.47356387  3.55413902], weights: [0.33307979 0.33321209 0.33370812], train_wt_loss:  54.5120, val_wt_loss: 55.7091, train_grp_loss: [18.70112827 17.59697528 18.12901213], val_grp_loss: [19.99453171 17.40707816 18.33487663], train_hist_grp_loss: [0.18238227 0.22209493 0.37084785], cur_train_grp_loss: [0.18238227 0.22209493 0.37084785], max_reward_err:  0.0902, max_reward_err_index: 0, max_kl_dist:  1.3892, max_kl_dist_index: 0, max_train_grp_loss:  18.7011, max_train_grp_loss_index: 0, max_val_grp_loss:  19.9945, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.3708, max_cur_train_grp_loss_index: 2, 
2024-09-18 20:44:09,875 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  99, train_loss:  18.1716, val_loss:  18.5673, grad_norm: 0.0045,  live_grad: 0.0000, reward_err: 0.0888, 0.0004, 0.0521, KL_dist: 1.4015, 0.6894, 1.1149, param: [ 9.30590701  3.90795903 10.50692775  3.63670751], weights: [0.31597383 0.31906691 0.36495926], train_wt_loss:  54.5148, val_wt_loss: 55.7018, train_grp_loss: [18.63625673 17.71147691 18.05845793], val_grp_loss: [19.92886806 17.52610265 18.27105337], train_hist_grp_loss: [14.85132031 15.82546299 29.26395282], cur_train_grp_loss: [0.14791226 0.15812712 0.29127751], max_reward_err:  0.0888, max_reward_err_index: 0, max_kl_dist:  1.4015, max_kl_dist_index: 0, max_train_grp_loss:  18.6363, max_train_grp_loss_index: 0, max_val_grp_loss:  19.9289, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2913, max_cur_train_grp_loss_index: 2, 
2024-09-18 20:44:10,094 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:387] - INFO: Policy parameter learned solely on the preference data rdpo: [ 9.30590701  3.90795903 10.50692775  3.63670751].
2024-09-18 20:44:10,423 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Uniform reward: 3.7233, 3.7233, 3.0838
2024-09-18 20:44:10,424 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Optimal reward: 3.7611, 3.7611, 3.2220
2024-09-18 20:44:10,424 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Policy reward: 3.4270, 3.7594, 3.0541
2024-09-18 20:44:10,425 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Reward Error: 0.0888, 0.0004, 0.0521
2024-09-18 20:44:11,090 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:416] - INFO: Optimal reward: 3.7611, 3.7611, 3.2220
Known param reward: [[3.761061906814575, 3.4177727699279785, 3.179455518722534], [3.4177727699279785, 3.761061906814575, 3.04893159866333], [3.7224037647247314, 3.5345420837402344, 3.2219769954681396]], Known param reward error: [[0.0, 0.0912745244274229, 0.01319732474980855], [0.0912745244274229, 0.0, 0.0537078312626707], [0.010278517888737756, 0.06022762418877369, 0.0]].
