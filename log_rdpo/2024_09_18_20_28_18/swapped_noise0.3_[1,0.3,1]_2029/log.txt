2024-09-18 20:48:09,463 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log_rdpo/2024_09_18_20_28_18/swapped_noise0.3_[1,0.3,1]_2029
2024-09-18 20:48:09,465 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2029
2024-09-18 20:48:09,466 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-09-18 20:48:09,629 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.5113, l2 distance: 10.3776, acc: 0.79.
2024-09-18 20:48:09,630 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-18 20:48:09,631 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [4.3593504  3.3275761  6.76851117 3.1285225 ]
2024-09-18 20:48:09,840 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.5742, 3.8625, 3.2288
2024-09-18 20:48:10,070 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-18 20:48:11,418 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  17.6955, val_loss:  18.3373, grad_norm: 0.1499, live_grad: 0.0000, reward_err: 0.0969, 0.0033, 0.0569, KL_dist: 1.3502, 0.6052, 1.0923, param: [ 6.75039997  4.25063407 11.30946564  4.2375029 ], weights: [0.33300983 0.33292375 0.33406642], train_wt_loss:  53.0864, val_wt_loss: 55.0120, train_grp_loss: [19.67888583 16.09628216 16.52558386], val_grp_loss: [19.50215285 17.09863302 18.25326756], train_hist_grp_loss: [0.16134682 0.13549209 0.47812892], cur_train_grp_loss: [0.16134682 0.13549209 0.47812892], max_reward_err:  0.0969, max_reward_err_index: 0, max_kl_dist:  1.3502, max_kl_dist_index: 0, max_train_grp_loss:  19.6789, max_train_grp_loss_index: 0, max_val_grp_loss:  19.5022, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4781, max_cur_train_grp_loss_index: 2, 
2024-09-18 20:48:15,903 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  99, train_loss:  17.7018, val_loss:  18.3387, grad_norm: 0.0114,  live_grad: 0.0000, reward_err: 0.0979, 0.0037, 0.0586, KL_dist: 1.4130, 0.6331, 1.1551, param: [ 6.47920245  4.41691394 11.79296559  4.42265843], weights: [0.30717242 0.29889483 0.39393276], train_wt_loss:  53.1053, val_wt_loss: 55.0161, train_grp_loss: [19.53588928 16.3319967  16.27423626], val_grp_loss: [19.38521947 17.33495562 18.16338208], train_hist_grp_loss: [15.2104352  12.47869048 40.08753731], cur_train_grp_loss: [0.15145281 0.12561017 0.3969985 ], max_reward_err:  0.0979, max_reward_err_index: 0, max_kl_dist:  1.4130, max_kl_dist_index: 0, max_train_grp_loss:  19.5359, max_train_grp_loss_index: 0, max_val_grp_loss:  19.3852, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.3970, max_cur_train_grp_loss_index: 2, 
2024-09-18 20:48:16,123 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:387] - INFO: Policy parameter learned solely on the preference data rdpo: [ 6.47920245  4.41691394 11.79296559  4.42265843].
2024-09-18 20:48:16,452 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Uniform reward: 3.8485, 3.8485, 3.2335
2024-09-18 20:48:16,453 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Optimal reward: 3.8941, 3.8941, 3.3780
2024-09-18 20:48:16,453 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Policy reward: 3.5128, 3.8796, 3.1801
2024-09-18 20:48:16,454 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Reward Error: 0.0979, 0.0037, 0.0586
2024-09-18 20:48:17,144 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:416] - INFO: Optimal reward: 3.8941, 3.8941, 3.3780
Known param reward: [[3.894106388092041, 3.4839439392089844, 3.341844081878662], [3.4839439392089844, 3.894106388092041, 3.171762704849243], [3.8587565422058105, 3.6140236854553223, 3.3780486583709717]], Known param reward error: [[0.0, 0.10532903007922702, 0.010717600648703753], [0.10532903007922702, 0.0, 0.06106660216706521], [0.009077781232256088, 0.0719247690543833, 0.0]].
