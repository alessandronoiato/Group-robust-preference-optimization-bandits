2024-09-18 20:41:51,843 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log_rdpo/2024_09_18_20_28_18/swapped_noise0.4_[1,0.4,1]_2021
2024-09-18 20:41:51,845 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2021
2024-09-18 20:41:51,845 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-09-18 20:41:52,007 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.4956, l2 distance: 15.3300, acc: 0.80.
2024-09-18 20:41:52,007 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-18 20:41:52,008 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [10.44868047  2.086339    1.4557587   3.20313765]
2024-09-18 20:41:52,218 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.3324, 3.8143, 2.9690
2024-09-18 20:41:52,470 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-18 20:41:53,793 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  17.0769, val_loss:  18.8857, grad_norm: 0.2045, live_grad: 0.0000, reward_err: 0.1380, 0.0045, 0.1075, KL_dist: 2.4862, 0.6791, 2.2142, param: [17.36379508  3.06758964  1.42027249  3.94423669], weights: [0.33305941 0.33303218 0.33390842], train_wt_loss:  51.2306, val_wt_loss: 56.6570, train_grp_loss: [18.37451741 15.08051344 18.82355217], val_grp_loss: [21.58432643 16.38104149 18.78946022], train_hist_grp_loss: [0.1692214  0.16104423 0.42380828], cur_train_grp_loss: [0.1692214  0.16104423 0.42380828], max_reward_err:  0.1380, max_reward_err_index: 0, max_kl_dist:  2.4862, max_kl_dist_index: 0, max_train_grp_loss:  18.8236, max_train_grp_loss_index: 2, max_val_grp_loss:  21.5843, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4238, max_cur_train_grp_loss_index: 2, 
2024-09-18 20:41:58,350 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  99, train_loss:  17.0798, val_loss:  18.8538, grad_norm: 0.0101,  live_grad: 0.0000, reward_err: 0.1374, 0.0046, 0.1068, KL_dist: 2.5042, 0.6954, 2.2331, param: [17.48622802  3.22035711  1.43960103  4.08001823], weights: [0.30933241 0.30164846 0.38901913], train_wt_loss:  51.2395, val_wt_loss: 56.5613, train_grp_loss: [18.26388615 15.23769152 18.72505709], val_grp_loss: [21.48417501 16.47788505 18.69140847], train_hist_grp_loss: [14.67943579 12.16401844 37.60063932], cur_train_grp_loss: [0.14612063 0.1218873  0.37452274], max_reward_err:  0.1374, max_reward_err_index: 0, max_kl_dist:  2.5042, max_kl_dist_index: 0, max_train_grp_loss:  18.7251, max_train_grp_loss_index: 2, max_val_grp_loss:  21.4842, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.3745, max_cur_train_grp_loss_index: 2, 
2024-09-18 20:41:58,580 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:387] - INFO: Policy parameter learned solely on the preference data rdpo: [17.48622802  3.22035711  1.43960103  4.08001823].
2024-09-18 20:41:58,941 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Uniform reward: 3.7985, 3.7985, 3.1685
2024-09-18 20:41:58,942 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Optimal reward: 3.8318, 3.8318, 3.2963
2024-09-18 20:41:58,943 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Policy reward: 3.3051, 3.8141, 2.9443
2024-09-18 20:41:58,943 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Reward Error: 0.1374, 0.0046, 0.1068
2024-09-18 20:41:59,657 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:416] - INFO: Optimal reward: 3.8318, 3.8318, 3.2963
Known param reward: [[3.831752300262451, 3.4357662200927734, 3.262315034866333], [3.4357662200927734, 3.831752300262451, 3.0935750007629395], [3.795030355453491, 3.565478563308716, 3.2963407039642334]], Known param reward error: [[0.0, 0.1033433398454684, 0.010322254934685776], [0.1033433398454684, 0.0, 0.061512362164943865], [0.009583590464979884, 0.06949137524768949, 0.0]].
