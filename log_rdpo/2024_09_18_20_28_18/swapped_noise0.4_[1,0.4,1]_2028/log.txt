2024-09-18 20:44:22,724 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log_rdpo/2024_09_18_20_28_18/swapped_noise0.4_[1,0.4,1]_2028
2024-09-18 20:44:22,726 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2028
2024-09-18 20:44:22,727 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-09-18 20:44:22,890 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.5013, l2 distance: 13.1473, acc: 0.80.
2024-09-18 20:44:22,891 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-18 20:44:22,892 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [6.95011815 4.29889072 6.20277518 4.38213871]
2024-09-18 20:44:23,104 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.5639, 3.7646, 3.1600
2024-09-18 20:44:23,354 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-18 20:44:24,677 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  17.7386, val_loss:  17.5186, grad_norm: 0.2374, live_grad: 0.0000, reward_err: 0.0700, 0.0108, 0.0346, KL_dist: 1.2245, 0.7767, 1.0047, param: [9.81187013 5.36805312 8.3425302  5.92165652], weights: [0.33309993 0.33310266 0.33379741], train_wt_loss:  53.2159, val_wt_loss: 52.5559, train_grp_loss: [19.69737885 15.86055471 16.99459729], val_grp_loss: [17.74994724 18.25606084 16.59561918], train_hist_grp_loss: [0.17301453 0.17383255 0.38218361], cur_train_grp_loss: [0.17301453 0.17383255 0.38218361], max_reward_err:  0.0700, max_reward_err_index: 0, max_kl_dist:  1.2245, max_kl_dist_index: 0, max_train_grp_loss:  19.6974, max_train_grp_loss_index: 0, max_val_grp_loss:  18.2561, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.3822, max_cur_train_grp_loss_index: 2, 
2024-09-18 20:44:29,164 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  99, train_loss:  17.7404, val_loss:  17.5154, grad_norm: 0.0060,  live_grad: 0.0000, reward_err: 0.0702, 0.0113, 0.0348, KL_dist: 1.2531, 0.8010, 1.0314, param: [9.99472178 5.46053467 8.39659747 6.02595404], weights: [0.31769022 0.31443872 0.36787106], train_wt_loss:  53.2211, val_wt_loss: 52.5461, train_grp_loss: [19.63633036 15.98480283 16.89662236], val_grp_loss: [17.66612441 18.44848741 16.49913863], train_hist_grp_loss: [15.15060071 14.12184811 29.81617487], cur_train_grp_loss: [0.15105361 0.14144646 0.29645011], max_reward_err:  0.0702, max_reward_err_index: 0, max_kl_dist:  1.2531, max_kl_dist_index: 0, max_train_grp_loss:  19.6363, max_train_grp_loss_index: 0, max_val_grp_loss:  18.4485, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2965, max_cur_train_grp_loss_index: 2, 
2024-09-18 20:44:29,387 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:387] - INFO: Policy parameter learned solely on the preference data rdpo: [9.99472178 5.46053467 8.39659747 6.02595404].
2024-09-18 20:44:29,713 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Uniform reward: 3.7723, 3.7723, 3.1239
2024-09-18 20:44:29,714 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Optimal reward: 3.8153, 3.8153, 3.2617
2024-09-18 20:44:29,714 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Policy reward: 3.5474, 3.7723, 3.1482
2024-09-18 20:44:29,715 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Reward Error: 0.0702, 0.0113, 0.0348
2024-09-18 20:44:30,396 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:416] - INFO: Optimal reward: 3.8153, 3.8153, 3.2617
Known param reward: [[3.815298318862915, 3.4180736541748047, 3.2313497066497803], [3.4180736541748047, 3.815298318862915, 3.058016777038574], [3.7792916297912598, 3.547971248626709, 3.2616615295410156]], Known param reward error: [[0.0, 0.10411365809174691, 0.00929336861495278], [0.10411365809174691, 0.0, 0.06243589368731908], [0.009437450511703749, 0.07006714754506493, 0.0]].
