2024-09-18 20:40:28,749 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log_rdpo/2024_09_18_20_28_18/swapped_noise0.5_[1,0.5,1]_2027
2024-09-18 20:40:28,751 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2027
2024-09-18 20:40:28,752 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-09-18 20:40:28,916 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.4829, l2 distance: 13.5092, acc: 0.79.
2024-09-18 20:40:28,917 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-18 20:40:28,918 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [5.67216327 3.4111978  8.28320704 2.40683498]
2024-09-18 20:40:29,120 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.4408, 3.7835, 3.0844
2024-09-18 20:40:29,370 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-18 20:40:30,707 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  16.7949, val_loss:  18.0641, grad_norm: 0.2459, live_grad: 0.0000, reward_err: 0.0977, 0.0005, 0.0606, KL_dist: 1.6511, 0.7548, 1.3406, param: [ 8.15791835  4.14545325 12.61632785  3.4651999 ], weights: [0.33315651 0.33313513 0.33370836], train_wt_loss:  50.3846, val_wt_loss: 54.1922, train_grp_loss: [19.03876287 14.87673073 15.69969288], val_grp_loss: [20.84081859 14.86526582 18.55372857], train_hist_grp_loss: [0.17660546 0.17018895 0.34211183], cur_train_grp_loss: [0.17660546 0.17018895 0.34211183], max_reward_err:  0.0977, max_reward_err_index: 0, max_kl_dist:  1.6511, max_kl_dist_index: 0, max_train_grp_loss:  19.0388, max_train_grp_loss_index: 0, max_val_grp_loss:  20.8408, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.3421, max_cur_train_grp_loss_index: 2, 
2024-09-18 20:40:35,209 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  99, train_loss:  16.7965, val_loss:  18.0470, grad_norm: 0.0059,  live_grad: 0.0000, reward_err: 0.0977, 0.0006, 0.0606, KL_dist: 1.6798, 0.7727, 1.3680, param: [ 8.15762848  4.23319092 12.8022072   3.56030026], weights: [0.32357057 0.31802999 0.35839944], train_wt_loss:  50.3894, val_wt_loss: 54.1411, train_grp_loss: [18.96730143 15.01773394 15.59798396], val_grp_loss: [20.78491282 14.94645385 18.47535182], train_hist_grp_loss: [15.10800695 13.38085036 25.33109457], cur_train_grp_loss: [0.15053997 0.13407358 0.25159726], max_reward_err:  0.0977, max_reward_err_index: 0, max_kl_dist:  1.6798, max_kl_dist_index: 0, max_train_grp_loss:  18.9673, max_train_grp_loss_index: 0, max_val_grp_loss:  20.7849, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2516, max_cur_train_grp_loss_index: 2, 
2024-09-18 20:40:35,433 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:387] - INFO: Policy parameter learned solely on the preference data rdpo: [ 8.15762848  4.23319092 12.8022072   3.56030026].
2024-09-18 20:40:35,767 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Uniform reward: 3.7505, 3.7505, 3.1220
2024-09-18 20:40:35,768 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Optimal reward: 3.7911, 3.7911, 3.2656
2024-09-18 20:40:35,768 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Policy reward: 3.4208, 3.7887, 3.0677
2024-09-18 20:40:35,769 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Reward Error: 0.0977, 0.0006, 0.0606
2024-09-18 20:40:36,472 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:416] - INFO: Optimal reward: 3.7911, 3.7911, 3.2656
Known param reward: [[3.7910752296447754, 3.430555582046509, 3.223391532897949], [3.430555582046509, 3.7910752296447754, 3.083258628845215], [3.7511558532714844, 3.553601026535034, 3.2656166553497314]], Known param reward error: [[0.0, 0.09509693840394916, 0.012930214078437238], [0.09509693840394916, 0.0, 0.055841835019360825], [0.010529829653903089, 0.06264032991294467, 0.0]].
