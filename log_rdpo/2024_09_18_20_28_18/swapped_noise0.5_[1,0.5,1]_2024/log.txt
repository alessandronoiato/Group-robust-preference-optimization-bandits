2024-09-18 20:39:27,903 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log_rdpo/2024_09_18_20_28_18/swapped_noise0.5_[1,0.5,1]_2024
2024-09-18 20:39:27,905 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2024
2024-09-18 20:39:27,905 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-09-18 20:39:28,063 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.5287, l2 distance: 9.4697, acc: 0.77.
2024-09-18 20:39:28,064 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-18 20:39:28,065 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [5.62552404 3.20254866 5.14111836 2.94602878]
2024-09-18 20:39:28,268 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.6390, 3.8946, 3.2918
2024-09-18 20:39:28,524 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-18 20:39:29,868 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  18.3684, val_loss:  17.0147, grad_norm: 0.3031, live_grad: 0.0000, reward_err: 0.0857, 0.0042, 0.0448, KL_dist: 1.1211, 0.5621, 0.8828, param: [9.11358191 4.34195898 8.31024334 4.25211252], weights: [0.33292919 0.33284451 0.3342263 ], train_wt_loss:  55.1053, val_wt_loss: 51.0440, train_grp_loss: [20.72771668 16.40152127 17.92047354], val_grp_loss: [19.58012913 13.67704548 17.797213  ], train_hist_grp_loss: [0.19718118 0.17174268 0.5860302 ], cur_train_grp_loss: [0.19718118 0.17174268 0.5860302 ], max_reward_err:  0.0857, max_reward_err_index: 0, max_kl_dist:  1.1211, max_kl_dist_index: 0, max_train_grp_loss:  20.7277, max_train_grp_loss_index: 0, max_val_grp_loss:  19.5801, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.5860, max_cur_train_grp_loss_index: 2, 
2024-09-18 20:39:34,392 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  99, train_loss:  18.3765, val_loss:  16.9687, grad_norm: 0.0147,  live_grad: 0.0000, reward_err: 0.0825, 0.0044, 0.0419, KL_dist: 1.1450, 0.5957, 0.9061, param: [8.92142918 4.5508223  8.8175592  4.43413064], weights: [0.30697533 0.29245825 0.40056641], train_wt_loss:  55.1295, val_wt_loss: 50.9060, train_grp_loss: [20.55987254 16.64449449 17.6671249 ], val_grp_loss: [19.41748439 13.87524005 17.62645931], train_hist_grp_loss: [16.95125923 12.10671191 43.5624776 ], cur_train_grp_loss: [0.16853834 0.12147212 0.43097272], max_reward_err:  0.0825, max_reward_err_index: 0, max_kl_dist:  1.1450, max_kl_dist_index: 0, max_train_grp_loss:  20.5599, max_train_grp_loss_index: 0, max_val_grp_loss:  19.4175, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4310, max_cur_train_grp_loss_index: 2, 
2024-09-18 20:39:34,617 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:387] - INFO: Policy parameter learned solely on the preference data rdpo: [8.92142918 4.5508223  8.8175592  4.43413064].
2024-09-18 20:39:34,953 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Uniform reward: 3.8883, 3.8883, 3.2742
2024-09-18 20:39:34,954 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Optimal reward: 3.9280, 3.9280, 3.4116
2024-09-18 20:39:34,954 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Policy reward: 3.6041, 3.9107, 3.2688
2024-09-18 20:39:34,955 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Reward Error: 0.0825, 0.0044, 0.0419
2024-09-18 20:39:35,640 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:416] - INFO: Optimal reward: 3.9280, 3.9280, 3.4116
Known param reward: [[3.927974224090576, 3.5139124393463135, 3.376384735107422], [3.5139124393463135, 3.927974224090576, 3.203280210494995], [3.887371301651001, 3.6481499671936035, 3.4115631580352783]], Known param reward error: [[0.0, 0.10541356972374948, 0.010311526211965462], [0.10541356972374948, 0.0, 0.061052056752844495], [0.010336860713228275, 0.07123882208309525, 0.0]].
