2024-09-18 20:45:06,618 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log_rdpo/2024_09_18_20_28_18/swapped_noise0.4_[1,0.4,1]_2030
2024-09-18 20:45:06,620 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2030
2024-09-18 20:45:06,620 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-09-18 20:45:06,788 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.4711, l2 distance: 12.8291, acc: 0.77.
2024-09-18 20:45:06,788 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-18 20:45:06,789 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [3.6833524  4.41691365 8.37422007 3.00526584]
2024-09-18 20:45:07,005 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.4800, 3.8293, 3.1678
2024-09-18 20:45:07,237 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-18 20:45:08,546 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  16.5501, val_loss:  18.1482, grad_norm: 0.3652, live_grad: 0.0000, reward_err: 0.1131, 0.0060, 0.0738, KL_dist: 1.4404, 0.5581, 1.1790, param: [ 4.82239221  4.98771229 11.97105837  3.59068703], weights: [0.33311981 0.33289631 0.33398388], train_wt_loss:  49.6503, val_wt_loss: 54.4447, train_grp_loss: [20.26994981 12.43866853 20.50975112], val_grp_loss: [21.20477757 14.09712538 18.78146176], train_hist_grp_loss: [0.22199479 0.15487948 0.4810445 ], cur_train_grp_loss: [0.22199479 0.15487948 0.4810445 ], max_reward_err:  0.1131, max_reward_err_index: 0, max_kl_dist:  1.4404, max_kl_dist_index: 0, max_train_grp_loss:  20.5098, max_train_grp_loss_index: 2, max_val_grp_loss:  21.2048, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4810, max_cur_train_grp_loss_index: 2, 
2024-09-18 20:45:13,078 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  99, train_loss:  16.5655, val_loss:  18.0696, grad_norm: 0.0214,  live_grad: 0.0000, reward_err: 0.1073, 0.0078, 0.0679, KL_dist: 1.3620, 0.5899, 1.1071, param: [ 5.38874703  5.28662231 11.50589904  3.89112006], weights: [0.31664892 0.28623426 0.39711682], train_wt_loss:  49.6964, val_wt_loss: 54.2087, train_grp_loss: [20.09520393 12.73178706 20.12401053], val_grp_loss: [20.93398137 14.38917994 18.5419743 ], train_hist_grp_loss: [18.89845062  8.80014179 41.54213459], cur_train_grp_loss: [0.1878234  0.08839074 0.41077891], max_reward_err:  0.1073, max_reward_err_index: 0, max_kl_dist:  1.3620, max_kl_dist_index: 0, max_train_grp_loss:  20.1240, max_train_grp_loss_index: 2, max_val_grp_loss:  20.9340, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4108, max_cur_train_grp_loss_index: 2, 
2024-09-18 20:45:13,303 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:387] - INFO: Policy parameter learned solely on the preference data rdpo: [ 5.38874703  5.28662231 11.50589904  3.89112006].
2024-09-18 20:45:13,642 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Uniform reward: 3.8314, 3.8314, 3.2257
2024-09-18 20:45:13,642 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Optimal reward: 3.8751, 3.8751, 3.3832
2024-09-18 20:45:13,643 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Policy reward: 3.4592, 3.8450, 3.1536
2024-09-18 20:45:13,643 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Reward Error: 0.1073, 0.0078, 0.0679
2024-09-18 20:45:14,344 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:416] - INFO: Optimal reward: 3.8751, 3.8751, 3.3832
Known param reward: [[3.875110387802124, 3.4832417964935303, 3.3414347171783447], [3.4832417964935303, 3.875110387802124, 3.1878042221069336], [3.835331678390503, 3.593684434890747, 3.3831582069396973]], Known param reward error: [[0.0, 0.1011244976509825, 0.012332704298535996], [0.1011244976509825, 0.0, 0.05774308290757558], [0.010265180970543316, 0.07262398351211756, 0.0]].
