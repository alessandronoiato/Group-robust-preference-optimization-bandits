2024-09-18 20:46:48,218 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log_rdpo/2024_09_18_20_28_18/swapped_noise0.3_[1,0.3,1]_2025
2024-09-18 20:46:48,220 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2025
2024-09-18 20:46:48,220 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-09-18 20:46:48,387 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.5798, l2 distance: 6.9075, acc: 0.72.
2024-09-18 20:46:48,387 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-18 20:46:48,388 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [4.52051724 2.23924509 4.09916579 1.35699891]
2024-09-18 20:46:48,596 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.5016, 3.8293, 3.0928
2024-09-18 20:46:48,855 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-18 20:46:50,261 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  20.0454, val_loss:  19.4082, grad_norm: 0.1676, live_grad: 0.0000, reward_err: 0.0934, 0.0013, 0.0540, KL_dist: 1.0084, 0.4738, 0.7831, param: [8.91957399 3.92257227 7.57910739 2.43105697], weights: [0.33303485 0.3329514  0.33401375], train_wt_loss:  60.1363, val_wt_loss: 58.2245, train_grp_loss: [21.11607393 18.50101529 21.4526314 ], val_grp_loss: [22.07094489 17.13974334 19.03660862], train_hist_grp_loss: [0.18604204 0.16098315 0.47954317], cur_train_grp_loss: [0.18604204 0.16098315 0.47954317], max_reward_err:  0.0934, max_reward_err_index: 0, max_kl_dist:  1.0084, max_kl_dist_index: 0, max_train_grp_loss:  21.4526, max_train_grp_loss_index: 2, max_val_grp_loss:  22.0709, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4795, max_cur_train_grp_loss_index: 2, 
2024-09-18 20:46:54,770 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  99, train_loss:  20.0516, val_loss:  19.3490, grad_norm: 0.0146,  live_grad: 0.0000, reward_err: 0.0920, 0.0022, 0.0534, KL_dist: 1.0196, 0.4888, 0.7978, param: [9.2245019  4.11815653 7.33263138 2.61159432], weights: [0.30408908 0.29597684 0.39993407], train_wt_loss:  60.1547, val_wt_loss: 58.0470, train_grp_loss: [20.99578404 18.70214041 21.25861038], val_grp_loss: [21.93670189 17.25714787 18.87729869], train_hist_grp_loss: [17.1355602  14.43161377 44.53346338], cur_train_grp_loss: [0.1707083  0.14495937 0.4429322 ], max_reward_err:  0.0920, max_reward_err_index: 0, max_kl_dist:  1.0196, max_kl_dist_index: 0, max_train_grp_loss:  21.2586, max_train_grp_loss_index: 2, max_val_grp_loss:  21.9367, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4429, max_cur_train_grp_loss_index: 2, 
2024-09-18 20:46:54,991 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:387] - INFO: Policy parameter learned solely on the preference data rdpo: [9.2245019  4.11815653 7.33263138 2.61159432].
2024-09-18 20:46:55,315 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Uniform reward: 3.8078, 3.8078, 3.1434
2024-09-18 20:46:55,316 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Optimal reward: 3.8386, 3.8386, 3.2517
2024-09-18 20:46:55,316 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Policy reward: 3.4853, 3.8303, 3.0779
2024-09-18 20:46:55,317 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Reward Error: 0.0920, 0.0022, 0.0534
2024-09-18 20:46:55,993 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:416] - INFO: Optimal reward: 3.8386, 3.8386, 3.2517
Known param reward: [[3.8385727405548096, 3.460787534713745, 3.2131664752960205], [3.460787534713745, 3.8385727405548096, 3.0634775161743164], [3.796536684036255, 3.582489252090454, 3.2517144680023193]], Known param reward error: [[0.0, 0.09841814428830158, 0.011854667156547932], [0.09841814428830158, 0.0, 0.057888524247839544], [0.010950959994698183, 0.06671320456137621, 0.0]].
