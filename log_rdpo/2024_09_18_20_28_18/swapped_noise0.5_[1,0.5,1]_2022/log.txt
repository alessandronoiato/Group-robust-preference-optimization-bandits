2024-09-18 20:38:47,482 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log_rdpo/2024_09_18_20_28_18/swapped_noise0.5_[1,0.5,1]_2022
2024-09-18 20:38:47,484 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2022
2024-09-18 20:38:47,485 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-09-18 20:38:47,650 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.4500, l2 distance: 16.7322, acc: 0.80.
2024-09-18 20:38:47,651 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-18 20:38:47,652 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [9.385783   4.87832338 6.31300798 4.61071713]
2024-09-18 20:38:47,861 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.6061, 3.8367, 3.2033
2024-09-18 20:38:48,117 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-18 20:38:49,439 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  16.0766, val_loss:  17.5655, grad_norm: 0.2033, live_grad: 0.0000, reward_err: 0.0841, 0.0068, 0.0516, KL_dist: 1.5828, 0.8635, 1.3276, param: [12.83110514  5.71902392  7.75752503  4.70102369], weights: [0.33306174 0.33294163 0.33399663], train_wt_loss:  48.2299, val_wt_loss: 52.6966, train_grp_loss: [17.71683095 14.02830273 17.37123389], val_grp_loss: [18.96314628 16.02504969 17.76661472], train_hist_grp_loss: [0.16816196 0.13209269 0.44846212], cur_train_grp_loss: [0.16816196 0.13209269 0.44846212], max_reward_err:  0.0841, max_reward_err_index: 0, max_kl_dist:  1.5828, max_kl_dist_index: 0, max_train_grp_loss:  17.7168, max_train_grp_loss_index: 0, max_val_grp_loss:  18.9631, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4485, max_cur_train_grp_loss_index: 2, 
2024-09-18 20:38:53,993 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  99, train_loss:  16.0807, val_loss:  17.5840, grad_norm: 0.0110,  live_grad: 0.0000, reward_err: 0.0833, 0.0070, 0.0509, KL_dist: 1.6170, 0.8946, 1.3614, param: [13.02933067  5.90083469  7.79919101  4.84463048], weights: [0.31041035 0.30032938 0.38926027], train_wt_loss:  48.2421, val_wt_loss: 52.7520, train_grp_loss: [17.59162311 14.20792314 17.23452372], val_grp_loss: [18.85326853 16.29712182 17.6567691 ], train_hist_grp_loss: [14.26482762 10.96329309 36.90013463], cur_train_grp_loss: [0.14187891 0.11012301 0.36672369], max_reward_err:  0.0833, max_reward_err_index: 0, max_kl_dist:  1.6170, max_kl_dist_index: 0, max_train_grp_loss:  17.5916, max_train_grp_loss_index: 0, max_val_grp_loss:  18.8533, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.3667, max_cur_train_grp_loss_index: 2, 
2024-09-18 20:38:54,221 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:387] - INFO: Policy parameter learned solely on the preference data rdpo: [13.02933067  5.90083469  7.79919101  4.84463048].
2024-09-18 20:38:54,557 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Uniform reward: 3.8487, 3.8487, 3.2033
2024-09-18 20:38:54,558 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Optimal reward: 3.8787, 3.8787, 3.3327
2024-09-18 20:38:54,558 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Policy reward: 3.5557, 3.8515, 3.1630
2024-09-18 20:38:54,559 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Reward Error: 0.0833, 0.0070, 0.0509
2024-09-18 20:38:55,262 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:416] - INFO: Optimal reward: 3.8787, 3.8787, 3.3327
Known param reward: [[3.878673791885376, 3.5492217540740967, 3.282655954360962], [3.5492217540740967, 3.878673791885376, 3.170855760574341], [3.8372855186462402, 3.6475391387939453, 3.3327279090881348]], Known param reward error: [[0.0, 0.08493935182188567, 0.015024315243566644], [0.08493935182188567, 0.0, 0.04857046627550332], [0.01067072805290424, 0.05959115550655239, 0.0]].
