2024-09-17 21:51:54,925 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:198] - INFO: Logging to log_rdpo/2024_09_17_21_48_05/swapped_noise0.5_[1,0.5,1]_2023
2024-09-17 21:51:54,927 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: (IB) Seed: 2023
2024-09-17 21:51:54,927 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Data: 300
2024-09-17 21:51:55,087 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:296] - INFO: MLE reward loss: 0.4822, l2 distance: 15.4044, acc: 0.76.
2024-09-17 21:51:55,088 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-17 21:51:55,089 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: MLE reward parameter: [8.33205773 2.71337591 6.91290336 4.97302613]
2024-09-17 21:51:55,294 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:313] - INFO: Learned oracle reward: 3.5473, 3.8428, 3.1587
2024-09-17 21:51:55,546 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-17 21:51:56,734 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  17.0988, val_loss:  17.3256, grad_norm: 0.2448, live_grad: 0.0000, reward_err: 0.0915, 0.0017, 0.0523, KL_dist: 1.4919, 0.8382, 1.2067, param: [11.09404487  2.9640096   9.85342487  5.59522395], weights: [0.33337639 0.33321978 0.33340383], train_wt_loss:  51.2964, val_wt_loss: 51.9768, train_grp_loss: [19.7864815  14.0946882  17.62719171], val_grp_loss: [21.27447091 13.61753037 17.23082852], train_hist_grp_loss: [0.22595917 0.17897207 0.23419102], cur_train_grp_loss: [0.22595917 0.17897207 0.23419102], max_reward_err:  0.0915, max_reward_err_index: 0, max_kl_dist:  1.4919, max_kl_dist_index: 0, max_train_grp_loss:  19.7865, max_train_grp_loss_index: 0, max_val_grp_loss:  21.2745, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2342, max_cur_train_grp_loss_index: 2, 
2024-09-17 21:52:01,007 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  99, train_loss:  17.1008, val_loss:  17.3144, grad_norm: 0.0067,  live_grad: 0.0000, reward_err: 0.0904, 0.0019, 0.0514, KL_dist: 1.4994, 0.8521, 1.2158, param: [11.1640344   3.10505004  9.87013366  5.72229118], weights: [0.3414755  0.32051476 0.33800974], train_wt_loss:  51.3024, val_wt_loss: 51.9433, train_grp_loss: [19.68616957 14.28624378 17.52423539], val_grp_loss: [21.17664328 13.76889619 17.14365253], train_hist_grp_loss: [19.76539642 13.43063497 18.74527583], cur_train_grp_loss: [0.19687181 0.13475716 0.18643906], max_reward_err:  0.0904, max_reward_err_index: 0, max_kl_dist:  1.4994, max_kl_dist_index: 0, max_train_grp_loss:  19.6862, max_train_grp_loss_index: 0, max_val_grp_loss:  21.1766, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.1969, max_cur_train_grp_loss_index: 0, 
2024-09-17 21:52:01,223 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:386] - INFO: Policy parameter learned solely on the preference data rdpo: [11.1640344   3.10505004  9.87013366  5.72229118].
2024-09-17 21:52:01,547 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:397] - INFO: Uniform reward: 3.8265, 3.8265, 3.1778
2024-09-17 21:52:01,548 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Optimal reward: 3.8671, 3.8671, 3.3081
2024-09-17 21:52:01,548 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Policy reward: 3.5176, 3.8596, 3.1382
2024-09-17 21:52:01,549 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Reward Error: 0.0904, 0.0019, 0.0514
2024-09-17 21:52:02,203 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:415] - INFO: Optimal reward: 3.8671, 3.8671, 3.3081
Known param reward: [[3.867140769958496, 3.49029541015625, 3.2803642749786377], [3.49029541015625, 3.867140769958496, 3.118959903717041], [3.833752155303955, 3.6075756549835205, 3.3081343173980713]], Known param reward error: [[0.0, 0.09744805845438374, 0.00839447245941193], [0.09744805845438374, 0.0, 0.05718462297196584], [0.008633927917472566, 0.06712067918276514, 0.0]].
