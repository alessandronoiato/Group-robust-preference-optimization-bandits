2024-09-17 21:51:35,629 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:198] - INFO: Logging to log_rdpo/2024_09_17_21_48_05/swapped_noise0.5_[1,0.5,1]_2022
2024-09-17 21:51:35,631 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: (IB) Seed: 2022
2024-09-17 21:51:35,632 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Data: 300
2024-09-17 21:51:35,792 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:296] - INFO: MLE reward loss: 0.4244, l2 distance: 25.4025, acc: 0.80.
2024-09-17 21:51:35,793 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-17 21:51:35,793 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: MLE reward parameter: [12.07304729  3.63661977 10.49849702  7.65383579]
2024-09-17 21:51:35,995 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:313] - INFO: Learned oracle reward: 3.5903, 3.8294, 3.1966
2024-09-17 21:51:36,251 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-17 21:51:37,455 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  16.1244, val_loss:  17.7467, grad_norm: 0.2611, live_grad: 0.0000, reward_err: 0.0800, 0.0026, 0.0445, KL_dist: 1.6903, 0.9948, 1.3873, param: [12.24189719  3.3536831  10.59870721  6.17453578], weights: [0.33335037 0.33331979 0.33332984], train_wt_loss:  48.3733, val_wt_loss: 53.2402, train_grp_loss: [18.92032112 10.66488023 18.87160104], val_grp_loss: [20.1726038  16.09187854 16.93545416], train_hist_grp_loss: [0.22596783 0.21679206 0.21980715], cur_train_grp_loss: [0.22596783 0.21679206 0.21980715], max_reward_err:  0.0800, max_reward_err_index: 0, max_kl_dist:  1.6903, max_kl_dist_index: 0, max_train_grp_loss:  18.9203, max_train_grp_loss_index: 0, max_val_grp_loss:  20.1726, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2260, max_cur_train_grp_loss_index: 0, 
2024-09-17 21:51:41,741 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  99, train_loss:  16.1284, val_loss:  17.7416, grad_norm: 0.0090,  live_grad: 0.0000, reward_err: 0.0790, 0.0034, 0.0437, KL_dist: 1.6999, 1.0142, 1.4001, param: [12.35892389  3.55061443 10.55966377  6.38395669], weights: [0.34395976 0.31545712 0.34058312], train_wt_loss:  48.3852, val_wt_loss: 53.2249, train_grp_loss: [18.76835783 10.95572098 18.73986272], val_grp_loss: [20.03147194 16.36759309 16.80196484], train_hist_grp_loss: [19.45969799 10.80950485 18.4731504 ], cur_train_grp_loss: [0.19350408 0.10844215 0.18373723], max_reward_err:  0.0790, max_reward_err_index: 0, max_kl_dist:  1.6999, max_kl_dist_index: 0, max_train_grp_loss:  18.7684, max_train_grp_loss_index: 0, max_val_grp_loss:  20.0315, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.1935, max_cur_train_grp_loss_index: 0, 
2024-09-17 21:51:41,956 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:386] - INFO: Policy parameter learned solely on the preference data rdpo: [12.35892389  3.55061443 10.55966377  6.38395669].
2024-09-17 21:51:42,277 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:397] - INFO: Uniform reward: 3.8381, 3.8381, 3.1923
2024-09-17 21:51:42,277 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Optimal reward: 3.8683, 3.8683, 3.3211
2024-09-17 21:51:42,278 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Policy reward: 3.5628, 3.8553, 3.1761
2024-09-17 21:51:42,278 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Reward Error: 0.0790, 0.0034, 0.0437
2024-09-17 21:51:42,951 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:415] - INFO: Optimal reward: 3.8683, 3.8683, 3.3211
Known param reward: [[3.8683152198791504, 3.5409886837005615, 3.2718687057495117], [3.5409886837005615, 3.8683152198791504, 3.1612870693206787], [3.825526475906372, 3.6363391876220703, 3.3211145401000977]], Known param reward error: [[0.0, 0.08461733792956377, 0.014828104769039877], [0.08461733792956377, 0.0, 0.048124648773661925], [0.011061338474405682, 0.059968233991108726, 0.0]].
