2024-09-17 22:31:09,034 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:198] - INFO: Logging to log_rdpo/2024_09_17_22_26_54/swapped_noise0.3_[1,0.3,1]_2024
2024-09-17 22:31:09,036 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: (IB) Seed: 2024
2024-09-17 22:31:09,037 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Data: 300
2024-09-17 22:31:09,199 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:296] - INFO: MLE reward loss: 0.5065, l2 distance: 15.7670, acc: 0.78.
2024-09-17 22:31:09,200 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-17 22:31:09,201 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: MLE reward parameter: [6.51049185 4.04085673 8.51350199 5.3233502 ]
2024-09-17 22:31:09,406 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:313] - INFO: Learned oracle reward: 3.6292, 3.8749, 3.2831
2024-09-17 22:31:09,641 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-17 22:31:10,826 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  17.9814, val_loss:  18.7383, grad_norm: 0.1883, live_grad: 0.0000, reward_err: 0.0868, 0.0080, 0.0483, KL_dist: 1.6425, 0.9320, 1.3729, param: [ 8.14991958  5.09968653 13.07765146  6.36495135], weights: [0.33336313 0.33332514 0.33331173], train_wt_loss:  53.9441, val_wt_loss: 56.2148, train_grp_loss: [18.67370996 19.95229522 15.59963712], val_grp_loss: [19.18181467 19.66155537 17.41253129], train_hist_grp_loss: [0.21866118 0.20726644 0.20324305], cur_train_grp_loss: [0.21866118 0.20726644 0.20324305], max_reward_err:  0.0868, max_reward_err_index: 0, max_kl_dist:  1.6425, max_kl_dist_index: 0, max_train_grp_loss:  19.9523, max_train_grp_loss_index: 1, max_val_grp_loss:  19.6616, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2187, max_cur_train_grp_loss_index: 0, 
2024-09-17 22:31:15,188 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  99, train_loss:  17.9838, val_loss:  18.6946, grad_norm: 0.0054,  live_grad: 0.0000, reward_err: 0.0879, 0.0078, 0.0490, KL_dist: 1.6152, 0.9015, 1.3456, param: [ 8.07127454  4.94861735 12.92384891  6.17871646], weights: [0.33186318 0.34579091 0.32234591], train_wt_loss:  53.9513, val_wt_loss: 56.0837, train_grp_loss: [18.79555409 19.6658754  15.7302008 ], val_grp_loss: [19.29573978 19.27851204 17.53356074], train_hist_grp_loss: [17.88327579 21.99442554 14.97351979], cur_train_grp_loss: [0.17899421 0.21853929 0.14979953], max_reward_err:  0.0879, max_reward_err_index: 0, max_kl_dist:  1.6152, max_kl_dist_index: 0, max_train_grp_loss:  19.6659, max_train_grp_loss_index: 1, max_val_grp_loss:  19.2957, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2185, max_cur_train_grp_loss_index: 1, 
2024-09-17 22:31:15,413 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:386] - INFO: Policy parameter learned solely on the preference data rdpo: [ 8.07127454  4.94861735 12.92384891  6.17871646].
2024-09-17 22:31:15,742 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:397] - INFO: Uniform reward: 3.8875, 3.8875, 3.2769
2024-09-17 22:31:15,743 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Optimal reward: 3.9272, 3.9272, 3.4129
2024-09-17 22:31:15,743 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Policy reward: 3.5819, 3.8966, 3.2455
2024-09-17 22:31:15,744 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Reward Error: 0.0879, 0.0078, 0.0490
2024-09-17 22:31:16,425 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:415] - INFO: Optimal reward: 3.9272, 3.9272, 3.4129
Known param reward: [[3.9271814823150635, 3.503054618835449, 3.378288984298706], [3.503054618835449, 3.9271814823150635, 3.1996068954467773], [3.8862557411193848, 3.636671543121338, 3.4129228591918945]], Known param reward error: [[0.0, 0.1079977753484396, 0.0101478633775476], [0.1079977753484396, 0.0, 0.06250242755138795], [0.010421148444495387, 0.07397415691175818, 0.0]].
