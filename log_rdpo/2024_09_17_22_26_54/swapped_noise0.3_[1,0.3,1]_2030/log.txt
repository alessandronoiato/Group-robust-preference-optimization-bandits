2024-09-17 22:33:04,087 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:198] - INFO: Logging to log_rdpo/2024_09_17_22_26_54/swapped_noise0.3_[1,0.3,1]_2030
2024-09-17 22:33:04,089 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: (IB) Seed: 2030
2024-09-17 22:33:04,089 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Data: 300
2024-09-17 22:33:04,255 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:296] - INFO: MLE reward loss: 0.5866, l2 distance: 6.8663, acc: 0.72.
2024-09-17 22:33:04,256 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-17 22:33:04,257 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: MLE reward parameter: [3.16007899 1.36960043 5.0322715  2.61134783]
2024-09-17 22:33:04,468 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:313] - INFO: Learned oracle reward: 3.5342, 3.8697, 3.2132
2024-09-17 22:33:04,726 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-17 22:33:05,923 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  20.3564, val_loss:  18.7651, grad_norm: 0.2092, live_grad: 0.0000, reward_err: 0.1065, 0.0108, 0.0675, KL_dist: 1.1388, 0.4360, 0.8933, param: [ 5.32441013  2.17041011 10.05750878  4.67975147], weights: [0.33339128 0.3333521  0.33325662], train_wt_loss:  61.0693, val_wt_loss: 56.2952, train_grp_loss: [21.59083788 21.03503026 18.62511457], val_grp_loss: [20.48298573 16.05925473 19.52847642], train_hist_grp_loss: [0.25168812 0.23993597 0.21128845], cur_train_grp_loss: [0.25168812 0.23993597 0.21128845], max_reward_err:  0.1065, max_reward_err_index: 0, max_kl_dist:  1.1388, max_kl_dist_index: 0, max_train_grp_loss:  21.5908, max_train_grp_loss_index: 0, max_val_grp_loss:  20.4830, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2517, max_cur_train_grp_loss_index: 0, 
2024-09-17 22:33:10,367 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  99, train_loss:  20.3566, val_loss:  18.7617, grad_norm: 0.0014,  live_grad: 0.0000, reward_err: 0.1054, 0.0111, 0.0666, KL_dist: 1.1311, 0.4356, 0.8874, param: [ 5.29925788  2.19495943 10.02820579  4.71103189], weights: [0.34548229 0.33073649 0.32378122], train_wt_loss:  61.0697, val_wt_loss: 56.2851, train_grp_loss: [21.57073348 21.05653133 18.62078425], val_grp_loss: [20.46731854 16.07576887 19.51918567], train_hist_grp_loss: [24.2575148  19.89557387 17.77017988], cur_train_grp_loss: [0.24237015 0.19864434 0.17734127], max_reward_err:  0.1054, max_reward_err_index: 0, max_kl_dist:  1.1311, max_kl_dist_index: 0, max_train_grp_loss:  21.5707, max_train_grp_loss_index: 0, max_val_grp_loss:  20.4673, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2424, max_cur_train_grp_loss_index: 0, 
2024-09-17 22:33:10,593 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:386] - INFO: Policy parameter learned solely on the preference data rdpo: [ 5.29925788  2.19495943 10.02820579  4.71103189].
2024-09-17 22:33:10,926 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:397] - INFO: Uniform reward: 3.8714, 3.8714, 3.2553
2024-09-17 22:33:10,927 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Optimal reward: 3.9148, 3.9148, 3.4122
2024-09-17 22:33:10,927 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Policy reward: 3.5021, 3.8712, 3.1848
2024-09-17 22:33:10,928 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Reward Error: 0.1054, 0.0111, 0.0666
2024-09-17 22:33:11,622 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:415] - INFO: Optimal reward: 3.9148, 3.9148, 3.4122
Known param reward: [[3.9148213863372803, 3.5198121070861816, 3.370706081390381], [3.5198121070861816, 3.9148213863372803, 3.212374687194824], [3.8760476112365723, 3.641129970550537, 3.4121618270874023]], Known param reward error: [[0.0, 0.10090097101995006, 0.01214940785279455], [0.10090097101995006, 0.0, 0.05855148437174653], [0.009904353551359563, 0.06991159717833506, 0.0]].
