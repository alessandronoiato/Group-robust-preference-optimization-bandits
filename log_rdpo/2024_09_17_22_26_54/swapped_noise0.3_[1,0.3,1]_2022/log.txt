2024-09-17 22:30:28,455 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:198] - INFO: Logging to log_rdpo/2024_09_17_22_26_54/swapped_noise0.3_[1,0.3,1]_2022
2024-09-17 22:30:28,457 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: (IB) Seed: 2022
2024-09-17 22:30:28,457 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Data: 300
2024-09-17 22:30:28,616 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:296] - INFO: MLE reward loss: 0.4690, l2 distance: 18.2092, acc: 0.81.
2024-09-17 22:30:28,617 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-17 22:30:28,618 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: MLE reward parameter: [10.22725597  3.87998046  6.967695    4.9739066 ]
2024-09-17 22:30:28,823 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:313] - INFO: Learned oracle reward: 3.5084, 3.8186, 3.1291
2024-09-17 22:30:29,065 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-17 22:30:30,267 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  17.0130, val_loss:  17.6362, grad_norm: 0.1952, live_grad: 0.0000, reward_err: 0.1007, 0.0009, 0.0622, KL_dist: 1.7526, 0.8255, 1.4446, param: [13.31322269  3.94377233  8.00364859  4.62394292], weights: [0.33337832 0.33328891 0.33333277], train_wt_loss:  51.0390, val_wt_loss: 52.9086, train_grp_loss: [21.21099856 13.59393019 16.40631148], val_grp_loss: [20.73582499 15.02926526 17.20035006], train_hist_grp_loss: [0.21701271 0.19019031 0.20334676], cur_train_grp_loss: [0.21701271 0.19019031 0.20334676], max_reward_err:  0.1007, max_reward_err_index: 0, max_kl_dist:  1.7526, max_kl_dist_index: 0, max_train_grp_loss:  21.2110, max_train_grp_loss_index: 0, max_val_grp_loss:  20.7358, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2170, max_cur_train_grp_loss_index: 0, 
2024-09-17 22:30:34,603 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  99, train_loss:  17.0148, val_loss:  17.6130, grad_norm: 0.0062,  live_grad: 0.0000, reward_err: 0.1003, 0.0011, 0.0620, KL_dist: 1.7522, 0.8329, 1.4477, param: [13.34690113  4.08608497  7.95695797  4.74972571], weights: [0.34895851 0.32146667 0.32957482], train_wt_loss:  51.0445, val_wt_loss: 52.8389, train_grp_loss: [21.0986517  13.77719405 16.33713183], val_grp_loss: [20.64201295 15.11888558 17.13370677], train_hist_grp_loss: [21.80877421 13.60285786 16.09381188], cur_train_grp_loss: [0.21752367 0.13638894 0.16017476], max_reward_err:  0.1003, max_reward_err_index: 0, max_kl_dist:  1.7522, max_kl_dist_index: 0, max_train_grp_loss:  21.0987, max_train_grp_loss_index: 0, max_val_grp_loss:  20.6420, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2175, max_cur_train_grp_loss_index: 0, 
2024-09-17 22:30:34,824 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:386] - INFO: Policy parameter learned solely on the preference data rdpo: [13.34690113  4.08608497  7.95695797  4.74972571].
2024-09-17 22:30:35,148 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:397] - INFO: Uniform reward: 3.8062, 3.8062, 3.1654
2024-09-17 22:30:35,149 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Optimal reward: 3.8366, 3.8366, 3.2883
2024-09-17 22:30:35,150 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Policy reward: 3.4520, 3.8323, 3.0842
2024-09-17 22:30:35,150 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Reward Error: 0.1003, 0.0011, 0.0620
2024-09-17 22:30:35,832 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:415] - INFO: Optimal reward: 3.8366, 3.8366, 3.2883
Known param reward: [[3.8366410732269287, 3.45465350151062, 3.2577602863311768], [3.45465350151062, 3.8366410732269287, 3.1000757217407227], [3.801785469055176, 3.5611062049865723, 3.288270950317383]], Known param reward error: [[0.0, 0.09956301995042394, 0.009278634409144774], [0.09956301995042394, 0.0, 0.05723227538731126], [0.009084927025096074, 0.0718166914708571, 0.0]].
