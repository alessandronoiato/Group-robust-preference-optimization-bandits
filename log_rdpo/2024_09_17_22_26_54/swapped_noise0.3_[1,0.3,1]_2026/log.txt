2024-09-17 22:31:46,423 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:198] - INFO: Logging to log_rdpo/2024_09_17_22_26_54/swapped_noise0.3_[1,0.3,1]_2026
2024-09-17 22:31:46,425 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: (IB) Seed: 2026
2024-09-17 22:31:46,426 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Data: 300
2024-09-17 22:31:46,587 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:296] - INFO: MLE reward loss: 0.4915, l2 distance: 15.1024, acc: 0.80.
2024-09-17 22:31:46,588 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-17 22:31:46,589 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: MLE reward parameter: [7.6709395  5.76062616 6.25748351 4.73011934]
2024-09-17 22:31:46,798 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:313] - INFO: Learned oracle reward: 3.6576, 3.8017, 3.2815
2024-09-17 22:31:47,062 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-17 22:31:48,277 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  17.6974, val_loss:  17.2628, grad_norm: 0.1573, live_grad: 0.0000, reward_err: 0.0787, 0.0118, 0.0447, KL_dist: 1.2449, 0.7592, 1.0266, param: [10.77392727  6.33192709  7.21842393  5.02951115], weights: [0.3333403  0.33327338 0.33338632], train_wt_loss:  53.0921, val_wt_loss: 51.7883, train_grp_loss: [19.58168734 16.85159714 16.50128727], val_grp_loss: [17.95349578 16.26127185 17.5088757 ], train_hist_grp_loss: [0.19921904 0.1791403  0.21302352], cur_train_grp_loss: [0.19921904 0.1791403  0.21302352], max_reward_err:  0.0787, max_reward_err_index: 0, max_kl_dist:  1.2449, max_kl_dist_index: 0, max_train_grp_loss:  19.5817, max_train_grp_loss_index: 0, max_val_grp_loss:  17.9535, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2130, max_cur_train_grp_loss_index: 2, 
2024-09-17 22:31:52,612 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  99, train_loss:  17.6975, val_loss:  17.2649, grad_norm: 0.0015,  live_grad: 0.0000, reward_err: 0.0784, 0.0120, 0.0444, KL_dist: 1.2451, 0.7646, 1.0275, param: [10.76727875  6.37311117  7.24022776  5.06535282], weights: [0.33666894 0.33024626 0.3330848 ], train_wt_loss:  53.0925, val_wt_loss: 51.7948, train_grp_loss: [19.55402347 16.90443942 16.47582811], val_grp_loss: [17.92607026 16.32263597 17.48449111], train_hist_grp_loss: [18.64895443 16.72280869 17.57865908], cur_train_grp_loss: [0.1862314  0.16736548 0.17527744], max_reward_err:  0.0784, max_reward_err_index: 0, max_kl_dist:  1.2451, max_kl_dist_index: 0, max_train_grp_loss:  19.5540, max_train_grp_loss_index: 0, max_val_grp_loss:  17.9261, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.1862, max_cur_train_grp_loss_index: 0, 
2024-09-17 22:31:52,835 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:386] - INFO: Policy parameter learned solely on the preference data rdpo: [10.76727875  6.37311117  7.24022776  5.06535282].
2024-09-17 22:31:53,161 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:397] - INFO: Uniform reward: 3.8307, 3.8307, 3.2183
2024-09-17 22:31:53,161 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Optimal reward: 3.8720, 3.8720, 3.3668
2024-09-17 22:31:53,162 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Policy reward: 3.5686, 3.8255, 3.2174
2024-09-17 22:31:53,162 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Reward Error: 0.0784, 0.0120, 0.0444
2024-09-17 22:31:53,839 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:415] - INFO: Optimal reward: 3.8720, 3.8720, 3.3668
Known param reward: [[3.8719916343688965, 3.4697206020355225, 3.3270106315612793], [3.4697206020355225, 3.8719916343688965, 3.154261827468872], [3.8341760635375977, 3.6066181659698486, 3.3668301105499268]], Known param reward error: [[0.0, 0.10389253653409325, 0.011826993843221712], [0.10389253653409325, 0.0, 0.06313602887623412], [0.009766439187429305, 0.06853668433669062, 0.0]].
