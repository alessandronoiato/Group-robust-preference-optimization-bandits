2024-09-19 00:25:43,240 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log_rdpo/2024_09_19_00_03_26/swapped_noise1.0_[1,1.0,1]_2030
2024-09-19 00:25:43,242 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2030
2024-09-19 00:25:43,243 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-09-19 00:25:43,400 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.3234, l2 distance: 29.0058, acc: 0.84.
2024-09-19 00:25:43,400 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-19 00:25:43,401 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [12.81511744  6.94562577 12.93366958  5.46843   ]
2024-09-19 00:25:43,602 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.5538, 3.8595, 3.2321
2024-09-19 00:25:43,867 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-19 00:25:45,186 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  12.8794, val_loss:  14.7460, grad_norm: 0.3330, live_grad: 0.0000, reward_err: 0.0996, 0.0003, 0.0571, KL_dist: 1.9698, 0.9837, 1.5773, param: [12.27904443  4.79015152 11.2958818   3.49617203], weights: [0.33319507 0.33285513 0.3339498 ], train_wt_loss:  38.6383, val_wt_loss: 44.2380, train_grp_loss: [21.04998389  5.19166821 17.63013306], val_grp_loss: [20.12097213  6.01864921 17.8530228 ], train_hist_grp_loss: [0.20934004 0.10726143 0.43559531], cur_train_grp_loss: [0.20934004 0.10726143 0.43559531], max_reward_err:  0.0996, max_reward_err_index: 0, max_kl_dist:  1.9698, max_kl_dist_index: 0, max_train_grp_loss:  21.0500, max_train_grp_loss_index: 0, max_val_grp_loss:  20.1210, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4356, max_cur_train_grp_loss_index: 2, 
2024-09-19 00:25:49,666 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  100, train_loss:  12.8981, val_loss:  14.7000, grad_norm: 0.0261, live_grad: 0.0000, reward_err: 0.0938, 0.0007, 0.0523, KL_dist: 1.9492, 0.9998, 1.5672, param: [12.29112777  5.19225066 11.24153038  3.86687375], weights: [0.32996225 0.28140066 0.38863709], train_wt_loss:  38.6943, val_wt_loss: 44.1001, train_grp_loss: [20.75404372  5.55465627 17.32394361], val_grp_loss: [19.849451    6.39899041 17.61438742], train_hist_grp_loss: [19.74914347  3.82926616 36.11591559], cur_train_grp_loss: [0.19399299 0.0385437  0.35361824], max_reward_err:  0.0938, max_reward_err_index: 0, max_kl_dist:  1.9492, max_kl_dist_index: 0, max_train_grp_loss:  20.7540, max_train_grp_loss_index: 0, max_val_grp_loss:  19.8495, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.3536, max_cur_train_grp_loss_index: 2, 
2024-09-19 00:25:53,978 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  199, train_loss:  12.9678, val_loss:  14.6766, grad_norm: 0.0650,  live_grad: 0.0000, reward_err: 0.0893, 0.0022, 0.0484, KL_dist: 1.9314, 1.0274, 1.5613, param: [12.33576164  5.66934846 11.16836393  4.30535143], weights: [0.3215174  0.23585577 0.44262683], train_wt_loss:  38.9034, val_wt_loss: 44.0297, train_grp_loss: [20.41102107  6.07780186 16.96247874], val_grp_loss: [19.53241221  6.93597491 17.33419028], train_hist_grp_loss: [38.79832851  7.81520997 70.76586717], cur_train_grp_loss: [0.19079198 0.04216333 0.3462536 ], max_reward_err:  0.0893, max_reward_err_index: 0, max_kl_dist:  1.9314, max_kl_dist_index: 0, max_train_grp_loss:  20.4110, max_train_grp_loss_index: 0, max_val_grp_loss:  19.5324, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.3463, max_cur_train_grp_loss_index: 2, 
2024-09-19 00:25:54,196 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:387] - INFO: Policy parameter learned solely on the preference data rdpo: [12.33576164  5.66934846 11.16836393  4.30535143].
2024-09-19 00:25:54,525 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Uniform reward: 3.8314, 3.8314, 3.2209
2024-09-19 00:25:54,526 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Optimal reward: 3.8748, 3.8748, 3.3766
2024-09-19 00:25:54,526 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Policy reward: 3.5290, 3.8664, 3.2130
2024-09-19 00:25:54,527 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Reward Error: 0.0893, 0.0022, 0.0484
2024-09-19 00:25:55,210 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:416] - INFO: Optimal reward: 3.8748, 3.8748, 3.3766
Known param reward: [[3.874847650527954, 3.4763882160186768, 3.337296485900879], [3.4763882160186768, 3.874847650527954, 3.175377130508423], [3.8370981216430664, 3.5955355167388916, 3.3765645027160645]], Known param reward error: [[0.0, 0.102832284117025, 0.011629576980862906], [0.102832284117025, 0.0, 0.059583452958120335], [0.009742196929921686, 0.0720833846850742, 0.0]].
