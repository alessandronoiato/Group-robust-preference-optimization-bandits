2024-09-19 00:21:57,919 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log_rdpo/2024_09_19_00_03_26/swapped_noise1.0_[1,1.0,1]_2021
2024-09-19 00:21:57,920 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2021
2024-09-19 00:21:57,921 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-09-19 00:21:58,084 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.3566, l2 distance: 29.5613, acc: 0.82.
2024-09-19 00:21:58,085 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-19 00:21:58,085 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [12.9300958   5.57206545 13.55993407  6.18568546]
2024-09-19 00:21:58,297 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.5203, 3.8700, 3.1356
2024-09-19 00:21:58,555 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-19 00:21:59,879 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  13.9151, val_loss:  14.3378, grad_norm: 0.3116, live_grad: 0.0000, reward_err: 0.1134, 0.0000, 0.0690, KL_dist: 1.9738, 1.1352, 1.6140, param: [12.84605077  3.71658538 12.41779599  4.18155601], weights: [0.33311014 0.33290958 0.33398029], train_wt_loss:  41.7454, val_wt_loss: 43.0134, train_grp_loss: [21.8409914   5.00616752 16.37289558], val_grp_loss: [20.85907605  5.38287655 17.30322648], train_hist_grp_loss: [0.19146774 0.13124152 0.45234757], cur_train_grp_loss: [0.19146774 0.13124152 0.45234757], max_reward_err:  0.1134, max_reward_err_index: 0, max_kl_dist:  1.9738, max_kl_dist_index: 0, max_train_grp_loss:  21.8410, max_train_grp_loss_index: 0, max_val_grp_loss:  20.8591, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4523, max_cur_train_grp_loss_index: 2, 
2024-09-19 00:22:04,349 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  100, train_loss:  13.9306, val_loss:  14.2479, grad_norm: 0.0218, live_grad: 0.0000, reward_err: 0.1065, 0.0000, 0.0629, KL_dist: 1.9751, 1.1547, 1.6210, param: [12.63895449  4.02936893 12.74995564  4.55499249], weights: [0.32882878 0.2879028  0.38326842], train_wt_loss:  41.7917, val_wt_loss: 42.7437, train_grp_loss: [21.61089973  5.39851279 16.05977774], val_grp_loss: [20.58863529  5.61741876 17.04651072], train_hist_grp_loss: [17.57492665  4.28349825 32.89476451], cur_train_grp_loss: [0.17290666 0.04315174 0.32126207], max_reward_err:  0.1065, max_reward_err_index: 0, max_kl_dist:  1.9751, max_kl_dist_index: 0, max_train_grp_loss:  21.6109, max_train_grp_loss_index: 0, max_val_grp_loss:  20.5886, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.3213, max_cur_train_grp_loss_index: 2, 
2024-09-19 00:22:08,727 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  199, train_loss:  13.9846, val_loss:  14.1751, grad_norm: 0.0525,  live_grad: 0.0000, reward_err: 0.1021, 0.0000, 0.0592, KL_dist: 1.9853, 1.1822, 1.6372, param: [12.42826442  4.38169024 13.12783422  4.9794707 ], weights: [0.32061655 0.24761065 0.43177281], train_wt_loss:  41.9537, val_wt_loss: 42.5252, train_grp_loss: [21.35714622  5.92097826 15.71213864], val_grp_loss: [20.29037518  5.95400711 16.76048247], train_hist_grp_loss: [34.59295102  8.7541202  64.3583198 ], cur_train_grp_loss: [0.17087867 0.04731947 0.31431649], max_reward_err:  0.1021, max_reward_err_index: 0, max_kl_dist:  1.9853, max_kl_dist_index: 0, max_train_grp_loss:  21.3571, max_train_grp_loss_index: 0, max_val_grp_loss:  20.2904, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.3143, max_cur_train_grp_loss_index: 2, 
2024-09-19 00:22:08,950 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:387] - INFO: Policy parameter learned solely on the preference data rdpo: [12.42826442  4.38169024 13.12783422  4.9794707 ].
2024-09-19 00:22:09,281 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Uniform reward: 3.8390, 3.8390, 3.1881
2024-09-19 00:22:09,282 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Optimal reward: 3.8748, 3.8748, 3.3008
2024-09-19 00:22:09,282 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Policy reward: 3.4792, 3.8747, 3.1055
2024-09-19 00:22:09,282 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Reward Error: 0.1021, 0.0000, 0.0592
2024-09-19 00:22:09,962 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:416] - INFO: Optimal reward: 3.8748, 3.8748, 3.3008
Known param reward: [[3.8748409748077393, 3.4526655673980713, 3.2780399322509766], [3.4526655673980713, 3.8748409748077393, 3.086048126220703], [3.8403704166412354, 3.587584972381592, 3.300816535949707]], Known param reward error: [[0.0, 0.10895296352919757, 0.00690029374570411], [0.10895296352919757, 0.0, 0.06506523685576818], [0.008895992994451664, 0.07413362362319925, 0.0]].
