2024-09-19 00:37:44,351 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log_rdpo/2024_09_19_00_03_26/swapped_noise0.7_[1,0.7,1]_2029
2024-09-19 00:37:44,353 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2029
2024-09-19 00:37:44,353 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-09-19 00:37:44,516 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.4360, l2 distance: 17.6893, acc: 0.78.
2024-09-19 00:37:44,517 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-19 00:37:44,518 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [8.45198418 4.08444303 9.00463429 3.74875698]
2024-09-19 00:37:44,721 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.5361, 3.8741, 3.2061
2024-09-19 00:37:44,976 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-19 00:37:46,297 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  15.5847, val_loss:  15.0668, grad_norm: 0.2618, live_grad: 0.0000, reward_err: 0.1044, 0.0001, 0.0609, KL_dist: 1.7445, 0.8650, 1.4002, param: [10.13807846  4.22380206 12.11796393  3.52534785], weights: [0.33297622 0.33280623 0.33421755], train_wt_loss:  46.7542, val_wt_loss: 45.2005, train_grp_loss: [21.27217909  8.762941   19.32013025], val_grp_loss: [20.04988697  5.44047175 18.69020423], train_hist_grp_loss: [0.17864523 0.12757943 0.55074922], cur_train_grp_loss: [0.17864523 0.12757943 0.55074922], max_reward_err:  0.1044, max_reward_err_index: 0, max_kl_dist:  1.7445, max_kl_dist_index: 0, max_train_grp_loss:  21.2722, max_train_grp_loss_index: 0, max_val_grp_loss:  20.0499, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.5507, max_cur_train_grp_loss_index: 2, 
2024-09-19 00:37:50,814 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  100, train_loss:  15.6004, val_loss:  15.0013, grad_norm: 0.0236, live_grad: 0.0000, reward_err: 0.1002, 0.0005, 0.0576, KL_dist: 1.7481, 0.8821, 1.4119, param: [ 9.89343236  4.6027367  12.39487377  3.87192623], weights: [0.30594592 0.27800911 0.41604498], train_wt_loss:  46.8013, val_wt_loss: 45.0040, train_grp_loss: [21.02608356  9.13997453 19.01377913], val_grp_loss: [19.81039129  5.72189318 18.48814871], train_hist_grp_loss: [16.5776283   7.00218164 47.31613122], cur_train_grp_loss: [0.16301403 0.07027233 0.46383336], max_reward_err:  0.1002, max_reward_err_index: 0, max_kl_dist:  1.7481, max_kl_dist_index: 0, max_train_grp_loss:  21.0261, max_train_grp_loss_index: 0, max_val_grp_loss:  19.8104, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4638, max_cur_train_grp_loss_index: 2, 
2024-09-19 00:37:55,200 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  199, train_loss:  15.6627, val_loss:  14.9494, grad_norm: 0.0635,  live_grad: 0.0000, reward_err: 0.0960, 0.0018, 0.0544, KL_dist: 1.7595, 0.9109, 1.4329, param: [ 9.63838532  5.07628348 12.71509739  4.30214109], weights: [0.27343165 0.22737502 0.49919333], train_wt_loss:  46.9880, val_wt_loss: 44.8481, train_grp_loss: [20.72632923  9.69821657 18.64227837], val_grp_loss: [19.5138929   6.16685129 18.23559562], train_hist_grp_loss: [32.60394107 14.158848   92.79812013], cur_train_grp_loss: [0.16069509 0.07454912 0.45479029], max_reward_err:  0.0960, max_reward_err_index: 0, max_kl_dist:  1.7595, max_kl_dist_index: 0, max_train_grp_loss:  20.7263, max_train_grp_loss_index: 0, max_val_grp_loss:  19.5139, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4548, max_cur_train_grp_loss_index: 2, 
2024-09-19 00:37:55,420 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:387] - INFO: Policy parameter learned solely on the preference data rdpo: [ 9.63838532  5.07628348 12.71509739  4.30214109].
2024-09-19 00:37:55,746 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Uniform reward: 3.8387, 3.8387, 3.2243
2024-09-19 00:37:55,746 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Optimal reward: 3.8841, 3.8841, 3.3675
2024-09-19 00:37:55,747 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Policy reward: 3.5111, 3.8771, 3.1843
2024-09-19 00:37:55,747 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Reward Error: 0.0960, 0.0018, 0.0544
2024-09-19 00:37:56,431 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:416] - INFO: Optimal reward: 3.8841, 3.8841, 3.3675
Known param reward: [[3.884077310562134, 3.4758739471435547, 3.3304951190948486], [3.4758739471435547, 3.884077310562134, 3.1624059677124023], [3.847635269165039, 3.6067681312561035, 3.3674604892730713]], Known param reward error: [[0.0, 0.10509661131320291, 0.010977224616584088], [0.10509661131320291, 0.0, 0.060892925756326766], [0.009382419165034734, 0.07139641081600817, 0.0]].
