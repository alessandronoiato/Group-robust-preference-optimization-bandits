2024-09-19 00:26:58,822 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log_rdpo/2024_09_19_00_03_26/swapped_noise0.9_[1,0.9,1]_2023
2024-09-19 00:26:58,823 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2023
2024-09-19 00:26:58,824 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-09-19 00:26:58,982 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.3607, l2 distance: 29.7318, acc: 0.84.
2024-09-19 00:26:58,983 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-19 00:26:58,983 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [12.24983848  7.46889102 13.19746037  7.26665612]
2024-09-19 00:26:59,188 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.5955, 3.8423, 3.1920
2024-09-19 00:26:59,437 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-19 00:27:00,754 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  14.2833, val_loss:  14.2758, grad_norm: 0.3069, live_grad: 0.0000, reward_err: 0.0905, 0.0006, 0.0508, KL_dist: 1.7700, 1.0464, 1.4538, param: [12.00801681  4.49354763 11.62841664  5.25371773], weights: [0.33307434 0.33299958 0.33392608], train_wt_loss:  42.8498, val_wt_loss: 42.8275, train_grp_loss: [20.13542511  6.79709992 16.83371395], val_grp_loss: [20.27179553  6.4213025  16.64132682], train_hist_grp_loss: [0.17274938 0.15030288 0.42814279], cur_train_grp_loss: [0.17274938 0.15030288 0.42814279], max_reward_err:  0.0905, max_reward_err_index: 0, max_kl_dist:  1.7700, max_kl_dist_index: 0, max_train_grp_loss:  20.1354, max_train_grp_loss_index: 0, max_val_grp_loss:  20.2718, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4281, max_cur_train_grp_loss_index: 2, 
2024-09-19 00:27:05,306 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  100, train_loss:  14.2927, val_loss:  14.2726, grad_norm: 0.0162, live_grad: 0.0000, reward_err: 0.0874, 0.0008, 0.0483, KL_dist: 1.7794, 1.0752, 1.4681, param: [12.09680295  4.80721496 11.66568706  5.55222879], weights: [0.3223851  0.29290061 0.38471428], train_wt_loss:  42.8782, val_wt_loss: 42.8179, train_grp_loss: [19.92901287  7.12594701 16.64818066], val_grp_loss: [20.05746838  6.80675263 16.44273893], train_hist_grp_loss: [15.58431757  5.99297291 33.25973157], cur_train_grp_loss: [0.1533168  0.05985058 0.32647392], max_reward_err:  0.0874, max_reward_err_index: 0, max_kl_dist:  1.7794, max_kl_dist_index: 0, max_train_grp_loss:  19.9290, max_train_grp_loss_index: 0, max_val_grp_loss:  20.0575, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.3265, max_cur_train_grp_loss_index: 2, 
2024-09-19 00:27:09,683 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  199, train_loss:  14.3258, val_loss:  14.2890, grad_norm: 0.0391,  live_grad: 0.0000, reward_err: 0.0853, 0.0019, 0.0464, KL_dist: 1.7944, 1.1113, 1.4881, param: [12.23371241  5.1625575  11.69106803  5.8837853 ], weights: [0.3081481  0.25587224 0.43597966], train_wt_loss:  42.9774, val_wt_loss: 42.8671, train_grp_loss: [19.70320056  7.54629788 16.43751294], val_grp_loss: [19.81880787  7.29479483 16.22103951], train_hist_grp_loss: [30.67728041 12.087055   65.3787895 ], cur_train_grp_loss: [0.15158145 0.063374   0.32234857], max_reward_err:  0.0853, max_reward_err_index: 0, max_kl_dist:  1.7944, max_kl_dist_index: 0, max_train_grp_loss:  19.7032, max_train_grp_loss_index: 0, max_val_grp_loss:  19.8188, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.3223, max_cur_train_grp_loss_index: 2, 
2024-09-19 00:27:09,907 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:387] - INFO: Policy parameter learned solely on the preference data rdpo: [12.23371241  5.1625575  11.69106803  5.8837853 ].
2024-09-19 00:27:10,237 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Uniform reward: 3.8305, 3.8305, 3.1813
2024-09-19 00:27:10,238 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Optimal reward: 3.8691, 3.8691, 3.3071
2024-09-19 00:27:10,238 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Policy reward: 3.5393, 3.8620, 3.1535
2024-09-19 00:27:10,239 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Reward Error: 0.0853, 0.0019, 0.0464
2024-09-19 00:27:10,925 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:416] - INFO: Optimal reward: 3.8691, 3.8691, 3.3071
Known param reward: [[3.8691489696502686, 3.4901177883148193, 3.2788524627685547], [3.4901177883148193, 3.8691489696502686, 3.1177523136138916], [3.8334453105926514, 3.6074156761169434, 3.3071203231811523]], Known param reward error: [[0.0, 0.09796241610457035, 0.008547575428222254], [0.09796241610457035, 0.0, 0.05726069542734561], [0.00922778092486949, 0.06764621770481564, 0.0]].
