2024-09-19 00:34:51,348 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log_rdpo/2024_09_19_00_03_26/swapped_noise0.7_[1,0.7,1]_2022
2024-09-19 00:34:51,350 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2022
2024-09-19 00:34:51,350 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-09-19 00:34:51,518 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.4860, l2 distance: 13.4347, acc: 0.77.
2024-09-19 00:34:51,519 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-19 00:34:51,520 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [6.72509148 2.81764665 7.31992199 3.84579016]
2024-09-19 00:34:51,732 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.5185, 3.8475, 3.1578
2024-09-19 00:34:51,985 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-19 00:34:53,365 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  16.9518, val_loss:  14.0881, grad_norm: 0.2310, live_grad: 0.0000, reward_err: 0.0964, 0.0011, 0.0548, KL_dist: 1.5027, 0.7619, 1.2005, param: [ 9.67852176  3.26394908 10.92240132  4.86010691], weights: [0.33303609 0.33295587 0.33400804], train_wt_loss:  50.8554, val_wt_loss: 42.2644, train_grp_loss: [20.41138739 12.75071963 19.35493406], val_grp_loss: [19.15447875  5.69957835 18.04159005], train_hist_grp_loss: [0.17627665 0.15218739 0.46769648], cur_train_grp_loss: [0.17627665 0.15218739 0.46769648], max_reward_err:  0.0964, max_reward_err_index: 0, max_kl_dist:  1.5027, max_kl_dist_index: 0, max_train_grp_loss:  20.4114, max_train_grp_loss_index: 0, max_val_grp_loss:  19.1545, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4677, max_cur_train_grp_loss_index: 2, 
2024-09-19 00:34:58,010 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  100, train_loss:  16.9587, val_loss:  14.0275, grad_norm: 0.0160, live_grad: 0.0000, reward_err: 0.0940, 0.0014, 0.0526, KL_dist: 1.5124, 0.7856, 1.2128, param: [ 9.78794707  3.48935458 10.972202    5.09572414], weights: [0.31053047 0.29111551 0.39835402], train_wt_loss:  50.8762, val_wt_loss: 42.0826, train_grp_loss: [20.25261936 12.97910208 19.19124814], val_grp_loss: [18.98537165  5.83610894 17.87798896], train_hist_grp_loss: [16.57557544 10.11938502 41.48148331], cur_train_grp_loss: [0.16334153 0.10059252 0.4083626 ], max_reward_err:  0.0940, max_reward_err_index: 0, max_kl_dist:  1.5124, max_kl_dist_index: 0, max_train_grp_loss:  20.2526, max_train_grp_loss_index: 0, max_val_grp_loss:  18.9854, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4084, max_cur_train_grp_loss_index: 2, 
2024-09-19 00:35:02,533 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  199, train_loss:  16.9850, val_loss:  13.9679, grad_norm: 0.0411,  live_grad: 0.0000, reward_err: 0.0922, 0.0021, 0.0511, KL_dist: 1.5257, 0.8161, 1.2291, param: [ 9.93529933  3.75665262 11.02314275  5.37871694], weights: [0.28444993 0.25107423 0.46447583], train_wt_loss:  50.9551, val_wt_loss: 41.9038, train_grp_loss: [20.06524564 13.29153861 18.99604207], val_grp_loss: [18.78511763  6.03412193 17.68274993], train_hist_grp_loss: [32.67313422 20.19227377 81.70836175], cur_train_grp_loss: [0.16183311 0.10300656 0.40421695], max_reward_err:  0.0922, max_reward_err_index: 0, max_kl_dist:  1.5257, max_kl_dist_index: 0, max_train_grp_loss:  20.0652, max_train_grp_loss_index: 0, max_val_grp_loss:  18.7851, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4042, max_cur_train_grp_loss_index: 2, 
2024-09-19 00:35:02,756 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:387] - INFO: Policy parameter learned solely on the preference data rdpo: [ 9.93529933  3.75665262 11.02314275  5.37871694].
2024-09-19 00:35:03,097 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Uniform reward: 3.8288, 3.8288, 3.1923
2024-09-19 00:35:03,098 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Optimal reward: 3.8608, 3.8608, 3.3174
2024-09-19 00:35:03,099 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Policy reward: 3.5050, 3.8527, 3.1479
2024-09-19 00:35:03,099 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Reward Error: 0.0922, 0.0021, 0.0511
2024-09-19 00:35:03,797 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:416] - INFO: Optimal reward: 3.8608, 3.8608, 3.3174
Known param reward: [[3.8608431816101074, 3.4672656059265137, 3.286299705505371], [3.4672656059265137, 3.8608431816101074, 3.1212518215179443], [3.8267719745635986, 3.5796079635620117, 3.3174452781677246]], Known param reward error: [[0.0, 0.10194083446804438, 0.009388420923571552], [0.10194083446804438, 0.0, 0.05913992250028639], [0.008824809878006984, 0.07284295290408836, 0.0]].
