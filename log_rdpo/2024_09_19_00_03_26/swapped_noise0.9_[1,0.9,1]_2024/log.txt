2024-09-19 00:27:22,982 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log_rdpo/2024_09_19_00_03_26/swapped_noise0.9_[1,0.9,1]_2024
2024-09-19 00:27:22,984 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2024
2024-09-19 00:27:22,985 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-09-19 00:27:23,142 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.3578, l2 distance: 26.3512, acc: 0.80.
2024-09-19 00:27:23,143 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-19 00:27:23,144 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [13.34414817  4.47039801 10.55789716  5.99404178]
2024-09-19 00:27:23,350 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.4399, 3.7812, 3.0773
2024-09-19 00:27:23,598 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-19 00:27:24,910 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  13.6589, val_loss:  14.3465, grad_norm: 0.2943, live_grad: 0.0000, reward_err: 0.0959, 0.0001, 0.0576, KL_dist: 1.9528, 1.0615, 1.5760, param: [12.74228289  3.75834346 11.73826257  4.64080856], weights: [0.33302288 0.33283869 0.33413842], train_wt_loss:  40.9767, val_wt_loss: 43.0396, train_grp_loss: [19.95143254  6.88460878 17.57074465], val_grp_loss: [19.49558011  5.89947235 17.18907939], train_hist_grp_loss: [0.18243758 0.12711409 0.5168515 ], cur_train_grp_loss: [0.18243758 0.12711409 0.5168515 ], max_reward_err:  0.0959, max_reward_err_index: 0, max_kl_dist:  1.9528, max_kl_dist_index: 0, max_train_grp_loss:  19.9514, max_train_grp_loss_index: 0, max_val_grp_loss:  19.4956, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.5169, max_cur_train_grp_loss_index: 2, 
2024-09-19 00:27:29,537 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  100, train_loss:  13.6716, val_loss:  14.2762, grad_norm: 0.0200, live_grad: 0.0000, reward_err: 0.0921, 0.0002, 0.0540, KL_dist: 1.9616, 1.0901, 1.5877, param: [12.39837703  4.04579313 12.26764859  4.91761569], weights: [0.31280028 0.27947759 0.40772213], train_wt_loss:  41.0149, val_wt_loss: 42.8286, train_grp_loss: [19.84256729  7.10715285 17.24434673], val_grp_loss: [19.28430398  6.13659987 16.97188829], train_hist_grp_loss: [16.49192011  5.22764289 42.99402103], cur_train_grp_loss: [0.16265294 0.0518575  0.42068272], max_reward_err:  0.0921, max_reward_err_index: 0, max_kl_dist:  1.9616, max_kl_dist_index: 0, max_train_grp_loss:  19.8426, max_train_grp_loss_index: 0, max_val_grp_loss:  19.2843, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4207, max_cur_train_grp_loss_index: 2, 
2024-09-19 00:27:33,877 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  199, train_loss:  13.7212, val_loss:  14.2187, grad_norm: 0.0522,  live_grad: 0.0000, reward_err: 0.0886, 0.0007, 0.0513, KL_dist: 1.9904, 1.1291, 1.6196, param: [11.95613974  4.38775633 12.95510243  5.25159149], weights: [0.28755572 0.23058859 0.48185569], train_wt_loss:  41.1637, val_wt_loss: 42.6561, train_grp_loss: [19.73353882  7.43151479 16.84791829], val_grp_loss: [19.0405181   6.4880976  16.71780459], train_hist_grp_loss: [32.55005152 10.47189785 84.17285422], cur_train_grp_loss: [0.16175947 0.05421582 0.41103064], max_reward_err:  0.0886, max_reward_err_index: 0, max_kl_dist:  1.9904, max_kl_dist_index: 0, max_train_grp_loss:  19.7335, max_train_grp_loss_index: 0, max_val_grp_loss:  19.0405, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4110, max_cur_train_grp_loss_index: 2, 
2024-09-19 00:27:34,099 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:387] - INFO: Policy parameter learned solely on the preference data rdpo: [11.95613974  4.38775633 12.95510243  5.25159149].
2024-09-19 00:27:34,431 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Uniform reward: 3.7421, 3.7421, 3.1080
2024-09-19 00:27:34,432 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Optimal reward: 3.7876, 3.7876, 3.2552
2024-09-19 00:27:34,432 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Policy reward: 3.4520, 3.7851, 3.0884
2024-09-19 00:27:34,433 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Reward Error: 0.0886, 0.0007, 0.0513
2024-09-19 00:27:35,110 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:416] - INFO: Optimal reward: 3.7876, 3.7876, 3.2552
Known param reward: [[3.7876079082489014, 3.425462007522583, 3.221684455871582], [3.425462007522583, 3.7876079082489014, 3.069401741027832], [3.755828619003296, 3.553105354309082, 3.2552034854888916]], Known param reward error: [[0.0, 0.09561335531526725, 0.010297061233416388], [0.09561335531526725, 0.0, 0.057078380902862186], [0.008390332372153529, 0.06191310178360972, 0.0]].
