2024-09-19 00:29:28,795 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log_rdpo/2024_09_19_00_03_26/swapped_noise0.9_[1,0.9,1]_2029
2024-09-19 00:29:28,797 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2029
2024-09-19 00:29:28,797 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-09-19 00:29:28,960 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.3922, l2 distance: 23.9064, acc: 0.84.
2024-09-19 00:29:28,961 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-19 00:29:28,962 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [ 9.06453268  6.49602515 11.99559379  5.81513793]
2024-09-19 00:29:29,175 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.5470, 3.8297, 3.1719
2024-09-19 00:29:29,406 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-19 00:29:30,724 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  14.7644, val_loss:  14.6486, grad_norm: 0.2877, live_grad: 0.0000, reward_err: 0.0990, 0.0021, 0.0582, KL_dist: 1.8604, 0.9786, 1.5424, param: [ 8.89931201  4.8997856  13.82221874  5.0197232 ], weights: [0.33296465 0.33288588 0.33414947], train_wt_loss:  44.2932, val_wt_loss: 43.9458, train_grp_loss: [19.53157547  9.01619404 17.99122163], val_grp_loss: [19.41067171  6.08409469 17.84348112], train_hist_grp_loss: [0.17276123 0.14910397 0.52797062], cur_train_grp_loss: [0.17276123 0.14910397 0.52797062], max_reward_err:  0.0990, max_reward_err_index: 0, max_kl_dist:  1.8604, max_kl_dist_index: 0, max_train_grp_loss:  19.5316, max_train_grp_loss_index: 0, max_val_grp_loss:  19.4107, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.5280, max_cur_train_grp_loss_index: 2, 
2024-09-19 00:29:35,239 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  100, train_loss:  14.7769, val_loss:  14.6062, grad_norm: 0.0220, live_grad: 0.0000, reward_err: 0.0970, 0.0029, 0.0562, KL_dist: 1.8489, 1.0090, 1.5357, param: [ 9.17471858  5.19828469 13.68556401  5.32833542], weights: [0.30701935 0.28332229 0.40965836], train_wt_loss:  44.3307, val_wt_loss: 43.8186, train_grp_loss: [19.32010877  9.34495745 17.70557131], val_grp_loss: [19.19434275  6.44546836 17.5953962 ], train_hist_grp_loss: [15.2347896   7.20222219 44.07606611], cur_train_grp_loss: [0.14978616 0.07185419 0.4319201 ], max_reward_err:  0.0970, max_reward_err_index: 0, max_kl_dist:  1.8489, max_kl_dist_index: 0, max_train_grp_loss:  19.3201, max_train_grp_loss_index: 0, max_val_grp_loss:  19.1943, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4319, max_cur_train_grp_loss_index: 2, 
2024-09-19 00:29:39,575 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  199, train_loss:  14.8254, val_loss:  14.5770, grad_norm: 0.0578,  live_grad: 0.0000, reward_err: 0.0929, 0.0039, 0.0526, KL_dist: 1.8397, 1.0497, 1.5319, param: [ 9.53377888  5.55981891 13.51197047  5.70216811], weights: [0.27660254 0.23692086 0.4864766 ], train_wt_loss:  44.4761, val_wt_loss: 43.7309, train_grp_loss: [19.07074214  9.81262192 17.36200253], val_grp_loss: [18.93723536  6.94739493 17.29455578], train_hist_grp_loss: [29.96986714 14.48432559 86.43058785], cur_train_grp_loss: [0.14785643 0.07543849 0.42355584], max_reward_err:  0.0929, max_reward_err_index: 0, max_kl_dist:  1.8397, max_kl_dist_index: 0, max_train_grp_loss:  19.0707, max_train_grp_loss_index: 0, max_val_grp_loss:  18.9372, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4236, max_cur_train_grp_loss_index: 2, 
2024-09-19 00:29:39,803 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:387] - INFO: Policy parameter learned solely on the preference data rdpo: [ 9.53377888  5.55981891 13.51197047  5.70216811].
2024-09-19 00:29:40,129 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Uniform reward: 3.8215, 3.8215, 3.1846
2024-09-19 00:29:40,130 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Optimal reward: 3.8606, 3.8606, 3.3138
2024-09-19 00:29:40,130 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Policy reward: 3.5019, 3.8455, 3.1395
2024-09-19 00:29:40,131 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Reward Error: 0.0929, 0.0039, 0.0526
2024-09-19 00:29:40,830 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:416] - INFO: Optimal reward: 3.8606, 3.8606, 3.3138
Known param reward: [[3.860621452331543, 3.4612629413604736, 3.285645008087158], [3.4612629413604736, 3.860621452331543, 3.115248203277588], [3.8245344161987305, 3.578054666519165, 3.3138341903686523]], Known param reward error: [[0.0, 0.1034440998430149, 0.008506515613672933], [0.1034440998430149, 0.0, 0.0599263498663379], [0.009347468167597338, 0.07319204674722188, 0.0]].
