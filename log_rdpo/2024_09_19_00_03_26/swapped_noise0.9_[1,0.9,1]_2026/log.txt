2024-09-19 00:28:13,523 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log_rdpo/2024_09_19_00_03_26/swapped_noise0.9_[1,0.9,1]_2026
2024-09-19 00:28:13,525 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2026
2024-09-19 00:28:13,526 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-09-19 00:28:13,686 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.3801, l2 distance: 24.0384, acc: 0.83.
2024-09-19 00:28:13,687 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-19 00:28:13,688 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [11.01885555  4.26191254 10.61306472  7.05320076]
2024-09-19 00:28:13,896 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.5574, 3.8319, 3.1799
2024-09-19 00:28:14,147 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-19 00:28:15,474 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  14.3656, val_loss:  14.8943, grad_norm: 0.2549, live_grad: 0.0000, reward_err: 0.0950, 0.0009, 0.0528, KL_dist: 1.6973, 0.9495, 1.3705, param: [11.28801543  2.98567339 11.30407512  5.62538742], weights: [0.3330633  0.33289197 0.33404472], train_wt_loss:  43.0968, val_wt_loss: 44.6828, train_grp_loss: [18.69453509  7.92646023 17.41035283], val_grp_loss: [19.81249448  6.08747176 17.99294456], train_hist_grp_loss: [0.15766481 0.10621133 0.45189582], cur_train_grp_loss: [0.15766481 0.10621133 0.45189582], max_reward_err:  0.0950, max_reward_err_index: 0, max_kl_dist:  1.6973, max_kl_dist_index: 0, max_train_grp_loss:  18.6945, max_train_grp_loss_index: 0, max_val_grp_loss:  19.8125, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4519, max_cur_train_grp_loss_index: 2, 
2024-09-19 00:28:20,005 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  100, train_loss:  14.3748, val_loss:  14.8361, grad_norm: 0.0154, live_grad: 0.0000, reward_err: 0.0945, 0.0014, 0.0525, KL_dist: 1.7190, 0.9763, 1.3933, param: [11.83329762  3.20065002 10.98416943  5.8569845 ], weights: [0.31226949 0.2924952  0.3952353 ], train_wt_loss:  43.1244, val_wt_loss: 44.5082, train_grp_loss: [18.56527911  8.21416769 17.14482047], val_grp_loss: [19.66449254  6.23731408 17.83489052], train_hist_grp_loss: [13.65885624  7.11702486 37.22032705], cur_train_grp_loss: [0.13454085 0.07139905 0.36484273], max_reward_err:  0.0945, max_reward_err_index: 0, max_kl_dist:  1.7190, max_kl_dist_index: 0, max_train_grp_loss:  18.5653, max_train_grp_loss_index: 0, max_val_grp_loss:  19.6645, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.3648, max_cur_train_grp_loss_index: 2, 
2024-09-19 00:28:24,399 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  199, train_loss:  14.4071, val_loss:  14.7874, grad_norm: 0.0384,  live_grad: 0.0000, reward_err: 0.0925, 0.0017, 0.0512, KL_dist: 1.7564, 1.0098, 1.4316, param: [12.43599379  3.44470716 10.65561796  6.12157147], weights: [0.28839016 0.25427881 0.45733104], train_wt_loss:  43.2213, val_wt_loss: 44.3623, train_grp_loss: [18.42389607  8.58600453 16.85630706], val_grp_loss: [19.5027063   6.44980065 17.66144937], train_hist_grp_loss: [26.92805423 14.33975992 73.03737691], cur_train_grp_loss: [0.13351735 0.07462382 0.35870938], max_reward_err:  0.0925, max_reward_err_index: 0, max_kl_dist:  1.7564, max_kl_dist_index: 0, max_train_grp_loss:  18.4239, max_train_grp_loss_index: 0, max_val_grp_loss:  19.5027, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.3587, max_cur_train_grp_loss_index: 2, 
2024-09-19 00:28:24,618 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:387] - INFO: Policy parameter learned solely on the preference data rdpo: [12.43599379  3.44470716 10.65561796  6.12157147].
2024-09-19 00:28:24,952 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Uniform reward: 3.8188, 3.8188, 3.1808
2024-09-19 00:28:24,953 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Optimal reward: 3.8594, 3.8594, 3.3085
2024-09-19 00:28:24,953 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Policy reward: 3.5024, 3.8528, 3.1392
2024-09-19 00:28:24,954 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Reward Error: 0.0925, 0.0017, 0.0512
2024-09-19 00:28:25,656 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:416] - INFO: Optimal reward: 3.8594, 3.8594, 3.3085
Known param reward: [[3.8594422340393066, 3.4673831462860107, 3.2762653827667236], [3.4673831462860107, 3.8594422340393066, 3.114921808242798], [3.819638729095459, 3.5962886810302734, 3.3084986209869385]], Known param reward error: [[0.0, 0.10158439069133712, 0.009742557550348786], [0.10158439069133712, 0.0, 0.058508959778981524], [0.010313279103594501, 0.06818434816515331, 0.0]].
