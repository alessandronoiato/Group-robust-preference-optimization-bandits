2024-09-19 00:30:43,033 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log_rdpo/2024_09_19_00_03_26/swapped_noise0.8_[1,0.8,1]_2022
2024-09-19 00:30:43,035 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2022
2024-09-19 00:30:43,035 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-09-19 00:30:43,196 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.4465, l2 distance: 17.2654, acc: 0.79.
2024-09-19 00:30:43,196 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-19 00:30:43,197 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [7.73322927 5.13439292 8.93418526 3.72803641]
2024-09-19 00:30:43,403 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.5959, 3.8329, 3.2039
2024-09-19 00:30:43,665 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-19 00:30:44,995 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  16.0317, val_loss:  13.7626, grad_norm: 0.2638, live_grad: 0.0000, reward_err: 0.0731, 0.0034, 0.0380, KL_dist: 1.4795, 0.8301, 1.2026, param: [10.16716003  5.32766621 10.75259767  4.00819465], weights: [0.33304936 0.33290506 0.33404558], train_wt_loss:  48.0950, val_wt_loss: 41.2879, train_grp_loss: [21.69088704  9.55509805 18.87710743], val_grp_loss: [18.9625201   6.13079778 17.12001778], train_hist_grp_loss: [0.18557105 0.14223385 0.48424335], cur_train_grp_loss: [0.18557105 0.14223385 0.48424335], max_reward_err:  0.0731, max_reward_err_index: 0, max_kl_dist:  1.4795, max_kl_dist_index: 0, max_train_grp_loss:  21.6909, max_train_grp_loss_index: 0, max_val_grp_loss:  18.9625, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4842, max_cur_train_grp_loss_index: 2, 
2024-09-19 00:30:49,496 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  100, train_loss:  16.0404, val_loss:  13.7418, grad_norm: 0.0176, live_grad: 0.0000, reward_err: 0.0708, 0.0042, 0.0360, KL_dist: 1.4870, 0.8576, 1.2144, param: [10.29854793  5.59193582 10.71456889  4.27410944], weights: [0.31624757 0.28623098 0.39752144], train_wt_loss:  48.1211, val_wt_loss: 41.2254, train_grp_loss: [21.51771287  9.80077609 18.71524029], val_grp_loss: [18.77626001  6.38813429 16.95289668], train_hist_grp_loss: [17.61093569  7.63831113 40.48328641], cur_train_grp_loss: [0.17354503 0.07595266 0.39823438], max_reward_err:  0.0708, max_reward_err_index: 0, max_kl_dist:  1.4870, max_kl_dist_index: 0, max_train_grp_loss:  21.5177, max_train_grp_loss_index: 0, max_val_grp_loss:  18.7763, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.3982, max_cur_train_grp_loss_index: 2, 
2024-09-19 00:30:53,877 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  199, train_loss:  16.0731, val_loss:  13.7295, grad_norm: 0.0449,  live_grad: 0.0000, reward_err: 0.0702, 0.0049, 0.0356, KL_dist: 1.5022, 0.8951, 1.2340, param: [10.46642725  5.90329564 10.69643673  4.59151307], weights: [0.29484156 0.24277162 0.46238682], train_wt_loss:  48.2194, val_wt_loss: 41.1886, train_grp_loss: [21.31709966 10.14013626 18.52208863], val_grp_loss: [18.55657312  6.73017652 16.75113479], train_hist_grp_loss: [34.7131972  15.28150211 79.7095675 ], cur_train_grp_loss: [0.17192972 0.07857449 0.39413234], max_reward_err:  0.0702, max_reward_err_index: 0, max_kl_dist:  1.5022, max_kl_dist_index: 0, max_train_grp_loss:  21.3171, max_train_grp_loss_index: 0, max_val_grp_loss:  18.5566, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.3941, max_cur_train_grp_loss_index: 2, 
2024-09-19 00:30:54,095 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:387] - INFO: Policy parameter learned solely on the preference data rdpo: [10.46642725  5.90329564 10.69643673  4.59151307].
2024-09-19 00:30:54,419 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Uniform reward: 3.8267, 3.8267, 3.1836
2024-09-19 00:30:54,420 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Optimal reward: 3.8586, 3.8586, 3.3169
2024-09-19 00:30:54,420 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Policy reward: 3.5877, 3.8398, 3.1989
2024-09-19 00:30:54,420 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Reward Error: 0.0702, 0.0049, 0.0356
2024-09-19 00:30:55,102 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:416] - INFO: Optimal reward: 3.8586, 3.8586, 3.3169
Known param reward: [[3.8586065769195557, 3.531782627105713, 3.266848564147949], [3.531782627105713, 3.8586065769195557, 3.1579184532165527], [3.8154232501983643, 3.627133369445801, 3.3168587684631348]], Known param reward error: [[0.0, 0.08469999293754285, 0.015077580266813035], [0.08469999293754285, 0.0, 0.04791892761844273], [0.011191430341588746, 0.05998880758103799, 0.0]].
