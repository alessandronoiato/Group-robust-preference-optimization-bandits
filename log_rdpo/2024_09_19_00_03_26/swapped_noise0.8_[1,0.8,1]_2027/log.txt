2024-09-19 00:32:45,885 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log_rdpo/2024_09_19_00_03_26/swapped_noise0.8_[1,0.8,1]_2027
2024-09-19 00:32:45,887 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2027
2024-09-19 00:32:45,887 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-09-19 00:32:46,054 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.3814, l2 distance: 23.7630, acc: 0.85.
2024-09-19 00:32:46,055 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-19 00:32:46,056 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [ 8.88080729  4.95567706 12.33493647  6.36297512]
2024-09-19 00:32:46,264 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.5399, 3.8381, 3.2082
2024-09-19 00:32:46,520 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-19 00:32:47,929 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  14.2959, val_loss:  14.4690, grad_norm: 0.3519, live_grad: 0.0000, reward_err: 0.1133, 0.0053, 0.0759, KL_dist: 2.2517, 0.9477, 1.9179, param: [ 6.41051157  3.86455596 16.08026732  5.2499128 ], weights: [0.33317625 0.33307607 0.33374768], train_wt_loss:  42.8877, val_wt_loss: 43.4071, train_grp_loss: [18.72188084  9.84527037 13.34097275], val_grp_loss: [19.34630748  6.75475775 17.29058582], train_hist_grp_loss: [0.18689847 0.15682636 0.35826263], cur_train_grp_loss: [0.18689847 0.15682636 0.35826263], max_reward_err:  0.1133, max_reward_err_index: 0, max_kl_dist:  2.2517, max_kl_dist_index: 0, max_train_grp_loss:  18.7219, max_train_grp_loss_index: 0, max_val_grp_loss:  19.3463, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.3583, max_cur_train_grp_loss_index: 2, 
2024-09-19 00:32:52,470 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  100, train_loss:  14.2989, val_loss:  14.4598, grad_norm: 0.0087, live_grad: 0.0000, reward_err: 0.1126, 0.0054, 0.0754, KL_dist: 2.2934, 0.9721, 1.9585, param: [ 6.40261237  3.98263659 16.30401938  5.37865798], weights: [0.33202825 0.31273289 0.35523886], train_wt_loss:  42.8967, val_wt_loss: 43.3794, train_grp_loss: [18.63596482 10.02456943 13.20629398], val_grp_loss: [19.26362618  6.89692309 17.20435877], train_hist_grp_loss: [15.01195767  9.02489385 21.76899134], cur_train_grp_loss: [0.1479114  0.08948812 0.21302678], max_reward_err:  0.1126, max_reward_err_index: 0, max_kl_dist:  2.2934, max_kl_dist_index: 0, max_train_grp_loss:  18.6360, max_train_grp_loss_index: 0, max_val_grp_loss:  19.2636, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2130, max_cur_train_grp_loss_index: 2, 
2024-09-19 00:32:56,900 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  199, train_loss:  14.3082, val_loss:  14.4541, grad_norm: 0.0187,  live_grad: 0.0000, reward_err: 0.1115, 0.0054, 0.0746, KL_dist: 2.3363, 0.9977, 2.0001, param: [ 6.40019613  4.10436504 16.53204154  5.51094634], weights: [0.32999778 0.29371011 0.37629211], train_wt_loss:  42.9246, val_wt_loss: 43.3624, train_grp_loss: [18.54854819 10.22361274 13.06930996], val_grp_loss: [19.17958475  7.05369757 17.11574008], train_hist_grp_loss: [29.62064152 17.97137518 42.74862384], cur_train_grp_loss: [0.14721779 0.09126333 0.21081788], max_reward_err:  0.1115, max_reward_err_index: 0, max_kl_dist:  2.3363, max_kl_dist_index: 0, max_train_grp_loss:  18.5485, max_train_grp_loss_index: 0, max_val_grp_loss:  19.1796, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2108, max_cur_train_grp_loss_index: 2, 
2024-09-19 00:32:57,135 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:387] - INFO: Policy parameter learned solely on the preference data rdpo: [ 6.40019613  4.10436504 16.53204154  5.51094634].
2024-09-19 00:32:57,472 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Uniform reward: 3.8205, 3.8205, 3.2153
2024-09-19 00:32:57,473 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Optimal reward: 3.8664, 3.8664, 3.3644
2024-09-19 00:32:57,474 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Policy reward: 3.4352, 3.8456, 3.1135
2024-09-19 00:32:57,474 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Reward Error: 0.1115, 0.0054, 0.0746
2024-09-19 00:32:58,162 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:416] - INFO: Optimal reward: 3.8664, 3.8664, 3.3644
Known param reward: [[3.866352081298828, 3.466999053955078, 3.324810028076172], [3.466999053955078, 3.866352081298828, 3.1610913276672363], [3.8258588314056396, 3.5992729663848877, 3.364398956298828]], Known param reward error: [[0.0, 0.10328935879258955, 0.011767013584562513], [0.10328935879258955, 0.0, 0.06042910822182941], [0.010473244298947946, 0.06907780494326327, 0.0]].
