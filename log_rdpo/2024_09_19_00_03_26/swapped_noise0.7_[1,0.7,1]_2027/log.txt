2024-09-19 00:36:55,350 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log_rdpo/2024_09_19_00_03_26/swapped_noise0.7_[1,0.7,1]_2027
2024-09-19 00:36:55,352 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2027
2024-09-19 00:36:55,353 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-09-19 00:36:55,513 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.4740, l2 distance: 14.0690, acc: 0.80.
2024-09-19 00:36:55,514 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-19 00:36:55,514 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [8.04817029 4.05673083 5.77693217 4.47787971]
2024-09-19 00:36:55,718 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.5225, 3.7577, 3.1520
2024-09-19 00:36:55,969 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-19 00:36:57,287 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  16.8293, val_loss:  14.5842, grad_norm: 0.2424, live_grad: 0.0000, reward_err: 0.0793, 0.0055, 0.0438, KL_dist: 1.3408, 0.7162, 1.0838, param: [10.7459885   4.71003168  8.28364489  4.95603614], weights: [0.33319784 0.333091   0.33371115], train_wt_loss:  50.4879, val_wt_loss: 43.7526, train_grp_loss: [19.75382672 14.04526351 15.91518129], val_grp_loss: [19.50620902  7.31893787 17.11072239], train_hist_grp_loss: [0.17912995 0.14706004 0.33306683], cur_train_grp_loss: [0.17912995 0.14706004 0.33306683], max_reward_err:  0.0793, max_reward_err_index: 0, max_kl_dist:  1.3408, max_kl_dist_index: 0, max_train_grp_loss:  19.7538, max_train_grp_loss_index: 0, max_val_grp_loss:  19.5062, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.3331, max_cur_train_grp_loss_index: 2, 
2024-09-19 00:37:01,806 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  100, train_loss:  16.8324, val_loss:  14.5326, grad_norm: 0.0079, live_grad: 0.0000, reward_err: 0.0763, 0.0055, 0.0410, KL_dist: 1.3526, 0.7390, 1.0937, param: [10.63684294  4.82924761  8.62623683  5.04172977], weights: [0.32519943 0.31534314 0.35945743], train_wt_loss:  50.4971, val_wt_loss: 43.5978, train_grp_loss: [19.70507612 14.21238091 15.72712766], val_grp_loss: [19.41753927  7.36884055 16.99200778], train_hist_grp_loss: [15.83761615 12.75989379 25.85332973], cur_train_grp_loss: [0.15639336 0.12688048 0.25369411], max_reward_err:  0.0763, max_reward_err_index: 0, max_kl_dist:  1.3526, max_kl_dist_index: 0, max_train_grp_loss:  19.7051, max_train_grp_loss_index: 0, max_val_grp_loss:  19.4175, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2537, max_cur_train_grp_loss_index: 2, 
2024-09-19 00:37:06,151 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  199, train_loss:  16.8417, val_loss:  14.4841, grad_norm: 0.0171,  live_grad: 0.0000, reward_err: 0.0753, 0.0058, 0.0398, KL_dist: 1.3684, 0.7630, 1.1073, param: [10.52924082  4.95226494  8.97863931  5.12948548], weights: [0.31663655 0.29849716 0.38486629], train_wt_loss:  50.5252, val_wt_loss: 43.4524, train_grp_loss: [19.65704059 14.39722997 15.53616013], val_grp_loss: [19.32865494  7.42978413 16.87164742], train_hist_grp_loss: [31.30146747 25.40205252 50.81560902], cur_train_grp_loss: [0.15601209 0.12852915 0.25061464], max_reward_err:  0.0753, max_reward_err_index: 0, max_kl_dist:  1.3684, max_kl_dist_index: 0, max_train_grp_loss:  19.6570, max_train_grp_loss_index: 0, max_val_grp_loss:  19.3287, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2506, max_cur_train_grp_loss_index: 2, 
2024-09-19 00:37:06,373 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:387] - INFO: Policy parameter learned solely on the preference data rdpo: [10.52924082  4.95226494  8.97863931  5.12948548].
2024-09-19 00:37:06,697 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Uniform reward: 3.7599, 3.7599, 3.1348
2024-09-19 00:37:06,698 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Optimal reward: 3.8017, 3.8017, 3.2811
2024-09-19 00:37:06,698 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Policy reward: 3.5154, 3.7794, 3.1505
2024-09-19 00:37:06,699 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Reward Error: 0.0753, 0.0058, 0.0398
2024-09-19 00:37:07,377 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:416] - INFO: Optimal reward: 3.8017, 3.8017, 3.2811
Known param reward: [[3.8016552925109863, 3.4387340545654297, 3.238321304321289], [3.4387340545654297, 3.8016552925109863, 3.0975143909454346], [3.7612709999084473, 3.561779260635376, 3.281050205230713]], Known param reward error: [[0.0, 0.0954640044983794, 0.013022934193845799], [0.0954640044983794, 0.0, 0.055938130417109135], [0.010622818087187834, 0.06309778594291558, 0.0]].
