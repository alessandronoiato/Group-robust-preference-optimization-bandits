2024-09-19 00:38:33,698 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log_rdpo/2024_09_19_00_03_26/swapped_noise0.6_[1,0.6,1]_2021
2024-09-19 00:38:33,700 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2021
2024-09-19 00:38:33,700 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-09-19 00:38:33,862 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.4881, l2 distance: 12.8925, acc: 0.78.
2024-09-19 00:38:33,863 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-19 00:38:33,864 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [7.49008496 2.76987425 6.30387609 1.756958  ]
2024-09-19 00:38:34,070 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.4326, 3.8265, 3.0841
2024-09-19 00:38:34,303 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-19 00:38:35,675 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  16.7639, val_loss:  15.0545, grad_norm: 0.2916, live_grad: 0.0000, reward_err: 0.1171, 0.0015, 0.0756, KL_dist: 1.6653, 0.7999, 1.3201, param: [11.96573426  3.35066488  9.61307431  2.2347112 ], weights: [0.33301452 0.33309912 0.33388637], train_wt_loss:  50.2917, val_wt_loss: 45.1635, train_grp_loss: [20.2170814  13.24602228 16.92561263], val_grp_loss: [20.76672069  5.83887078 18.78588843], train_hist_grp_loss: [0.1707128  0.19611413 0.43217717], cur_train_grp_loss: [0.1707128  0.19611413 0.43217717], max_reward_err:  0.1171, max_reward_err_index: 0, max_kl_dist:  1.6653, max_kl_dist_index: 0, max_train_grp_loss:  20.2171, max_train_grp_loss_index: 0, max_val_grp_loss:  20.7667, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4322, max_cur_train_grp_loss_index: 2, 
2024-09-19 00:38:40,234 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  100, train_loss:  16.7691, val_loss:  14.9878, grad_norm: 0.0119, live_grad: 0.0000, reward_err: 0.1176, 0.0011, 0.0764, KL_dist: 1.7043, 0.8269, 1.3575, param: [12.33450038  3.52675781  9.54782501  2.35857207], weights: [0.31822517 0.30144582 0.38032901], train_wt_loss:  50.3073, val_wt_loss: 44.9633, train_grp_loss: [20.08239629 13.46058433 16.75722492], val_grp_loss: [20.66731495  5.84345621 18.67867626], train_hist_grp_loss: [16.29181413 10.87492189 34.1195635 ], cur_train_grp_loss: [0.16067041 0.10766568 0.33517989], max_reward_err:  0.1176, max_reward_err_index: 0, max_kl_dist:  1.7043, max_kl_dist_index: 0, max_train_grp_loss:  20.0824, max_train_grp_loss_index: 0, max_val_grp_loss:  20.6673, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.3352, max_cur_train_grp_loss_index: 2, 
2024-09-19 00:38:44,669 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  199, train_loss:  16.7869, val_loss:  14.9209, grad_norm: 0.0283,  live_grad: 0.0000, reward_err: 0.1179, 0.0008, 0.0771, KL_dist: 1.7505, 0.8585, 1.4015, param: [12.72976807  3.72316165  9.50112816  2.49446599], weights: [0.30129049 0.2712418  0.42746771], train_wt_loss:  50.3608, val_wt_loss: 44.7626, train_grp_loss: [19.93742904 13.72193233 16.57318347], val_grp_loss: [20.55911197  5.86769245 18.55950515], train_hist_grp_loss: [32.1410203  21.63460236 67.12140852], cur_train_grp_loss: [0.15951162 0.10975212 0.33150261], max_reward_err:  0.1179, max_reward_err_index: 0, max_kl_dist:  1.7505, max_kl_dist_index: 0, max_train_grp_loss:  19.9374, max_train_grp_loss_index: 0, max_val_grp_loss:  20.5591, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.3315, max_cur_train_grp_loss_index: 2, 
2024-09-19 00:38:44,890 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:387] - INFO: Policy parameter learned solely on the preference data rdpo: [12.72976807  3.72316165  9.50112816  2.49446599].
2024-09-19 00:38:45,214 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Uniform reward: 3.7957, 3.7957, 3.1631
2024-09-19 00:38:45,215 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Optimal reward: 3.8296, 3.8296, 3.2923
2024-09-19 00:38:45,215 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Policy reward: 3.3780, 3.8267, 3.0386
2024-09-19 00:38:45,216 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Reward Error: 0.1179, 0.0008, 0.0771
2024-09-19 00:38:45,893 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:416] - INFO: Optimal reward: 3.8296, 3.8296, 3.2923
Known param reward: [[3.8295645713806152, 3.440261125564575, 3.2583417892456055], [3.440261125564575, 3.8295645713806152, 3.092778205871582], [3.7937707901000977, 3.5698022842407227, 3.2923295497894287]], Known param reward error: [[0.0, 0.10165736562464864, 0.010323316675876822], [0.10165736562464864, 0.0, 0.0606109871141574], [0.009346697415161585, 0.06783076307974209, 0.0]].
