2024-09-19 00:23:12,816 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log_rdpo/2024_09_19_00_03_26/swapped_noise1.0_[1,1.0,1]_2024
2024-09-19 00:23:12,818 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2024
2024-09-19 00:23:12,818 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-09-19 00:23:12,981 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.3279, l2 distance: 34.1898, acc: 0.82.
2024-09-19 00:23:12,982 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-19 00:23:12,983 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [13.14701482  8.44873766 15.31760858  8.28786146]
2024-09-19 00:23:13,192 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.6625, 3.9176, 3.3293
2024-09-19 00:23:13,448 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-19 00:23:14,771 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  13.3407, val_loss:  14.1468, grad_norm: 0.2555, live_grad: 0.0000, reward_err: 0.0959, 0.0009, 0.0541, KL_dist: 2.0544, 1.1165, 1.6867, param: [10.88462629  4.83892943 14.16298328  4.9649163 ], weights: [0.33303926 0.3328212  0.33413954], train_wt_loss:  40.0221, val_wt_loss: 42.4404, train_grp_loss: [20.79863114  5.39401025 17.70235657], val_grp_loss: [19.76389286  5.76582879 16.97765976], train_hist_grp_loss: [0.17711935 0.1116226  0.50695119], cur_train_grp_loss: [0.17711935 0.1116226  0.50695119], max_reward_err:  0.0959, max_reward_err_index: 0, max_kl_dist:  2.0544, max_kl_dist_index: 0, max_train_grp_loss:  20.7986, max_train_grp_loss_index: 0, max_val_grp_loss:  19.7639, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.5070, max_cur_train_grp_loss_index: 2, 
2024-09-19 00:23:19,284 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  100, train_loss:  13.3576, val_loss:  14.1392, grad_norm: 0.0258, live_grad: 0.0000, reward_err: 0.0929, 0.0018, 0.0517, KL_dist: 2.0403, 1.1326, 1.6828, param: [10.81089877  5.20661648 14.18967384  5.34060166], weights: [0.31457988 0.27639969 0.40902043], train_wt_loss:  40.0729, val_wt_loss: 42.4176, train_grp_loss: [20.51414768  5.76594382 17.42997554], val_grp_loss: [19.51858745  6.19918844 16.76502923], train_hist_grp_loss: [17.1134015   4.17439632 43.3661077 ], cur_train_grp_loss: [0.1681743  0.04205442 0.42519483], max_reward_err:  0.0929, max_reward_err_index: 0, max_kl_dist:  2.0403, max_kl_dist_index: 0, max_train_grp_loss:  20.5141, max_train_grp_loss_index: 0, max_val_grp_loss:  19.5186, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4252, max_cur_train_grp_loss_index: 2, 
2024-09-19 00:23:23,669 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  199, train_loss:  13.4234, val_loss:  14.1597, grad_norm: 0.0680,  live_grad: 0.0000, reward_err: 0.0904, 0.0022, 0.0496, KL_dist: 2.0294, 1.1611, 1.6834, param: [10.77390558  5.6571331  14.2141443   5.79644009], weights: [0.2897989  0.22545791 0.48474318], train_wt_loss:  40.2701, val_wt_loss: 42.4792, train_grp_loss: [20.17583003  6.30995979 17.09979945], val_grp_loss: [19.22325319  6.81780211 16.50111176], train_hist_grp_loss: [33.6283136   8.52293892 85.07151168], cur_train_grp_loss: [0.16540617 0.04600984 0.41715764], max_reward_err:  0.0904, max_reward_err_index: 0, max_kl_dist:  2.0294, max_kl_dist_index: 0, max_train_grp_loss:  20.1758, max_train_grp_loss_index: 0, max_val_grp_loss:  19.2233, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4172, max_cur_train_grp_loss_index: 2, 
2024-09-19 00:23:23,893 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:387] - INFO: Policy parameter learned solely on the preference data rdpo: [10.77390558  5.6571331  14.2141443   5.79644009].
2024-09-19 00:23:24,228 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Uniform reward: 3.9164, 3.9164, 3.3093
2024-09-19 00:23:24,229 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Optimal reward: 3.9575, 3.9575, 3.4535
2024-09-19 00:23:24,229 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Policy reward: 3.6000, 3.9486, 3.2822
2024-09-19 00:23:24,230 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Reward Error: 0.0904, 0.0022, 0.0496
2024-09-19 00:23:24,926 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:416] - INFO: Optimal reward: 3.9575, 3.9575, 3.4535
Known param reward: [[3.9575352668762207, 3.5510668754577637, 3.4159226417541504], [3.5510668754577637, 3.9575352668762207, 3.2513158321380615], [3.9158573150634766, 3.681488275527954, 3.453465223312378]], Known param reward error: [[0.0, 0.10270745906436166, 0.010870988740468253], [0.10270745906436166, 0.0, 0.058535232904539165], [0.010531290058633277, 0.06975225051276858, 0.0]].
