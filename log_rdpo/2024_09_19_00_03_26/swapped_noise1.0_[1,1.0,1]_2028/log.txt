2024-09-19 00:24:52,820 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log_rdpo/2024_09_19_00_03_26/swapped_noise1.0_[1,1.0,1]_2028
2024-09-19 00:24:52,822 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2028
2024-09-19 00:24:52,822 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-09-19 00:24:52,983 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.3651, l2 distance: 26.9971, acc: 0.81.
2024-09-19 00:24:52,984 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-19 00:24:52,984 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [12.46026982  6.25374019 11.11274631  7.09775389]
2024-09-19 00:24:53,192 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.5669, 3.8411, 3.2101
2024-09-19 00:24:53,441 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-19 00:24:54,785 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  14.1809, val_loss:  14.6444, grad_norm: 0.2665, live_grad: 0.0000, reward_err: 0.0910, 0.0018, 0.0511, KL_dist: 1.8079, 1.0315, 1.4748, param: [11.27687639  5.05771448 12.29562599  5.21112383], weights: [0.33317559 0.33298101 0.3338434 ], train_wt_loss:  42.5426, val_wt_loss: 43.9333, train_grp_loss: [20.20595267  6.1447392  16.37069717], val_grp_loss: [19.00998424  7.32656813 16.95432391], train_hist_grp_loss: [0.17534179 0.1169234  0.37557778], cur_train_grp_loss: [0.17534179 0.1169234  0.37557778], max_reward_err:  0.0910, max_reward_err_index: 0, max_kl_dist:  1.8079, max_kl_dist_index: 0, max_train_grp_loss:  20.2060, max_train_grp_loss_index: 0, max_val_grp_loss:  19.0100, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.3756, max_cur_train_grp_loss_index: 2, 
2024-09-19 00:24:59,322 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  100, train_loss:  14.1914, val_loss:  14.6584, grad_norm: 0.0157, live_grad: 0.0000, reward_err: 0.0888, 0.0024, 0.0492, KL_dist: 1.8104, 1.0640, 1.4824, param: [11.56504502  5.36170398 12.13227981  5.55376321], weights: [0.3280832  0.29717297 0.37474383], train_wt_loss:  42.5743, val_wt_loss: 43.9751, train_grp_loss: [19.95903702  6.55886177 16.1685317 ], val_grp_loss: [18.78064446  7.79939071 16.78932811], train_hist_grp_loss: [15.62532502  5.7300367  28.92286666], cur_train_grp_loss: [0.15355061 0.05800266 0.28369529], max_reward_err:  0.0888, max_reward_err_index: 0, max_kl_dist:  1.8104, max_kl_dist_index: 0, max_train_grp_loss:  19.9590, max_train_grp_loss_index: 0, max_val_grp_loss:  18.7806, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2837, max_cur_train_grp_loss_index: 2, 
2024-09-19 00:25:03,703 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  199, train_loss:  14.2259, val_loss:  14.6957, grad_norm: 0.0362,  live_grad: 0.0000, reward_err: 0.0839, 0.0030, 0.0451, KL_dist: 1.8197, 1.1032, 1.4970, param: [11.84862099  5.68974584 12.00246939  5.92417137], weights: [0.32002583 0.26453415 0.41544002], train_wt_loss:  42.6778, val_wt_loss: 44.0872, train_grp_loss: [19.70075013  7.05619041 15.95314421], val_grp_loss: [18.53867425  8.37665895 16.60826937], train_hist_grp_loss: [30.72835117 11.68521312 56.82200328], cur_train_grp_loss: [0.15156477 0.06239555 0.27991915], max_reward_err:  0.0839, max_reward_err_index: 0, max_kl_dist:  1.8197, max_kl_dist_index: 0, max_train_grp_loss:  19.7008, max_train_grp_loss_index: 0, max_val_grp_loss:  18.5387, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2799, max_cur_train_grp_loss_index: 2, 
2024-09-19 00:25:03,925 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:387] - INFO: Policy parameter learned solely on the preference data rdpo: [11.84862099  5.68974584 12.00246939  5.92417137].
2024-09-19 00:25:04,258 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Uniform reward: 3.8344, 3.8344, 3.2119
2024-09-19 00:25:04,259 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Optimal reward: 3.8714, 3.8714, 3.3478
2024-09-19 00:25:04,260 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Policy reward: 3.5464, 3.8598, 3.1969
2024-09-19 00:25:04,260 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Reward Error: 0.0839, 0.0030, 0.0451
2024-09-19 00:25:04,931 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:416] - INFO: Optimal reward: 3.8714, 3.8714, 3.3478
Known param reward: [[3.8714330196380615, 3.4622552394866943, 3.31345272064209], [3.4622552394866943, 3.8714330196380615, 3.1356377601623535], [3.8367903232574463, 3.6059677600860596, 3.34783935546875]], Known param reward error: [[0.0, 0.10569155609196644, 0.010271291772255747], [0.10569155609196644, 0.0, 0.06338464089077683], [0.008948287676653118, 0.06857028345974592, 0.0]].
