2024-09-19 00:23:38,102 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log_rdpo/2024_09_19_00_03_26/swapped_noise1.0_[1,1.0,1]_2025
2024-09-19 00:23:38,104 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2025
2024-09-19 00:23:38,105 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-09-19 00:23:38,268 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.2984, l2 distance: 38.1703, acc: 0.86.
2024-09-19 00:23:38,269 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-19 00:23:38,270 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [15.30897596  7.8882492  17.26025981  7.68476984]
2024-09-19 00:23:38,474 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.5736, 3.8739, 3.1818
2024-09-19 00:23:38,727 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-19 00:23:40,077 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  12.9688, val_loss:  14.3058, grad_norm: 0.3360, live_grad: 0.0000, reward_err: 0.1068, 0.0003, 0.0675, KL_dist: 2.0539, 1.1076, 1.6863, param: [10.49829693  3.99675156 14.10636186  4.67215544], weights: [0.33305473 0.3329222  0.33402307], train_wt_loss:  38.9063, val_wt_loss: 42.9175, train_grp_loss: [18.30920877  6.36332821 17.03593176], val_grp_loss: [20.12245887  5.52467893 17.06731486], train_hist_grp_loss: [0.18000837 0.14020842 0.47032971], cur_train_grp_loss: [0.18000837 0.14020842 0.47032971], max_reward_err:  0.1068, max_reward_err_index: 0, max_kl_dist:  2.0539, max_kl_dist_index: 0, max_train_grp_loss:  18.3092, max_train_grp_loss_index: 0, max_val_grp_loss:  20.1225, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4703, max_cur_train_grp_loss_index: 2, 
2024-09-19 00:23:44,591 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  100, train_loss:  12.9771, val_loss:  14.2537, grad_norm: 0.0165, live_grad: 0.0000, reward_err: 0.1056, 0.0005, 0.0664, KL_dist: 2.0738, 1.1387, 1.7078, param: [10.62889554  4.26325479 14.21278525  4.90939058], weights: [0.31870852 0.28886565 0.39242583], train_wt_loss:  38.9314, val_wt_loss: 42.7610, train_grp_loss: [18.13029044  6.61261551 16.87677737], val_grp_loss: [19.95242327  5.73025145 16.88530946], train_hist_grp_loss: [14.99528675  5.16376271 35.80234772], cur_train_grp_loss: [0.14741634 0.05123819 0.35163549], max_reward_err:  0.1056, max_reward_err_index: 0, max_kl_dist:  2.0738, max_kl_dist_index: 0, max_train_grp_loss:  18.1303, max_train_grp_loss_index: 0, max_val_grp_loss:  19.9524, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.3516, max_cur_train_grp_loss_index: 2, 
2024-09-19 00:23:48,943 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  199, train_loss:  13.0078, val_loss:  14.2059, grad_norm: 0.0413,  live_grad: 0.0000, reward_err: 0.1012, 0.0007, 0.0624, KL_dist: 2.0979, 1.1772, 1.7335, param: [10.80621333  4.57513213 14.32226005  5.18149693], weights: [0.30018255 0.24786838 0.45194907], train_wt_loss:  39.0233, val_wt_loss: 42.6178, train_grp_loss: [17.92617075  6.94748047 16.69130804], val_grp_loss: [19.75750592  6.00575784 16.67414593], train_hist_grp_loss: [29.50854694 10.35925577 70.4264156 ], cur_train_grp_loss: [0.14575916 0.05382608 0.34777772], max_reward_err:  0.1012, max_reward_err_index: 0, max_kl_dist:  2.0979, max_kl_dist_index: 0, max_train_grp_loss:  17.9262, max_train_grp_loss_index: 0, max_val_grp_loss:  19.7575, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.3478, max_cur_train_grp_loss_index: 2, 
2024-09-19 00:23:49,166 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:387] - INFO: Policy parameter learned solely on the preference data rdpo: [10.80621333  4.57513213 14.32226005  5.18149693].
2024-09-19 00:23:49,494 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Uniform reward: 3.8481, 3.8481, 3.1906
2024-09-19 00:23:49,495 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Optimal reward: 3.8879, 3.8879, 3.3280
2024-09-19 00:23:49,495 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Policy reward: 3.4945, 3.8850, 3.1203
2024-09-19 00:23:49,496 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Reward Error: 0.1012, 0.0007, 0.0624
2024-09-19 00:23:50,182 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:416] - INFO: Optimal reward: 3.8879, 3.8879, 3.3280
Known param reward: [[3.8879001140594482, 3.5038833618164062, 3.288445234298706], [3.5038833618164062, 3.8879001140594482, 3.1316840648651123], [3.8516592979431152, 3.6378118991851807, 3.328000545501709]], Known param reward error: [[0.0, 0.09877227834489838, 0.011885608389237752], [0.09877227834489838, 0.0, 0.05898931744525938], [0.009321437036223937, 0.06432475308969411, 0.0]].
