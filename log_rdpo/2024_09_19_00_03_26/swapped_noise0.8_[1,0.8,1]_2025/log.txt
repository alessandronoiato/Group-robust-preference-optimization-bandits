2024-09-19 00:31:57,687 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log_rdpo/2024_09_19_00_03_26/swapped_noise0.8_[1,0.8,1]_2025
2024-09-19 00:31:57,689 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2025
2024-09-19 00:31:57,690 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-09-19 00:31:57,859 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.3974, l2 distance: 22.4422, acc: 0.82.
2024-09-19 00:31:57,860 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-19 00:31:57,861 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [10.23808935  5.11249781 10.66500278  4.93769836]
2024-09-19 00:31:58,072 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.5516, 3.8284, 3.1261
2024-09-19 00:31:58,362 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-19 00:31:59,772 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  14.7020, val_loss:  14.3330, grad_norm: 0.3109, live_grad: 0.0000, reward_err: 0.0956, 0.0000, 0.0563, KL_dist: 1.6736, 0.9575, 1.3597, param: [11.24873704  4.27015754 11.6514256   3.74826123], weights: [0.33308207 0.33293532 0.3339826 ], train_wt_loss:  44.1059, val_wt_loss: 42.9990, train_grp_loss: [20.36790284  7.98937507 18.22314819], val_grp_loss: [19.69833255  5.48480445 17.53616517], train_hist_grp_loss: [0.1864826  0.14241431 0.45648088], cur_train_grp_loss: [0.1864826  0.14241431 0.45648088], max_reward_err:  0.0956, max_reward_err_index: 0, max_kl_dist:  1.6736, max_kl_dist_index: 0, max_train_grp_loss:  20.3679, max_train_grp_loss_index: 0, max_val_grp_loss:  19.6983, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4565, max_cur_train_grp_loss_index: 2, 
2024-09-19 00:32:04,401 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  100, train_loss:  14.7165, val_loss:  14.2749, grad_norm: 0.0183, live_grad: 0.0000, reward_err: 0.0958, 0.0002, 0.0569, KL_dist: 1.7076, 0.9891, 1.3960, param: [10.80163833  4.56576341 12.33864347  4.02563419], weights: [0.31842282 0.28743475 0.39414243], train_wt_loss:  44.1495, val_wt_loss: 42.8246, train_grp_loss: [20.22529255  8.30500308 17.83114901], val_grp_loss: [19.45969161  5.76758789 17.32954417], train_hist_grp_loss: [16.68919507  6.45077061 38.0224172 ], cur_train_grp_loss: [0.16444537 0.06435164 0.37156695], max_reward_err:  0.0958, max_reward_err_index: 0, max_kl_dist:  1.7076, max_kl_dist_index: 0, max_train_grp_loss:  20.2253, max_train_grp_loss_index: 0, max_val_grp_loss:  19.4597, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.3716, max_cur_train_grp_loss_index: 2, 
2024-09-19 00:32:08,915 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  199, train_loss:  14.7667, val_loss:  14.2386, grad_norm: 0.0452,  live_grad: 0.0000, reward_err: 0.0969, 0.0006, 0.0585, KL_dist: 1.7650, 1.0295, 1.4557, param: [10.34932401  4.90196131 13.08568761  4.34362506], weights: [0.30000845 0.24579276 0.45419879], train_wt_loss:  44.3002, val_wt_loss: 42.7159, train_grp_loss: [20.07143821  8.72263649 17.41696226], val_grp_loss: [19.20241524  6.15563719 17.10512013], train_hist_grp_loss: [32.90768322 12.97549109 74.38011372], cur_train_grp_loss: [0.1631956  0.0675799  0.36294268], max_reward_err:  0.0969, max_reward_err_index: 0, max_kl_dist:  1.7650, max_kl_dist_index: 0, max_train_grp_loss:  20.0714, max_train_grp_loss_index: 0, max_val_grp_loss:  19.2024, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.3629, max_cur_train_grp_loss_index: 2, 
2024-09-19 00:32:09,142 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:387] - INFO: Policy parameter learned solely on the preference data rdpo: [10.34932401  4.90196131 13.08568761  4.34362506].
2024-09-19 00:32:09,469 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Uniform reward: 3.8095, 3.8095, 3.1414
2024-09-19 00:32:09,469 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Optimal reward: 3.8433, 3.8433, 3.2542
2024-09-19 00:32:09,470 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Policy reward: 3.4710, 3.8410, 3.0637
2024-09-19 00:32:09,470 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Reward Error: 0.0969, 0.0006, 0.0585
2024-09-19 00:32:10,158 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:416] - INFO: Optimal reward: 3.8433, 3.8433, 3.2542
Known param reward: [[3.8433432579040527, 3.466123342514038, 3.218020439147949], [3.466123342514038, 3.8433432579040527, 3.063755989074707], [3.803264617919922, 3.5905978679656982, 3.2542388439178467]], Known param reward error: [[0.0, 0.09814890059956018, 0.01112960864491844], [0.09814890059956018, 0.0, 0.058533765952413414], [0.010428066736351708, 0.06576185705468002, 0.0]].
