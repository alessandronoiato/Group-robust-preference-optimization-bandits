2024-09-19 00:22:47,034 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log_rdpo/2024_09_19_00_03_26/swapped_noise1.0_[1,1.0,1]_2023
2024-09-19 00:22:47,036 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2023
2024-09-19 00:22:47,036 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-09-19 00:22:47,200 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.3431, l2 distance: 35.5343, acc: 0.83.
2024-09-19 00:22:47,200 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-19 00:22:47,201 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [15.61298457  7.73326877 14.20212669  8.81141422]
2024-09-19 00:22:47,412 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.5015, 3.7537, 3.0878
2024-09-19 00:22:47,661 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-19 00:22:48,962 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  14.2698, val_loss:  14.3725, grad_norm: 0.3029, live_grad: 0.0000, reward_err: 0.0917, 0.0007, 0.0517, KL_dist: 1.9011, 1.0730, 1.5613, param: [11.5360603   4.3099699  12.66615237  5.08525962], weights: [0.33305692 0.33303463 0.33390845], train_wt_loss:  42.8094, val_wt_loss: 43.1174, train_grp_loss: [19.86280372  6.51137077 18.11606972], val_grp_loss: [18.98874295  7.00774834 17.10653311], train_hist_grp_loss: [0.16734455 0.16065065 0.42268975], cur_train_grp_loss: [0.16734455 0.16065065 0.42268975], max_reward_err:  0.0917, max_reward_err_index: 0, max_kl_dist:  1.9011, max_kl_dist_index: 0, max_train_grp_loss:  19.8628, max_train_grp_loss_index: 0, max_val_grp_loss:  18.9887, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4227, max_cur_train_grp_loss_index: 2, 
2024-09-19 00:22:53,540 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  100, train_loss:  14.2822, val_loss:  14.4128, grad_norm: 0.0194, live_grad: 0.0000, reward_err: 0.0900, 0.0012, 0.0505, KL_dist: 1.9149, 1.0996, 1.5807, param: [11.27259758  4.6545154  13.01489939  5.38100584], weights: [0.31907111 0.28991769 0.3910112 ], train_wt_loss:  42.8465, val_wt_loss: 43.2383, train_grp_loss: [19.6445407   6.89218561 17.85659855], val_grp_loss: [18.81747368  7.47510332 16.93760454], train_hist_grp_loss: [15.36500389  5.78330759 35.69722402], cur_train_grp_loss: [0.15112965 0.05788089 0.35018303], max_reward_err:  0.0900, max_reward_err_index: 0, max_kl_dist:  1.9149, max_kl_dist_index: 0, max_train_grp_loss:  19.6445, max_train_grp_loss_index: 0, max_val_grp_loss:  18.8175, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.3502, max_cur_train_grp_loss_index: 2, 
2024-09-19 00:22:58,003 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  199, train_loss:  14.3255, val_loss:  14.4804, grad_norm: 0.0476,  live_grad: 0.0000, reward_err: 0.0885, 0.0023, 0.0494, KL_dist: 1.9373, 1.1338, 1.6091, param: [11.00031589  5.04414203 13.39535501  5.7169483 ], weights: [0.3011518  0.25023082 0.44861738], train_wt_loss:  42.9766, val_wt_loss: 43.4412, train_grp_loss: [19.40200554  7.38851285 17.57198441], val_grp_loss: [18.62573869  8.06616297 16.74885697], train_hist_grp_loss: [30.23535376 11.71228685 70.09094389], cur_train_grp_loss: [0.14926607 0.06204042 0.3446077 ], max_reward_err:  0.0885, max_reward_err_index: 0, max_kl_dist:  1.9373, max_kl_dist_index: 0, max_train_grp_loss:  19.4020, max_train_grp_loss_index: 0, max_val_grp_loss:  18.6257, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.3446, max_cur_train_grp_loss_index: 2, 
2024-09-19 00:22:58,241 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:387] - INFO: Policy parameter learned solely on the preference data rdpo: [11.00031589  5.04414203 13.39535501  5.7169483 ].
2024-09-19 00:22:58,578 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Uniform reward: 3.7505, 3.7505, 3.0898
2024-09-19 00:22:58,579 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Optimal reward: 3.7806, 3.7806, 3.2051
2024-09-19 00:22:58,579 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Policy reward: 3.4462, 3.7720, 3.0468
2024-09-19 00:22:58,580 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Reward Error: 0.0885, 0.0023, 0.0494
2024-09-19 00:22:59,267 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:416] - INFO: Optimal reward: 3.7806, 3.7806, 3.2051
Known param reward: [[3.7806432247161865, 3.4037325382232666, 3.1705894470214844], [3.4037325382232666, 3.7806432247161865, 3.017861843109131], [3.7406539916992188, 3.5228474140167236, 3.2050557136535645]], Known param reward error: [[0.0, 0.09969485722134351, 0.010753718409715467], [0.09969485722134351, 0.0, 0.05840580859389936], [0.010577362274106087, 0.06818834663215693, 0.0]].
