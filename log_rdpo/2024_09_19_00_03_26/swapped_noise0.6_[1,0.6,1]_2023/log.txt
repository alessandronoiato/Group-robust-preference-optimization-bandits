2024-09-19 00:39:21,606 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log_rdpo/2024_09_19_00_03_26/swapped_noise0.6_[1,0.6,1]_2023
2024-09-19 00:39:21,608 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2023
2024-09-19 00:39:21,609 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-09-19 00:39:21,772 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.4901, l2 distance: 13.7110, acc: 0.77.
2024-09-19 00:39:21,772 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-19 00:39:21,773 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [8.67865662 2.73331006 5.03288862 3.70226044]
2024-09-19 00:39:21,984 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.4786, 3.8485, 3.0931
2024-09-19 00:39:22,240 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-19 00:39:23,547 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  17.1330, val_loss:  15.4328, grad_norm: 0.1997, live_grad: 0.0000, reward_err: 0.1066, 0.0015, 0.0705, KL_dist: 1.6893, 0.7319, 1.4125, param: [13.60835552  3.63087451  6.31533188  4.24782206], weights: [0.33308658 0.33301085 0.33390256], train_wt_loss:  51.3989, val_wt_loss: 46.2983, train_grp_loss: [20.01242431 13.70678801 17.78760314], val_grp_loss: [21.01366548  6.26376239 19.21790817], train_hist_grp_loss: [0.16837282 0.14563467 0.41304791], cur_train_grp_loss: [0.16837282 0.14563467 0.41304791], max_reward_err:  0.1066, max_reward_err_index: 0, max_kl_dist:  1.6893, max_kl_dist_index: 0, max_train_grp_loss:  20.0124, max_train_grp_loss_index: 0, max_val_grp_loss:  21.0137, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4130, max_cur_train_grp_loss_index: 2, 
2024-09-19 00:39:28,000 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  100, train_loss:  17.1398, val_loss:  15.3296, grad_norm: 0.0123, live_grad: 0.0000, reward_err: 0.1037, 0.0016, 0.0672, KL_dist: 1.6603, 0.7599, 1.3832, param: [13.39955919  3.80306615  6.80918314  4.44141189], weights: [0.31460712 0.30300438 0.3823885 ], train_wt_loss:  51.4195, val_wt_loss: 45.9887, train_grp_loss: [19.90465219 13.9573708  17.51808026], val_grp_loss: [20.87775249  6.26573139 19.04281687], train_hist_grp_loss: [15.5220202  11.76428242 35.03326836], cur_train_grp_loss: [0.1531213  0.11726538 0.34354706], max_reward_err:  0.1037, max_reward_err_index: 0, max_kl_dist:  1.6603, max_kl_dist_index: 0, max_train_grp_loss:  19.9047, max_train_grp_loss_index: 0, max_val_grp_loss:  20.8778, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.3435, max_cur_train_grp_loss_index: 2, 
2024-09-19 00:39:32,331 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  199, train_loss:  17.1631, val_loss:  15.2273, grad_norm: 0.0292,  live_grad: 0.0000, reward_err: 0.1017, 0.0016, 0.0650, KL_dist: 1.6374, 0.7930, 1.3596, param: [13.18744975  3.99193466  7.35111835  4.65680036], weights: [0.29453175 0.27423753 0.43123072], train_wt_loss:  51.4894, val_wt_loss: 45.6818, train_grp_loss: [19.79024261 14.26573994 17.22723594], val_grp_loss: [20.73336551  6.2923092  18.85429475], train_hist_grp_loss: [30.63753032 23.49831095 68.76317671], cur_train_grp_loss: [0.15224181 0.11985116 0.33784871], max_reward_err:  0.1017, max_reward_err_index: 0, max_kl_dist:  1.6374, max_kl_dist_index: 0, max_train_grp_loss:  19.7902, max_train_grp_loss_index: 0, max_val_grp_loss:  20.7334, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.3378, max_cur_train_grp_loss_index: 2, 
2024-09-19 00:39:32,550 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:387] - INFO: Policy parameter learned solely on the preference data rdpo: [13.18744975  3.99193466  7.35111835  4.65680036].
2024-09-19 00:39:32,881 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Uniform reward: 3.8219, 3.8219, 3.1727
2024-09-19 00:39:32,882 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Optimal reward: 3.8605, 3.8605, 3.2988
2024-09-19 00:39:32,882 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Policy reward: 3.4680, 3.8544, 3.0844
2024-09-19 00:39:32,882 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Reward Error: 0.1017, 0.0016, 0.0650
2024-09-19 00:39:33,567 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:416] - INFO: Optimal reward: 3.8605, 3.8605, 3.2988
Known param reward: [[3.8605411052703857, 3.4837193489074707, 3.270322322845459], [3.4837193489074707, 3.8605411052703857, 3.110097646713257], [3.825101613998413, 3.5993566513061523, 3.298776388168335]], Known param reward error: [[0.0, 0.09760853364531734, 0.008625642351791921], [0.09760853364531734, 0.0, 0.05719658420370927], [0.009179928488156982, 0.06765488226706512, 0.0]].
