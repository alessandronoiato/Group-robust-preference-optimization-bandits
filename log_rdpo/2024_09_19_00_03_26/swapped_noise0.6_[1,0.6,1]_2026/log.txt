2024-09-19 00:40:38,011 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log_rdpo/2024_09_19_00_03_26/swapped_noise0.6_[1,0.6,1]_2026
2024-09-19 00:40:38,013 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2026
2024-09-19 00:40:38,014 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-09-19 00:40:38,171 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.4897, l2 distance: 13.8904, acc: 0.75.
2024-09-19 00:40:38,172 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-19 00:40:38,173 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [7.98825619 2.69900213 6.4400013  3.59401665]
2024-09-19 00:40:38,381 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.4928, 3.8618, 3.1795
2024-09-19 00:40:38,632 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-19 00:40:39,952 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  17.0466, val_loss:  15.0650, grad_norm: 0.2213, live_grad: 0.0000, reward_err: 0.1018, 0.0004, 0.0616, KL_dist: 1.6755, 0.8264, 1.3388, param: [12.02466149  3.46270334  9.78929666  4.5263621 ], weights: [0.33297686 0.33300255 0.3340206 ], train_wt_loss:  51.1398, val_wt_loss: 45.1949, train_grp_loss: [20.61562312 12.23435932 18.34206054], val_grp_loss: [20.22888987  6.04892171 17.78273188], train_hist_grp_loss: [0.16019724 0.1679114  0.4731636 ], cur_train_grp_loss: [0.16019724 0.1679114  0.4731636 ], max_reward_err:  0.1018, max_reward_err_index: 0, max_kl_dist:  1.6755, max_kl_dist_index: 0, max_train_grp_loss:  20.6156, max_train_grp_loss_index: 0, max_val_grp_loss:  20.2289, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4732, max_cur_train_grp_loss_index: 2, 
2024-09-19 00:40:44,455 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  100, train_loss:  17.0541, val_loss:  15.0255, grad_norm: 0.0133, live_grad: 0.0000, reward_err: 0.1005, 0.0006, 0.0599, KL_dist: 1.6678, 0.8487, 1.3317, param: [11.67241264  3.62130421 10.33710909  4.71912388], weights: [0.30928651 0.29677302 0.39394046], train_wt_loss:  51.1624, val_wt_loss: 45.0765, train_grp_loss: [20.48245313 12.51401241 18.09679439], val_grp_loss: [20.10699144  6.16818072 17.68673226], train_hist_grp_loss: [15.0520407  10.92199448 39.24521236], cur_train_grp_loss: [0.14843367 0.10879017 0.38509314], max_reward_err:  0.1005, max_reward_err_index: 0, max_kl_dist:  1.6678, max_kl_dist_index: 0, max_train_grp_loss:  20.4825, max_train_grp_loss_index: 0, max_val_grp_loss:  20.1070, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.3851, max_cur_train_grp_loss_index: 2, 
2024-09-19 00:40:48,861 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  199, train_loss:  17.0805, val_loss:  14.9933, grad_norm: 0.0330,  live_grad: 0.0000, reward_err: 0.0965, 0.0009, 0.0563, KL_dist: 1.6752, 0.8773, 1.3393, param: [11.304377    3.80384339 10.94868402  4.93944592], weights: [0.28322701 0.26182638 0.45494661], train_wt_loss:  51.2414, val_wt_loss: 44.9798, train_grp_loss: [20.33806301 12.86558459 17.82852458], val_grp_loss: [19.97549532  6.33358318 17.58062267], train_hist_grp_loss: [29.69546617 21.83875316 77.08860097], cur_train_grp_loss: [0.1473883  0.11184001 0.37939053], max_reward_err:  0.0965, max_reward_err_index: 0, max_kl_dist:  1.6752, max_kl_dist_index: 0, max_train_grp_loss:  20.3381, max_train_grp_loss_index: 0, max_val_grp_loss:  19.9755, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.3794, max_cur_train_grp_loss_index: 2, 
2024-09-19 00:40:49,080 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:387] - INFO: Policy parameter learned solely on the preference data rdpo: [11.304377    3.80384339 10.94868402  4.93944592].
2024-09-19 00:40:49,407 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Uniform reward: 3.8294, 3.8294, 3.2249
2024-09-19 00:40:49,408 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Optimal reward: 3.8697, 3.8697, 3.3747
2024-09-19 00:40:49,409 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Policy reward: 3.4964, 3.8663, 3.1848
2024-09-19 00:40:49,409 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Reward Error: 0.0965, 0.0009, 0.0563
2024-09-19 00:40:50,086 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:416] - INFO: Optimal reward: 3.8697, 3.8697, 3.3747
Known param reward: [[3.869661331176758, 3.4677367210388184, 3.334665060043335], [3.4677367210388184, 3.869661331176758, 3.163583993911743], [3.832443952560425, 3.602559804916382, 3.3746607303619385]], Known param reward error: [[0.0, 0.1038655778219524, 0.011851760373646185], [0.1038655778219524, 0.0, 0.06254754279478546], [0.00961773536006451, 0.06902452266517878, 0.0]].
