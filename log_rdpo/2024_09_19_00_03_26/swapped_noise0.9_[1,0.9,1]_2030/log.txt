2024-09-19 00:29:53,611 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log_rdpo/2024_09_19_00_03_26/swapped_noise0.9_[1,0.9,1]_2030
2024-09-19 00:29:53,613 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2030
2024-09-19 00:29:53,614 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-09-19 00:29:53,783 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.4282, l2 distance: 17.0495, acc: 0.80.
2024-09-19 00:29:53,784 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-19 00:29:53,784 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [7.37774022 3.69856674 9.52307453 3.50330935]
2024-09-19 00:29:53,991 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.4683, 3.8639, 3.1679
2024-09-19 00:29:54,227 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-19 00:29:55,587 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  15.1869, val_loss:  15.2662, grad_norm: 0.3004, live_grad: 0.0000, reward_err: 0.1119, 0.0001, 0.0685, KL_dist: 1.7566, 0.7799, 1.3916, param: [ 9.40893534  3.4215963  11.9308176   3.84361335], weights: [0.33317318 0.33285047 0.33397636], train_wt_loss:  45.5608, val_wt_loss: 45.7985, train_grp_loss: [20.81809581  9.41030686 19.86644373], val_grp_loss: [20.78236935  5.68985987 18.66325074], train_hist_grp_loss: [0.21800882 0.12110253 0.4587879 ], cur_train_grp_loss: [0.21800882 0.12110253 0.4587879 ], max_reward_err:  0.1119, max_reward_err_index: 0, max_kl_dist:  1.7566, max_kl_dist_index: 0, max_train_grp_loss:  20.8181, max_train_grp_loss_index: 0, max_val_grp_loss:  20.7824, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4588, max_cur_train_grp_loss_index: 2, 
2024-09-19 00:30:00,148 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  100, train_loss:  15.2007, val_loss:  15.1780, grad_norm: 0.0227, live_grad: 0.0000, reward_err: 0.1064, 0.0003, 0.0635, KL_dist: 1.7396, 0.8002, 1.3805, param: [ 9.70542283  3.69700253 11.74335087  4.1879813 ], weights: [0.32101484 0.28233148 0.39665367], train_wt_loss:  45.6020, val_wt_loss: 45.5341, train_grp_loss: [20.61560714  9.68032911 19.59932781], val_grp_loss: [20.56157375  5.87173538 18.45423311], train_hist_grp_loss: [19.5833127   6.74276228 40.74093096], cur_train_grp_loss: [0.19268987 0.0672019  0.40004572], max_reward_err:  0.1064, max_reward_err_index: 0, max_kl_dist:  1.7396, max_kl_dist_index: 0, max_train_grp_loss:  20.6156, max_train_grp_loss_index: 0, max_val_grp_loss:  20.5616, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4000, max_cur_train_grp_loss_index: 2, 
2024-09-19 00:30:04,608 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  199, train_loss:  15.2529, val_loss:  15.0955, grad_norm: 0.0580,  live_grad: 0.0000, reward_err: 0.0996, 0.0010, 0.0571, KL_dist: 1.7279, 0.8298, 1.3755, param: [10.05843117  4.02492632 11.53609948  4.60351772], weights: [0.30370183 0.2364569  0.45984127], train_wt_loss:  45.7588, val_wt_loss: 45.2866, train_grp_loss: [20.37649268 10.07339686 19.28624394], val_grp_loss: [20.30185084  6.1531133  18.20706521], train_hist_grp_loss: [38.55126046 13.52321785 80.03475797], cur_train_grp_loss: [0.19045906 0.06992111 0.39366637], max_reward_err:  0.0996, max_reward_err_index: 0, max_kl_dist:  1.7279, max_kl_dist_index: 0, max_train_grp_loss:  20.3765, max_train_grp_loss_index: 0, max_val_grp_loss:  20.3019, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.3937, max_cur_train_grp_loss_index: 2, 
2024-09-19 00:30:04,833 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:387] - INFO: Policy parameter learned solely on the preference data rdpo: [10.05843117  4.02492632 11.53609948  4.60351772].
2024-09-19 00:30:05,166 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Uniform reward: 3.8277, 3.8277, 3.2194
2024-09-19 00:30:05,167 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Optimal reward: 3.8721, 3.8721, 3.3771
2024-09-19 00:30:05,167 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Policy reward: 3.4866, 3.8682, 3.1842
2024-09-19 00:30:05,168 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Reward Error: 0.0996, 0.0010, 0.0571
2024-09-19 00:30:05,897 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:416] - INFO: Optimal reward: 3.8721, 3.8721, 3.3771
Known param reward: [[3.8721461296081543, 3.473419189453125, 3.3377835750579834], [3.473419189453125, 3.8721461296081543, 3.1756153106689453], [3.834397315979004, 3.592139482498169, 3.377051591873169]], Known param reward error: [[0.0, 0.10297311279297687, 0.01162789958841124], [0.10297311279297687, 0.0, 0.05964856494611378], [0.00974880915276057, 0.07231303719891401, 0.0]].
