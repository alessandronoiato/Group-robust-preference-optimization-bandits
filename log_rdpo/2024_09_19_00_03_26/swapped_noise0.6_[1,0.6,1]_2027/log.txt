2024-09-19 00:41:03,058 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log_rdpo/2024_09_19_00_03_26/swapped_noise0.6_[1,0.6,1]_2027
2024-09-19 00:41:03,059 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2027
2024-09-19 00:41:03,060 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-09-19 00:41:03,222 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.4811, l2 distance: 13.0261, acc: 0.81.
2024-09-19 00:41:03,223 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-19 00:41:03,223 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [6.28961974 4.34750067 6.93739929 3.90022049]
2024-09-19 00:41:03,426 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.5598, 3.7478, 3.1749
2024-09-19 00:41:03,743 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-19 00:41:05,076 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  17.0056, val_loss:  14.7113, grad_norm: 0.1994, live_grad: 0.0000, reward_err: 0.0775, 0.0051, 0.0412, KL_dist: 1.2774, 0.6937, 1.0247, param: [8.94842134 4.98464457 9.82843764 4.5317189 ], weights: [0.33315261 0.33315917 0.33368822], train_wt_loss:  51.0167, val_wt_loss: 44.1339, train_grp_loss: [20.06342922 14.41195552 15.47642496], val_grp_loss: [19.84291648  7.11059778 17.34864782], train_hist_grp_loss: [0.16674378 0.16871138 0.32738426], cur_train_grp_loss: [0.16674378 0.16871138 0.32738426], max_reward_err:  0.0775, max_reward_err_index: 0, max_kl_dist:  1.2774, max_kl_dist_index: 0, max_train_grp_loss:  20.0634, max_train_grp_loss_index: 0, max_val_grp_loss:  19.8429, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.3274, max_cur_train_grp_loss_index: 2, 
2024-09-19 00:41:09,596 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  100, train_loss:  17.0075, val_loss:  14.6693, grad_norm: 0.0068, live_grad: 0.0000, reward_err: 0.0774, 0.0051, 0.0411, KL_dist: 1.3005, 0.7152, 1.0463, param: [8.99966895 5.0778587  9.98192467 4.64396668], weights: [0.32610244 0.31659042 0.35730714], train_wt_loss:  51.0226, val_wt_loss: 44.0080, train_grp_loss: [19.99074435 14.56137536 15.3637395 ], val_grp_loss: [19.7665195   7.16016704 17.24777184], train_hist_grp_loss: [16.0616722  13.10140517 25.20008883], cur_train_grp_loss: [0.15866254 0.12999824 0.24782083], max_reward_err:  0.0774, max_reward_err_index: 0, max_kl_dist:  1.3005, max_kl_dist_index: 0, max_train_grp_loss:  19.9907, max_train_grp_loss_index: 0, max_val_grp_loss:  19.7665, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2478, max_cur_train_grp_loss_index: 2, 
2024-09-19 00:41:13,994 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  199, train_loss:  17.0136, val_loss:  14.6282, grad_norm: 0.0147,  live_grad: 0.0000, reward_err: 0.0765, 0.0054, 0.0404, KL_dist: 1.3252, 0.7378, 1.0694, param: [ 9.0568198   5.17325962 10.14218253  4.75889109], weights: [0.31840502 0.30077229 0.38082269], train_wt_loss:  51.0409, val_wt_loss: 43.8847, train_grp_loss: [19.91707647 14.7250834  15.24730258], val_grp_loss: [19.68876788  7.21633699 17.14406138], train_hist_grp_loss: [31.74013619 26.04305944 49.64110319], cur_train_grp_loss: [0.158078   0.13145847 0.24594357], max_reward_err:  0.0765, max_reward_err_index: 0, max_kl_dist:  1.3252, max_kl_dist_index: 0, max_train_grp_loss:  19.9171, max_train_grp_loss_index: 0, max_val_grp_loss:  19.6888, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2459, max_cur_train_grp_loss_index: 2, 
2024-09-19 00:41:14,215 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:387] - INFO: Policy parameter learned solely on the preference data rdpo: [ 9.0568198   5.17325962 10.14218253  4.75889109].
2024-09-19 00:41:14,541 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Uniform reward: 3.7506, 3.7506, 3.1231
2024-09-19 00:41:14,542 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Optimal reward: 3.7912, 3.7912, 3.2668
2024-09-19 00:41:14,542 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Policy reward: 3.5012, 3.7708, 3.1348
2024-09-19 00:41:14,543 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Reward Error: 0.0765, 0.0054, 0.0404
2024-09-19 00:41:15,230 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:416] - INFO: Optimal reward: 3.7912, 3.7912, 3.2668
Known param reward: [[3.791201591491699, 3.43137788772583, 3.2245421409606934], [3.43137788772583, 3.791201591491699, 3.0854053497314453], [3.751282215118408, 3.552793025970459, 3.2667675018310547]], Known param reward error: [[0.0, 0.0949102006533743, 0.012925731888386182], [0.0949102006533743, 0.0, 0.055517312449678204], [0.010529478691631431, 0.06288469757352977, 0.0]].
