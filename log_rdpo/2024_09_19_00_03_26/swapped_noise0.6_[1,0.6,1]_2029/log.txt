2024-09-19 00:41:52,819 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log_rdpo/2024_09_19_00_03_26/swapped_noise0.6_[1,0.6,1]_2029
2024-09-19 00:41:52,821 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2029
2024-09-19 00:41:52,822 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-09-19 00:41:52,988 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.4092, l2 distance: 20.9934, acc: 0.79.
2024-09-19 00:41:52,989 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-19 00:41:52,989 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [ 8.9093947   5.69403463 10.38975048  5.04649461]
2024-09-19 00:41:53,204 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.5765, 3.8583, 3.2332
2024-09-19 00:41:53,441 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-19 00:41:54,803 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  15.1740, val_loss:  14.9337, grad_norm: 0.2776, live_grad: 0.0000, reward_err: 0.0923, 0.0019, 0.0503, KL_dist: 1.6232, 0.8650, 1.3107, param: [10.188876    5.18016435 11.46394249  4.24879572], weights: [0.33298444 0.33280859 0.33420697], train_wt_loss:  45.5220, val_wt_loss: 44.8010, train_grp_loss: [20.29439504  9.19764325 18.01299744], val_grp_loss: [19.40272004  6.30019997 18.18335758], train_hist_grp_loss: [0.17771232 0.12488578 0.54418184], cur_train_grp_loss: [0.17771232 0.12488578 0.54418184], max_reward_err:  0.0923, max_reward_err_index: 0, max_kl_dist:  1.6232, max_kl_dist_index: 0, max_train_grp_loss:  20.2944, max_train_grp_loss_index: 0, max_val_grp_loss:  19.4027, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.5442, max_cur_train_grp_loss_index: 2, 
2024-09-19 00:41:59,297 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  100, train_loss:  15.1848, val_loss:  14.9025, grad_norm: 0.0198, live_grad: 0.0000, reward_err: 0.0906, 0.0028, 0.0491, KL_dist: 1.6367, 0.8941, 1.3289, param: [10.10167944  5.46235831 11.68399223  4.55715273], weights: [0.30802478 0.28284949 0.40912573], train_wt_loss:  45.5543, val_wt_loss: 44.7075, train_grp_loss: [20.08922827  9.49653229 17.7895971 ], val_grp_loss: [19.20314526  6.62131246 18.00472322], train_hist_grp_loss: [15.83353875  7.30700703 44.21776549], cur_train_grp_loss: [0.15574787 0.07302295 0.43395273], max_reward_err:  0.0906, max_reward_err_index: 0, max_kl_dist:  1.6367, max_kl_dist_index: 0, max_train_grp_loss:  20.0892, max_train_grp_loss_index: 0, max_val_grp_loss:  19.2031, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4340, max_cur_train_grp_loss_index: 2, 
2024-09-19 00:42:03,590 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  199, train_loss:  15.2265, val_loss:  14.8819, grad_norm: 0.0522,  live_grad: 0.0000, reward_err: 0.0874, 0.0036, 0.0467, KL_dist: 1.6570, 0.9342, 1.3543, param: [10.04880208  5.80741113 11.92245445  4.93366782], weights: [0.27827529 0.23601451 0.4857102 ], train_wt_loss:  45.6796, val_wt_loss: 44.6457, train_grp_loss: [19.84475117  9.92068758 17.51944834], val_grp_loss: [18.95831081  7.07497851 17.78296036], train_hist_grp_loss: [31.16085976 14.68910174 86.86098576], cur_train_grp_loss: [0.15385621 0.07627373 0.42737683], max_reward_err:  0.0874, max_reward_err_index: 0, max_kl_dist:  1.6570, max_kl_dist_index: 0, max_train_grp_loss:  19.8448, max_train_grp_loss_index: 0, max_val_grp_loss:  18.9583, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4274, max_cur_train_grp_loss_index: 2, 
2024-09-19 00:42:03,811 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:387] - INFO: Policy parameter learned solely on the preference data rdpo: [10.04880208  5.80741113 11.92245445  4.93366782].
2024-09-19 00:42:04,137 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Uniform reward: 3.8387, 3.8387, 3.2243
2024-09-19 00:42:04,137 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Optimal reward: 3.8841, 3.8841, 3.3675
2024-09-19 00:42:04,138 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Policy reward: 3.5445, 3.8702, 3.2102
2024-09-19 00:42:04,138 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Reward Error: 0.0874, 0.0036, 0.0467
2024-09-19 00:42:04,814 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:416] - INFO: Optimal reward: 3.8841, 3.8841, 3.3675
Known param reward: [[3.884077310562134, 3.4758739471435547, 3.3304951190948486], [3.4758739471435547, 3.884077310562134, 3.1624059677124023], [3.847635269165039, 3.6067681312561035, 3.3674604892730713]], Known param reward error: [[0.0, 0.10509661131320291, 0.010977224616584088], [0.10509661131320291, 0.0, 0.060892925756326766], [0.009382419165034734, 0.07139641081600817, 0.0]].
