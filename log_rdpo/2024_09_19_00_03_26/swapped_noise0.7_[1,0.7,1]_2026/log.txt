2024-09-19 00:36:30,411 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log_rdpo/2024_09_19_00_03_26/swapped_noise0.7_[1,0.7,1]_2026
2024-09-19 00:36:30,413 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2026
2024-09-19 00:36:30,413 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-09-19 00:36:30,576 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.4813, l2 distance: 14.8904, acc: 0.78.
2024-09-19 00:36:30,577 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-19 00:36:30,578 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [7.67816127 4.45673794 7.13735006 4.03215563]
2024-09-19 00:36:30,782 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.5911, 3.8424, 3.2513
2024-09-19 00:36:31,020 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-19 00:36:32,351 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  17.2133, val_loss:  14.6263, grad_norm: 0.1905, live_grad: 0.0000, reward_err: 0.0846, 0.0041, 0.0465, KL_dist: 1.3323, 0.7224, 1.0615, param: [9.97747737 4.86680442 9.42385487 4.79878361], weights: [0.33301233 0.33297485 0.33401281], train_wt_loss:  51.6399, val_wt_loss: 43.8789, train_grp_loss: [19.49983275 14.17207237 17.94090425], val_grp_loss: [18.60380306  7.26531031 17.47697014], train_hist_grp_loss: [0.15681377 0.14555772 0.45679643], cur_train_grp_loss: [0.15681377 0.14555772 0.45679643], max_reward_err:  0.0846, max_reward_err_index: 0, max_kl_dist:  1.3323, max_kl_dist_index: 0, max_train_grp_loss:  19.4998, max_train_grp_loss_index: 0, max_val_grp_loss:  18.6038, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4568, max_cur_train_grp_loss_index: 2, 
2024-09-19 00:36:36,867 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  100, train_loss:  17.2171, val_loss:  14.5734, grad_norm: 0.0094, live_grad: 0.0000, reward_err: 0.0834, 0.0040, 0.0454, KL_dist: 1.3580, 0.7505, 1.0850, param: [9.88866833 4.99685128 9.79405505 4.92759959], weights: [0.30701134 0.30182119 0.39116748], train_wt_loss:  51.6513, val_wt_loss: 43.7202, train_grp_loss: [19.40044454 14.36150076 17.7935544 ], val_grp_loss: [18.50451825  7.33251075 17.35777654], train_hist_grp_loss: [14.25230218 12.54730922 38.47741556], cur_train_grp_loss: [0.14059063 0.12486408 0.37861982], max_reward_err:  0.0834, max_reward_err_index: 0, max_kl_dist:  1.3580, max_kl_dist_index: 0, max_train_grp_loss:  19.4004, max_train_grp_loss_index: 0, max_val_grp_loss:  18.5045, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.3786, max_cur_train_grp_loss_index: 2, 
2024-09-19 00:36:41,336 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  199, train_loss:  17.2308, val_loss:  14.5171, grad_norm: 0.0235,  live_grad: 0.0000, reward_err: 0.0826, 0.0044, 0.0448, KL_dist: 1.3929, 0.7845, 1.1170, param: [ 9.80890185  5.1480151  10.21149204  5.07782173], weights: [0.27934627 0.27075865 0.44989509], train_wt_loss:  51.6925, val_wt_loss: 43.5513, train_grp_loss: [19.28775825 14.60083831 17.62651994], val_grp_loss: [18.39106396  7.42349154 17.22053553], train_hist_grp_loss: [28.13089928 25.00847009 75.78713064], cur_train_grp_loss: [0.13977517 0.12694014 0.37507057], max_reward_err:  0.0826, max_reward_err_index: 0, max_kl_dist:  1.3929, max_kl_dist_index: 0, max_train_grp_loss:  19.2878, max_train_grp_loss_index: 0, max_val_grp_loss:  18.3911, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.3751, max_cur_train_grp_loss_index: 2, 
2024-09-19 00:36:41,559 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:387] - INFO: Policy parameter learned solely on the preference data rdpo: [ 9.80890185  5.1480151  10.21149204  5.07782173].
2024-09-19 00:36:41,896 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Uniform reward: 3.8296, 3.8296, 3.2253
2024-09-19 00:36:41,897 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Optimal reward: 3.8699, 3.8699, 3.3751
2024-09-19 00:36:41,897 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Policy reward: 3.5504, 3.8529, 3.2238
2024-09-19 00:36:41,898 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Reward Error: 0.0826, 0.0044, 0.0448
2024-09-19 00:36:42,589 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:416] - INFO: Optimal reward: 3.8699, 3.8699, 3.3751
Known param reward: [[3.8699047565460205, 3.4682676792144775, 3.3350672721862793], [3.4682676792144775, 3.8699047565460205, 3.164400100708008], [3.831815481185913, 3.603090763092041, 3.375126361846924]], Known param reward error: [[0.0, 0.10378474474137016, 0.011868915520758028], [0.10378474474137016, 0.0, 0.06243507310452317], [0.009842432244793276, 0.06894588116223231, 0.0]].
