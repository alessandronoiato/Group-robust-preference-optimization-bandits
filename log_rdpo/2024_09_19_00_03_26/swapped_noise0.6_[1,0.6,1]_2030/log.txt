2024-09-19 00:42:17,680 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log_rdpo/2024_09_19_00_03_26/swapped_noise0.6_[1,0.6,1]_2030
2024-09-19 00:42:17,682 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2030
2024-09-19 00:42:17,682 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-09-19 00:42:17,841 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.4961, l2 distance: 10.5890, acc: 0.77.
2024-09-19 00:42:17,842 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-19 00:42:17,843 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [5.36923291 3.75606204 5.9084699  3.85520782]
2024-09-19 00:42:18,051 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.5727, 3.7607, 3.2144
2024-09-19 00:42:18,288 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-19 00:42:19,625 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  17.3700, val_loss:  15.8288, grad_norm: 0.2504, live_grad: 0.0000, reward_err: 0.0746, 0.0083, 0.0372, KL_dist: 1.0549, 0.5638, 0.8317, param: [7.94764051 4.49200547 8.75987484 4.93040514], weights: [0.33313868 0.3329211  0.33394022], train_wt_loss:  52.1101, val_wt_loss: 47.4865, train_grp_loss: [20.4526932  14.59045827 18.80713808], val_grp_loss: [20.3785592   8.06822224 18.3878428 ], train_hist_grp_loss: [0.20297176 0.13764008 0.44328466], cur_train_grp_loss: [0.20297176 0.13764008 0.44328466], max_reward_err:  0.0746, max_reward_err_index: 0, max_kl_dist:  1.0549, max_kl_dist_index: 0, max_train_grp_loss:  20.4527, max_train_grp_loss_index: 0, max_val_grp_loss:  20.3786, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4433, max_cur_train_grp_loss_index: 2, 
2024-09-19 00:42:24,146 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  100, train_loss:  17.3782, val_loss:  15.7788, grad_norm: 0.0164, live_grad: 0.0000, reward_err: 0.0728, 0.0091, 0.0357, KL_dist: 1.0672, 0.5989, 0.8472, param: [8.02149576 4.76371944 8.83406638 5.17894802], weights: [0.3195684  0.29239304 0.38803856], train_wt_loss:  52.1347, val_wt_loss: 47.3363, train_grp_loss: [20.25935984 14.81412105 18.62212378], val_grp_loss: [20.19693406  8.28734539 18.2191851 ], train_hist_grp_loss: [19.23021118 10.34297    38.64355126], cur_train_grp_loss: [0.1893591  0.10285792 0.38008428], max_reward_err:  0.0728, max_reward_err_index: 0, max_kl_dist:  1.0672, max_kl_dist_index: 0, max_train_grp_loss:  20.2594, max_train_grp_loss_index: 0, max_val_grp_loss:  20.1969, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.3801, max_cur_train_grp_loss_index: 2, 
2024-09-19 00:42:28,521 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  199, train_loss:  17.4079, val_loss:  15.7326, grad_norm: 0.0404,  live_grad: 0.0000, reward_err: 0.0698, 0.0101, 0.0334, KL_dist: 1.0855, 0.6423, 0.8689, param: [8.09022127 5.07706113 8.95570663 5.46619505], weights: [0.30243747 0.25451081 0.44305171], train_wt_loss:  52.2237, val_wt_loss: 47.1978, train_grp_loss: [20.04089807 15.11154543 18.4068312 ], val_grp_loss: [19.99248378  8.57120758 18.02404712], train_hist_grp_loss: [37.87700358 20.62388078 76.0581972 ], cur_train_grp_loss: [0.18732009 0.10491724 0.37569746], max_reward_err:  0.0698, max_reward_err_index: 0, max_kl_dist:  1.0855, max_kl_dist_index: 0, max_train_grp_loss:  20.0409, max_train_grp_loss_index: 0, max_val_grp_loss:  19.9925, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.3757, max_cur_train_grp_loss_index: 2, 
2024-09-19 00:42:28,743 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:387] - INFO: Policy parameter learned solely on the preference data rdpo: [8.09022127 5.07706113 8.95570663 5.46619505].
2024-09-19 00:42:29,068 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Uniform reward: 3.7751, 3.7751, 3.1646
2024-09-19 00:42:29,069 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Optimal reward: 3.8138, 3.8138, 3.3081
2024-09-19 00:42:29,069 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Policy reward: 3.5477, 3.7752, 3.1976
2024-09-19 00:42:29,069 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Reward Error: 0.0698, 0.0101, 0.0334
2024-09-19 00:42:29,745 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:416] - INFO: Optimal reward: 3.8138, 3.8138, 3.3081
Known param reward: [[3.8138465881347656, 3.439753770828247, 3.273068904876709], [3.439753770828247, 3.8138465881347656, 3.121405839920044], [3.7787630558013916, 3.5612988471984863, 3.308058500289917]], Known param reward error: [[0.0, 0.09808806113763369, 0.010577078794145125], [0.09808806113763369, 0.0, 0.05642362743993641], [0.009198988874519018, 0.06621864175711184, 0.0]].
