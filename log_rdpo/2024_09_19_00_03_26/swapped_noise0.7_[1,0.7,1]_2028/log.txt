2024-09-19 00:37:19,195 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log_rdpo/2024_09_19_00_03_26/swapped_noise0.7_[1,0.7,1]_2028
2024-09-19 00:37:19,197 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2028
2024-09-19 00:37:19,197 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-09-19 00:37:19,359 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.4872, l2 distance: 13.0978, acc: 0.77.
2024-09-19 00:37:19,360 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-19 00:37:19,361 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [6.46691538 3.95756071 6.43337544 5.0747662 ]
2024-09-19 00:37:19,566 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.6532, 3.8141, 3.2658
2024-09-19 00:37:19,818 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-19 00:37:21,175 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  17.3920, val_loss:  15.4514, grad_norm: 0.3157, live_grad: 0.0000, reward_err: 0.0668, 0.0123, 0.0328, KL_dist: 1.0578, 0.6843, 0.8558, param: [7.86526872 4.57604731 9.07256169 6.17415474], weights: [0.33304661 0.33315312 0.33380027], train_wt_loss:  52.1759, val_wt_loss: 46.3542, train_grp_loss: [20.8437049  13.38790755 17.45743647], val_grp_loss: [18.9007719   9.30834047 17.36619607], train_hist_grp_loss: [0.17723622 0.20921197 0.40327243], cur_train_grp_loss: [0.17723622 0.20921197 0.40327243], max_reward_err:  0.0668, max_reward_err_index: 0, max_kl_dist:  1.0578, max_kl_dist_index: 0, max_train_grp_loss:  20.8437, max_train_grp_loss_index: 0, max_val_grp_loss:  18.9008, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4033, max_cur_train_grp_loss_index: 2, 
2024-09-19 00:37:25,682 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  100, train_loss:  17.3958, val_loss:  15.4264, grad_norm: 0.0106, live_grad: 0.0000, reward_err: 0.0659, 0.0137, 0.0320, KL_dist: 1.0706, 0.7109, 0.8701, param: [8.00208379 4.7607061  9.08154673 6.33363008], weights: [0.32054243 0.30795623 0.37150134], train_wt_loss:  52.1874, val_wt_loss: 46.2793, train_grp_loss: [20.71154515 13.61832093 17.32219527], val_grp_loss: [18.76672768  9.51351818 17.24783709], train_hist_grp_loss: [16.16096281 12.15526483 30.91474659], cur_train_grp_loss: [0.15933    0.12049415 0.30392299], max_reward_err:  0.0659, max_reward_err_index: 0, max_kl_dist:  1.0706, max_kl_dist_index: 0, max_train_grp_loss:  20.7115, max_train_grp_loss_index: 0, max_val_grp_loss:  18.7667, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.3039, max_cur_train_grp_loss_index: 2, 
2024-09-19 00:37:30,031 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  199, train_loss:  17.4084, val_loss:  15.4025, grad_norm: 0.0243,  live_grad: 0.0000, reward_err: 0.0639, 0.0141, 0.0304, KL_dist: 1.0876, 0.7409, 0.8881, param: [8.14247474 4.95937465 9.11545852 6.5039303 ], weights: [0.30652342 0.28385327 0.40962332], train_wt_loss:  52.2252, val_wt_loss: 46.2076, train_grp_loss: [20.57413028 13.88376005 17.17575871], val_grp_loss: [18.62419244  9.74393217 17.11885396], train_hist_grp_loss: [31.88221727 24.1985455  60.8766023 ], cur_train_grp_loss: [0.15827347 0.1228396  0.30135615], max_reward_err:  0.0639, max_reward_err_index: 0, max_kl_dist:  1.0876, max_kl_dist_index: 0, max_train_grp_loss:  20.5741, max_train_grp_loss_index: 0, max_val_grp_loss:  18.6242, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.3014, max_cur_train_grp_loss_index: 2, 
2024-09-19 00:37:30,252 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:387] - INFO: Policy parameter learned solely on the preference data rdpo: [8.14247474 4.95937465 9.11545852 6.5039303 ].
2024-09-19 00:37:30,577 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Uniform reward: 3.8371, 3.8371, 3.2123
2024-09-19 00:37:30,578 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Optimal reward: 3.8741, 3.8741, 3.3487
2024-09-19 00:37:30,578 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Policy reward: 3.6267, 3.8195, 3.2469
2024-09-19 00:37:30,578 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Reward Error: 0.0639, 0.0141, 0.0304
2024-09-19 00:37:31,254 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:416] - INFO: Optimal reward: 3.8741, 3.8741, 3.3487
Known param reward: [[3.8741343021392822, 3.4676833152770996, 3.31387996673584], [3.4676833152770996, 3.8741343021392822, 3.1369452476501465], [3.840017557144165, 3.611396074295044, 3.3486669063568115]], Known param reward error: [[0.0, 0.10491401566480076, 0.010388294982380973], [0.10491401566480076, 0.0, 0.0632256550523886], [0.008806288665903515, 0.06781856470467615, 0.0]].
