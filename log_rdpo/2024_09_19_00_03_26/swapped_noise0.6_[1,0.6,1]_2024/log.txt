2024-09-19 00:39:48,053 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log_rdpo/2024_09_19_00_03_26/swapped_noise0.6_[1,0.6,1]_2024
2024-09-19 00:39:48,055 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2024
2024-09-19 00:39:48,056 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-09-19 00:39:48,215 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.4614, l2 distance: 14.2156, acc: 0.81.
2024-09-19 00:39:48,215 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-19 00:39:48,216 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [7.12777926 3.69118221 7.29367386 4.24080502]
2024-09-19 00:39:48,417 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.5381, 3.7683, 3.1486
2024-09-19 00:39:48,669 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-19 00:39:49,978 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  16.2059, val_loss:  14.8814, grad_norm: 0.2086, live_grad: 0.0000, reward_err: 0.0805, 0.0033, 0.0454, KL_dist: 1.4301, 0.7803, 1.1487, param: [ 9.00570615  3.95671099 10.89152432  5.3304464 ], weights: [0.33304949 0.33284837 0.33410214], train_wt_loss:  48.6177, val_wt_loss: 44.6441, train_grp_loss: [19.68409627 13.23160731 15.79461328], val_grp_loss: [19.38970417  7.02768425 17.97153387], train_hist_grp_loss: [0.17700651 0.11659973 0.49257111], cur_train_grp_loss: [0.17700651 0.11659973 0.49257111], max_reward_err:  0.0805, max_reward_err_index: 0, max_kl_dist:  1.4301, max_kl_dist_index: 0, max_train_grp_loss:  19.6841, max_train_grp_loss_index: 0, max_val_grp_loss:  19.3897, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4926, max_cur_train_grp_loss_index: 2, 
2024-09-19 00:39:54,486 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  100, train_loss:  16.2122, val_loss:  14.8144, grad_norm: 0.0138, live_grad: 0.0000, reward_err: 0.0791, 0.0035, 0.0442, KL_dist: 1.4742, 0.8180, 1.1904, param: [ 9.05191364  4.15721641 11.19404863  5.49135356], weights: [0.31341768 0.29394293 0.39263939], train_wt_loss:  48.6365, val_wt_loss: 44.4432, train_grp_loss: [19.54576839 13.42554235 15.60400245], val_grp_loss: [19.26210566  7.10605526 17.82568507], train_hist_grp_loss: [16.25660269  9.84149189 38.79208789], cur_train_grp_loss: [0.16022329 0.09798045 0.38063566], max_reward_err:  0.0791, max_reward_err_index: 0, max_kl_dist:  1.4742, max_kl_dist_index: 0, max_train_grp_loss:  19.5458, max_train_grp_loss_index: 0, max_val_grp_loss:  19.2621, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.3806, max_cur_train_grp_loss_index: 2, 
2024-09-19 00:39:58,841 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  199, train_loss:  16.2349, val_loss:  14.7447, grad_norm: 0.0342,  live_grad: 0.0000, reward_err: 0.0781, 0.0039, 0.0436, KL_dist: 1.5288, 0.8634, 1.2418, param: [ 9.11896257  4.38563852 11.55119946  5.67568695], weights: [0.29084224 0.25685546 0.4523023 ], train_wt_loss:  48.7046, val_wt_loss: 44.2341, train_grp_loss: [19.39055198 13.67938409 15.38377346], val_grp_loss: [19.11805851  7.21530289 17.65862787], train_hist_grp_loss: [32.05644519 19.62969586 76.2134232 ], cur_train_grp_loss: [0.15895258 0.0998281  0.37527227], max_reward_err:  0.0781, max_reward_err_index: 0, max_kl_dist:  1.5288, max_kl_dist_index: 0, max_train_grp_loss:  19.3906, max_train_grp_loss_index: 0, max_val_grp_loss:  19.1181, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.3753, max_cur_train_grp_loss_index: 2, 
2024-09-19 00:39:59,064 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:387] - INFO: Policy parameter learned solely on the preference data rdpo: [ 9.11896257  4.38563852 11.55119946  5.67568695].
2024-09-19 00:39:59,391 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Uniform reward: 3.7483, 3.7483, 3.1113
2024-09-19 00:39:59,392 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Optimal reward: 3.7937, 3.7937, 3.2584
2024-09-19 00:39:59,392 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Policy reward: 3.4974, 3.7790, 3.1163
2024-09-19 00:39:59,393 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Reward Error: 0.0781, 0.0039, 0.0436
2024-09-19 00:40:00,073 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:416] - INFO: Optimal reward: 3.7937, 3.7937, 3.2584
Known param reward: [[3.7937493324279785, 3.4302093982696533, 3.224942445755005], [3.4302093982696533, 3.7937493324279785, 3.071303129196167], [3.7626752853393555, 3.56032395362854, 3.2583768367767334]], Known param reward error: [[0.0, 0.09582602916088334, 0.010261057175572927], [0.09582602916088334, 0.0, 0.057413159051800874], [0.008190854051165217, 0.061528940988319736, 0.0]].
