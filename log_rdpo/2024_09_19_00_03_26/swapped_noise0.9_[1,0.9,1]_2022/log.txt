2024-09-19 00:26:33,511 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log_rdpo/2024_09_19_00_03_26/swapped_noise0.9_[1,0.9,1]_2022
2024-09-19 00:26:33,513 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2022
2024-09-19 00:26:33,514 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-09-19 00:26:33,670 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.3535, l2 distance: 28.4868, acc: 0.85.
2024-09-19 00:26:33,670 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-19 00:26:33,671 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [12.5384091   6.91815982 12.54481599  6.12893569]
2024-09-19 00:26:33,868 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.5601, 3.8531, 3.1999
2024-09-19 00:26:34,115 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-19 00:26:35,411 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  13.8276, val_loss:  14.0473, grad_norm: 0.3075, live_grad: 0.0000, reward_err: 0.0960, 0.0008, 0.0540, KL_dist: 1.8804, 1.0321, 1.5331, param: [12.69620374  5.4020049  11.11686669  4.03135654], weights: [0.333068   0.33289748 0.33403452], train_wt_loss:  41.4827, val_wt_loss: 42.1420, train_grp_loss: [19.98563402  6.85203006 16.72639016], val_grp_loss: [19.37056704  6.46286412 16.90535167], train_hist_grp_loss: [0.18353414 0.13232229 0.47330093], cur_train_grp_loss: [0.18353414 0.13232229 0.47330093], max_reward_err:  0.0960, max_reward_err_index: 0, max_kl_dist:  1.8804, max_kl_dist_index: 0, max_train_grp_loss:  19.9856, max_train_grp_loss_index: 0, max_val_grp_loss:  19.3706, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4733, max_cur_train_grp_loss_index: 2, 
2024-09-19 00:26:39,874 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  100, train_loss:  13.8380, val_loss:  14.0423, grad_norm: 0.0171, live_grad: 0.0000, reward_err: 0.0931, 0.0010, 0.0520, KL_dist: 1.9107, 1.0645, 1.5666, param: [13.084008    5.69721145 10.92687319  4.29597543], weights: [0.32112769 0.28848417 0.39038814], train_wt_loss:  41.5139, val_wt_loss: 42.1269, train_grp_loss: [19.86022134  7.09564342 16.45495964], val_grp_loss: [19.16928145  6.81732529 16.71103158], train_hist_grp_loss: [16.2520426   5.5321836  35.78230815], cur_train_grp_loss: [0.16017387 0.05498281 0.3501673 ], max_reward_err:  0.0931, max_reward_err_index: 0, max_kl_dist:  1.9107, max_kl_dist_index: 0, max_train_grp_loss:  19.8602, max_train_grp_loss_index: 0, max_val_grp_loss:  19.1693, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.3502, max_cur_train_grp_loss_index: 2, 
2024-09-19 00:26:44,139 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  199, train_loss:  13.8756, val_loss:  14.0582, grad_norm: 0.0423,  live_grad: 0.0000, reward_err: 0.0910, 0.0017, 0.0506, KL_dist: 1.9528, 1.1057, 1.6122, param: [13.52945061  6.04089542 10.7246608   4.60173049], weights: [0.3054035  0.24766582 0.44693068], train_wt_loss:  41.6268, val_wt_loss: 42.1747, train_grp_loss: [19.71852243  7.43072341 16.14937472], val_grp_loss: [18.94150687  7.28142625 16.48998946], train_hist_grp_loss: [32.05342062 11.09807183 70.13038611], cur_train_grp_loss: [0.15903264 0.0575719  0.3436731 ], max_reward_err:  0.0910, max_reward_err_index: 0, max_kl_dist:  1.9528, max_kl_dist_index: 0, max_train_grp_loss:  19.7185, max_train_grp_loss_index: 0, max_val_grp_loss:  18.9415, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.3437, max_cur_train_grp_loss_index: 2, 
2024-09-19 00:26:44,359 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:387] - INFO: Policy parameter learned solely on the preference data rdpo: [13.52945061  6.04089542 10.7246608   4.60173049].
2024-09-19 00:26:44,685 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Uniform reward: 3.8376, 3.8376, 3.2077
2024-09-19 00:26:44,686 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Optimal reward: 3.8707, 3.8707, 3.3351
2024-09-19 00:26:44,686 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Policy reward: 3.5186, 3.8640, 3.1663
2024-09-19 00:26:44,687 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Reward Error: 0.0910, 0.0017, 0.0506
2024-09-19 00:26:45,364 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:416] - INFO: Optimal reward: 3.8707, 3.8707, 3.3351
Known param reward: [[3.870741367340088, 3.47579288482666, 3.3037049770355225], [3.47579288482666, 3.870741367340088, 3.1393208503723145], [3.836113214492798, 3.5835537910461426, 3.3351211547851562]], Known param reward error: [[0.0, 0.10203432496055144, 0.009419801048174388], [0.10203432496055144, 0.0, 0.05870860317380433], [0.008946129322788094, 0.07419446277582117, 0.0]].
