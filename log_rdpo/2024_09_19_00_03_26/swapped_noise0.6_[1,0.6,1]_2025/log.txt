2024-09-19 00:40:13,301 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log_rdpo/2024_09_19_00_03_26/swapped_noise0.6_[1,0.6,1]_2025
2024-09-19 00:40:13,303 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2025
2024-09-19 00:40:13,304 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-09-19 00:40:13,464 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.4642, l2 distance: 14.7870, acc: 0.79.
2024-09-19 00:40:13,465 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-19 00:40:13,466 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [6.92350956 3.51719138 8.20337024 3.46492795]
2024-09-19 00:40:13,670 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.5289, 3.8317, 3.1086
2024-09-19 00:40:13,931 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-19 00:40:15,257 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  16.2770, val_loss:  14.9356, grad_norm: 0.2566, live_grad: 0.0000, reward_err: 0.0988, 0.0001, 0.0593, KL_dist: 1.5128, 0.8221, 1.2185, param: [10.07720448  3.46846653 11.24723835  3.90651736], weights: [0.33305919 0.33291853 0.33402229], train_wt_loss:  48.8309, val_wt_loss: 44.8068, train_grp_loss: [19.55725504 12.52784939 17.94690847], val_grp_loss: [20.56934913  5.83519332 18.41123305], train_hist_grp_loss: [0.182508   0.14026642 0.47125848], cur_train_grp_loss: [0.182508   0.14026642 0.47125848], max_reward_err:  0.0988, max_reward_err_index: 0, max_kl_dist:  1.5128, max_kl_dist_index: 0, max_train_grp_loss:  19.5573, max_train_grp_loss_index: 0, max_val_grp_loss:  20.5693, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4713, max_cur_train_grp_loss_index: 2, 
2024-09-19 00:40:19,800 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  100, train_loss:  16.2848, val_loss:  14.8922, grad_norm: 0.0140, live_grad: 0.0000, reward_err: 0.0973, 0.0002, 0.0582, KL_dist: 1.5438, 0.8496, 1.2507, param: [ 9.88270114  3.69187878 11.6695146   4.13609308], weights: [0.31421369 0.29572111 0.3900652 ], train_wt_loss:  48.8543, val_wt_loss: 44.6765, train_grp_loss: [19.3845824  12.79235558 17.72733514], val_grp_loss: [20.42405938  6.00142836 18.26042293], train_hist_grp_loss: [16.01459751  9.94894963 37.63865745], cur_train_grp_loss: [0.1576131  0.09914237 0.36936788], max_reward_err:  0.0973, max_reward_err_index: 0, max_kl_dist:  1.5438, max_kl_dist_index: 0, max_train_grp_loss:  19.3846, max_train_grp_loss_index: 0, max_val_grp_loss:  20.4241, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.3694, max_cur_train_grp_loss_index: 2, 
2024-09-19 00:40:24,214 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  199, train_loss:  16.3121, val_loss:  14.8564, grad_norm: 0.0344,  live_grad: 0.0000, reward_err: 0.0983, 0.0005, 0.0596, KL_dist: 1.5857, 0.8834, 1.2938, param: [ 9.68557226  3.94575451 12.13883664  4.39624959], weights: [0.29254258 0.26036382 0.44709359], train_wt_loss:  48.9363, val_wt_loss: 44.5693, train_grp_loss: [19.19294795 13.1290613  17.4843674 ], val_grp_loss: [20.26329658  6.22358208 18.09222003], train_hist_grp_loss: [31.54190508 19.88887864 73.95767573], cur_train_grp_loss: [0.15605684 0.10174593 0.36431146], max_reward_err:  0.0983, max_reward_err_index: 0, max_kl_dist:  1.5857, max_kl_dist_index: 0, max_train_grp_loss:  19.1929, max_train_grp_loss_index: 0, max_val_grp_loss:  20.2633, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.3643, max_cur_train_grp_loss_index: 2, 
2024-09-19 00:40:24,439 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:387] - INFO: Policy parameter learned solely on the preference data rdpo: [ 9.68557226  3.94575451 12.13883664  4.39624959].
2024-09-19 00:40:24,766 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Uniform reward: 3.8103, 3.8103, 3.1427
2024-09-19 00:40:24,767 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Optimal reward: 3.8440, 3.8440, 3.2545
2024-09-19 00:40:24,768 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Policy reward: 3.4660, 3.8421, 3.0604
2024-09-19 00:40:24,768 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Reward Error: 0.0983, 0.0005, 0.0596
2024-09-19 00:40:25,478 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:416] - INFO: Optimal reward: 3.8440, 3.8440, 3.2545
Known param reward: [[3.843956232070923, 3.4647014141082764, 3.2180964946746826], [3.4647014141082764, 3.843956232070923, 3.0630156993865967], [3.8041796684265137, 3.590562105178833, 3.254488229751587]], Known param reward error: [[0.0, 0.09866262648841967, 0.011182014654169469], [0.09866262648841967, 0.0, 0.058833376201703216], [0.010347819080910722, 0.06592013841832281, 0.0]].
