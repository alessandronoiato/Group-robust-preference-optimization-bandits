2024-09-19 00:24:03,477 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log_rdpo/2024_09_19_00_03_26/swapped_noise1.0_[1,1.0,1]_2026
2024-09-19 00:24:03,479 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2026
2024-09-19 00:24:03,479 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-09-19 00:24:03,646 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.3205, l2 distance: 37.0255, acc: 0.85.
2024-09-19 00:24:03,647 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-19 00:24:03,648 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [16.29530932  7.55488527 15.66290624  7.13011982]
2024-09-19 00:24:03,857 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.5156, 3.8430, 3.1442
2024-09-19 00:24:04,123 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-19 00:24:05,450 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  13.3766, val_loss:  14.6094, grad_norm: 0.2651, live_grad: 0.0000, reward_err: 0.1050, 0.0000, 0.0617, KL_dist: 2.2103, 1.2639, 1.8071, param: [13.77803389  4.59437425 13.07620144  3.86552967], weights: [0.33302154 0.33298425 0.33399421], train_wt_loss:  40.1298, val_wt_loss: 43.8281, train_grp_loss: [17.75179516  6.23045244 18.01556159], val_grp_loss: [19.65952557  6.39590106 16.89293572], train_hist_grp_loss: [0.1500302  0.13883355 0.44167941], cur_train_grp_loss: [0.1500302  0.13883355 0.44167941], max_reward_err:  0.1050, max_reward_err_index: 0, max_kl_dist:  2.2103, max_kl_dist_index: 0, max_train_grp_loss:  18.0156, max_train_grp_loss_index: 2, max_val_grp_loss:  19.6595, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.4417, max_cur_train_grp_loss_index: 2, 
2024-09-19 00:24:10,033 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  100, train_loss:  13.3858, val_loss:  14.5699, grad_norm: 0.0171, live_grad: 0.0000, reward_err: 0.1027, 0.0000, 0.0598, KL_dist: 2.2255, 1.2901, 1.8251, param: [13.80215535  4.8922633  13.26868968  4.13128371], weights: [0.31038092 0.2886275  0.40099158], train_wt_loss:  40.1574, val_wt_loss: 43.7097, train_grp_loss: [17.57566619  6.54829323 17.81377206], val_grp_loss: [19.4788089   6.67384283 16.71083658], train_hist_grp_loss: [12.95231881  5.68597832 38.56632901], cur_train_grp_loss: [0.12737379 0.05690936 0.37906313], max_reward_err:  0.1027, max_reward_err_index: 0, max_kl_dist:  2.2255, max_kl_dist_index: 0, max_train_grp_loss:  17.8138, max_train_grp_loss_index: 2, max_val_grp_loss:  19.4788, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.3791, max_cur_train_grp_loss_index: 2, 
2024-09-19 00:24:14,394 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  199, train_loss:  13.4204, val_loss:  14.5415, grad_norm: 0.0438,  live_grad: 0.0000, reward_err: 0.0998, 0.0001, 0.0571, KL_dist: 2.2441, 1.3224, 1.8471, param: [13.83254985  5.25025639 13.48574795  4.44480682], weights: [0.28376076 0.24671171 0.46952753], train_wt_loss:  40.2612, val_wt_loss: 43.6245, train_grp_loss: [17.36892636  6.9832921  17.57719925], val_grp_loss: [19.26543946  7.05897454 16.49755383], train_hist_grp_loss: [25.4895952  11.49849804 75.84913996], cur_train_grp_loss: [0.12587818 0.06067966 0.37403801], max_reward_err:  0.0998, max_reward_err_index: 0, max_kl_dist:  2.2441, max_kl_dist_index: 0, max_train_grp_loss:  17.5772, max_train_grp_loss_index: 2, max_val_grp_loss:  19.2654, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.3740, max_cur_train_grp_loss_index: 2, 
2024-09-19 00:24:14,631 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:387] - INFO: Policy parameter learned solely on the preference data rdpo: [13.83254985  5.25025639 13.48574795  4.44480682].
2024-09-19 00:24:14,973 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Uniform reward: 3.8112, 3.8112, 3.1709
2024-09-19 00:24:14,974 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Optimal reward: 3.8518, 3.8518, 3.2974
2024-09-19 00:24:14,974 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Policy reward: 3.4676, 3.8515, 3.1091
2024-09-19 00:24:14,975 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Reward Error: 0.0998, 0.0001, 0.0571
2024-09-19 00:24:15,692 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:416] - INFO: Optimal reward: 3.8518, 3.8518, 3.2974
Known param reward: [[3.8518338203430176, 3.4604334831237793, 3.266357421875], [3.4604334831237793, 3.8518338203430176, 3.1038687229156494], [3.8126895427703857, 3.589339256286621, 3.297445297241211]], Known param reward error: [[0.0, 0.10161402476713881, 0.009427866898116682], [0.10161402476713881, 0.0, 0.058705014602521616], [0.010162504250805377, 0.06814794622500629, 0.0]].
