2024-09-18 16:05:26,822 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log_rdpo/2024_09_18_15_16_04/swapped_noise0.3_[1,0.3,1]_2027
2024-09-18 16:05:26,824 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2027
2024-09-18 16:05:26,825 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-09-18 16:05:26,984 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.4935, l2 distance: 15.3927, acc: 0.81.
2024-09-18 16:05:26,985 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-18 16:05:26,986 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [7.5757812  4.13887051 6.87684585 5.87984426]
2024-09-18 16:05:27,192 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.6175, 3.7697, 3.2662
2024-09-18 16:05:27,438 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-18 16:05:28,619 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  17.5660, val_loss:  18.8028, grad_norm: 0.2508, live_grad: 0.0000, reward_err: 0.0707, 0.0126, 0.0332, KL_dist: 1.4464, 0.9228, 1.1860, param: [ 9.77033925  4.94404802 10.44135979  7.13492172], weights: [0.33331402 0.33338667 0.33329931], train_wt_loss:  52.6981, val_wt_loss: 56.4084, train_grp_loss: [18.61678617 18.64557267 15.58973068], val_grp_loss: [18.40001422 20.65772529 17.4199664 ], train_hist_grp_loss: [0.22214062 0.24393302 0.21772444], cur_train_grp_loss: [0.22214062 0.24393302 0.21772444], max_reward_err:  0.0707, max_reward_err_index: 0, max_kl_dist:  1.4464, max_kl_dist_index: 0, max_train_grp_loss:  18.6456, max_train_grp_loss_index: 1, max_val_grp_loss:  20.6577, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2439, max_cur_train_grp_loss_index: 1, 
2024-09-18 16:05:33,034 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  99, train_loss:  17.5672, val_loss:  18.7672, grad_norm: 0.0040,  live_grad: 0.0000, reward_err: 0.0707, 0.0126, 0.0332, KL_dist: 1.4254, 0.9014, 1.1660, param: [ 9.71858708  4.83463329 10.31458239  7.03854363], weights: [0.33387984 0.34216094 0.32395922], train_wt_loss:  52.7017, val_wt_loss: 56.3016, train_grp_loss: [18.68658938 18.46165086 15.68334816], val_grp_loss: [18.47095551 20.39558173 17.49688837], train_hist_grp_loss: [17.97733608 20.42734209 14.96098625], cur_train_grp_loss: [0.1796723  0.20289435 0.14935662], max_reward_err:  0.0707, max_reward_err_index: 0, max_kl_dist:  1.4254, max_kl_dist_index: 0, max_train_grp_loss:  18.6866, max_train_grp_loss_index: 0, max_val_grp_loss:  20.3956, max_val_grp_loss_index: 1, max_cur_train_grp_loss:  0.2029, max_cur_train_grp_loss_index: 1, 
2024-09-18 16:05:33,253 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:387] - INFO: Policy parameter learned solely on the preference data rdpo: [ 9.71858708  4.83463329 10.31458239  7.03854363].
2024-09-18 16:05:33,575 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Uniform reward: 3.8069, 3.8069, 3.2022
2024-09-18 16:05:33,576 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Optimal reward: 3.8516, 3.8516, 3.3521
2024-09-18 16:05:33,576 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Policy reward: 3.5792, 3.8030, 3.2408
2024-09-18 16:05:33,577 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Reward Error: 0.0707, 0.0126, 0.0332
2024-09-18 16:05:34,250 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:416] - INFO: Optimal reward: 3.8516, 3.8516, 3.3521
Known param reward: [[3.8516299724578857, 3.4543135166168213, 3.311732530593872], [3.4543135166168213, 3.8516299724578857, 3.15214204788208], [3.8093669414520264, 3.581690788269043, 3.3521463871002197]], Known param reward error: [[0.0, 0.10315540658946536, 0.012056113259811346], [0.10315540658946536, 0.0, 0.05966455999290465], [0.010972765117125093, 0.07008440221909046, 0.0]].
