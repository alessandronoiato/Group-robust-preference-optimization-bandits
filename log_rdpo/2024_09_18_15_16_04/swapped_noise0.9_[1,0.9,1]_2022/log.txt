2024-09-18 15:44:39,843 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log_rdpo/2024_09_18_15_16_04/swapped_noise0.9_[1,0.9,1]_2022
2024-09-18 15:44:39,845 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2022
2024-09-18 15:44:39,845 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-09-18 15:44:40,010 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.3352, l2 distance: 43.9297, acc: 0.84.
2024-09-18 15:44:40,011 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-18 15:44:40,012 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [19.08965865  8.96320989 17.85715783  8.46320643]
2024-09-18 15:44:40,224 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.5953, 3.8576, 3.2072
2024-09-18 15:44:40,484 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-18 15:44:41,654 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  14.3518, val_loss:  15.1066, grad_norm: 0.2997, live_grad: 0.0000, reward_err: 0.0838, 0.0004, 0.0474, KL_dist: 2.2438, 1.3374, 1.8638, param: [12.70787192  4.52110594 14.77013203  5.44183165], weights: [0.33337915 0.33325841 0.33336244], train_wt_loss:  43.0555, val_wt_loss: 45.3199, train_grp_loss: [16.95450374  8.2210306  17.94739792], val_grp_loss: [21.00362002  8.6171943  15.63424514], train_hist_grp_loss: [0.23162082 0.19539761 0.22660936], cur_train_grp_loss: [0.23162082 0.19539761 0.22660936], max_reward_err:  0.0838, max_reward_err_index: 0, max_kl_dist:  2.2438, max_kl_dist_index: 0, max_train_grp_loss:  17.9474, max_train_grp_loss_index: 2, max_val_grp_loss:  21.0036, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2316, max_cur_train_grp_loss_index: 0, 
2024-09-18 15:44:46,102 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  99, train_loss:  14.3560, val_loss:  15.1132, grad_norm: 0.0094,  live_grad: 0.0000, reward_err: 0.0832, 0.0005, 0.0470, KL_dist: 2.2679, 1.3641, 1.8886, param: [12.79192135  4.736964   14.9059574   5.61711751], weights: [0.34311832 0.31333665 0.34354503], train_wt_loss:  43.0681, val_wt_loss: 45.3397, train_grp_loss: [16.811118    8.49448331 17.82533996], val_grp_loss: [20.88092156  8.89052068 15.50743634], train_hist_grp_loss: [17.46348928  8.38377274 17.58777268], cur_train_grp_loss: [0.17332555 0.08407492 0.17477047], max_reward_err:  0.0832, max_reward_err_index: 0, max_kl_dist:  2.2679, max_kl_dist_index: 0, max_train_grp_loss:  17.8253, max_train_grp_loss_index: 2, max_val_grp_loss:  20.8809, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.1748, max_cur_train_grp_loss_index: 2, 
2024-09-18 15:44:46,326 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:387] - INFO: Policy parameter learned solely on the preference data rdpo: [12.79192135  4.736964   14.9059574   5.61711751].
2024-09-18 15:44:46,656 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Uniform reward: 3.8425, 3.8425, 3.1988
2024-09-18 15:44:46,657 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Optimal reward: 3.8738, 3.8738, 3.3306
2024-09-18 15:44:46,658 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Policy reward: 3.5514, 3.8718, 3.1741
2024-09-18 15:44:46,658 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Reward Error: 0.0832, 0.0005, 0.0470
2024-09-18 15:44:47,335 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:416] - INFO: Optimal reward: 3.8738, 3.8738, 3.3306
Known param reward: [[3.873821496963501, 3.54714035987854, 3.280407190322876], [3.54714035987854, 3.873821496963501, 3.172149896621704], [3.830048084259033, 3.6424906253814697, 3.330552816390991]], Known param reward error: [[0.0, 0.08433045697666511, 0.015056247065450643], [0.08433045697666511, 0.0, 0.04756054880430737], [0.011299801175345743, 0.059716450993769384, 0.0]].
