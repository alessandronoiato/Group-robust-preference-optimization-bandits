2024-09-18 16:03:31,509 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log_rdpo/2024_09_18_15_16_04/swapped_noise0.3_[1,0.3,1]_2021
2024-09-18 16:03:31,511 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2021
2024-09-18 16:03:31,511 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-09-18 16:03:31,677 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.5459, l2 distance: 9.5949, acc: 0.76.
2024-09-18 16:03:31,677 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-18 16:03:31,678 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [5.14645297 2.17027301 5.65774903 3.64849919]
2024-09-18 16:03:31,886 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.5048, 3.7725, 3.1313
2024-09-18 16:03:32,116 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-18 16:03:33,284 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  18.9632, val_loss:  18.4460, grad_norm: 0.2209, live_grad: 0.0000, reward_err: 0.0895, 0.0085, 0.0504, KL_dist: 1.2074, 0.6544, 0.9591, param: [8.35237384 3.00135751 9.71524897 5.69250312], weights: [0.33332338 0.33332644 0.33335018], train_wt_loss:  56.8896, val_wt_loss: 55.3380, train_grp_loss: [19.8469216  18.83967764 18.16950584], val_grp_loss: [20.23673321 16.4240174  18.70627664], train_hist_grp_loss: [0.22119248 0.22211087 0.22923387], cur_train_grp_loss: [0.22119248 0.22211087 0.22923387], max_reward_err:  0.0895, max_reward_err_index: 0, max_kl_dist:  1.2074, max_kl_dist_index: 0, max_train_grp_loss:  19.8469, max_train_grp_loss_index: 0, max_val_grp_loss:  20.2367, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2292, max_cur_train_grp_loss_index: 2, 
2024-09-18 16:03:37,694 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  99, train_loss:  18.9633, val_loss:  18.4441, grad_norm: 0.0017,  live_grad: 0.0000, reward_err: 0.0884, 0.0090, 0.0495, KL_dist: 1.2098, 0.6593, 0.9618, param: [8.36569426 3.03789124 9.731302   5.73191814], weights: [0.3361695  0.33002509 0.3338054 ], train_wt_loss:  56.8900, val_wt_loss: 55.3323, train_grp_loss: [19.81738152 18.89334608 18.14173199], val_grp_loss: [20.20824633 16.47401954 18.67887516], train_hist_grp_loss: [19.8550736  18.01039087 19.14934249], cur_train_grp_loss: [0.19817674 0.17993153 0.19096849], max_reward_err:  0.0884, max_reward_err_index: 0, max_kl_dist:  1.2098, max_kl_dist_index: 0, max_train_grp_loss:  19.8174, max_train_grp_loss_index: 0, max_val_grp_loss:  20.2082, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.1982, max_cur_train_grp_loss_index: 0, 
2024-09-18 16:03:37,912 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:387] - INFO: Policy parameter learned solely on the preference data rdpo: [8.36569426 3.03789124 9.731302   5.73191814].
2024-09-18 16:03:38,235 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Uniform reward: 3.7839, 3.7839, 3.1489
2024-09-18 16:03:38,236 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Optimal reward: 3.8160, 3.8160, 3.2742
2024-09-18 16:03:38,236 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Policy reward: 3.4787, 3.7818, 3.1121
2024-09-18 16:03:38,237 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Reward Error: 0.0884, 0.0090, 0.0495
2024-09-18 16:03:38,908 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:416] - INFO: Optimal reward: 3.8160, 3.8160, 3.2742
Known param reward: [[3.816042423248291, 3.418431043624878, 3.2406399250030518], [3.418431043624878, 3.816042423248291, 3.0701699256896973], [3.7798354625701904, 3.5481436252593994, 3.2741682529449463]], Known param reward error: [[0.0, 0.10419469584537752, 0.01024025809050513], [0.10419469584537752, 0.0, 0.062305389184493805], [0.00948809176164255, 0.07020330705884838, 0.0]].
