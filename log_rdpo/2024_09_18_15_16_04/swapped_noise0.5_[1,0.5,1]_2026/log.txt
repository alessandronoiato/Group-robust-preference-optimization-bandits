2024-09-18 15:58:44,612 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log_rdpo/2024_09_18_15_16_04/swapped_noise0.5_[1,0.5,1]_2026
2024-09-18 15:58:44,614 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2026
2024-09-18 15:58:44,614 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-09-18 15:58:44,774 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.3777, l2 distance: 27.5739, acc: 0.83.
2024-09-18 15:58:44,775 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-18 15:58:44,776 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [12.91962812  7.82453273  9.98957798  7.56196729]
2024-09-18 15:58:44,980 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.6069, 3.8094, 3.2118
2024-09-18 15:58:45,233 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-18 15:58:46,424 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  15.0404, val_loss:  17.0628, grad_norm: 0.2590, live_grad: 0.0000, reward_err: 0.0919, 0.0104, 0.0544, KL_dist: 1.6836, 0.9180, 1.4245, param: [13.56370086  6.36161164  7.13814763  4.98648581], weights: [0.33338717 0.33316867 0.33344417], train_wt_loss:  45.1212, val_wt_loss: 51.1885, train_grp_loss: [17.41665599 11.57315432 16.11150632], val_grp_loss: [19.21829504 14.33593141 17.5226834 ], train_hist_grp_loss: [0.20893844 0.14337754 0.22603423], cur_train_grp_loss: [0.20893844 0.14337754 0.22603423], max_reward_err:  0.0919, max_reward_err_index: 0, max_kl_dist:  1.6836, max_kl_dist_index: 0, max_train_grp_loss:  17.4167, max_train_grp_loss_index: 0, max_val_grp_loss:  19.2183, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2260, max_cur_train_grp_loss_index: 2, 
2024-09-18 15:58:50,821 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  99, train_loss:  15.0418, val_loss:  17.0749, grad_norm: 0.0056,  live_grad: 0.0000, reward_err: 0.0914, 0.0109, 0.0539, KL_dist: 1.6980, 0.9356, 1.4393, param: [13.6440068   6.47233994  7.17623198  5.08157474], weights: [0.33823605 0.32163279 0.34013116], train_wt_loss:  45.1254, val_wt_loss: 51.2247, train_grp_loss: [17.34142261 11.7279281  16.03369987], val_grp_loss: [19.14968518 14.51286417 17.45301212], train_hist_grp_loss: [16.59521189 11.5618604  17.15394059], cur_train_grp_loss: [0.16516362 0.11610227 0.17057961], max_reward_err:  0.0914, max_reward_err_index: 0, max_kl_dist:  1.6980, max_kl_dist_index: 0, max_train_grp_loss:  17.3414, max_train_grp_loss_index: 0, max_val_grp_loss:  19.1497, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.1706, max_cur_train_grp_loss_index: 2, 
2024-09-18 15:58:51,039 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:387] - INFO: Policy parameter learned solely on the preference data rdpo: [13.6440068   6.47233994  7.17623198  5.08157474].
2024-09-18 15:58:51,360 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Uniform reward: 3.8371, 3.8371, 3.1972
2024-09-18 15:58:51,361 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Optimal reward: 3.8738, 3.8738, 3.3175
2024-09-18 15:58:51,361 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Policy reward: 3.5196, 3.8314, 3.1385
2024-09-18 15:58:51,362 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Reward Error: 0.0914, 0.0109, 0.0539
2024-09-18 15:58:52,034 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:416] - INFO: Optimal reward: 3.8738, 3.8738, 3.3175
Known param reward: [[3.8737521171569824, 3.4834368228912354, 3.283886432647705], [3.4834368228912354, 3.8737521171569824, 3.128574848175049], [3.83065128326416, 3.603095769882202, 3.3174588680267334]], Known param reward error: [[0.0, 0.10075897539675477, 0.010119925133841261], [0.10075897539675477, 0.0, 0.05693635621894995], [0.011126378918756102, 0.06986929960645492, 0.0]].
