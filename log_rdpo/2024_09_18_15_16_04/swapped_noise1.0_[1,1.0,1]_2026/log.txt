2024-09-18 15:42:39,810 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log_rdpo/2024_09_18_15_16_04/swapped_noise1.0_[1,1.0,1]_2026
2024-09-18 15:42:39,812 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2026
2024-09-18 15:42:39,812 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-09-18 15:42:39,975 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.3087, l2 distance: 38.9242, acc: 0.85.
2024-09-18 15:42:39,976 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-18 15:42:39,977 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [15.88878879  8.80170801 16.01295451  9.88039608]
2024-09-18 15:42:40,190 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.5908, 3.8271, 3.2006
2024-09-18 15:42:40,441 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-18 15:42:41,634 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  13.4192, val_loss:  14.0323, grad_norm: 0.2676, live_grad: 0.0000, reward_err: 0.0870, 0.0022, 0.0464, KL_dist: 2.0305, 1.2295, 1.6846, param: [12.10218496  6.2922392  13.44193991  5.18633949], weights: [0.33338144 0.33319094 0.33342763], train_wt_loss:  40.2575, val_wt_loss: 42.0968, train_grp_loss: [19.04301373  6.37026789 14.71101654], val_grp_loss: [18.28658065  7.93671035 15.28820238], train_hist_grp_loss: [0.20616348 0.14900545 0.22001781], cur_train_grp_loss: [0.20616348 0.14900545 0.22001781], max_reward_err:  0.0870, max_reward_err_index: 0, max_kl_dist:  2.0305, max_kl_dist_index: 0, max_train_grp_loss:  19.0430, max_train_grp_loss_index: 0, max_val_grp_loss:  18.2866, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2200, max_cur_train_grp_loss_index: 2, 
2024-09-18 15:42:46,104 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  99, train_loss:  13.4246, val_loss:  14.0551, grad_norm: 0.0106,  live_grad: 0.0000, reward_err: 0.0853, 0.0028, 0.0450, KL_dist: 2.0492, 1.2603, 1.7053, param: [12.22841292  6.53878591 13.50557697  5.39648506], weights: [0.34884287 0.31078318 0.34037395], train_wt_loss:  40.2738, val_wt_loss: 42.1652, train_grp_loss: [18.89568962  6.68032376 14.55973828], val_grp_loss: [18.13099618  8.33852315 15.14261329], train_hist_grp_loss: [18.09270784  6.54009729 15.63503402], cur_train_grp_loss: [0.17997339 0.06610871 0.15490729], max_reward_err:  0.0853, max_reward_err_index: 0, max_kl_dist:  2.0492, max_kl_dist_index: 0, max_train_grp_loss:  18.8957, max_train_grp_loss_index: 0, max_val_grp_loss:  18.1310, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.1800, max_cur_train_grp_loss_index: 0, 
2024-09-18 15:42:46,325 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:387] - INFO: Policy parameter learned solely on the preference data rdpo: [12.22841292  6.53878591 13.50557697  5.39648506].
2024-09-18 15:42:46,654 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Uniform reward: 3.8214, 3.8214, 3.1807
2024-09-18 15:42:46,655 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Optimal reward: 3.8609, 3.8609, 3.3073
2024-09-18 15:42:46,655 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Policy reward: 3.5314, 3.8502, 3.1584
2024-09-18 15:42:46,656 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Reward Error: 0.0853, 0.0028, 0.0450
2024-09-18 15:42:47,339 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:416] - INFO: Optimal reward: 3.8609, 3.8609, 3.3073
Known param reward: [[3.8608756065368652, 3.4840316772460938, 3.274003028869629], [3.4840316772460938, 3.8608756065368652, 3.124580144882202], [3.820035219192505, 3.599329948425293, 3.307262659072876]], Known param reward error: [[0.0, 0.09760581994735479, 0.010056543320502622], [0.09760581994735479, 0.0, 0.055236772225972876], [0.010578011701597771, 0.06774257571747408, 0.0]].
