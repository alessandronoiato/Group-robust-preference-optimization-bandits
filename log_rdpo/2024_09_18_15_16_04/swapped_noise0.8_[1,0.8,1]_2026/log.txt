2024-09-18 15:49:10,913 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log_rdpo/2024_09_18_15_16_04/swapped_noise0.8_[1,0.8,1]_2026
2024-09-18 15:49:10,915 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2026
2024-09-18 15:49:10,916 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-09-18 15:49:11,086 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.3977, l2 distance: 25.9068, acc: 0.83.
2024-09-18 15:49:11,087 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-18 15:49:11,088 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [11.60729834  4.46739144 11.40637411  7.49257033]
2024-09-18 15:49:11,304 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.5574, 3.8264, 3.1706
2024-09-18 15:49:11,561 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-18 15:49:12,812 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  14.8331, val_loss:  15.7080, grad_norm: 0.3162, live_grad: 0.0000, reward_err: 0.0904, 0.0013, 0.0492, KL_dist: 2.0136, 1.1838, 1.6582, param: [11.86029919  4.08842622 13.38497863  6.07058516], weights: [0.33331241 0.33329595 0.33339165], train_wt_loss:  44.4994, val_wt_loss: 47.1241, train_grp_loss: [18.04658717  9.6565577  16.80566339], val_grp_loss: [19.34475895 10.38972946 16.79817442], train_hist_grp_loss: [0.22050169 0.2155623  0.24427144], cur_train_grp_loss: [0.22050169 0.2155623  0.24427144], max_reward_err:  0.0904, max_reward_err_index: 0, max_kl_dist:  2.0136, max_kl_dist_index: 0, max_train_grp_loss:  18.0466, max_train_grp_loss_index: 0, max_val_grp_loss:  19.3448, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2443, max_cur_train_grp_loss_index: 2, 
2024-09-18 15:49:17,378 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  99, train_loss:  14.8369, val_loss:  15.7270, grad_norm: 0.0080,  live_grad: 0.0000, reward_err: 0.0886, 0.0019, 0.0476, KL_dist: 2.0274, 1.2078, 1.6744, param: [11.9323878   4.31897645 13.46532654  6.27964072], weights: [0.34057862 0.31645571 0.34296567], train_wt_loss:  44.5108, val_wt_loss: 47.1809, train_grp_loss: [17.90358421  9.95277194 16.65932412], val_grp_loss: [19.20612324 10.77347077 16.64988769], train_hist_grp_loss: [17.16909373  9.82282366 17.86752786], cur_train_grp_loss: [0.17052405 0.09851161 0.17724254], max_reward_err:  0.0886, max_reward_err_index: 0, max_kl_dist:  2.0274, max_kl_dist_index: 0, max_train_grp_loss:  17.9036, max_train_grp_loss_index: 0, max_val_grp_loss:  19.2061, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.1772, max_cur_train_grp_loss_index: 2, 
2024-09-18 15:49:17,606 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:387] - INFO: Policy parameter learned solely on the preference data rdpo: [11.9323878   4.31897645 13.46532654  6.27964072].
2024-09-18 15:49:17,939 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Uniform reward: 3.8147, 3.8147, 3.1704
2024-09-18 15:49:17,940 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Optimal reward: 3.8534, 3.8534, 3.2942
2024-09-18 15:49:17,940 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Policy reward: 3.5120, 3.8462, 3.1373
2024-09-18 15:49:17,941 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Reward Error: 0.0886, 0.0019, 0.0476
2024-09-18 15:49:18,642 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:416] - INFO: Optimal reward: 3.8534, 3.8534, 3.2942
Known param reward: [[3.85337495803833, 3.4755589962005615, 3.260967493057251], [3.4755589962005615, 3.85337495803833, 3.111621856689453], [3.811624526977539, 3.59085750579834, 3.2942490577697754]], Known param reward error: [[0.0, 0.0980480659037932, 0.01010292911339746], [0.0980480659037932, 0.0, 0.05543818875794469], [0.010834769913500776, 0.06812663057675347, 0.0]].
