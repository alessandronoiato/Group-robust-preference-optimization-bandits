2024-09-18 15:57:08,519 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log_rdpo/2024_09_18_15_16_04/swapped_noise0.5_[1,0.5,1]_2021
2024-09-18 15:57:08,521 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2021
2024-09-18 15:57:08,521 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-09-18 15:57:08,678 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.4932, l2 distance: 12.4583, acc: 0.83.
2024-09-18 15:57:08,679 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-18 15:57:08,679 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [6.14416532 4.10611549 6.4709344  4.40162939]
2024-09-18 15:57:08,886 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.6199, 3.8275, 3.2155
2024-09-18 15:57:09,131 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-18 15:57:10,284 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  17.3433, val_loss:  17.3830, grad_norm: 0.2542, live_grad: 0.0000, reward_err: 0.0886, 0.0038, 0.0478, KL_dist: 1.2087, 0.6914, 0.9794, param: [ 8.63826535  4.63774076 10.05609637  5.06940734], weights: [0.33339228 0.33319725 0.33341047], train_wt_loss:  52.0300, val_wt_loss: 52.1490, train_grp_loss: [18.97087716 15.93096294 17.1912149 ], val_grp_loss: [19.64364435 15.37571808 17.22974992], train_hist_grp_loss: [0.23125893 0.17274146 0.23671243], cur_train_grp_loss: [0.23125893 0.17274146 0.23671243], max_reward_err:  0.0886, max_reward_err_index: 0, max_kl_dist:  1.2087, max_kl_dist_index: 0, max_train_grp_loss:  18.9709, max_train_grp_loss_index: 0, max_val_grp_loss:  19.6436, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2367, max_cur_train_grp_loss_index: 2, 
2024-09-18 15:57:14,709 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  99, train_loss:  17.3440, val_loss:  17.3782, grad_norm: 0.0035,  live_grad: 0.0000, reward_err: 0.0885, 0.0046, 0.0478, KL_dist: 1.2140, 0.7010, 0.9857, param: [ 8.63032537  4.71975183 10.11503818  5.14713988], weights: [0.33844326 0.326019   0.33553775], train_wt_loss:  52.0320, val_wt_loss: 52.1345, train_grp_loss: [18.91335971 16.039679   17.13362693], val_grp_loss: [19.58888616 15.46191582 17.17821733], train_hist_grp_loss: [18.98412442 15.24404548 18.12192544], cur_train_grp_loss: [0.18913933 0.15274836 0.18036001], max_reward_err:  0.0885, max_reward_err_index: 0, max_kl_dist:  1.2140, max_kl_dist_index: 0, max_train_grp_loss:  18.9134, max_train_grp_loss_index: 0, max_val_grp_loss:  19.5889, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.1891, max_cur_train_grp_loss_index: 0, 
2024-09-18 15:57:14,925 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:387] - INFO: Policy parameter learned solely on the preference data rdpo: [ 8.63032537  4.71975183 10.11503818  5.14713988].
2024-09-18 15:57:15,246 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Uniform reward: 3.8503, 3.8503, 3.2061
2024-09-18 15:57:15,247 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Optimal reward: 3.8851, 3.8851, 3.3189
2024-09-18 15:57:15,247 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Policy reward: 3.5411, 3.8673, 3.1601
2024-09-18 15:57:15,248 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Reward Error: 0.0885, 0.0046, 0.0478
2024-09-18 15:57:15,918 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:416] - INFO: Optimal reward: 3.8851, 3.8851, 3.3189
Known param reward: [[3.88508939743042, 3.4581034183502197, 3.2941160202026367], [3.4581034183502197, 3.88508939743042, 3.1016483306884766], [3.85002064704895, 3.5887107849121094, 3.318911552429199]], Known param reward error: [[0.0, 0.10990377193446481, 0.007470983132531505], [0.10990377193446481, 0.0, 0.06546219093476653], [0.009026497666865538, 0.07628617573493521, 0.0]].
