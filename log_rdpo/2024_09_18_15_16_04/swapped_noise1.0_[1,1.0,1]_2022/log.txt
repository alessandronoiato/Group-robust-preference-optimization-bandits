2024-09-18 15:41:20,423 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log_rdpo/2024_09_18_15_16_04/swapped_noise1.0_[1,1.0,1]_2022
2024-09-18 15:41:20,424 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2022
2024-09-18 15:41:20,425 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-09-18 15:41:20,592 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.3316, l2 distance: 39.4446, acc: 0.83.
2024-09-18 15:41:20,593 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-18 15:41:20,594 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [16.35863729  9.16281242 16.84987109  7.67203992]
2024-09-18 15:41:20,803 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.6080, 3.8501, 3.2158
2024-09-18 15:41:21,056 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-18 15:41:22,233 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  14.1493, val_loss:  14.3858, grad_norm: 0.2573, live_grad: 0.0000, reward_err: 0.0801, 0.0005, 0.0440, KL_dist: 2.1107, 1.2508, 1.7483, param: [12.59928615  4.88174311 13.85531942  5.15044657], weights: [0.33346304 0.33315452 0.33338244], train_wt_loss:  42.4480, val_wt_loss: 43.1575, train_grp_loss: [19.60859429  7.17620229 15.86246629], val_grp_loss: [20.47688718  7.06393916 15.98688058], train_hist_grp_loss: [0.2357484  0.14318371 0.21157298], cur_train_grp_loss: [0.2357484  0.14318371 0.21157298], max_reward_err:  0.0801, max_reward_err_index: 0, max_kl_dist:  2.1107, max_kl_dist_index: 0, max_train_grp_loss:  19.6086, max_train_grp_loss_index: 0, max_val_grp_loss:  20.4769, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2357, max_cur_train_grp_loss_index: 0, 
2024-09-18 15:41:26,709 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  99, train_loss:  14.1560, val_loss:  14.4045, grad_norm: 0.0110,  live_grad: 0.0000, reward_err: 0.0802, 0.0008, 0.0442, KL_dist: 2.1258, 1.2747, 1.7674, param: [12.50681046  5.15603199 14.06921755  5.39381344], weights: [0.35275708 0.31038756 0.33685537], train_wt_loss:  42.4680, val_wt_loss: 43.2134, train_grp_loss: [19.40715905  7.54325611 15.71015658], val_grp_loss: [20.29518962  7.43056062 15.83513508], train_hist_grp_loss: [20.1472495  7.351455  15.5346501], cur_train_grp_loss: [0.20009498 0.07464663 0.15403641], max_reward_err:  0.0802, max_reward_err_index: 0, max_kl_dist:  2.1258, max_kl_dist_index: 0, max_train_grp_loss:  19.4072, max_train_grp_loss_index: 0, max_val_grp_loss:  20.2952, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2001, max_cur_train_grp_loss_index: 0, 
2024-09-18 15:41:26,933 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:387] - INFO: Policy parameter learned solely on the preference data rdpo: [12.50681046  5.15603199 14.06921755  5.39381344].
2024-09-18 15:41:27,262 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Uniform reward: 3.8395, 3.8395, 3.1958
2024-09-18 15:41:27,262 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Optimal reward: 3.8707, 3.8707, 3.3276
2024-09-18 15:41:27,263 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Policy reward: 3.5604, 3.8677, 3.1806
2024-09-18 15:41:27,263 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Reward Error: 0.0802, 0.0008, 0.0442
2024-09-18 15:41:27,944 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:416] - INFO: Optimal reward: 3.8707, 3.8707, 3.3276
Known param reward: [[3.870737075805664, 3.5440561771392822, 3.277423858642578], [3.5440561771392822, 3.870737075805664, 3.1691665649414062], [3.8269641399383545, 3.639406681060791, 3.327569007873535]], Known param reward error: [[0.0, 0.08439759463599984, 0.015069604600928176], [0.08439759463599984, 0.0, 0.04760305272627693], [0.011308682302633167, 0.059763913232655674, 0.0]].
