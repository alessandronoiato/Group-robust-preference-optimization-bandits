2024-09-18 16:06:06,648 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log_rdpo/2024_09_18_15_16_04/swapped_noise0.3_[1,0.3,1]_2029
2024-09-18 16:06:06,650 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2029
2024-09-18 16:06:06,650 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-09-18 16:06:06,812 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.5283, l2 distance: 10.5358, acc: 0.78.
2024-09-18 16:06:06,813 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-18 16:06:06,813 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [6.17680958 2.52010835 5.71404645 2.41442656]
2024-09-18 16:06:07,019 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.4885, 3.8396, 3.1360
2024-09-18 16:06:07,251 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-18 16:06:08,401 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  18.2217, val_loss:  19.1429, grad_norm: 0.1585, live_grad: 0.0000, reward_err: 0.1004, 0.0003, 0.0578, KL_dist: 1.4401, 0.6814, 1.1436, param: [10.58398146  3.83006326  9.13467754  3.49382188], weights: [0.3334067  0.33322132 0.33337198], train_wt_loss:  54.6652, val_wt_loss: 57.4287, train_grp_loss: [19.74311336 17.17335306 17.93336582], val_grp_loss: [21.27787875 16.97103768 19.0169276 ], train_hist_grp_loss: [0.22567658 0.17006023 0.21526186], cur_train_grp_loss: [0.22567658 0.17006023 0.21526186], max_reward_err:  0.1004, max_reward_err_index: 0, max_kl_dist:  1.4401, max_kl_dist_index: 0, max_train_grp_loss:  19.7431, max_train_grp_loss_index: 0, max_val_grp_loss:  21.2779, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2257, max_cur_train_grp_loss_index: 0, 
2024-09-18 16:06:12,845 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  99, train_loss:  18.2226, val_loss:  19.1340, grad_norm: 0.0040,  live_grad: 0.0000, reward_err: 0.0991, 0.0004, 0.0566, KL_dist: 1.4474, 0.6924, 1.1509, param: [10.59007198  3.91024255  9.23033281  3.57785576], weights: [0.341828   0.32414481 0.33402719], train_wt_loss:  54.6678, val_wt_loss: 57.4021, train_grp_loss: [19.6804419  17.28268954 17.87208366], val_grp_loss: [21.21902093 17.07036881 18.95464894], train_hist_grp_loss: [20.98624519 15.67451391 18.67771692], cur_train_grp_loss: [0.20937311 0.15710516 0.18617395], max_reward_err:  0.0991, max_reward_err_index: 0, max_kl_dist:  1.4474, max_kl_dist_index: 0, max_train_grp_loss:  19.6804, max_train_grp_loss_index: 0, max_val_grp_loss:  21.2190, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2094, max_cur_train_grp_loss_index: 0, 
2024-09-18 16:06:13,066 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:387] - INFO: Policy parameter learned solely on the preference data rdpo: [10.59007198  3.91024255  9.23033281  3.57785576].
2024-09-18 16:06:13,393 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Uniform reward: 3.8042, 3.8042, 3.1701
2024-09-18 16:06:13,394 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Optimal reward: 3.8441, 3.8441, 3.3031
2024-09-18 16:06:13,394 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Policy reward: 3.4631, 3.8424, 3.1162
2024-09-18 16:06:13,395 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Reward Error: 0.0991, 0.0004, 0.0566
2024-09-18 16:06:14,059 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:416] - INFO: Optimal reward: 3.8441, 3.8441, 3.3031
Known param reward: [[3.8440520763397217, 3.454845666885376, 3.27467942237854], [3.454845666885376, 3.8440520763397217, 3.1118218898773193], [3.806739330291748, 3.5654454231262207, 3.3031394481658936]], Known param reward error: [[0.0, 0.10124899499929386, 0.008616053374057906], [0.10124899499929386, 0.0, 0.057919915671379094], [0.009706618252555662, 0.07247733581143058, 0.0]].
