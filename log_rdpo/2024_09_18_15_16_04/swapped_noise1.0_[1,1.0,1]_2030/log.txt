2024-09-18 15:43:59,353 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log_rdpo/2024_09_18_15_16_04/swapped_noise1.0_[1,1.0,1]_2030
2024-09-18 15:43:59,355 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2030
2024-09-18 15:43:59,355 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-09-18 15:43:59,521 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.3479, l2 distance: 35.0581, acc: 0.82.
2024-09-18 15:43:59,521 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-18 15:43:59,522 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [15.05760198  9.02088505 13.91934012  8.40113114]
2024-09-18 15:43:59,728 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.6171, 3.8399, 3.2835
2024-09-18 15:43:59,993 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-18 15:44:01,194 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  14.3657, val_loss:  14.7155, grad_norm: 0.3403, live_grad: 0.0000, reward_err: 0.0915, 0.0012, 0.0503, KL_dist: 2.0595, 1.0531, 1.6700, param: [13.27014591  5.08265336 10.92734454  4.60110495], weights: [0.33345432 0.33322723 0.33331845], train_wt_loss:  43.0970, val_wt_loss: 44.1466, train_grp_loss: [19.46867596  6.14885099 18.3352935 ], val_grp_loss: [19.59015648  6.47597188 17.14539084], train_hist_grp_loss: [0.26681289 0.19868818 0.22606044], cur_train_grp_loss: [0.26681289 0.19868818 0.22606044], max_reward_err:  0.0915, max_reward_err_index: 0, max_kl_dist:  2.0595, max_kl_dist_index: 0, max_train_grp_loss:  19.4687, max_train_grp_loss_index: 0, max_val_grp_loss:  19.5902, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2668, max_cur_train_grp_loss_index: 0, 
2024-09-18 15:44:05,646 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  99, train_loss:  14.3743, val_loss:  14.6997, grad_norm: 0.0131,  live_grad: 0.0000, reward_err: 0.0859, 0.0020, 0.0456, KL_dist: 2.0598, 1.0781, 1.6766, param: [13.32364252  5.38057238 10.94120773  4.92367714], weights: [0.35565245 0.30394096 0.34040659], train_wt_loss:  43.1228, val_wt_loss: 44.0991, train_grp_loss: [19.27041619  6.51111434 18.16227599], val_grp_loss: [19.3694808   6.87749894 16.96082961], train_hist_grp_loss: [21.81517208  6.103119   17.43384867], cur_train_grp_loss: [0.21654483 0.06138749 0.17299127], max_reward_err:  0.0859, max_reward_err_index: 0, max_kl_dist:  2.0598, max_kl_dist_index: 0, max_train_grp_loss:  19.2704, max_train_grp_loss_index: 0, max_val_grp_loss:  19.3695, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2165, max_cur_train_grp_loss_index: 0, 
2024-09-18 15:44:05,869 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:387] - INFO: Policy parameter learned solely on the preference data rdpo: [13.32364252  5.38057238 10.94120773  4.92367714].
2024-09-18 15:44:06,198 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Uniform reward: 3.8379, 3.8379, 3.2305
2024-09-18 15:44:06,199 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Optimal reward: 3.8816, 3.8816, 3.3879
2024-09-18 15:44:06,199 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Policy reward: 3.5483, 3.8738, 3.2333
2024-09-18 15:44:06,200 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Reward Error: 0.0859, 0.0020, 0.0456
2024-09-18 15:44:06,905 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:416] - INFO: Optimal reward: 3.8816, 3.8816, 3.3879
Known param reward: [[3.881588935852051, 3.493168592453003, 3.3462095260620117], [3.493168592453003, 3.881588935852051, 3.1958134174346924], [3.8417856693267822, 3.59991455078125, 3.3879454135894775]], Known param reward error: [[0.0, 0.10006735638888185, 0.012318937418548096], [0.10006735638888185, 0.0, 0.05671047573084248], [0.01025437447990131, 0.07256677348524289, 0.0]].
