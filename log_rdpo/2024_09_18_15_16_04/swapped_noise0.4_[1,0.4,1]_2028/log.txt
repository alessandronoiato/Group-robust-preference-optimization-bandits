2024-09-18 16:02:33,895 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log_rdpo/2024_09_18_15_16_04/swapped_noise0.4_[1,0.4,1]_2028
2024-09-18 16:02:33,897 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2028
2024-09-18 16:02:33,897 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-09-18 16:02:34,057 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.5103, l2 distance: 15.4764, acc: 0.73.
2024-09-18 16:02:34,058 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-18 16:02:34,059 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [6.84160916 4.81847435 8.49304786 1.47056677]
2024-09-18 16:02:34,267 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.4529, 3.8020, 3.0781
2024-09-18 16:02:34,535 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-18 16:02:35,694 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  17.9152, val_loss:  17.9472, grad_norm: 0.2340, live_grad: 0.0000, reward_err: 0.1107, 0.0042, 0.0697, KL_dist: 1.7545, 0.9907, 1.4194, param: [ 9.77543262  6.11268657 12.58832912  1.45401188], weights: [0.33325668 0.33332002 0.3334233 ], train_wt_loss:  53.7457, val_wt_loss: 53.8417, train_grp_loss: [21.63189536 13.16364389 17.75432126], val_grp_loss: [19.66598882 15.49650456 18.52002614], train_hist_grp_loss: [0.20400736 0.22300994 0.25399111], cur_train_grp_loss: [0.20400736 0.22300994 0.25399111], max_reward_err:  0.1107, max_reward_err_index: 0, max_kl_dist:  1.7545, max_kl_dist_index: 0, max_train_grp_loss:  21.6319, max_train_grp_loss_index: 0, max_val_grp_loss:  19.6660, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2540, max_cur_train_grp_loss_index: 2, 
2024-09-18 16:02:40,135 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  99, train_loss:  17.9164, val_loss:  17.9338, grad_norm: 0.0047,  live_grad: 0.0000, reward_err: 0.1096, 0.0041, 0.0688, KL_dist: 1.7601, 1.0021, 1.4263, param: [ 9.79689557  6.23386765 12.64443712  1.56267783], weights: [0.33549611 0.32442253 0.34008137], train_wt_loss:  53.7492, val_wt_loss: 53.8015, train_grp_loss: [21.55020613 13.35996938 17.67081139], val_grp_loss: [19.58584359 15.62325211 18.43904949], train_hist_grp_loss: [18.16638195 14.81002224 19.52383639], cur_train_grp_loss: [0.18110094 0.14842216 0.19419381], max_reward_err:  0.1096, max_reward_err_index: 0, max_kl_dist:  1.7601, max_kl_dist_index: 0, max_train_grp_loss:  21.5502, max_train_grp_loss_index: 0, max_val_grp_loss:  19.5858, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.1942, max_cur_train_grp_loss_index: 2, 
2024-09-18 16:02:40,364 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:387] - INFO: Policy parameter learned solely on the preference data rdpo: [ 9.79689557  6.23386765 12.64443712  1.56267783].
2024-09-18 16:02:40,691 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Uniform reward: 3.7921, 3.7921, 3.1395
2024-09-18 16:02:40,692 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Optimal reward: 3.8328, 3.8328, 3.2723
2024-09-18 16:02:40,693 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Policy reward: 3.4127, 3.8170, 3.0473
2024-09-18 16:02:40,693 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Reward Error: 0.1096, 0.0041, 0.0688
2024-09-18 16:02:41,370 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:416] - INFO: Optimal reward: 3.8328, 3.8328, 3.2723
Known param reward: [[3.8328447341918945, 3.4360735416412354, 3.2429821491241455], [3.4360735416412354, 3.8328447341918945, 3.0682969093322754], [3.796973705291748, 3.567776918411255, 3.272308111190796]], Known param reward error: [[0.0, 0.1035187230547478, 0.008961858440640128], [0.1035187230547478, 0.0, 0.06234474105932544], [0.0093588525984759, 0.06915694064412076, 0.0]].
