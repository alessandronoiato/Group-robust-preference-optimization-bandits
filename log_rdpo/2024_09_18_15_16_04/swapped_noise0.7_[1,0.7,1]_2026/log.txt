2024-09-18 15:52:18,419 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log_rdpo/2024_09_18_15_16_04/swapped_noise0.7_[1,0.7,1]_2026
2024-09-18 15:52:18,421 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2026
2024-09-18 15:52:18,421 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-09-18 15:52:18,586 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.4755, l2 distance: 16.9014, acc: 0.77.
2024-09-18 15:52:18,587 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-18 15:52:18,588 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [7.0226657  4.42818104 9.53176052 3.17686003]
2024-09-18 15:52:18,795 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.4968, 3.8612, 3.1627
2024-09-18 15:52:19,059 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-18 15:52:20,231 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  16.7617, val_loss:  15.8995, grad_norm: 0.2261, live_grad: 0.0000, reward_err: 0.1038, 0.0017, 0.0662, KL_dist: 1.8420, 0.9806, 1.5114, param: [ 9.23748375  5.51626802 13.8265395   4.06369003], weights: [0.33332365 0.33328566 0.33339069], train_wt_loss:  50.2851, val_wt_loss: 47.6986, train_grp_loss: [19.40300309 14.10393155 16.66703132], val_grp_loss: [18.97152094 11.17184712 17.25982875], train_hist_grp_loss: [0.21208721 0.20069043 0.23220057], cur_train_grp_loss: [0.21208721 0.20069043 0.23220057], max_reward_err:  0.1038, max_reward_err_index: 0, max_kl_dist:  1.8420, max_kl_dist_index: 0, max_train_grp_loss:  19.4030, max_train_grp_loss_index: 0, max_val_grp_loss:  18.9715, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2322, max_cur_train_grp_loss_index: 2, 
2024-09-18 15:52:24,724 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  99, train_loss:  16.7627, val_loss:  15.9006, grad_norm: 0.0044,  live_grad: 0.0000, reward_err: 0.1038, 0.0017, 0.0662, KL_dist: 1.8491, 0.9906, 1.5199, param: [ 9.21948554  5.61305218 13.89522675  4.16231066], weights: [0.33899559 0.32446482 0.3365396 ], train_wt_loss:  50.2880, val_wt_loss: 47.7019, train_grp_loss: [19.33532183 14.24513154 16.59397984], val_grp_loss: [18.90597068 11.30550579 17.20241345], train_hist_grp_loss: [18.47465117 14.09365257 17.74752411], cur_train_grp_loss: [0.18415236 0.14102668 0.17653944], max_reward_err:  0.1038, max_reward_err_index: 0, max_kl_dist:  1.8491, max_kl_dist_index: 0, max_train_grp_loss:  19.3353, max_train_grp_loss_index: 0, max_val_grp_loss:  18.9060, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.1842, max_cur_train_grp_loss_index: 0, 
2024-09-18 15:52:24,946 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:387] - INFO: Policy parameter learned solely on the preference data rdpo: [ 9.21948554  5.61305218 13.89522675  4.16231066].
2024-09-18 15:52:25,274 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Uniform reward: 3.8338, 3.8338, 3.2190
2024-09-18 15:52:25,275 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Optimal reward: 3.8731, 3.8731, 3.3639
2024-09-18 15:52:25,275 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Policy reward: 3.4712, 3.8665, 3.1413
2024-09-18 15:52:25,275 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Reward Error: 0.1038, 0.0017, 0.0662
2024-09-18 15:52:25,960 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:416] - INFO: Optimal reward: 3.8731, 3.8731, 3.3639
Known param reward: [[3.873142719268799, 3.4625096321105957, 3.3238730430603027], [3.4625096321105957, 3.873142719268799, 3.1438493728637695], [3.8371264934539795, 3.6077330112457275, 3.363903284072876]], Known param reward error: [[0.0, 0.10602064445374364, 0.011899938146885801], [0.10602064445374364, 0.0, 0.06541624197431568], [0.009298966866271003, 0.0685256721118651, 0.0]].
