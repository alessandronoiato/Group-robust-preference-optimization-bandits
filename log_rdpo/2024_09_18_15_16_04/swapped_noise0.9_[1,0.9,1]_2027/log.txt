2024-09-18 15:46:21,026 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log_rdpo/2024_09_18_15_16_04/swapped_noise0.9_[1,0.9,1]_2027
2024-09-18 15:46:21,028 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2027
2024-09-18 15:46:21,028 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-09-18 15:46:21,194 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.3791, l2 distance: 35.9712, acc: 0.80.
2024-09-18 15:46:21,195 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-18 15:46:21,196 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [15.55082776  9.61629557 13.71492516  8.76822564]
2024-09-18 15:46:21,407 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.5916, 3.8140, 3.2522
2024-09-18 15:46:21,654 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-18 15:46:22,815 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  15.1653, val_loss:  14.9129, grad_norm: 0.2541, live_grad: 0.0000, reward_err: 0.0931, 0.0021, 0.0524, KL_dist: 2.3144, 1.3361, 1.9250, param: [15.51531408  5.86612142 11.74598024  6.03076515], weights: [0.33336338 0.33329249 0.33334413], train_wt_loss:  45.4960, val_wt_loss: 44.7386, train_grp_loss: [18.98409657  7.78032988 17.78326157], val_grp_loss: [18.03381702 11.07909388 15.67829774], train_hist_grp_loss: [0.22522557 0.20396028 0.21945171], cur_train_grp_loss: [0.22522557 0.20396028 0.21945171], max_reward_err:  0.0931, max_reward_err_index: 0, max_kl_dist:  2.3144, max_kl_dist_index: 0, max_train_grp_loss:  18.9841, max_train_grp_loss_index: 0, max_val_grp_loss:  18.0338, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2252, max_cur_train_grp_loss_index: 0, 
2024-09-18 15:46:27,256 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  99, train_loss:  15.1716, val_loss:  14.9828, grad_norm: 0.0101,  live_grad: 0.0000, reward_err: 0.0905, 0.0031, 0.0504, KL_dist: 2.3156, 1.3588, 1.9329, param: [15.59339865  6.15697971 11.68893693  6.32635683], weights: [0.34501281 0.31444471 0.34054248], train_wt_loss:  45.5147, val_wt_loss: 44.9483, train_grp_loss: [18.77985995  8.25776515 17.58959719], val_grp_loss: [17.85249783 11.62356152 15.5150245 ], train_hist_grp_loss: [18.1999843   8.92265383 16.89581801], cur_train_grp_loss: [0.18059514 0.09069012 0.16753838], max_reward_err:  0.0905, max_reward_err_index: 0, max_kl_dist:  2.3156, max_kl_dist_index: 0, max_train_grp_loss:  18.7799, max_train_grp_loss_index: 0, max_val_grp_loss:  17.8525, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.1806, max_cur_train_grp_loss_index: 0, 
2024-09-18 15:46:27,474 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:387] - INFO: Policy parameter learned solely on the preference data rdpo: [15.59339865  6.15697971 11.68893693  6.32635683].
2024-09-18 15:46:27,799 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Uniform reward: 3.8228, 3.8228, 3.2184
2024-09-18 15:46:27,799 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Optimal reward: 3.8669, 3.8669, 3.3658
2024-09-18 15:46:27,800 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Policy reward: 3.5170, 3.8550, 3.1962
2024-09-18 15:46:27,800 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Reward Error: 0.0905, 0.0031, 0.0504
2024-09-18 15:46:28,476 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:416] - INFO: Optimal reward: 3.8669, 3.8669, 3.3658
Known param reward: [[3.8669028282165527, 3.4664041996002197, 3.3253726959228516], [3.4664041996002197, 3.8669028282165527, 3.1640493869781494], [3.8246397972106934, 3.594559669494629, 3.3657867908477783]], Known param reward error: [[0.0, 0.10357090581483432, 0.012007324716711247], [0.10357090581483432, 0.0, 0.05993766581358977], [0.01092942669711497, 0.07042927397467878, 0.0]].
