2024-09-18 15:47:54,018 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log_rdpo/2024_09_18_15_16_04/swapped_noise0.8_[1,0.8,1]_2022
2024-09-18 15:47:54,020 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2022
2024-09-18 15:47:54,020 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-09-18 15:47:54,185 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.4777, l2 distance: 18.0881, acc: 0.74.
2024-09-18 15:47:54,186 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-18 15:47:54,187 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [ 6.9603825   4.45961344 10.22326722  4.2247405 ]
2024-09-18 15:47:54,392 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.5682, 3.8547, 3.1741
2024-09-18 15:47:54,647 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-18 15:47:55,826 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  17.1030, val_loss:  15.6120, grad_norm: 0.1956, live_grad: 0.0000, reward_err: 0.0917, 0.0049, 0.0587, KL_dist: 1.7755, 0.9231, 1.5006, param: [ 7.57586844  4.86679041 14.19351791  5.00303094], weights: [0.33337794 0.33328374 0.33333832], train_wt_loss:  51.3090, val_wt_loss: 46.8360, train_grp_loss: [21.36348709 11.97591152 18.1281436 ], val_grp_loss: [19.17405645 10.51553746 17.21370879], train_hist_grp_loss: [0.22007053 0.19181198 0.20818659], cur_train_grp_loss: [0.22007053 0.19181198 0.20818659], max_reward_err:  0.0917, max_reward_err_index: 0, max_kl_dist:  1.7755, max_kl_dist_index: 0, max_train_grp_loss:  21.3635, max_train_grp_loss_index: 0, max_val_grp_loss:  19.1741, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2201, max_cur_train_grp_loss_index: 0, 
2024-09-18 15:48:00,298 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  99, train_loss:  17.1064, val_loss:  15.6256, grad_norm: 0.0087,  live_grad: 0.0000, reward_err: 0.0887, 0.0057, 0.0562, KL_dist: 1.7731, 0.9363, 1.5027, param: [ 7.54688157  5.04585277 14.19937693  5.18780989], weights: [0.3490853  0.31617335 0.33474135], train_wt_loss:  51.3192, val_wt_loss: 46.8769, train_grp_loss: [21.21933524 12.22443601 18.02918329], val_grp_loss: [19.05203261 10.76467118 17.12452844], train_hist_grp_loss: [21.95157309 12.04900398 17.7557552 ], cur_train_grp_loss: [0.21877125 0.12100787 0.17676658], max_reward_err:  0.0887, max_reward_err_index: 0, max_kl_dist:  1.7731, max_kl_dist_index: 0, max_train_grp_loss:  21.2193, max_train_grp_loss_index: 0, max_val_grp_loss:  19.0520, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2188, max_cur_train_grp_loss_index: 0, 
2024-09-18 15:48:00,520 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:387] - INFO: Policy parameter learned solely on the preference data rdpo: [ 7.54688157  5.04585277 14.19937693  5.18780989].
2024-09-18 15:48:00,847 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Uniform reward: 3.8491, 3.8491, 3.2014
2024-09-18 15:48:00,847 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Optimal reward: 3.8793, 3.8793, 3.3301
2024-09-18 15:48:00,848 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Policy reward: 3.5350, 3.8570, 3.1430
2024-09-18 15:48:00,848 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Reward Error: 0.0887, 0.0057, 0.0562
2024-09-18 15:48:01,539 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:416] - INFO: Optimal reward: 3.8793, 3.8793, 3.3301
Known param reward: [[3.879298448562622, 3.552269458770752, 3.2809364795684814], [3.552269458770752, 3.879298448562622, 3.1701314449310303], [3.8373265266418457, 3.6485824584960938, 3.3300602436065674]], Known param reward error: [[0.0, 0.08430106477449359, 0.014751614218511329], [0.08430106477449359, 0.0, 0.04802579742591348], [0.010819461940683636, 0.05947363759857518, 0.0]].
