2024-09-18 16:01:18,421 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log_rdpo/2024_09_18_15_16_04/swapped_noise0.4_[1,0.4,1]_2024
2024-09-18 16:01:18,423 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2024
2024-09-18 16:01:18,424 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-09-18 16:01:18,585 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.4993, l2 distance: 17.5270, acc: 0.79.
2024-09-18 16:01:18,586 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-18 16:01:18,586 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [8.23705571 4.39496946 7.61601428 6.6496933 ]
2024-09-18 16:01:18,790 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.5858, 3.7073, 3.1668
2024-09-18 16:01:19,039 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-18 16:01:20,212 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  18.0449, val_loss:  17.6480, grad_norm: 0.1837, live_grad: 0.0000, reward_err: 0.0611, 0.0173, 0.0289, KL_dist: 1.4639, 1.0121, 1.2082, param: [10.14189741  4.58293219 10.2012202   7.74352031], weights: [0.33336417 0.33330363 0.33333221], train_wt_loss:  54.1347, val_wt_loss: 52.9439, train_grp_loss: [19.83723733 17.15261838 17.01739175], val_grp_loss: [19.13480381 16.99639867 16.77808718], train_hist_grp_loss: [0.21791031 0.19974854 0.20832342], cur_train_grp_loss: [0.21791031 0.19974854 0.20832342], max_reward_err:  0.0611, max_reward_err_index: 0, max_kl_dist:  1.4639, max_kl_dist_index: 0, max_train_grp_loss:  19.8372, max_train_grp_loss_index: 0, max_val_grp_loss:  19.1348, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2179, max_cur_train_grp_loss_index: 0, 
2024-09-18 16:01:24,678 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  99, train_loss:  18.0451, val_loss:  17.6430, grad_norm: 0.0015,  live_grad: 0.0000, reward_err: 0.0613, 0.0173, 0.0291, KL_dist: 1.4576, 1.0036, 1.2020, param: [10.06832003  4.54239376 10.21768395  7.69563514], weights: [0.33617405 0.33648554 0.32734042], train_wt_loss:  54.1353, val_wt_loss: 52.9289, train_grp_loss: [19.86338183 17.07864996 17.05517119], val_grp_loss: [19.16398743 16.91433965 16.81310482], train_hist_grp_loss: [18.93400602 19.02662166 16.27116971], cur_train_grp_loss: [0.18917268 0.18977064 0.16242671], max_reward_err:  0.0613, max_reward_err_index: 0, max_kl_dist:  1.4576, max_kl_dist_index: 0, max_train_grp_loss:  19.8634, max_train_grp_loss_index: 0, max_val_grp_loss:  19.1640, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.1898, max_cur_train_grp_loss_index: 1, 
2024-09-18 16:01:24,895 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:387] - INFO: Policy parameter learned solely on the preference data rdpo: [10.06832003  4.54239376 10.21768395  7.69563514].
2024-09-18 16:01:25,216 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Uniform reward: 3.7439, 3.7439, 3.0964
2024-09-18 16:01:25,217 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Optimal reward: 3.7882, 3.7882, 3.2414
2024-09-18 16:01:25,217 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Policy reward: 3.5559, 3.7226, 3.1471
2024-09-18 16:01:25,218 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Reward Error: 0.0613, 0.0173, 0.0291
2024-09-18 16:01:25,885 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:416] - INFO: Optimal reward: 3.7882, 3.7882, 3.2414
Known param reward: [[3.7881884574890137, 3.4343247413635254, 3.2098934650421143], [3.4343247413635254, 3.7881884574890137, 3.060838222503662], [3.7553627490997314, 3.5580506324768066, 3.2413690090179443]], Known param reward error: [[0.0, 0.093412384335294, 0.009710571023620171], [0.093412384335294, 0.0, 0.055695845185173364], [0.008665278604180274, 0.06075141920598982, 0.0]].
