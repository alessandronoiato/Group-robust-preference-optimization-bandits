2024-09-18 15:56:49,203 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log_rdpo/2024_09_18_15_16_04/swapped_noise0.6_[1,0.6,1]_2030
2024-09-18 15:56:49,205 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2030
2024-09-18 15:56:49,205 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-09-18 15:56:49,368 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.5158, l2 distance: 11.2455, acc: 0.79.
2024-09-18 15:56:49,369 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-18 15:56:49,370 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [6.22996446 2.66590808 6.06671242 3.49468443]
2024-09-18 15:56:49,585 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.5924, 3.8740, 3.2694
2024-09-18 15:56:49,833 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-18 15:56:51,029 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  17.9728, val_loss:  17.8261, grad_norm: 0.1640, live_grad: 0.0000, reward_err: 0.0909, 0.0005, 0.0492, KL_dist: 1.4790, 0.6518, 1.1569, param: [9.98305712 3.07909483 9.50723224 4.31910958], weights: [0.33348181 0.33319731 0.33332088], train_wt_loss:  53.9183, val_wt_loss: 53.4783, train_grp_loss: [21.51284124 14.42591478 18.55277967], val_grp_loss: [20.73649378 13.0041639  19.05940832], train_hist_grp_loss: [0.24912226 0.16377203 0.20085379], cur_train_grp_loss: [0.24912226 0.16377203 0.20085379], max_reward_err:  0.0909, max_reward_err_index: 0, max_kl_dist:  1.4790, max_kl_dist_index: 0, max_train_grp_loss:  21.5128, max_train_grp_loss_index: 0, max_val_grp_loss:  20.7365, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2491, max_cur_train_grp_loss_index: 0, 
2024-09-18 15:56:55,458 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  99, train_loss:  17.9752, val_loss:  17.7888, grad_norm: 0.0074,  live_grad: 0.0000, reward_err: 0.0882, 0.0009, 0.0469, KL_dist: 1.4698, 0.6589, 1.1517, param: [9.92552875 3.23527054 9.54553759 4.46717417], weights: [0.3522758  0.31749069 0.33023351], train_wt_loss:  53.9256, val_wt_loss: 53.3663, train_grp_loss: [21.39905067 14.60943102 18.4709334 ], val_grp_loss: [20.62551887 13.11638464 18.96664825], train_hist_grp_loss: [24.1169035  13.72031158 17.65546487], cur_train_grp_loss: [0.24045193 0.13780639 0.17592163], max_reward_err:  0.0882, max_reward_err_index: 0, max_kl_dist:  1.4698, max_kl_dist_index: 0, max_train_grp_loss:  21.3991, max_train_grp_loss_index: 0, max_val_grp_loss:  20.6255, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2405, max_cur_train_grp_loss_index: 0, 
2024-09-18 15:56:55,678 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:387] - INFO: Policy parameter learned solely on the preference data rdpo: [9.92552875 3.23527054 9.54553759 4.46717417].
2024-09-18 15:56:56,002 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Uniform reward: 3.8520, 3.8520, 3.2425
2024-09-18 15:56:56,003 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Optimal reward: 3.8957, 3.8957, 3.3999
2024-09-18 15:56:56,004 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Policy reward: 3.5520, 3.8920, 3.2404
2024-09-18 15:56:56,004 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Reward Error: 0.0882, 0.0009, 0.0469
2024-09-18 15:56:56,677 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:416] - INFO: Optimal reward: 3.8957, 3.8957, 3.3999
Known param reward: [[3.895703077316284, 3.5065040588378906, 3.358201503753662], [3.5065040588378906, 3.895703077316284, 3.206737756729126], [3.8558998107910156, 3.6177587509155273, 3.399937152862549]], Known param reward error: [[0.0, 0.09990469262008268, 0.012275417818752249], [0.09990469262008268, 0.0, 0.056824402171893156], [0.010217222856904351, 0.07134638366541791, 0.0]].
