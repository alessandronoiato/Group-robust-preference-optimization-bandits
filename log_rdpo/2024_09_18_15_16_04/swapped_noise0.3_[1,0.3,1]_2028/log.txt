2024-09-18 16:05:45,770 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log_rdpo/2024_09_18_15_16_04/swapped_noise0.3_[1,0.3,1]_2028
2024-09-18 16:05:45,772 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2028
2024-09-18 16:05:45,773 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-09-18 16:05:45,938 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.5490, l2 distance: 9.9924, acc: 0.78.
2024-09-18 16:05:45,939 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-18 16:05:45,940 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [5.82429623 4.04486507 5.13720847 2.31809739]
2024-09-18 16:05:46,147 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.5857, 3.8171, 3.2181
2024-09-18 16:05:46,395 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-18 16:05:47,559 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  19.1656, val_loss:  18.7613, grad_norm: 0.1492, live_grad: 0.0000, reward_err: 0.0930, 0.0105, 0.0545, KL_dist: 1.2351, 0.6545, 0.9823, param: [10.18826033  5.8413878   8.05275467  2.84290525], weights: [0.33323077 0.33337754 0.33339169], train_wt_loss:  57.4969, val_wt_loss: 56.2839, train_grp_loss: [21.11718368 18.73906639 17.03551588], val_grp_loss: [20.39656034 17.66744158 18.06403972], train_hist_grp_loss: [0.18317759 0.22721333 0.23145893], cur_train_grp_loss: [0.18317759 0.22721333 0.23145893], max_reward_err:  0.0930, max_reward_err_index: 0, max_kl_dist:  1.2351, max_kl_dist_index: 0, max_train_grp_loss:  21.1172, max_train_grp_loss_index: 0, max_val_grp_loss:  20.3966, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2315, max_cur_train_grp_loss_index: 2, 
2024-09-18 16:05:51,987 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  99, train_loss:  19.1661, val_loss:  18.7621, grad_norm: 0.0029,  live_grad: 0.0000, reward_err: 0.0933, 0.0100, 0.0547, KL_dist: 1.2315, 0.6472, 0.9777, param: [10.13022824  5.76978233  8.08452095  2.78702859], weights: [0.3288767 0.3389127 0.3322106], train_wt_loss:  57.4982, val_wt_loss: 56.2864, train_grp_loss: [21.17337331 18.63163596 17.06973096], val_grp_loss: [20.44177479 17.57756006 18.10489307], train_hist_grp_loss: [17.77468441 20.7806489  18.78330471], cur_train_grp_loss: [0.17792291 0.20702962 0.18757583], max_reward_err:  0.0933, max_reward_err_index: 0, max_kl_dist:  1.2315, max_kl_dist_index: 0, max_train_grp_loss:  21.1734, max_train_grp_loss_index: 0, max_val_grp_loss:  20.4418, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2070, max_cur_train_grp_loss_index: 1, 
2024-09-18 16:05:52,207 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:387] - INFO: Policy parameter learned solely on the preference data rdpo: [10.13022824  5.76978233  8.08452095  2.78702859].
2024-09-18 16:05:52,532 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Uniform reward: 3.8431, 3.8431, 3.2160
2024-09-18 16:05:52,533 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Optimal reward: 3.8795, 3.8795, 3.3513
2024-09-18 16:05:52,533 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Policy reward: 3.5174, 3.8405, 3.1680
2024-09-18 16:05:52,534 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Reward Error: 0.0933, 0.0100, 0.0547
2024-09-18 16:05:53,221 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:416] - INFO: Optimal reward: 3.8795, 3.8795, 3.3513
Known param reward: [[3.879473924636841, 3.4689507484436035, 3.3167123794555664], [3.4689507484436035, 3.879473924636841, 3.1360788345336914], [3.846095323562622, 3.6189825534820557, 3.351266622543335]], Known param reward error: [[0.0, 0.10581928997800044, 0.010310800953683814], [0.10581928997800044, 0.0, 0.06421088270390547], [0.00860389880757952, 0.06714605542275165, 0.0]].
