2024-09-18 15:50:27,199 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log_rdpo/2024_09_18_15_16_04/swapped_noise0.8_[1,0.8,1]_2030
2024-09-18 15:50:27,201 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2030
2024-09-18 15:50:27,202 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-09-18 15:50:27,368 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.3903, l2 distance: 27.8631, acc: 0.83.
2024-09-18 15:50:27,368 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-18 15:50:27,369 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [10.15636855  6.76642894 13.53385788  7.51097068]
2024-09-18 15:50:27,576 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.5106, 3.7696, 3.1588
2024-09-18 15:50:27,825 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-18 15:50:29,037 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  15.2784, val_loss:  16.6828, grad_norm: 0.2203, live_grad: 0.0000, reward_err: 0.1011, 0.0060, 0.0638, KL_dist: 1.9136, 0.9665, 1.6032, param: [ 8.04278845  5.07644577 14.26935469  5.9563343 ], weights: [0.33346898 0.3331799  0.33335112], train_wt_loss:  45.8352, val_wt_loss: 50.0485, train_grp_loss: [18.16986537 10.50697464 17.64443468], val_grp_loss: [19.53956743 11.9010382  17.98896469], train_hist_grp_loss: [0.23601648 0.14928857 0.20066506], cur_train_grp_loss: [0.23601648 0.14928857 0.20066506], max_reward_err:  0.1011, max_reward_err_index: 0, max_kl_dist:  1.9136, max_kl_dist_index: 0, max_train_grp_loss:  18.1699, max_train_grp_loss_index: 0, max_val_grp_loss:  19.5396, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2360, max_cur_train_grp_loss_index: 0, 
2024-09-18 15:50:33,509 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  99, train_loss:  15.2817, val_loss:  16.6824, grad_norm: 0.0080,  live_grad: 0.0000, reward_err: 0.1005, 0.0066, 0.0633, KL_dist: 1.9238, 0.9924, 1.6145, param: [ 8.14578983  5.24663102 14.32471387  6.13352092], weights: [0.34884654 0.31463276 0.33652069], train_wt_loss:  45.8450, val_wt_loss: 50.0471, train_grp_loss: [18.05245936 10.72342477 17.5347083 ], val_grp_loss: [19.41386707 12.17422445 17.87169826], train_hist_grp_loss: [20.38314127 10.06054183 16.78589372], cur_train_grp_loss: [0.20285015 0.10114259 0.16700792], max_reward_err:  0.1005, max_reward_err_index: 0, max_kl_dist:  1.9238, max_kl_dist_index: 0, max_train_grp_loss:  18.0525, max_train_grp_loss_index: 0, max_val_grp_loss:  19.4139, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2029, max_cur_train_grp_loss_index: 0, 
2024-09-18 15:50:33,732 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:387] - INFO: Policy parameter learned solely on the preference data rdpo: [ 8.14578983  5.24663102 14.32471387  6.13352092].
2024-09-18 15:50:34,062 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Uniform reward: 3.7674, 3.7674, 3.1544
2024-09-18 15:50:34,063 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Optimal reward: 3.8061, 3.8061, 3.2958
2024-09-18 15:50:34,064 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Policy reward: 3.4234, 3.7811, 3.0872
2024-09-18 15:50:34,064 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Reward Error: 0.1005, 0.0066, 0.0633
2024-09-18 15:50:34,745 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:416] - INFO: Optimal reward: 3.8061, 3.8061, 3.2958
Known param reward: [[3.8060805797576904, 3.436021089553833, 3.2607407569885254], [3.436021089553833, 3.8060805797576904, 3.1107161045074463], [3.772174119949341, 3.559548854827881, 3.2957820892333984]], Known param reward error: [[0.0, 0.09722849594198997, 0.010632175094143948], [0.09722849594198997, 0.0, 0.056152372855754744], [0.008908497625793363, 0.06477312283953397, 0.0]].
