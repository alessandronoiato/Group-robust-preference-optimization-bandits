2024-09-18 15:47:35,362 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:199] - INFO: Logging to log_rdpo/2024_09_18_15_16_04/swapped_noise0.8_[1,0.8,1]_2021
2024-09-18 15:47:35,364 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:200] - INFO: (IB) Seed: 2021
2024-09-18 15:47:35,364 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:201] - INFO: (IB) Data: 300
2024-09-18 15:47:35,529 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:297] - INFO: MLE reward loss: 0.4323, l2 distance: 20.8234, acc: 0.81.
2024-09-18 15:47:35,530 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:298] - INFO: True reward parameter: [[1.  3.  1.  3. ]
 [3.  1.  3.  1. ]
 [1.5 2.5 1.5 2.5]]
2024-09-18 15:47:35,531 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:299] - INFO: MLE reward parameter: [ 6.19093621  5.23578827 12.25371113  4.32454036]
2024-09-18 15:47:35,743 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:314] - INFO: Learned oracle reward: 3.4904, 3.8706, 3.1036
2024-09-18 15:47:36,001 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1297] - INFO: unique_group_ids: {0, 1, 2}
2024-09-18 15:47:37,186 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1523] - INFO: Iteration:  0, train_loss:  15.8143, val_loss:  16.3247, grad_norm: 0.2138, live_grad: 0.0000, reward_err: 0.1311, 0.0012, 0.0928, KL_dist: 2.1894, 0.8851, 1.8869, param: [ 5.37602674  4.1326761  16.39910847  3.72172926], weights: [0.33336829 0.33322758 0.33340414], train_wt_loss:  47.4430, val_wt_loss: 48.9742, train_grp_loss: [19.50974389 11.36434697 16.84282129], val_grp_loss: [21.31698327  9.27840734 18.40113577], train_hist_grp_loss: [0.21285741 0.17064121 0.22361073], cur_train_grp_loss: [0.21285741 0.17064121 0.22361073], max_reward_err:  0.1311, max_reward_err_index: 0, max_kl_dist:  2.1894, max_kl_dist_index: 0, max_train_grp_loss:  19.5097, max_train_grp_loss_index: 0, max_val_grp_loss:  21.3170, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.2236, max_cur_train_grp_loss_index: 2, 
2024-09-18 15:47:41,661 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/algos/linear_bandit/group_robust_dpo_vectorised_gradfix.py[line:1631] - INFO: Iteration:  99, train_loss:  15.8173, val_loss:  16.2989, grad_norm: 0.0083,  live_grad: 0.0000, reward_err: 0.1295, 0.0015, 0.0913, KL_dist: 2.1956, 0.8974, 1.8956, param: [ 5.38293195  4.28556479 16.46830242  3.89048532], weights: [0.34467645 0.31663429 0.33868926], train_wt_loss:  47.4518, val_wt_loss: 48.8968, train_grp_loss: [19.39467195 11.58177792 16.73285429], val_grp_loss: [21.20713087  9.39792591 18.31311846], train_hist_grp_loss: [19.47132609 10.98545643 17.71901667], cur_train_grp_loss: [0.19395846 0.11028076 0.17614707], max_reward_err:  0.1295, max_reward_err_index: 0, max_kl_dist:  2.1956, max_kl_dist_index: 0, max_train_grp_loss:  19.3947, max_train_grp_loss_index: 0, max_val_grp_loss:  21.2071, max_val_grp_loss_index: 0, max_cur_train_grp_loss:  0.1940, max_cur_train_grp_loss_index: 0, 
2024-09-18 15:47:41,887 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:387] - INFO: Policy parameter learned solely on the preference data rdpo: [ 5.38293195  4.28556479 16.46830242  3.89048532].
2024-09-18 15:47:42,229 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:398] - INFO: Uniform reward: 3.8512, 3.8512, 3.2031
2024-09-18 15:47:42,230 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:399] - INFO: Optimal reward: 3.8864, 3.8864, 3.3152
2024-09-18 15:47:42,231 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:400] - INFO: Policy reward: 3.3833, 3.8803, 3.0124
2024-09-18 15:47:42,232 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:401] - INFO: Reward Error: 0.1295, 0.0015, 0.0913
2024-09-18 15:47:42,934 - /Users/noesis/Projects/Group-robust-preference-optimization-bandits/experiments/run_glb_noisy.py[line:416] - INFO: Optimal reward: 3.8864, 3.8864, 3.3152
Known param reward: [[3.8863613605499268, 3.458714246749878, 3.291393280029297], [3.458714246749878, 3.8863613605499268, 3.0966663360595703], [3.851715087890625, 3.5921897888183594, 3.315164804458618]], Known param reward error: [[0.0, 0.11003791828033614, 0.007170540781969749], [0.11003791828033614, 0.0, 0.06590878019252189], [0.008914835612301181, 0.07569331424444319, 0.0]].
